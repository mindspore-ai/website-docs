

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindspore.nn.thor &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script src="../../_static/js/training.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="mindspore.nn.CosineDecayLR" href="mindspore.nn.CosineDecayLR.html" />
    <link rel="prev" title="mindspore.nn.SGD" href="mindspore.nn.SGD.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/programming_paradigm.html">Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/auto_gradient.html">Functional Differential Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/pluggable_device.html">Third-Party Chip Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/all_scenarios.html">Full-scenarios Unification</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/training_visual_design.html">Design of Visualization↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption"><span class="caption-text">Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/benchmark.html">Benchmarks</a></li>
<li class="toctree-l1"><a class="reference external" href="https://gitee.com/mindspore/models/blob/master/README.md#table-of-contents">Network List↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/operator_list.html">API List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/syntax_list.html">Syntax Support</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../mindspore.html">mindspore</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../mindspore.nn.html">mindspore.nn</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#basic-block">Basic Block</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#container">Container</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#wrapper-layer">Wrapper Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#convolutional-layer">Convolutional Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#recurrent-layer">Recurrent Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#transformer-layer">Transformer Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#embedding-layer">Embedding Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#nonlinear-activation-layer">Nonlinear Activation Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#linear-layer">Linear Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#dropout-layer">Dropout Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#normalization-layer">Normalization Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#pooling-layer">Pooling Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#padding-layer">Padding Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#loss-function">Loss Function</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../mindspore.nn.html#optimizer">Optimizer</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.Adadelta.html">mindspore.nn.Adadelta</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.Adagrad.html">mindspore.nn.Adagrad</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.Adam.html">mindspore.nn.Adam</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.AdaMax.html">mindspore.nn.AdaMax</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.AdamOffload.html">mindspore.nn.AdamOffload</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.AdamWeightDecay.html">mindspore.nn.AdamWeightDecay</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.AdaSumByDeltaWeightWrapCell.html">mindspore.nn.AdaSumByDeltaWeightWrapCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.AdaSumByGradWrapCell.html">mindspore.nn.AdaSumByGradWrapCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.ASGD.html">mindspore.nn.ASGD</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.FTRL.html">mindspore.nn.FTRL</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.Lamb.html">mindspore.nn.Lamb</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.LARS.html">mindspore.nn.LARS</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.LazyAdam.html">mindspore.nn.LazyAdam</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.Momentum.html">mindspore.nn.Momentum</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.ProximalAdagrad.html">mindspore.nn.ProximalAdagrad</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.RMSProp.html">mindspore.nn.RMSProp</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.Rprop.html">mindspore.nn.Rprop</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.SGD.html">mindspore.nn.SGD</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">mindspore.nn.thor</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#dynamic-learning-rate">Dynamic Learning Rate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#image-processing-layer">Image Processing Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#tools">Tools</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/en/master/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/tensorflow_api_mapping.html">TensorFlow and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption"><span class="caption-text">Migration Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/enveriment_preparation.html">Environment Preparation and Information Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/model_development/model_development.html">Constructing MindSpore Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/faq.html">FAQs</a></li>
</ul>
<p class="caption"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../mindspore.nn.html">mindspore.nn</a> &raquo;</li>
        
      <li>mindspore.nn.thor</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/api_python/nn/mindspore.nn.thor.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="mindspore-nn-thor">
<h1>mindspore.nn.thor<a class="headerlink" href="#mindspore-nn-thor" title="Permalink to this headline">¶</a></h1>
<dl class="function">
<dt id="mindspore.nn.thor">
<code class="sig-prename descclassname">mindspore.nn.</code><code class="sig-name descname">thor</code><span class="sig-paren">(</span><em class="sig-param">net</em>, <em class="sig-param">learning_rate</em>, <em class="sig-param">damping</em>, <em class="sig-param">momentum</em>, <em class="sig-param">weight_decay=0.0</em>, <em class="sig-param">loss_scale=1.0</em>, <em class="sig-param">batch_size=32</em>, <em class="sig-param">use_nesterov=False</em>, <em class="sig-param">decay_filter=lambda x: x.name not in []</em>, <em class="sig-param">split_indices=None</em>, <em class="sig-param">enable_clip_grad=False</em>, <em class="sig-param">frequency=100</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/optim/thor.html#thor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.thor" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates gradients by second-order algorithm–THOR.</p>
<p>The updating formulas are as follows,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll}
  &amp; \textbf{Parameter:} \: \text{the learning rate } \gamma\text{, the damping parameter }\lambda \\
  &amp; \textbf{Init:} \: \lambda \leftarrow 0 \\
  &amp; A_{i-1}=\mathbb{E}\left[a_{i-1} a_{i-1}^{T}\right] \\
  &amp; G_{i}=\mathbb{E}\left[D_{s_i} D_{s_i}^{T}\right] \\
  &amp; w_{i}^{(k+1)} \leftarrow w_{i}^{(k)}-\gamma\left(\left(A_{i-1}^{(k)}+\lambda I\right)^{-1}
    \otimes\left(G_{i}^{(k)}+\lambda I\right)^{-1}\right) \nabla_{w_{i}} J^{(k)}
\end{array}\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(a_{i-1}\)</span> represents the input of i-th layer,and which is the activations of previous layer.
<span class="math notranslate nohighlight">\(D_{s_i}\)</span> represents the derivative of the loss function of the output of the i-th layer.
<span class="math notranslate nohighlight">\(I\)</span> represents the identity matrix.
<span class="math notranslate nohighlight">\(\lambda\)</span> represents <span class="math notranslate nohighlight">\(damping\)</span>, <span class="math notranslate nohighlight">\(g_i\)</span> represents gradients of the i-th layer.
<span class="math notranslate nohighlight">\(\otimes\)</span> represents Kronecker product, <span class="math notranslate nohighlight">\(\gamma\)</span> represents ‘learning rate’.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When a parameter group is separated, ‘weight_decay’ of each group is applied to the corresponding parameter.
‘weight_decay’ in the optimizer is applied to arguments that do not have ‘beta’ or ‘gamma’ in their name
when the argument group is not separated.
When separating parameter groups, set grad_centralization to True if you want to concentrate gradients,
but concentration gradients can only be applied to parameters of the convolution layer.
If the parameter for the unconvolutional layer is set to True, an error will be reported.
To improve the performance of parameter groups, you can customize the order of parameters.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net</strong> (<a class="reference internal" href="mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The training network.</p></li>
<li><p><strong>learning_rate</strong> (<a class="reference internal" href="../mindspore/mindspore.Tensor.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A value for the learning rate.</p></li>
<li><p><strong>damping</strong> (<a class="reference internal" href="../mindspore/mindspore.Tensor.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A value for the damping.</p></li>
<li><p><strong>momentum</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Hyper-parameter of type float, means momentum for the moving average. It must be at least 0.0.</p></li>
<li><p><strong>weight_decay</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Weight decay (L2 penalty). It must be equal to or greater than 0.0. Default: 0.0.</p></li>
<li><p><strong>loss_scale</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – A value for the loss scale. It must be greater than 0.0. In general, use the
default value. Default: 1.0.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The size of a batch. Default: 32</p></li>
<li><p><strong>use_nesterov</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Enable Nesterov momentum. Default: False.</p></li>
<li><p><strong>decay_filter</strong> (<em>function</em>) – A function to determine which layers the weight decay applied to. And it
only works when the weight_decay &gt; 0. Default: lambda x: x.name not in []</p></li>
<li><p><strong>split_indices</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – Set allreduce fusion strategy by A/G layer indices . Only works when distributed
computing. ResNet50 as an example, there are 54 layers of A/G respectively, when split_indices is set
to [26, 53], it means A/G is divided into two groups to allreduce,  one is 0~26 layer, and the other
is 27~53. Default: None</p></li>
<li><p><strong>enable_clip_grad</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to clip the gradients. Default: False</p></li>
<li><p><strong>frequency</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The update interval of A/G and <span class="math notranslate nohighlight">\(A^{-1}/G^{-1}\)</span>. When frequency equals N
(N is greater than 1), A/G and <span class="math notranslate nohighlight">\(A^{-1}/G^{-1}\)</span> will be updated every N steps,
and other steps will use the stale A/G and <span class="math notranslate nohighlight">\(A^{-1}/G^{-1}\)</span> to update weights. Default: 100.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>gradients</strong> (tuple[Tensor]) - The gradients of <cite>params</cite>, the shape is the same as <cite>params</cite>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>tuple[bool], all elements are True.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If <cite>learning_rate</cite> is not Tensor.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If <cite>loss_scale</cite>, <cite>momentum</cite> or <cite>frequency</cite> is not a float.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If <cite>weight_decay</cite> is neither float nor int.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If <cite>use_nesterov</cite> is not a bool.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If <cite>frequency</cite> is not int.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>loss_scale</cite> is less than or equal to 0.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>weight_decay</cite> or <cite>momentum</cite> is less than 0.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>frequency</cite> is less than 2.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Before running the following example, you need to customize the network Net and
dataset preparation function create_dataset. Refer to
<a class="reference external" href="https://www.mindspore.cn/tutorials/en/master/beginner/model.html">Building a Network</a>
and <a class="reference external" href="https://www.mindspore.cn/tutorials/en/master/beginner/dataset.html">Dataset</a> .</p>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">thor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">temp</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">4e-4</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">],</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">thor</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">temp</span><span class="p">,</span> <span class="n">damping</span><span class="o">=</span><span class="n">temp</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">FixedLossScaleManager</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">drop_overflow_update</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">},</span>
<span class="gp">... </span>              <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O2&quot;</span><span class="p">,</span> <span class="n">keep_batchnorm_fp32</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">ConvertModelUtils</span><span class="o">.</span><span class="n">convert_to_thor_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span>
<span class="gp">... </span>                                                <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">},</span>
<span class="gp">... </span>                                                <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O2&quot;</span><span class="p">,</span> <span class="n">keep_batchnorm_fp32</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_cb</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">LossMonitor</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">loss_cb</span><span class="p">,</span> <span class="n">sink_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="mindspore.nn.CosineDecayLR.html" class="btn btn-neutral float-right" title="mindspore.nn.CosineDecayLR" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="mindspore.nn.SGD.html" class="btn btn-neutral float-left" title="mindspore.nn.SGD" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>