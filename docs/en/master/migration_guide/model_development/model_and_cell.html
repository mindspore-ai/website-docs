

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Network Construction &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script src="../../_static/js/training.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Learning Rate and Optimizer" href="learning_rate_and_optimizer.html" />
    <link rel="prev" title="Constructing Dataset" href="dataset.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/programming_paradigm.html">Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/auto_gradient.html">Functional Differential Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/pluggable_device.html">Third-Party Chip Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/all_scenarios.html">Full-scenarios Unification</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/training_visual_design.html">Design of Visualization↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption"><span class="caption-text">Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/benchmark.html">Benchmarks</a></li>
<li class="toctree-l1"><a class="reference external" href="https://gitee.com/mindspore/models/blob/master/README.md#table-of-contents">Network List↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/operator_list.html">API List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/syntax_list.html">Syntax Support</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/en/master/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/tensorflow_api_mapping.html">TensorFlow and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption"><span class="caption-text">Migration Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../enveriment_preparation.html">Environment Preparation and Information Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="model_development.html">Constructing MindSpore Network</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="dataset.html">Constructing Dataset</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Network Construction</a></li>
<li class="toctree-l2"><a class="reference internal" href="learning_rate_and_optimizer.html">Learning Rate and Optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="gradient.html">Gradient Derivation</a></li>
<li class="toctree-l2"><a class="reference internal" href="training_and_evaluation_procession.html">Inference and Training Process</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQs</a></li>
</ul>
<p class="caption"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="model_development.html">Constructing MindSpore Network</a> &raquo;</li>
        
      <li>Network Construction</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/migration_guide/model_development/model_and_cell.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="network-construction">
<h1>Network Construction<a class="headerlink" href="#network-construction" title="Permalink to this headline">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/master/docs/mindspore/source_en/migration_guide/model_development/model_and_cell.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png"></a></p>
<p>Before reading this section, read the tutorials <a class="reference external" href="https://www.mindspore.cn/tutorials/en/master/advanced/modules/loss.html">Loss Function</a> on the MindSpore official website first.</p>
<div class="section" id="network-basic-unit-cell">
<h2>Network Basic Unit: Cell<a class="headerlink" href="#network-basic-unit-cell" title="Permalink to this headline">¶</a></h2>
<p>MindSpore uses <a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/nn/mindspore.nn.Cell.html#mindspore.nn.Cell">Cell</a> to construct graphs. You need to define a class that inherits the <code class="docutils literal notranslate"><span class="pre">Cell</span></code> base class, declare the required APIs and submodules in <code class="docutils literal notranslate"><span class="pre">init</span></code>, and perform calculation in <code class="docutils literal notranslate"><span class="pre">construct</span></code>. <code class="docutils literal notranslate"><span class="pre">Cell</span></code> compiles a computational graph in <code class="docutils literal notranslate"><span class="pre">GRAPH_MODE</span></code> (static graph mode). It is used as the basic module of neural network in <code class="docutils literal notranslate"><span class="pre">PYNATIVE_MODE</span></code> (dynamic graph mode). The basic <code class="docutils literal notranslate"><span class="pre">Cell</span></code> setup process is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="k">class</span> <span class="nc">MyCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">forward_net</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">forward_net</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="n">inner_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">my_net</span> <span class="o">=</span> <span class="n">MyCell</span><span class="p">(</span><span class="n">inner_net</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">my_net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>    [Parameter (name=net.weight, shape=(240, 120, 4, 4), dtype=Float32, requires_grad=True)]
</pre></div>
</div>
<p>A parameter name is generally formed based on an object name defined by <code class="docutils literal notranslate"><span class="pre">__init__</span></code> and a name used during parameter definition. For example, in the foregoing example, a convolutional parameter name is <code class="docutils literal notranslate"><span class="pre">net.weight</span></code>, where <code class="docutils literal notranslate"><span class="pre">net</span></code> is an object name in <code class="docutils literal notranslate"><span class="pre">self.net</span> <span class="pre">=</span> <span class="pre">forward_net</span></code>, and <code class="docutils literal notranslate"><span class="pre">weight</span></code> is <code class="docutils literal notranslate"><span class="pre">name</span></code>: <code class="docutils literal notranslate"><span class="pre">self.weight</span> <span class="pre">=</span> <span class="pre">Parameter(initializer(self.weight_init,</span> <span class="pre">shape),</span> <span class="pre">name='weight')</span></code> when a convolutional parameter is defined in Conv2d.</p>
<p>To align parameter names, you may not need to add object names. The cell provides the <code class="docutils literal notranslate"><span class="pre">auto_prefix</span></code> interface to determine whether to add object names to parameter names in the cell. The default value is <code class="docutils literal notranslate"><span class="pre">True</span></code>, that is, add object names. If <code class="docutils literal notranslate"><span class="pre">auto_prefix</span></code> is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the <code class="docutils literal notranslate"><span class="pre">name</span></code> of <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> in the preceding example is <code class="docutils literal notranslate"><span class="pre">weight</span></code>.</p>
<div class="section" id="unit-test">
<h3>Unit Test<a class="headerlink" href="#unit-test" title="Permalink to this headline">¶</a></h3>
<p>After the <code class="docutils literal notranslate"><span class="pre">Cell</span></code> is set up, you are advised to build a unit test method for each <code class="docutils literal notranslate"><span class="pre">Cell</span></code> and compare it with the benchmarking code. In the preceding example, the PyTorch build code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">torch_nn</span>

<span class="k">class</span> <span class="nc">MyCell_pt</span><span class="p">(</span><span class="n">torch_nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">forward_net</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyCell_pt</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">forward_net</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">torch_nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="n">inner_net_pt</span> <span class="o">=</span> <span class="n">torch_nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">pt_net</span> <span class="o">=</span> <span class="n">MyCell_pt</span><span class="p">(</span><span class="n">inner_net_pt</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pt_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>    torch.Size([240, 120, 4, 4])
</pre></div>
</div>
<p>With the script for building the <code class="docutils literal notranslate"><span class="pre">Cell</span></code>, you need to use the same input data and parameters to compare the output.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">pt_net</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch_nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="n">torch_nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">cell</span> <span class="ow">in</span> <span class="n">my_net</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

<span class="n">y_ms</span> <span class="o">=</span> <span class="n">my_net</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">y_pt</span> <span class="o">=</span> <span class="n">pt_net</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_ms</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span> <span class="o">-</span> <span class="n">y_pt</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span>

<span class="c1"># ValueError: operands could not be broadcast together with shapes (2,240,12,12) (2,240,9,9)</span>
</pre></div>
</div>
<p>The output of MindSpore is different from that of PyTorch. Why?</p>
<p>According to the <a class="reference external" href="https://www.mindspore.cn/docs/en/master/note/api_mapping/pytorch_diff/Conv2d.html">Function Differences with torch.nn.Conv2d</a>, the default parameters of <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code> are different in MindSpore and PyTorch.
By default, MindSpore uses the <code class="docutils literal notranslate"><span class="pre">same</span></code> mode, and PyTorch uses the <code class="docutils literal notranslate"><span class="pre">pad</span></code> mode. During migration, you need to modify the <code class="docutils literal notranslate"><span class="pre">pad_mode</span></code> of MindSpore <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">inner_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;pad&quot;</span><span class="p">)</span>
<span class="n">my_net</span> <span class="o">=</span> <span class="n">MyCell</span><span class="p">(</span><span class="n">inner_net</span><span class="p">)</span>

<span class="c1"># Construct random input.</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">pt_net</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch_nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="c1"># Fixed PyTorch initialization parameter</span>
        <span class="n">torch_nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">cell</span> <span class="ow">in</span> <span class="n">my_net</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="c1"># Fixed MindSpore initialization parameter</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

<span class="n">y_ms</span> <span class="o">=</span> <span class="n">my_net</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">y_pt</span> <span class="o">=</span> <span class="n">pt_net</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_ms</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span> <span class="o">-</span> <span class="n">y_pt</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>    2.9355288e-06
</pre></div>
</div>
<p>The overall error is about 0.01%, which basically meets the expectation. <strong>During cell migration, you are advised to perform a unit test on each cell to ensure migration consistency.</strong></p>
</div>
<div class="section" id="common-methods-of-cells">
<h3>Common Methods of Cells<a class="headerlink" href="#common-methods-of-cells" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Cell</span></code> is the basic unit of the neural network in MindSpore. It provides many flag setting and easy-to-use methods. The following describes some common methods.</p>
<div class="section" id="manual-mixed-precision">
<h4>Manual Mixed-precision<a class="headerlink" href="#manual-mixed-precision" title="Permalink to this headline">¶</a></h4>
<p>MindSpore provides an auto mixed precision method. For details, see the amp_level attribute in <a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/train/mindspore.train.Model.html#mindspore.train.Model">Model</a>.</p>
<p>However, sometimes the hybrid precision policy is expected to be more flexible during network development. MindSpore also provides the <a class="reference external" href="https://mindspore.cn/docs/en/master/api_python/nn/mindspore.nn.Cell.html#mindspore.nn.Cell.to_float">to_float</a> method to manually add hybrid precision.</p>
<p><code class="docutils literal notranslate"><span class="pre">to_float(dst_type)</span></code>: adds type conversion to the input of the <code class="docutils literal notranslate"><span class="pre">Cell</span></code> and all child <code class="docutils literal notranslate"><span class="pre">Cell</span></code> to run with a specific floating-point type.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">dst_type</span></code> is <code class="docutils literal notranslate"><span class="pre">ms.float16</span></code>, all inputs of <code class="docutils literal notranslate"><span class="pre">Cell</span></code> (including input, <code class="docutils literal notranslate"><span class="pre">Parameter</span></code>, and <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> used as constants) will be converted to <code class="docutils literal notranslate"><span class="pre">float16</span></code>. For example, if you want to change all BNs and losses in a network to the <code class="docutils literal notranslate"><span class="pre">float32</span></code> type and other operations to the <code class="docutils literal notranslate"><span class="pre">float16</span></code> type, run the following command:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="c1"># Define model</span>
<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;pad&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">12</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;pad&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveMaxPool2d</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>
<span class="n">net</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>  <span class="c1">#Add the float16 flag to all operations in the net. The framework adds the cast method to the input during compilation.</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">cell</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">)):</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">WithLossCell</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
<p>The customized <code class="docutils literal notranslate"><span class="pre">to_float</span></code> conflicts with the <code class="docutils literal notranslate"><span class="pre">amp_level</span></code> in the model. If the customized mixing precision is used, do not set the <code class="docutils literal notranslate"><span class="pre">amp_level</span></code> in the model.</p>
</div>
<div class="section" id="customizing-initialization-parameters">
<h4>Customizing Initialization Parameters<a class="headerlink" href="#customizing-initialization-parameters" title="Permalink to this headline">¶</a></h4>
<p>Generally, the high-level API encapsulated by MindSpore initializes parameters by default. Sometimes, the initialization distribution is inconsistent with the required initialization and PyTorch initialization. In this case, you need to customize initialization. <a class="reference external" href="https://mindspore.cn/tutorials/en/master/advanced/modules/initializer.html#customized-parameter-initialization">Initializing Network Arguments</a> describes a method of initializing parameters by using API attributes. This section describes a method of initializing parameters by using Cell.</p>
<p>For details about the parameters, see <a class="reference external" href="https://mindspore.cn/tutorials/zh-CN/master/advanced/modules/initializer.html">Network Parameters</a>. This section uses <code class="docutils literal notranslate"><span class="pre">Cell</span></code> as an example to describe how to obtain all parameters in <code class="docutils literal notranslate"><span class="pre">Cell</span></code> and how to initialize the parameters in <code class="docutils literal notranslate"><span class="pre">Cell</span></code>.</p>
<blockquote>
<div><p>Note that the method described in this section cannot be performed in <code class="docutils literal notranslate"><span class="pre">construct</span></code>. To change the value of a parameter on the network, use <a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/ops/mindspore.ops.assign.html">assign</a>.</p>
</div></blockquote>
<p><a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/mindspore/mindspore.Parameter.html?highlight=set_data#mindspore.Parameter.set_data">set_data(data, slice_shape=False)</a> sets parameter data.</p>
<p>For details about the parameter initialization methods supported by MindSpore, see <a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/mindspore.common.initializer.html">mindspore.common.initializer</a>. You can also directly transfer a defined <a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/mindspore/mindspore.Parameter.html#mindspore.Parameter">Parameter</a> object.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="c1"># Define model</span>
<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;pad&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">12</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;pad&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveMaxPool2d</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>

<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">cell</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span>
            <span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">HeNormal</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fan_out&#39;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
            <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">)):</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;ones&quot;</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;zeros&quot;</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">)):</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span>
            <span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">HeUniform</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)),</span>
            <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;zeros&quot;</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="freezing-parameters">
<h4>Freezing Parameters<a class="headerlink" href="#freezing-parameters" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">Parameter</span></code> has a <code class="docutils literal notranslate"><span class="pre">requires_grad</span></code> attribute to determine whether to update parameters. When <code class="docutils literal notranslate"><span class="pre">requires_grad=False</span></code>, <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> is equivalent to the <code class="docutils literal notranslate"><span class="pre">buffer</span></code> object of PyTorch.</p>
<p>You can obtain the parameter list in <code class="docutils literal notranslate"><span class="pre">Cell</span></code> through <code class="docutils literal notranslate"><span class="pre">parameters_dict</span></code>, <code class="docutils literal notranslate"><span class="pre">get_parameters</span></code>, and <code class="docutils literal notranslate"><span class="pre">trainable_params</span></code> of the cell.</p>
<ul class="simple">
<li><p>parameters_dict: obtains all parameters in the network structure and returns an <code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code> with <code class="docutils literal notranslate"><span class="pre">key</span></code> as the parameter name and <code class="docutils literal notranslate"><span class="pre">value</span></code> as the parameter value.</p></li>
<li><p>get_parameters: obtains all parameters in the network structure and returns the iterator of the <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> in the <code class="docutils literal notranslate"><span class="pre">Cell</span></code>.</p></li>
<li><p>trainable_params: obtains the attributes whose <code class="docutils literal notranslate"><span class="pre">requires_grad</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code> in <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> and returns the list of trainable parameters.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>

<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">():</span>
    <span class="n">param_name</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span>
    <span class="k">if</span> <span class="s2">&quot;bias&quot;</span> <span class="ow">in</span> <span class="n">param_name</span><span class="p">:</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>    [Parameter (name=weight, shape=(1, 2), dtype=Float32, requires_grad=True), Parameter (name=bias, shape=(1,), dtype=Float32, requires_grad=True)]
    [Parameter (name=weight, shape=(1, 2), dtype=Float32, requires_grad=True)]
</pre></div>
</div>
<p>When defining an optimizer, use <code class="docutils literal notranslate"><span class="pre">net.trainable_params()</span></code> to obtain the list of parameters that need to be updated.</p>
<p>In addition to setting the parameter <code class="docutils literal notranslate"><span class="pre">requires_grad=False</span></code> not to update the parameter, you can also use <code class="docutils literal notranslate"><span class="pre">stop_gradient</span></code> to block gradient calculation to freeze the parameter. When will <code class="docutils literal notranslate"><span class="pre">requires_grad=False</span></code> and <code class="docutils literal notranslate"><span class="pre">stop_gradient</span></code> be used?</p>
<p><img alt="parameter-freeze" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_en/migration_guide/model_development/images/parameter_freeze.png" /></p>
<p>As shown in the preceding figure, the <code class="docutils literal notranslate"><span class="pre">requires_grad=False</span></code> does not update some parameters, but the backward gradient calculation is normal.
The <code class="docutils literal notranslate"><span class="pre">stop_gradient</span></code> directly cuts off backward gradient. When there is no parameter to be trained before the parameter to be frozen, the two parameters are equivalent in function.
However, <code class="docutils literal notranslate"><span class="pre">stop_gradient</span></code> is faster (with less backward gradient calculations).
If there are parameters to be trained before the frozen parameters, only <code class="docutils literal notranslate"><span class="pre">requires_grad=False</span></code> can be used.
In addition, <code class="docutils literal notranslate"><span class="pre">stop_gradient</span></code> needs to be added to the computational link of the network, acting on the Tensor.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">A</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">B</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="saving-and-loading-parameters">
<h4>Saving and Loading Parameters<a class="headerlink" href="#saving-and-loading-parameters" title="Permalink to this headline">¶</a></h4>
<p>MindSpore provides the <code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code> and <code class="docutils literal notranslate"><span class="pre">save_checkpoint</span></code> methods for saving and loading parameters. Note that when a parameter is saved, the parameter list is saved. When a parameter is loaded, the object must be a cell.
When loading parameters, you may need to modify the parameter names. In this case, you can directly construct a new parameter list for the <code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code> to load the parameter list to the cell.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>

<span class="n">ms</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="s2">&quot;dense.ckpt&quot;</span><span class="p">)</span>
<span class="n">dense_params</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;dense.ckpt&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dense_params</span><span class="p">)</span>
<span class="n">new_params</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="n">dense_params</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param_name</span><span class="p">,</span> <span class="n">dense_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
    <span class="n">new_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">dense_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">param_name</span><span class="p">)</span>

<span class="n">ms</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">new_params</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>    weight [[-0.0042482  -0.00427286]]
    bias [0.]
    {&#39;weight&#39;: Parameter (name=weight, shape=(1, 2), dtype=Float32, requires_grad=True), &#39;bias&#39;: Parameter (name=bias, shape=(1,), dtype=Float32, requires_grad=True)}
    weight [[-0.0042482  -0.00427286]]
    bias [0.]
    weight [[1. 1.]]
    bias [1.]
</pre></div>
</div>
</div>
</div>
<div class="section" id="dynamic-and-static-graphs">
<h3>Dynamic and Static Graphs<a class="headerlink" href="#dynamic-and-static-graphs" title="Permalink to this headline">¶</a></h3>
<p>For <code class="docutils literal notranslate"><span class="pre">Cell</span></code>, MindSpore provides two image modes: <code class="docutils literal notranslate"><span class="pre">GRAPH_MODE</span></code> (static image) and <code class="docutils literal notranslate"><span class="pre">PYNATIVE_MODE</span></code> (dynamic image). For details, see <a class="reference external" href="https://www.mindspore.cn/tutorials/en/master/advanced/compute_graph.html">Dynamic Image and Static Graphs</a>.</p>
<p>The <strong>inference</strong> behavior of the model in <code class="docutils literal notranslate"><span class="pre">PyNative</span></code> mode is the same as that of common Python code. However, during training, <strong>once a tensor is converted into NumPy for other operations, the gradient of the network is truncated, which is equivalent to detach of PyTorch</strong>.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">GRAPH_MODE</span></code> is used, syntax restrictions usually occur. In this case, graph compilation needs to be performed on the Python code. However, MindSpore does not support the complete Python syntax set. Therefore, there are some restrictions on compiling the <code class="docutils literal notranslate"><span class="pre">construct</span></code> function. For details about the restrictions, see <a class="reference external" href="https://www.mindspore.cn/docs/en/master/note/static_graph_syntax_support.html">MindSpore Static Graph Syntax</a>.</p>
<div class="section" id="common-restrictions">
<h4>Common Restrictions<a class="headerlink" href="#common-restrictions" title="Permalink to this headline">¶</a></h4>
<p>Compared with the detailed syntax description, the common restrictions are as follows:</p>
<ul>
<li><p>Scenario 1</p>
<p>Restriction: During image composition (construct functions or functions modified by ms_function), do not invoke other Python libraries, such as NumPy and scipy. Related processing must be moved forward to the <code class="docutils literal notranslate"><span class="pre">__init__</span></code> phase.
Measure: Use the APIs provided by MindSpore to replace the functions of other Python libraries. The processing of constants can be moved forward to the <code class="docutils literal notranslate"><span class="pre">__init__</span></code> phase.</p>
</li>
<li><p>Scenario 2</p>
<p>Restriction: Do not use user-defined types during graph build. Instead, use the data types provided by MindSpore and basic Python types. You can use the tuple/list combination based on these types.
Measure: Use basic types for combination. You can increase the number of function parameters. There is no restriction on the input parameters of the function, and variable-length input can be used.</p>
</li>
<li><p>Scenario 3</p>
<p>Restriction: Do not perform multi-thread or multi-process processing on data during image composition.
Measure: Avoid multi-thread processing on the network.</p>
</li>
</ul>
</div>
</div>
<div class="section" id="customized-backward-network-construction">
<h3>Customized Backward Network Construction<a class="headerlink" href="#customized-backward-network-construction" title="Permalink to this headline">¶</a></h3>
<p>Sometimes, MindSpore does not support some processing and needs to use some third-party library methods. However, we do not want to truncate the network gradient. In this case, what should we do? This section describes how to customize backward network construction to avoid this problem in <code class="docutils literal notranslate"><span class="pre">PYNATIVE_MODE</span></code>.</p>
<p>In this scenario, a value greater than 0.5 needs to be randomly selected, and the shape of each batch is fixed to <code class="docutils literal notranslate"><span class="pre">max_num</span></code>. However, the random put-back operation is not supported by MindSpore APIs. In this case, NumPy is used for computation in <code class="docutils literal notranslate"><span class="pre">PYNATIVE_MODE</span></code>, and then a gradient propagation process is constructed.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">MySampler</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="c1"># Customize a sampler and select `max_num` values greater than 0.5 in each batch.</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_num</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MySampler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_num</span> <span class="o">=</span> <span class="n">max_num</span>

    <span class="k">def</span> <span class="nf">random_positive</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Method of the third-party library NumPy. Select a position greater than 0.5.</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">pos_indice</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_num</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pos_indice</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Forward Network Construction</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">pos_value</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">pos_indice</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
            <span class="n">pos_ind</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_positive</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
            <span class="n">pos_value</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">pos_ind</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            <span class="n">pos_indice</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">pos_ind</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
        <span class="n">pos_values</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">pos_value</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">pos_indices</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">pos_indice</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pos_values forword&quot;</span><span class="p">,</span> <span class="n">pos_values</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pos_indices forword&quot;</span><span class="p">,</span> <span class="n">pos_indices</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pos_values</span><span class="p">,</span> <span class="n">pos_indices</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">MySampler</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">pos_values</span><span class="p">,</span> <span class="n">pos_indices</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">grad</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">sampler</span><span class="p">,</span> <span class="n">grad_position</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dx&quot;</span><span class="p">,</span> <span class="n">grad</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>    x [[1.2510660e+00 2.1609735e+00 3.4312444e-04 9.0699774e-01 4.4026768e-01]
     [2.7701578e-01 5.5878061e-01 1.0366821e+00 1.1903024e+00 1.6164502e+00]]
    pos_values forword [[0.90699774 2.1609735  0.90699774]
     [0.5587806  1.6164502  0.5587806 ]]
    pos_indices forword [[3 1 3]
     [1 4 1]]
    pos_values forword [[0.90699774 1.251066   2.1609735 ]
     [1.1903024  1.1903024  0.5587806 ]]
    pos_indices forword [[3 0 1]
     [3 3 1]]
    dx (Tensor(shape=[2, 5], dtype=Float32, value=
    [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
     [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]),)
</pre></div>
</div>
<p>When we do not construct this backward process, the gradient will be truncated because the numpy method is used to calculate the <code class="docutils literal notranslate"><span class="pre">pos_value</span></code>.
As shown in the preceding information, the value of <code class="docutils literal notranslate"><span class="pre">dx</span></code> is all 0s. In addition, you may find that <code class="docutils literal notranslate"><span class="pre">pos_values</span> <span class="pre">forword</span></code> and <code class="docutils literal notranslate"><span class="pre">pos_indices</span> <span class="pre">forword</span></code> are printed twice in this process. This is because the forward graph is constructed again when the backward graph is constructed in <code class="docutils literal notranslate"><span class="pre">PYNATIVE_MODE</span></code>. As a result, the forward graph is constructed twice and the backward graph is constructed once, which wastes training resources. In some cases, precision problems may occur. For example, in the case of BatchNorm, <code class="docutils literal notranslate"><span class="pre">moving_mean</span></code> and <code class="docutils literal notranslate"><span class="pre">moving_var</span></code> are updated during forward running. As a result, <code class="docutils literal notranslate"><span class="pre">moving_mean</span></code> and <code class="docutils literal notranslate"><span class="pre">moving_var</span></code> are updated twice during one training.
To avoid this scenario, MindSpore has a method <code class="docutils literal notranslate"><span class="pre">set_grad()</span></code> for <code class="docutils literal notranslate"><span class="pre">Cell</span></code>. In <code class="docutils literal notranslate"><span class="pre">PYNATIVE_MODE</span></code> mode, the framework synchronously constructs the backward process when constructing the forward process. In this way, the forward process is not executed when the backward process is executed.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">MySampler</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">set_grad</span><span class="p">()</span>
<span class="n">pos_values</span><span class="p">,</span> <span class="n">pos_indices</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">grad</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">sampler</span><span class="p">,</span> <span class="n">grad_position</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dx&quot;</span><span class="p">,</span> <span class="n">grad</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>    x [[1.2519144  1.6760695  0.42116082 0.59430444 2.4022336 ]
     [2.9047847  0.9402725  2.076968   2.6291676  2.68382   ]]
    pos_values forword [[1.2519144 1.2519144 1.6760695]
     [2.6291676 2.076968  0.9402725]]
    pos_indices forword [[0 0 1]
     [3 2 1]]
    dx (Tensor(shape=[2, 5], dtype=Float32, value=
    [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
     [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]),)
</pre></div>
</div>
<p>Now, let’s see how to <a class="reference external" href="https://mindspore.cn/tutorials/zh-CN/master/advanced/modules/layer.html#%E8%87%AA%E5%AE%9A%E4%B9%89cell%E5%8F%8D%E5%90%91">customize backward network construction</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">MySampler</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="c1"># Customize a sampler and select `max_num` values greater than 0.5 in each batch.</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_num</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MySampler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_num</span> <span class="o">=</span> <span class="n">max_num</span>

    <span class="k">def</span> <span class="nf">random_positive</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Method of the third-party library NumPy. Select a position greater than 0.5.</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">pos_indice</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_num</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pos_indice</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Forward network construction</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">pos_value</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">pos_indice</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
            <span class="n">pos_ind</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_positive</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
            <span class="n">pos_value</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">pos_ind</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            <span class="n">pos_indice</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">pos_ind</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
        <span class="n">pos_values</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">pos_value</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">pos_indices</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">pos_indice</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pos_values forword&quot;</span><span class="p">,</span> <span class="n">pos_values</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pos_indices forword&quot;</span><span class="p">,</span> <span class="n">pos_indices</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pos_values</span><span class="p">,</span> <span class="n">pos_indices</span>

    <span class="k">def</span> <span class="nf">bprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
        <span class="c1"># Backward network construction</span>
        <span class="n">pos_indices</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pos_indices backward&quot;</span><span class="p">,</span> <span class="n">pos_indices</span><span class="p">)</span>
        <span class="n">grad_x</span> <span class="o">=</span> <span class="n">dout</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;grad_x backward&quot;</span><span class="p">,</span> <span class="n">grad_x</span><span class="p">)</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
            <span class="n">dx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">UnsortedSegmentSum</span><span class="p">()(</span><span class="n">grad_x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">pos_indices</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">MySampler</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">set_grad</span><span class="p">()</span>
<span class="n">pos_values</span><span class="p">,</span> <span class="n">pos_indices</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">grad</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">sampler</span><span class="p">,</span> <span class="n">grad_position</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dx&quot;</span><span class="p">,</span> <span class="n">grad</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>    x [[1.2510660e+00 2.1609735e+00 3.4312444e-04 9.0699774e-01 4.4026768e-01]
     [2.7701578e-01 5.5878061e-01 1.0366821e+00 1.1903024e+00 1.6164502e+00]]
    pos_values forword [[0.90699774 2.1609735  0.90699774]
     [0.5587806  1.6164502  0.5587806 ]]
    pos_indices forword [[3 1 3]
     [1 4 1]]
    pos_indices backward [[3 1 3]
     [1 4 1]]
    grad_x backward [[1. 1. 1.]
     [1. 1. 1.]]
    dx (Tensor(shape=[2, 5], dtype=Float32, value=
    [[0.00000000e+000, 1.00000000e+000, 0.00000000e+000, 2.00000000e+000, 0.00000000e+000],
     [0.00000000e+000, 2.00000000e+000, 0.00000000e+000, 0.00000000e+000, 1.00000000e+000]]),)
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">bprop</span></code> method is added to the <code class="docutils literal notranslate"><span class="pre">MySampler</span></code> class. The input of this method is forward input (expanded write), forward output (a tuple), and output gradient (a tuple). In this method, a gradient-to-input backward propagation process is constructed.
In batch 0, the values at positions 3, 1, and 3 are randomly selected. The output gradient is 1, and the reverse gradient is <code class="docutils literal notranslate"><span class="pre">[0.00000000e+000,</span> <span class="pre">1.00000000e+000,</span> <span class="pre">0.00000000e+000,</span> <span class="pre">2.00000000e+000,</span> <span class="pre">0.00000000e+000]</span></code>, which meets the expectation.</p>
</div>
<div class="section" id="dynamic-shape-workarounds">
<h3>Dynamic Shape Workarounds<a class="headerlink" href="#dynamic-shape-workarounds" title="Permalink to this headline">¶</a></h3>
<p>Generally, dynamic shape is introduced due to the following reasons:</p>
<ul class="simple">
<li><p>The input shape is not fixed.</p></li>
<li><p>Operators that cause shape changes exist during network execution.</p></li>
<li><p>Different branches of the control flow introduce shape changes.</p></li>
</ul>
<p>Now, let’s look at some workarounds for these scenarios.</p>
<div class="section" id="input-shape-not-fixed">
<h4>Input Shape Not Fixed<a class="headerlink" href="#input-shape-not-fixed" title="Permalink to this headline">¶</a></h4>
<ol class="simple">
<li><p>You can add pads to the input data to a fixed shape. For example, <a class="reference external" href="https://gitee.com/mindspore/models/blob/master/official/audio/DeepSpeech2/src/dataset.py#L153">Data Processing</a> of deep_speechv2 specifies the maximum length of <code class="docutils literal notranslate"><span class="pre">input_length</span></code>. Short <code class="docutils literal notranslate"><span class="pre">input_length</span></code> are padded with 0s, and long <code class="docutils literal notranslate"><span class="pre">input_length</span></code> are randomly truncated. Note that this method may affect the training accuracy. Therefore, the training accuracy and training performance need to be balanced.</p></li>
<li><p>You can set a group of fixed input shapes to process the input into several fixed scales. For example, in <a class="reference external" href="https://gitee.com/mindspore/models/blob/master/official/cv/YOLOv3/src/yolo_dataset.py#L177">Data Processing</a> of YOLOv3_darknet53, the processing function <code class="docutils literal notranslate"><span class="pre">multi_scale_trans</span></code> is added to the batch method, and a shape is randomly selected from <a class="reference external" href="https://gitee.com/mindspore/models/blob/master/official/cv/YOLOv3/src/transforms.py#L456">MultiScaleTrans</a> for processing.</p></li>
</ol>
<p>Currently, the support for completely random input shapes is limited and needs to be supported in the new version.</p>
</div>
<div class="section" id="operations-that-cause-shape-changes-during-network-execution">
<h4>Operations that Cause Shape Changes During Network Execution<a class="headerlink" href="#operations-that-cause-shape-changes-during-network-execution" title="Permalink to this headline">¶</a></h4>
<p>In the scenario where tensors with unfixed shapes are generated during network running, the most common method is to construct a mask to filter out values in invalid positions. For example, in the detection scenario, some boxes need to be selected based on the iou results of the prediction box and real box.
The PyTorch implementation is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">box_select_torch</span><span class="p">(</span><span class="n">box</span><span class="p">,</span> <span class="n">iou_score</span><span class="p">):</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">iou_score</span> <span class="o">&gt;</span> <span class="mf">0.3</span>
    <span class="k">return</span> <span class="n">box</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
</pre></div>
</div>
<p>In versions later than MindSpore 1.8, <code class="docutils literal notranslate"><span class="pre">masked_select</span></code> is supported in all scenarios. In MindSpore, <code class="docutils literal notranslate"><span class="pre">masked_select</span></code> can be implemented as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">box_select_ms</span><span class="p">(</span><span class="n">box</span><span class="p">,</span> <span class="n">iou_score</span><span class="p">):</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">iou_score</span> <span class="o">&gt;</span> <span class="mf">0.3</span><span class="p">)</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">box</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s look at the result comparison.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">box</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">iou_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;box_select_ms&quot;</span><span class="p">,</span> <span class="n">box_select_ms</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">box</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">iou_score</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;box_select_torch&quot;</span><span class="p">,</span> <span class="n">box_select_torch</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">box</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">iou_score</span><span class="p">)))</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>    box_select_ms [0.14675589 0.09233859 0.18626021 0.34556073]
    box_select_torch tensor([[0.1468, 0.0923, 0.1863, 0.3456]])
</pre></div>
</div>
<p>However, after this operation, dynamic shape is generated, which may cause problems in subsequent network calculation. Currently, you are advised to use the mask to avoid this problem.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">box_select_ms2</span><span class="p">(</span><span class="n">box</span><span class="p">,</span> <span class="n">iou_score</span><span class="p">):</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">iou_score</span> <span class="o">&gt;</span> <span class="mf">0.3</span><span class="p">)</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">box</span> <span class="o">*</span> <span class="n">mask</span><span class="p">,</span> <span class="n">mask</span>
</pre></div>
</div>
<p>In subsequent computation, if some box operations are involved, check whether the mask needs to be multiplied to filter invalid results.</p>
<p>If a tensor with an unfixed shape is obtained due to feature selection during loss computation, the processing method is basically the same as that during network running. The only difference is that the loss part may not have other operations and the mask does not need to be returned.</p>
<p>For example, we want to select the values of the first 70% positive samples to compute the loss.
The PyTorch implementation is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">torch_nn</span>

<span class="k">class</span> <span class="nc">ClassLoss_pt</span><span class="p">(</span><span class="n">torch_nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ClassLoss_pt</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">con_loss</span> <span class="o">=</span> <span class="n">torch_nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">label</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="n">vaild_label</span> <span class="o">=</span> <span class="n">label</span> <span class="o">*</span> <span class="n">mask</span>
        <span class="n">pos_num</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">int</span><span class="p">()</span>
        <span class="n">con</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">con_loss</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">vaild_label</span><span class="o">.</span><span class="n">long</span><span class="p">())</span> <span class="o">*</span> <span class="n">mask</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">con</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">pos_num</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">torch.topk</span></code> is used to obtain the first 70% positive sample data. Currently, MindSpore does not support K as a variable. Therefore, you need to convert the method to obtain the Kth largest value and then obtain the mask of the top K based on the value. The MindSpore implementation is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span> <span class="k">as</span> <span class="n">ms_nn</span>

<span class="k">class</span> <span class="nc">ClassLoss_ms</span><span class="p">(</span><span class="n">ms_nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ClassLoss_ms</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">con_loss</span> <span class="o">=</span> <span class="n">ms_nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sort_descending</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sort</span><span class="p">(</span><span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">label</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="n">vaild_label</span> <span class="o">=</span> <span class="n">label</span> <span class="o">*</span> <span class="n">mask</span>
        <span class="n">pos_num</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="n">con</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">con_loss</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">vaild_label</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span> <span class="o">*</span> <span class="n">mask</span>
        <span class="n">con_sort</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sort_descending</span><span class="p">(</span><span class="n">con</span><span class="p">)</span>
        <span class="n">con_k</span> <span class="o">=</span> <span class="n">con_sort</span><span class="p">[</span><span class="n">pos_num</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">con_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">con</span> <span class="o">&gt;=</span> <span class="n">con_k</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">con</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">con</span> <span class="o">*</span> <span class="n">con_mask</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">con_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
<p>Let’s look at the test result.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pred&quot;</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
<span class="n">t_loss</span> <span class="o">=</span> <span class="n">ClassLoss_pt</span><span class="p">()</span>
<span class="n">cls_loss_pt</span> <span class="o">=</span> <span class="n">t_loss</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">pred</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">label</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cls_loss_pt&quot;</span><span class="p">,</span> <span class="n">cls_loss_pt</span><span class="p">)</span>
<span class="n">m_loss</span> <span class="o">=</span> <span class="n">ClassLoss_ms</span><span class="p">()</span>
<span class="n">cls_loss_ms</span> <span class="o">=</span> <span class="n">m_loss</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">pred</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">label</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cls_loss_ms&quot;</span><span class="p">,</span> <span class="n">cls_loss_ms</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>    pred [[4.17021990e-01 7.20324516e-01]
     [1.14374816e-04 3.02332580e-01]
     [1.46755889e-01 9.23385918e-02]
     [1.86260208e-01 3.45560730e-01]
     [3.96767467e-01 5.38816750e-01]]
    label [-1  0  1  1  0]
    cls_loss_pt tensor(0.7207)
    cls_loss_ms 0.7207259
</pre></div>
</div>
</div>
<div class="section" id="shape-changes-introduced-by-different-branches-of-control-flows">
<h4>Shape Changes Introduced by Different Branches of Control Flows<a class="headerlink" href="#shape-changes-introduced-by-different-branches-of-control-flows" title="Permalink to this headline">¶</a></h4>
<p>The following is an example in the model analysis and preparation section:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">cond</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>

<span class="k">if</span> <span class="n">cond</span><span class="p">:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cond</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>    [4.17021990e-01 7.20324516e-01 1.14374816e-04 3.02332580e-01
     1.46755889e-01 9.23385918e-02 1.86260208e-01 3.45560730e-01
     3.96767467e-01 5.38816750e-01]
    True
    [0.7203245  0.53881675]
</pre></div>
</div>
<p>In <code class="docutils literal notranslate"><span class="pre">cond=True</span></code> mode, the maximum shape is the same as x. According to the preceding mask adding method, the maximum shape can be written as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">cond</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>

<span class="k">if</span> <span class="n">cond</span><span class="p">:</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">mask</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cond</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>    [4.17021990e-01 7.20324516e-01 1.14374816e-04 3.02332580e-01
     1.46755889e-01 9.23385918e-02 1.86260208e-01 3.45560730e-01
     3.96767467e-01 5.38816750e-01]
    True
    [0.         0.7203245  0.         0.         0.         0.
     0.         0.         0.         0.53881675]
</pre></div>
</div>
<p>Note that if y is subsequently involved in other calculations, it needs to be passed in mask to do filtering on the valid positions.</p>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="learning_rate_and_optimizer.html" class="btn btn-neutral float-right" title="Learning Rate and Optimizer" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="dataset.html" class="btn btn-neutral float-left" title="Constructing Dataset" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>