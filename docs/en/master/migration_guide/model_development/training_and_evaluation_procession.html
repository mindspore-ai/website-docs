

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Inference and Training Process &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script src="../../_static/js/training.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Debugging and Tuning" href="../debug_and_tune.html" />
    <link rel="prev" title="Gradient Derivation" href="gradient.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/programming_paradigm.html">Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/auto_gradient.html">Functional Differential Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/all_scenarios.html">Full-scenarios Unification</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/training_visual_design.html">Design of Visualization↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption"><span class="caption-text">Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/benchmark.html">Benchmarks</a></li>
<li class="toctree-l1"><a class="reference external" href="https://gitee.com/mindspore/models/blob/master/README.md#table-of-contents">Network List↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/operator_list.html">API List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/syntax_list.html">Syntax Support</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/en/master/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/tensorflow_api_mapping.html">TensorFlow and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption"><span class="caption-text">Migration Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../enveriment_preparation.html">Environment Preparation and Information Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="model_development.html">Constructing MindSpore Network</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="dataset.html">Constructing Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_and_cell.html">Network Construction</a></li>
<li class="toctree-l2"><a class="reference internal" href="learning_rate_and_optimizer.html">Learning Rate and Optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="gradient.html">Gradient Derivation</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Inference and Training Process</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQs</a></li>
</ul>
<p class="caption"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="model_development.html">Constructing MindSpore Network</a> &raquo;</li>
        
      <li>Inference and Training Process</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/migration_guide/model_development/training_and_evaluation_procession.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="inference-and-training-process">
<h1>Inference and Training Process<a class="headerlink" href="#inference-and-training-process" title="Permalink to this headline">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/master/docs/mindspore/source_en/migration_guide/model_development/training_and_evaluation_procession.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png"></a></p>
<div class="section" id="general-operating-environment-settings">
<h2>General Operating Environment Settings<a class="headerlink" href="#general-operating-environment-settings" title="Permalink to this headline">¶</a></h2>
<p>We generally need to set up the operating environment before network training and inference, and a general operating environment configuration is given here.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication.management</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span><span class="p">,</span> <span class="n">get_group_size</span>

<span class="k">def</span> <span class="nf">init_env</span><span class="p">(</span><span class="n">cfg</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize the operating environment.&quot;&quot;&quot;</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
    <span class="c1"># If device_target is set to None, use the framework to get device_target automatically, otherwise use the set one.</span>
    <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">device_target</span> <span class="o">!=</span> <span class="s2">&quot;None&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">device_target</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;Ascend&quot;</span><span class="p">,</span> <span class="s2">&quot;GPU&quot;</span><span class="p">,</span> <span class="s2">&quot;CPU&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid device_target: </span><span class="si">{</span><span class="n">cfg</span><span class="o">.</span><span class="n">device_target</span><span class="si">}</span><span class="s2">, &quot;</span>
                             <span class="sa">f</span><span class="s2">&quot;should be in [&#39;None&#39;, &#39;Ascend&#39;, &#39;GPU&#39;, &#39;CPU&#39;]&quot;</span><span class="p">)</span>
        <span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device_target</span><span class="p">)</span>

    <span class="c1"># Configure operation mode, and support graph mode and PYNATIVE mode</span>
    <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">context_mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;graph&quot;</span><span class="p">,</span> <span class="s2">&quot;pynative&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid context_mode: </span><span class="si">{</span><span class="n">cfg</span><span class="o">.</span><span class="n">context_mode</span><span class="si">}</span><span class="s2">, &quot;</span>
                         <span class="sa">f</span><span class="s2">&quot;should be in [&#39;graph&#39;, &#39;pynative&#39;]&quot;</span><span class="p">)</span>
    <span class="n">context_mode</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span> <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">context_mode</span> <span class="o">==</span> <span class="s2">&quot;graph&quot;</span> <span class="k">else</span> <span class="n">ms</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context_mode</span><span class="p">)</span>

    <span class="n">cfg</span><span class="o">.</span><span class="n">device_target</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">get_context</span><span class="p">(</span><span class="s2">&quot;device_target&quot;</span><span class="p">)</span>
    <span class="c1"># If running on CPU, not configure multiple-cards environment</span>
    <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">device_target</span> <span class="o">==</span> <span class="s2">&quot;CPU&quot;</span><span class="p">:</span>
        <span class="n">cfg</span><span class="o">.</span><span class="n">device_id</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">cfg</span><span class="o">.</span><span class="n">device_num</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">cfg</span><span class="o">.</span><span class="n">rank_id</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Set the card to be used at runtime</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="s2">&quot;device_id&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">device_id</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_id</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device_id</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">device_num</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># The init method is used to initialize multiple cards, and does not distinguish between Ascend and GPU. get_group_size and get_rank can only be used after init</span>
        <span class="n">init</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;run distribute!&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">group_size</span> <span class="o">=</span> <span class="n">get_group_size</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">device_num</span> <span class="o">!=</span> <span class="n">group_size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;the setting device_num: </span><span class="si">{</span><span class="n">cfg</span><span class="o">.</span><span class="n">device_num</span><span class="si">}</span><span class="s2"> not equal to the real group_size: </span><span class="si">{</span><span class="n">group_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">cfg</span><span class="o">.</span><span class="n">rank_id</span> <span class="o">=</span> <span class="n">get_rank</span><span class="p">()</span>
        <span class="n">ms</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">parallel_mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">DATA_PARALLEL</span><span class="p">,</span> <span class="n">gradients_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="s2">&quot;all_reduce_fusion_config&quot;</span><span class="p">):</span>
            <span class="n">ms</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">all_reduce_fusion_config</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">all_reduce_fusion_config</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cfg</span><span class="o">.</span><span class="n">device_num</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">cfg</span><span class="o">.</span><span class="n">rank_id</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;run standalone!&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>cfg is the parameter configuration file. Using this template requires at least the following parameters to be configured.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">seed</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">device_target</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;None&quot;</span>
<span class="nt">context_mode</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;graph&quot;</span><span class="w">  </span><span class="c1"># should be in [&#39;graph&#39;, &#39;pynative&#39;]</span>
<span class="nt">device_num</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">device_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
</pre></div>
</div>
<p>The above procedure is just a basic configuration of the operating environment. If you need to add some advanced features, please refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/mindspore/mindspore.set_context.html#mindspore.set_context">set_context</a>.</p>
</div>
<div class="section" id="generic-scripting-framework">
<h2>Generic Scripting Framework<a class="headerlink" href="#generic-scripting-framework" title="Permalink to this headline">¶</a></h2>
<p>A generic <a class="reference external" href="https://gitee.com/mindspore/models/tree/master/utils/model_scaffolding">script rack</a> provided by the models bin is used for:</p>
<ol class="simple">
<li><p>yaml parameter file parsing, parameter obtaining</p></li>
<li><p>ModelArts unified tool both on the cloud and on-premise</p></li>
</ol>
<p>The python files in the src directory are placed in the model_utils directory for use, e.g. <a class="reference external" href="https://gitee.com/mindspore/models/tree/master/official/cv/ResNet/src/model_utils">resnet</a>.</p>
</div>
<div class="section" id="inference-process">
<h2>Inference Process<a class="headerlink" href="#inference-process" title="Permalink to this headline">¶</a></h2>
<p>A generic inference process is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">src.model</span> <span class="kn">import</span> <span class="n">Net</span>
<span class="kn">from</span> <span class="nn">src.dataset</span> <span class="kn">import</span> <span class="n">create_dataset</span>
<span class="kn">from</span> <span class="nn">src.utils</span> <span class="kn">import</span> <span class="n">init_env</span>
<span class="kn">from</span> <span class="nn">src.model_utils.config</span> <span class="kn">import</span> <span class="n">config</span>

<span class="c1"># Initialize the operating environment</span>
<span class="n">init_env</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="c1"># Constructing dataset objects</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># Network model, task-related</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="c1"># Loss function, task-related</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="c1"># Load the trained parameters</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">net</span><span class="p">)</span>
<span class="c1"># Encapsulation into Model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;top_1_accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;top_5_accuracy&#39;</span><span class="p">})</span>
<span class="c1"># Model inference</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;result:&quot;</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="s2">&quot;ckpt=&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">checkpoint_path</span><span class="p">)</span>
</pre></div>
</div>
<p>Generally, the source code for network construction and data processing will be placed in the <code class="docutils literal notranslate"><span class="pre">src</span></code> directory, and the scripting framework will be placed in the <code class="docutils literal notranslate"><span class="pre">src.model_utils</span></code> directory. For example, you can refer to the implementation in <a class="reference external" href="https://gitee.com/mindspore/models">MindSpore models</a>.</p>
<p>The inference process cannot be encapsulated into a Model for operation sometimes, and then the inference process can be expanded into the form of a for loop. See <a class="reference external" href="https://gitee.com/mindspore/models/blob/master/official/cv/SSD/eval.py">ssd inference</a>.</p>
<div class="section" id="inference-verification">
<h3>Inference Verification<a class="headerlink" href="#inference-verification" title="Permalink to this headline">¶</a></h3>
<p>In the model analysis and preparation phase, we get the trained parameters of the reference implementation (in the reference implementation README or for training replication). Since the implementation of the model algorithm is not related to the framework, the trained parameters can be first converted into MindSpore <a class="reference external" href="https://www.mindspore.cn/tutorials/en/master/beginner/save_load.html">checkpoint</a> and loaded into the network for inference verification.</p>
<p>Please refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/master/migration_guide/sample_code.html">resnet network migration</a> for the whole process of inference verification.</p>
</div>
</div>
<div class="section" id="training-process">
<h2>Training Process<a class="headerlink" href="#training-process" title="Permalink to this headline">¶</a></h2>
<p>A general training process is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">LossMonitor</span><span class="p">,</span> <span class="n">TimeMonitor</span><span class="p">,</span> <span class="n">CheckpointConfig</span><span class="p">,</span> <span class="n">ModelCheckpoint</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">src.model</span> <span class="kn">import</span> <span class="n">Net</span>
<span class="kn">from</span> <span class="nn">src.dataset</span> <span class="kn">import</span> <span class="n">create_dataset</span>
<span class="kn">from</span> <span class="nn">src.utils</span> <span class="kn">import</span> <span class="n">init_env</span>
<span class="kn">from</span> <span class="nn">src.model_utils.config</span> <span class="kn">import</span> <span class="n">config</span>
<span class="kn">from</span> <span class="nn">src.model_utils.moxing_adapter</span> <span class="kn">import</span> <span class="n">moxing_wrapper</span>

<span class="nd">@moxing_wrapper</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">train_net</span><span class="p">():</span>
    <span class="c1"># Initialize the operating environment</span>
    <span class="n">init_env</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="c1"># Constructing dataset objects</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># Network model, task-related</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
    <span class="c1"># Loss function, task-related</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
    <span class="c1"># Optimizer implementation, task-related</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">config</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">)</span>
    <span class="c1"># Encapsulation into Model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;top_1_accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;top_5_accuracy&#39;</span><span class="p">})</span>
    <span class="c1"># checkpoint saving</span>
    <span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">(),</span>
                                         <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">ckpt_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;resnet&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s2">&quot;./checkpoint&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
    <span class="c1"># Model training</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">LossMonitor</span><span class="p">(),</span> <span class="n">TimeMonitor</span><span class="p">()])</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">train_net</span><span class="p">()</span>
</pre></div>
</div>
<p>Please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/master/beginner/save_load.html">Save and Load</a> for checkpoint saving.</p>
<p>In addition, the training process can be constructed through a functional approach, which is more flexible:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span><span class="p">,</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.amp</span> <span class="kn">import</span> <span class="n">StaticLossScaler</span><span class="p">,</span> <span class="n">all_finite</span>

<span class="k">class</span> <span class="nc">Trainer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A training example with two losses&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">loss1</span><span class="p">,</span> <span class="n">loss2</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">eval_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">net</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss1</span> <span class="o">=</span> <span class="n">loss1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss2</span> <span class="o">=</span> <span class="n">loss2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opt</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_data_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>    <span class="c1"># Get the number of training set batches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">parameters</span>
        <span class="c1"># Note that the first parameter of value_and_grad needs to be a graph that needs to be gradient-derived, typically containing a network and a loss. Here it can be a function, or a Cell</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_and_grad</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">forward_fn</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Use in the distributed scenario</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grad_reducer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_grad_reducer</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span> <span class="o">=</span> <span class="n">StaticLossScaler</span><span class="p">(</span><span class="n">loss_scale</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">run_eval</span> <span class="o">=</span> <span class="n">eval_dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_eval</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">eval_dataset</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_acc</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">get_grad_reducer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">grad_reducer</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">identity</span>
        <span class="n">parallel_mode</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">get_auto_parallel_context</span><span class="p">(</span><span class="s2">&quot;parallel_mode&quot;</span><span class="p">)</span>
        <span class="c1"># Determine whether it is a distributed scenario, and refer to the above generic runtime environment settings for the distributed scenario settings</span>
        <span class="n">reducer_flag</span> <span class="o">=</span> <span class="p">(</span><span class="n">parallel_mode</span> <span class="o">!=</span> <span class="n">ms</span><span class="o">.</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">STAND_ALONE</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">reducer_flag</span><span class="p">:</span>
            <span class="n">grad_reducer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DistributedGradReducer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">grad_reducer</span>

    <span class="k">def</span> <span class="nf">forward_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Positive network construction. Note that the first output must be the one that requires the gradient at the end&quot;&quot;&quot;</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">loss1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss1</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">loss2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss2</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss1</span> <span class="o">+</span> <span class="n">loss2</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">loss1</span><span class="p">,</span> <span class="n">loss2</span>

    <span class="nd">@ms</span><span class="o">.</span><span class="n">jit</span>    <span class="c1"># jit acceleration, need to meet the requirements of graph mode build, otherwise it will report an error</span>
    <span class="k">def</span> <span class="nf">train_single</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">loss1</span><span class="p">,</span> <span class="n">loss2</span><span class="p">),</span> <span class="n">grads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span><span class="o">.</span><span class="n">unscale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span><span class="o">.</span><span class="n">unscale</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_reducer</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">all_finite</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">state</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">loss1</span><span class="p">,</span> <span class="n">loss2</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
        <span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="c1"># Training an epoch</span>
            <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">):</span>
                <span class="n">loss</span><span class="p">,</span> <span class="n">loss1</span><span class="p">,</span> <span class="n">loss2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_single</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">batch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;step: [</span><span class="si">{</span><span class="n">batch</span><span class="si">}</span><span class="s2"> /</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data_size</span><span class="si">}</span><span class="s2">] &quot;</span>
                          <span class="sa">f</span><span class="s2">&quot;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">, loss1: </span><span class="si">{</span><span class="n">loss1</span><span class="si">}</span><span class="s2">, loss2: </span><span class="si">{</span><span class="n">loss2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="c1"># Reason and save the best checkpoint</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_eval</span><span class="p">:</span>
                <span class="n">eval_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">):</span>
                    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
                <span class="n">accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">accuracy</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_acc</span><span class="p">:</span>
                    <span class="c1"># Save the best checkpoint</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">best_acc</span> <span class="o">=</span> <span class="n">accuracy</span>
                    <span class="n">ms</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span> <span class="s2">&quot;best.ckpt&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Updata best acc: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="distributed-training">
<h3>Distributed Training<a class="headerlink" href="#distributed-training" title="Permalink to this headline">¶</a></h3>
<p>The multi-card distributed training process is the same as the single-card training process, except for the distributed-related configuration items and gradient aggregation. It should be noted that multi-card parallelism actually starts multiple python processes on MindSpore, and before MindSpore version 1.8, on Ascend environment, multiple processes need to be started manually.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="nv">$#</span><span class="w"> </span>!<span class="o">=</span><span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="o">]</span>
<span class="k">then</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Usage: sh run_distribution_ascend.sh [DEVICE_NUM] [START_ID] [RANK_TABLE_FILE] [CONFIG_PATH]&quot;</span>
<span class="nb">exit</span><span class="w"> </span><span class="m">1</span>
<span class="k">fi</span>

get_real_path<span class="o">(){</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">1</span><span class="p">:</span><span class="nv">0</span><span class="p">:</span><span class="nv">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;/&quot;</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">        </span><span class="nb">echo</span><span class="w"> </span><span class="nv">$1</span>
<span class="w">    </span><span class="k">else</span>
<span class="w">        </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>realpath<span class="w"> </span>-m<span class="w"> </span><span class="si">${</span><span class="nv">PWD</span><span class="si">}</span>/<span class="nv">$1</span><span class="k">)</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="k">fi</span>
<span class="o">}</span>

<span class="nv">RANK_TABLE_FILE</span><span class="o">=</span><span class="k">$(</span>get_real_path<span class="w"> </span><span class="nv">$3</span><span class="k">)</span>
<span class="nv">CONFIG_PATH</span><span class="o">=</span><span class="k">$(</span>get_real_path<span class="w"> </span><span class="nv">$4</span><span class="k">)</span>

<span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span>!<span class="w"> </span>-f<span class="w"> </span><span class="nv">$RANK_TABLE_FILE</span><span class="w"> </span><span class="o">]</span>
<span class="k">then</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;error: RANK_TABLE_FILE=</span><span class="nv">$RANK_TABLE_FILE</span><span class="s2"> is not a file&quot;</span>
<span class="nb">exit</span><span class="w"> </span><span class="m">1</span>
<span class="k">fi</span>

<span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span>!<span class="w"> </span>-f<span class="w"> </span><span class="nv">$CONFIG_PATH</span><span class="w"> </span><span class="o">]</span>
<span class="k">then</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;error: CONFIG_PATH=</span><span class="nv">$CONFIG_PATH</span><span class="s2"> is not a file&quot;</span>
<span class="nb">exit</span><span class="w"> </span><span class="m">1</span>
<span class="k">fi</span>

<span class="nv">BASE_PATH</span><span class="o">=</span><span class="k">$(</span><span class="nb">cd</span><span class="w"> </span>./<span class="s2">&quot;`dirname </span><span class="nv">$0</span><span class="s2">`&quot;</span><span class="w"> </span><span class="o">||</span><span class="w"> </span>exit<span class="p">;</span><span class="w"> </span><span class="nb">pwd</span><span class="k">)</span>

<span class="nb">export</span><span class="w"> </span><span class="nv">RANK_SIZE</span><span class="o">=</span><span class="nv">$1</span>
<span class="nv">STRAT_ID</span><span class="o">=</span><span class="nv">$2</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">RANK_TABLE_FILE</span><span class="o">=</span><span class="nv">$RANK_TABLE_FILE</span>

<span class="nb">cd</span><span class="w"> </span><span class="nv">$BASE_PATH</span>
<span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i&lt;<span class="si">${</span><span class="nv">RANK_SIZE</span><span class="si">}</span><span class="p">;</span><span class="w"> </span>i++<span class="o">))</span>
<span class="k">do</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_ID</span><span class="o">=</span><span class="k">$((</span>STRAT_ID<span class="w"> </span><span class="o">+</span><span class="w"> </span>i<span class="k">))</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">RANK_ID</span><span class="o">=</span><span class="nv">$i</span>
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span>./train_parallel<span class="nv">$i</span>
<span class="w">    </span>mkdir<span class="w"> </span>./train_parallel<span class="nv">$i</span>
<span class="w">    </span>cp<span class="w"> </span>-r<span class="w"> </span>../src<span class="w"> </span>./train_parallel<span class="nv">$i</span>
<span class="w">    </span>cp<span class="w"> </span>../*.py<span class="w"> </span>./train_parallel<span class="nv">$i</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;start training for rank </span><span class="nv">$RANK_ID</span><span class="s2">, device </span><span class="nv">$DEVICE_ID</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span>./train_parallel<span class="nv">$i</span><span class="w"> </span><span class="o">||</span><span class="nb">exit</span>
<span class="w">    </span>env<span class="w"> </span>&gt;<span class="w"> </span>env.log
<span class="w">    </span>python<span class="w"> </span>train.py<span class="w"> </span>--config_path<span class="o">=</span><span class="nv">$CONFIG_FILE</span><span class="w"> </span>--device_num<span class="o">=</span><span class="nv">$RANK_SIZE</span><span class="w"> </span>&gt;<span class="w"> </span>log.txt<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span>..
<span class="k">done</span>
</pre></div>
</div>
<p>After MindSpore 1.8, it can be launched with mpirun as well as the GPU.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="nv">$#</span><span class="w"> </span>!<span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="o">]</span>
<span class="k">then</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Usage: sh run_distribution_ascend.sh [DEVICE_NUM] [CONFIG_PATH]&quot;</span>
<span class="nb">exit</span><span class="w"> </span><span class="m">1</span>
<span class="k">fi</span>

get_real_path<span class="o">(){</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">1</span><span class="p">:</span><span class="nv">0</span><span class="p">:</span><span class="nv">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;/&quot;</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">        </span><span class="nb">echo</span><span class="w"> </span><span class="nv">$1</span>
<span class="w">    </span><span class="k">else</span>
<span class="w">        </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>realpath<span class="w"> </span>-m<span class="w"> </span><span class="si">${</span><span class="nv">PWD</span><span class="si">}</span>/<span class="nv">$1</span><span class="k">)</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="k">fi</span>
<span class="o">}</span>

<span class="nv">CONFIG_PATH</span><span class="o">=</span><span class="k">$(</span>get_real_path<span class="w"> </span><span class="nv">$2</span><span class="k">)</span>

<span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span>!<span class="w"> </span>-f<span class="w"> </span><span class="nv">$CONFIG_PATH</span><span class="w"> </span><span class="o">]</span>
<span class="k">then</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;error: CONFIG_PATH=</span><span class="nv">$CONFIG_PATH</span><span class="s2"> is not a file&quot;</span>
<span class="nb">exit</span><span class="w"> </span><span class="m">1</span>
<span class="k">fi</span>

<span class="nv">BASE_PATH</span><span class="o">=</span><span class="k">$(</span><span class="nb">cd</span><span class="w"> </span>./<span class="s2">&quot;`dirname </span><span class="nv">$0</span><span class="s2">`&quot;</span><span class="w"> </span><span class="o">||</span><span class="w"> </span>exit<span class="p">;</span><span class="w"> </span><span class="nb">pwd</span><span class="k">)</span>

<span class="nb">export</span><span class="w"> </span><span class="nv">RANK_SIZE</span><span class="o">=</span><span class="nv">$1</span>

<span class="nb">cd</span><span class="w"> </span><span class="nv">$BASE_PATH</span>
mpirun<span class="w"> </span>--allow-run-as-root<span class="w"> </span>-n<span class="w"> </span><span class="nv">$RANK_SIZE</span><span class="w"> </span>python<span class="w"> </span>../train.py<span class="w"> </span>--config_path<span class="o">=</span><span class="nv">$CONFIG_FILE</span><span class="w"> </span>--device_num<span class="o">=</span><span class="nv">$RANK_SIZE</span><span class="w"> </span>&gt;<span class="w"> </span>log.txt<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
</pre></div>
</div>
<p>If on the GPU, you can set which cards to use by <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7</span></code>. Specifying the card number is not currently supported on Ascend.</p>
<p>Please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/parallel/distributed_case.html">Distributed Case</a> for more details.</p>
</div>
</div>
<div class="section" id="offline-inference">
<h2>Offline Inference<a class="headerlink" href="#offline-inference" title="Permalink to this headline">¶</a></h2>
<p>In addition to the possibility of online reasoning, MindSpore provides many offline inference methods for different environments. Please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/infer/inference.html">Model Inference</a> for details.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../debug_and_tune.html" class="btn btn-neutral float-right" title="Debugging and Tuning" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="gradient.html" class="btn btn-neutral float-left" title="Gradient Derivation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>