

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Protecting User Privacy with Suppress Privacy &mdash; MindSpore master documentation</title>
  

  
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Using Membership Inference to Test Model Security" href="test_model_security_membership_inference.html" />
    <link rel="prev" title="Protecting User Privacy with Differential Privacy Mechanism" href="protect_user_privacy_with_differential_privacy.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindarmour_install.html">MindArmour Installation</a></li>
</ul>
<p class="caption"><span class="caption-text">AI Security</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="improve_model_security_nad.html">Improving Model Security with NAD Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_fuzzing.html">Testing Model Security Using Fuzz Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluation_of_CNNCTC.html">Evaluating the Robustness of the OCR Model CNN-CTC</a></li>
<li class="toctree-l1"><a class="reference internal" href="dynamic_obfuscation_protection.html">Dynamic Model Obfuscation</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_encrypt_protection.html">Model Encryption Protection</a></li>
</ul>
<p class="caption"><span class="caption-text">AI Privacy</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="protect_user_privacy_with_differential_privacy.html">Protecting User Privacy with Differential Privacy Mechanism</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Protecting User Privacy with Suppress Privacy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#mindarmour's-implementation-of-privacy-suppression">MindArmour’s Implementation of Privacy Suppression</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#implementation">Implementation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#importing-library-files">Importing Library Files</a></li>
<li class="toctree-l3"><a class="reference internal" href="#parameter-configuration">Parameter Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#preprocessed-datasets">Preprocessed Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="#building-the-model">Building the Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#introduction-of-privacy-suppression">Introduction of Privacy Suppression</a></li>
<li class="toctree-l3"><a class="reference internal" href="#privacy-protection-effect-test">Privacy Protection Effect Test</a></li>
<li class="toctree-l3"><a class="reference internal" href="#citation">Citation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="test_model_security_membership_inference.html">Using Membership Inference to Test Model Security</a></li>
</ul>
<p class="caption"><span class="caption-text">AI Reliability</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="concept_drift_time_series.html">Implementing the Concept Drift Detection Application of Time Series Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="concept_drift_images.html">Implementing the Concept Drift Detection Application of Image Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="fault_injection.html">Implementing the Model Fault Injection and Evaluation</a></li>
</ul>
<p class="caption"><span class="caption-text">API References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.html">mindarmour</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.attacks.html">mindarmour.adv_robustness.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.defenses.html">mindarmour.adv_robustness.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.detectors.html">mindarmour.adv_robustness.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.adv_robustness.evaluations.html">mindarmour.adv_robustness.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.fuzz_testing.html">mindarmour.fuzz_testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.natural_robustness.transform.image.html">mindarmour.natural_robustness.transform.image</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.diff_privacy.html">mindarmour.privacy.diff_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.evaluation.html">mindarmour.privacy.evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.privacy.sup_privacy.html">mindarmour.privacy.sup_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.reliability.html">mindarmour.reliability</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.utils.html">mindarmour.utils</a></li>
</ul>
<p class="caption"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design.html">Overall Security and Trustworthiness Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="differential_privacy_design.html">Differential Privacy Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="fuzzer_design.html">AI Model Security Testing Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="security_and_privacy.html">MindArmour Module Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Protecting User Privacy with Suppress Privacy</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/protect_user_privacy_with_suppress_privacy.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="protecting-user-privacy-with-suppress-privacy">
<h1>Protecting User Privacy with Suppress Privacy<a class="headerlink" href="#protecting-user-privacy-with-suppress-privacy" title="Permalink to this headline">¶</a></h1>
<p>Translator: <a class="reference external" href="https://gitee.com/weng-weihua">翁炜华</a></p>
<p><a href="https://gitee.com/mindspore/docs/blob/master/docs/mindarmour/docs/source_en/protect_user_privacy_with_suppress_privacy.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png"></a></p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>Privacy suppression is a mechanism to protect the privacy of user dat a. Privacy suppression is a way to protect user privacy when training an AI model. By removing unimportant parameters from the model, the number of its parameters can be significantly reduced, which reduces the input sample information that may be leaked by the model, thus greatly reducing the possibility of obtaining the original samples through model reversal attacks. Experiments show that the privacy suppression technique can achieve a better balance between the training accuracy and the degree of privacy protection for some models compared to differential privacy.</p>
<div class="section" id="mindarmour's-implementation-of-privacy-suppression">
<h3>MindArmour’s Implementation of Privacy Suppression<a class="headerlink" href="#mindarmour's-implementation-of-privacy-suppression" title="Permalink to this headline">¶</a></h3>
<p>Suppress-Privacy, a Suppress-Privacy module in MindArmour, implements a suppressed privacy optimizer. During the model training process, unimportant parameters are gradually set to 0 in a certain ratio, and eventually only 5-10% of the parameters are retained.</p>
<p>Here is an example showing that how to train a neural network model in MindSpore using the LeNet model, MNIST dataset, and the SuppressourPrivacy optimizer.</p>
<blockquote>
<div><p>This example is for the Ascend 910 AI processor and you can download the full sample code at <a class="reference external" href="https://gitee.com/mindspore/mindarmour/blob/master/examples/privacy/sup_privacy/sup_privacy.py">https://gitee.com/mindspore/mindarmour/blob/master/examples/privacy/sup_privacy/sup_privacy.py</a></p>
</div></blockquote>
</div>
</div>
<div class="section" id="implementation">
<h2>Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="importing-library-files">
<h3>Importing Library Files<a class="headerlink" href="#importing-library-files" title="Permalink to this headline">¶</a></h3>
<p>The following presents the public modules, MindSpore-related modules, and privacy suppression modules that we need.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">easydict</span> <span class="kn">import</span> <span class="n">EasyDict</span> <span class="k">as</span> <span class="n">edict</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Accuracy</span><span class="p">,</span> <span class="n">LossMonitor</span><span class="p">,</span> <span class="n">CheckpointConfig</span><span class="p">,</span> <span class="n">ModelCheckpoint</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.vision</span> <span class="k">as</span> <span class="nn">vision</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset.vision</span> <span class="kn">import</span> <span class="n">Inter</span>

<span class="kn">from</span> <span class="nn">examples.common.networks.lenet5.lenet5_net</span> <span class="kn">import</span> <span class="n">LeNet5</span>

<span class="kn">from</span> <span class="nn">mindarmour.privacy.sup_privacy</span> <span class="kn">import</span> <span class="n">SuppressModel</span>
<span class="kn">from</span> <span class="nn">mindarmour.privacy.sup_privacy</span> <span class="kn">import</span> <span class="n">SuppressMasker</span>
<span class="kn">from</span> <span class="nn">mindarmour.privacy.sup_privacy</span> <span class="kn">import</span> <span class="n">SuppressPrivacyFactory</span>
<span class="kn">from</span> <span class="nn">mindarmour.privacy.sup_privacy</span> <span class="kn">import</span> <span class="n">MaskLayerDes</span>

<span class="kn">from</span> <span class="nn">mindarmour.utils</span> <span class="kn">import</span> <span class="n">LogUtil</span>

<span class="n">LOGGER</span> <span class="o">=</span> <span class="n">LogUtil</span><span class="o">.</span><span class="n">get_instance</span><span class="p">()</span>
<span class="n">LOGGER</span><span class="o">.</span><span class="n">set_level</span><span class="p">(</span><span class="s1">&#39;INFO&#39;</span><span class="p">)</span>
<span class="n">TAG</span> <span class="o">=</span> <span class="s1">&#39;Lenet5_Suppress_train&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="parameter-configuration">
<h3>Parameter Configuration<a class="headerlink" href="#parameter-configuration" title="Permalink to this headline">¶</a></h3>
<ol>
<li><p>Set the runtime environment, model training parameters, checkpoint storage parameters, and the batch_size parameter is recommended not to exceed 64. For more configurations, please refer to <a class="reference external" href="https://gitee.com/mindspore/mindarmour/blob/master/examples/privacy/sup_privacy/sup_privacy_config.py">https://gitee.com/mindspore/mindarmour/blob/master/examples/privacy/sup_privacy/sup_privacy_config.py</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cfg</span> <span class="o">=</span> <span class="n">edict</span><span class="p">({</span>
     <span class="s1">&#39;num_classes&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>  <span class="c1"># the number of classes of model&#39;s output</span>
     <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>  <span class="c1"># batch size for training</span>
     <span class="s1">&#39;image_height&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>  <span class="c1"># the height of training samples</span>
     <span class="s1">&#39;image_width&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>  <span class="c1"># the width of training samples</span>
     <span class="s1">&#39;keep_checkpoint_max&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>  <span class="c1"># the maximum number of checkpoint files would be saved</span>
     <span class="s1">&#39;device_target&#39;</span><span class="p">:</span> <span class="s1">&#39;Ascend&#39;</span><span class="p">,</span>  <span class="c1"># device used</span>
<span class="p">})</span>
</pre></div>
</div>
</li>
<li><p>Configure the necessary information, including environment information and the execution mode. The PyNative mode on Ascend is currently supported.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">device_target</span><span class="p">)</span>
</pre></div>
</div>
<p>For detailed interface configuration information, see the <code class="docutils literal notranslate"><span class="pre">set_context</span></code> interface description.</p>
</li>
</ol>
</div>
<div class="section" id="preprocessed-datasets">
<h3>Preprocessed Datasets<a class="headerlink" href="#preprocessed-datasets" title="Permalink to this headline">¶</a></h3>
<p>Load the dataset and convert it into MindSpore data format.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_mnist_dataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">repeat_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                           <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    create dataset for training or testing</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># define dataset</span>
    <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">MnistDataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>

    <span class="c1"># define operation parameters</span>
    <span class="n">resize_height</span><span class="p">,</span> <span class="n">resize_width</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span>
    <span class="n">rescale</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">255.0</span>
    <span class="n">shift</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="c1"># define map operations</span>
    <span class="n">resize_op</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="n">resize_height</span><span class="p">,</span> <span class="n">resize_width</span><span class="p">),</span>
                          <span class="n">interpolation</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">)</span>
    <span class="n">rescale_op</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">Rescale</span><span class="p">(</span><span class="n">rescale</span><span class="p">,</span> <span class="n">shift</span><span class="p">)</span>
    <span class="n">hwc2chw_op</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
    <span class="n">type_cast_op</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">TypeCast</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="c1"># apply map operations on images</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sparse</span><span class="p">:</span>
        <span class="n">one_hot_enco</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">OneHot</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">one_hot_enco</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span>
                      <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>
        <span class="n">type_cast_op</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">TypeCast</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">type_cast_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span>
                  <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>
    <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">resize_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span>
                  <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>
    <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">rescale_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span>
                  <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>
    <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">hwc2chw_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span>
                  <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>

    <span class="c1"># apply DatasetOps</span>
    <span class="n">buffer_size</span> <span class="o">=</span> <span class="mi">10000</span>
    <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">buffer_size</span><span class="p">)</span>
    <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ds1</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repeat_size</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ds1</span>
</pre></div>
</div>
</div>
<div class="section" id="building-the-model">
<h3>Building the Model<a class="headerlink" href="#building-the-model" title="Permalink to this headline">¶</a></h3>
<p>Here is an example of training the LeNet model, you can also build and train your own model.</p>
<p>Load the LeNet network, configure the checkpoint, set the optimizer type, and load the data with the loading function <code class="docutils literal notranslate"><span class="pre">generate_mnist_dataset</span></code> defined above.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">networks_l5</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
<span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                             <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">keep_checkpoint_max</span><span class="p">)</span>
<span class="n">ckpoint_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;checkpoint_lenet&quot;</span><span class="p">,</span>
                             <span class="n">directory</span><span class="o">=</span><span class="s1">&#39;./trained_ckpt_file/&#39;</span><span class="p">,</span>
                             <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>

<span class="c1"># get training dataset</span>
<span class="n">ds_train</span> <span class="o">=</span> <span class="n">generate_mnist_dataset</span><span class="p">(</span><span class="s1">&#39;MNIST_unzip/train&#39;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="introduction-of-privacy-suppression">
<h3>Introduction of Privacy Suppression<a class="headerlink" href="#introduction-of-privacy-suppression" title="Permalink to this headline">¶</a></h3>
<ol>
<li><p>Configure the parameters of the suppress privacy optimizer</p>
<ul class="simple">
<li><p>Define which layers of the AI model are involved in the suppress operation.</p></li>
<li><p>Instantiate the suppress privacy factory class.</p></li>
<li><p>Define the loss function.</p></li>
<li><p>Set the optimizer type.</p></li>
<li><p>If the sample size is 60000, the recommended parameters are set to end_epoch:10, start_epoch:3, mask_times:1000, lr:0.10, sparse_end:0.95, and sparse_start:0.0.
This way the interval between two adjacent suppress operations is roughly 10~20 batches.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># layer_name (str): Layer name, get the name of one layer as following:</span>
<span class="c1">#    for layer in networks.get_parameters(expand=True):</span>
<span class="c1">#        if layer.name == &quot;conv&quot;: ...</span>
<span class="c1"># grad_idx (int): Grad layer index, get mask layer&#39;s index in grad tuple.</span>
<span class="c1"># is_add_noise (bool): If True, the weight of this layer can add noise.</span>
<span class="c1">#    If False, the weight of this layer can not add noise.</span>
<span class="c1"># is_lower_clip (bool): If true, the weights of this layer would be clipped to greater than an lower bound value.</span>
<span class="c1">#    If False, the weights of this layer won&#39;t be clipped.</span>
<span class="c1"># min_num (int): The number of weights left that not be suppressed, which need to be greater than 0.</span>
<span class="c1"># upper_bound (float): max value of weight in this layer, default value is 1.20 .</span>
<span class="n">masklayers_lenet5</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># determine which layer should be masked</span>
<span class="n">masklayers_lenet5</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MaskLayerDes</span><span class="p">(</span><span class="s2">&quot;conv1.weight&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">masklayers_lenet5</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MaskLayerDes</span><span class="p">(</span><span class="s2">&quot;conv2.weight&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span>
<span class="n">masklayers_lenet5</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MaskLayerDes</span><span class="p">(</span><span class="s2">&quot;fc1.weight&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">masklayers_lenet5</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MaskLayerDes</span><span class="p">(</span><span class="s2">&quot;fc2.weight&quot;</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">masklayers_lenet5</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MaskLayerDes</span><span class="p">(</span><span class="s2">&quot;fc3.weight&quot;</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span>

<span class="c1"># networks (Cell): The training network.</span>
<span class="c1"># mask_layers (list): Description of the training network layers that need to be suppressed.</span>
<span class="c1"># policy (str): Training policy for suppress privacy training. &quot;local_train&quot; means local training.</span>
<span class="c1"># end_epoch (int): The last epoch in suppress operations, 0 &lt; start_epoch &lt;= end_epoch &lt;= 100 .</span>
<span class="c1"># batch_num (int): The num of batch in an epoch, should be equal to num_samples/batch_size .</span>
<span class="c1"># start_epoch (int): The first epoch in suppress operations, 0 &lt; start_epoch &lt;= end_epoch &lt;= 100 .</span>
<span class="c1"># mask_times (int): The num of suppress operations.</span>
<span class="c1"># lr (Union[float, int]): Learning rate, 0 &lt; lr &lt;= 0.5 .</span>
<span class="c1"># sparse_end (float): The sparsity to reach, 0.0 &lt;= sparse_start &lt; sparse_end &lt; 1.0 .</span>
<span class="c1"># sparse_start (float): The sparsity to start, 0.0 &lt;= sparse_start &lt; sparse_end &lt; 1.0 .  </span>
<span class="n">suppress_ctrl_instance</span> <span class="o">=</span> <span class="n">SuppressPrivacyFactory</span><span class="p">()</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">networks_l5</span><span class="p">,</span>
                                                        <span class="n">masklayers_lenet5</span><span class="p">,</span>
                                                        <span class="n">policy</span><span class="o">=</span><span class="s2">&quot;local_train&quot;</span><span class="p">,</span>
                                                        <span class="n">end_epoch</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                                        <span class="n">batch_num</span><span class="o">=</span><span class="mi">1875</span><span class="p">,</span>
                                                        <span class="n">start_epoch</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                                                        <span class="n">mask_times</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                                                        <span class="n">lr</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                                                        <span class="n">sparse_end</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
                                                        <span class="n">sparse_start</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
<span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="n">net_opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">networks_l5</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="mf">0.05</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Packaging the LeNet model as a suppression privacy model</p>
<ul class="simple">
<li><p>Instantiate the suppress privacy model class SuppressModel, which is used to train the model.</p></li>
<li><p>Instantiate SuppressMasker, a privacy suppression monitor, for selecting the appropriate time during training to perform suppress (set to zero) operations on model parameters.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create the suppress model for training.</span>
<span class="n">model_instance</span> <span class="o">=</span> <span class="n">SuppressModel</span><span class="p">(</span><span class="n">network</span><span class="o">=</span><span class="n">networks_l5</span><span class="p">,</span>
                                <span class="n">loss_fn</span><span class="o">=</span><span class="n">net_loss</span><span class="p">,</span>
                                <span class="n">optimizer</span><span class="o">=</span><span class="n">net_opt</span><span class="p">,</span>
                                <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">Accuracy</span><span class="p">()})</span>
<span class="n">model_instance</span><span class="o">.</span><span class="n">link_suppress_ctrl</span><span class="p">(</span><span class="n">suppress_ctrl_instance</span><span class="p">)</span>
<span class="n">suppress_masker</span> <span class="o">=</span> <span class="n">SuppressMasker</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_instance</span><span class="p">,</span> <span class="n">suppress_ctrl</span><span class="o">=</span><span class="n">suppress_ctrl_instance</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Model Training and Testing</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">TAG</span><span class="p">,</span> <span class="s2">&quot;============== Starting SUPP Training ==============&quot;</span><span class="p">)</span>
<span class="n">model_instance</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ckpoint_cb</span><span class="p">,</span> <span class="n">LossMonitor</span><span class="p">(),</span> <span class="n">suppress_masker</span><span class="p">],</span>
                     <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">TAG</span><span class="p">,</span> <span class="s2">&quot;============== Starting SUPP Testing ==============&quot;</span><span class="p">)</span>
<span class="n">ds_eval</span> <span class="o">=</span> <span class="n">generate_mnist_dataset</span><span class="p">(</span><span class="s1">&#39;MNIST_unzip/test&#39;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">model_instance</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">ds_eval</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">TAG</span><span class="p">,</span> <span class="s2">&quot;============== SUPP Accuracy: </span><span class="si">%s</span><span class="s2">  ==============&quot;</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Executing the command</p>
<p>To run the script, enter the following command in the command line:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>examples/privacy/sup_privacy/sup_privacy.py
</pre></div>
</div>
<p>Replace <code class="docutils literal notranslate"><span class="pre">sup_privacy.py</span></code> with the name of your script.</p>
</li>
<li><p>Displaying the results</p>
<p>The accuracy of LeNet model without privacy suppression is stable at 99%, and the convergence of LeNet model using privacy suppression is stable at about 97.5%.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>============== Starting SUPP Training ==============
...
============== Starting SUPP Testing ==============
...
============== SUPP Accuracy: 0.9745  ==============
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="privacy-protection-effect-test">
<h3>Privacy Protection Effect Test<a class="headerlink" href="#privacy-protection-effect-test" title="Permalink to this headline">¶</a></h3>
<p>To evaluate the effect of privacy suppression training on the protection of the dataset, we test it using an image reversal attack.
This inverse attack can restore the original image based on the output of the original image at one layer of the neural network, mainly because the network “remembers” the features of the training set during the training process.</p>
<p>The principle of this attack method can be found in <a class="reference external" href="https://arxiv.org/pdf/1412.0035.pdf">https://arxiv.org/pdf/1412.0035.pdf</a> and the complete code implementation can be found in <a class="reference external" href="https://gitee.com/mindspore/mindarmour/blob/master/examples/privacy/inversion_attack/mnist_inversion_attack.py">https://gitee.com/mindspore/mindarmour/blob/master/examples/privacy/inversion_attack/mnist_inversion_attack.py</a>, The following describes detailed test steps:</p>
<ol>
<li><p>Preparation</p>
<p>In order to compare with the suppressed privacy training, we need to get the CheckPoint file of the model using the regular training first. The model training can be referred to
<a class="reference external" href="https://gitee.com/mindspore/mindarmour/blob/master/examples/common/networks/lenet5/mnist_train.py">mindarmour/examples/common/networks/lenet5</a>,
It has the following directory structure:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>├── __init__.py
├── lenet5_net.py
└── mnist_train.py
</pre></div>
</div>
<p>Where <code class="docutils literal notranslate"><span class="pre">lenet5_net.py</span></code> is the model definition for LeNet5 and <code class="docutils literal notranslate"><span class="pre">mnist_train.py</span></code> is the regular training script for LeNet5. The <code class="docutils literal notranslate"><span class="pre">trained_ckpt_file</span></code> folder containing the model CheckPoint files can be generated by running the following command in this directory.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>mnist_train.py
</pre></div>
</div>
<p>In addition, since the newly trained model is needed for the evaluation of attack effectiveness in step 7 below, we change the generation command of the variable <code class="docutils literal notranslate"><span class="pre">ckpoint_cb</span></code> in the <code class="docutils literal notranslate"><span class="pre">mnist_train.py</span></code> file after generating the <code class="docutils literal notranslate"><span class="pre">trained_ckpt_file</span></code> directory to.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ckpoint_cb</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;checkpoint_lenet&quot;</span><span class="p">,</span>
                          <span class="n">directory</span><span class="o">=</span><span class="s2">&quot;./new_trained_ckpt_file/&quot;</span><span class="p">,</span>
                          <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
</pre></div>
</div>
<p>Where <code class="docutils literal notranslate"><span class="pre">prefix</span></code> represents the prefix of the generated CheckPoint file name, <code class="docutils literal notranslate"><span class="pre">directory</span></code> represents the path where the CheckPoint file is stored, and then run <code class="docutils literal notranslate"><span class="pre">mnist_train.py</span></code>.
Run <code class="docutils literal notranslate"><span class="pre">mnist_train.py</span></code> to get the <code class="docutils literal notranslate"><span class="pre">new_trained_ckpt_file</span></code> folder and the model files contained in it. At this point, the directory structure of <code class="docutils literal notranslate"><span class="pre">examples/common/networks/lenet5</span></code> should look like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span> ├── __init__.py
 ├── lenet5_net.py
 ├── mnist_train.py
 ├── new_trained_ckpt_file
 │   ├── checkpoint_lenet-10_1875.ckpt
 │   ├── checkpoint_lenet-1_1875.ckpt
 │   ├── checkpoint_lenet-2_1875.ckpt
 │   ├── checkpoint_lenet-3_1875.ckpt
 │   ├── checkpoint_lenet-4_1875.ckpt
 │   ├── checkpoint_lenet-5_1875.ckpt
 │   ├── checkpoint_lenet-6_1875.ckpt
 │   ├── checkpoint_lenet-7_1875.ckpt
 │   ├── checkpoint_lenet-8_1875.ckpt
 │   ├── checkpoint_lenet-9_1875.ckpt
 │   └── checkpoint_lenet-graph.meta
 └── trained_ckpt_file
     ├── checkpoint_lenet-10_1875.ckpt
     ├── checkpoint_lenet-1_1875.ckpt
     ├── checkpoint_lenet-2_1875.ckpt
     ├── checkpoint_lenet-3_1875.ckpt
     ├── checkpoint_lenet-4_1875.ckpt
     ├── checkpoint_lenet-5_1875.ckpt
     ├── checkpoint_lenet-6_1875.ckpt
     ├── checkpoint_lenet-7_1875.ckpt
     ├── checkpoint_lenet-8_1875.ckpt
     ├── checkpoint_lenet-9_1875.ckpt
     └── checkpoint_lenet-graph.meta
</pre></div>
</div>
</li>
<li><p>Import the required modules</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">softmax</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindarmour.privacy.evaluation</span> <span class="kn">import</span> <span class="n">ImageInversionAttack</span>
<span class="kn">from</span> <span class="nn">mindarmour.utils</span> <span class="kn">import</span> <span class="n">LogUtil</span>
<span class="kn">from</span> <span class="nn">examples.common.networks.lenet5.lenet5_net</span> <span class="kn">import</span> <span class="n">LeNet5</span><span class="p">,</span> <span class="n">conv</span><span class="p">,</span> <span class="n">fc_with_initialize</span>
<span class="kn">from</span> <span class="nn">examples.common.dataset.data_processing</span> <span class="kn">import</span> <span class="n">generate_mnist_dataset</span>
<span class="n">LOGGER</span> <span class="o">=</span> <span class="n">LogUtil</span><span class="o">.</span><span class="n">get_instance</span><span class="p">()</span>
<span class="n">LOGGER</span><span class="o">.</span><span class="n">set_level</span><span class="p">(</span><span class="s1">&#39;INFO&#39;</span><span class="p">)</span>
<span class="n">TAG</span> <span class="o">=</span> <span class="s1">&#39;InversionAttack&#39;</span>
</pre></div>
</div>
</li>
<li><p>Build a reverse test network</p>
<p>For better demonstration, we take the first two convolutional layers conv1 and conv2 of LeNet5 and the first fully connected layer fc1 as the test network, so the attack task is: to restore a certain image based on the feature map output from fc1.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LeNet5_part</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Part of LeNet5 network.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeNet5_part</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">16</span><span class="o">*</span><span class="mi">5</span><span class="o">*</span><span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</li>
<li><p>Import the trained CheckPoint file into the model</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Checkpoint_path</span> <span class="o">=</span> <span class="s1">&#39;../../common/networks/lenet5/trained_ckpt_file/checkpoint_lenet-10_1875.ckpt&#39;</span>
<span class="n">load_dict</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">Checkpoint_path</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5_part</span><span class="p">()</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">load_dict</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Get test samples</p>
<p>We take 30 images for testing, saving them by themselves and their output after <code class="docutils literal notranslate"><span class="pre">LeNet5_part</span></code> (i.e. <code class="docutils literal notranslate"><span class="pre">target_features</span></code>).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># get original data</span>
<span class="n">data_list</span> <span class="o">=</span> <span class="s2">&quot;../../common/dataset/MNIST/train&quot;</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">generate_mnist_dataset</span><span class="p">(</span><span class="n">data_list</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">batch_num</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">sample_num</span> <span class="o">=</span> <span class="mi">30</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">ds</span><span class="o">.</span><span class="n">create_tuple_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">true_labels</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">][:</span> <span class="n">sample_num</span><span class="p">]</span>
    <span class="n">target_features</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">images</span><span class="p">))</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()[:</span><span class="n">sample_num</span><span class="p">]</span>
    <span class="n">original_images</span> <span class="o">=</span> <span class="n">images</span><span class="p">[:</span> <span class="n">sample_num</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">batch_num</span><span class="p">:</span>
        <span class="k">break</span>
</pre></div>
</div>
</li>
<li><p>Conduct reverse attacks</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">inversion_attack</span> <span class="o">=</span> <span class="n">ImageInversionAttack</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">input_bound</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loss_weights</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">inversion_images</span> <span class="o">=</span> <span class="n">inversion_attack</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">target_features</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Attack result evaluation and presentation</p>
<p>We use matplotlib to draw the original image and the image restored with the inverse attack, and call the <code class="docutils literal notranslate"><span class="pre">evaluate</span></code> method of <code class="docutils literal notranslate"><span class="pre">inversion_attack</span></code> for quantitative evaluation.
The <code class="docutils literal notranslate"><span class="pre">evaluate</span></code> method returns <code class="docutils literal notranslate"><span class="pre">avg_l2_dis</span></code>, <code class="docutils literal notranslate"><span class="pre">avg_ssim</span></code> and <code class="docutils literal notranslate"><span class="pre">avg_confi</span></code>, which denote the average L2 parametric distance and average structural similarity, as well as the inference result of the reverse-reduced image on a new model (average confidence on its true label).
In general, the smaller <code class="docutils literal notranslate"><span class="pre">avg_l2_dis</span></code> and the larger <code class="docutils literal notranslate"><span class="pre">avg_ssim</span></code> represent the closer the inversion_images are to the original_images; and the new neural network model can replace the human vision to make a quantitative assessment of the recognizability of the images (i.e., the higher <code class="docutils literal notranslate"><span class="pre">avg_confi</span></code> indicates that the inversion _image contains semantic information that is closer to the original image).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plot_num</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">sample_num</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">plot_num</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">plot_num</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Original images&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gray</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">plot_num</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="n">plot_num</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Inverted images based on ordinary trained model&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gray</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">inversion_images</span><span class="p">[</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">net2</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
<span class="n">new_ckpt_path</span> <span class="o">=</span> <span class="s1">&#39;../../common/networks/lenet5/new_trained_ckpt_file/checkpoint_lenet-10_1875.ckpt&#39;</span>
<span class="n">new_load_dict</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">new_ckpt_path</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net2</span><span class="p">,</span> <span class="n">new_load_dict</span><span class="p">)</span>
<span class="n">pred_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">net2</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inversion_images</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">avg_l2_dis</span><span class="p">,</span> <span class="n">avg_ssim</span><span class="p">,</span> <span class="n">avg_confi</span> <span class="o">=</span> <span class="n">inversion_attack</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">original_images</span><span class="p">,</span> <span class="n">inversion_images</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">,</span> <span class="n">net2</span><span class="p">)</span>
<span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">TAG</span><span class="p">,</span> <span class="s1">&#39;The average L2 distance between original images and inverted images is: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_l2_dis</span><span class="p">))</span>
<span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">TAG</span><span class="p">,</span> <span class="s1">&#39;The average ssim value between original images and inverted images is: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_ssim</span><span class="p">))</span>
<span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">TAG</span><span class="p">,</span> <span class="s1">&#39;The average prediction confidence on true labels of inverted images is: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_confi</span><span class="p">))</span>
<span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">TAG</span><span class="p">,</span> <span class="s1">&#39;True labels of original images are:      </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">true_labels</span><span class="p">)</span>
<span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">TAG</span><span class="p">,</span> <span class="s1">&#39;Predicted labels of inverted images are: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">pred_labels</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Experimental results</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>The average L2 distance between original images and inverted images is: 0.8294931122450715
The average ssim value between original images and inverted images is: 0.2429179625584347
The average prediction confidence on true labels of inverted images is: 0.9547292590141296
True labels of original images are:      [5 7 1 0 4 3 1 5 5 9 5 0 9 9 7 5 4 2 1 7 4 0 0 6 2 6 0 6 6 6]
Predicted labels of inverted images are: [5 7 1 0 4 3 1 5 5 9 5 0 9 9 7 5 4 2 1 7 4 0 0 6 2 6 0 6 6 6]
</pre></div>
</div>
<p><img alt="fuzz_seed" src="_images/inversion_ordinary.png" /></p>
<p>We can see the general outline of the original_images from the inversion_images, indicating that the conventionally trained model is likely to lead to privacy leakage of the training set.
<strong>In order to verify that the model obtained by privacy suppression training can better protect the information of the training data</strong>, we replace the CheckPoint file in step 4 above with the CheckPoint file obtained by privacy suppression training and execute the process from step 2 to step 7 above, we can obtain the following results.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>The average L2 distance between original images and inverted images is: 0.862553358599391
The average ssim value between original images and inverted images is: 0.2644709319921787
The average prediction confidence on true labels of inverted images is: 0.5576204061508179
True labels of original images are:      [9 2 2 0 1 2 9 8 5 0 7 3 4 8 9 0 6 6 7 2 0 6 7 5 8 8 1 6 7 9]
Predicted labels of inverted images are: [8 2 2 0 1 2 7 8 5 0 7 3 4 8 9 7 6 6 7 2 0 6 7 5 8 8 1 5 7 9]
</pre></div>
</div>
<p><img alt="fuzz_seed" src="_images/inversion_sup.png" /></p>
<p>First, the results on the visualization show that the model obtained from the inverse attack based on the suppression of privacy training is very poor; however, the avg_l2_dis and avg_ssim obtained in this case are very close to the previous one.
This is mainly due to the fact that avg_l2_dis and avg_ssim can only compare low-order information between images based on the mean and standard deviation of image pixels, while avg_confi can compare higher-order semantic information between images.</p>
<p>The samples used in this experiment are MNIST datasets, which are relatively simple images, with the black background occupying most of the image and the white part containing the main information occupying less of the area. However, it can be seen that the avg_confi obtained based on the suppressed privacy model is significantly lower than the previous set of experiments, which indicates that the images constructed in reverse have been more difficult to be recognized by the new model, and this result is consistent with the results observed by our human vision.</p>
</li>
</ol>
</div>
<div class="section" id="citation">
<h3>Citation<a class="headerlink" href="#citation" title="Permalink to this headline">¶</a></h3>
<p>[1] Ligeng Zhu, Zhijian Liu, and Song Han. <a class="reference external" href="http://arxiv.org/pdf/1906.08935.pdf">Deep Leakage from Gradients</a>. NeurIPS, 2019.</p>
<p>[2] Aravindh Mahendran, Andrea Vedaldi. <a class="reference external" href="https://arxiv.org/pdf/1412.0035.pdf">Understanding Deep Image Representations by Inverting Them</a>. CVPR, 2015.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="test_model_security_membership_inference.html" class="btn btn-neutral float-right" title="Using Membership Inference to Test Model Security" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="protect_user_privacy_with_differential_privacy.html" class="btn btn-neutral float-left" title="Protecting User Privacy with Differential Privacy Mechanism" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>