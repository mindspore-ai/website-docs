<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.ops.operations &mdash; MindSpore 0.2.0-alpha documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script><script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/js/theme.js"></script><script src="../../../_static/underscore.js"></script><script src="../../../_static/doctools.js"></script><script async="async" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/mathjax/MathJax-3.2.2/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="mindspore.parallel" href="mindspore.parallel.html" />
    <link rel="prev" title="mindspore.ops.composite" href="mindspore.ops.composite.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dtype.html">mindspore.dtype</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.dynamic_lr.html">mindspore.nn.dynamic_lr</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.composite.html">mindspore.ops.composite</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindspore.ops.operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.parallel.html">mindspore.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.transforms.c_transforms.html">mindspore.dataset.transforms.c_transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.transforms.vision.c_transforms.html">mindspore.dataset.transforms.vision.c_transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.transforms.py_transforms.html">mindspore.dataset.transforms.py_transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.transforms.vision.py_transforms.html">mindspore.dataset.transforms.vision.py_transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindinsight/mindinsight.lineagemgr.html">mindinsight.lineagemgr</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.html">mindarmour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.utils.html">mindarmour.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.evaluations.html">mindarmour.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.detectors.html">mindarmour.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.attacks.html">mindarmour.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.defenses.html">mindarmour.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.fuzzing.html">mindarmour.fuzzing</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>mindspore.ops.operations</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/api/python/mindspore/mindspore.ops.operations.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-mindspore.ops.operations">
<span id="mindspore-ops-operations"></span><h1>mindspore.ops.operations<a class="headerlink" href="#module-mindspore.ops.operations" title="Permalink to this headline"></a></h1>
<p>Primitive operator classes.</p>
<p>A collection of operators to build nerual networks or computing functions.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ACos">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ACos</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#ACos"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ACos" title="Permalink to this definition"></a></dt>
<dd><p>Computes arccosine of input element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape as <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">acos</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ACos</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.74</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.30</span><span class="p">,</span> <span class="mf">0.56</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">acos</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Abs">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Abs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Abs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Abs" title="Permalink to this definition"></a></dt>
<dd><p>Returns absolute value of a tensor element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor. The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape as the <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">abs</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Abs</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">abs</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">[1.0, 1.0, 0.0]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Acosh">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Acosh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Acosh"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Acosh" title="Permalink to this definition"></a></dt>
<dd><p>Compute inverse hyperbolic cosine of x element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>,
and the data type of ‘input_x’ is number, the element in ‘input_x’ should be greater than or equal to 1.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape as <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">acosh</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Acosh</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">acosh</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Adam">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Adam</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#Adam"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Adam" title="Permalink to this definition"></a></dt>
<dd><p>Updates gradients by Adaptive Moment Estimation (Adam) algorithm.</p>
<p>The Adam algorithm is proposed in <a class="reference external" href="https://arxiv.org/abs/1412.6980">Adam: A Method for Stochastic Optimization</a>.</p>
<p>The updating formulas are as follows,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll} \\
    m = \beta_1 * m + (1 - \beta_1) * g \\
    v = \beta_2 * v + (1 - \beta_2) * g * g \\
    l = \alpha * \frac{\sqrt{1-\beta_2^t}}{1-\beta_1^t} \\
    w = w - l * \frac{m}{\sqrt{v} + \epsilon}
\end{array}\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(m\)</span> represents the 1st moment vector, <span class="math notranslate nohighlight">\(v\)</span> represents the 2nd moment vector, <span class="math notranslate nohighlight">\(g\)</span> represents
<cite>gradient</cite>, <span class="math notranslate nohighlight">\(l\)</span> represents scaling factor <cite>lr</cite>, <span class="math notranslate nohighlight">\(\beta_1, \beta_2\)</span> represent <cite>beta1</cite> and <cite>beta2</cite>,
<span class="math notranslate nohighlight">\(t\)</span> represents updating step while <span class="math notranslate nohighlight">\(beta_1^t\)</span> and <span class="math notranslate nohighlight">\(beta_2^t\)</span> represent <cite>beta1_power</cite> and
<cite>beta2_power</cite>, <span class="math notranslate nohighlight">\(\alpha\)</span> represents <cite>learning_rate</cite>, <span class="math notranslate nohighlight">\(w\)</span> represents <cite>var</cite>, <span class="math notranslate nohighlight">\(\epsilon\)</span> represents
<cite>epsilon</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>use_locking</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to enable a lock to protect updating variable tensors.
If True, updating of the var, m, and v tensors will be protected by a lock.
If False, the result is unpredictable. Default: False.</p></li>
<li><p><strong>use_nesterov</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to use Nesterov Accelerated Gradient (NAG) algorithm to update the gradients.
If True, updates the gradients using NAG.
If False, updates the gradients without using NAG. Default: False.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>var</strong> (Tensor) - Weights to be updated.</p></li>
<li><p><strong>m</strong> (Tensor) - The 1st moment vector in the updating formula.</p></li>
<li><p><strong>v</strong> (Tensor) - the 2nd moment vector in the updating formula.</p></li>
<li><p><strong>beta1_power</strong> (float) - <span class="math notranslate nohighlight">\(beta_1^t\)</span> in the updating formula.</p></li>
<li><p><strong>beta2_power</strong> (float) - <span class="math notranslate nohighlight">\(beta_2^t\)</span> in the updating formula.</p></li>
<li><p><strong>lr</strong> (float) - <span class="math notranslate nohighlight">\(l\)</span> in the updating formula.</p></li>
<li><p><strong>beta1</strong> (float) - The exponential decay rate for the 1st moment estimates.</p></li>
<li><p><strong>beta2</strong> (float) - The exponential decay rate for the 2nd moment estimates.</p></li>
<li><p><strong>epsilon</strong> (float) - Term added to the denominator to improve numerical stability.</p></li>
<li><p><strong>gradient</strong> (Tensor) - Gradients.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tuple of 3 Tensor, the updated parameters.</p>
<ul class="simple">
<li><p><strong>var</strong> (Tensor) - The same shape and data type as <cite>var</cite>.</p></li>
<li><p><strong>m</strong> (Tensor) - The same shape and data type as <cite>m</cite>.</p></li>
<li><p><strong>v</strong> (Tensor) - The same shape and data type as <cite>v</cite>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.AddN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">AddN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#AddN"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.AddN" title="Permalink to this definition"></a></dt>
<dd><p>Computes addition of all input tensors element-wise.</p>
<p>All input tensors should have the same shape.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union(tuple[Tensor], list[Tensor])) - The input tuple or list
is made up of multiple tensors whose dtype is number or bool to be added together.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape and dtype as each entry of the <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">NetAddN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">NetAddN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">addN</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">AddN</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">z</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">addN</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">NetAddN</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">,</span> <span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">Tensor([10, 14, 18], shape=(3,), dtype=mindspore.int32)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.AllGather">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">AllGather</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/comm_ops.html#AllGather"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.AllGather" title="Permalink to this definition"></a></dt>
<dd><p>Gathers tensors from the specified communication group.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Tensor must have the same shape and format in all processes participating in the collective.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The communication group to work on. Default: “hccl_world_group”.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If group is not a string.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the local rank id of the calling process in the group
    is larger than the group’s rank size.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor. If the number of devices in the group is N,
then the shape of output is <span class="math notranslate nohighlight">\((N, x_1, x_2, ..., x_R)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init</span><span class="p">(</span><span class="s1">&#39;nccl&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">allgather</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">AllGather</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="s2">&quot;nccl_world_group&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">allgather</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.AllReduce">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">AllReduce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/comm_ops.html#AllReduce"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.AllReduce" title="Permalink to this definition"></a></dt>
<dd><p>Reduces the tensor data across all devices in such a way that all devices will get the same final result.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The operation of AllReduce does not support “prod” currently.
Tensor must have same shape and format in all processes participating in the collective.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>op</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Specifies an operation used for element-wise reductions,
like sum, max, min. Default: ReduceOp.SUM.</p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The communication group to work on. Default: “hccl_world_group”.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If any of op and group is not a string
    or fusion is not a integer or the input’s dtype is bool.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If op is “prod”</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape of the input, i.e., <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.
The contents depend on the specified operation.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init</span><span class="p">(</span><span class="s1">&#39;nccl&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">allreduce_sum</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">AllReduce</span><span class="p">(</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s2">&quot;nccl_world_group&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">allreduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.ops.operations.AllReduce.vm_impl">
<span class="sig-name descname"><span class="pre">vm_impl</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/comm_ops.html#AllReduce.vm_impl"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.AllReduce.vm_impl" title="Permalink to this definition"></a></dt>
<dd><p>Implement by vm mode.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ApplyCenteredRMSProp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ApplyCenteredRMSProp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#ApplyCenteredRMSProp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ApplyCenteredRMSProp" title="Permalink to this definition"></a></dt>
<dd><p>Optimizer that implements the centered RMSProp algorithm.
Please refer to the usage in source code of <cite>nn.RMSProp</cite>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Update <cite>var</cite> according to the centered RMSProp algorithm.</p>
<div class="math notranslate nohighlight">
\[g_{t} = \rho g_{t-1} + (1 - \rho)\nabla Q_{i}(w)\]</div>
<div class="math notranslate nohighlight">
\[s_{t} = \rho s_{t-1} + (1 - \rho)(\nabla Q_{i}(w))^2\]</div>
<div class="math notranslate nohighlight">
\[m_{t} = \beta m_{t-1} + \frac{\eta} {\sqrt{s_{t} - g_{t}^2 + \epsilon}} \nabla Q_{i}(w)\]</div>
<div class="math notranslate nohighlight">
\[w = w - m_{t}\]</div>
<p>where, <span class="math notranslate nohighlight">\(w\)</span> represents <cite>var</cite>, which will be updated.
<span class="math notranslate nohighlight">\(g_{t}\)</span> represents <cite>mean_gradient</cite>, <span class="math notranslate nohighlight">\(g_{t-1}\)</span> is the last momentent of <span class="math notranslate nohighlight">\(g_{t}\)</span>.
<span class="math notranslate nohighlight">\(s_{t}\)</span> represents <cite>mean_square</cite>, <span class="math notranslate nohighlight">\(s_{t-1}\)</span> is the last momentent of <span class="math notranslate nohighlight">\(s_{t}\)</span>,
<span class="math notranslate nohighlight">\(m_{t}\)</span> represents <cite>moment</cite>, <span class="math notranslate nohighlight">\(m_{t-1}\)</span> is the last momentent of <span class="math notranslate nohighlight">\(m_{t}\)</span>.
<span class="math notranslate nohighlight">\(\rho\)</span> represents <cite>decay</cite>. <span class="math notranslate nohighlight">\(\beta\)</span> is the momentum term, represents <cite>momentum</cite>.
<span class="math notranslate nohighlight">\(\epsilon\)</span> is a smoothing term to avoid division by zero, represents <cite>epsilon</cite>.
<span class="math notranslate nohighlight">\(\eta\)</span> represents <cite>learning_rate</cite>. <span class="math notranslate nohighlight">\(\nabla Q_{i}(w)\)</span> represents <cite>grad</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>use_locking</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Enable a lock to protect the update of variable tensors. Default: False.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>var</strong> (Tensor) - Weights to be update.</p></li>
<li><p><strong>mean_gradient</strong> (Tensor) - Mean gradients, must have the same type as <cite>var</cite>.</p></li>
<li><p><strong>mean_square</strong> (Tensor) - Mean square gradients, must have the same type as <cite>var</cite>.</p></li>
<li><p><strong>moment</strong> (Tensor) - Delta of <cite>var</cite>, must have the same type as <cite>var</cite>.</p></li>
<li><p><strong>grad</strong> (Tensor) - Gradients, must have the same type as <cite>var</cite>.</p></li>
<li><p><strong>learning_rate</strong> (Union[Number, Tensor]) - Learning rate.</p></li>
<li><p><strong>decay</strong> (float) - Decay rate.</p></li>
<li><p><strong>momentum</strong> (float) - Momentum.</p></li>
<li><p><strong>epsilon</strong> (float) - Ridge term.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, parameters to be update.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ApplyFtrl">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ApplyFtrl</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#ApplyFtrl"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ApplyFtrl" title="Permalink to this definition"></a></dt>
<dd><p>Update relevant entries according to the FTRL scheme.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>use_locking</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Use locks for update operation if True . Default: False.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>var</strong> (Tensor): The variable to be updated.</p></li>
<li><p><strong>accum</strong> (Tensor): The accum to be updated, must be same type and shape as <cite>var</cite>.</p></li>
<li><p><strong>linear</strong> (Tensor): The linear to be updated, must be same type and shape as <cite>var</cite>.</p></li>
<li><p><strong>grad</strong> (Tensor): Gradient.</p></li>
<li><p><strong>lr</strong> (Union[Number, Tensor]): The learning rate value, must be positive. Default: 0.001.</p></li>
<li><p><strong>l1</strong> (Union[Number, Tensor]): l1 regularization strength, must be greater than or equal to zero.
Default: 0.0.</p></li>
<li><p><strong>l2</strong> (Union[Number, Tensor]): l2 regularization strength, must be greater than or equal to zero.
Default: 0.0.</p></li>
<li><p><strong>lr_power</strong> (Union[Number, Tensor]): Learning rate power controls how the learning rate decreases
during training, must be less than or equal to zero. Use fixed learning rate if lr_power is zero.
Default: -0.5.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, representing the updated var.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ApplyMomentum">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ApplyMomentum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#ApplyMomentum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ApplyMomentum" title="Permalink to this definition"></a></dt>
<dd><p>Optimizer that implements the Momentum algorithm.</p>
<p>Refer to the paper <a class="reference external" href="https://dl.acm.org/doi/10.5555/3042817.3043064">On the importance of initialization and momentum in deep
learning</a>  for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>use_locking</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Enable a lock to protect the update of variable and accumlation tensors. Default: False.</p></li>
<li><p><strong>use_nesterov</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Enable Nesterov momentum. Default: False.</p></li>
<li><p><strong>gradient_scale</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The scale of the gradient. Default: 1.0.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>variable</strong> (Tensor) - Weights to be updated.</p></li>
<li><p><strong>accumulation</strong> (Tensor) - Accumulated gradient value by moment weight.</p></li>
<li><p><strong>learning_rate</strong> (float) - Learning rate.</p></li>
<li><p><strong>gradient</strong> (Tensor) - Gradients.</p></li>
<li><p><strong>momentum</strong> (float) - Momentum.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, parameters to be updated.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Please refer to the usage in nn.ApplyMomentum.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ApplyRMSProp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ApplyRMSProp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#ApplyRMSProp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ApplyRMSProp" title="Permalink to this definition"></a></dt>
<dd><p>Optimizer that implements the Root Mean Square prop(RMSProp) algorithm.
Please refer to the usage in source code of <cite>nn.RMSProp</cite>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Update <cite>var</cite> according to the RMSProp algorithm.</p>
<div class="math notranslate nohighlight">
\[s_{t} = \rho s_{t-1} + (1 - \rho)(\nabla Q_{i}(w))^2\]</div>
<div class="math notranslate nohighlight">
\[m_{t} = \beta m_{t-1} + \frac{\eta} {\sqrt{s_{t} + \epsilon}} \nabla Q_{i}(w)\]</div>
<div class="math notranslate nohighlight">
\[w = w - m_{t}\]</div>
<p>where, <span class="math notranslate nohighlight">\(w\)</span> represents <cite>var</cite>, which will be updated.
<span class="math notranslate nohighlight">\(s_{t}\)</span> represents <cite>mean_square</cite>, <span class="math notranslate nohighlight">\(s_{t-1}\)</span> is the last momentent of <span class="math notranslate nohighlight">\(s_{t}\)</span>,
<span class="math notranslate nohighlight">\(m_{t}\)</span> represents <cite>moment</cite>, <span class="math notranslate nohighlight">\(m_{t-1}\)</span> is the last momentent of <span class="math notranslate nohighlight">\(m_{t}\)</span>.
<span class="math notranslate nohighlight">\(\rho\)</span> represents <cite>decay</cite>. <span class="math notranslate nohighlight">\(\beta\)</span> is the momentum term, represents <cite>momentum</cite>.
<span class="math notranslate nohighlight">\(\epsilon\)</span> is a smoothing term to avoid division by zero, represents <cite>epsilon</cite>.
<span class="math notranslate nohighlight">\(\eta\)</span> represents <cite>learning_rate</cite>. <span class="math notranslate nohighlight">\(\nabla Q_{i}(w)\)</span> represents <cite>grad</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>use_locking</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Enable a lock to protect the update of variable tensors. Default: False.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>var</strong> (Tensor) - Weights to be update.</p></li>
<li><p><strong>mean_square</strong> (Tensor) - Mean square gradients, must have the same type as <cite>var</cite>.</p></li>
<li><p><strong>moment</strong> (Tensor) - Delta of <cite>var</cite>, must have the same type as <cite>var</cite>.</p></li>
<li><p><strong>grad</strong> (Tensor) - Gradients, must have the same type as <cite>var</cite>.</p></li>
<li><p><strong>learning_rate</strong> (Union[Number, Tensor]) - Learning rate.</p></li>
<li><p><strong>decay</strong> (float) - Decay rate.</p></li>
<li><p><strong>momentum</strong> (float) - Momentum.</p></li>
<li><p><strong>epsilon</strong> (float) - Ridge term.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, parameters to be update.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ArgMaxWithValue">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ArgMaxWithValue</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#ArgMaxWithValue"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ArgMaxWithValue" title="Permalink to this definition"></a></dt>
<dd><p>Calculates maximum value with corresponding index.</p>
<p>Calculates maximum value along with given axis for the input tensor. Returns the maximum values and indices.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In auto_parallel and semi_auto_parallel mode, the first output index can not be used.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The dimension to reduce. Default: 0.</p></li>
<li><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to reduce dimension, if true the output will keep same dimension with the input,
the output will reduce dimension if false. Default: False.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor, can be any dimension. Set the shape of input tensor as
<span class="math notranslate nohighlight">\((x_1, x_2, ..., x_N)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, corresponding index and maximum value of input tensor. If <cite>keep_dims</cite> is true, the output tensors shape
is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_{axis-1}, 1, x_{axis+1}, ..., x_N)\)</span>. Else, the shape is
<span class="math notranslate nohighlight">\((x_1, x_2, ..., x_{axis-1}, x_{axis+1}, ..., x_N)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">index</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ArgMaxWithValue</span><span class="p">()(</span><span class="n">input_x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ArgMinWithValue">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ArgMinWithValue</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#ArgMinWithValue"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ArgMinWithValue" title="Permalink to this definition"></a></dt>
<dd><p>Calculates minimum value with corresponding index, return indices and values.</p>
<p>Calculates minimum value along with given axis for the input tensor. Returns the minimum values and indices.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In auto_parallel and semi_auto_parallel mode, the first output index can not be used.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The dimension to reduce. Default: 0.</p></li>
<li><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to reduce dimension, if true the output will keep same dimension as the input,
the output will reduce dimension if false. Default: False.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor, can be any dimension. Set the shape of input tensor as
<span class="math notranslate nohighlight">\((x_1, x_2, ..., x_N)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, corresponding index and minimum value of input tensor. If <cite>keep_dims</cite> is true, the output tensors shape
is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_{axis-1}, 1, x_{axis+1}, ..., x_N)\)</span>. Else, the shape is
<span class="math notranslate nohighlight">\((x_1, x_2, ..., x_{axis-1}, x_{axis+1}, ..., x_N)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">index</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ArgMinWithValue</span><span class="p">()(</span><span class="n">input_x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Argmax">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Argmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Argmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Argmax" title="Permalink to this definition"></a></dt>
<dd><p>Returns the indices of the max value of a tensor across the axis.</p>
<p>If the shape of input tensor is <span class="math notranslate nohighlight">\((x_1, ..., x_N)\)</span>, the output tensor shape is
<span class="math notranslate nohighlight">\((x_1, ..., x_{axis-1}, x_{axis+1}, ..., x_N)\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Axis on which Argmax operation applies. Default: -1.</p></li>
<li><p><strong>output_type</strong> (<a class="reference internal" href="mindspore.dtype.html#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – An optional data type of <cite>mindspore.dtype.int32</cite> and
<cite>mindspore.dtype.int64</cite>. Default: <cite>mindspore.dtype.int64</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - Input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, indices of the max value of input tensor across the axis.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">index</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Argmax</span><span class="p">(</span><span class="n">output_type</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)(</span><span class="n">input_x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Argmin">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Argmin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Argmin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Argmin" title="Permalink to this definition"></a></dt>
<dd><p>Returns the indices of the min value of a tensor across the axis.</p>
<p>If the shape of input tensor is <span class="math notranslate nohighlight">\((x_1, ..., x_N)\)</span>, the output tensor shape is
<span class="math notranslate nohighlight">\((x_1, ..., x_{axis-1}, x_{axis+1}, ..., x_N)\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Axis on which Argmin operation applies. Default: -1.</p></li>
<li><p><strong>output_type</strong> (<a class="reference internal" href="mindspore.dtype.html#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – An optional data type from: <cite>mindspore.dtype.int32</cite>,
<cite>mindspore.dtype.int64</cite>. Default: <cite>mindspore.dtype.int64</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - Input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, indices of the min value of input tensor across the axis.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">index</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Argmin</span><span class="p">()(</span><span class="n">input_x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">index</span> <span class="o">==</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Assign">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Assign</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/other_ops.html#Assign"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Assign" title="Permalink to this definition"></a></dt>
<dd><p>Assign <cite>Parameter</cite> with a value.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>variable</strong> (Parameter) - The <cite>Parameter</cite>.</p></li>
<li><p><strong>value</strong> (Tensor) - The value to assign.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same type as original <cite>variable</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">P</span><span class="o">.</span><span class="n">Assign</span><span class="p">()(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">x</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.AssignAdd">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">AssignAdd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#AssignAdd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.AssignAdd" title="Permalink to this definition"></a></dt>
<dd><p>Updates a <cite>Parameter</cite> by adding a value to it.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>variable</strong> (Parameter) - The <cite>Parameter</cite>.</p></li>
<li><p><strong>value</strong> (Union[numbers.Number, Tensor]) - The value to be added to the <cite>variable</cite>.
It should have the same shape as <cite>variable</cite> if it is a Tensor.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">AssignAdd</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">AssignAdd</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">variable</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;global_step&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">AssignAdd</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">variable</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">variable</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.AssignSub">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">AssignSub</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#AssignSub"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.AssignSub" title="Permalink to this definition"></a></dt>
<dd><p>Updates a <cite>Parameter</cite> by subtracting a value from it.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>variable</strong> (Parameter) - The <cite>Parameter</cite>.</p></li>
<li><p><strong>value</strong> (Union[numbers.Number, Tensor]) - The value to be subtracted from the <cite>variable</cite>.
It should have the same shape as <cite>variable</cite> if it is a Tensor.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">AssignSub</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">AssignSub</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">variable</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;global_step&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">AssignSub</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">variable</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">variable</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Atan2">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Atan2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Atan2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Atan2" title="Permalink to this definition"></a></dt>
<dd><p>Returns arctangent of input_x/input_y element-wise.</p>
<p>It returns <span class="math notranslate nohighlight">\(\theta\ \in\ (-\frac{\pi}{2}, \frac{\pi}{2})\)</span>
such that <span class="math notranslate nohighlight">\(x = r*\sin(\theta), y = r*\cos(\theta)\)</span>, where <span class="math notranslate nohighlight">\(r = \sqrt{x^2 + y^2}\)</span>.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
<li><p><strong>input_y</strong> (Tensor) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is same as <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">atan2</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Atan2</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">atan2</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[[0. 0.7853982]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.AvgPool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">AvgPool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#AvgPool"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.AvgPool" title="Permalink to this definition"></a></dt>
<dd><p>Average pooling operation.</p>
<p>Applies a 2D average pooling over an input Tensor which can be regarded as a composition of 2D input planes.
Typically the input is of shape <span class="math notranslate nohighlight">\((N_{in}, C_{in}, H_{in}, W_{in})\)</span>, AvgPool2d outputs
regional average in the <span class="math notranslate nohighlight">\((H_{in}, W_{in})\)</span>-dimension. Given kernel size
<span class="math notranslate nohighlight">\(ks = (h_{ker}, w_{ker})\)</span> and stride <span class="math notranslate nohighlight">\(s = (s_0, s_1)\)</span>, the operation is as follows.</p>
<div class="math notranslate nohighlight">
\[\text{output}(N_i, C_j, h, w) = \frac{1}{h_{ker} * w_{ker}} \sum_{m=0}^{h_{ker}-1} \sum_{n=0}^{w_{ker}-1}
\text{input}(N_i, C_j, s_0 \times h + m, s_1 \times w + n)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ksize</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The size of kernel used to take the average value,
is an int number that represents height and width are both ksize, or a tuple
of two int numbers that represent height and width respectively. Default: 1.</p></li>
<li><p><strong>strides</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The distance of kernel moving, an int number that represents
the height and width of movement are both strides, or a tuple of two int numbers that
represent height and width of movement respectively. Default: 1.</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>The optional values for pad mode, is “same” or “valid”, not case sensitive.
Default: “valid”.</p>
<ul>
<li><p>same: Adopts the way of completion. Output height and width will be the same as
the input. Total number of padding will be calculated for horizontal and vertical
direction and evenly distributed to top and bottom, left and right if possible.
Otherwise, the last extra padding will be done from the bottom and the right side.</p></li>
<li><p>valid: Adopts the way of discarding. The possibly largest height and width of output
will be return without padding. Extra pixels will be discarded.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, C_{in}, H_{in}, W_{in})\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with shape <span class="math notranslate nohighlight">\((N, C_{out}, H_{out}, W_{out})\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.BatchMatMul">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">BatchMatMul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#BatchMatMul"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.BatchMatMul" title="Permalink to this definition"></a></dt>
<dd><p>Computes matrix multiplication between two tensors by batch</p>
<p><cite>result[…, :, :] = tensor(a[…, :, :]) * tensor(b[…, :, :])</cite>.</p>
<p>The two input tensors must have same rank and the rank must be <cite>3</cite> at least.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>transpose_a</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, <cite>a</cite> is transposed on the last two dimensions before multiplication.
Default: False.</p></li>
<li><p><strong>transpose_b</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, <cite>b</cite> is transposed on the last two dimensions before multiplication.
Default: False.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The first tensor to be multiplied. The shape of the tensor is <span class="math notranslate nohighlight">\((*B, N, C)\)</span>,
where <span class="math notranslate nohighlight">\(*B\)</span> represents the batch size which can be multidimensional, <span class="math notranslate nohighlight">\(N\)</span> and <span class="math notranslate nohighlight">\(C\)</span> are the
size of the last two dimensions. If <cite>transpose_a</cite> is True, its shape should be <span class="math notranslate nohighlight">\((*B, C, N)\)</span>.</p></li>
<li><p><strong>input_y</strong> (Tensor) - The second tensor to be multiplied. The shape of the tensor is <span class="math notranslate nohighlight">\((*B, C, M)\)</span>. If
<cite>transpose_b</cite> is True, its shape should be <span class="math notranslate nohighlight">\((*B, M, C)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape of the output tensor is <span class="math notranslate nohighlight">\((*B, N, M)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batmatmul</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">BatchMatMul</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">batmatmul</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batmatmul</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">BatchMatMul</span><span class="p">(</span><span class="n">transpose_a</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">batmatmul</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.BatchNorm">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">BatchNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#BatchNorm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.BatchNorm" title="Permalink to this definition"></a></dt>
<dd><p>Batch Normalization for input data and updated parameters.</p>
<p>Batch Normalization is widely used in convolutional neural networks. This operation
applies Batch Normalization over input to avoid internal covariate shift as described
in the paper <a class="reference external" href="https://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal
Covariate Shift</a>. It rescales and recenters the
features using a mini-batch of data and the learned parameters which can be described
in the following formula,</p>
<div class="math notranslate nohighlight">
\[y = \frac{x - mean}{\sqrt{variance + \epsilon}} * \gamma + \beta\]</div>
<p>where <span class="math notranslate nohighlight">\(\gamma\)</span> is scale, <span class="math notranslate nohighlight">\(\beta\)</span> is bias, <span class="math notranslate nohighlight">\(\epsilon\)</span> is epsilon.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>is_training</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If <cite>is_training</cite> is True, <cite>mean</cite> and <cite>variance</cite> are computed during training.
If <cite>is_training</cite> is False, they’re loaded from checkpoint during inference. Default: False.</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – A small value added for numerical stability. Default: 1e-5.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, C)\)</span>.</p></li>
<li><p><strong>scale</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>bias</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>mean</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>variance</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tuple of 5 Tensor, the normalized inputs and the updated parameters.</p>
<ul class="simple">
<li><p><strong>output_x</strong> (Tensor) - The same type and shape as the input_x. The shape is <span class="math notranslate nohighlight">\((N, C)\)</span>.</p></li>
<li><p><strong>updated_scale</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>updated_bias</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>reserve_space_1</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>reserve_space_2</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>reserve_space_3</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.BatchNormFold">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">BatchNormFold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/_quant_ops.html#BatchNormFold"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.BatchNormFold" title="Permalink to this definition"></a></dt>
<dd><p>Batch normalization folded.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>momentum</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Momentum value should be [0, 1]. Default: 0.1.</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – A small float number to avoid dividing by 0. 1e-12 if dtype in
float32 else 1e-3. Default: 1e-12.</p></li>
<li><p><strong>is_training</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – In training mode set True, else set False. Default: True.</p></li>
<li><p><strong>freeze_bn</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Delay in steps at which computation switches from regular batch
norm to frozen mean and std. Default: 0.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>x</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, C)\)</span>.</p></li>
<li><p><strong>mean</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>variance</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>global_step</strong> (Tensor) - Tensor to record current global step.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tuple of 4 Tensor, the normalized input and the updated parameters.</p>
<ul class="simple">
<li><p><strong>batch_mean</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>batch_std</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>running_mean</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>running_std</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.BatchNormFold2">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">BatchNormFold2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/_quant_ops.html#BatchNormFold2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.BatchNormFold2" title="Permalink to this definition"></a></dt>
<dd><p>Scale the bias with a correction factor to the long term statistics
prior to quantization. This ensures that there is no jitter in the quantized bias
due to batch to batch variation.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>x</strong> (Tensor)  - Tensor of shape <span class="math notranslate nohighlight">\((N, C)\)</span>.</p></li>
<li><p><strong>beta</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>gamma</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>batch_std</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>batch_mean</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>running_std</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>running_mean</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>global_step</strong> (Tensor) - Tensor to record current global step.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><ul class="simple">
<li><p><strong>y</strong> (Tensor) - Tensor has the same shape as x.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.BatchNormFold2Grad">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">BatchNormFold2Grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/_quant_ops.html#BatchNormFold2Grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.BatchNormFold2Grad" title="Permalink to this definition"></a></dt>
<dd><p>Performs grad of CorrectionAddGrad operation.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.BatchNormFoldGrad">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">BatchNormFoldGrad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/_quant_ops.html#BatchNormFoldGrad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.BatchNormFoldGrad" title="Permalink to this definition"></a></dt>
<dd><p>Performs grad of BatchNormFold operation.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.BatchToSpace">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">BatchToSpace</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#BatchToSpace"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.BatchToSpace" title="Permalink to this definition"></a></dt>
<dd><p>Divide batch dimension with blocks and interleaves these blocks back into spatial dimensions.</p>
<p>This operation will divide batch dimension N into blocks with block_size, the output tensor’s N dimension
is the corresponding number of blocks after division. The output tensor’s H, W dimension is product of original H, W
dimension and block_size with given amount to crop from dimension, respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>block_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The block size of dividing block with value &gt;= 1.</p></li>
<li><p><strong>crops</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – The crop value for H and W dimension, containing 2 sub list, each containing 2 int value.
All values must be &gt;= 0. crops[i] specifies the crop values for spatial dimension i, which corresponds to
input dimension i+2. It is required that input_shape[i+2]*block_size &gt;= crops[i][0]+crops[i][1].</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the output tensor with the same type as input. Assume input shape is (n, c, h, w) with block_size
and crops. The output shape will be (n’, c’, h’, w’), where</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(n' = n//(block\_size*block\_size)\)</span></p>
<p><span class="math notranslate nohighlight">\(c' = c\)</span></p>
<p><span class="math notranslate nohighlight">\(h' = h*block\_size-crops[0][0]-crops[0][1]\)</span></p>
<p><span class="math notranslate nohighlight">\(w' = w*block\_size-crops[1][0]-crops[1][1]\)</span></p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">block_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">crops</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">BatchToSpace</span><span class="p">(</span><span class="n">block_size</span><span class="p">,</span> <span class="n">crops</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mi">1</span><span class="p">]]],</span> <span class="p">[[[</span><span class="mi">2</span><span class="p">]]],</span> <span class="p">[[[</span><span class="mi">3</span><span class="p">]]],</span> <span class="p">[[[</span><span class="mi">4</span><span class="p">]]]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">[[[[1., 2.], [3., 4.]]]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.BiasAdd">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">BiasAdd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#BiasAdd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.BiasAdd" title="Permalink to this definition"></a></dt>
<dd><p>Returns sum of input and bias tensor.</p>
<p>Adds the 1-D bias tensor to the input tensor, and boardcasts the shape on all axis
except for the channel axis.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - Input value, with shape <span class="math notranslate nohighlight">\((N, C)\)</span> or <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>bias</strong> (Tensor) - Bias value, with shape <span class="math notranslate nohighlight">\((C)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with the same shape and type as <cite>input_x</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.BinaryCrossEntropy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">BinaryCrossEntropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#BinaryCrossEntropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.BinaryCrossEntropy" title="Permalink to this definition"></a></dt>
<dd><p>Computes the Binary Cross Entropy between the target and the output.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Sets input as <span class="math notranslate nohighlight">\(x\)</span>, input label as <span class="math notranslate nohighlight">\(y\)</span>, output as <span class="math notranslate nohighlight">\(\ell(x, y)\)</span>.
Let,</p>
<div class="math notranslate nohighlight">
\[L = \{l_1,\dots,l_N\}^\top, \quad
l_n = - w_n \left[ y_n \cdot \log x_n + (1 - y_n) \cdot \log (1 - x_n) \right]\]</div>
<p>Then,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\ell(x, y) = \begin{cases}
L, &amp; \text{if reduction} = \text{'none';}\\
\operatorname{mean}(L), &amp; \text{if reduction} = \text{'mean';}\\
\operatorname{sum}(L),  &amp; \text{if reduction} = \text{'sum'.}
\end{cases}\end{split}\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>reduction</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Specifies the reduction to apply to the output.
Its value should be one of ‘none’, ‘mean’, ‘sum’. Default: ‘mean’.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input Tensor.</p></li>
<li><p><strong>input_y</strong> (Tensor) - The label Tensor which has same shape as <cite>input_x</cite>.</p></li>
<li><p><strong>weight</strong> (Tensor, optional) - A rescaling weight applied to the loss of each batch element.
And it should have same shape as <cite>input_x</cite>. Default: None.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor or Scalar, if <cite>reduction</cite> is ‘none’, then output is a tensor and same shape as <cite>input_x</cite>.
Otherwise it is a scalar.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.BoundingBoxDecode">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">BoundingBoxDecode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/other_ops.html#BoundingBoxDecode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.BoundingBoxDecode" title="Permalink to this definition"></a></dt>
<dd><p>Decode bounding boxes locations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>means</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – The means of deltas calculation. Default: (0.0, 0.0, 0.0, 0.0).</p></li>
<li><p><strong>stds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – The standard deviations of deltas calculation. Default: (1.0, 1.0, 1.0, 1.0).</p></li>
<li><p><strong>max_shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – The max size limit for decoding box calculation.</p></li>
<li><p><strong>wh_ratio_clip</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The limit of width and height ratio for decoding box calculation. Default: 0.016.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>anchor_box</strong> (Tensor) - Anchor boxes.</p></li>
<li><p><strong>deltas</strong> (Tensor) - Delta of boxes.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, decoded boxes.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">boundingbox_decode</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">BoundingBoxDecode</span><span class="p">(</span><span class="n">means</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span> <span class="n">stds</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span>                                         <span class="n">max_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">768</span><span class="p">,</span> <span class="mi">1280</span><span class="p">),</span> <span class="n">wh_ratio_clip</span><span class="o">=</span><span class="mf">0.016</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bbox</span> <span class="o">=</span> <span class="n">boundingbox_decode</span><span class="p">(</span><span class="n">anchor_box</span><span class="p">,</span> <span class="n">deltas</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.BoundingBoxEncode">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">BoundingBoxEncode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/other_ops.html#BoundingBoxEncode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.BoundingBoxEncode" title="Permalink to this definition"></a></dt>
<dd><p>Encode bounding boxes locations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>means</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Means for encoding bounding boxes calculation. Default: (0.0, 0.0, 0.0, 0.0).</p></li>
<li><p><strong>stds</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Stds for encoding bounding boxes calculation. Default: (1.0, 1.0, 1.0, 1.0).</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>anchor_box</strong> (Tensor) - Anchor boxes.</p></li>
<li><p><strong>groundtruth_box</strong> (Tensor) - Ground truth boxes.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, encoded bounding boxes.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">boundingbox_encode</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">BoundingBoxEncode</span><span class="p">(</span><span class="n">means</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span> <span class="n">stds</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">delta_box</span> <span class="o">=</span> <span class="n">boundingbox_encode</span><span class="p">(</span><span class="n">anchor_box</span><span class="p">,</span> <span class="n">groundtruth_box</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Broadcast">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Broadcast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/comm_ops.html#Broadcast"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Broadcast" title="Permalink to this definition"></a></dt>
<dd><p>Broadcasts the tensor to the whole group.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Tensor must have the same shape and format in all processes participating in the collective.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root_rank</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Source rank. Required in all processes except the one
that is sending the data.</p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The communication group to work on. Default: “hccl_world_group”.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape of the input, i.e., <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.
The contents depend on the data of the <cite>root_rank</cite> device.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If root_rank is not a integer or group is not a string.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init</span><span class="p">(</span><span class="s1">&#39;nccl&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">broadcast</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Broadcast</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">broadcast</span><span class="p">((</span><span class="n">x</span><span class="p">,))</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Cast">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Cast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Cast"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Cast" title="Permalink to this definition"></a></dt>
<dd><p>Returns a tensor with the new specified data type.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, Number]) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.
The tensor to be casted.</p></li>
<li><p><strong>type</strong> (dtype.Number) - The valid data type of the output tensor. Only constant value is allowed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>, same as <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">input_np</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">type_dst</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cast</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Cast</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">type_dst</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.CheckValid">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">CheckValid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/other_ops.html#CheckValid"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.CheckValid" title="Permalink to this definition"></a></dt>
<dd><p>Check bounding box.</p>
<p>Check whether the bounding box cross data and data border.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>bboxes</strong> (Tensor) - Bounding boxes tensor with shape (N, 4).</p></li>
<li><p><strong>img_metas</strong> (Tensor) - Raw image size information, format (height, width, ratio).</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the valided tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Concat">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Concat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Concat"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Concat" title="Permalink to this definition"></a></dt>
<dd><p>Concat tensor in specified axis.</p>
<p>Concat input tensors along with the given axis.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The input data is a tuple of tensors. These tensors have the same rank <cite>R</cite>. Set the given axis as <cite>m</cite>, and
<span class="math notranslate nohighlight">\(0 \le m &lt; N\)</span>. Set the number of input tensors as <cite>N</cite>. For the <span class="math notranslate nohighlight">\(i\)</span>-th tensor <span class="math notranslate nohighlight">\(t_i\)</span> has
the shape <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_{mi}, ..., x_R)\)</span>. <span class="math notranslate nohighlight">\(x_{mi}\)</span> is the <span class="math notranslate nohighlight">\(m\)</span>-th dimension of the
<span class="math notranslate nohighlight">\(i\)</span>-th tensor. Then, the output tensor shape is</p>
<div class="math notranslate nohighlight">
\[(x_1, x_2, ..., \sum_{i=1}^Nx_{mi}, ..., x_R)\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The specified axis. Default: 0.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (tuple, list) - Tuple or list of input tensors.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is <span class="math notranslate nohighlight">\((x_1, x_2, ..., \sum_{i=1}^Nx_{mi}, ..., x_R)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data1</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data2</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Concat</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">((</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ConfusionMulGrad">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ConfusionMulGrad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#ConfusionMulGrad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ConfusionMulGrad" title="Permalink to this definition"></a></dt>
<dd><p><cite>output0</cite> is the result of which input0 dot multily input1.</p>
<p><cite>output1</cite> is the result of which input0 dot multily input1, then reducesum it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The dimensions to reduce.
Default:(), reduce all dimensions. Only constant value is allowed.</p></li>
<li><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – <ul>
<li><p>If true, keep these reduced dimensions and the length is 1.</p></li>
<li><p>If false, don’t keep these dimensions. Default:False.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_0</strong> (Tensor) - The input Tensor.</p></li>
<li><p><strong>input_1</strong> (Tensor) - The input Tensor.</p></li>
<li><p><strong>input_2</strong> (Tensor) - The input Tensor.</p></li>
</ul>
</dd>
<dt>outputs:</dt><dd><ul>
<li><p><strong>output_0</strong> (Tensor) - The same shape with <cite>input0</cite>.</p></li>
<li><p><strong>output_1</strong> (Tensor)</p>
<blockquote>
<div><ul class="simple">
<li><p>If axis is (), and keep_dims is false, the output is a 0-D array representing
the sum of all elements in the input array.</p></li>
<li><p>If axis is int, set as 2, and keep_dims is false,
the shape of output is <span class="math notranslate nohighlight">\((x_1,x_3,...,x_R)\)</span>.</p></li>
<li><p>If axis is tuple(int), set as (2,3), and keep_dims is false,
the shape of output is <span class="math notranslate nohighlight">\((x_1,x_4,...x_R)\)</span>.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ControlDepend">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ControlDepend</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/control_ops.html#ControlDepend"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ControlDepend" title="Permalink to this definition"></a></dt>
<dd><p>Adds control dependency relation between source and destination operation.</p>
<p>In many cases, we need to control the execution order of operations. ControlDepend is designed for this.
ControlDepend will indicate the execution engine to run the operations in specific order. ControlDepend
tells the engine that the destination operations should depend on the source operation which means the source
operations should be executed before the destination.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>depend_mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Use 0 for normal depend, 1 for depend on operations that used the parameter. Default: 0.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>src</strong> (Any) - The source input. It can be a tuple of operations output or a single operation output. We do
not concern about the input data, but concern about the operation that generates the input data.
If <cite>depend_mode = 1</cite> is specified and the source input is parameter, we will try to find the operations that
used the parameter as input.</p></li>
<li><p><strong>dst</strong> (Any) - The destination input. It can be a tuple of operations output or a single operation output.
We do not concern about the input data, but concern about the operation that generates the input data.
If <cite>depend_mode = 1</cite> is specified and the source input is parameter, we will try to find the operations that
used the parameter as input.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Bool. This operation has no actual data output, it will be used to setup the order of relative operations.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># In the following example, the data calculation uses original global_step. After the calculation the global</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># step should be increased, so the add operation should depend on the data calculation operation.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">control_depend</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ControlDepend</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">mul</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">softmax</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">control_depend</span><span class="p">(</span><span class="n">mul</span><span class="p">,</span> <span class="n">softmax</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">ret</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Conv2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Conv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#Conv2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Conv2D" title="Permalink to this definition"></a></dt>
<dd><p>2D convolution layer.</p>
<p>Applies a 2D convolution over an input tensor which is typically of shape <span class="math notranslate nohighlight">\((N, C_{in}, H_{in}, W_{in})\)</span>,
where <span class="math notranslate nohighlight">\(N\)</span> is batch size and <span class="math notranslate nohighlight">\(C_{in}\)</span> is channel number. For each batch of shape
<span class="math notranslate nohighlight">\((C_{in}, H_{in}, W_{in})\)</span>, the formula is defined as:</p>
<div class="math notranslate nohighlight">
\[out_j = \sum_{i=0}^{C_{in} - 1} ccor(W_{ij}, X_i) + b_j,\]</div>
<p>where <span class="math notranslate nohighlight">\(ccor\)</span> is cross correlation operator, <span class="math notranslate nohighlight">\(C_{in}\)</span> is the input channel number, <span class="math notranslate nohighlight">\(j\)</span> ranges
from <span class="math notranslate nohighlight">\(0\)</span> to <span class="math notranslate nohighlight">\(C_{out} - 1\)</span>, <span class="math notranslate nohighlight">\(W_{ij}\)</span> corresponds to <span class="math notranslate nohighlight">\(i\)</span>-th channel of the <span class="math notranslate nohighlight">\(j\)</span>-th
filter and <span class="math notranslate nohighlight">\(out_{j}\)</span> corresponds to the <span class="math notranslate nohighlight">\(j\)</span>-th channel of the output. <span class="math notranslate nohighlight">\(W_{ij}\)</span> is a slice
of kernel and it has shape <span class="math notranslate nohighlight">\((\text{ks_h}, \text{ks_w})\)</span>, where <span class="math notranslate nohighlight">\(\text{ks_h}\)</span> and
<span class="math notranslate nohighlight">\(\text{ks_w}\)</span> are height and width of the convolution kernel. The full kernel has shape
<span class="math notranslate nohighlight">\((C_{out}, C_{in} // \text{group}, \text{ks_h}, \text{ks_w})\)</span>, where group is the group number
to split the input in the channel dimension.</p>
<p>If the ‘pad_mode’ is set to be “valid”, the output height and width will be
<span class="math notranslate nohighlight">\(\left \lfloor{1 + \frac{H_{in} + 2 \times \text{padding} - \text{ks_h} -
(\text{ks_h} - 1) \times (\text{dilation} - 1) }{\text{stride}}} \right \rfloor\)</span> and
<span class="math notranslate nohighlight">\(\left \lfloor{1 + \frac{W_{in} + 2 \times \text{padding} - \text{ks_w} -
(\text{ks_w} - 1) \times (\text{dilation} - 1) }{\text{stride}}} \right \rfloor\)</span> respectively.</p>
<p>The first introduction can be found in paper <a class="reference external" href="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf">Gradient Based Learning Applied to Document Recognition</a>. More detailed introduction can be found here:
<a class="reference external" href="http://cs231n.github.io/convolutional-networks/">http://cs231n.github.io/convolutional-networks/</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>out_channel</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The dimension of the output.</p></li>
<li><p><strong>kernel_size</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The kernel size of the 2D convolution.</p></li>
<li><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – 0 Math convolutiuon, 1 cross-correlation convolution ,
2 deconvolution, 3 depthwise convolution. Default: 1.</p></li>
<li><p><strong>pad_mode</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – “valid”, “same”, “pad” the mode to fill padding. Default: “valid”.</p></li>
<li><p><strong>pad</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The pad value to fill. Default: 0.</p></li>
<li><p><strong>stride</strong> (<em>Union</em><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>)</em>) – The stride to apply conv filter. Default: 1.</p></li>
<li><p><strong>dilation</strong> (<em>Union</em><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>)</em>) – Specify the space to use between kernel elements. Default: 1.</p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Split input into groups. Default: 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, the value that applied 2D convolution.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, C_{in}, H_{in}, W_{in})\)</span>.</p></li>
<li><p><strong>weight</strong> (Tensor) - Set size of kernel is <span class="math notranslate nohighlight">\((K_1, K_2)\)</span>, then the shape is
<span class="math notranslate nohighlight">\((C_{out}, C_{in}, K_1, K_2)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor of shape <span class="math notranslate nohighlight">\((N, C_{out}, H_{out}, W_{out})\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Conv2DBackpropInput">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Conv2DBackpropInput</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#Conv2DBackpropInput"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Conv2DBackpropInput" title="Permalink to this definition"></a></dt>
<dd><p>Computes the gradients of convolution with respect to the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>out_channel</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The dimensionality of the output space.</p></li>
<li><p><strong>kernel_size</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The size of the convolution window.</p></li>
<li><p><strong>pad_mode</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – “valid”, “same”, “pad” the mode to fill padding. Default: “valid”.</p></li>
<li><p><strong>pad</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The pad value to fill. Default: 0.</p></li>
<li><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – 0 Math convolutiuon, 1 cross-correlation convolution ,
2 deconvolution, 3 depthwise convolution. Default: 1.</p></li>
<li><p><strong>stride</strong> (<em>Union</em><em>[</em><em>int. tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The stride to apply conv filter. Default: 1.</p></li>
<li><p><strong>dilation</strong> (<em>Union</em><em>[</em><em>int. tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – Specifies the dilation rate to use for dilated convolution. Default: 1.</p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Splits input into groups. Default: 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, the gradients of convolution.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.CorrectionMul">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">CorrectionMul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/_quant_ops.html#CorrectionMul"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.CorrectionMul" title="Permalink to this definition"></a></dt>
<dd><p>Scale the weights with a correction factor to the long term statistics
prior to quantization. This ensures that there is no jitter in the quantized weights
due to batch to batch variation.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>x</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, C)\)</span>.</p></li>
<li><p><strong>batch_std</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>running_std</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><ul class="simple">
<li><p><strong>out</strong> (Tensor) - Tensor has the same shape as x.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.CorrectionMulGrad">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">CorrectionMulGrad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/_quant_ops.html#CorrectionMulGrad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.CorrectionMulGrad" title="Permalink to this definition"></a></dt>
<dd><p>Performs grad of CorrectionMul operation.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Cos">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Cos</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Cos"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Cos" title="Permalink to this definition"></a></dt>
<dd><p>Computes cosine of input element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape as <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cos</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Cos</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.24</span><span class="p">,</span> <span class="mf">0.83</span><span class="p">,</span> <span class="mf">0.31</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">cos</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.CumProd">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">CumProd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#CumProd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.CumProd" title="Permalink to this definition"></a></dt>
<dd><p>Compute the cumulative product of the tensor x along axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>exclusive</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, perform exclusive cumulative product. Default: False.</p></li>
<li><p><strong>reverse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, reverse the result along axis. Default: False</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor[Number]) - The input tensor.</p></li>
<li><p><strong>axis</strong> (int) - The dimensions to compute the cumulative product.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape and dtype as the ‘input_x’.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op0</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">CumProd</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op0</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># output=[a, a * b, a * b * c]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op1</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">CumProd</span><span class="p">(</span><span class="n">exclusive</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op1</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># output=[1, a, a * b]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op2</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">CumProd</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op2</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># output=[a * b * c, b * c, c]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op3</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">CumProd</span><span class="p">(</span><span class="n">exclusive</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op3</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># output=[b * c, c, 1]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.CumSum">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">CumSum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#CumSum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.CumSum" title="Permalink to this definition"></a></dt>
<dd><p>Computes the cumulative sum of input tensor along axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>exclusive</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, perform exclusive mode. Default: False.</p></li>
<li><p><strong>reverse</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, perform inverse cumulative sum. Default: False.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor) - The input tensor to accumulate.</p></li>
<li><p><strong>axis</strong>  (int) - The axis to accumulate the tensor’s value.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape of the output tensor is consistent with the input tensor’s.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cumsum</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">CumSum</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">cumsum</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">[[ 3.  7. 13. 23.]</span>
<span class="go"> [ 1.  7. 14. 23.]</span>
<span class="go"> [ 4.  7. 15. 22.]</span>
<span class="go"> [ 1.  4. 11. 20.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.DType">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">DType</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#DType"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.DType" title="Permalink to this definition"></a></dt>
<dd><p>Returns the data type of input tensor as mindspore.dtype.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>mindspore.dtype, the data type of a tensor.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">DType</span><span class="p">()(</span><span class="n">input_tensor</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.DepthToSpace">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">DepthToSpace</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#DepthToSpace"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.DepthToSpace" title="Permalink to this definition"></a></dt>
<dd><p>Rearrange blocks of depth data into spatial dimensions.</p>
<p>This is the reverse operation of SpaceToDepth.</p>
<p>The output tensor’s <cite>height</cite> dimension is <span class="math notranslate nohighlight">\(height * block\_size\)</span>.</p>
<p>The output tensor’s <cite>weight</cite> dimension is <span class="math notranslate nohighlight">\(weight * block\_size\)</span>.</p>
<p>The depth of output tensor is <span class="math notranslate nohighlight">\(input\_depth / (block\_size * block\_size)\)</span>.</p>
<p>The input tensor’s depth must be divisible by <cite>block_size * block_size</cite>.
The data format is “NCHW”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>block_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The block size used to divide depth data. It must be &gt;= 2.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>x</strong> (Tensor) - The target tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the same type as <cite>x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">block_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">DepthToSpace</span><span class="p">(</span><span class="n">block_size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.DepthwiseConv2dNative">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">DepthwiseConv2dNative</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#DepthwiseConv2dNative"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.DepthwiseConv2dNative" title="Permalink to this definition"></a></dt>
<dd><p>Returns the depth-wise convolution value for the input.</p>
<p>Applies depthwise conv2d for the input, which will generate more channels with channel_multiplier.
Given an input tensor of shape <span class="math notranslate nohighlight">\((N, C_{in}, H_{in}, W_{in})\)</span> where <span class="math notranslate nohighlight">\(N\)</span> is the batch size and a
filter tensor with kernel size <span class="math notranslate nohighlight">\((ks_{h}, ks_{w})\)</span>, containing <span class="math notranslate nohighlight">\(C_{in} * \text{channel_multiplier}\)</span>
convolutional filters of depth 1; it applies different filters to each input channel (channel_multiplier channels
for each with default value 1), then concatenates the results together. The output has
<span class="math notranslate nohighlight">\(\text{in_channels} * \text{channel_multiplier}\)</span> channels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>channel_multiplier</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The multipiler for the original output conv.</p></li>
<li><p><strong>kernel_size</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The size of the conv kernel.</p></li>
<li><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – 0 Math convolution, 1 cross-correlation convolution ,
2 deconvolution, 3 depthwise convolution. Default: 3.</p></li>
<li><p><strong>pad_mode</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – “valid”, “same”, “pad” the mode to fill padding. Default: “valid”.</p></li>
<li><p><strong>pad</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The pad value to fill. Default: 0.</p></li>
<li><p><strong>stride</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The stride to apply conv filter. Default: 1.</p></li>
<li><p><strong>dilation</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – Specifies the dilation rate to use for dilated convolution. Default: 1.</p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Splits input into groups. Default: 1.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, C_{in}, H_{in}, W_{in})\)</span>.</p></li>
<li><p><strong>weight</strong> (Tensor) - Set size of kernel is <span class="math notranslate nohighlight">\((K_1, K_2)\)</span>, then the shape is
<span class="math notranslate nohighlight">\((\text{channel_multiplier}, C_{in}, K_1, K_2)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor of shape <span class="math notranslate nohighlight">\((N, C_{in} * \text{channel_multiplier}, H_{out}, W_{out})\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Diag">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Diag</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Diag"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Diag" title="Permalink to this definition"></a></dt>
<dd><p>Construct a diagonal tensor with a given diagonal values.</p>
<p>Assume <cite>input_x</cite> has dimensions <span class="math notranslate nohighlight">\([D_1,... D_k]\)</span>, the output is a tensor of
rank 2k with dimensions <span class="math notranslate nohighlight">\([D_1,..., D_k, D_1,..., D_k]\)</span> where:
<span class="math notranslate nohighlight">\(output[i_1,..., i_k, i_1,..., i_k] = input_x[i_1,..., i_k]\)</span> and 0 everywhere else.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">diag</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Diag</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">diag</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">[[1, 0, 0, 0],</span>
<span class="go"> [0, 2, 0, 0],</span>
<span class="go"> [0, 0, 3, 0],</span>
<span class="go"> [0, 0, 0, 4]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.DiagPart">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">DiagPart</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#DiagPart"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.DiagPart" title="Permalink to this definition"></a></dt>
<dd><p>Extract the diagonal part from given tensor.</p>
<p>Assume input has dimensions <span class="math notranslate nohighlight">\([D_1,..., D_k, D_1,..., D_k]\)</span>, the output is a tensor
of rank k with dimensions <span class="math notranslate nohighlight">\([D_1,..., D_k]\)</span> where:
<span class="math notranslate nohighlight">\(output[i_1,..., i_k] = input[i_1,..., i_k, i_1,..., i_k]\)</span>.</p>
<dl>
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input Tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor.</p>
</dd>
<dt>Examples</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">diag_part</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">DiagPart</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">diag_part</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">[1, 2, 3, 4]</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Div">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Div</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Div"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Div" title="Permalink to this definition"></a></dt>
<dd><p>Computes the quotient of dividing the first input tensor by the second input tensor element-wise.</p>
<p>The inputs must be two tensors or one tensor and one scalar.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be same.
When the inputs are one tensor and one scalar, the scalar cannot be a parameter, only can be a constant,
and the type of the scalar is the same as the data type of the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, Number]) - The first input is a tensor whose data type is number or a number.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, Number]) - The second input is a tensor whose data type is same as ‘input_x’ or
a number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is same as ‘input_x’.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – When <cite>input_x</cite> and <cite>input_y</cite> are not the same dtype.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">div</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Div</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">div</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.DropoutDoMask">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">DropoutDoMask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#DropoutDoMask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.DropoutDoMask" title="Permalink to this definition"></a></dt>
<dd><p>Applies dropout mask on the input tensor.</p>
<p>Take the mask output of DropoutGenMask as input, and apply dropout on the input.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
<li><p><strong>mask</strong> (Tensor) - The mask to be applied on <cite>input_x</cite>, which is the output of <cite>DropoutGenMask</cite>. And the
shape of <cite>input_x</cite> must be same as the value of <cite>DropoutGenMask</cite>’s input <cite>shape</cite>. If input wrong <cite>mask</cite>,
the output of <cite>DropoutDoMask</cite> are unpredictable.</p></li>
<li><p><strong>keep_prob</strong> (Tensor) - The keep rate, between 0 and 1, e.g. keep_prob = 0.9,
means dropping out 10% of input units. The value of <cite>keep_prob</cite> is same as the input <cite>keep_prob</cite> of
<cite>DropoutGenMask</cite>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the value that applied dropout on.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">keep_prob</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dropout_gen_mask</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">DropoutGenMask</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dropout_do_mask</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">DropoutDoMask</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span> <span class="o">=</span> <span class="n">dropout_gen_mask</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">dropout_do_mask</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">()</span> <span class="o">==</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.DropoutGenMask">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">DropoutGenMask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#DropoutGenMask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.DropoutGenMask" title="Permalink to this definition"></a></dt>
<dd><p>Generates the mask value for the input shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Seed0</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Seed0 value for random generating. Default: 0.</p></li>
<li><p><strong>Seed1</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Seed1 value for random generating. Default: 0.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>shape</strong> (tuple[int]) - The shape of target mask.</p></li>
<li><p><strong>keep_prob</strong> (Tensor) - The keep rate, between 0 and 1, e.g. keep_prob = 0.9,
means dropping out 10% of input units.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the value of generated mask for input shape.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">dropout_gen_mask</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">DropoutGenMask</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">keep_prob</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span> <span class="o">=</span> <span class="n">dropout_gen_mask</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Elu">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Elu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#Elu"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Elu" title="Permalink to this definition"></a></dt>
<dd><p>Computes exponential linear: <cite>alpha * (exp(x) - 1)</cite> if x &lt; 0, <cite>x</cite> otherwise.
The data type of input tensor should be float.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The coefficient of negative factor whose type is float. Default: 1.0.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor whose data type should be float.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape and data type as <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">elu</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Elu</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">elu</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">Tensor([[-0.632  4.0   -0.999]</span>
<span class="go">        [2.0    -0.993  9.0  ]], shape=(2, 3), dtype=mindspore.float32)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Equal">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Equal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Equal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Equal" title="Permalink to this definition"></a></dt>
<dd><p>Computes the equivalence between two tensors element-wise.</p>
<p>The inputs must be two tensors or one tensor and one scalar.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be same.
When the inputs are one tensor and one scalar, the scalar cannot be a parameter, only can be a constant,
and the type of the scalar is the same as the data type of the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, Number, bool]) - The first input is a tensor whose data type is number or bool, or
a number or a bool object.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, Number, bool]) - The second input tensor whose data type is same as ‘input_x’ or
a number or a bool object.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is bool.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">equal</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Equal</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">equal</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span>
<span class="go">[False, True, False]</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">equal</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Equal</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">equal</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[True, True, False]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.EqualCount">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">EqualCount</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#EqualCount"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.EqualCount" title="Permalink to this definition"></a></dt>
<dd><p>Computes the number of the same elements of two tensors.</p>
<p>The two input tensors should have same shape.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The first input tensor.</p></li>
<li><p><strong>input_y</strong> (Tensor) - The second input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with the type as <cite>mindspore.int32</cite> and size as (1,).</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">equal_count</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">EqualCount</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">equal_count</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Erf">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Erf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Erf"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Erf" title="Permalink to this definition"></a></dt>
<dd><p>Computes the Gauss error function of <cite>input_x</cite> element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape and dtype as the <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">erf</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Erf</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">erf</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">[-0.8427168, 0., 0.8427168, 0.99530876, 0.99997765]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Exp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Exp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Exp" title="Permalink to this definition"></a></dt>
<dd><p>Returns exponential of a tensor element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape as the <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">exp</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Exp</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">exp</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">[ 2.71828183,  7.3890561 , 54.59815003]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ExpandDims">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ExpandDims</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#ExpandDims"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ExpandDims" title="Permalink to this definition"></a></dt>
<dd><p>Adds an additional dimension at the given axis.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the specified axis is a negative number, the index is counted
backward from the end and starts at 1.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If axis is not an integer or not in the valid range.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
<li><p><strong>axis</strong> (int) - Specifies the dimension index at which to expand
the shape of <cite>input_x</cite>. The value of axis must be in the range
<cite>[-input_x.dim()-1, input_x.dim()]</cite>. Only constant value is allowed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape of tensor is <span class="math notranslate nohighlight">\((1, x_1, x_2, ..., x_R)\)</span> if the
value of <cite>axis</cite> is 0.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">expand_dims</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ExpandDims</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">expand_dims</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ExtractImagePatches">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ExtractImagePatches</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#ExtractImagePatches"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ExtractImagePatches" title="Permalink to this definition"></a></dt>
<dd><p>Extract patches from images.
The input tensor must be a 4-D tensor and the data format is NHWC.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ksizes</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The size of sliding window, should be a tuple or list of int,
and the format is [1, ksize_row, ksize_col, 1].</p></li>
<li><p><strong>strides</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – Distance between the centers of the two consecutive patches,
should be a tuple or list of int, and the format is [1, stride_row, stride_col, 1].</p></li>
<li><p><strong>rates</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – In each extracted patch, the gap between the corresponding dim
pixel positions, should be a tuple or list of int, and the format is [1, rate_row, rate_col, 1].</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>The type of padding algorithm, is a string whose value is “same” or “valid”,
not case sensitive. Default: “valid”.</p>
<ul>
<li><p>same: Means that the patch can take the part beyond the original image, and this part is filled with 0.</p></li>
<li><p>valid: Means that the patch area taken must be completely contained in the original image.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - A 4-D tensor whose shape is [in_batch, in_row, in_col, in_depth] and
data type is int8, float16, uint8.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, a 4-D tensor whose data type is same as ‘input_x’,
and the shape is [out_batch, out_row, out_col, out_depth], the out_batch is same as the in_batch.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Eye">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Eye</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Eye"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Eye" title="Permalink to this definition"></a></dt>
<dd><p>Creates a tensor with ones on the diagonal and zeros elsewhere.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>n</strong> (int) - Number of rows of returned tensor</p></li>
<li><p><strong>m</strong> (int) - Number of columns of returned tensor</p></li>
<li><p><strong>t</strong> (mindspore.dtype) - Mindspore’s dtype, The data type of the returned tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, a tensor with ones on the diagonal and zeros elsewhere.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">eye</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Eye</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.FakeQuantWithMinMax">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">FakeQuantWithMinMax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/_quant_ops.html#FakeQuantWithMinMax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.FakeQuantWithMinMax" title="Permalink to this definition"></a></dt>
<dd><p>Simulate the quantize and dequantize operations in training time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_bits</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number bits for aware quantilization. Default: 8.</p></li>
<li><p><strong>ema</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Use EMA algorithm update value min and max. Default: False.</p></li>
<li><p><strong>ema_decay</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – EMA algorithm decay parameter. Default: 0.999.</p></li>
<li><p><strong>quant_delay</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Quantilization delay parameter. Before delay step in training time not update
simulate aware quantize funcion. After delay step in training time begin simulate the aware
quantize funcion. Default: 0.</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Quantization algorithm use symmetric or not. Default: False.</p></li>
<li><p><strong>narrow_range</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Quantization algorithm use narrow range or not. Default: False.</p></li>
<li><p><strong>training</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Training the network or not. Default: True.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>x</strong> (Tensor) : float32 Tensor representing the shape of the output tensor.</p></li>
<li><p><strong>min</strong> (Tensor) : Value of the min range of the input data x.</p></li>
<li><p><strong>max</strong> (Tensor) : Value of the max range of the input data x.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><ul class="simple">
<li><p>Tensor: Simulate quantize tensor of x.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">min_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">6</span><span class="p">]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">max_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">6</span><span class="p">]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output_tensor</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">FakeQuantWithMinMax</span><span class="p">(</span><span class="n">num_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">)(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">min_tensor</span><span class="p">,</span> <span class="n">max_tensor</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.FakeQuantWithMinMaxGrad">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">FakeQuantWithMinMaxGrad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/_quant_ops.html#FakeQuantWithMinMaxGrad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.FakeQuantWithMinMaxGrad" title="Permalink to this definition"></a></dt>
<dd><p>Performs grad of FakeQuantWithMinMax operation.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.FakeQuantWithMinMaxPerChannel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">FakeQuantWithMinMaxPerChannel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/_quant_ops.html#FakeQuantWithMinMaxPerChannel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.FakeQuantWithMinMaxPerChannel" title="Permalink to this definition"></a></dt>
<dd><p>Simulate the quantize and dequantize operations in training time base on per channel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_bits</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number bits to quantilization. Default: 8.</p></li>
<li><p><strong>ema</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Use EMA algorithm update tensor min and tensor max. Default: False.</p></li>
<li><p><strong>ema_decay</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – EMA algorithm decay parameter. Default: 0.999.</p></li>
<li><p><strong>quant_delay</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Quantilization delay  parameter. Before delay step in training time not
update the weight data to simulate quantize operation. After delay step in training time
begin simulate the quantize operation. Default: 0.</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Quantization algorithm use symmetric or not. Default: False.</p></li>
<li><p><strong>narrow_range</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Quantization algorithm use narrow range or not. Default: False.</p></li>
<li><p><strong>training</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Training the network or not. Default: True.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>x</strong> (Tensor) : 4-D float32 Tensor representing the shape of the output tensor.</p></li>
<li><p><strong>min</strong> (int, float) : Value of the min range of the input data.</p></li>
<li><p><strong>max</strong> (int, float) : Value of the max range of the input data.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><ul class="simple">
<li><p>Tensor, has the same type as input.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">min_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">6.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.0</span><span class="p">]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">max_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">6.5</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output_tensor</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">FakeQuantWithMinMax</span><span class="p">(</span><span class="n">num_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">)(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">min_tensor</span><span class="p">,</span> <span class="n">max_tensor</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.FakeQuantWithMinMaxPerChannelGrad">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">FakeQuantWithMinMaxPerChannelGrad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/_quant_ops.html#FakeQuantWithMinMaxPerChannelGrad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.FakeQuantWithMinMaxPerChannelGrad" title="Permalink to this definition"></a></dt>
<dd><p>Performs grad of FakeQuantWithMinMaxPerChannel operation.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Fill">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Fill</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Fill"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Fill" title="Permalink to this definition"></a></dt>
<dd><p>Creates a tensor filled with a scalar value.</p>
<p>Creates a tensor with shape described by the first argument and fills it with values in the second argument.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>type</strong> (mindspore.dtype) - The specified type of output tensor. Only constant value is allowed.</p></li>
<li><p><strong>shape</strong> (tuple) - The specified shape of output tensor. Only constant value is allowed.</p></li>
<li><p><strong>value</strong> (scalar) - Value to fill the returned tensor. Only constant value is allowed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same type and shape as input value.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fill</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Fill</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fill</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Flatten">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Flatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#Flatten"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Flatten" title="Permalink to this definition"></a></dt>
<dd><p>Flattens a tensor without changing its batch size on the 0-th axis.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, \ldots)\)</span> to be flattened.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape of the output tensor is <span class="math notranslate nohighlight">\((N, X)\)</span>, where <span class="math notranslate nohighlight">\(X\)</span> is
the product of the remaining dimension.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">flatten</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">flatten</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">()</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">24</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.FloatStatus">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">FloatStatus</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#FloatStatus"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.FloatStatus" title="Permalink to this definition"></a></dt>
<dd><p>Determine if the elements contains nan, inf or -inf. <cite>0</cite> for normal, <cite>1</cite> for overflow.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the shape of <cite>(1,)</cite>, and has the same dtype of input <cite>mindspore.dtype.float32</cite> or
<cite>mindspore.dtype.float16</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Floor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Floor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Floor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Floor" title="Permalink to this definition"></a></dt>
<dd><p>Round a tensor down to the closest integer element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor. Its element data type must be float.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape as <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">floor</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Floor</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">floor</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">[1.0, 2.0, -2.0]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.FloorDiv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">FloorDiv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#FloorDiv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.FloorDiv" title="Permalink to this definition"></a></dt>
<dd><p>Divide the first input tensor by the second input tensor element-wise and rounds down to the closest integer.</p>
<p>The inputs must be two tensors or one tensor and one scalar.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be same.
When the inputs are one tensor and one scalar, the scalar cannot be a parameter, only can be a constant,
and the type of the scalar is the same as the data type of the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, Number]) - The first input is a tensor whose data type is number or a number.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, Number]) - The second input is a tensor whose data type is same as ‘input_x’ or
a number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is same as ‘input_x’.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">floor_div</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">FloorDiv</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">floor_div</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[0, 1, -1]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.FloorMod">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">FloorMod</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#FloorMod"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.FloorMod" title="Permalink to this definition"></a></dt>
<dd><p>Compute element-wise remainder of division.</p>
<p>The inputs must be two tensors or one tensor and one scalar.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be same.
When the inputs are one tensor and one scalar, the scalar cannot be a parameter, only can be a constant,
and the type of the scalar is the same as the data type of the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, Number]) - The first input is a tensor whose data type is number or a number.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, Number]) - The second input is a tensor whose data type is same as ‘input_x’ or
a number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is same as ‘input_x’.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">floor_mod</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">FloorMod</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">floor_mod</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[2, 1, 2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.FusedBatchNorm">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">FusedBatchNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#FusedBatchNorm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.FusedBatchNorm" title="Permalink to this definition"></a></dt>
<dd><p>FusedBatchNorm is a BatchNorm that moving mean and moving variance will be computed instead of being loaded.</p>
<p>Batch Normalization is widely used in convolutional networks. This operation applies
Batch Normalization over input to avoid internal covariate shift as described in the
paper <a class="reference external" href="https://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal
Covariate Shift</a>. It rescales and recenters the
feature using a mini-batch of data and the learned parameters which can be described
in the following formula.</p>
<div class="math notranslate nohighlight">
\[y = \frac{x - mean}{\sqrt{variance + \epsilon}} * \gamma + \beta\]</div>
<p>where <span class="math notranslate nohighlight">\(\gamma\)</span> is scale, <span class="math notranslate nohighlight">\(\beta\)</span> is bias, <span class="math notranslate nohighlight">\(\epsilon\)</span> is epsilon.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Mode of batch normalization, value is 0 or 1. Default: 0.</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – A small value added for numerical stability. Default: 1e-5.</p></li>
<li><p><strong>momentum</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The hyper parameter to compute moving average for running_mean and running_var
(e.g. <span class="math notranslate nohighlight">\(new\_running\_mean = momentum * running\_mean + (1 - momentum) * current\_mean\)</span>).
Momentum value should be [0, 1]. Default: 0.9.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, C)\)</span>.</p></li>
<li><p><strong>scale</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>bias</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>mean</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>variance</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tuple of 5 Tensor, the normalized input and the updated parameters.</p>
<ul class="simple">
<li><p><strong>output_x</strong> (Tensor) - The same type and shape as the <cite>input_x</cite>.</p></li>
<li><p><strong>updated_scale</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>updated_bias</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>updated_moving_mean</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>updated_moving_variance</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.GatherNd">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">GatherNd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#GatherNd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.GatherNd" title="Permalink to this definition"></a></dt>
<dd><p>Gathers slices from a tensor by indices.</p>
<p>Using given indices to gather slices from a tensor with a specified shape.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The target tensor to gather values.</p></li>
<li><p><strong>indices</strong> (Tensor) - The index tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same type as <cite>input_x</cite> and the shape is indices_shape[:-1] + x_shape[indices_shape[-1]:].</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">GatherNd</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.GatherV2">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">GatherV2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#GatherV2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.GatherV2" title="Permalink to this definition"></a></dt>
<dd><p>Returns a slice of input tensor based on the specified indices and axis.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_params</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.
The original Tensor.</p></li>
<li><p><strong>input_indices</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((y_1, y_2, ..., y_S)\)</span>.
Specifies the indices of elements of the original Tensor. Must be in the range
<cite>[0, input_param.shape()[axis])</cite>.</p></li>
<li><p><strong>axis</strong> (int) - Specifies the dimension index to gather indices.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape of tensor is <span class="math notranslate nohighlight">\((z_1, z_2, ..., z_N)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_params</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">42</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">54</span><span class="p">,</span> <span class="mi">22</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">GatherV2</span><span class="p">()(</span><span class="n">input_params</span><span class="p">,</span> <span class="n">input_indices</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.GeSwitch">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">GeSwitch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/control_ops.html#GeSwitch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.GeSwitch" title="Permalink to this definition"></a></dt>
<dd><p>Adds control switch to data.</p>
<p>Switch data to flow into false or true branch depend on the condition. If the condition is true,
the true branch will be activated, or vise verse.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>data</strong> (Tensor) - The data to be used for switch control.</p></li>
<li><p><strong>pred</strong> (Tensor) - It should be a scalar whose type is bool and shape is <cite>()</cite>, It is used as condition for
switch control.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>tuple. Output is tuple(false_output, true_output). The Elements in the tuple has the same shape of input data.
The false_output connects with the false_branch and the true_output connects with the true_branch.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">square</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Square</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">TensorAdd</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">1</span><span class="p">),</span> <span class="mi">3</span><span class="p">),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">switch</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">GeSwitch</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">merge</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Merge</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">less</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Less</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">cond</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">st1</span><span class="p">,</span> <span class="n">sf1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">switch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">cond</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">st2</span><span class="p">,</span> <span class="n">sf2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">switch</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">cond</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">add_ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">st1</span><span class="p">,</span> <span class="n">st2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">st3</span><span class="p">,</span> <span class="n">sf3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">switch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">cond</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">sq_ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">sf3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">merge</span><span class="p">((</span><span class="n">add_ret</span><span class="p">,</span> <span class="n">sq_ret</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">ret</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">5.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Gelu">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Gelu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#Gelu"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Gelu" title="Permalink to this definition"></a></dt>
<dd><p>Gaussian Error Linear Units activation function.</p>
<p>GeLU is described in the paper <a class="reference external" href="https://arxiv.org/abs/1606.08415">Gaussian Error Linear Units (GELUs)</a>.
And also please refer to <a class="reference external" href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.</a>.</p>
<p>Defined as follows:</p>
<div class="math notranslate nohighlight">
\[\text{output} = 0.5 * x * (1 + erf(x / \sqrt{2})),\]</div>
<p>where <span class="math notranslate nohighlight">\(erf\)</span> is the “Gauss error function” .</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - Input to compute the Gelu.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with the same type and shape as input.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gelu</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Gelu</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">gelu</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.GetNext">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">GetNext</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#GetNext"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.GetNext" title="Permalink to this definition"></a></dt>
<dd><p>Returns the next element in the dataset queue.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>GetNext op needs to be associated with network and also depends on the init_dataset interface,
it can’t be used directly as a single op.
For details, please refer to <cite>nn.cell_wrapper.DataWrapper</cite> source code.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>types</strong> (list[<a class="reference internal" href="mindspore.dtype.html#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>]) – The type of the outputs.</p></li>
<li><p><strong>shapes</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The dimensionality of the outputs.</p></li>
<li><p><strong>output_num</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The output number, length of <cite>types</cite> and <cite>shapes</cite>.</p></li>
<li><p><strong>shared_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The queue name of <cite>init_dataset</cite> interface.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><p>No inputs.</p>
</dd>
<dt>Outputs:</dt><dd><p>tuple[Tensor], the output of Dataset. The shape is described in <cite>shapes</cite>
and the type is described is <cite>types</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">get_next</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">GetNext</span><span class="p">([</span><span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">],</span> <span class="p">[[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">]],</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;shared_name&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">get_next</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Greater">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Greater</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Greater"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Greater" title="Permalink to this definition"></a></dt>
<dd><p>Computes the boolean value of <span class="math notranslate nohighlight">\(x &gt; y\)</span> element-wise.</p>
<p>The inputs must be two tensors or one tensor and one scalar.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be same.
When the inputs are one tensor and one scalar, the scalar cannot be a parameter, only can be a constant,
and the type of the scalar is the same as the data type of the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, Number]) - The first input is a tensor whose data type is number or a number.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, Number]) - The second input is a tensor whose data type is same as <cite>input_x</cite> or
a number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is bool.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">greater</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Greater</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">greater</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[False, True, False]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.GreaterEqual">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">GreaterEqual</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#GreaterEqual"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.GreaterEqual" title="Permalink to this definition"></a></dt>
<dd><p>Computes the boolean value of <span class="math notranslate nohighlight">\(x &gt;= y\)</span> element-wise.</p>
<p>The inputs must be two tensors or one tensor and one scalar.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be same.
When the inputs are one tensor and one scalar, the scalar cannot be a parameter, only can be a constant,
and the type of the scalar is the same as the data type of the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, Number]) - The first input is a tensor whose data type is number or a number.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, Number]) - The second input is a tensor whose data type is same as <cite>input_x</cite> or
a number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is bool.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">greater_equal</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">GreaterEqual</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">greater_equal</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[True, True, False]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.HSigmoid">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">HSigmoid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#HSigmoid"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.HSigmoid" title="Permalink to this definition"></a></dt>
<dd><p>Hard sigmoid activation function.</p>
<p>Applies hard sigmoid activation element-wise. The input is a Tensor with any valid shape.</p>
<p>Hard sigmoid is defined as:</p>
<div class="math notranslate nohighlight">
\[\text{hsigmoid}(x_{i}) = max(0, min(1, \frac{2 * x_{i} + 5}{10})),\]</div>
<p>where <span class="math notranslate nohighlight">\(x_{i}\)</span> is the <span class="math notranslate nohighlight">\(i\)</span>-th slice along the given dim of the input Tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_data</strong> (Tensor) - The input of HSigmoid.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with the same type and shape as the <cite>input_data</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.HSwish">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">HSwish</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#HSwish"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.HSwish" title="Permalink to this definition"></a></dt>
<dd><p>Hard swish activation function.</p>
<p>Applies hswish-type activation element-wise. The input is a Tensor with any valid shape.</p>
<p>Hard swish is defined as:</p>
<div class="math notranslate nohighlight">
\[\text{hswish}(x_{i}) = x_{i} * \frac{ReLU6(x_{i} + 3)}{6},\]</div>
<p>where <span class="math notranslate nohighlight">\(x_{i}\)</span> is the <span class="math notranslate nohighlight">\(i\)</span>-th slice along the given dim of the input Tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_data</strong> (Tensor) - The input of HSwish.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with the same type and shape as the <cite>input_data</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.HistogramSummary">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">HistogramSummary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/debug_ops.html#HistogramSummary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.HistogramSummary" title="Permalink to this definition"></a></dt>
<dd><p>Output tensor to protocol buffer through histogram summary operator.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>name</strong> (str) - The name of the input variable.</p></li>
<li><p><strong>value</strong> (Tensor) - The value of tensor, and the rank of tensor should be greater than 0.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">SummaryDemo</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">SummaryDemo</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">summary</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">HistogramSummary</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">TensorAdd</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;x&quot;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.IOU">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">IOU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/other_ops.html#IOU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.IOU" title="Permalink to this definition"></a></dt>
<dd><p>Calculate intersection over union for boxes.</p>
<p>Compute the intersection over union (IOU) or the intersection over foreground (IOF) based on the ground-truth and
predicted regions.</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\text{IOU} = \frac{\text{Area of Overlap}}{\text{Area of Union}}\\\text{IOF} = \frac{\text{Area of Overlap}}{\text{Area of Ground Truth}}\end{aligned}\end{align} \]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>string</em>) – The mode is used to specify the calculation method,
now support ‘iou’ (intersection over union) or ‘iof’
(intersection over foreground) mode. Default: ‘iou’.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>anchor_boxes</strong> (Tensor) - Anchor boxes, tensor of shape (N, 4). “N” indicates the number of anchor boxes,
and the value “4” refers to “x0”, “x1”, “y0”, and “y1”.</p></li>
<li><p><strong>gt_boxes</strong> (Tensor) - Ground truth boxes, tensor of shape (M, 4). “M” indicates the number of ground
truth boxes, and the value “4” refers to “x0”, “x1”, “y0”, and “y1”.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the ‘iou’ values, tensor of shape (M, N).</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#KeyError" title="(in Python v3.8)"><strong>KeyError</strong></a> – When <cite>mode</cite> is not ‘iou’ or ‘iof’.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">iou</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">IOU</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">anchor_boxes</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gt_boxes</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iou</span><span class="p">(</span><span class="n">anchor_boxes</span><span class="p">,</span> <span class="n">gt_boxes</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ImageSummary">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ImageSummary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/debug_ops.html#ImageSummary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ImageSummary" title="Permalink to this definition"></a></dt>
<dd><p>Output image tensor to protocol buffer through image summary operator.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>name</strong> (str) - The name of the input variable.</p></li>
<li><p><strong>value</strong> (Tensor) - The value of image.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">summary</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ImageSummary</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;image&quot;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.InsertGradientOf">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">InsertGradientOf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/debug_ops.html#InsertGradientOf"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.InsertGradientOf" title="Permalink to this definition"></a></dt>
<dd><p>Attach callback to graph node that will be invoked on the node’s gradient.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>f</strong> (<em>Function</em>) – MindSpore’s Function. Callback function.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The graph node to attach to.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, returns <cite>input_x</cite> directly. <cite>InsertGradientOf</cite> does not affect the forward result.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">clip_gradient</span><span class="p">(</span><span class="n">dx</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">ret</span> <span class="o">=</span> <span class="n">dx</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">ret</span> <span class="o">&gt;</span> <span class="mf">1.0</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ret</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">ret</span> <span class="o">&lt;</span> <span class="mf">0.2</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ret</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">return</span> <span class="n">ret</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clip</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">InsertGradientOf</span><span class="p">(</span><span class="n">clip_gradient</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad_all</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">GradOperation</span><span class="p">(</span><span class="s1">&#39;get_all&#39;</span><span class="p">,</span> <span class="n">get_all</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">InsertGradientOfClipDemo</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">clip_test</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="n">clip</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">y</span> <span class="o">=</span> <span class="n">clip</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">c</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">c</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@ms_function</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">clip_test</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">fd</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">grad_all</span><span class="p">(</span><span class="n">clip_test</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;forward: &quot;</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;clip_gradient:&quot;</span><span class="p">,</span> <span class="n">fd</span><span class="p">(</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.InvertPermutation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">InvertPermutation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#InvertPermutation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.InvertPermutation" title="Permalink to this definition"></a></dt>
<dd><p>Computes the inverse of an index permutation.</p>
<p>Given a tuple input, this operation inserts a dimension of 1 at the dimension
This operation calculates the inverse of the index replacement. It requires a
1-dimensional tuple x, which represents the array starting at zero,
and swaps each value with its index position. In other words, for the output
tuple y and the input tuple x, this operation calculates the following:
<span class="math notranslate nohighlight">\(y[x[i]] = i, \quad i \in [0, 1, \ldots, \text{len}(x)-1]\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>These values must include 0. There must be no duplicate values and the
values can not be negative.</p>
</div>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (tuple[int]) - The input tuple is constructed by multiple
integers, i.e., <span class="math notranslate nohighlight">\((y_1, y_2, ..., y_S)\)</span> representing the indices.
The values must include 0. There can be no duplicate values or negative values.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>tuple[int]. the lenth is same as input.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">invert</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">InvertPermutation</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_data</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">invert</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">==</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.IsFinite">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">IsFinite</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#IsFinite"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.IsFinite" title="Permalink to this definition"></a></dt>
<dd><p>Judging which elements are finite for each position</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape of input, and the dtype is bool.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.IsInf">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">IsInf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#IsInf"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.IsInf" title="Permalink to this definition"></a></dt>
<dd><p>Judging which elements are inf or -inf for each position</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape of input, and the dtype is bool.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.IsInstance">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">IsInstance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#IsInstance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.IsInstance" title="Permalink to this definition"></a></dt>
<dd><p>Check whether an object is an instance of a target type.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>inst</strong> (Any Object) - The instance to be check. Only constant value is allowed.</p></li>
<li><p><strong>type_</strong> (mindspore.dtype) - The target type. Only constant value is allowed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>bool, the check result.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">IsInstance</span><span class="p">()(</span><span class="n">a</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.IsNan">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">IsNan</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#IsNan"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.IsNan" title="Permalink to this definition"></a></dt>
<dd><p>Judging which elements are nan for each position</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape of input, and the dtype is bool.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.IsSubClass">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">IsSubClass</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#IsSubClass"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.IsSubClass" title="Permalink to this definition"></a></dt>
<dd><p>Check whether one type is sub class of another type.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>sub_type</strong> (mindspore.dtype) - The type to be check. Only constant value is allowed.</p></li>
<li><p><strong>type_</strong> (mindspore.dtype) - The target type. Only constant value is allowed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>bool, the check result.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">IsSubClass</span><span class="p">()(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>  <span class="n">mindspore</span><span class="o">.</span><span class="n">intc</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.L2Loss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">L2Loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#L2Loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.L2Loss" title="Permalink to this definition"></a></dt>
<dd><p>Calculates half of the L2 norm of a tensor without using the <cite>sqrt</cite>.</p>
<p>Set <cite>input_x</cite> as x and output as loss.</p>
<div class="math notranslate nohighlight">
\[loss = sum(x ** 2) / 2\]</div>
<dl>
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - A input Tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor. Has the same dtype as <cite>input_x</cite>. The output tensor is the value of loss which is a scalar tensor.</p>
</dd>
<dt>Examples</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l2_loss</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">L2Loss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l2_loss</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">7.0</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.L2Normalize">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">L2Normalize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#L2Normalize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.L2Normalize" title="Permalink to this definition"></a></dt>
<dd><p>L2 normalization Operator.</p>
<p>This operator will normalizes the input using the given axis. The function is shown as follows:</p>
<div class="math notranslate nohighlight">
\[\text{output} = \frac{x}{\sqrt{\text{max}(\text{sum} (\text{input_x}^2), \epsilon)}},\]</div>
<p>where <span class="math notranslate nohighlight">\(\epsilon\)</span> is epsilon.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The begin axis for the input to apply L2 normalize. Default: 0.</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – A small value added for numerical stability. Default: 1e-4.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - Input to compute the normalization.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with the same type and shape as the input.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.LARSUpdate">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">LARSUpdate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#LARSUpdate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.LARSUpdate" title="Permalink to this definition"></a></dt>
<dd><p>Conduct lars (layer-wise adaptive rate scaling) update on the square sum of gradient.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Term added to the denominator to improve numerical stability. Default: 1e-05.</p></li>
<li><p><strong>hyperpara</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Trust coefficient for calculating the local learning rate. Default: 0.001.</p></li>
<li><p><strong>use_clip</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to use clip operation for calculating the local learning rate. Default: False.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>weight</strong> (Tensor) - The weight to be updated.</p></li>
<li><p><strong>gradient</strong> (Tensor) - The gradient of weight, which has the same shape and dtype with weight.</p></li>
<li><p><strong>norm_weight</strong> (Tensor) - A scalar tensor, representing the square sum of weight.</p></li>
<li><p><strong>norm_gradient</strong> (Tensor) - A scalar tensor, representing the square sum of gradient.</p></li>
<li><p><strong>weight_decay</strong> (Union[Number, Tensor]) - Weight decay. It should be a scalar tensor or number.</p></li>
<li><p><strong>learning_rate</strong> (Union[Number, Tensor]) - Learning rate. It should be a scalar tensor or number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, representing the new gradient.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.LSTM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">LSTM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#LSTM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.LSTM" title="Permalink to this definition"></a></dt>
<dd><p>Performs the long short term memory(LSTM) on the input.</p>
<p>Detailed information, please refer to <cite>nn.LSTM</cite>.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.LayerNorm">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">LayerNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#LayerNorm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.LayerNorm" title="Permalink to this definition"></a></dt>
<dd><p>Applies the Layer Normalization to the input tensor.</p>
<p>This operator will normalize the input tensor on given axis. LayerNorm is described in the paper
<a class="reference external" href="https://arxiv.org/abs/1607.06450">Layer Normalization</a>.</p>
<div class="math notranslate nohighlight">
\[y = \frac{x - mean}{\sqrt{variance + \epsilon}} * \gamma + \beta\]</div>
<p>where <span class="math notranslate nohighlight">\(\gamma\)</span> is scale, <span class="math notranslate nohighlight">\(\beta\)</span> is bias, <span class="math notranslate nohighlight">\(\epsilon\)</span> is epsilon.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>begin_norm_axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The begin axis of the <cite>input_x</cite> to apply LayerNorm,
the value should be in [-1, rank(input)). Default: 1.</p></li>
<li><p><strong>begin_params_axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The begin axis of the parameter input (<cite>gamma</cite>, <cite>beta</cite>) to
apply LayerNorm, the value should be in [-1, rank(input)). Default: 1.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, \ldots)\)</span>.
The input of LayerNorm.</p></li>
<li><p><strong>gamma</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((P_0, \ldots, P_\text{begin_params_axis})\)</span>.
The learnable parameter <cite>gamma</cite> as the scale on norm.</p></li>
<li><p><strong>beta</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((P_0, \ldots, P_\text{begin_params_axis})\)</span>.
The learnable parameter <cite>beta</cite> as the scale on norm.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>tuple[Tensor], tuple of 3 tensors, the normalized input and the updated parameters.</p>
<ul class="simple">
<li><p><strong>output_x</strong> (Tensor) - The normalized input, has the same type and shape as the <cite>input_x</cite>.
The shape is <span class="math notranslate nohighlight">\((N, C)\)</span>.</p></li>
<li><p><strong>updated_gamma</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
<li><p><strong>updated_beta</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((C,)\)</span>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Less">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Less</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Less"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Less" title="Permalink to this definition"></a></dt>
<dd><p>Computes the boolean value of <span class="math notranslate nohighlight">\(x &lt; y\)</span> element-wise.</p>
<p>The inputs must be two tensors or one tensor and one scalar.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be same.
When the inputs are one tensor and one scalar, the scalar cannot be a parameter, only can be a constant,
and the type of the scalar is the same as the data type of the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, Number]) - The first input is a tensor whose data type is number or a number.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, Number]) - The second input is a tensor whose data type is same as <cite>input_x</cite> or
a number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is bool.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">less</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Less</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">less</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[False, False, True]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.LessEqual">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">LessEqual</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#LessEqual"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.LessEqual" title="Permalink to this definition"></a></dt>
<dd><p>Computes the boolean value of <span class="math notranslate nohighlight">\(x &lt;= y\)</span> element-wise.</p>
<p>The inputs must be two tensors or one tensor and one scalar.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be same.
When the inputs are one tensor and one scalar, the scalar cannot be a parameter, only can be a constant,
and the type of the scalar is the same as the data type of the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, Number]) - The first input is a tensor whose data type is number or a number.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, Number]) - The second input is a tensor whose data type is same as <cite>input_x</cite> or
a number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is bool.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">less_equal</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">LessEqual</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">less_equal</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[True, False, True]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Log">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Log"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Log" title="Permalink to this definition"></a></dt>
<dd><p>Returns the natural logarithm of a tensor element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape as the <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Log</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">[0.0, 0.69314718, 1.38629436]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.LogSoftmax">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">LogSoftmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#LogSoftmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.LogSoftmax" title="Permalink to this definition"></a></dt>
<dd><p>Log Softmax activation function.</p>
<p>Applies the Log Softmax function to the input tensor on the specified axis.
Suppose a slice along the given aixs <span class="math notranslate nohighlight">\(x\)</span> then for each element <span class="math notranslate nohighlight">\(x_i\)</span>
the Log Softmax function is shown as follows:</p>
<div class="math notranslate nohighlight">
\[\text{output}(x_i) = \log \left(\frac{exp(x_i)} {\sum_{j = 0}^{N-1}\exp(x_j)}\right),\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the length of the Tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The axis to do the Log softmax operation. Default: -1.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>logits</strong> (Tensor) - The input of Log Softmax.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with the same type and shape as the logits.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.LogicalAnd">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">LogicalAnd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#LogicalAnd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.LogicalAnd" title="Permalink to this definition"></a></dt>
<dd><p>Computes the “logical AND” of two tensors element-wise.</p>
<p>The inputs must be two tensors or one tensor and one bool object.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be bool.
When the inputs are one tensor and one bool object, the bool object cannot be a parameter, only can be a constant,
and the data type of the tensor should be bool.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, bool]) - The first input is a tensor whose data type is bool or a bool object.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, bool]) - The second input is a tensor whose data type is bool or a bool object.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is bool.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logical_and</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">LogicalAnd</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logical_and</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[True, False, False]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.LogicalNot">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">LogicalNot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#LogicalNot"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.LogicalNot" title="Permalink to this definition"></a></dt>
<dd><p>Computes the “logical NOT” of a tensor element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor whose dtype is bool.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the <cite>input_x</cite>, and the dtype is bool.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logical_not</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">LogicalNot</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logical_not</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">[False, True, False]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.LogicalOr">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">LogicalOr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#LogicalOr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.LogicalOr" title="Permalink to this definition"></a></dt>
<dd><p>Computes the “logical OR” of two tensors element-wise.</p>
<p>The inputs must be two tensors or one tensor and one bool object.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be bool.
When the inputs are one tensor and one bool object, the bool object cannot be a parameter, only can be a constant,
and the data type of the tensor should be bool.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, bool]) - The first input is a tensor whose data type is bool or a bool object.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, bool]) - The second input is a tensor whose data type is bool or a bool object.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is bool.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logical_or</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">LogicalOr</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logical_or</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[True, True, True]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.MakeRefKey">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">MakeRefKey</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/other_ops.html#MakeRefKey"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.MakeRefKey" title="Permalink to this definition"></a></dt>
<dd><p>Make a RefKey instance by string. RefKey stores the name of Parameter, can be passed through the functions,
and used for Assign target.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Parameter name to make the RefKey.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><p>No input.</p>
</dd>
<dt>Outputs:</dt><dd><p>RefKeyType, made from the Parameter name.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">make_ref_key</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">MakeRefKey</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_ref_key</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ref</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">make_ref</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">ref</span> <span class="o">*</span> <span class="n">x</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.MatMul">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">MatMul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#MatMul"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.MatMul" title="Permalink to this definition"></a></dt>
<dd><p>Multiplies matrix <cite>a</cite> by matrix <cite>b</cite>.</p>
<p>The rank of input tensors must be <cite>2</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>transpose_a</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, <cite>a</cite> is transposed before multiplication. Default: False.</p></li>
<li><p><strong>transpose_b</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, <cite>b</cite> is transposed before multiplication. Default: False.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The first tensor to be multiplied. The shape of the tensor is <span class="math notranslate nohighlight">\((N, C)\)</span>. If
<cite>transpose_a</cite> is True, its shape should be <span class="math notranslate nohighlight">\((N, C)\)</span> after transposing.</p></li>
<li><p><strong>input_y</strong> (Tensor) - The second tensor to be multiplied. The shape of the tensor is <span class="math notranslate nohighlight">\((C, M)\)</span>. If
<cite>transpose_b</cite> is True, its shape should be <span class="math notranslate nohighlight">\((C, M)\)</span> after transpose.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape of the output tensor is <span class="math notranslate nohighlight">\((N, M)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matmul</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">MatMul</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">matmul</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.MaxPool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">MaxPool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#MaxPool"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.MaxPool" title="Permalink to this definition"></a></dt>
<dd><p>Max pooling operation.</p>
<p>Applies a 2D max pooling over an input Tensor which can be regarded as a composition of 2D planes.</p>
<p>Typically the input is of shape <span class="math notranslate nohighlight">\((N_{in}, C_{in}, H_{in}, W_{in})\)</span>, MaxPool outputs
regional maximum in the <span class="math notranslate nohighlight">\((H_{in}, W_{in})\)</span>-dimension. Given kernel size
<span class="math notranslate nohighlight">\(ks = (h_{ker}, w_{ker})\)</span> and stride <span class="math notranslate nohighlight">\(s = (s_0, s_1)\)</span>, the operation is as follows.</p>
<div class="math notranslate nohighlight">
\[\text{output}(N_i, C_j, h, w) = \max_{m=0, \ldots, h_{ker}-1} \max_{n=0, \ldots, w_{ker}-1}
\text{input}(N_i, C_j, s_0 \times h + m, s_1 \times w + n)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ksize</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The size of kernel used to take the maximum value,
is an int number that represents height and width are both ksize, or a tuple
of two int numbers that represent height and width respectively. Default: 1.</p></li>
<li><p><strong>strides</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The distance of kernel moving, an int number that represents
the height and width of movement are both strides, or a tuple of two int numbers that
represent height and width of movement respectively. Default: 1.</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>The optional values for pad mode, is “same” or “valid”, not case sensitive.
Default: “valid”.</p>
<ul>
<li><p>same: Adopts the way of completion. Output height and width will be the same as
the input. Total number of padding will be calculated for horizontal and vertical
direction and evenly distributed to top and bottom, left and right if possible.
Otherwise, the last extra padding will be done from the bottom and the right side.</p></li>
<li><p>valid: Adopts the way of discarding. The possibly largest height and width of output
will be return without padding. Extra pixels will be discarded.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, C_{in}, H_{in}, W_{in})\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with shape <span class="math notranslate nohighlight">\((N, C_{out}, H_{out}, W_{out})\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">maxpool_op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">MaxPool</span><span class="p">(</span><span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output_tensor</span> <span class="o">=</span> <span class="n">maxpool_op</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.MaxPoolWithArgmax">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">MaxPoolWithArgmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ksize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'valid'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#MaxPoolWithArgmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.MaxPoolWithArgmax" title="Permalink to this definition"></a></dt>
<dd><p>Performs max pooling on the input Tensor and return both max values and indices.</p>
<p>Typically the input is of shape <span class="math notranslate nohighlight">\((N_{in}, C_{in}, H_{in}, W_{in})\)</span>, MaxPool outputs
regional maximum in the <span class="math notranslate nohighlight">\((H_{in}, W_{in})\)</span>-dimension. Given kernel size
<span class="math notranslate nohighlight">\(ks = (h_{ker}, w_{ker})\)</span> and stride <span class="math notranslate nohighlight">\(s = (s_0, s_1)\)</span>, the operation is as follows.</p>
<div class="math notranslate nohighlight">
\[\text{output}(N_i, C_j, h, w) = \max_{m=0, \ldots, h_{ker}-1} \max_{n=0, \ldots, w_{ker}-1}
\text{input}(N_i, C_j, s_0 \times h + m, s_1 \times w + n)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ksize</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The size of kernel used to take the maximum value and arg value,
is an int number that represents height and width are both ksize, or a tuple of
two int numbers that represent height and width respectively. Default: 1.</p></li>
<li><p><strong>strides</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The distance of kernel moving, an int number that represents
the height and width of movement are both strides, or a tuple of two int numbers that
represent height and width of movement respectively. Default: 1.</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>The optional values for pad mode, is “same” or “valid”, not case sensitive.
Default: “valid”.</p>
<ul>
<li><p>same: Adopts the way of completion. Output height and width will be the same as
the input. Total number of padding will be calculated for horizontal and vertical
direction and evenly distributed to top and bottom, left and right if possible.
Otherwise, the last extra padding will be done from the bottom and the right side.</p></li>
<li><p>valid: Adopts the way of discarding. The possibly largest height and width of output
will be return without padding. Extra pixels will be discarded.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, C_{in}, H_{in}, W_{in})\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tuple of 2 Tensor, the maxpool result and where max values from.</p>
<ul class="simple">
<li><p><strong>output</strong> (Tensor) -  Maxpooling result, with shape <span class="math notranslate nohighlight">\((N, C_{out}, H_{out}, W_{out})\)</span>.</p></li>
<li><p><strong>mask</strong> (Tensor) -  Max values’ index represented by the mask.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">maxpool_arg_op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">MaxPoolWithArgmax</span><span class="p">(</span><span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output_tensor</span><span class="p">,</span> <span class="n">argmax</span> <span class="o">=</span> <span class="n">maxpool_arg_op</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Maximum">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Maximum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Maximum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Maximum" title="Permalink to this definition"></a></dt>
<dd><p>Computes the element-wise maximum of input tensors.</p>
<p>The inputs must be two tensors or one tensor and one scalar.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be same.
When the inputs are one tensor and one scalar, the scalar cannot be a parameter, only can be a constant,
and the type of the scalar is the same as the data type of the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, Number]) - The first input is a tensor whose data type is number or a number.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, Number]) - The second input is a tensor whose data type is same as ‘input_x’ or
a number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is same as ‘input_x’.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">maximum</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Maximum</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">maximum</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[4.0, 5.0, 6.0]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Merge">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Merge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/control_ops.html#Merge"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Merge" title="Permalink to this definition"></a></dt>
<dd><p>Merges all input data to one.</p>
<p>One and only one of the inputs should be selected as the output</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (Tuple) - The data to be merged. All tuple elements should have same shape.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>tuple. Output is tuple(<cite>data</cite>, <cite>output_index</cite>). The <cite>data</cite> has the same shape of <cite>inputs</cite> element.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Minimum">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Minimum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Minimum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Minimum" title="Permalink to this definition"></a></dt>
<dd><p>Computes the element-wise minimum of input tensors.</p>
<p>The inputs must be two tensors or one tensor and one scalar.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be same.
When the inputs are one tensor and one scalar, the scalar cannot be a parameter, only can be a constant,
and the type of the scalar is the same as the data type of the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, Number]) - The first input is a tensor whose data type is number or a number.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, Number]) - The second input is a tensor whose data type is same as ‘input_x’ or
a number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is same as ‘input_x’.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">minimum</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Minimum</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">minimum</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[1.0, 2.0, 3.0]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.MirrorPad">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">MirrorPad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#MirrorPad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.MirrorPad" title="Permalink to this definition"></a></dt>
<dd><p>Pads the input tensor according to the paddings and mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>string</em>) – Specifies padding mode. The optional values are “REFLECT”, “SYMMETRIC”.
Default: “REFLECT”.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
<li><dl class="simple">
<dt><strong>paddings</strong> (Tensor) - The paddings tensor. The value of <cite>paddings</cite> is a matrix(list),</dt><dd><p>and its shape is (N, 2). N is the rank of input data. All elements of paddings
are int type. For <cite>D</cite> th dimension of input, paddings[D, 0] indicates how many sizes to be
extended ahead of the <cite>D</cite> th dimension of the input tensor, and paddings[D, 1] indicates
how many sizes to be extended behind of the <cite>D</cite> th dimension of the input tensor.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the tensor after padding.</p>
<ul class="simple">
<li><p>If ‘mode` is “REFLECT”, it uses a way of symmetrical copying throught the axis of symmetry to fill in,
symmetry. If the <cite>input_x</cite> is [[1,2,3],[4,5,6],[7,8,9]] and <cite>paddings</cite> is [[1,1],[2,2]], then the
Outputs is [[6,5,4,5,6,5,4],[3,2,1,2,3,2,1],[6,5,4,5,6,5,4],[9,8,7,8,9,8,7],[6,5,4,5,6,5,4]].</p></li>
<li><p>If ‘mode’ is “SYMMETRIC”, the filling method is similar to the “REFLECT”. It is also copied
according to the symmetry axis, except that it includes the symmetry axis. If the <cite>input_x</cite>
is [[1,2,3],[4,5,6],[7,8,9]] and <cite>paddings</cite> is [[1,1],[2,2]], then the Outputs is
[[2,1,1,2,3,3,2],[2,1,1,2,3,3,2],[5,4,4,5,6,6,5],[8,7,7,8,9,9,8],[8,7,7,8,9,9,8]].</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">pad</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">MirrorPad</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;REFLECT&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">paddings</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">paddings</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pad</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms_output</span> <span class="o">=</span> <span class="n">pad</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">paddings</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Mul">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Mul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Mul"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Mul" title="Permalink to this definition"></a></dt>
<dd><p>Multiplies two tensors element-wise.</p>
<p>The inputs must be two tensors or one tensor and one scalar.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be same.
When the inputs are one tensor and one scalar, the scalar cannot be a parameter, only can be a constant,
and the type of the scalar is the same as the data type of the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, Number]) - The first input is a tensor whose data type is number or a number.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, Number]) - The second input is a tensor whose data type is same as ‘input_x’ or
a number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is same as ‘input_x’.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mul</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Mul</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mul</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[4, 10, 18]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.NMSWithMask">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">NMSWithMask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#NMSWithMask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.NMSWithMask" title="Permalink to this definition"></a></dt>
<dd><p>Select some bounding boxes in descending order of score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>iou_threshold</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Specifies the threshold of overlap boxes with respect to
IOU. Default: 0.5.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the iou_threshold is not a float number, or if the first dimension
    of input Tensor is less than or equal to 0, or if the data type of the input
    Tensor is not float16 or float32.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>bboxes</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((N, 5)\)</span>. Input bounding boxes.
<cite>N</cite> is the number of input bounding boxes. Every bounding box
contains 5 values, the first 4 values are the coordinates of bounding
box, and the last value is the score of this bounding box.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>tuple[Tensor], tuple of three tensors, they are selected_boxes, selected_idx and selected_mask.</p>
<ul class="simple">
<li><p><strong>selected_boxes</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((N, 5)\)</span>. Bounding boxes
list after non-max suppression calculation.</p></li>
<li><p><strong>selected_idx</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((N,)\)</span>. The indexes list of
valid input bounding boxes.</p></li>
<li><p><strong>selected_mask</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((N,)\)</span>. A mask list of
valid output bounding boxes.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bbox</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bbox</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">+=</span> <span class="n">bbox</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bbox</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">+=</span> <span class="n">bbox</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">bbox</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nms</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">NMSWithMask</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output_boxes</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">nms</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.NPUAllocFloatStatus">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">NPUAllocFloatStatus</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#NPUAllocFloatStatus"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.NPUAllocFloatStatus" title="Permalink to this definition"></a></dt>
<dd><p>Allocates a flag to store the overflow status.</p>
<p>The flag is a tensor whose shape is <cite>(8,)</cite> and data type is <cite>mindspore.dtype.float32</cite>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Examples: see <cite>NPUGetFloatStatus</cite>.</p>
</div>
<dl class="simple">
<dt>Outputs:</dt><dd><p>Tensor, has the shape of <cite>(8,)</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">alloc_status</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">NPUAllocFloatStatus</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init</span> <span class="o">=</span> <span class="n">alloc_status</span><span class="p">()</span>
<span class="go">Tensor([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], shape=(8,), dtype=mindspore.float32)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.NPUClearFloatStatus">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">NPUClearFloatStatus</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#NPUClearFloatStatus"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.NPUClearFloatStatus" title="Permalink to this definition"></a></dt>
<dd><p>Clear the flag which stores the overflow status.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The flag is in the register on the <cite>Ascend</cite> device. It will be reset and can not be reused again after the
<cite>NPUClearFloatStatus</cite> is called.</p>
<p>Examples: see <cite>NPUGetFloatStatus</cite>.</p>
</div>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The output tensor of <cite>NPUAllocFloatStatus</cite>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape as <cite>input_x</cite>. All the elements in the tensor will be zero.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">alloc_status</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">NPUAllocFloatStatus</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">get_status</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">NPUGetFloatStatus</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clear_status</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">NPUClearFloatStatus</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init</span> <span class="o">=</span> <span class="n">alloc_status</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">flag</span> <span class="o">=</span> <span class="n">get_status</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clear</span> <span class="o">=</span> <span class="n">clear_status</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
<span class="go">Tensor([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], shape=(8,), dtype=mindspore.float32)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.NPUGetFloatStatus">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">NPUGetFloatStatus</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#NPUGetFloatStatus"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.NPUGetFloatStatus" title="Permalink to this definition"></a></dt>
<dd><p>Updates the flag which is the output tensor of <cite>NPUAllocFloatStatus</cite> with latest overflow status.</p>
<p>The flag is a tensor whose shape is <cite>(8,)</cite> and data type is <cite>mindspore.dtype.float32</cite>.
If the sum of the flag equals 0, there is no overflow happened. If the sum of the flag is bigger than 0, there
is overflow happened.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The output tensor of <cite>NPUAllocFloatStatus</cite>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape as <cite>input_x</cite>. All the elements in the tensor will be zero.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">alloc_status</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">NPUAllocFloatStatus</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">get_status</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">NPUGetFloatStatus</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init</span> <span class="o">=</span> <span class="n">alloc_status</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">flag</span> <span class="o">=</span> <span class="n">get_status</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
<span class="go">Tensor([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], shape=(8,), dtype=mindspore.float32)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Neg">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Neg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Neg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Neg" title="Permalink to this definition"></a></dt>
<dd><p>Returns a tensor with negative values of the input tensor element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor whose dtype is number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape and dtype as input.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.NotEqual">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">NotEqual</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#NotEqual"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.NotEqual" title="Permalink to this definition"></a></dt>
<dd><p>Computes the non-equivalence of two tensors element-wise.</p>
<p>The inputs must be two tensors or one tensor and one scalar.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be same.
When the inputs are one tensor and one scalar, the scalar cannot be a parameter, only can be a constant,
and the type of the scalar is the same as the data type of the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, Number, bool]) - The first input is a tensor whose data type is number or bool, or
a number or a bool object.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, Number, bool]) - The second input tensor whose data type is same as <cite>input_x</cite> or
a number or a bool object.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is bool.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">not_equal</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">NotEqual</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">not_equal</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span>
<span class="go">[True, False, True]</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">not_equal</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">NotEqual</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">not_equal</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[False, False, True]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.OneHot">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">OneHot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#OneHot"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.OneHot" title="Permalink to this definition"></a></dt>
<dd><p>Computes a one-hot tensor.</p>
<p>Makes a new tensor, whose locations represented by indices in <cite>indices</cite> take value <cite>on_value</cite>, while all
other locations take value <cite>off_value</cite>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the input indices is rank <cite>N</cite>, the output will have rank <cite>N+1</cite>. The new axis is created at dimension <cite>axis</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Position to insert the value. e.g. If <cite>indices</cite> shape is [n, c], and <cite>axis</cite> is <cite>-1</cite> the output shape
will be [n, c, depth], If <cite>axis</cite> is <cite>0</cite> the output shape will be [depth, n, c]. Default: -1.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>indices</strong> (Tensor) - A tensor of indices. Tensor of shape <span class="math notranslate nohighlight">\((X_0, \ldots, X_n)\)</span>.</p></li>
<li><p><strong>depth</strong> (int) - A scalar defining the depth of the one hot dimension.</p></li>
<li><p><strong>on_value</strong> (Tensor) - A value to fill in output when <cite>indices[j] = i</cite>.</p></li>
<li><p><strong>off_value</strong> (Tensor) - A value to fill in output when <cite>indices[j] != i</cite>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, one_hot tensor. Tensor of shape <span class="math notranslate nohighlight">\((X_0, \ldots, X_{axis}, \text{depth} ,X_{axis+1}, \ldots, X_n)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">depth</span><span class="p">,</span> <span class="n">on_value</span><span class="p">,</span> <span class="n">off_value</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">onehot</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">OneHot</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">onehot</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">on_value</span><span class="p">,</span> <span class="n">off_value</span><span class="p">)</span>
<span class="go">[[1, 0, 0], [0, 1, 0], [0, 0, 1]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.OnesLike">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">OnesLike</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#OnesLike"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.OnesLike" title="Permalink to this definition"></a></dt>
<dd><p>Creates a new tensor. All elements’ value are 1.</p>
<p>Returns a tensor of ones with the same shape and type as the input.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - Input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape and type as <cite>input_x</cite> but filled with ones.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">oneslike</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">OnesLike</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">oneslike</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.PReLU">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">PReLU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#PReLU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.PReLU" title="Permalink to this definition"></a></dt>
<dd><p>Parametric Rectified Linear Unit activation function.</p>
<p>PReLU is described in the paper <a class="reference external" href="https://arxiv.org/abs/1502.01852">Delving Deep into Rectifiers: Surpassing Human-Level Performance on
ImageNet Classification</a>. Defined as follows:</p>
<div class="math notranslate nohighlight">
\[prelu(x_i)= \max(0, x_i) + \min(0, w * x_i),\]</div>
<p>where <span class="math notranslate nohighlight">\(x_i\)</span> is an element of an channel of the input.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - Float tensor, representing the output of the preview layer.</p></li>
<li><p><strong>weight</strong> (Tensor) -  Float Tensor, w &gt; 0, there is only two shapes are legitimate,
1 or the number of channels at input.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with the same type as <cite>input_x</cite>.</p>
</dd>
</dl>
<p>Detailed information, please refer to <cite>nn.PReLU</cite>.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Pack">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Pack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Pack"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Pack" title="Permalink to this definition"></a></dt>
<dd><p>Packs a list of tensors in specified axis.</p>
<p>Packs the list of input tensors with the same rank <cite>R</cite>, output is a tensor of rank <cite>(R+1)</cite>.</p>
<p>Given input tensors of shape <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>. Set the number of input tensors as <cite>N</cite>.
If <span class="math notranslate nohighlight">\(0 \le axis\)</span>, the output tensor shape is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_{axis}, N, x_{axis+1}, ..., x_R)\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Dimension along which to pack. Default: 0.
Negative values wrap around. The range is [-(R+1), R+1).</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[tuple, list]) - A Tuple or list of Tensor objects with the same shape and type.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor. A packed Tensor with the same type as <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data1</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data2</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pack</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Pack</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">pack</span><span class="p">([</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">])</span>
<span class="go">[[0, 1], [2, 3]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Pad">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Pad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#Pad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Pad" title="Permalink to this definition"></a></dt>
<dd><p>Pads input tensor according to the paddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>paddings</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – The shape of parameter <cite>paddings</cite> is (N, 2). N is the rank of input data. All elements of
paddings are int type. For <cite>D</cite> th dimension of input, paddings[D, 0] indicates how many sizes to be
extended ahead of the <cite>D</cite> th dimension of the input tensor, and paddings[D, 1] indicates how many sizes to
be extended behind of the <cite>D</cite> th dimension of the input tensor.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the tensor after padding.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pad_op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Pad</span><span class="p">(((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output_tensor</span> <span class="o">=</span> <span class="n">pad_op</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">output_tensor</span> <span class="o">==</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span> <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.</span> <span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                                         <span class="p">[</span> <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span>  <span class="mf">0.3</span><span class="p">,</span>  <span class="mf">3.6</span><span class="p">,</span>  <span class="mf">0.</span> <span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                                         <span class="p">[</span> <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.4</span><span class="p">,</span>  <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">,</span>  <span class="mf">0.</span> <span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                                         <span class="p">[</span> <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.</span> <span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                                         <span class="p">[</span> <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.</span> <span class="p">,</span>  <span class="mf">0.</span> <span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Pow">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Pow</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Pow"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Pow" title="Permalink to this definition"></a></dt>
<dd><p>Computes a tensor to the power of the second input.</p>
<p>The first input must be a tensor, and the second input should be a tensor or a number.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be the same.
When the inputs are one tensor and one scalar, the scalar could not be a parameter,
only could be a constant, and the type of the scalar is the same as the data type of the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor]) - The first input is a tensor whose data type is number.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, Number]) - The second input is a tensor whose data type is same as ‘input_x’ or
a number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is same as ‘input_x’.</p>
</dd>
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, Number]) - The exponent part. If exponent is a tensor, its shape must be able to
broadcast to the shape of the <cite>input_x</cite>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape as the <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="mf">3.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">pow</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Pow</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">pow</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[1.0, 8.0, 64.0]</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">pow</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Pow</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">pow</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[1.0, 16.0, 64.0]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Print">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Print</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/debug_ops.html#Print"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Print" title="Permalink to this definition"></a></dt>
<dd><p>Output tensor or string to stdout.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The print operation cannot support float64 and bool types currently.</p>
</div>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, str]) - The graph node to attach to. The input supports
multiple strings and tensors which are separated by ‘,’.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">PrintDemo</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">PrintDemo</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">print</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Print</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="s1">&#39;Print Tensor x and Tensor y:&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ROIAlign">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ROIAlign</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#ROIAlign"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ROIAlign" title="Permalink to this definition"></a></dt>
<dd><p>Computes Region of Interest (RoI) Align operator.</p>
<p>The operator computes the value of each sampling point by bilinear interpolation from the nearby grid points on the
feature map. No quantization is performed on any coordinates involved in the RoI, its bins, or the sampling
points. The details of (RoI) Align operator are described in <a class="reference external" href="https://arxiv.org/abs/1703.06870">Mask R-CNN</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pooled_height</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The output features’ height.</p></li>
<li><p><strong>pooled_width</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The output features’ width.</p></li>
<li><p><strong>spatial_scale</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – A scaling factor that maps the raw image coordinates to the input
feature map coordinates. Suppose the height of a RoI is <cite>ori_h</cite> in the raw image and <cite>fea_h</cite> in the
input feature map, the <cite>spatial_scale</cite> should be <cite>fea_h / ori_h</cite>.</p></li>
<li><p><strong>sample_num</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of sampling points. Default: 2.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>features</strong> (Tensor) - The input features, whose shape should be <cite>(N, C, H, W)</cite>.</p></li>
<li><p><strong>rois</strong> (Tensor) - The shape is <cite>(rois_n, 5)</cite>. <cite>rois_n</cite> represents the number of RoI. The size of
the second dimension should be <cite>5</cite> and the <cite>5</cite> colunms are
<cite>(image_index, top_left_x, top_left_y, bottom_right_x, bottom_right_y)</cite>. <cite>image_index</cite> represents the
index of image. <cite>top_left_x</cite> and <cite>top_left_y</cite> represent the <cite>x, y</cite> coordinates of the top left corner
of corresponding RoI, respectively. <cite>bottom_right_x</cite> and <cite>bottom_right_y</cite> represent the <cite>x, y</cite>
coordinates of the bottom right corner of corresponding RoI, respectively.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is <cite>(rois_n, C, pooled_height, pooled_width)</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">]]]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rois</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roi_align</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ROIAlign</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output_tensor</span> <span class="o">=</span> <span class="n">roi_align</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">rois</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">output_tensor</span> <span class="o">==</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mf">2.15</span><span class="p">]]]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.RandomChoiceWithMask">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">RandomChoiceWithMask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/random_ops.html#RandomChoiceWithMask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.RandomChoiceWithMask" title="Permalink to this definition"></a></dt>
<dd><p>Generates a random samply as index tensor with a mask tensor from a given tensor.</p>
<p>The input must be a tensor of rank &gt;= 1. If its rank &gt;= 2, the first dimension specify the number of sample.
The index tensor and the mask tensor have the fixed shapes. The index tensor denotes the index of the nonzero
sample, while the mask tensor denotes which elements in the index tensor are valid.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>count</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of items expected to get and the number should be greater than 0. Default: 256.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Random seed. Default: 0.</p></li>
<li><p><strong>seed2</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Random seed2. Default: 0.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor[bool]) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Two tensors, the first one is the index tensor and the other one is the mask tensor.</p>
<ul class="simple">
<li><p><strong>index</strong> (Tensor) - The output has shape between 2-D and 5-D.</p></li>
<li><p><strong>mask</strong> (Tensor) - The output has shape 1-D.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rnd_choice_mask</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">RandomChoiceWithMask</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">240000</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output_y</span><span class="p">,</span> <span class="n">output_mask</span> <span class="o">=</span> <span class="n">rnd_choice_mask</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Rank">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Rank</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Rank"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Rank" title="Permalink to this definition"></a></dt>
<dd><p>Returns the rank of a tensor.</p>
<p>Returns a 0-D int32 Tensor representing the rank of input; the rank of a tensor
is the number of indices required to uniquely select each element of the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor. 0-D int32 Tensor representing the rank of input, i.e., <span class="math notranslate nohighlight">\(R\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rank</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Rank</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rank</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ReLU">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ReLU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#ReLU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ReLU" title="Permalink to this definition"></a></dt>
<dd><p>Computes ReLU(Rectified Linear Unit) of input tensor element-wise.</p>
<p>It returns <span class="math notranslate nohighlight">\(\max(x,\  0)\)</span> element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with the same type and shape as the <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">relu</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">[[0, 4.0, 0.0], [2.0, 0.0, 9.0]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ReLU6">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ReLU6</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#ReLU6"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ReLU6" title="Permalink to this definition"></a></dt>
<dd><p>Computes ReLU(Rectified Linear Unit) upper bounded by 6 of input tensor element-wise.</p>
<p>It returns <span class="math notranslate nohighlight">\(\min(\max(0,x), 6)\)</span> element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with the same type and shape as the <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">relu6</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReLU6</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">relu6</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ReLUV2">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ReLUV2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#ReLUV2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ReLUV2" title="Permalink to this definition"></a></dt>
<dd><p>Computes ReLU(Rectified Linear Unit) of input tensor element-wise.</p>
<p>It returns <span class="math notranslate nohighlight">\(\max(x,\  0)\)</span> element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor should be a 4-D tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><ul class="simple">
<li><p><strong>output</strong> (Tensor) - Has the same type and shape as the <cite>input_x</cite>.</p></li>
<li><p><strong>mask</strong> (Tensor) - A tensor whose data type must be uint8.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="p">[[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">8</span><span class="p">]]]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">relu_v2</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReLUV2</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">relu_v2</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">([[[[1., 0.], [0., 4.]], [[0., 6.], [7., 0.]]]],</span>
<span class="go"> [[[[1, 0], [2, 0]], [[2, 0], [1, 0]]]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.RealDiv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">RealDiv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#RealDiv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.RealDiv" title="Permalink to this definition"></a></dt>
<dd><p>Divide the first input tensor by the second input tensor in floating-point type element-wise.</p>
<p>The inputs must be two tensors or one tensor and one scalar.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be same.
When the inputs are one tensor and one scalar, the scalar cannot be a parameter, only can be a constant,
and the type of the scalar is the same as the data type of the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, Number]) - The first input is a tensor whose data type is number or a number.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, Number]) - The second input is a tensor whose data type is same as ‘input_x’ or
a number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is same as ‘input_x’.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">realdiv</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">RealDiv</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">realdiv</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[0.25, 0.4, 0.5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Reciprocal">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Reciprocal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Reciprocal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Reciprocal" title="Permalink to this definition"></a></dt>
<dd><p>Returns reciprocal of a tensor element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape as the <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reciprocal</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Reciprocal</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reciprocal</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">[1.0, 0.5, 0.25]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ReduceAll">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ReduceAll</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#ReduceAll"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ReduceAll" title="Permalink to this definition"></a></dt>
<dd><p>Reduce a dimension of a tensor by the “logical and” of all elements in the dimension.</p>
<p>The dtype of the tensor to be reduced is bool.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, keep these reduced dimensions and the length is 1.
If False, don’t keep these dimensions.
Default : False, don’t keep these reduced dimensions.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor[bool]) - The input tensor.</p></li>
<li><p><strong>axis</strong> (Union[int, tuple(int), list(int)]) - The dimensions to reduce. Default: (), reduce all dimensions.
Only constant value is allowed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the dtype is bool.</p>
<ul class="simple">
<li><p>If axis is (), and keep_dims is false,
the output is a 0-D tensor representing the “logical and” of of all elements in the input tensor.</p></li>
<li><p>If axis is int, set as 2, and keep_dims is false,
and keep_dims is false, the shape of output is <span class="math notranslate nohighlight">\((x_1, x_3, ..., x_R)\)</span>.</p></li>
<li><p>If axis is tuple(int), set as (2, 3), and keep_dims is false,
the shape of output is <span class="math notranslate nohighlight">\((x_1, x_4, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceAll</span><span class="p">(</span><span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ReduceMax">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ReduceMax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#ReduceMax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ReduceMax" title="Permalink to this definition"></a></dt>
<dd><p>Reduce a dimension of a tensor by the maximum value in this dimension.</p>
<p>The dtype of the tensor to be reduced is number.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, keep these reduced dimensions and the length is 1.
If False, don’t keep these dimensions.
Default : False, don’t keep these reduced dimensions.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor[Number]) - The input tensor.</p></li>
<li><p><strong>axis</strong> (Union[int, tuple(int), list(int)]) - The dimensions to reduce. Default: (), reduce all dimensions.
Only constant value is allowed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same dtype as the ‘input_x’.</p>
<ul class="simple">
<li><p>If axis is (), and keep_dims is false,
the output is a 0-D tensor representing the maximum of all elements in the input tensor.</p></li>
<li><p>If axis is int, set as 2, and keep_dims is false,
the shape of output is <span class="math notranslate nohighlight">\((x_1, x_3, ..., x_R)\)</span>.</p></li>
<li><p>If axis is tuple(int), set as (2, 3), and keep_dims is false,
the shape of output is <span class="math notranslate nohighlight">\((x_1, x_4, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceMax</span><span class="p">(</span><span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ReduceMean">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ReduceMean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#ReduceMean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ReduceMean" title="Permalink to this definition"></a></dt>
<dd><blockquote>
<div><p>Reduce a dimension of a tensor by averaging all elements in the dimension.</p>
<p>The dtype of the tensor to be reduced is number.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, keep these reduced dimensions and the length is 1.
If False, don’t keep these dimensions. Default : False.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor[Number]) - The input tensor.</p></li>
<li><p><strong>axis</strong> (Union[int, tuple(int), list(int)]) - The dimensions to reduce. Default: (), reduce all dimensions.
Only constant value is allowed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same dtype as the ‘input_x’.</p>
<ul class="simple">
<li><p>If axis is (), and keep_dims is false,
the output is a 0-D tensor representing the sum of all elements in the input tensor.</p></li>
<li><p>If axis is int, set as 2, and keep_dims is false,
the shape of output is <span class="math notranslate nohighlight">\((x_1, x_3, ..., x_R)\)</span>.</p></li>
<li><p>If axis is tuple(int), set as (2, 3), and keep_dims is false,
the shape of output is <span class="math notranslate nohighlight">\((x_1, x_4, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">(</span><span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ReduceMin">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ReduceMin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#ReduceMin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ReduceMin" title="Permalink to this definition"></a></dt>
<dd><p>Reduce a dimension of a tensor by the minimum value in the dimension.</p>
<p>The dtype of the tensor to be reduced is number.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, keep these reduced dimensions and the length is 1.
If False, don’t keep these dimensions.
Default : False, don’t keep these reduced dimensions.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor[Number]) - The input tensor.</p></li>
<li><p><strong>axis</strong> (Union[int, tuple(int), list(int)]) - The dimensions to reduce. Default: (), reduce all dimensions.
Only constant value is allowed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same dtype as the ‘input_x’.</p>
<ul class="simple">
<li><p>If axis is (), and keep_dims is false,
the output is a 0-D tensor representing the minimum of all elements in the input tensor.</p></li>
<li><p>If axis is int, set as 2, and keep_dims is false,
the shape of output is <span class="math notranslate nohighlight">\((x_1, x_3, ..., x_R)\)</span>.</p></li>
<li><p>If axis is tuple(int), set as (2, 3), and keep_dims is false,
the shape of output is <span class="math notranslate nohighlight">\((x_1, x_4, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceMin</span><span class="p">(</span><span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ReduceOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ReduceOp</span></span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/comm_ops.html#ReduceOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ReduceOp" title="Permalink to this definition"></a></dt>
<dd><p>Operation options for reduce tensors.</p>
<p>There are four kinds of operation options, “SUM”,”MAX”,”MIN”,”PROD”.</p>
<blockquote>
<div><ul class="simple">
<li><p>SUM: Take the sum.</p></li>
<li><p>MAX: Take the maximum.</p></li>
<li><p>MIN: Take the minimum.</p></li>
<li><p>PROD: Take the product.</p></li>
</ul>
</div></blockquote>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ReduceProd">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ReduceProd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#ReduceProd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ReduceProd" title="Permalink to this definition"></a></dt>
<dd><p>Reduce a dimension of a tensor by multiplying all elements in the dimension.</p>
<p>The dtype of the tensor to be reduced is number.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, keep these reduced dimensions and the length is 1.
If False, don’t keep these dimensions.
Default : False, don’t keep these reduced dimensions.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor[Number]) - The input tensor.</p></li>
<li><p><strong>axis</strong> (Union[int, tuple(int), list(int)]) - The dimensions to reduce. Default: (), reduce all dimensions.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same dtype as the ‘input_x’.</p>
<ul class="simple">
<li><p>If axis is (), and keep_dims is false,
the output is a 0-D tensor representing the product of all elements in the input tensor.</p></li>
<li><p>If axis is int, set as 2, and keep_dims is false,
the shape of output is <span class="math notranslate nohighlight">\((x_1, x_3, ..., x_R)\)</span>.</p></li>
<li><p>If axis is tuple(int), set as (2, 3), and keep_dims is false,
the shape of output is <span class="math notranslate nohighlight">\((x_1, x_4, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceProd</span><span class="p">(</span><span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ReduceScatter">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ReduceScatter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/comm_ops.html#ReduceScatter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ReduceScatter" title="Permalink to this definition"></a></dt>
<dd><blockquote>
<div><p>Reduces and scatters tensors from the specified communication group.</p>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The back propagation of the op is not surported yet. Stay tuned for more.
Tensor must have the same shape and format in all processes participating in the collective.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>op</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Specifies an operation used for element-wise reductions,
like sum, max, avg. Default: ReduceOp.SUM.</p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The communication group to work on. Default: “hccl_world_group”.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If any of op and group is not a string</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the first dimension of input can not be divided by rank size.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init</span><span class="p">(</span><span class="s1">&#39;nccl&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">reducescatter</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceScatter</span><span class="p">(</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s2">&quot;nccl_world_group&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reducescatter</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ReduceSum">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ReduceSum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#ReduceSum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ReduceSum" title="Permalink to this definition"></a></dt>
<dd><p>Reduce a dimension of a tensor by summing all elements in the dimension.</p>
<p>The dtype of the tensor to be reduced is number.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, keep these reduced dimensions and the length is 1.
If False, don’t keep these dimensions. Default : False.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor[Number]) - The input tensor.</p></li>
<li><p><strong>axis</strong> (Union[int, tuple(int), list(int)]) - The dimensions to reduce. Default: (), reduce all dimensions.
Only constant value is allowed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same dtype as the ‘input_x’.</p>
<ul class="simple">
<li><p>If axis is (), and keep_dims is false,
the output is a 0-D tensor representing the sum of all elements in the input tensor.</p></li>
<li><p>If axis is int, set as 2, and keep_dims is false,
the shape of output is <span class="math notranslate nohighlight">\((x_1, x_3, ..., x_R)\)</span>.</p></li>
<li><p>If axis is tuple(int), set as (2, 3), and keep_dims is false,
the shape of output is <span class="math notranslate nohighlight">\((x_1, x_4, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">(</span><span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Reshape">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Reshape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Reshape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Reshape" title="Permalink to this definition"></a></dt>
<dd><p>Reshapes input tensor with the same values based on a given shape tuple.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Given a shape tuple, if it has more than one -1; or if the product
    of its elements is less than or equal to 0 or cannot be divided by the product
    of the input tensor shape; or if it does not match the input’s array size.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
<li><p><strong>input_shape</strong> (tuple[int]) - The input tuple is constructed by multiple
integers, i.e., <span class="math notranslate nohighlight">\((y_1, y_2, ..., y_S)\)</span>. Only constant value is allowed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape of tensor is <span class="math notranslate nohighlight">\((y_1, y_2, ..., y_S)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reshape</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Reshape</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ResizeBilinear">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ResizeBilinear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#ResizeBilinear"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ResizeBilinear" title="Permalink to this definition"></a></dt>
<dd><p>Resizes the image to certain size using bilinear interpolation.</p>
<p>The resizing only affects the lower two dimensions which represent the height and width. The input images
can be represented by different data types, but the data types of output images are always float32.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – A tuple of 2 int elements <cite>(new_height, new_width)</cite>, the new size for the images.</p></li>
<li><p><strong>align_corners</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If it’s true, rescale input by <cite>(new_height - 1) / (height - 1)</cite>,
which exactly aligns the 4 corners of images and resized images. If it’s false,
rescale by <cite>new_height / height</cite>. Default: False.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor) - Image to be resized. Tensor of shape <cite>(N_i, …, N_n, height, width)</cite>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, resized image. Tensor of shape <cite>(N_i, …, N_n, new_height, new_width)</cite> in <cite>float32</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]]],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">resize_bilinear</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ResizeBilinear</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">resize_bilinear</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="p">()</span> <span class="o">==</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ResizeNearestNeighbor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ResizeNearestNeighbor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#ResizeNearestNeighbor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ResizeNearestNeighbor" title="Permalink to this definition"></a></dt>
<dd><p>Resize the input tensor by using nearest neighbor algorithm.</p>
<p>Resize input tensor to given size by using nearest neighbor algorithm. The nearest
neighbor algorithm selects the value of the nearest point and does not consider the
values of neighboring points at all, yielding a piecewise-constant interpolant.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>]</em>) – The target size. The dimension of size must be 2.</p></li>
<li><p><strong>align_corners</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether the centers of the 4 corner pixels of the input
and output tensors are aligned. Default: False.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor. The shape of the tensor is <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape of the output tensor is <span class="math notranslate nohighlight">\((N, NEW\_C, NEW\_H, W)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">resize</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ResizeNearestNeighbor</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">resize</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Round">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Round</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Round"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Round" title="Permalink to this definition"></a></dt>
<dd><p>Returns half to even of a tensor element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape and type as the <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.5</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">round</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Round</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">round</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">[1.0, 2.0, 2.0, 2.0, -4.0]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Rsqrt">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Rsqrt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Rsqrt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Rsqrt" title="Permalink to this definition"></a></dt>
<dd><p>Computes reciprocal of square root of input tensor element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input of Rsqrt. Each element should be a non-negative number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same type and shape as <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">]],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rsqrt</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Rsqrt</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rsqrt</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
<span class="go">[[0.5, 0.5], [0.333333, 0.333333]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.SGD">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">SGD</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#SGD"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.SGD" title="Permalink to this definition"></a></dt>
<dd><p>Computes stochastic gradient descent (optionally with momentum).</p>
<p>Nesterov momentum is based on the formula from On the importance of
initialization and momentum in deep learning.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For details, please refer to <cite>nn.SGD</cite> source code.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dampening</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The dampening for momentum. Default: 0.0.</p></li>
<li><p><strong>weight_decay</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Weight decay (L2 penalty). Default: 0.0.</p></li>
<li><p><strong>nesterov</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Enable Nesterov momentum. Default: False.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>parameters</strong> (Tensor) - Parameters to be updated. Their data type can be list or tuple.</p></li>
<li><p><strong>gradient</strong> (Tensor) - Gradients.</p></li>
<li><p><strong>learning_rate</strong> (Tensor) - Learning rate. Must be float value. e.g. Tensor(0.1, mindspore.float32).</p></li>
<li><p><strong>accum</strong> (Tensor) - Accum(velocity) to be updated.</p></li>
<li><p><strong>momentum</strong> (Tensor) - Momentum. e.g. Tensor(0.1, mindspore.float32).</p></li>
<li><p><strong>stat</strong> (Tensor) - States to be updated with the same shape as gradient.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, parameters to be updated.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.SameTypeShape">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">SameTypeShape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#SameTypeShape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.SameTypeShape" title="Permalink to this definition"></a></dt>
<dd><p>Checks whether data type and shape of two tensors are the same.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If not the same.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
<li><p><strong>input_y</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_S)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>,
if data type and shape of <cite>input_x</cite> and <cite>input_y</cite> are the same.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">SameTypeShape</span><span class="p">()(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ScalarCast">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ScalarCast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/inner_ops.html#ScalarCast"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ScalarCast" title="Permalink to this definition"></a></dt>
<dd><p>Cast the input scalar to another type.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (scalar) - The input scalar. Only constant value is allowed.</p></li>
<li><p><strong>input_y</strong> (mindspore.dtype) - The type should cast to be. Only constant value is allowed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Scalar. The type is same as the python type corresponding to <cite>input_y</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">scalar_cast</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ScalarCast</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">scalar_cast</span><span class="p">(</span><span class="mf">255.0</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ScalarSummary">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ScalarSummary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/debug_ops.html#ScalarSummary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ScalarSummary" title="Permalink to this definition"></a></dt>
<dd><p>Output scalar to protocol buffer through scalar summary operator.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>name</strong> (str) - The name of the input variable.</p></li>
<li><p><strong>value</strong> (Tensor) - The value of scalar.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">SummaryDemo</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">SummaryDemo</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">summary</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ScalarSummary</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">TensorAdd</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;x&quot;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ScalarToArray">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ScalarToArray</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#ScalarToArray"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ScalarToArray" title="Permalink to this definition"></a></dt>
<dd><p>Converts scalar to <cite>Tensor</cite>.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[int, float]) - The input is a scalar. Only constant value is allowed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor. 0-D Tensor and the content is the input.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ScalarToArray</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ScalarToTensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ScalarToTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#ScalarToTensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ScalarToTensor" title="Permalink to this definition"></a></dt>
<dd><p>Converts scalar to <cite>Tensor</cite>, and convert data type to specified type.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[int, float]) - The input is a scalar. Only constant value is allowed.</p></li>
<li><p><strong>dtype</strong> (mindspore.dtype) - The target data type. Default: mindspore.float32. Only
constant value is allowed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor. 0-D Tensor and the content is the input.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ScalarToTensor</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ScatterNd">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ScatterNd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#ScatterNd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ScatterNd" title="Permalink to this definition"></a></dt>
<dd><p>Scatters a tensor into a new tensor depending on the specified indices.</p>
<p>Creates an empty tensor, and set values by scattering the update tensor depending on indices.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>indices</strong> (Tensor) - The index of scattering in the new tensor.</p></li>
<li><p><strong>update</strong> (Tensor) - The source Tensor to be scattered.</p></li>
<li><p><strong>shape</strong> (tuple[int]) - Define the shape of the output tensor. Has the same type as indices.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the new tensor, has the same type as <cite>update</cite> and the same shape as <cite>shape</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ScatterNd</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">update</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">3.2</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ScatterNdUpdate">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ScatterNdUpdate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#ScatterNdUpdate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ScatterNdUpdate" title="Permalink to this definition"></a></dt>
<dd><p>Update tensor value by using input indices and value.</p>
<p>Using given values to update tensor value, along with the input indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>use_locking</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether protect the assignment by a lock. Defaule: True.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The target tensor.</p></li>
<li><p><strong>indices</strong> (Tensor) - The index of input tensor.</p></li>
<li><p><strong>update</strong> (Tensor) - The tensor to add to the input tensor, has the same type as input.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape and type as <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">update</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ScatterNdUpdate</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">update</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Select">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Select</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Select"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Select" title="Permalink to this definition"></a></dt>
<dd><p>Return the selected elements, either from input <span class="math notranslate nohighlight">\(x\)</span> or input <span class="math notranslate nohighlight">\(y\)</span>, depending on the <cite>condition</cite>.</p>
<p>Given a tensor as input, this operation inserts a dimension of 1 at the dimension,
if both <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> are none, the operation returns the coordinates of the true
element in the condition, the coordinates are returned as a two-dimensional
tensor, where the first dimension (row) represents the number of true elements
and the second dimension (columns) represents the coordinates of the true
elements. Keep in mind that the shape of the output tensor can vary depending
on how much of the true value is in the input. Indexes are output in row-first
order.</p>
<p>If neither is None, <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> must have the same shape. If <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> are
scalars, the conditional tensor must be a scalar. If <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> are
higher-demensional vectors, the condition must be a vector whose size matches the
first dimension of <span class="math notranslate nohighlight">\(x\)</span>, or must have the same shape as <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>The conditional tensor acts as an optional compensation (mask), which
determines whether the corresponding element / row in the output should be
selected from <span class="math notranslate nohighlight">\(x\)</span> (if true) or <span class="math notranslate nohighlight">\(y\)</span> (if false) based on the value of each
element.</p>
<p>If condition is a vector, then <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> are higher-demensional matrices, then it
chooses to copy that row (external dimensions) from <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span>. If condition has
the same shape as <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span>, you can choose to copy these elements from <span class="math notranslate nohighlight">\(x\)</span>
and <span class="math notranslate nohighlight">\(y\)</span>.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor[bool]) - The shape is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_N)\)</span>.
The condition tensor, decides whose element is chosen.</p></li>
<li><p><strong>input_y</strong> (Tensor) - The shape is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_N, ..., x_R)\)</span>.
The first input tensor.</p></li>
<li><p><strong>input_z</strong> (Tensor) - The shape is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_N, ..., x_R)\)</span>.
The second input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape as input_y. The shape is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_N, ..., x_R)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">select</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Select</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_z</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">select</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">,</span> <span class="n">input_z</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Shape">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Shape" title="Permalink to this definition"></a></dt>
<dd><p>Returns the shape of input tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>tuple[int], the output tuple is constructed by multiple integers,
<span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Shape</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">shape</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Sigmoid">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Sigmoid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#Sigmoid"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Sigmoid" title="Permalink to this definition"></a></dt>
<dd><p>Sigmoid activation function.</p>
<p>Computes Sigmoid of input element-wise. The Sigmoid function is defined as:</p>
<div class="math notranslate nohighlight">
\[\text{sigmoid}(x_i) = \frac{1}{1 + exp(-x_i)},\]</div>
<p>where <span class="math notranslate nohighlight">\(x_i\)</span> is the element of the input.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input of Sigmoid.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with the same type and shape as the input_x.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.SigmoidCrossEntropyWithLogits">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">SigmoidCrossEntropyWithLogits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#SigmoidCrossEntropyWithLogits"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.SigmoidCrossEntropyWithLogits" title="Permalink to this definition"></a></dt>
<dd><p>Uses the given logits to compute sigmoid cross entropy.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Sets input logits as <cite>X</cite>, input label as <cite>Y</cite>, output as <cite>loss</cite>. Then,</p>
<div class="math notranslate nohighlight">
\[p_{ij} = sigmoid(X_{ij}) = \frac{1}{1 + e^{-X_{ij}}}\]</div>
<div class="math notranslate nohighlight">
\[loss_{ij} = -[Y_{ij} * ln(p_{ij}) + (1 - Y_{ij})ln(1 - p_{ij})]\]</div>
</div>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>logits</strong> (Tensor) - Input logits.</p></li>
<li><p><strong>label</strong> (Tensor) - Ground truth label.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with the same shape and type as input <cite>logits</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Sign">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Sign</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Sign"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Sign" title="Permalink to this definition"></a></dt>
<dd><p>Perform <span class="math notranslate nohighlight">\(sign\)</span> on tensor element-wise.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<div class="math notranslate nohighlight">
\[sign(x) = \begin{cases} -1, &amp;if\ x &lt; 0 \cr
0, &amp;if\ x == 0 \cr
1, &amp;if\ x &gt; 0\end{cases}\]</div>
</div>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape and type as the <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sign</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Sign</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">sign</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">[[1.0, 0.0, -1.0]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Sin">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Sin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Sin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Sin" title="Permalink to this definition"></a></dt>
<dd><p>Computes sine of input element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape as <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sin</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Sin</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.62</span><span class="p">,</span> <span class="mf">0.28</span><span class="p">,</span> <span class="mf">0.43</span><span class="p">,</span> <span class="mf">0.62</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">sin</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Size">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Size" title="Permalink to this definition"></a></dt>
<dd><p>Returns the elements count size of a tensor.</p>
<p>Returns an int scalar representing the elements size of input, the total number of elements in the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>int, a scalar representing the elements size of <cite>input_x</cite>, tensor is the number of elements
in a tensor, <span class="math notranslate nohighlight">\(size=x_1*x_2*...x_R\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">size</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Size</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">size</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Slice">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Slice</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Slice"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Slice" title="Permalink to this definition"></a></dt>
<dd><p>Slice a tensor in specified shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The target tensor.</p></li>
<li><p><strong>begin</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – The beginning of the slice. Only constant value is allowed.</p></li>
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – The size of the slice. Only constant value is allowed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span>
<span class="gp">&gt;&gt;&gt; </span>                        <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span>
<span class="gp">&gt;&gt;&gt; </span>                        <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Slice</span><span class="p">()(</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.SmoothL1Loss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">SmoothL1Loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#SmoothL1Loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.SmoothL1Loss" title="Permalink to this definition"></a></dt>
<dd><p>Computes smooth L1 loss, a robust L1 loss.</p>
<p>SmoothL1Loss is a Loss similar to MSELoss but less sensitive to outliers as described in the
<a class="reference external" href="https://arxiv.org/abs/1504.08083">Fast R-CNN</a> by Ross Girshick.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Sets input prediction as <cite>X</cite>, input target as <cite>Y</cite>, output as <cite>loss</cite>. Then,</p>
<div class="math notranslate nohighlight">
\[\text{SmoothL1Loss} = \begin{cases}0.5x^{2}, &amp;if \left |x \right |\leq \text{sigma} \cr
\left |x \right|-0.5, &amp;\text{otherwise}\end{cases}\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>sigma</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – A parameter used to control the point where the function will change from
quadratic to linear. Default: 1.0.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>prediction</strong> (Tensor) - Predict data.</p></li>
<li><p><strong>target</strong> (Tensor) - Ground truth data, with the same type and shape as <cite>prediction</cite>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with the same type and shape as <cite>prediction</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Softmax">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#Softmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Softmax" title="Permalink to this definition"></a></dt>
<dd><p>Softmax operation.</p>
<p>Applies the Softmax operation to the input tensor on the specified axis.
Suppose a slice along the given aixs <span class="math notranslate nohighlight">\(x\)</span> then for each element <span class="math notranslate nohighlight">\(x_i\)</span>
the Softmax function is shown as follows:</p>
<div class="math notranslate nohighlight">
\[\text{output}(x_i) = \frac{exp(x_i)}{\sum_{j = 0}^{N-1}\exp(x_j)},\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the length of the tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – The axis to do the Softmax operation. Default: -1.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>logits</strong> (Tensor) - The input of Softmax.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with the same type and shape as the logits.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.SoftmaxCrossEntropyWithLogits">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">SoftmaxCrossEntropyWithLogits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#SoftmaxCrossEntropyWithLogits"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.SoftmaxCrossEntropyWithLogits" title="Permalink to this definition"></a></dt>
<dd><p>Gets the softmax cross-entropy value between logits and labels which shoule be one-hot encoding.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Sets input logits as <cite>X</cite>, input label as <cite>Y</cite>, output as <cite>loss</cite>. Then,</p>
<div class="math notranslate nohighlight">
\[p_{ij} = softmax(X_{ij}) = \frac{exp(x_i)}{\sum_{j = 0}^{N-1}\exp(x_j)}\]</div>
<div class="math notranslate nohighlight">
\[loss_{ij} = -\sum_j{Y_{ij} * ln(p_{ij})}\]</div>
</div>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>logits</strong> (Tensor) - Input logits, with shape <span class="math notranslate nohighlight">\((N, C)\)</span>.</p></li>
<li><p><strong>labels</strong> (Tensor) - Ground truth labels, with shape <span class="math notranslate nohighlight">\((N, C)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tuple of 2 Tensor, the loss shape is <cite>(N,)</cite>, and the dlogits with the same shape as <cite>logits</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.SpaceToBatch">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">SpaceToBatch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#SpaceToBatch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.SpaceToBatch" title="Permalink to this definition"></a></dt>
<dd><p>Divide spatial dimensions into blocks and combine the block size with the original batch.</p>
<p>This operation will divide spatial dimensions (H, W) into blocks with block_size, the output tensor’s H and W
dimension is the corresponding number of blocks after division. The output tensor’s batch dimension is the
product of the original batch and the square of block_size. Prior to division into blocks, the spatial dimensions
of the input are zero padded according to paddings if necessary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>block_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The block size of dividing block with value &gt;= 1.</p></li>
<li><p><strong>paddings</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – The padding value for H and W dimension, containing 2 sub list, each containing 2 int value.
All values must be &gt;= 0. paddings[i] specifies the paddings for spatial dimension i, which corresponds to
input dimension i+2. It is required that input_shape[i+2]+paddings[i][0]+paddings[i][1] is divisible
by block_size.</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the output tensor with the same type as input. Assume input shape is <span class="math notranslate nohighlight">\((n, c, h, w)\)</span> with
<span class="math notranslate nohighlight">\(block\_size\)</span> and <span class="math notranslate nohighlight">\(padddings\)</span>. The output tensor shape will be <span class="math notranslate nohighlight">\((n', c', h', w')\)</span>, where</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(n' = n*(block\_size*block\_size)\)</span></p>
<p><span class="math notranslate nohighlight">\(c' = c\)</span></p>
<p><span class="math notranslate nohighlight">\(h' = (h+paddings[0][0]+paddings[0][1])//block\_size\)</span></p>
<p><span class="math notranslate nohighlight">\(w' = (w+paddings[1][0]+paddings[1][1])//block\_size\)</span></p>
</div></blockquote>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">block_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">paddings</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">space_to_batch</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">SpaceToBatch</span><span class="p">(</span><span class="n">block_size</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">space_to_batch</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">[[[[1.]]], [[[2.]]], [[[3.]]], [[[4.]]]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.SpaceToDepth">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">SpaceToDepth</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#SpaceToDepth"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.SpaceToDepth" title="Permalink to this definition"></a></dt>
<dd><p>Rearrange blocks of spatial data into depth.</p>
<p>The output tensor’s <cite>height</cite> dimension is <span class="math notranslate nohighlight">\(height / block\_size\)</span>.</p>
<p>The output tensor’s <cite>weight</cite> dimension is <span class="math notranslate nohighlight">\(weight / block\_size\)</span>.</p>
<p>The depth of output tensor is <span class="math notranslate nohighlight">\(block\_size * block\_size * input\_depth\)</span>.</p>
<p>The input tensor’s height and width must be divisible by <cite>block_size</cite>.
The data format is “NCHW”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>block_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The block size used to divide spatial data. It must be &gt;= 2.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>x</strong> (Tensor) - The target tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the same type as <cite>x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">block_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">SpaceToDepth</span><span class="p">(</span><span class="n">block_size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.SparseApplyAdagrad">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">SparseApplyAdagrad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#SparseApplyAdagrad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.SparseApplyAdagrad" title="Permalink to this definition"></a></dt>
<dd><p>Update relevant entries according to the adagrad scheme.</p>
<div class="math notranslate nohighlight">
\[accum += grad * grad\]</div>
<div class="math notranslate nohighlight">
\[var -= lr * grad * (1 / sqrt(accum))\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Learning rate.</p></li>
<li><p><strong>use_locking</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, updating of the var and accum tensors will be protected. Default: False.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>var</strong> (Tensor) - Variable to be updated. The type must be float32.</p></li>
<li><p><strong>accum</strong> (Tensor) - Accum to be updated. The shape must be the same as <cite>var</cite>’s shape,
the type must be float32.</p></li>
<li><p><strong>grad</strong> (Tensor) - Gradient. The shape must be the same as <cite>var</cite>’s shape
except first dimension, the type must be float32.</p></li>
<li><p><strong>indices</strong> (Tensor) - A vector of indices into the first dimension of <cite>var</cite> and <cite>accum</cite>.
The shape of <cite>indices</cite> must be the same as <cite>grad</cite> in first dimension, the type must be int32.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape and type as <cite>var</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.SparseSoftmaxCrossEntropyWithLogits">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">SparseSoftmaxCrossEntropyWithLogits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#SparseSoftmaxCrossEntropyWithLogits"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.SparseSoftmaxCrossEntropyWithLogits" title="Permalink to this definition"></a></dt>
<dd><p>Computes the softmax cross-entropy value between logits and sparse encoding labels.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Sets input logits as <cite>X</cite>, input label as <cite>Y</cite>, output as <cite>loss</cite>. Then,</p>
<div class="math notranslate nohighlight">
\[p_{ij} = softmax(X_{ij}) = \frac{exp(x_i)}{\sum_{j = 0}^{N-1}\exp(x_j)}\]</div>
<div class="math notranslate nohighlight">
\[loss_{ij} = \begin{cases} -ln(p_{ij}), &amp;j = y_i \cr -ln(1 - p_{ij}), &amp; j \neq y_i \end{cases}\]</div>
<div class="math notranslate nohighlight">
\[loss = \sum_{ij} loss_{ij}\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>is_grad</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If it’s true, this operation returns the computed gradient. Default: False.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>logits</strong> (Tensor) - Input logits, with shape <span class="math notranslate nohighlight">\((N, C)\)</span>.</p></li>
<li><p><strong>labels</strong> (Tensor) - Ground truth labels, with shape <span class="math notranslate nohighlight">\((N)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, if <cite>is_grad</cite> is False, the output tensor is the value of loss which is a scalar tensor;
if <cite>is_grad</cite> is True, the output tensor is the gradient of input with the same shape as <cite>logits</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Split">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Split"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Split" title="Permalink to this definition"></a></dt>
<dd><p>Splits input tensor into output_num of tensors along the given axis and output numbers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Index of the split position. Default: 0.</p></li>
<li><p><strong>output_num</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of output tensors. Default: 1.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If axis is out of the range [-len(input_x.shape()), len(input_x.shape())),
    or if the output_num is less than or equal to 0, or if the
    dimension which to split cannot be evenly divided by output_num.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>tuple[Tensor], the shape of each output tensor is same, which is
<span class="math notranslate nohighlight">\((y_1, y_2, ..., y_S)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">split</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Split</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">split</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Sqrt">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Sqrt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Sqrt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Sqrt" title="Permalink to this definition"></a></dt>
<dd><p>Returns square root of a tensor element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor whose dtype is number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape as the <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sqrt</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Sqrt</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sqrt</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">[1.0, 2.0, 3.0]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Square">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Square</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Square"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Square" title="Permalink to this definition"></a></dt>
<dd><p>Returns square of a tensor element-wise.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input tensor whose dtype is number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape and dtype as the <cite>input_x</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Square</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">[1.0, 4.0, 9.0]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Squeeze">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Squeeze</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Squeeze"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Squeeze" title="Permalink to this definition"></a></dt>
<dd><p>Returns a tensor with the same type but dimensions of 1 being removed based on axis.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The dimension index starts at 0 and must be in the range <cite>[-input.dim(), input.dim())</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the corresponding dimension of the specified axis does not equal to 1.</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Specifies the dimension indexes of shape to be removed, which will remove
all the dimensions that are equal to 1. If specified, it must be int32 or int64.
Default: (), an empty tuple.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_S)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">squeeze</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.StridedSlice">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">StridedSlice</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#StridedSlice"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.StridedSlice" title="Permalink to this definition"></a></dt>
<dd><p>Extracts a strided slice of a tensor.</p>
<p>Given an input tensor, this operation inserts a dimension of length 1 at the dimension.
This operation extracts a fragment of size (end-begin)/stride from the given
‘input_tensor’. Starting from the position specified by the begin, the fragment
continues adding stride to the index until all dimensions are not less than end.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The stride may be negative value, which causes reverse slicing.
The shape of <cite>begin</cite>, <cite>end</cite> and <cite>strides</cite> should be the same.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>begin_mask</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Starting index of the slice. Default: 0.</p></li>
<li><p><strong>end_mask</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Ending index of the slice. Default: 0.</p></li>
<li><p><strong>ellipsis_mask</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – An int mask. Default: 0.</p></li>
<li><p><strong>new_axis_mask</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – An int mask. Default: 0.</p></li>
<li><p><strong>shrink_axis_mask</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – An int mask. Default: 0.</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input Tensor.</p></li>
<li><p><strong>begin</strong> (tuple[int]) - A tuple which represents the location where to start. Only
constant value is allowed.</p></li>
<li><p><strong>end</strong> (tuple[int]) - A tuple or which represents the maximum location where to stop.
Only constant value is allowed.</p></li>
<li><p><strong>strides</strong> (tuple[int]) - A tuple which represents the stride continuously added
before reach the maximum location. Only constant value is allowed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor.
Explain with the following example.</p>
<blockquote>
<div><ul class="simple">
<li><p>In the 0th dim, begin is 1, end is 2, and strides is 1,
because <span class="math notranslate nohighlight">\(1+1=2\geq2\)</span>, the interval is <span class="math notranslate nohighlight">\([1,2)\)</span>.
Thus, return the element with <span class="math notranslate nohighlight">\(index = 1\)</span> in 0th dim, i.e., [[3, 3, 3], [4, 4, 4]].</p></li>
<li><p>In the 1st dim, similarly, the interval is <span class="math notranslate nohighlight">\([0,1)\)</span>.
Based on the return value of the 0th dim, return the element with <span class="math notranslate nohighlight">\(index = 0\)</span>,
i.e., [3, 3, 3].</p></li>
<li><p>In the 2nd dim, similarly, the interval is <span class="math notranslate nohighlight">\([0,3)\)</span>.
Based on the return value of the 1st dim, return the element with <span class="math notranslate nohighlight">\(index = 0,1,2\)</span>,
i.e., [3, 3, 3].</p></li>
<li><p>Finally, the output is [3, 3, 3].</p></li>
</ul>
</div></blockquote>
</dd>
<dt>Examples</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span>
<span class="gp">&gt;&gt;&gt; </span>                  <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">slice</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">StridedSlice</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">()</span>
<span class="go">(1, 1, 3)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span>
<span class="go">[[[3, 3, 3]]]</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Sub">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Sub</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#Sub"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Sub" title="Permalink to this definition"></a></dt>
<dd><p>Subtracts the second input tensor from the first input tensor element-wise.</p>
<p>The inputs must be two tensors or one tensor and one scalar.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be same.
When the inputs are one tensor and one scalar, the scalar cannot be a parameter, only can be a constant,
and the type of the scalar is the same as the data type of the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, Number]) - The first input is a tensor whose data type is number or a number.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, Number]) - The second input is a tensor whose data type is same as ‘input_x’ or
a number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is same as ‘input_x’.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sub</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Sub</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sub</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[-3, -3, -3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Tanh">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Tanh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#Tanh"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Tanh" title="Permalink to this definition"></a></dt>
<dd><p>Tanh activation function.</p>
<p>Computes hyperbolic tangent of input element-wise. The Tanh function is defined as:</p>
<div class="math notranslate nohighlight">
\[tanh(x_i) = \frac{\exp(x_i) - \exp(-x_i)}{\exp(x_i) + \exp(-x_i)} = \frac{\exp(2x_i) - 1}{\exp(2x_i) + 1},\]</div>
<p>where <span class="math notranslate nohighlight">\(x_i\)</span> is an element of the input Tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The input of Tanh.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with the same type and shape as the input_x.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.TensorAdd">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">TensorAdd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/math_ops.html#TensorAdd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.TensorAdd" title="Permalink to this definition"></a></dt>
<dd><p>Adds two input tensors element-wise.</p>
<p>The inputs must be two tensors or one tensor and one scalar.
When the inputs are two tensors, the shapes of them could be broadcast,
and the data types of them should be same.
When the inputs are one tensor and one scalar, the scalar cannot be a parameter, only can be a constant,
and the type of the scalar is the same as the data type of the tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Union[Tensor, Number]) - The first input is a tensor whose data type is number or a number.</p></li>
<li><p><strong>input_y</strong> (Union[Tensor, Number]) - The second input is a tensor whose data type is same as ‘input_x’ or
a number.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is same as the shape after broadcasting, and the data type is same as ‘input_x’.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">add</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">TensorAdd</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">add</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="go">[5,7,9]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.TensorSummary">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">TensorSummary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/debug_ops.html#TensorSummary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.TensorSummary" title="Permalink to this definition"></a></dt>
<dd><p>Output tensor to protocol buffer through tensor summary operator.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>name</strong> (str) - The name of the input variable.</p></li>
<li><p><strong>value</strong> (Tensor) - The value of tensor.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">SummaryDemo</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">SummaryDemo</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">summary</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">TensorSummary</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">TensorAdd</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;x&quot;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Tile">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Tile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Tile"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Tile" title="Permalink to this definition"></a></dt>
<dd><p>Replicates a tensor with given multiples times.</p>
<p>Creates a new tensor by replicating input multiples times. The dimension of
output tensor is the larger of the dimension length of input and the length of multiples.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - 1-D or higher Tensor. Set the shape of input tensor as
<span class="math notranslate nohighlight">\((x_1, x_2, ..., x_S)\)</span>.</p></li>
<li><p><strong>multiples</strong> (tuple[int]) - The input tuple is constructed by multiple
integers, i.e., <span class="math notranslate nohighlight">\((y_1, y_2, ..., y_S)\)</span>. The length of <cite>multiples</cite>
can’t be smaller than the length of shape in <cite>input_x</cite>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same type as the <cite>input_x</cite>.</p>
<ul class="simple">
<li><p>If the length of <cite>multiples</cite> is the same as the length of shape in <cite>input_x</cite>,
then the shape of their corresponding positions can be multiplied, and
the shape of Outputs is <span class="math notranslate nohighlight">\((x_1*y_1, x_2*y_2, ..., x_S*y_R)\)</span>.</p></li>
<li><p>If the length of <cite>multiples</cite> is larger than the length of shape in <cite>input_x</cite>,
fill in multiple 1 in front of the shape in <cite>input_x</cite> until their lengths are consistent.
Such as set the shape of <cite>input_x</cite> as <span class="math notranslate nohighlight">\((1, ..., x_1, x_2, ..., x_S)\)</span>,
then the shape of their corresponding positions can be multiplied, and
the shape of Outputs is <span class="math notranslate nohighlight">\((1*y_1, ..., x_S*y_R)\)</span>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.TopK">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">TopK</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/nn_ops.html#TopK"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.TopK" title="Permalink to this definition"></a></dt>
<dd><p>Finds values and indices of the <cite>k</cite> largest entries along the last dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>sorted</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If true, the resulting elements will
be sorted by the values in descending order. Default: False.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - Input to be computed.</p></li>
<li><p><strong>k</strong> (int) - Number of top elements to be computed along the last dimension, constant input is needed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tuple of 2 Tensor, the values and the indices.</p>
<ul class="simple">
<li><p><strong>values</strong> (Tensor) - The <cite>k</cite> largest elements along each last dimensional slice.</p></li>
<li><p><strong>indices</strong> (Tensor) - The indices of values within the last dimension of input.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">topk</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">TopK</span><span class="p">(</span><span class="nb">sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">values</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">topk</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">values</span> <span class="o">==</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">indices</span> <span class="o">==</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Transpose">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Transpose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Transpose"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Transpose" title="Permalink to this definition"></a></dt>
<dd><p>Permutes the dimensions of input tensor according to input perm.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of tensor is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
<li><p><strong>input_perm</strong> (tuple[int]) - The permutation to be converted. The input tuple is constructed by multiple
indexes. The length of <cite>input_perm</cite> and the shape of <cite>input_x</cite> should be the same. Only constant value is
allowed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the type of output tensor is same as <cite>input_x</cite> and the shape of output tensor is decided by the
shape of <cite>input_x</cite> and the value of <cite>input_perm</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">perm</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transpose</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Transpose</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">transpose</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">perm</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.TruncatedNormal">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">TruncatedNormal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#TruncatedNormal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.TruncatedNormal" title="Permalink to this definition"></a></dt>
<dd><p>Returns a tensor of the specified shape filled with truncated normal values.</p>
<p>The generated values follow a normal distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – A int number used to create random seed. Default: 0.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.dtype.html#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – Data type. Default: mindspore.float32.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>shape</strong> (tuple[int]) - Shape of output tensor, is a tuple of positive int.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, type of output tensor is same as attribute <cite>dtype</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">truncated_normal</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">TruncatedNormal</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">truncated_normal</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.TupleToArray">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">TupleToArray</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#TupleToArray"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.TupleToArray" title="Permalink to this definition"></a></dt>
<dd><p>Converts a tuple to tensor.</p>
<p>If the first number type of tuple is int, the output tensor type is int. Else, the output tensor type is float.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (tuple) - A tuple of numbers. These numbers have the same type. Only constant value is allowed.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, if the input tuple contain <cite>N</cite> numbers, then the output tensor shape is (N,).</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">TupleToArray</span><span class="p">()((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.Unpack">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">Unpack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#Unpack"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.Unpack" title="Permalink to this definition"></a></dt>
<dd><p>Unpacks tensor in specified axis.</p>
<p>Unpacks a tensor of rank <cite>R</cite> along axis dimension, output tensors will have rank <cite>(R-1)</cite>.</p>
<p>Given a tensor of shape <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>. If <span class="math notranslate nohighlight">\(0 \le axis\)</span>,
the shape of tensor in output is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_{axis}, x_{axis+2}, ..., x_R)\)</span>.</p>
<p>This is the opposite of pack.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Dimension along which to pack. Default: 0.
Negative values wrap around. The range is [-R, R).</p></li>
<li><p><strong>num</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of tensors to be unpacked to. Default : “None”.
If <cite>num</cite> is not specified, it is inferred from the shape of <cite>input_x</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.
A rank R &gt; 0 Tensor to be unpacked.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>A tuple of Tensors, the shape of each objects is same.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If axis is out of the range [-len(input_x.shape()), len(input_x.shape())),
    or if len(input_x.shape[axis]) not equal to num.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">unpack</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Unpack</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">unpack</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="go">([1, 1, 1, 1], [2, 2, 2, 2])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.UnsortedSegmentSum">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">UnsortedSegmentSum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#UnsortedSegmentSum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.UnsortedSegmentSum" title="Permalink to this definition"></a></dt>
<dd><p>Computes the sum along segments of a tensor.</p>
<p>Calculates a tensor such that <span class="math notranslate nohighlight">\(\text{output}[i] = \sum_{segment\_ids[j] == i} \text{data}[j, \ldots]\)</span>, where
<span class="math notranslate nohighlight">\(j\)</span> is a tuple describing the index of element in data.  <cite>segment_ids</cite> selects which elements in data to sum
up. Segment_ids does not need to be sorted, and it does not need to cover all values in the entire valid value
range.</p>
<p>If the sum of the given segment_ids <span class="math notranslate nohighlight">\(i\)</span> is empty, then <span class="math notranslate nohighlight">\(\text{output}[i] = 0\)</span>. If the given segment_ids
is negative, the value will be ignored. ‘num_segments’ should be equal to the number of different segment_ids.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape is <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_R)\)</span>.</p></li>
<li><p><strong>segment_ids</strong> (Tensor) - Set the shape as <span class="math notranslate nohighlight">\((x_1, x_2, ..., x_N)\)</span>, where 0 &lt; N &lt;= R. Type must be int.</p></li>
<li><p><strong>num_segments</strong> (int) - Set <span class="math notranslate nohighlight">\(z\)</span> as num_segments.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape is <span class="math notranslate nohighlight">\((z, x_{N+1}, ..., x_R)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">segment_ids</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_segments</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">P</span><span class="o">.</span><span class="n">UnsortedSegmentSum</span><span class="p">()(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">)</span>
<span class="go">[3, 3, 4, 0]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.operations.ZerosLike">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.operations.</span></span><span class="sig-name descname"><span class="pre">ZerosLike</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/ops/operations/array_ops.html#ZerosLike"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.operations.ZerosLike" title="Permalink to this definition"></a></dt>
<dd><p>Creates a new tensor. All elements value are 0.</p>
<p>Returns a tensor of zeros with the same shape and type as the input tensor.</p>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - Input tensor.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, has the same shape and type as <cite>input_x</cite> but filled with zeros.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">zeroslike</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ZerosLike</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">zeroslike</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindspore.ops.composite.html" class="btn btn-neutral float-left" title="mindspore.ops.composite" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mindspore.parallel.html" class="btn btn-neutral float-right" title="mindspore.parallel" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>