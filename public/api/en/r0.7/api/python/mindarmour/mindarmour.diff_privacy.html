

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindarmour.diff_privacy &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="prev" title="mindarmour.fuzzing" href="mindarmour.fuzzing.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">MindSpore Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.dtype.html">mindspore.dtype</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.hub.html">mindspore.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.nn.dynamic_lr.html">mindspore.nn.dynamic_lr</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.nn.learning_rate_schedule.html">mindspore.nn.learning_rate_schedule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.ops.composite.html">mindspore.ops.composite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.ops.operations.html">mindspore.ops.operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.parallel.html">mindspore.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.dataset.transforms.vision.html">mindspore.dataset.transforms.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore/mindspore.profiler.html">mindspore.profiler</a></li>
</ul>
<p class="caption"><span class="caption-text">MindInsight Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindinsight/mindinsight.lineagemgr.html">mindinsight.lineagemgr</a></li>
</ul>
<p class="caption"><span class="caption-text">MindArmour Python API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mindarmour.html">mindarmour</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.utils.html">mindarmour.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.evaluations.html">mindarmour.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.detectors.html">mindarmour.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.attacks.html">mindarmour.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.defenses.html">mindarmour.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindarmour.fuzzing.html">mindarmour.fuzzing</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindarmour.diff_privacy</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>mindarmour.diff_privacy</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../../_sources/api/python/mindarmour/mindarmour.diff_privacy.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-mindarmour.diff_privacy">
<span id="mindarmour-diff-privacy"></span><h1>mindarmour.diff_privacy<a class="headerlink" href="#module-mindarmour.diff_privacy" title="Permalink to this headline">¶</a></h1>
<p>This module provide Differential Privacy feature to protect user privacy.</p>
<dl class="class">
<dt id="mindarmour.diff_privacy.NoiseGaussianRandom">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.diff_privacy.</code><code class="sig-name descname">NoiseGaussianRandom</code><span class="sig-paren">(</span><em class="sig-param">norm_bound=1.0</em>, <em class="sig-param">initial_noise_multiplier=1.0</em>, <em class="sig-param">seed=0</em>, <em class="sig-param">decay_policy=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/mechanisms/mechanisms.html#NoiseGaussianRandom"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.NoiseGaussianRandom" title="Permalink to this definition">¶</a></dt>
<dd><p>Gaussian noise generated mechanism.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>norm_bound</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Clipping bound for the l2 norm of the gradients.
Default: 1.0.</p></li>
<li><p><strong>initial_noise_multiplier</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Ratio of the standard deviation of
Gaussian noise divided by the norm_bound, which will be used to
calculate privacy spent. Default: 1.0.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Original random seed, if seed=0 random normal will use secure
random number. IF seed!=0 random normal will generate values using
given seed. Default: 0.</p></li>
<li><p><strong>decay_policy</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Mechanisms parameters update policy. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, generated noise with shape like given gradients.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">gradients</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">norm_bound</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">initial_noise_multiplier</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">decay_policy</span> <span class="o">=</span> <span class="kc">None</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">NoiseGaussianRandom</span><span class="p">(</span><span class="n">norm_bound</span><span class="p">,</span> <span class="n">initial_noise_multiplier</span><span class="p">,</span> <span class="n">seed</span><span class="p">,</span> <span class="n">decay_policy</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">gradients</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.diff_privacy.NoiseGaussianRandom.construct">
<code class="sig-name descname">construct</code><span class="sig-paren">(</span><em class="sig-param">gradients</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/mechanisms/mechanisms.html#NoiseGaussianRandom.construct"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.NoiseGaussianRandom.construct" title="Permalink to this definition">¶</a></dt>
<dd><p>Generated Gaussian noise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>gradients</strong> (<a class="reference internal" href="../mindspore/mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The gradients.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, generated noise with shape like given gradients.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.diff_privacy.NoiseAdaGaussianRandom">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.diff_privacy.</code><code class="sig-name descname">NoiseAdaGaussianRandom</code><span class="sig-paren">(</span><em class="sig-param">norm_bound=1.0</em>, <em class="sig-param">initial_noise_multiplier=1.0</em>, <em class="sig-param">seed=0</em>, <em class="sig-param">noise_decay_rate=6e-06</em>, <em class="sig-param">decay_policy='Exp'</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/mechanisms/mechanisms.html#NoiseAdaGaussianRandom"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.NoiseAdaGaussianRandom" title="Permalink to this definition">¶</a></dt>
<dd><p>Adaptive Gaussian noise generated mechanism. Noise would be decayed with
training. Decay mode could be ‘Time’ mode, ‘Step’ mode, ‘Exp’ mode.
<cite>self._noise_multiplier</cite> will be update during the model.train, using
_MechanismsParamsUpdater.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>norm_bound</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Clipping bound for the l2 norm of the gradients.
Default: 1.0.</p></li>
<li><p><strong>initial_noise_multiplier</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Ratio of the standard deviation of
Gaussian noise divided by the norm_bound, which will be used to
calculate privacy spent. Default: 1.0.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Original random seed, if seed=0 random normal will use secure
random number. IF seed!=0 random normal will generate values using
given seed. Default: 0.</p></li>
<li><p><strong>noise_decay_rate</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Hyper parameter for controlling the noise decay.
Default: 6e-6.</p></li>
<li><p><strong>decay_policy</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Noise decay strategy include ‘Step’, ‘Time’, ‘Exp’.
Default: ‘Exp’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, generated noise with shape like given gradients.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">gradients</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">norm_bound</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">initial_noise_multiplier</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">noise_decay_rate</span> <span class="o">=</span> <span class="mf">6e-4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">decay_policy</span> <span class="o">=</span> <span class="s2">&quot;Exp&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">NoiseAdaGaussianRandom</span><span class="p">(</span><span class="n">norm_bound</span><span class="p">,</span> <span class="n">initial_noise_multiplier</span><span class="p">,</span> <span class="n">seed</span><span class="p">,</span> <span class="n">noise_decay_rate</span><span class="p">,</span> <span class="n">decay_policy</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">gradients</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindarmour.diff_privacy.AdaClippingWithGaussianRandom">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.diff_privacy.</code><code class="sig-name descname">AdaClippingWithGaussianRandom</code><span class="sig-paren">(</span><em class="sig-param">decay_policy='Linear'</em>, <em class="sig-param">learning_rate=0.001</em>, <em class="sig-param">target_unclipped_quantile=0.9</em>, <em class="sig-param">fraction_stddev=0.01</em>, <em class="sig-param">seed=0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/mechanisms/mechanisms.html#AdaClippingWithGaussianRandom"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.AdaClippingWithGaussianRandom" title="Permalink to this definition">¶</a></dt>
<dd><p>Adaptive clipping. If <cite>decay_policy</cite> is ‘Linear’, the update formula <span class="math notranslate nohighlight">\(norm bound = norm bound -
learning rate*(beta - target unclipped quantile)\)</span>.
If <cite>decay_policy</cite> is ‘Geometric’, the update formula is <span class="math notranslate nohighlight">\(norm bound =
norm bound*exp(-learning rate*(empirical fraction - target unclipped quantile))\)</span>.
where beta is the empirical fraction of samples with the value at most
<cite>target_unclipped_quantile</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decay_policy</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Decay policy of adaptive clipping, decay_policy must
be in [‘Linear’, ‘Geometric’]. Default: Linear.</p></li>
<li><p><strong>learning_rate</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Learning rate of update norm clip. Default: 0.001.</p></li>
<li><p><strong>target_unclipped_quantile</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Target quantile of norm clip. Default: 0.9.</p></li>
<li><p><strong>fraction_stddev</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The stddev of Gaussian normal which used in
empirical_fraction, the formula is empirical_fraction + N(0, fraction_stddev).
Default: 0.01.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Original random seed, if seed=0 random normal will use secure
random number. IF seed!=0 random normal will generate values using
given seed. Default: 0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, undated norm clip .</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">decay_policy</span> <span class="o">=</span> <span class="s1">&#39;Linear&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">beta</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">norm_bound</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">beta_stddev</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_unclipped_quantile</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ada_clip</span> <span class="o">=</span> <span class="n">AdaClippingWithGaussianRandom</span><span class="p">(</span><span class="n">decay_policy</span><span class="o">=</span><span class="n">decay_policy</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                         <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                         <span class="n">target_unclipped_quantile</span><span class="o">=</span><span class="n">target_unclipped_quantile</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                         <span class="n">fraction_stddev</span><span class="o">=</span><span class="n">beta_stddev</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">next_norm_bound</span> <span class="o">=</span> <span class="n">ada_clip</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">norm_bound</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.diff_privacy.AdaClippingWithGaussianRandom.construct">
<code class="sig-name descname">construct</code><span class="sig-paren">(</span><em class="sig-param">empirical_fraction</em>, <em class="sig-param">norm_bound</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/mechanisms/mechanisms.html#AdaClippingWithGaussianRandom.construct"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.AdaClippingWithGaussianRandom.construct" title="Permalink to this definition">¶</a></dt>
<dd><p>Update value of norm_bound.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>empirical_fraction</strong> (<a class="reference internal" href="../mindspore/mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – empirical fraction of samples with the
value at most <cite>target_unclipped_quantile</cite>.</p></li>
<li><p><strong>norm_bound</strong> (<a class="reference internal" href="../mindspore/mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – Clipping bound for the l2 norm of the gradients.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, generated noise with shape like given gradients.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.diff_privacy.NoiseMechanismsFactory">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.diff_privacy.</code><code class="sig-name descname">NoiseMechanismsFactory</code><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/mechanisms/mechanisms.html#NoiseMechanismsFactory"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.NoiseMechanismsFactory" title="Permalink to this definition">¶</a></dt>
<dd><p>Factory class of noise mechanisms</p>
<dl class="method">
<dt id="mindarmour.diff_privacy.NoiseMechanismsFactory.create">
<em class="property">static </em><code class="sig-name descname">create</code><span class="sig-paren">(</span><em class="sig-param">mech_name</em>, <em class="sig-param">norm_bound=1.0</em>, <em class="sig-param">initial_noise_multiplier=1.0</em>, <em class="sig-param">seed=0</em>, <em class="sig-param">noise_decay_rate=6e-06</em>, <em class="sig-param">decay_policy=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/mechanisms/mechanisms.html#NoiseMechanismsFactory.create"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.NoiseMechanismsFactory.create" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mech_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Noise generated strategy, could be ‘Gaussian’ or
‘AdaGaussian’. Noise would be decayed with ‘AdaGaussian’ mechanism
while be constant with ‘Gaussian’ mechanism.</p></li>
<li><p><strong>norm_bound</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Clipping bound for the l2 norm of the gradients. Default: 1.0.</p></li>
<li><p><strong>initial_noise_multiplier</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Ratio of the standard deviation of
Gaussian noise divided by the norm_bound, which will be used to
calculate privacy spent. Default: 1.0.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Original random seed, if seed=0 random normal will use secure
random number. IF seed!=0 random normal will generate values using
given seed. Default: 0.</p></li>
<li><p><strong>noise_decay_rate</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Hyper parameter for controlling the noise decay. Default: 6e-6.</p></li>
<li><p><strong>decay_policy</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Mechanisms parameters update policy. Default: None, no
parameters need update. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#NameError" title="(in Python v3.8)"><strong>NameError</strong></a> – <cite>mech_name</cite> must be in [‘Gaussian’, ‘AdaGaussian’].</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Mechanisms, class of noise generated Mechanism.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">norm_bound</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">initial_noise_multiplier</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batches</span> <span class="o">=</span> <span class="mi">128</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">is_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">noise_mech</span> <span class="o">=</span> <span class="n">NoiseMechanismsFactory</span><span class="p">()</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="s1">&#39;Gaussian&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                             <span class="n">norm_bound</span><span class="o">=</span><span class="n">norm_bound</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                             <span class="n">initial_noise_multiplier</span><span class="o">=</span><span class="n">initial_noise_multiplier</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clip_mech</span> <span class="o">=</span> <span class="n">ClipMechanismsFactory</span><span class="p">()</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="s1">&#39;Gaussian&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                           <span class="n">decay_policy</span><span class="o">=</span><span class="s1">&#39;Linear&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                           <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                           <span class="n">target_unclipped_quantile</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                           <span class="n">fraction_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                      <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">DPModel</span><span class="p">(</span><span class="n">micro_batches</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">clip_mech</span><span class="o">=</span><span class="n">clip_mech</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">norm_bound</span><span class="o">=</span><span class="n">norm_bound</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">noise_mech</span><span class="o">=</span><span class="n">noise_mech</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">network</span><span class="o">=</span><span class="n">network</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">optimizer</span><span class="o">=</span><span class="n">net_opt</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms_ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">dataset_generator</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">batches</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span>                           <span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms_ds</span><span class="o">.</span><span class="n">set_dataset_size</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">batches</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">ms_ds</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.diff_privacy.ClipMechanismsFactory">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.diff_privacy.</code><code class="sig-name descname">ClipMechanismsFactory</code><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/mechanisms/mechanisms.html#ClipMechanismsFactory"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.ClipMechanismsFactory" title="Permalink to this definition">¶</a></dt>
<dd><p>Factory class of clip mechanisms</p>
<dl class="method">
<dt id="mindarmour.diff_privacy.ClipMechanismsFactory.create">
<em class="property">static </em><code class="sig-name descname">create</code><span class="sig-paren">(</span><em class="sig-param">mech_name</em>, <em class="sig-param">decay_policy='Linear'</em>, <em class="sig-param">learning_rate=0.001</em>, <em class="sig-param">target_unclipped_quantile=0.9</em>, <em class="sig-param">fraction_stddev=0.01</em>, <em class="sig-param">seed=0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/mechanisms/mechanisms.html#ClipMechanismsFactory.create"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.ClipMechanismsFactory.create" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mech_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Clip noise generated strategy, support ‘Gaussian’ now.</p></li>
<li><p><strong>decay_policy</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Decay policy of adaptive clipping, decay_policy must
be in [‘Linear’, ‘Geometric’]. Default: Linear.</p></li>
<li><p><strong>learning_rate</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Learning rate of update norm clip. Default: 0.001.</p></li>
<li><p><strong>target_unclipped_quantile</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Target quantile of norm clip. Default: 0.9.</p></li>
<li><p><strong>fraction_stddev</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The stddev of Gaussian normal which used in
empirical_fraction, the formula is <span class="math notranslate nohighlight">\(empirical fraction + N(0, fraction sstddev)\)</span>.
Default: 0.01.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Original random seed, if seed=0 random normal will use secure
random number. IF seed!=0 random normal will generate values using
given seed. Default: 0.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#NameError" title="(in Python v3.8)"><strong>NameError</strong></a> – <cite>mech_name</cite> must be in [‘Gaussian’].</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Mechanisms, class of noise generated Mechanism.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">decay_policy</span> <span class="o">=</span> <span class="s1">&#39;Linear&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">beta</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">norm_bound</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">beta_stddev</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_unclipped_quantile</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clip_mechanism</span> <span class="o">=</span> <span class="n">ClipMechanismsFactory</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ada_clip</span> <span class="o">=</span> <span class="n">clip_mechanism</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="s1">&#39;Gaussian&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                         <span class="n">decay_policy</span><span class="o">=</span><span class="n">decay_policy</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                         <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                         <span class="n">target_unclipped_quantile</span><span class="o">=</span><span class="n">target_unclipped_quantile</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                         <span class="n">fraction_stddev</span><span class="o">=</span><span class="n">beta_stddev</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">next_norm_bound</span> <span class="o">=</span> <span class="n">ada_clip</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">norm_bound</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.diff_privacy.PrivacyMonitorFactory">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.diff_privacy.</code><code class="sig-name descname">PrivacyMonitorFactory</code><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/monitor/monitor.html#PrivacyMonitorFactory"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.PrivacyMonitorFactory" title="Permalink to this definition">¶</a></dt>
<dd><p>Factory class of DP training’s privacy monitor.</p>
<dl class="method">
<dt id="mindarmour.diff_privacy.PrivacyMonitorFactory.create">
<em class="property">static </em><code class="sig-name descname">create</code><span class="sig-paren">(</span><em class="sig-param">policy</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/monitor/monitor.html#PrivacyMonitorFactory.create"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.PrivacyMonitorFactory.create" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a privacy monitor class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>policy</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Monitor policy, ‘rdp’ and ‘zcdp’ are supported
by now. If policy is ‘rdp’, the monitor will compute the
privacy budget of DP training based on Renyi differential
privacy theory; If policy is ‘zcdp’, the monitor will compute
the privacy budget of DP training based on zero-concentrated
differential privacy theory. It’s worth noting that ‘zcdp’
is not suitable for subsampling nosie mechanism.</p></li>
<li><p><strong>args</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em>) – Parameters
used for creating a privacy monitor.</p></li>
<li><p><strong>kwargs</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em>) – Keyword
parameters used for creating a privacy monitor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Callback, a privacy monitor.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rdp</span> <span class="o">=</span> <span class="n">PrivacyMonitorFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">policy</span><span class="o">=</span><span class="s1">&#39;rdp&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_samples</span><span class="o">=</span><span class="mi">60000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.diff_privacy.RDPMonitor">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.diff_privacy.</code><code class="sig-name descname">RDPMonitor</code><span class="sig-paren">(</span><em class="sig-param">num_samples</em>, <em class="sig-param">batch_size</em>, <em class="sig-param">initial_noise_multiplier=1.5</em>, <em class="sig-param">max_eps=10.0</em>, <em class="sig-param">target_delta=0.001</em>, <em class="sig-param">max_delta=None</em>, <em class="sig-param">target_eps=None</em>, <em class="sig-param">orders=None</em>, <em class="sig-param">noise_decay_mode='Time'</em>, <em class="sig-param">noise_decay_rate=0.0006</em>, <em class="sig-param">per_print_times=50</em>, <em class="sig-param">dataset_sink_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/monitor/monitor.html#RDPMonitor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.RDPMonitor" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the privacy budget of DP training based on Renyi differential
privacy (RDP) theory. According to the reference below, if a randomized
mechanism is said to have ε’-Renyi differential privacy of order α, it
also satisfies conventional differential privacy (ε, δ) as below:</p>
<div class="math notranslate nohighlight">
\[(ε'+\frac{log(1/δ)}{α-1}, δ)\]</div>
<p>Reference: <a class="reference external" href="https://arxiv.org/abs/1908.10530">Rényi Differential Privacy of the Sampled Gaussian Mechanism</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_samples</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The total number of samples in training data sets.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of samples in a batch while training.</p></li>
<li><p><strong>initial_noise_multiplier</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – Ratio of the standard
deviation of Gaussian noise divided by the norm_bound, which will
be used to calculate privacy spent. Default: 1.5.</p></li>
<li><p><strong>max_eps</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – The maximum acceptable epsilon
budget for DP training, which is used for estimating the max
training epochs. Default: 10.0.</p></li>
<li><p><strong>target_delta</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Target delta budget for DP
training. If target_delta is set to be δ, then the privacy budget
δ would be fixed during the whole training process. Default: 1e-3.</p></li>
<li><p><strong>max_delta</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – The maximum acceptable delta
budget for DP training, which is used for estimating the max
training epochs. Max_delta must be less than 1 and suggested
to be less than 1e-3, otherwise overflow would be encountered.
Default: None.</p></li>
<li><p><strong>target_eps</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>]</em>) – Target epsilon budget for DP
training. If target_eps is set to be ε, then the privacy budget
ε would be fixed during the whole training process. Default: None.</p></li>
<li><p><strong>orders</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em><em>]</em>) – Finite orders used for
computing rdp, which must be greater than 1. The computation result
of privacy budget would be different for various orders. In order
to obtain a tighter (smaller) privacy budget estimation, a list
of orders could be tried. Default: None.</p></li>
<li><p><strong>noise_decay_mode</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em>) – Decay mode of adding noise while
training, which can be None, ‘Time’, ‘Step’ or ‘Exp’. Default: ‘Time’.</p></li>
<li><p><strong>noise_decay_rate</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Decay rate of noise while training. Default: 6e-4.</p></li>
<li><p><strong>per_print_times</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The interval steps of computing and printing
the privacy budget. Default: 50.</p></li>
<li><p><strong>dataset_sink_mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, all training data would be passed
to device(Ascend) one-time. If False, training data would be passed
to device after each step training. Default: False.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">norm_clip</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">initial_noise_multiplier</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mech</span> <span class="o">=</span> <span class="n">NoiseMechanismsFactory</span><span class="p">()</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="s1">&#39;AdaGaussian&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">norm_bound</span><span class="o">=</span><span class="n">norm_clip</span><span class="p">,</span> <span class="n">initial_noise_multiplier</span><span class="o">=</span><span class="n">initial_noise_multiplier</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">DPModel</span><span class="p">(</span><span class="n">micro_batches</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">norm_clip</span><span class="o">=</span><span class="n">norm_clip</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mech</span><span class="o">=</span><span class="n">mech</span><span class="p">,</span> <span class="n">network</span><span class="o">=</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">net_opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rdp</span> <span class="o">=</span> <span class="n">PrivacyMonitorFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">policy</span><span class="o">=</span><span class="s1">&#39;rdp&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_samples</span><span class="o">=</span><span class="mi">60000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">initial_noise_multiplier</span><span class="o">=</span><span class="n">initial_noise_multiplier</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">rdp</span><span class="p">],</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.diff_privacy.RDPMonitor.max_epoch_suggest">
<code class="sig-name descname">max_epoch_suggest</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/monitor/monitor.html#RDPMonitor.max_epoch_suggest"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.RDPMonitor.max_epoch_suggest" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimate the maximum training epochs to satisfy the predefined
privacy budget.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>int, the recommended maximum training epochs.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rdp</span> <span class="o">=</span> <span class="n">PrivacyMonitorFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">policy</span><span class="o">=</span><span class="s1">&#39;rdp&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_samples</span><span class="o">=</span><span class="mi">60000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">suggest_epoch</span> <span class="o">=</span> <span class="n">rdp</span><span class="o">.</span><span class="n">max_epoch_suggest</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindarmour.diff_privacy.RDPMonitor.step_end">
<code class="sig-name descname">step_end</code><span class="sig-paren">(</span><em class="sig-param">run_context</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/monitor/monitor.html#RDPMonitor.step_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.RDPMonitor.step_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute privacy budget after each training step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="../mindspore/mindspore.train.html#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Include some information of the model.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.diff_privacy.ZCDPMonitor">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.diff_privacy.</code><code class="sig-name descname">ZCDPMonitor</code><span class="sig-paren">(</span><em class="sig-param">num_samples</em>, <em class="sig-param">batch_size</em>, <em class="sig-param">initial_noise_multiplier=1.5</em>, <em class="sig-param">max_eps=10.0</em>, <em class="sig-param">target_delta=0.001</em>, <em class="sig-param">noise_decay_mode='Time'</em>, <em class="sig-param">noise_decay_rate=0.0006</em>, <em class="sig-param">per_print_times=50</em>, <em class="sig-param">dataset_sink_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/monitor/monitor.html#ZCDPMonitor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.ZCDPMonitor" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the privacy budget of DP training based on zero-concentrated
differential privacy theory (zcdp). According to the reference below,
if a randomized mechanism is said to have ρ-ｚCDP, it also satisfies
conventional differential privacy (ε, δ) as below:</p>
<div class="math notranslate nohighlight">
\[(ρ+２\sqrt{ρlog(1/δ)}, δ)\]</div>
<p>It should be noted that ZCDPMonitor is not suitable for subsampling
noise mechanisms(such as NoiseAdaGaussianRandom and NoiseGaussianRandom).
The matching noise mechanism of ZCDP will be developed in the future.
Reference: <a class="reference external" href="https://arxiv.org/abs/1808.09501">Concentrated Differentially Private Gradient Descent with
Adaptive per-Iteration Privacy Budget</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_samples</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The total number of samples in training data sets.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of samples in a batch while training.</p></li>
<li><p><strong>initial_noise_multiplier</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – Ratio of the standard
deviation of Gaussian noise divided by the norm_bound, which will
be used to calculate privacy spent. Default: 1.5.</p></li>
<li><p><strong>max_eps</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – The maximum acceptable epsilon budget for
DP training, which is used for estimating the max training epochs.
Default: 10.0.</p></li>
<li><p><strong>target_delta</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – Target delta budget for DP training.
If target_delta is set to be δ, then the privacy budget δ would be
fixed during the whole training process. Default: 1e-3.</p></li>
<li><p><strong>noise_decay_mode</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em>) – Decay mode of adding noise while
training, which can be None, ‘Time’, ‘Step’ or ‘Exp’. Default: ‘Time’.</p></li>
<li><p><strong>noise_decay_rate</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Decay rate of noise while training. Default: 6e-4.</p></li>
<li><p><strong>per_print_times</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The interval steps of computing and printing
the privacy budget. Default: 50.</p></li>
<li><p><strong>dataset_sink_mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, all training data would be passed
to device(Ascend) one-time. If False, training data would be passed
to device after each step training. Default: False.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">norm_clip</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">initial_noise_multiplier</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mech</span> <span class="o">=</span> <span class="n">NoiseMechanismsFactory</span><span class="p">()</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="s1">&#39;AdaGaussian&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">norm_bound</span><span class="o">=</span><span class="n">norm_clip</span><span class="p">,</span> <span class="n">initial_noise_multiplier</span><span class="o">=</span><span class="n">initial_noise_multiplier</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">DPModel</span><span class="p">(</span><span class="n">micro_batches</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">norm_clip</span><span class="o">=</span><span class="n">norm_clip</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mech</span><span class="o">=</span><span class="n">mech</span><span class="p">,</span> <span class="n">network</span><span class="o">=</span><span class="n">network</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">net_opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">zcdp</span> <span class="o">=</span> <span class="n">PrivacyMonitorFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">policy</span><span class="o">=</span><span class="s1">&#39;zcdp&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_samples</span><span class="o">=</span><span class="mi">60000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">initial_noise_multiplier</span><span class="o">=</span><span class="n">initial_noise_multiplier</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">zcdp</span><span class="p">],</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.diff_privacy.ZCDPMonitor.max_epoch_suggest">
<code class="sig-name descname">max_epoch_suggest</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/monitor/monitor.html#ZCDPMonitor.max_epoch_suggest"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.ZCDPMonitor.max_epoch_suggest" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimate the maximum training epochs to satisfy the predefined
privacy budget.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>int, the recommended maximum training epochs.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">zcdp</span> <span class="o">=</span> <span class="n">PrivacyMonitorFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">policy</span><span class="o">=</span><span class="s1">&#39;zcdp&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_samples</span><span class="o">=</span><span class="mi">60000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">suggest_epoch</span> <span class="o">=</span> <span class="n">zcdp</span><span class="o">.</span><span class="n">max_epoch_suggest</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindarmour.diff_privacy.ZCDPMonitor.step_end">
<code class="sig-name descname">step_end</code><span class="sig-paren">(</span><em class="sig-param">run_context</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/monitor/monitor.html#ZCDPMonitor.step_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.ZCDPMonitor.step_end" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute privacy budget after each training step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="../mindspore/mindspore.train.html#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Include some information of the model.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.diff_privacy.DPOptimizerClassFactory">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.diff_privacy.</code><code class="sig-name descname">DPOptimizerClassFactory</code><span class="sig-paren">(</span><em class="sig-param">micro_batches=2</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/optimizer/optimizer.html#DPOptimizerClassFactory"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.DPOptimizerClassFactory" title="Permalink to this definition">¶</a></dt>
<dd><p>Factory class of Optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>micro_batches</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of small batches split from an original batch. Default: 2.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Optimizer, Optimizer class</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">GaussianSGD</span> <span class="o">=</span> <span class="n">DPOptimizerClassFactory</span><span class="p">(</span><span class="n">micro_batches</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">GaussianSGD</span><span class="o">.</span><span class="n">set_mechanisms</span><span class="p">(</span><span class="s1">&#39;Gaussian&#39;</span><span class="p">,</span> <span class="n">norm_bound</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">initial_noise_multiplier</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_opt</span> <span class="o">=</span> <span class="n">GaussianSGD</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="s1">&#39;Momentum&#39;</span><span class="p">)(</span><span class="n">params</span><span class="o">=</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span>
<span class="gp">&gt;&gt;&gt; </span>                                         <span class="n">learning_rate</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                         <span class="n">momentum</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">momentum</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindarmour.diff_privacy.DPOptimizerClassFactory.create">
<code class="sig-name descname">create</code><span class="sig-paren">(</span><em class="sig-param">policy</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/optimizer/optimizer.html#DPOptimizerClassFactory.create"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.DPOptimizerClassFactory.create" title="Permalink to this definition">¶</a></dt>
<dd><p>Create DP optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>policy</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Choose original optimizer type.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Optimizer, A optimizer with DP.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindarmour.diff_privacy.DPOptimizerClassFactory.set_mechanisms">
<code class="sig-name descname">set_mechanisms</code><span class="sig-paren">(</span><em class="sig-param">policy</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/optimizer/optimizer.html#DPOptimizerClassFactory.set_mechanisms"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.DPOptimizerClassFactory.set_mechanisms" title="Permalink to this definition">¶</a></dt>
<dd><p>Get noise mechanism object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>policy</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Choose mechanism type.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindarmour.diff_privacy.DPModel">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.diff_privacy.</code><code class="sig-name descname">DPModel</code><span class="sig-paren">(</span><em class="sig-param">micro_batches=2</em>, <em class="sig-param">norm_bound=1.0</em>, <em class="sig-param">noise_mech=None</em>, <em class="sig-param">clip_mech=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/train/model.html#DPModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.DPModel" title="Permalink to this definition">¶</a></dt>
<dd><p>This class is overload mindspore.train.model.Model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>micro_batches</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of small batches split from an original
batch. Default: 2.</p></li>
<li><p><strong>norm_bound</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Use to clip the bound, if set 1, will return the
original data. Default: 1.0.</p></li>
<li><p><strong>noise_mech</strong> (<em>Mechanisms</em>) – The object can generate the different type of
noise. Default: None.</p></li>
<li><p><strong>clip_mech</strong> (<em>Mechanisms</em>) – The object is used to update the adaptive clip.
Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If DPOptimizer and noise_mecn are both None or not None.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If noise_mech or DPOtimizer’s mech method is adaptive while clip_mech is not None.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">norm_bound</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">initial_noise_multiplier</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batches</span> <span class="o">=</span> <span class="mi">128</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">micro_batches</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">is_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">factory_opt</span> <span class="o">=</span> <span class="n">DPOptimizerClassFactory</span><span class="p">(</span><span class="n">micro_batches</span><span class="o">=</span><span class="n">micro_batches</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">factory_opt</span><span class="o">.</span><span class="n">set_mechanisms</span><span class="p">(</span><span class="s1">&#39;Gaussian&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                           <span class="n">norm_bound</span><span class="o">=</span><span class="n">norm_bound</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                           <span class="n">initial_noise_multiplier</span><span class="o">=</span><span class="n">initial_noise_multiplier</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_opt</span> <span class="o">=</span> <span class="n">factory_opt</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="s1">&#39;Momentum&#39;</span><span class="p">)(</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span>
<span class="gp">&gt;&gt;&gt; </span>                                         <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clip_mech</span> <span class="o">=</span> <span class="n">ClipMechanismsFactory</span><span class="p">()</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="s1">&#39;Gaussian&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                           <span class="n">decay_policy</span><span class="o">=</span><span class="s1">&#39;Linear&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                           <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                           <span class="n">target_unclipped_quantile</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                           <span class="n">fraction_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">DPModel</span><span class="p">(</span><span class="n">micro_batches</span><span class="o">=</span><span class="n">micro_batches</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">norm_bound</span><span class="o">=</span><span class="n">norm_bound</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">clip_mech</span><span class="o">=</span><span class="n">clip_mech</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">noise_mech</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">network</span><span class="o">=</span><span class="n">network</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">optimizer</span><span class="o">=</span><span class="n">net_opt</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms_ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">dataset_generator</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">batches</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span>                            <span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms_ds</span><span class="o">.</span><span class="n">set_dataset_size</span><span class="p">(</span><span class="n">batch_size</span><span class="o">*</span><span class="n">batches</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">ms_ds</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindarmour.diff_privacy.MembershipInference">
<em class="property">class </em><code class="sig-prename descclassname">mindarmour.diff_privacy.</code><code class="sig-name descname">MembershipInference</code><span class="sig-paren">(</span><em class="sig-param">model</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/evaluation/membership_inference.html#MembershipInference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.MembershipInference" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluation proposed by Shokri, Stronati, Song and Shmatikov is a grey-box attack.
The attack requires obtain loss or logits results of training samples.</p>
<p>References: <a class="reference external" href="https://arxiv.org/abs/1610.05820v2">Reza Shokri, Marco Stronati, Congzheng Song, Vitaly Shmatikov.
Membership Inference Attacks against Machine Learning Models. 2017.</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<a class="reference internal" href="../mindspore/mindspore.html#mindspore.Model" title="mindspore.Model"><em>Model</em></a>) – Target model.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_1</span><span class="p">,</span> <span class="n">train_2</span> <span class="n">are</span> <span class="n">non</span><span class="o">-</span><span class="n">overlapping</span> <span class="n">datasets</span> <span class="kn">from</span> <span class="nn">training</span> <span class="n">dataset</span> <span class="n">of</span> <span class="n">target</span> <span class="n">model</span><span class="o">.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_1</span><span class="p">,</span> <span class="n">test_2</span> <span class="n">are</span> <span class="n">non</span><span class="o">-</span><span class="n">overlapping</span> <span class="n">datasets</span> <span class="kn">from</span> <span class="nn">test</span> <span class="n">dataset</span> <span class="n">of</span> <span class="n">target</span> <span class="n">model</span><span class="o">.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">We</span> <span class="n">use</span> <span class="n">train_1</span><span class="p">,</span> <span class="n">test_1</span> <span class="n">to</span> <span class="n">train</span> <span class="n">attack</span> <span class="n">model</span><span class="p">,</span> <span class="ow">and</span> <span class="n">use</span> <span class="n">train_2</span><span class="p">,</span> <span class="n">test_2</span> <span class="n">to</span> <span class="n">evaluate</span> <span class="n">attack</span> <span class="n">model</span><span class="o">.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inference_model</span> <span class="o">=</span> <span class="n">MembershipInference</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;KNN&quot;</span><span class="p">,</span> <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;n_neighbors&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">]}}]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inference_model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_1</span><span class="p">,</span> <span class="n">test_1</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;recall&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">inference_model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">train_2</span><span class="p">,</span> <span class="n">test_2</span><span class="p">,</span> <span class="n">metrics</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If type of model is not mindspore.train.Model.</p>
</dd>
</dl>
<dl class="method">
<dt id="mindarmour.diff_privacy.MembershipInference.eval">
<code class="sig-name descname">eval</code><span class="sig-paren">(</span><em class="sig-param">dataset_train</em>, <em class="sig-param">dataset_test</em>, <em class="sig-param">metrics</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/evaluation/membership_inference.html#MembershipInference.eval"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.MembershipInference.eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the different privacy of the target model.
Evaluation indicators shall be specified by metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset_train</strong> (<em>mindspore.dataset</em>) – The training dataset for the target model.</p></li>
<li><p><strong>dataset_test</strong> (<em>mindspore.dataset</em>) – The test dataset for the target model.</p></li>
<li><p><strong>metrics</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – Evaluation indicators. The value of metrics
must be in [“precision”, “accuracy”, “recall”]. Default: [“precision”].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list, Each element contains an evaluation indicator for the attack model.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindarmour.diff_privacy.MembershipInference.train">
<code class="sig-name descname">train</code><span class="sig-paren">(</span><em class="sig-param">dataset_train</em>, <em class="sig-param">dataset_test</em>, <em class="sig-param">attack_config</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindarmour/diff_privacy/evaluation/membership_inference.html#MembershipInference.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindarmour.diff_privacy.MembershipInference.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Depending on the configuration, use the incoming data set to train the attack model.
Save the attack model to self.attack_list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset_train</strong> (<em>mindspore.dataset</em>) – The training dataset for the target model.</p></li>
<li><p><strong>dataset_test</strong> (<em>mindspore.dataset</em>) – The test set for the target model.</p></li>
<li><p><strong>attack_config</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – <p>Parameter setting for the attack model. The format is
[{“method”: “knn”, “params”: {“n_neighbors”: [3, 5, 7]}},</p>
<blockquote>
<div><p>{“method”: “lr”, “params”: {“C”: np.logspace(-4, 2, 10)}}].</p>
</div></blockquote>
<p>The support methods list is in self.method_list, and the params of each method
must within the range of changeable parameters. Tips of params implement
can be found in
“<a class="reference external" href="https://scikit-learn.org/0.16/modules/generated/sklearn.grid_search.GridSearchCV.html">https://scikit-learn.org/0.16/modules/generated/sklearn.grid_search.GridSearchCV.html</a>”.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#KeyError" title="(in Python v3.8)"><strong>KeyError</strong></a> – If each config in attack_config doesn’t have keys {“method”, “params”}</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the method(case insensitive) in attack_config is not in [“lr”, “knn”, “rf”, “mlp”].</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="mindarmour.fuzzing.html" class="btn btn-neutral float-left" title="mindarmour.fuzzing" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, MindSpore

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>