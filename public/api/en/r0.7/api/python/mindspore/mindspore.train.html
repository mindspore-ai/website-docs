<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.train &mdash; MindSpore master documentation</title><link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="mindspore.dataset" href="mindspore.dataset.html" />
    <link rel="prev" title="mindspore.parallel" href="mindspore.parallel.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">MindSpore Python API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dtype.html">mindspore.dtype</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.hub.html">mindspore.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.dynamic_lr.html">mindspore.nn.dynamic_lr</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.learning_rate_schedule.html">mindspore.nn.learning_rate_schedule</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.composite.html">mindspore.ops.composite</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.operations.html">mindspore.ops.operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.parallel.html">mindspore.parallel</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindspore.train</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.train.summary">mindspore.train.summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.train.callback">mindspore.train.callback</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.train.serialization">mindspore.train.serialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.train.amp">mindspore.train.amp</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.train.loss_scale_manager">mindspore.train.loss_scale_manager</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.train.quant">mindspore.train.quant</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.transforms.vision.html">mindspore.dataset.transforms.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.profiler.html">mindspore.profiler</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindInsight Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindinsight/mindinsight.lineagemgr.html">mindinsight.lineagemgr</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindArmour Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.html">mindarmour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.utils.html">mindarmour.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.evaluations.html">mindarmour.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.detectors.html">mindarmour.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.attacks.html">mindarmour.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.defenses.html">mindarmour.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.fuzzing.html">mindarmour.fuzzing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.diff_privacy.html">mindarmour.diff_privacy</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>mindspore.train</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/api/python/mindspore/mindspore.train.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mindspore-train">
<h1>mindspore.train<a class="headerlink" href="#mindspore-train" title="Permalink to this headline"></a></h1>
<section id="module-mindspore.train.summary">
<span id="mindspore-train-summary"></span><h2>mindspore.train.summary<a class="headerlink" href="#module-mindspore.train.summary" title="Permalink to this headline"></a></h2>
<p>SummaryRecord.</p>
<p>User can use SummaryRecord to dump the summary data, the summary is a series of operations
to collect data for analysis and visualization.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.summary.SummaryRecord">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.summary.</span></span><span class="sig-name descname"><span class="pre">SummaryRecord</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">queue_max_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flush_time</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">120</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'events'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_suffix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'_MS'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">network</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_file_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/summary/summary_record.html#SummaryRecord"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.summary.SummaryRecord" title="Permalink to this definition"></a></dt>
<dd><p>SummaryRecord is used to record the summary data and lineage data.</p>
<p>The API will create a summary file and lineage files lazily in a given directory and writes data to them.
It writes the data to files by executing the ‘record’ method. In addition to recording the data bubbled up from
the network by defining the summary operators, SummaryRecord also supports to record extra data which
can be added by calling add_value.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ol class="arabic simple">
<li><p>Make sure to close the SummaryRecord at the end, otherwise the process will not exit.
Please see the Example section below to learn how to close properly in two ways.</p></li>
<li><p>Only one SummaryRecord instance is allowed at a time, otherwise it will cause data writing problems.</p></li>
</ol>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_dir</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The log_dir is a directory location to save the summary.</p></li>
<li><p><strong>queue_max_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Deprecated. The capacity of event queue.(reserved). Default: 0.</p></li>
<li><p><strong>flush_time</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Deprecated. Frequency of flush the summary file to disk. The unit is second. Default: 120.</p></li>
<li><p><strong>file_prefix</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The prefix of file. Default: “events”.</p></li>
<li><p><strong>file_suffix</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The suffix of file. Default: “_MS”.</p></li>
<li><p><strong>network</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Obtain a pipeline through network for saving graph summary. Default: None.</p></li>
<li><p><strong>max_file_size</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – The maximum size of each file that can be written to disk (in bytes).             Unlimited by default. For example, to write not larger than 4GB, specify <cite>max_file_size=4 * 1024**3</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If the data type of <cite>max_file_size</cite>, <cite>queue_max_size</cite> or <cite>flush_time</cite> is not int,             or the data type of <cite>file_prefix</cite> and <cite>file_suffix</cite> is not str.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – If the log_dir is not a normalized absolute path name.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># use in with statement to auto close</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./summary_dir&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">summary_record</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">pass</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># use in try .. finally .. to ensure closing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">try</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">summary_record</span> <span class="o">=</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./summary_dir&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">finally</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">summary_record</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.summary.SummaryRecord.add_value">
<span class="sig-name descname"><span class="pre">add_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">plugin</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/summary/summary_record.html#SummaryRecord.add_value"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.summary.SummaryRecord.add_value" title="Permalink to this definition"></a></dt>
<dd><p>Add value to be recorded later.</p>
<p>When the plugin is ‘tensor’, ‘scalar’, ‘image’ or ‘histogram’,
the name should be the tag name, and the value should be a Tensor.</p>
<p>When the plugin is ‘graph’, the value should be a GraphProto.</p>
<p>When the plugin is ‘dataset_graph’, ‘train_lineage’, ‘eval_lineage’,
or ‘custom_lineage_data’, the value should be a proto message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>plugin</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The value of the plugin.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The value of the name.</p></li>
<li><p><strong>value</strong> (<em>Union</em><em>[</em><a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><em>GraphProto</em><em>, </em><em>TrainLineage</em><em>, </em><em>EvaluationLineage</em><em>, </em><em>DatasetGraph</em><em>, </em><em>UserDefinedInfo</em><em>]</em>) – <p>The value to store.</p>
<ul>
<li><p>The data type of value should be ‘GraphProto’ when the plugin is ‘graph’.</p></li>
<li><p>The data type of value should be ‘Tensor’ when the plugin is ‘scalar’, ‘image’, ‘tensor’
or ‘histogram’.</p></li>
<li><p>The data type of value should be ‘TrainLineage’ when the plugin is ‘train_lineage’.</p></li>
<li><p>The data type of value should be ‘EvaluationLineage’ when the plugin is ‘eval_lineage’.</p></li>
<li><p>The data type of value should be ‘DatasetGraph’ when the plugin is ‘dataset_graph’.</p></li>
<li><p>The data type of value should be  ‘UserDefinedInfo’ when the plugin is ‘custom_lineage_data’.</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – When the name is not valid.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – When the value is not a Tensor.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./summary_dir&quot;</span><span class="p">,</span> <span class="n">file_prefix</span><span class="o">=</span><span class="s2">&quot;xxx_&quot;</span><span class="p">,</span> <span class="n">file_suffix</span><span class="o">=</span><span class="s2">&quot;_yyy&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">summary_record</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">summary_record</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s1">&#39;scalar&#39;</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.summary.SummaryRecord.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/summary/summary_record.html#SummaryRecord.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.summary.SummaryRecord.close" title="Permalink to this definition"></a></dt>
<dd><p>Flush all events and close summary records. Please use the statement to autoclose.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">try</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">summary_record</span> <span class="o">=</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./summary_dir&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">finally</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">summary_record</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.summary.SummaryRecord.flush">
<span class="sig-name descname"><span class="pre">flush</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/summary/summary_record.html#SummaryRecord.flush"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.summary.SummaryRecord.flush" title="Permalink to this definition"></a></dt>
<dd><p>Flush the event file to disk.</p>
<p>Call it to make sure that all pending events have been written to disk.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./summary_dir&quot;</span><span class="p">,</span> <span class="n">file_prefix</span><span class="o">=</span><span class="s2">&quot;xxx_&quot;</span><span class="p">,</span> <span class="n">file_suffix</span><span class="o">=</span><span class="s2">&quot;_yyy&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">summary_record</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">summary_record</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.summary.SummaryRecord.log_dir">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">log_dir</span></span><a class="headerlink" href="#mindspore.train.summary.SummaryRecord.log_dir" title="Permalink to this definition"></a></dt>
<dd><p>Get the full path of the log file.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>str, the full path of log file.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./summary_dir&quot;</span><span class="p">,</span> <span class="n">file_prefix</span><span class="o">=</span><span class="s2">&quot;xxx_&quot;</span><span class="p">,</span> <span class="n">file_suffix</span><span class="o">=</span><span class="s2">&quot;_yyy&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">summary_record</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="n">summary_record</span><span class="o">.</span><span class="n">log_dir</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.summary.SummaryRecord.record">
<span class="sig-name descname"><span class="pre">record</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_network</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plugin_filter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/summary/summary_record.html#SummaryRecord.record"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.summary.SummaryRecord.record" title="Permalink to this definition"></a></dt>
<dd><p>Record the summary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>step</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Represents training step number.</p></li>
<li><p><strong>train_network</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The network to call the callback.</p></li>
<li><p><strong>plugin_filter</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>]</em><em>]</em>) – The filter function,                 which is used to filter out plugins from being written by returning False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>bool, whether the record process is successful or not.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./summary_dir&quot;</span><span class="p">,</span> <span class="n">file_prefix</span><span class="o">=</span><span class="s2">&quot;xxx_&quot;</span><span class="p">,</span> <span class="n">file_suffix</span><span class="o">=</span><span class="s2">&quot;_yyy&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">summary_record</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">summary_record</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="n">step</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.summary.SummaryRecord.set_mode">
<span class="sig-name descname"><span class="pre">set_mode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/summary/summary_record.html#SummaryRecord.set_mode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.summary.SummaryRecord.set_mode" title="Permalink to this definition"></a></dt>
<dd><p>Set the mode for the recorder to be aware. The mode is set to ‘train’ by default.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The mode to be set, which should be ‘train’ or ‘eval’.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – When the mode is not recognized.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./summary_dir&quot;</span><span class="p">,</span> <span class="n">file_prefix</span><span class="o">=</span><span class="s2">&quot;xxx_&quot;</span><span class="p">,</span> <span class="n">file_suffix</span><span class="o">=</span><span class="s2">&quot;_yyy&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">summary_record</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">summary_record</span><span class="o">.</span><span class="n">set_mode</span><span class="p">(</span><span class="s1">&#39;eval&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="module-mindspore.train.callback">
<span id="mindspore-train-callback"></span><h2>mindspore.train.callback<a class="headerlink" href="#module-mindspore.train.callback" title="Permalink to this headline"></a></h2>
<p>Callback related classes and functions.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.callback.Callback">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.callback.</span></span><span class="sig-name descname"><span class="pre">Callback</span></span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_callback.html#Callback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.Callback" title="Permalink to this definition"></a></dt>
<dd><p>Abstract base class used to build a callback class. Callbacks are context managers
which will be entered and exited when passing into the Model.
You can use this mechanism to initialize and release resources automatically.</p>
<p>Callback function will execute some operations in the current step or epoch.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Print_info</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">cb_params</span><span class="o">.</span><span class="n">cur_epoch_num</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">print_cb</span> <span class="o">=</span> <span class="n">Print_info</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">print_cb</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.Callback.begin">
<span class="sig-name descname"><span class="pre">begin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_callback.html#Callback.begin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.Callback.begin" title="Permalink to this definition"></a></dt>
<dd><p>Called once before the network executing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Include some information of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.Callback.end">
<span class="sig-name descname"><span class="pre">end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_callback.html#Callback.end"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.Callback.end" title="Permalink to this definition"></a></dt>
<dd><p>Called once after network training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Include some information of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.Callback.epoch_begin">
<span class="sig-name descname"><span class="pre">epoch_begin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_callback.html#Callback.epoch_begin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.Callback.epoch_begin" title="Permalink to this definition"></a></dt>
<dd><p>Called before each epoch beginning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Include some information of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.Callback.epoch_end">
<span class="sig-name descname"><span class="pre">epoch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_callback.html#Callback.epoch_end"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.Callback.epoch_end" title="Permalink to this definition"></a></dt>
<dd><p>Called after each epoch finished.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Include some information of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.Callback.step_begin">
<span class="sig-name descname"><span class="pre">step_begin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_callback.html#Callback.step_begin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.Callback.step_begin" title="Permalink to this definition"></a></dt>
<dd><p>Called before each epoch beginning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Include some information of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.Callback.step_end">
<span class="sig-name descname"><span class="pre">step_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_callback.html#Callback.step_end"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.Callback.step_end" title="Permalink to this definition"></a></dt>
<dd><p>Called after each step finished.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Include some information of the model.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.callback.</span></span><span class="sig-name descname"><span class="pre">CheckpointConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_checkpoint_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_checkpoint_seconds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_checkpoint_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_checkpoint_per_n_minutes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integrated_save</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">async_save</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_checkpoint.html#CheckpointConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig" title="Permalink to this definition"></a></dt>
<dd><p>The configuration of model checkpoint.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>During the training process, if dataset is transmitted through the data channel,
It is suggested to set ‘save_checkpoint_steps’ to an integer multiple of loop_size.
Otherwise, the time to save the checkpoint may be biased.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_checkpoint_steps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Steps to save checkpoint. Default: 1.</p></li>
<li><p><strong>save_checkpoint_seconds</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Seconds to save checkpoint. Default: 0.
Can’t be used with save_checkpoint_steps at the same time.</p></li>
<li><p><strong>keep_checkpoint_max</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Maximum number of checkpoint files can be saved. Default: 5.</p></li>
<li><p><strong>keep_checkpoint_per_n_minutes</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Keep one checkpoint every n minutes. Default: 0.
Can’t be used with keep_checkpoint_max at the same time.</p></li>
<li><p><strong>integrated_save</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to perform integrated save function in automatic model parallel scene.
Default: True. Integrated save function is only supported in automatic parallel scene, not supported
in manual parallel.</p></li>
<li><p><strong>async_save</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether asynchronous execution saves the checkpoint to a file. Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the input_param is None or 0.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">config</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ckpoint_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;ck_prefix&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s1">&#39;./&#39;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">ckpoint_cb</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.async_save">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">async_save</span></span><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.async_save" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of _async_save.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.get_checkpoint_policy">
<span class="sig-name descname"><span class="pre">get_checkpoint_policy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_checkpoint.html#CheckpointConfig.get_checkpoint_policy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.get_checkpoint_policy" title="Permalink to this definition"></a></dt>
<dd><p>Get the policy of checkpoint.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.integrated_save">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">integrated_save</span></span><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.integrated_save" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of _integrated_save.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.keep_checkpoint_max">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">keep_checkpoint_max</span></span><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.keep_checkpoint_max" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of _keep_checkpoint_max.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.keep_checkpoint_per_n_minutes">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">keep_checkpoint_per_n_minutes</span></span><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.keep_checkpoint_per_n_minutes" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of _keep_checkpoint_per_n_minutes.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.save_checkpoint_seconds">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">save_checkpoint_seconds</span></span><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.save_checkpoint_seconds" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of _save_checkpoint_seconds.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.save_checkpoint_steps">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">save_checkpoint_steps</span></span><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.save_checkpoint_steps" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of _save_checkpoint_steps.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.callback.LossMonitor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.callback.</span></span><span class="sig-name descname"><span class="pre">LossMonitor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">per_print_times</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_loss_monitor.html#LossMonitor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.LossMonitor" title="Permalink to this definition"></a></dt>
<dd><p>Monitor the loss in training.</p>
<p>If the loss is NAN or INF, it will terminate training.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If per_print_times is 0, do not print loss.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>per_print_times</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Print the loss each every time. Default: 1.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If print_step is not an integer or less than zero.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.callback.ModelCheckpoint">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.callback.</span></span><span class="sig-name descname"><span class="pre">ModelCheckpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'CKP'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">directory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_checkpoint.html#ModelCheckpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.ModelCheckpoint" title="Permalink to this definition"></a></dt>
<dd><p>The checkpoint callback class.</p>
<p>It is called to combine with train process and save the model and network parameters after traning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The prefix name of checkpoint files. Default: “CKP”.</p></li>
<li><p><strong>directory</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The path of the folder which will be saved in the checkpoint file. Default: None.</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="#mindspore.train.callback.CheckpointConfig" title="mindspore.train.callback.CheckpointConfig"><em>CheckpointConfig</em></a>) – Checkpoint strategy configuration. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the prefix is invalid.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If the config is not CheckpointConfig type.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.ModelCheckpoint.end">
<span class="sig-name descname"><span class="pre">end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_checkpoint.html#ModelCheckpoint.end"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.ModelCheckpoint.end" title="Permalink to this definition"></a></dt>
<dd><p>Save the last checkpoint after training finished.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Context of the train running.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.ModelCheckpoint.latest_ckpt_file_name">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">latest_ckpt_file_name</span></span><a class="headerlink" href="#mindspore.train.callback.ModelCheckpoint.latest_ckpt_file_name" title="Permalink to this definition"></a></dt>
<dd><p>Return the latest checkpoint path and file name.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.ModelCheckpoint.step_end">
<span class="sig-name descname"><span class="pre">step_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_checkpoint.html#ModelCheckpoint.step_end"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.ModelCheckpoint.step_end" title="Permalink to this definition"></a></dt>
<dd><p>Save the checkpoint at the end of step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Context of the train running.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.callback.RunContext">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.callback.</span></span><span class="sig-name descname"><span class="pre">RunContext</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">original_args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_callback.html#RunContext"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.RunContext" title="Permalink to this definition"></a></dt>
<dd><p>Provides information about the model.</p>
<p>Provides information about original request to model function.
Callback objects can stop the loop by calling request_stop() of run_context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>original_args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – Holding the related information of model.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.RunContext.get_stop_requested">
<span class="sig-name descname"><span class="pre">get_stop_requested</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_callback.html#RunContext.get_stop_requested"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.RunContext.get_stop_requested" title="Permalink to this definition"></a></dt>
<dd><p>Returns whether a stop is requested or not.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>bool, if true, model.train() stops iterations.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.RunContext.original_args">
<span class="sig-name descname"><span class="pre">original_args</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_callback.html#RunContext.original_args"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.RunContext.original_args" title="Permalink to this definition"></a></dt>
<dd><p>Get the _original_args object.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dict, an object that holds the original arguments of model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.RunContext.request_stop">
<span class="sig-name descname"><span class="pre">request_stop</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_callback.html#RunContext.request_stop"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.RunContext.request_stop" title="Permalink to this definition"></a></dt>
<dd><p>Sets stop requirement during training.</p>
<p>Callbacks can use this function to request stop of iterations.
model.train() checks whether this is called or not.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.callback.SummaryCollector">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.callback.</span></span><span class="sig-name descname"><span class="pre">SummaryCollector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">summary_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collect_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collect_specified_data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_default_action</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_lineage_data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collect_tensor_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_file_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_summary_collector.html#SummaryCollector"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.SummaryCollector" title="Permalink to this definition"></a></dt>
<dd><p>SummaryCollector can help you to collect some common information.</p>
<p>It can help you to collect loss, learning late, computational graph and so on.
SummaryCollector also enables the summary operator to collect data from a summary file.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ol class="arabic simple">
<li><p>Multiple SummaryCollector instances in callback list are not allowed.</p></li>
<li><p>Not all information is collected at the training phase or at the eval phase.</p></li>
<li><p>SummaryCollector always record the data collected by the summary operator.</p></li>
</ol>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>summary_dir</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The collected data will be persisted to this directory.
If the directory does not exist, it will be created automatically.</p></li>
<li><p><strong>collect_freq</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Set the frequency of data collection, it should be greater then zero,
and the unit is <cite>step</cite>. Default: 10. If a frequency is set, we will collect data
when (current steps % freq) equals to 0, and the first step will be collected at any time.
It is important to note that if the data sink mode is used, the unit will become the <cite>epoch</cite>.
It is not recommended to collect data too frequently, which can affect performance.</p></li>
<li><p><strong>collect_specified_data</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a><em>]</em>) – <p>Perform custom operations on the collected data. Default: None.
By default, if set to None, all data is collected as the default behavior.
You can customize the collected data with a dictionary.
For example, you can set {‘collect_metric’: False} to control not collecting metrics.
The data that supports control is shown below.</p>
<ul>
<li><p>collect_metric: Whether to collect training metrics, currently only the loss is collected.
The first output will be treated as the loss and it will be averaged.
Optional: True/False. Default: True.</p></li>
<li><p>collect_graph: Whether to collect the computational graph. Currently, only
training computational graph is collected. Optional: True/False. Default: True.</p></li>
<li><p>collect_train_lineage: Whether to collect lineage data for the training phase,
this field will be displayed on the lineage page of Mindinsight. Optional: True/False. Default: True.</p></li>
<li><p>collect_eval_lineage: Whether to collect lineage data for the evaluation phase,
this field will be displayed on the lineage page of Mindinsight. Optional: True/False. Default: True.</p></li>
<li><p>collect_input_data: Whether to collect dataset for each training. Currently only image data is supported.
Optional: True/False. Default: True.</p></li>
<li><p>collect_dataset_graph: Whether to collect dataset graph for the training phase.
Optional: True/False. Default: True.</p></li>
<li><p>histogram_regular: Collect weight and bias for parameter distribution page and displayed in MindInsight.
This field allows regular strings to control which parameters to collect.
Default: None, it means only the first five parameters are collected.
It is not recommended to collect too many parameters at once, as it can affect performance.
Note that if you collect too many parameters and run out of memory, the training will fail.</p></li>
</ul>
</p></li>
<li><p><strong>keep_default_action</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – This field affects the collection behavior of the ‘collect_specified_data’ field.
Optional: True/False, Default: True.
True: it means that after specified data is set, non-specified data is collected as the default behavior.
False: it means that after specified data is set, only the specified data is collected,
and the others are not collected.</p></li>
<li><p><strong>custom_lineage_data</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a><em>, </em><em>None</em><em>]</em>) – Allows you to customize the data and present it on the MingInsight
lineage page. In the custom data, the type of the key supports str, and the type of value supports str, int
and float. Default: None, it means there is no custom data.</p></li>
<li><p><strong>collect_tensor_freq</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – The same semantics as the <cite>collect_freq</cite>, but controls TensorSummary only.
Because TensorSummary data is too large to be compared with other summary data, this parameter is used to
reduce its collection. By default, The maximum number of steps for collecting TensorSummary data is 20,
but it will not exceed the number of steps for collecting other summary data.
Default: None, which means to follow the behavior as described above. For example, given <cite>collect_freq=10</cite>,
when the total steps is 600, TensorSummary will be collected 20 steps, while other summary data 61 steps,
but when the total steps is 20, both TensorSummary and other summary will be collected 3 steps.
Also note that when in parallel mode, the total steps will be splitted evenly, which will
affect the number of steps TensorSummary will be collected.</p></li>
<li><p><strong>max_file_size</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – The maximum size in bytes of each file that can be written to the disk.
Default: None, which means no limit. For example, to write not larger than 4GB,
specify <cite>max_file_size=4 * 1024**3</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the parameter value is not expected.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If the parameter type is not expected.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – If an error occurs during data collection.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Simple usage:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">summary_collector</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">summary_collector</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Do not collect metric and collect the first layer parameter, others are collected by default</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">specified</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;collect_metric&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;histogram_regular&#39;</span><span class="p">:</span> <span class="s1">&#39;^conv1.*&#39;</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">summary_collector</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">,</span> <span class="n">collect_specified_data</span><span class="o">=</span><span class="n">specified</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">summary_collector</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Only collect metric, custom lineage data and record data that collected by the summary operator,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># others are not collected</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">specified</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;collect_metric&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">summary_collector</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                     <span class="n">collect_specified_data</span><span class="o">=</span><span class="n">specified</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                     <span class="n">keep_default_action</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                     <span class="n">custom_lineage_data</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;version&#39;</span><span class="p">:</span> <span class="s1">&#39;resnet50_v1&#39;</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span>                                     <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">summary_collector</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.callback.TimeMonitor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.callback.</span></span><span class="sig-name descname"><span class="pre">TimeMonitor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/callback/_time_monitor.html#TimeMonitor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.TimeMonitor" title="Permalink to this definition"></a></dt>
<dd><p>Monitor the time in training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Dataset size. Default: None.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-mindspore.train.serialization">
<span id="mindspore-train-serialization"></span><h2>mindspore.train.serialization<a class="headerlink" href="#module-mindspore.train.serialization" title="Permalink to this headline"></a></h2>
<p>Model and parameters serialization.</p>
<dl class="py function">
<dt class="sig sig-object py" id="mindspore.train.serialization.build_searched_strategy">
<span class="sig-prename descclassname"><span class="pre">mindspore.train.serialization.</span></span><span class="sig-name descname"><span class="pre">build_searched_strategy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">strategy_filename</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/serialization.html#build_searched_strategy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.serialization.build_searched_strategy" title="Permalink to this definition"></a></dt>
<dd><p>Build strategy of every parameter in network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>strategy_filename</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Name of strategy file.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dictionary, whose key is parameter name and value is slice strategy of this parameter.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Strategy file is incorrect.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – Strategy_filename is not str.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">strategy_filename</span> <span class="o">=</span> <span class="s2">&quot;./strategy_train.ckpt&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">strategy</span> <span class="o">=</span> <span class="n">build_searched_strategy</span><span class="p">(</span><span class="n">strategy_filename</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.train.serialization.export">
<span class="sig-prename descclassname"><span class="pre">mindspore.train.serialization.</span></span><span class="sig-name descname"><span class="pre">export</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">net</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'AIR'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/serialization.html#export"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.serialization.export" title="Permalink to this definition"></a></dt>
<dd><p>Export the MindSpore prediction model to a file in the specified format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – MindSpore network.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – Inputs of the <cite>net</cite>.</p></li>
<li><p><strong>file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – File name of the model to be exported.</p></li>
<li><p><strong>file_format</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>MindSpore currently supports ‘AIR’, ‘ONNX’ and ‘MINDIR’ format for exported model.</p>
<ul>
<li><p>AIR: Ascend Intermidiate Representation. An intermidiate representation format of Ascend model.
Recommended suffix for output file is ‘.air’.</p></li>
<li><p>ONNX: Open Neural Network eXchange. An open format built to represent machine learning models.
Recommended suffix for output file is ‘.onnx’.</p></li>
<li><p>MINDIR: MindSpore Native Intermidiate Representation for Anf. An intermidiate representation format
for MindSpore models.
Recommended suffix for output file is ‘.mindir’.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.train.serialization.load_checkpoint">
<span class="sig-prename descclassname"><span class="pre">mindspore.train.serialization.</span></span><span class="sig-name descname"><span class="pre">load_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_file_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/serialization.html#load_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.serialization.load_checkpoint" title="Permalink to this definition"></a></dt>
<dd><p>Loads checkpoint info from a specified file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Checkpoint file name.</p></li>
<li><p><strong>net</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Cell network. Default: None</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict, key is parameter name, value is a Parameter.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Checkpoint file is incorrect.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.train.serialization.load_param_into_net">
<span class="sig-prename descclassname"><span class="pre">mindspore.train.serialization.</span></span><span class="sig-name descname"><span class="pre">load_param_into_net</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">net</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameter_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/serialization.html#load_param_into_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.serialization.load_param_into_net" title="Permalink to this definition"></a></dt>
<dd><p>Loads parameters into network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Cell network.</p></li>
<li><p><strong>parameter_dict</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – Parameter dictionary.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – Argument is not a Cell, or parameter_dict is not a Parameter dictionary.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.train.serialization.merge_sliced_parameter">
<span class="sig-prename descclassname"><span class="pre">mindspore.train.serialization.</span></span><span class="sig-name descname"><span class="pre">merge_sliced_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sliced_parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/serialization.html#merge_sliced_parameter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.serialization.merge_sliced_parameter" title="Permalink to this definition"></a></dt>
<dd><p>Merge parameter slices to one whole parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sliced_parameters</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a><em>]</em>) – Parameter slices in order of rank_id.</p></li>
<li><p><strong>strategy</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – <p>Parameter slice strategy, the default is None.
If strategy is None, just merge parameter slices in 0 axis order.</p>
<ul>
<li><p>key (str): Parameter name.</p></li>
<li><p>value (&lt;class ‘node_strategy_pb2.ParallelLayouts’&gt;): Slice strategy of this parameter.</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Parameter, the merged parameter which has the whole data.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Failed to merge.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – The sliced_parameters is incorrect or strategy is not dict.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#KeyError" title="(in Python v3.8)"><strong>KeyError</strong></a> – The parameter name is not in keys of strategy.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">strategy</span> <span class="o">=</span> <span class="n">build_searched_strategy</span><span class="p">(</span><span class="s2">&quot;./strategy_train.ckpt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sliced_parameters</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">&gt;&gt;&gt; </span>                     <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.00023915</span><span class="p">,</span> <span class="mf">0.00013939</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00098059</span><span class="p">])),</span>
<span class="gp">&gt;&gt;&gt; </span>                               <span class="s2">&quot;network.embedding_table&quot;</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span>                     <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.00015815</span><span class="p">,</span> <span class="mf">0.00015458</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00012125</span><span class="p">])),</span>
<span class="gp">&gt;&gt;&gt; </span>                               <span class="s2">&quot;network.embedding_table&quot;</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span>                     <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.00042165</span><span class="p">,</span> <span class="mf">0.00029692</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00007941</span><span class="p">])),</span>
<span class="gp">&gt;&gt;&gt; </span>                               <span class="s2">&quot;network.embedding_table&quot;</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span>                     <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.00084451</span><span class="p">,</span> <span class="mf">0.00089960</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00010431</span><span class="p">])),</span>
<span class="gp">&gt;&gt;&gt; </span>                               <span class="s2">&quot;network.embedding_table&quot;</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">merged_parameter</span> <span class="o">=</span> <span class="n">merge_sliced_parameter</span><span class="p">(</span><span class="n">sliced_parameters</span><span class="p">,</span> <span class="n">strategy</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.train.serialization.parse_print">
<span class="sig-prename descclassname"><span class="pre">mindspore.train.serialization.</span></span><span class="sig-name descname"><span class="pre">parse_print</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">print_file_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/serialization.html#parse_print"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.serialization.parse_print" title="Permalink to this definition"></a></dt>
<dd><p>Loads Print data from a specified file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>print_file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The file name of saved print data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List, element of list is Tensor.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – The print file may be empty, please make sure enter the correct file name.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.train.serialization.save_checkpoint">
<span class="sig-prename descclassname"><span class="pre">mindspore.train.serialization.</span></span><span class="sig-name descname"><span class="pre">save_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameter_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_file_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">async_save</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/serialization.html#save_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.serialization.save_checkpoint" title="Permalink to this definition"></a></dt>
<dd><p>Saves checkpoint info to a specified file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameter_list</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – Parameters list, each element is a dictionary
like {“name”:xx, “type”:xx, “shape”:xx, “data”:xx}.</p></li>
<li><p><strong>ckpt_file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Checkpoint file name.</p></li>
<li><p><strong>async_save</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether asynchronous execution saves the checkpoint to a file. Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – Failed to save the Checkpoint file.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-mindspore.train.amp">
<span id="mindspore-train-amp"></span><h2>mindspore.train.amp<a class="headerlink" href="#module-mindspore.train.amp" title="Permalink to this headline"></a></h2>
<p>Auto mixed precision.</p>
<dl class="py function">
<dt class="sig sig-object py" id="mindspore.train.amp.build_train_network">
<span class="sig-prename descclassname"><span class="pre">mindspore.train.amp.</span></span><span class="sig-name descname"><span class="pre">build_train_network</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'O0'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/amp.html#build_train_network"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.amp.build_train_network" title="Permalink to this definition"></a></dt>
<dd><p>Build the mixed precision training cell automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Definition of the network.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a><em>]</em>) – Definition of the loss_fn. If None, the <cite>network</cite> should have the loss inside.
Default: None.</p></li>
<li><p><strong>optimizer</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Optimizer" title="mindspore.nn.Optimizer"><em>Optimizer</em></a>) – Optimizer to update the Parameter.</p></li>
<li><p><strong>level</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>Supports [O0, O2, O3]. Default: “O0”.</p>
<ul>
<li><p>O0: Do not change.</p></li>
<li><p>O2: Cast network to float16, keep batchnorm and <cite>loss_fn</cite> (if set) run in float32,
using dynamic loss scale.</p></li>
<li><p>O3: Cast network to float16, with additional property ‘keep_batchnorm_fp32=False’.</p></li>
</ul>
<p>O2 is recommended on GPU, O3 is recommended on Ascend.</p>
</p></li>
<li><p><strong>cast_model_type</strong> (<a class="reference internal" href="mindspore.dtype.html#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – Supports <cite>mstype.float16</cite> or <cite>mstype.float32</cite>.
If set to <cite>mstype.float16</cite>, use <cite>float16</cite> mode to train. If set, overwrite the level setting.</p></li>
<li><p><strong>keep_batchnorm_fp32</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Keep Batchnorm run in <cite>float32</cite>. If set, overwrite the level setting.
Only <cite>cast_model_type</cite> is <cite>float16</cite>, <cite>keep_batchnorm_fp32</cite> will take effect.</p></li>
<li><p><strong>loss_scale_manager</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference internal" href="#mindspore.train.loss_scale_manager.LossScaleManager" title="mindspore.train.loss_scale_manager.LossScaleManager"><em>LossScaleManager</em></a><em>]</em>) – If None, not scale the loss, or else
scale the loss by LossScaleManager. If set, overwrite the level setting.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-mindspore.train.loss_scale_manager">
<span id="mindspore-train-loss-scale-manager"></span><h2>mindspore.train.loss_scale_manager<a class="headerlink" href="#module-mindspore.train.loss_scale_manager" title="Permalink to this headline"></a></h2>
<p>Loss scale manager abstract class.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.loss_scale_manager.DynamicLossScaleManager">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.loss_scale_manager.</span></span><span class="sig-name descname"><span class="pre">DynamicLossScaleManager</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">init_loss_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16777216</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_window</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.loss_scale_manager.DynamicLossScaleManager" title="Permalink to this definition"></a></dt>
<dd><p>Dynamic loss-scale manager.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init_loss_scale</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Initialize loss scale. Default: 2**24.</p></li>
<li><p><strong>scale_factor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Coefficient of increase and decrease. Default: 2.</p></li>
<li><p><strong>scale_window</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Maximum continuous normal steps when there is no overflow. Default: 2000.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">DynamicLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.loss_scale_manager.DynamicLossScaleManager.get_drop_overflow_update">
<span class="sig-name descname"><span class="pre">get_drop_overflow_update</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager.get_drop_overflow_update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.loss_scale_manager.DynamicLossScaleManager.get_drop_overflow_update" title="Permalink to this definition"></a></dt>
<dd><p>Get the flag whether to drop optimizer update when there is an overflow.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.loss_scale_manager.DynamicLossScaleManager.get_loss_scale">
<span class="sig-name descname"><span class="pre">get_loss_scale</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager.get_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.loss_scale_manager.DynamicLossScaleManager.get_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Get loss scale value.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.loss_scale_manager.DynamicLossScaleManager.get_update_cell">
<span class="sig-name descname"><span class="pre">get_update_cell</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager.get_update_cell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.loss_scale_manager.DynamicLossScaleManager.get_update_cell" title="Permalink to this definition"></a></dt>
<dd><p>Returns the cell for <cite>TrainOneStepWithLossScaleCell</cite></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.loss_scale_manager.DynamicLossScaleManager.update_loss_scale">
<span class="sig-name descname"><span class="pre">update_loss_scale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overflow</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager.update_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.loss_scale_manager.DynamicLossScaleManager.update_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Update loss scale value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>overflow</strong> – Boolean. Whether it overflows.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.loss_scale_manager.FixedLossScaleManager">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.loss_scale_manager.</span></span><span class="sig-name descname"><span class="pre">FixedLossScaleManager</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_overflow_update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.loss_scale_manager.FixedLossScaleManager" title="Permalink to this definition"></a></dt>
<dd><p>Fixed loss-scale manager.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss_scale</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Loss scale. Default: 128.0.</p></li>
<li><p><strong>drop_overflow_update</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – whether to execute optimizer if there is an overflow. Default: True.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.loss_scale_manager.FixedLossScaleManager.get_drop_overflow_update">
<span class="sig-name descname"><span class="pre">get_drop_overflow_update</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager.get_drop_overflow_update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.loss_scale_manager.FixedLossScaleManager.get_drop_overflow_update" title="Permalink to this definition"></a></dt>
<dd><p>Get the flag whether to drop optimizer update when there is an overflow.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.loss_scale_manager.FixedLossScaleManager.get_loss_scale">
<span class="sig-name descname"><span class="pre">get_loss_scale</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager.get_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.loss_scale_manager.FixedLossScaleManager.get_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Get loss scale value.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.loss_scale_manager.FixedLossScaleManager.get_update_cell">
<span class="sig-name descname"><span class="pre">get_update_cell</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager.get_update_cell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.loss_scale_manager.FixedLossScaleManager.get_update_cell" title="Permalink to this definition"></a></dt>
<dd><p>Returns the cell for <cite>TrainOneStepWithLossScaleCell</cite></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.loss_scale_manager.FixedLossScaleManager.update_loss_scale">
<span class="sig-name descname"><span class="pre">update_loss_scale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overflow</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager.update_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.loss_scale_manager.FixedLossScaleManager.update_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Update loss scale value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>overflow</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether it overflows.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.loss_scale_manager.LossScaleManager">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.loss_scale_manager.</span></span><span class="sig-name descname"><span class="pre">LossScaleManager</span></span><a class="reference internal" href="../../../_modules/mindspore/train/loss_scale_manager.html#LossScaleManager"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.loss_scale_manager.LossScaleManager" title="Permalink to this definition"></a></dt>
<dd><p>Loss scale manager abstract class.</p>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.loss_scale_manager.LossScaleManager.get_loss_scale">
<span class="sig-name descname"><span class="pre">get_loss_scale</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/loss_scale_manager.html#LossScaleManager.get_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.loss_scale_manager.LossScaleManager.get_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Get loss scale value.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.loss_scale_manager.LossScaleManager.get_update_cell">
<span class="sig-name descname"><span class="pre">get_update_cell</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/loss_scale_manager.html#LossScaleManager.get_update_cell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.loss_scale_manager.LossScaleManager.get_update_cell" title="Permalink to this definition"></a></dt>
<dd><p>Get the loss scaling update logic cell.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.loss_scale_manager.LossScaleManager.update_loss_scale">
<span class="sig-name descname"><span class="pre">update_loss_scale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overflow</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/loss_scale_manager.html#LossScaleManager.update_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.loss_scale_manager.LossScaleManager.update_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Update loss scale value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>overflow</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether it overflows.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-mindspore.train.quant">
<span id="mindspore-train-quant"></span><h2>mindspore.train.quant<a class="headerlink" href="#module-mindspore.train.quant" title="Permalink to this headline"></a></h2>
<p>Quantization.</p>
<p>User can use quantization aware to train a model. MindSpore supports quantization aware training,
which models quantization errors in both the forward and backward passes using fake-quantization
operations. Note that the entire computation is carried out in floating point. At the end of quantization
aware training, MindSpore provides conversion functions to convert the trained model into lower precision.</p>
<dl class="py function">
<dt class="sig sig-object py" id="mindspore.train.quant.convert_quant_network">
<span class="sig-prename descclassname"><span class="pre">mindspore.train.quant.</span></span><span class="sig-name descname"><span class="pre">convert_quant_network</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bn_fold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freeze_bn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quant_delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(8,</span> <span class="pre">8)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_channel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(False,</span> <span class="pre">False)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(False,</span> <span class="pre">False)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">narrow_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(False,</span> <span class="pre">False)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/train/quant/quant.html#convert_quant_network"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.quant.convert_quant_network" title="Permalink to this definition"></a></dt>
<dd><p>Create quantization aware training network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Obtain a pipeline through network for saving graph summary.</p></li>
<li><p><strong>bn_fold</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Flag to used bn fold ops for simulation inference operation. Default: True.</p></li>
<li><p><strong>freeze_bn</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of steps after which BatchNorm OP parameters used total mean and variance. Default: 1e7.</p></li>
<li><p><strong>quant_delay</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em> or </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Number of steps after which weights and activations are quantized during
eval. The first element represent weights and second element represent data flow. Default: (0, 0)</p></li>
<li><p><strong>num_bits</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em> or </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Number of bits to use for quantize weights and activations. The first
element represent weights and second element represent data flow. Default: (8, 8)</p></li>
<li><p><strong>per_channel</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em> or </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Quantization granularity based on layer or on channel. If <cite>True</cite>
then base on per channel otherwise base on per layer. The first element represent weights
and second element represent data flow. Default: (False, False)</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em> or </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Whether the quantization algorithm is symmetric or not. If <cite>True</cite> then base on
symmetric otherwise base on asymmetric. The first element represent weights and second
element represent data flow. Default: (False, False)</p></li>
<li><p><strong>narrow_range</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em> or </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Whether the quantization algorithm uses narrow range or not.
The first element represents weights and the second element represents data flow. Default: (False, False)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Cell, Network which has change to quantization aware training network cell.</p>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindspore.parallel.html" class="btn btn-neutral float-left" title="mindspore.parallel" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mindspore.dataset.html" class="btn btn-neutral float-right" title="mindspore.dataset" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>