<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.nn.probability &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script><script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/js/theme.js"></script><script src="../../../_static/underscore.js"></script><script src="../../../_static/doctools.js"></script><script async="async" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/mathjax/MathJax-3.2.2/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="mindspore.ops" href="mindspore.ops.html" />
    <link rel="prev" title="mindspore.nn.learning_rate_schedule" href="mindspore.nn.learning_rate_schedule.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">MindSpore Python API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dtype.html">mindspore.dtype</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.hub.html">mindspore.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.dynamic_lr.html">mindspore.nn.dynamic_lr</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.learning_rate_schedule.html">mindspore.nn.learning_rate_schedule</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindspore.nn.probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.nn.probability.bijector">mindspore.nn.probability.bijector</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.nn.probability.bnn_layers">mindspore.nn.probability.bnn_layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.nn.probability.distribution">mindspore.nn.probability.distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.nn.probability.dpn">mindspore.nn.probability.dpn</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.nn.probability.infer">mindspore.nn.probability.infer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.nn.probability.toolbox">mindspore.nn.probability.toolbox</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.nn.probability.transforms">mindspore.nn.probability.transforms</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.composite.html">mindspore.ops.composite</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.operations.html">mindspore.ops.operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.parallel.html">mindspore.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.transforms.vision.html">mindspore.dataset.transforms.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.profiler.html">mindspore.profiler</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindInsight Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindinsight/mindinsight.lineagemgr.html">mindinsight.lineagemgr</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindArmour Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.html">mindarmour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.utils.html">mindarmour.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.evaluations.html">mindarmour.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.detectors.html">mindarmour.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.attacks.html">mindarmour.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.defenses.html">mindarmour.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.fuzzing.html">mindarmour.fuzzing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.diff_privacy.html">mindarmour.diff_privacy</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>mindspore.nn.probability</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/api/python/mindspore/mindspore.nn.probability.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mindspore-nn-probability">
<h1>mindspore.nn.probability<a class="headerlink" href="#mindspore-nn-probability" title="Permalink to this headline"></a></h1>
<section id="module-mindspore.nn.probability.bijector">
<span id="mindspore-nn-probability-bijector"></span><h2>mindspore.nn.probability.bijector<a class="headerlink" href="#module-mindspore.nn.probability.bijector" title="Permalink to this headline"></a></h2>
<p>Bijector.</p>
<p>The high-level components(Bijectors) used to construct the probabilistic network.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.bijector.Bijector">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.bijector.</span></span><span class="sig-name descname"><span class="pre">Bijector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">is_constant_jacobian</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_injective</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/bijector/bijector.html#Bijector"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.Bijector" title="Permalink to this definition"></a></dt>
<dd><p>Bijecotr class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>is_constant_jacobian</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – if the bijector has constant derivative. Default: False.</p></li>
<li><p><strong>is_injective</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – if the bijector is an one-to-one mapping. Default: True.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of the bijector. Default: None.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.dtype.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a>) – type of the distribution the bijector can operate on. Default: None.</p></li>
<li><p><strong>param</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – parameters used to initialize the bijector. Default: None.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.bijector.Bijector.construct">
<span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/bijector/bijector.html#Bijector.construct"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.Bijector.construct" title="Permalink to this definition"></a></dt>
<dd><p>Override construct in Cell.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Names of supported functions include:
‘forward’, ‘inverse’, ‘forward_log_jacobian’, ‘inverse_log_jacobian’.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of the function.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – list of positional arguments needed for the function.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – dictionary of keyword arguments needed for the function.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.bijector.Bijector.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/bijector/bijector.html#Bijector.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.Bijector.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward transformation: transform the input value to another distribution.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.bijector.Bijector.forward_log_jacobian">
<span class="sig-name descname"><span class="pre">forward_log_jacobian</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/bijector/bijector.html#Bijector.forward_log_jacobian"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.Bijector.forward_log_jacobian" title="Permalink to this definition"></a></dt>
<dd><p>Logarithm of the derivative of the forward transformation.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.bijector.Bijector.inverse">
<span class="sig-name descname"><span class="pre">inverse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/bijector/bijector.html#Bijector.inverse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.Bijector.inverse" title="Permalink to this definition"></a></dt>
<dd><p>Inverse transformation: transform the input value back to the original distribution.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.bijector.Bijector.inverse_log_jacobian">
<span class="sig-name descname"><span class="pre">inverse_log_jacobian</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/bijector/bijector.html#Bijector.inverse_log_jacobian"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.Bijector.inverse_log_jacobian" title="Permalink to this definition"></a></dt>
<dd><p>Logarithm of the derivative of the inverse transformation.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.bijector.Exp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.bijector.</span></span><span class="sig-name descname"><span class="pre">Exp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Exp'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/bijector/exp.html#Exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.Exp" title="Permalink to this definition"></a></dt>
<dd><p>Exponential Bijector.
This Bijector performs the operation: Y = exp(x).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of the bijector. Default: ‘Exp’.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a Exp bijector</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.bijector</span> <span class="k">as</span> <span class="nn">msb</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">msb</span><span class="o">.</span><span class="n">Exp</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use Exp distribution in a network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">e1</span> <span class="o">=</span> <span class="n">msb</span><span class="o">.</span><span class="n">Exp</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other probability functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing &#39;forward&#39; with the name of the function</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">forward_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">inverse_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.bijector.PowerTransform">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.bijector.</span></span><span class="sig-name descname"><span class="pre">PowerTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">power</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'PowerTransform'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/bijector/power_transform.html#PowerTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.PowerTransform" title="Permalink to this definition"></a></dt>
<dd><p>Power Bijector.
This Bijector performs the operation: Y = g(X) = (1 + X * c)^(1 / c), X &gt;= -1 / c, where c &gt;= 0 is the power.</p>
<p>The power transform maps inputs from <cite>[-1/c, inf]</cite> to <cite>[0, inf]</cite>.</p>
<p>This bijector is equivalent to the <cite>Exp</cite> bijector when <cite>c=0</cite></p>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the power is less than 0 or is not known statically.</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>power</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – scale factor. Default: 0.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of the bijector. Default: ‘PowerTransform’.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a PowerTransform bijector of power 0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.bijector</span> <span class="k">as</span> <span class="nn">msb</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">msb</span><span class="o">.</span><span class="n">PowerTransform</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use PowerTransform distribution in a network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">p1</span> <span class="o">=</span> <span class="n">msb</span><span class="o">.</span><span class="n">PowerTransform</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other probability functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing &#39;forward&#39; with the name of the function</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">forward_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">inverse_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.bijector.ScalarAffine">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.bijector.</span></span><span class="sig-name descname"><span class="pre">ScalarAffine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shift</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ScalarAffine'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/bijector/scalar_affine.html#ScalarAffine"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.ScalarAffine" title="Permalink to this definition"></a></dt>
<dd><p>Scalar Affine Bijector.
This Bijector performs the operation: Y = a * X + b, where a is the scale
factor and b is the shift factor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – scale factor. Default: 1.0.</p></li>
<li><p><strong>shift</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – shift factor. Default: 0.0.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of the bijector. Default: ‘ScalarAffine’.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a ScalarAffine bijector of scale 1 and shift 2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scalaraffine</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">probability</span><span class="o">.</span><span class="n">bijector</span><span class="o">.</span><span class="n">ScalarAffine</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use ScalarAffine bijector in a network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">s1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">probability</span><span class="o">.</span><span class="n">bijector</span><span class="o">.</span><span class="n">ScalarAffine</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other probability functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing &#39;forward&#39; with the name of the function</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">forward_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">inverse_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.bijector.Softplus">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.bijector.</span></span><span class="sig-name descname"><span class="pre">Softplus</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sharpness</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Softplus'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/bijector/softplus.html#Softplus"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.Softplus" title="Permalink to this definition"></a></dt>
<dd><p>Softplus Bijector.
This Bijector performs the operation, where k is the sharpness factor.</p>
<div class="math notranslate nohighlight">
\[Y = \frac{\log(1 + e ^ {kX})}{k}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sharpness</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – scale factor. Default: 1.0.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of the bijector. Default: ‘Softplus’.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a Softplus bijector of sharpness 2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">probability</span><span class="o">.</span><span class="n">bijector</span><span class="o">.</span><span class="n">Softfplus</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use ScalarAffine bijector in a network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">sp1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">probability</span><span class="o">.</span><span class="n">bijector</span><span class="o">.</span><span class="n">Softflus</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other probability functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing &#39;forward&#39; with the name of the function</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sp1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sp1</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sp1</span><span class="o">.</span><span class="n">forward_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sp1</span><span class="o">.</span><span class="n">inverse_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-mindspore.nn.probability.bnn_layers">
<span id="mindspore-nn-probability-bnn-layers"></span><h2>mindspore.nn.probability.bnn_layers<a class="headerlink" href="#module-mindspore.nn.probability.bnn_layers" title="Permalink to this headline"></a></h2>
<p>Bayesian Layer.</p>
<p>The high-level components(Cells) used to construct the bayesian neural network.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.bnn_layers.ConvReparam">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.bnn_layers.</span></span><span class="sig-name descname"><span class="pre">ConvReparam</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_mode='same'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding=0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">has_bias=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_prior_fn=NormalPrior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_posterior_fn=&lt;lambda</span> <span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape:</span> <span class="pre">NormalPosterior(name=name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape=shape)&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_prior_fn=NormalPrior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_posterior_fn=&lt;lambda</span> <span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape:</span> <span class="pre">NormalPosterior(name=name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape=shape)&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/bnn_layers/conv_variational.html#ConvReparam"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.bnn_layers.ConvReparam" title="Permalink to this definition"></a></dt>
<dd><p>Convolutional variational layers with Reparameterization.</p>
<p>See more details in paper <a class="reference external" href="https://arxiv.org/abs/1312.6114">Auto-Encoding Variational Bayes</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of input channel <span class="math notranslate nohighlight">\(C_{in}\)</span>.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of output channel <span class="math notranslate nohighlight">\(C_{out}\)</span>.</p></li>
<li><p><strong>kernel_size</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The data type is int or
tuple with 2 integers. Specifies the height and width of the 2D
convolution window. Single int means the value if for both
height and width of the kernel. A tuple of 2 ints means the
first value is for the height and the other is for the width of
the kernel.</p></li>
<li><p><strong>stride</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The distance of kernel moving,
an int number that represents the height and width of movement
are both strides, or a tuple of two int numbers that represent
height and width of movement respectively. Default: 1.</p></li>
<li><p><strong>pad_mode</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>Specifies padding mode. The optional values are
“same”, “valid”, “pad”. Default: “same”.</p>
<ul>
<li><p>same: Adopts the way of completion. Output height and width
will be the same as the input.
Total number of padding will be calculated for horizontal and
vertical direction and evenly distributed to top and bottom,
left and right if possible. Otherwise, the last extra padding
will be done from the bottom and the right side. If this mode
is set, <cite>padding</cite> must be 0.</p></li>
<li><p>valid: Adopts the way of discarding. The possibly largest
height and width of output will be return without padding.
Extra pixels will be discarded. If this mode is set, <cite>padding</cite>
must be 0.</p></li>
<li><p>pad: Implicit paddings on both sides of the input. The number
of <cite>padding</cite> will be padded to the input Tensor borders.
<cite>padding</cite> should be greater than or equal to 0.</p></li>
</ul>
</p></li>
<li><p><strong>padding</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – Implicit paddings on both sides of
the input. Default: 0.</p></li>
<li><p><strong>dilation</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The data type is int or tuple
with 2 integers. Specifies the dilation rate to use for dilated
convolution. If set to be <span class="math notranslate nohighlight">\(k &gt; 1\)</span>,
there will be <span class="math notranslate nohighlight">\(k - 1\)</span> pixels skipped for each sampling
location. Its value should be greater or equal to 1 and bounded
by the height and width of the input. Default: 1.</p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Split filter into groups, <cite>in_ channels</cite> and
<cite>out_channels</cite> should be divisible by the number of groups.
Default: 1.</p></li>
<li><p><strong>has_bias</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Specifies whether the layer uses a bias vector.
Default: False.</p></li>
<li><p><strong>weight_prior_fn</strong> – prior distribution for weight.
It should return a mindspore distribution instance.
Default: NormalPrior. (which creates an instance of standard
normal distribution). The current version only supports normal distribution.</p></li>
<li><p><strong>weight_posterior_fn</strong> – posterior distribution for sampling weight.
It should be a function handle which returns a mindspore
distribution instance. Default: lambda name, shape: NormalPosterior(name=name, shape=shape).
The current version only supports normal distribution.</p></li>
<li><p><strong>bias_prior_fn</strong> – prior distribution for bias vector. It should return
a mindspore distribution. Default: NormalPrior(which creates an
instance of standard normal distribution). The current version
only supports normal distribution.</p></li>
<li><p><strong>bias_posterior_fn</strong> – posterior distribution for sampling bias vector.
It should be a function handle which returns a mindspore
distribution instance. Default: lambda name, shape: NormalPosterior(name=name, shape=shape).
The current version only supports normal distribution.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, C_{in}, H_{in}, W_{in})\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor of shape <span class="math notranslate nohighlight">\((N, C_{out}, H_{out}, W_{out})\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">ConvReparam</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">640</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(1, 240, 1024, 640)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.bnn_layers.DenseReparam">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.bnn_layers.</span></span><span class="sig-name descname"><span class="pre">DenseReparam</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">has_bias=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_prior_fn=NormalPrior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_posterior_fn=&lt;lambda</span> <span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape:</span> <span class="pre">NormalPosterior(name=name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape=shape)&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_prior_fn=NormalPrior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_posterior_fn=&lt;lambda</span> <span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape:</span> <span class="pre">NormalPosterior(name=name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape=shape)&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/bnn_layers/dense_variational.html#DenseReparam"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.bnn_layers.DenseReparam" title="Permalink to this definition"></a></dt>
<dd><p>Dense variational layers with Reparameterization.</p>
<p>See more details in paper <a class="reference external" href="https://arxiv.org/abs/1312.6114">Auto-Encoding Variational Bayes</a>.</p>
<p>Applies dense-connected layer for the input. This layer implements the operation as:</p>
<div class="math notranslate nohighlight">
\[\text{outputs} = \text{activation}(\text{inputs} * \text{kernel} + \text{bias}),\]</div>
<p>where <span class="math notranslate nohighlight">\(\text{activation}\)</span> is the activation function passed as the activation
argument (if passed in), <span class="math notranslate nohighlight">\(\text{activation}\)</span> is a weight matrix with the same
data type as the inputs created by the layer, <span class="math notranslate nohighlight">\(\text{weight}\)</span> is a weight
matrix sampling from posterior distribution of weight, and <span class="math notranslate nohighlight">\(\text{bias}\)</span> is a
bias vector with the same data type as the inputs created by the layer (only if
has_bias is True). The bias vector is sampling from posterior distribution of
<span class="math notranslate nohighlight">\(\text{bias}\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of input channel.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of output channel .</p></li>
<li><p><strong>has_bias</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Specifies whether the layer uses a bias vector. Default: False.</p></li>
<li><p><strong>activation</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Regularizer function applied to the output of the layer. The type of activation can
be str (eg. ‘relu’) or Cell (eg. nn.ReLU()). Note that if the type of activation is Cell, it must have been
instantiated. Default: None.</p></li>
<li><p><strong>weight_prior_fn</strong> – prior distribution for weight.
It should return a mindspore distribution instance.
Default: NormalPrior. (which creates an instance of standard
normal distribution). The current version only supports normal distribution.</p></li>
<li><p><strong>weight_posterior_fn</strong> – posterior distribution for sampling weight.
It should be a function handle which returns a mindspore
distribution instance. Default: lambda name, shape: NormalPosterior(name=name, shape=shape).
The current version only supports normal distribution.</p></li>
<li><p><strong>bias_prior_fn</strong> – prior distribution for bias vector. It should return
a mindspore distribution. Default: NormalPrior(which creates an
instance of standard normal distribution). The current version
only supports normal distribution.</p></li>
<li><p><strong>bias_posterior_fn</strong> – posterior distribution for sampling bias vector.
It should be a function handle which returns a mindspore
distribution instance. Default: lambda name, shape: NormalPosterior(name=name, shape=shape).
The current version only supports normal distribution.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, in\_channels)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor of shape <span class="math notranslate nohighlight">\((N, out\_channels)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">DenseReparam</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2, 4)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.bnn_layers.WithBNNLossCell">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.bnn_layers.</span></span><span class="sig-name descname"><span class="pre">WithBNNLossCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">backbone</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dnn_factor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bnn_factor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/bnn_layers/bnn_cell_wrapper.html#WithBNNLossCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.bnn_layers.WithBNNLossCell" title="Permalink to this definition"></a></dt>
<dd><p>Generate WithLossCell suitable for BNN.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>backbone</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The target network.</p></li>
<li><p><strong>loss_fn</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The loss function used to compute loss.</p></li>
<li><p><strong>dnn_factor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The coefficient of backbone’s loss, which is computed by loss functin. Default: 1.</p></li>
<li><p><strong>bnn_factor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The coefficient of kl loss, which is kl divergence of Bayesian layer. Default: 1.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>data</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, \ldots)\)</span>.</p></li>
<li><p><strong>label</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, \ldots)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, a scalar tensor with shape <span class="math notranslate nohighlight">\(()\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">is_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_with_criterion_object</span> <span class="o">=</span> <span class="n">WithBNNLossCell</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_with_criterion</span> <span class="o">=</span> <span class="n">net_with_criterion_object</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_with_criterion</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.bnn_layers.NormalPosterior">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.bnn_layers.</span></span><span class="sig-name descname"><span class="pre">NormalPosterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">mindspore.float32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc_mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">untransformed_scale_mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">untransformed_scale_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/bnn_layers/layer_distribution.html#NormalPosterior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.bnn_layers.NormalPosterior" title="Permalink to this definition"></a></dt>
<dd><p>Build Normal distributions with trainable parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Name prepended to trainable parameter.</p></li>
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Shape of the mean and standard deviation.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.dtype.html#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – The argument is used to define the data type of the output tensor.
Default: mindspore.float32.</p></li>
<li><p><strong>loc_mean</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Mean of distribution to initialize trainable parameters. Default: 0.</p></li>
<li><p><strong>loc_std</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Standard deviation of distribution to initialize trainable parameters. Default: 0.1.</p></li>
<li><p><strong>untransformed_scale_mean</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Mean of distribution to initialize trainable parameters. Default: -5.</p></li>
<li><p><strong>untransformed_scale_std</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Standard deviation of distribution to initialize trainable parameters.
Default: 0.1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Cell, a normal distribution.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.bnn_layers.NormalPosterior.std_trans">
<span class="sig-name descname"><span class="pre">std_trans</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">std_pre</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/bnn_layers/layer_distribution.html#NormalPosterior.std_trans"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.bnn_layers.NormalPosterior.std_trans" title="Permalink to this definition"></a></dt>
<dd><p>Transform std_pre to prevent its value being zero.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.bnn_layers.NormalPrior">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.bnn_layers.</span></span><span class="sig-name descname"><span class="pre">NormalPrior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">mindspore.float32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/bnn_layers/layer_distribution.html#NormalPrior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.bnn_layers.NormalPrior" title="Permalink to this definition"></a></dt>
<dd><p>To initialize a normal distribution of mean 0 and standard deviation 0.1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.dtype.html#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – The argument is used to define the data type of the output tensor.
Default: mindspore.float32.</p></li>
<li><p><strong>mean</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Mean of normal distribution. Default: 0.</p></li>
<li><p><strong>std</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Standard deviation of normal distribution. Default: 0.1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Cell, a normal distribution.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-mindspore.nn.probability.distribution">
<span id="mindspore-nn-probability-distribution"></span><h2>mindspore.nn.probability.distribution<a class="headerlink" href="#module-mindspore.nn.probability.distribution" title="Permalink to this headline"></a></h2>
<p>Distribution.</p>
<p>The high-level components(Distributions) used to construct the probabilistic network.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Bernoulli">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.distribution.</span></span><span class="sig-name descname"><span class="pre">Bernoulli</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">probs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">mindspore.int32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Bernoulli'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/bernoulli.html#Bernoulli"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Bernoulli" title="Permalink to this definition"></a></dt>
<dd><p>Bernoulli Distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>probs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a>) – probability of 1 as outcome.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – seed to use in sampling. Default: 0.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.dtype.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a>) – type of the distribution. Default: mstype.int32.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of the distribution. Default: Bernoulli.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>probs should be proper probabilities (0 &lt; p &lt; 1).
Dist_spec_args is probs.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a Bernoulli distribution of prob 0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The following creates two independent Bernoulli distributions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># A Bernoulli distribution can be initilized without arguments</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># In this case, probs must be passed in through args during function calls.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use Bernoulli in a network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">b1</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">b2</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># All the following calls in construct are valid</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">,</span> <span class="n">probs_a</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other probability functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing &#39;prob&#39; with the name of the function</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Evaluate with the respect to distribution b</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># probs must be passed in during function calls</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">probs_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Functions &#39;sd&#39;, &#39;var&#39;, &#39;entropy&#39; have the same usage as &#39;mean&#39;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Will return 0.5</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Will return probs_b</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">probs_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># probs must be passed in during function calls</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">probs_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Usage of &#39;kl_loss&#39; and &#39;cross_entropy&#39; are similar</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Bernoulli&#39;</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Bernoulli&#39;</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">,</span> <span class="n">probs_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Additional probs_a must be passed in through</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Bernoulli&#39;</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">,</span> <span class="n">probs_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Sample</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">probs_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">probs_a</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Bernoulli.probs">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">probs</span></span><a class="headerlink" href="#mindspore.nn.probability.distribution.Bernoulli.probs" title="Permalink to this definition"></a></dt>
<dd><p>Returns the probability for the outcome is 1.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Categorical">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.distribution.</span></span><span class="sig-name descname"><span class="pre">Categorical</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">probs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">mindspore.int32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Categorical'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/categorical.html#Categorical"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Categorical" title="Permalink to this definition"></a></dt>
<dd><p>Creates a categorical distribution parameterized by either probs or logits (but not both).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>probs</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – event probabilities.</p></li>
<li><p><strong>logits</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – event log-odds.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – seed to use in sampling. Default: 0.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.dtype.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a>) – type of the distribution. Default: mstype.int32.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of the distribution. Default: Categorical.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>probs must be non-negative, finite and have a non-zero sum, and it will be normalized to sum to 1.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a Categorical distribution of prob is [0.5, 0.5]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use Categorical in a network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">probs</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">ca</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="n">probs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># All the following calls in construct are valid</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to logits</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca</span><span class="o">.</span><span class="n">probs</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># value should be Tensor</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Usage of enumerate_support</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca</span><span class="o">.</span><span class="n">enumerate_support</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Usage of entropy</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Sample</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,))</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Categorical.enumerate_support">
<span class="sig-name descname"><span class="pre">enumerate_support</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">expand</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/categorical.html#Categorical.enumerate_support"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Categorical.enumerate_support" title="Permalink to this definition"></a></dt>
<dd><p>Enumerate categories.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Categorical.logits">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logits</span></span><a class="headerlink" href="#mindspore.nn.probability.distribution.Categorical.logits" title="Permalink to this definition"></a></dt>
<dd><p>Returns the logits.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Categorical.probs">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">probs</span></span><a class="headerlink" href="#mindspore.nn.probability.distribution.Categorical.probs" title="Permalink to this definition"></a></dt>
<dd><p>Returns the probability.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Distribution">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.distribution.</span></span><span class="sig-name descname"><span class="pre">Distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution" title="Permalink to this definition"></a></dt>
<dd><p>Base class for all mathematical distributions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – random seed used in sampling.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.dtype.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a>) – type of the distribution.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Python str name prefixed to Ops created by this class. Default: subclass name.</p></li>
<li><p><strong>param</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – parameters used to initialize the distribution.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Derived class should override operations such as ,_mean, _prob,
and _log_prob. Required arguments, such as value for _prob,
should be passed in through args or kwargs. dist_spec_args which specify
a new distribution are optional.</p>
<p>dist_spec_args are unique for each type of distribution. For example, mean and sd
are the dist_spec_args for a Normal distribution, while rate is the dist_spec_args
for exponential distribution.</p>
<p>For all functions, passing in dist_spec_args, is optional.
Passing in the additional dist_spec_args will make the result to be evaluated with
new distribution specified by the dist_spec_args. But it won’t change the
original distribuion.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Distribution.cdf">
<span class="sig-name descname"><span class="pre">cdf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.cdf"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.cdf" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the cdf at given value.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Args must include value.
dist_spec_args are optional.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Distribution.construct">
<span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.construct"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.construct" title="Permalink to this definition"></a></dt>
<dd><p>Override construct in Cell.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Names of supported functions include:
‘prob’, ‘log_prob’, ‘cdf’, ‘log_cdf’, ‘survival_function’, ‘log_survival’
‘var’, ‘sd’, ‘entropy’, ‘kl_loss’, ‘cross_entropy’, ‘sample’.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of the function.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – list of positional arguments needed for the function.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – dictionary of keyword arguments needed for the function.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Distribution.cross_entropy">
<span class="sig-name descname"><span class="pre">cross_entropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.cross_entropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.cross_entropy" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the cross_entropy between distribution a and b.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Args must include type of the distribution, parameters of distribution b.
Parameters for distribution a are optional.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Distribution.entropy">
<span class="sig-name descname"><span class="pre">entropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.entropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.entropy" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the entropy.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>dist_spec_args are optional.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Distribution.kl_loss">
<span class="sig-name descname"><span class="pre">kl_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.kl_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.kl_loss" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the KL divergence, i.e. KL(a||b).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Args must include type of the distribution, parameters of distribution b.
Parameters for distribution a are optional.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Distribution.log_cdf">
<span class="sig-name descname"><span class="pre">log_cdf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.log_cdf"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.log_cdf" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the log cdf at given value.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Args must include value.
dist_spec_args are optional.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Distribution.log_prob">
<span class="sig-name descname"><span class="pre">log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.log_prob"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.log_prob" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the log probability(pdf or pmf) at the given value.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Args must include value.
dist_spec_args are optional.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Distribution.log_survival">
<span class="sig-name descname"><span class="pre">log_survival</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.log_survival"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.log_survival" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the log survival function at given value.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Args must include value.
dist_spec_args are optional.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Distribution.mean">
<span class="sig-name descname"><span class="pre">mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.mean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.mean" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the mean.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>dist_spec_args are optional.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Distribution.mode">
<span class="sig-name descname"><span class="pre">mode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.mode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.mode" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the mode.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>dist_spec_args are optional.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Distribution.prob">
<span class="sig-name descname"><span class="pre">prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.prob"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.prob" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the probability (pdf or pmf) at given value.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Args must include value.
dist_spec_args are optional.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Distribution.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.sample" title="Permalink to this definition"></a></dt>
<dd><p>Sampling function.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Shape of the sample is default to ().
dist_spec_args are optional.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Distribution.sd">
<span class="sig-name descname"><span class="pre">sd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.sd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.sd" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the standard deviation.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>dist_spec_args are optional.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Distribution.survival_function">
<span class="sig-name descname"><span class="pre">survival_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.survival_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.survival_function" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the survival function at given value.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Args must include value.
dist_spec_args are optional.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Distribution.var">
<span class="sig-name descname"><span class="pre">var</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.var"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.var" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the variance.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>dist_spec_args are optional.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Exponential">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.distribution.</span></span><span class="sig-name descname"><span class="pre">Exponential</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">mindspore.float32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Exponential'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/exponential.html#Exponential"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Exponential" title="Permalink to this definition"></a></dt>
<dd><p>Example class: Exponential Distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rate</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a>) – inverse scale.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – seed to use in sampling. Default: 0.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.dtype.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a>) – type of the distribution. Default: mstype.float32.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of the distribution. Default: Exponential.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>rate should be strictly greater than 0.
Dist_spec_args is rate.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize an Exponential distribution of rate 0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The following creates two independent Exponential distributions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Exponential</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># An Exponential distribution can be initilized without arguments</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># In this case, rate must be passed in through args during function calls</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use Exponential in a network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">e1</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">e2</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># All the following calls in construct are valid</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">rate_b</span><span class="p">,</span> <span class="n">rate_a</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other probability functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing &#39;prob&#39; with the name of the function</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Evaluate with the respect to distribution b</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">rate_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Rate must be passed in during function calls</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e2</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">rate_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Functions &#39;sd&#39;, &#39;var&#39;, &#39;entropy&#39; have the same usage as&#39;mean&#39;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Will return 2</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Will return 1 / rate_b</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rate_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Rate must be passed in during function calls</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e2</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rate_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Usage of &#39;kl_loss&#39; and &#39;cross_entropy&#39; are similar</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Exponential&#39;</span><span class="p">,</span> <span class="n">rate_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Exponential&#39;</span><span class="p">,</span> <span class="n">rate_b</span><span class="p">,</span> <span class="n">rate_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Additional rate must be passed in</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e2</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Exponential&#39;</span><span class="p">,</span> <span class="n">rate_b</span><span class="p">,</span> <span class="n">rate_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Sample</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">rate_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e2</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">rate_a</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Exponential.rate">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">rate</span></span><a class="headerlink" href="#mindspore.nn.probability.distribution.Exponential.rate" title="Permalink to this definition"></a></dt>
<dd><p>Return rate of the distribution.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Geometric">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.distribution.</span></span><span class="sig-name descname"><span class="pre">Geometric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">probs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">mindspore.int32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Geometric'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/geometric.html#Geometric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Geometric" title="Permalink to this definition"></a></dt>
<dd><p>Geometric Distribution.
It represents k+1 Bernoulli trials needed to get one success, k is the number of failures.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>probs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a>) – probability of success.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – seed to use in sampling. Default: 0.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.dtype.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a>) – type of the distribution. Default: mstype.int32.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of the distribution. Default: Geometric.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>probs should be proper probabilities (0 &lt; p &lt; 1).
Dist_spec_args is probs.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a Geometric distribution of prob 0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Geometric</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The following creates two independent Geometric distributions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Geometric</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># A Geometric distribution can be initilized without arguments</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># In this case, probs must be passed in through args during function calls.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Geometric</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use Geometric in a network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">g1</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Geometric</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">g2</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Geometric</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># Tthe following calls are valid in construct</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">,</span> <span class="n">probs_a</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other probability functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing &#39;prob&#39; with the name of the function</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Evaluate with the respect to distribution b</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Probs must be passed in during function calls</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g2</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">probs_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Functions &#39;sd&#39;, &#39;var&#39;, &#39;entropy&#39; have the same usage as &#39;mean&#39;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Will return 1.0</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Another possible usage</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">probs_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Probs must be passed in during function calls</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g2</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">probs_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Usage of &#39;kl_loss&#39; and &#39;cross_entropy&#39; are similar</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Geometric&#39;</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Geometric&#39;</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">,</span> <span class="n">probs_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Additional probs must be passed in</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g2</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Geometric&#39;</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">,</span> <span class="n">probs_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Sample</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">probs_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g2</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">probs_a</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Geometric.probs">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">probs</span></span><a class="headerlink" href="#mindspore.nn.probability.distribution.Geometric.probs" title="Permalink to this definition"></a></dt>
<dd><p>Returns the probability of success of the Bernoulli trail.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Normal">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.distribution.</span></span><span class="sig-name descname"><span class="pre">Normal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sd</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">mindspore.float32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Normal'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/normal.html#Normal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Normal" title="Permalink to this definition"></a></dt>
<dd><p>Normal distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mean</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a>) – mean of the Normal distribution.</p></li>
<li><p><strong>sd</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a>) – stddev of the Normal distribution.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – seed to use in sampling. Default: 0.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.dtype.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a>) – type of the distribution. Default: mstype.float32.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of the distribution. Default: Normal.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Standard deviation should be greater than zero.
Dist_spec_args are mean and sd.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a Normal distribution of mean 3.0 and standard deviation 4.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The following creates two independent Normal distributions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Normal</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># A Normal distribution can be initilize without arguments</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># In this case, mean and sd must be passed in through args.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use Normal in a network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">n1</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Nomral</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">n2</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># The following calls are valid in construct</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">mean_b</span><span class="p">,</span> <span class="n">sd_b</span><span class="p">,</span> <span class="n">mean_a</span><span class="p">,</span> <span class="n">sd_a</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other probability functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing &#39;prob&#39; with the name of the function</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Evaluate with the respect to distribution b</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">mean_b</span><span class="p">,</span> <span class="n">sd_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># mean and sd must be passed in during function calls</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n2</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">mean_a</span><span class="p">,</span> <span class="n">sd_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Functions &#39;sd&#39;, &#39;var&#39;, &#39;entropy&#39; have the same usage as &#39;mean&#39;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># will return [0.0]</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># will return mean_b</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_b</span><span class="p">,</span> <span class="n">sd_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># mean and sd must be passed during function calls</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n2</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_a</span><span class="p">,</span> <span class="n">sd_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Usage of &#39;kl_loss&#39; and &#39;cross_entropy&#39; are similar</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Normal&#39;</span><span class="p">,</span> <span class="n">mean_b</span><span class="p">,</span> <span class="n">sd_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Normal&#39;</span><span class="p">,</span> <span class="n">mean_b</span><span class="p">,</span> <span class="n">sd_b</span><span class="p">,</span> <span class="n">mean_a</span><span class="p">,</span> <span class="n">sd_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Additional mean and sd must be passed</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n2</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Normal&#39;</span><span class="p">,</span> <span class="n">mean_b</span><span class="p">,</span> <span class="n">sd_b</span><span class="p">,</span> <span class="n">mean_a</span><span class="p">,</span> <span class="n">sd_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Sample</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">mean_b</span><span class="p">,</span> <span class="n">sd_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n2</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">mean_a</span><span class="p">,</span> <span class="n">sd_a</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.TransformedDistribution">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.distribution.</span></span><span class="sig-name descname"><span class="pre">TransformedDistribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bijector</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distribution</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'transformed_distribution'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/transformed_distribution.html#TransformedDistribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.TransformedDistribution" title="Permalink to this definition"></a></dt>
<dd><p>Transformed Distribution.
This class contains a bijector and a distribution and transforms the original distribution
to a new distribution through the operation defined by the bijector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bijector</strong> (<a class="reference internal" href="#mindspore.nn.probability.bijector.Bijector" title="mindspore.nn.probability.bijector.Bijector"><em>Bijector</em></a>) – transformation to perform.</p></li>
<li><p><strong>distribution</strong> (<a class="reference internal" href="#mindspore.nn.probability.distribution.Distribution" title="mindspore.nn.probability.distribution.Distribution"><em>Distribution</em></a>) – The original distribution.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of the transformed distribution. Default: transformed_distribution.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The arguments used to initialize the original distribution cannot be None.
For example, mynormal = nn.Normal(dtype=dtyple.float32) cannot be used to initialized a
TransformedDistribution since mean and sd are not specified.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a transformed distribution, e.g. lognormal distribution,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># using Normal distribution as the base distribution, and Exp bijector as the bijector function.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.bijector</span> <span class="k">as</span> <span class="nn">msb</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ln</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">TransformedDistribution</span><span class="p">(</span><span class="n">msb</span><span class="o">.</span><span class="n">Exp</span><span class="p">(),</span>
<span class="gp">&gt;&gt;&gt; </span>                                 <span class="n">msd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span>                                 <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use a transformed distribution in a network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">ln</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">TransformedDistribution</span><span class="p">(</span><span class="n">msb</span><span class="o">.</span><span class="n">Exp</span><span class="p">(),</span>
<span class="gp">&gt;&gt;&gt; </span>                                              <span class="n">msd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span>                                              <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other probability functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing &#39;sample&#39; with the name of the function</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Uniform">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.distribution.</span></span><span class="sig-name descname"><span class="pre">Uniform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">low</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">mindspore.float32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Uniform'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/distribution/uniform.html#Uniform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Uniform" title="Permalink to this definition"></a></dt>
<dd><p>Example class: Uniform Distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>low</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a>) – lower bound of the distribution.</p></li>
<li><p><strong>high</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a>) – upper bound of the distribution.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – seed to use in sampling. Default: 0.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.dtype.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a>) – type of the distribution. Default: mstype.float32.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of the distribution. Default: Uniform.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>low should be stricly less than high.
Dist_spec_args are high and low.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a Uniform distribution of mean 3.0 and standard deviation 4.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The following creates two independent Uniform distributions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># A Uniform distribution can be initilized without arguments</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># In this case, high and low must be passed in through args during function calls.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use Uniform in a network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">u1</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">u2</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># All the following calls in construct are valid</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">low_b</span><span class="p">,</span> <span class="n">high_b</span><span class="p">,</span> <span class="n">low_a</span><span class="p">,</span> <span class="n">high_a</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other probability functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing &#39;prob&#39; with the name of the function</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Evaluate with the respect to distribution b</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">low_b</span><span class="p">,</span> <span class="n">high_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># High and low must be passed in during function calls</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u2</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">low_a</span><span class="p">,</span> <span class="n">high_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Functions &#39;sd&#39;, &#39;var&#39;, &#39;entropy&#39; have the same usage as &#39;mean&#39;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Will return 0.5</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Will return (low_b + high_b) / 2</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">low_b</span><span class="p">,</span> <span class="n">high_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># High and low must be passed in during function calls</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u2</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">low_a</span><span class="p">,</span> <span class="n">high_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Usage of &#39;kl_loss&#39; and &#39;cross_entropy&#39; are similar</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Uniform&#39;</span><span class="p">,</span> <span class="n">low_b</span><span class="p">,</span> <span class="n">high_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Uniform&#39;</span><span class="p">,</span> <span class="n">low_b</span><span class="p">,</span> <span class="n">high_b</span><span class="p">,</span> <span class="n">low_a</span><span class="p">,</span> <span class="n">high_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Additional high and low must be passed</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u2</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Uniform&#39;</span><span class="p">,</span> <span class="n">low_b</span><span class="p">,</span> <span class="n">high_b</span><span class="p">,</span> <span class="n">low_a</span><span class="p">,</span> <span class="n">high_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Sample</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">low_b</span><span class="p">,</span> <span class="n">high_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u2</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">low_a</span><span class="p">,</span> <span class="n">high_a</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Uniform.high">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">high</span></span><a class="headerlink" href="#mindspore.nn.probability.distribution.Uniform.high" title="Permalink to this definition"></a></dt>
<dd><p>Return upper bound of the distribution.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.nn.probability.distribution.Uniform.low">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">low</span></span><a class="headerlink" href="#mindspore.nn.probability.distribution.Uniform.low" title="Permalink to this definition"></a></dt>
<dd><p>Return lower bound of the distribution.</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-mindspore.nn.probability.dpn">
<span id="mindspore-nn-probability-dpn"></span><h2>mindspore.nn.probability.dpn<a class="headerlink" href="#module-mindspore.nn.probability.dpn" title="Permalink to this headline"></a></h2>
<p>Deep Probability Network(dpn).</p>
<p>Deep probability network such as BNN and VAE network.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.dpn.ConditionalVAE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.dpn.</span></span><span class="sig-name descname"><span class="pre">ConditionalVAE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/dpn/vae/cvae.html#ConditionalVAE"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.dpn.ConditionalVAE" title="Permalink to this definition"></a></dt>
<dd><p>Conditional Variational Auto-Encoder (CVAE).</p>
<p>The difference with VAE is that CVAE uses labels information.
see more details in <a class="reference external" href="http://papers.nips.cc/paper/5775-learning-structured-output-representation-using-deep-conditional-generative-models">Learning Structured Output Representation using Deep Conditional Generative Models</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When define the encoder and decoder, the shape of the encoder’s output tensor and decoder’s input tensor
should be <span class="math notranslate nohighlight">\((N, hidden\_size)\)</span>.
The latent_size should be less than or equal to the hidden_size.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The DNN model defined as encoder.</p></li>
<li><p><strong>decoder</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The DNN model defined as decoder.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The size of encoder’s output tensor.</p></li>
<li><p><strong>latent_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The size of the latent space.</p></li>
<li><p><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of classes.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - the same shape as the input of encoder, the shape is <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>input_y</strong> (Tensor) - the tensor of the target data, the shape is <span class="math notranslate nohighlight">\((N,)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><ul class="simple">
<li><p><strong>output</strong> (tuple) - (recon_x(Tensor), x(Tensor), mu(Tensor), std(Tensor)).</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.dpn.ConditionalVAE.construct">
<span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/dpn/vae/cvae.html#ConditionalVAE.construct"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.dpn.ConditionalVAE.construct" title="Permalink to this definition"></a></dt>
<dd><p>The input are x and y, so the WithLossCell method needs to be rewritten when using cvae interface.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.dpn.ConditionalVAE.generate_sample">
<span class="sig-name descname"><span class="pre">generate_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generate_nums</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/dpn/vae/cvae.html#ConditionalVAE.generate_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.dpn.ConditionalVAE.generate_sample" title="Permalink to this definition"></a></dt>
<dd><p>Randomly sample from latent space to generate sample.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sample_y</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – Define the label of sample. Tensor of shape (generate_nums, ) and type mindspore.int32.</p></li>
<li><p><strong>generate_nums</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of samples to generate.</p></li>
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – The shape of sample, it should be (generate_nums, C, H, W) or (-1, C, H, W).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, the generated sample.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.dpn.ConditionalVAE.reconstruct_sample">
<span class="sig-name descname"><span class="pre">reconstruct_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/dpn/vae/cvae.html#ConditionalVAE.reconstruct_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.dpn.ConditionalVAE.reconstruct_sample" title="Permalink to this definition"></a></dt>
<dd><p>Reconstruct sample from original data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The input tensor to be reconstructed, the shape is (N, C, H, W).</p></li>
<li><p><strong>y</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The label of the input tensor, the shape is (N,).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, the reconstructed sample.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.dpn.VAE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.dpn.</span></span><span class="sig-name descname"><span class="pre">VAE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/dpn/vae/vae.html#VAE"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.dpn.VAE" title="Permalink to this definition"></a></dt>
<dd><p>Variational Auto-Encoder (VAE).</p>
<p>The VAE defines a generative model, <cite>Z</cite> is sampled from the prior, then used to reconstruct <cite>X</cite> by a decoder.
see more details in <a class="reference external" href="https://arxiv.org/abs/1312.6114">Auto-Encoding Variational Bayes</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When define the encoder and decoder, the shape of the encoder’s output tensor and decoder’s input tensor
should be <span class="math notranslate nohighlight">\((N, hidden\_size)\)</span>.
The latent_size should be less than or equal to the hidden_size.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The DNN model defined as encoder.</p></li>
<li><p><strong>decoder</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The DNN model defined as decoder.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The size of encoder’s output tensor.</p></li>
<li><p><strong>latent_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The size of the latent space.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor) - the same shape as the input of encoder, the shape is <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><ul class="simple">
<li><p><strong>output</strong> (Tuple) - (recon_x(Tensor), x(Tensor), mu(Tensor), std(Tensor)).</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.dpn.VAE.generate_sample">
<span class="sig-name descname"><span class="pre">generate_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">generate_nums</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/dpn/vae/vae.html#VAE.generate_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.dpn.VAE.generate_sample" title="Permalink to this definition"></a></dt>
<dd><p>Randomly sample from latent space to generate sample.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>generate_nums</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of samples to generate.</p></li>
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – The shape of sample, it should be (generate_nums, C, H, W) or (-1, C, H, W).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, the generated sample.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.dpn.VAE.reconstruct_sample">
<span class="sig-name descname"><span class="pre">reconstruct_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/dpn/vae/vae.html#VAE.reconstruct_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.dpn.VAE.reconstruct_sample" title="Permalink to this definition"></a></dt>
<dd><p>Reconstruct sample from original data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The input tensor to be reconstructed, the shape is (N, C, H, W).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, the reconstructed sample.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-mindspore.nn.probability.infer">
<span id="mindspore-nn-probability-infer"></span><h2>mindspore.nn.probability.infer<a class="headerlink" href="#module-mindspore.nn.probability.infer" title="Permalink to this headline"></a></h2>
<p>Infer algorithms in Probabilistic Programming.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.infer.ELBO">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.infer.</span></span><span class="sig-name descname"><span class="pre">ELBO</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Normal'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Normal'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/infer/variational/elbo.html#ELBO"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.infer.ELBO" title="Permalink to this definition"></a></dt>
<dd><p>The Evidence Lower Bound (ELBO).</p>
<p>Variational inference minimizes the Kullback-Leibler (KL) divergence from the variational distribution to
the posterior distribution. It maximizes the evidence lower bound (ELBO), a lower bound on the logarithm of
the marginal probability of the observations log p(x). The ELBO is equal to the negative KL divergence up to
an additive constant.
see more details in <a class="reference external" href="https://arxiv.org/abs/1601.00670">Variational Inference: A Review for Statisticians</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>latent_prior</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The prior distribution of latent space. Default: Normal.
- Normal: The prior distribution of latent space is Normal.</p></li>
<li><p><strong>output_prior</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The distribution of output data. Default: Normal.
- Normal: If the distribution of output data is Normal, the reconstruct loss is MSELoss.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_data</strong> (Tuple) - (recon_x(Tensor), x(Tensor), mu(Tensor), std(Tensor)).</p></li>
<li><p><strong>target_data</strong> (Tensor) - the target tensor of shape <span class="math notranslate nohighlight">\((N,)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, loss float tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.infer.SVI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.infer.</span></span><span class="sig-name descname"><span class="pre">SVI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">net_with_loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/infer/variational/svi.html#SVI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.infer.SVI" title="Permalink to this definition"></a></dt>
<dd><p>Stochastic Variational Inference(SVI).</p>
<p>Variational inference casts the inference problem as an optimization. Some distributions over the hidden
variables that is indexed by a set of free parameters, and then optimize the parameters to make it closest to
the posterior of interest.
see more details in <a class="reference external" href="https://arxiv.org/abs/1601.00670">Variational Inference: A Review for Statisticians</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net_with_loss</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Cell with loss function.</p></li>
<li><p><strong>optimizer</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Optimizer for updating the weights.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.infer.SVI.get_train_loss">
<span class="sig-name descname"><span class="pre">get_train_loss</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/infer/variational/svi.html#SVI.get_train_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.infer.SVI.get_train_loss" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>numpy.dtype, the loss after training.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.infer.SVI.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/infer/variational/svi.html#SVI.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.infer.SVI.run" title="Permalink to this definition"></a></dt>
<dd><p>Optimize the parameters by training the probability network, and return the trained network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epochs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Total number of iterations on the data. Default: 10.</p></li>
<li><p><strong>train_dataset</strong> (<em>Dataset</em>) – A training dataset iterator.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Outputs:</dt><dd><p>Cell, the trained probability network.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-mindspore.nn.probability.toolbox">
<span id="mindspore-nn-probability-toolbox"></span><h2>mindspore.nn.probability.toolbox<a class="headerlink" href="#module-mindspore.nn.probability.toolbox" title="Permalink to this headline"></a></h2>
<p>Uncertainty toolbox.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.toolbox.UncertaintyEvaluation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.toolbox.</span></span><span class="sig-name descname"><span class="pre">UncertaintyEvaluation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epi_uncer_model_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ale_uncer_model_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/toolbox/uncertainty_evaluation.html#UncertaintyEvaluation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.toolbox.UncertaintyEvaluation" title="Permalink to this definition"></a></dt>
<dd><p>Toolbox for Uncertainty Evaluation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The model for uncertainty evaluation.</p></li>
<li><p><strong>train_dataset</strong> (<em>Dataset</em>) – A dataset iterator to train model.</p></li>
<li><p><strong>task_type</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Option for the task types of model
- regression: A regression model.
- classification: A classification model.</p></li>
<li><p><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of labels of classification.
If the task type is classification, it must be set; if not classification, it need not to be set.
Default: None.</p></li>
<li><p><strong>epochs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Total number of iterations on the data. Default: 1.</p></li>
<li><p><strong>epi_uncer_model_path</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The save or read path of the epistemic uncertainty model. Default: None.</p></li>
<li><p><strong>ale_uncer_model_path</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The save or read path of the aleatoric uncertainty model. Default: None.</p></li>
<li><p><strong>save_model</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Save the uncertainty model or not, if True, the epi_uncer_model_path
and ale_uncer_model_path should not be None. If False, give the path of
the uncertainty model, it will load the model to evaluate, if not given
the path, it will not save or load the uncertainty model. Default: False.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s1">&#39;checkpoint_lenet.ckpt&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;workspace/mnist/train&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">evaluation</span> <span class="o">=</span> <span class="n">UncertaintyEvaluation</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">network</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                   <span class="n">train_dataset</span><span class="o">=</span><span class="n">ds_train</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                   <span class="n">task_type</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                   <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                   <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                   <span class="n">epi_uncer_model_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                   <span class="n">ale_uncer_model_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                   <span class="n">save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">epistemic_uncertainty</span> <span class="o">=</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">eval_epistemic_uncertainty</span><span class="p">(</span><span class="n">eval_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aleatoric_uncertainty</span> <span class="o">=</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">eval_aleatoric_uncertainty</span><span class="p">(</span><span class="n">eval_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">epistemic_uncertainty</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(32, 10)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aleatoric_uncertainty</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(32,)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.toolbox.UncertaintyEvaluation.eval_aleatoric_uncertainty">
<span class="sig-name descname"><span class="pre">eval_aleatoric_uncertainty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eval_data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/toolbox/uncertainty_evaluation.html#UncertaintyEvaluation.eval_aleatoric_uncertainty"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.toolbox.UncertaintyEvaluation.eval_aleatoric_uncertainty" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the aleatoric uncertainty of inference results, which also called data uncertainty.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>eval_data</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The data samples to be evaluated, the shape should be (N,C,H,W).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.dtype, the aleatoric uncertainty of inference results of data samples.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.toolbox.UncertaintyEvaluation.eval_epistemic_uncertainty">
<span class="sig-name descname"><span class="pre">eval_epistemic_uncertainty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eval_data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/toolbox/uncertainty_evaluation.html#UncertaintyEvaluation.eval_epistemic_uncertainty"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.toolbox.UncertaintyEvaluation.eval_epistemic_uncertainty" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the epistemic uncertainty of inference results, which also called model uncertainty.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>eval_data</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The data samples to be evaluated, the shape should be (N,C,H,W).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.dtype, the epistemic uncertainty of inference results of data samples.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-mindspore.nn.probability.transforms">
<span id="mindspore-nn-probability-transforms"></span><h2>mindspore.nn.probability.transforms<a class="headerlink" href="#module-mindspore.nn.probability.transforms" title="Permalink to this headline"></a></h2>
<p>Transforms.</p>
<p>The high-level components used to transform model between DNN and BNN.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.probability.transforms.TransformToBNN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.probability.transforms.</span></span><span class="sig-name descname"><span class="pre">TransformToBNN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainable_dnn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dnn_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bnn_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/transforms/transform_bnn.html#TransformToBNN"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.transforms.TransformToBNN" title="Permalink to this definition"></a></dt>
<dd><p>Transform Deep Neural Network (DNN) model to Bayesian Neural Network (BNN) model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainable_dnn</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – A trainable DNN model (backbone) wrapped by TrainOneStepCell.</p></li>
<li><p><strong>dnn_factor</strong> (<em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The coefficient of backbone’s loss, which is computed by loss function. Default: 1.</p></li>
<li><p><strong>bnn_factor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The coefficient of kl loss, which is kl divergence of Bayesian layer. Default: 1.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="o">*</span><span class="mi">224</span><span class="o">*</span><span class="mi">224</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span> <span class="c1"># padding=0</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">is_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">WithLossCell</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_network</span> <span class="o">=</span> <span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">net_with_loss</span><span class="p">,</span> <span class="n">optim</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bnn_transformer</span> <span class="o">=</span> <span class="n">TransformToBNN</span><span class="p">(</span><span class="n">train_network</span><span class="p">,</span> <span class="mi">60000</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.transforms.TransformToBNN.transform_to_bnn_layer">
<span class="sig-name descname"><span class="pre">transform_to_bnn_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dnn_layer_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bnn_layer_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">get_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/transforms/transform_bnn.html#TransformToBNN.transform_to_bnn_layer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.transforms.TransformToBNN.transform_to_bnn_layer" title="Permalink to this definition"></a></dt>
<dd><p>Transform a specific type of layers in DNN model to corresponding BNN layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dnn_layer_type</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The type of DNN layer to be transformed to BNN layer. The optional values are
nn.Dense, nn.Conv2d.</p></li>
<li><p><strong>bnn_layer_type</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The type of BNN layer to be transformed to. The optional values are
DenseReparam, ConvReparam.</p></li>
<li><p><strong>get_args</strong> – The arguments gotten from the DNN layer. Default: None.</p></li>
<li><p><strong>add_args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – The new arguments added to BNN layer. Note that the arguments in <cite>add_args</cite> should not
duplicate arguments in <cite>get_args</cite>. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Cell, a trainable model wrapped by TrainOneStepCell, whose sprcific type of layer is transformed to the
corresponding bayesian layer.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">is_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">WithLossCell</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_network</span> <span class="o">=</span> <span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">net_with_loss</span><span class="p">,</span> <span class="n">optim</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bnn_transformer</span> <span class="o">=</span> <span class="n">TransformToBNN</span><span class="p">(</span><span class="n">train_network</span><span class="p">,</span> <span class="mi">60000</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_bnn_network</span> <span class="o">=</span> <span class="n">bnn_transformer</span><span class="o">.</span><span class="n">transform_to_bnn_layer</span><span class="p">(</span><span class="n">Dense</span><span class="p">,</span> <span class="n">DenseReparam</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.probability.transforms.TransformToBNN.transform_to_bnn_model">
<span class="sig-name descname"><span class="pre">transform_to_bnn_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">get_dense_args=&lt;function</span> <span class="pre">TransformToBNN.&lt;lambda&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">get_conv_args=&lt;function</span> <span class="pre">TransformToBNN.&lt;lambda&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dense_args=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_conv_args=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mindspore/nn/probability/transforms/transform_bnn.html#TransformToBNN.transform_to_bnn_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.probability.transforms.TransformToBNN.transform_to_bnn_model" title="Permalink to this definition"></a></dt>
<dd><p>Transform the whole DNN model to BNN model, and wrap BNN model by TrainOneStepCell.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>get_dense_args</strong> – The arguments gotten from the DNN full connection layer. Default: lambda dp:
{“in_channels”: dp.in_channels, “out_channels”: dp.out_channels, “has_bias”: dp.has_bias}.</p></li>
<li><p><strong>get_conv_args</strong> – The arguments gotten from the DNN convolutional layer. Default: lambda dp:
{“in_channels”: dp.in_channels, “out_channels”: dp.out_channels, “pad_mode”: dp.pad_mode,
“kernel_size”: dp.kernel_size, “stride”: dp.stride, “has_bias”: dp.has_bias}.</p></li>
<li><p><strong>add_dense_args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – The new arguments added to BNN full connection layer. Note that the arguments in
<cite>add_dense_args</cite> should not duplicate arguments in <cite>get_dense_args</cite>. Default: None.</p></li>
<li><p><strong>add_conv_args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – The new arguments added to BNN convolutional layer. Note that the arguments in
<cite>add_conv_args</cite> should not duplicate arguments in <cite>get_conv_args</cite>. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Cell, a trainable BNN model wrapped by TrainOneStepCell.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">is_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">WithLossCell</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_network</span> <span class="o">=</span> <span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">net_with_loss</span><span class="p">,</span> <span class="n">optim</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bnn_transformer</span> <span class="o">=</span> <span class="n">TransformToBNN</span><span class="p">(</span><span class="n">train_network</span><span class="p">,</span> <span class="mi">60000</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_bnn_network</span> <span class="o">=</span> <span class="n">bnn_transformer</span><span class="o">.</span><span class="n">transform_to_bnn_model</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindspore.nn.learning_rate_schedule.html" class="btn btn-neutral float-left" title="mindspore.nn.learning_rate_schedule" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mindspore.ops.html" class="btn btn-neutral float-right" title="mindspore.ops" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>