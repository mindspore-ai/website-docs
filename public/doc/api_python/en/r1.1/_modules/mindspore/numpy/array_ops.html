

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindspore.numpy.array_ops &mdash; MindSpore r1.1 documentation</title>
  

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">MindSpore Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.compression.html">mindspore.compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.explainer.html">mindspore.explainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.profiler.html">mindspore.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.train.html">mindspore.train</a></li>
</ul>
<p class="caption"><span class="caption-text">MindArmour Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.html">mindarmour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.adv_robustness.attacks.html">mindarmour.adv_robustness.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.adv_robustness.defenses.html">mindarmour.adv_robustness.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.adv_robustness.detectors.html">mindarmour.adv_robustness.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.adv_robustness.evaluations.html">mindarmour.adv_robustness.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.fuzz_testing.html">mindarmour.fuzz_testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.privacy.diff_privacy.html">mindarmour.privacy.diff_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.privacy.evaluation.html">mindarmour.privacy.evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.utils.html">mindarmour.utils</a></li>
</ul>
<p class="caption"><span class="caption-text">MindSpore Hub Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore_hub/mindspore_hub.html">mindspore_hub</a></li>
</ul>
<p class="caption"><span class="caption-text">MindSpore Serving Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore_serving/mindspore_serving.html">mindspore_serving</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>mindspore.numpy.array_ops</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for mindspore.numpy.array_ops</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2020 Huawei Technologies Co., Ltd</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ============================================================================</span>
<span class="sd">&quot;&quot;&quot;array operations, the function docs are adapted from Numpy API.&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">copy</span> <span class="k">as</span> <span class="n">py_copy</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">onp</span>

<span class="kn">from</span> <span class="nn">..common</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">..common</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">from</span> <span class="nn">..ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="kn">from</span> <span class="nn">..ops</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">..ops.primitive</span> <span class="kn">import</span> <span class="n">constexpr</span>

<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">_check_shape</span><span class="p">,</span> <span class="n">_check_shape_compile</span><span class="p">,</span> <span class="n">_check_dtype</span><span class="p">,</span> <span class="n">_check_is_int</span><span class="p">,</span> \
    <span class="n">_check_axes_range</span><span class="p">,</span> <span class="n">_check_start_normalize</span><span class="p">,</span> <span class="n">_check_shape_contain_zero</span><span class="p">,</span> <span class="n">_check_is_tensor</span><span class="p">,</span> \
    <span class="n">_check_input_for_asarray</span><span class="p">,</span> <span class="n">_deep_list</span><span class="p">,</span> <span class="n">_deep_tensor_to_nparray</span><span class="p">,</span> <span class="n">_check_is_list</span><span class="p">,</span> \
    <span class="n">_covert_list_tensor_to_tuple_tensor</span>

<span class="n">DEFAULT_FLOAT_DTYPE</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span>
<span class="n">DEFAULT_INT_DTYPE</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span>
<span class="c1"># According to official numpy reference, the dimension of a numpy array must be less</span>
<span class="c1"># than 32</span>
<span class="n">MAX_NUMPY_DIMS</span> <span class="o">=</span> <span class="mi">32</span>

<div class="viewcode-block" id="array"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.array.html#mindspore.numpy.array">[docs]</a><span class="k">def</span> <span class="nf">array</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ndmin</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a tensor.</span>

<span class="sd">    This function creates tensors from an array-like object.</span>

<span class="sd">    Args:</span>
<span class="sd">        obj (Union[int, float, bool, list, tuple, numpy.ndarray]): Input data, in</span>
<span class="sd">        any form that can be converted to a tensor. This includes lists, lists of</span>
<span class="sd">        tuples, tuples, tuples of tuples, tuples of lists and numpy.ndarray.</span>
<span class="sd">        dtype (Union[mstype.dtype, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.int32, or `int32`. If dtype is None, the data type</span>
<span class="sd">            of the new tensor will be inferred from obj. Default is None.</span>
<span class="sd">        copy (bool): If true, then the object is copied. Otherwise, a copy will</span>
<span class="sd">            only be made if necessary. Default: True.</span>
<span class="sd">        ndmin (int): Specifies the minimum number of dimensions that the resulting</span>
<span class="sd">            tensor should have. Ones will be pre-pended to the shape as needed to</span>
<span class="sd">            meet this requirement. Default: 0</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, generated tensor with the specified dtype.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.array([1,2,3]))</span>
<span class="sd">        [1 2 3]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">ndmin</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Fall back to original numpy creation.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
            <span class="n">obj</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">asarray</span><span class="p">(</span><span class="n">onp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="n">copy</span><span class="p">,</span> <span class="n">ndmin</span><span class="o">=</span><span class="n">ndmin</span><span class="p">))</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">copy</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">asarray</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

    <span class="n">obj</span> <span class="o">=</span> <span class="n">py_copy</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">asarray</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="asarray"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.asarray.html#mindspore.numpy.asarray">[docs]</a><span class="k">def</span> <span class="nf">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts the input to tensor.</span>

<span class="sd">    This function converts tensors from an array-like object.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Union[int, float, bool, list, tuple, numpy.ndarray]): Input data, in</span>
<span class="sd">        any form that can be converted to a tensor. This includes lists, lists of</span>
<span class="sd">        tuples, tuples, tuples of tuples, tuples of lists and ndarrays.</span>
<span class="sd">        dtype (Union[mstype.dtype, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.int32, or `int32`. If dtype is None, the data type</span>
<span class="sd">            of the new tensor will be inferred from a. Default is None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, generated tensor with the specified dtype.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.asarray([1,2,3]))</span>
<span class="sd">        [1 2 3]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

    <span class="n">_</span> <span class="o">=</span> <span class="n">_check_input_for_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">DEFAULT_FLOAT_DTYPE</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">DEFAULT_INT_DTYPE</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">bool_</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="c1"># Convert all tuple/nested tuples to lists</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">_deep_list</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="c1"># Convert all tensor sub-elements to numpy arrays</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">_deep_tensor_to_nparray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">onp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="c1"># If dtype is not specified, we keep consistent with numpy decision</span>
        <span class="c1"># only exceptions are: we use int/float32</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">onp</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;int64&#39;</span><span class="p">):</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">DEFAULT_INT_DTYPE</span>
            <span class="k">elif</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">onp</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float64&#39;</span><span class="p">):</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">DEFAULT_FLOAT_DTYPE</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">onp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">onp</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;bool&#39;</span><span class="p">):</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">bool_</span>
        <span class="k">elif</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">onp</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">):</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">DEFAULT_INT_DTYPE</span>
        <span class="k">elif</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">onp</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float&#39;</span><span class="p">):</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">DEFAULT_FLOAT_DTYPE</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="c1"># If a is already a tensor and we don&#39;t need to cast dtype, return a</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">a</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">a</span>

    <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="asfarray"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.asfarray.html#mindspore.numpy.asfarray">[docs]</a><span class="k">def</span> <span class="nf">asfarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">DEFAULT_FLOAT_DTYPE</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Similar to asarray, converts the input to a float tensor.</span>

<span class="sd">    If non-float dtype is defined, this function will return a float32 tensor instead.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Union[int, float, bool, list, tuple, numpy.ndarray]): Input data, in</span>
<span class="sd">        any form that can be converted to a tensor. This includes lists, lists of</span>
<span class="sd">        tuples, tuples, tuples of tuples, tuples of lists and numpy.ndarray.</span>
<span class="sd">        dtype (Union[mstype.dtype, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.float32, or `float32`. Default is mstype.float32.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, generated tensor with the specified float dtype.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.asfarray([1,2,3]))</span>
<span class="sd">        [1. 2. 3.]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">_check_input_for_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">):</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">DEFAULT_FLOAT_DTYPE</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="c1"># Convert all tuple/nested tuples to lists</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">_deep_list</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="c1"># Convert all tensor sub-elements to numpy arrays</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">_deep_tensor_to_nparray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">onp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">onp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">copy_</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a tensor copy of the given object.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Tensor): Input tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, has the same data as `a`.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; x = np.ones((2,2))</span>
<span class="sd">        &gt;&gt;&gt; print(np.copy(x))</span>
<span class="sd">        [[1. 1.]</span>
<span class="sd">         [1. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">py_copy</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>


<div class="viewcode-block" id="ones"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.ones.html#mindspore.numpy.ones">[docs]</a><span class="k">def</span> <span class="nf">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">DEFAULT_FLOAT_DTYPE</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new tensor of given shape and type, filled with ones.</span>

<span class="sd">    Args:</span>
<span class="sd">        shape (Union[int, tuple, list]): the shape of the new tensor.</span>
<span class="sd">        dtype (Union[mstype.dtype, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.float32, or `float32`. Default is mstype.float32.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, with the designated shape and dtype, filled with ones.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.ones((2,2)))</span>
<span class="sd">        [[1. 1.]</span>
<span class="sd">        [1. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">_check_shape_contain_zero</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">asarray</span><span class="p">(</span><span class="n">onp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">_check_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">fill</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Fill</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">fill</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="zeros"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.zeros.html#mindspore.numpy.zeros">[docs]</a><span class="k">def</span> <span class="nf">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">DEFAULT_FLOAT_DTYPE</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new tensor of given shape and type, filled with zeros.</span>

<span class="sd">    Args:</span>
<span class="sd">        shape (Union[int, tuple, list]): the shape of the new tensor.</span>
<span class="sd">        dtype (Union[mstype.dtype, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.float32, or `float32`. Default is mstype.float32.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, with the designated shape and dtype, filled with zeros.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.zeros((2,2)))</span>
<span class="sd">        [[0. 0.]</span>
<span class="sd">        [0. 0.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">_check_shape_contain_zero</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">asarray</span><span class="p">(</span><span class="n">onp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">_check_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">fill</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Fill</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">fill</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="full"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.full.html#mindspore.numpy.full">[docs]</a><span class="k">def</span> <span class="nf">full</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new tensor of given shape and type, filled with fill_value.</span>

<span class="sd">    Args:</span>
<span class="sd">        shape (Union[int, tuple(int), list(int)]): Shape of the new tensor, e.g.,</span>
<span class="sd">            (2, 3) or 2.</span>
<span class="sd">        fill_value (Union[int, float, bool, list, tuple]): scalar or array_like</span>
<span class="sd">            fill value.</span>
<span class="sd">        dtype (Union[mstype.dtype, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.float32, or `float32`, if dtype is None, the data type</span>
<span class="sd">            of the new tensor will be inferred from fill_value. Default is None.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, with the designated shape and dtype, filled with `fill_value`.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.full((2,2), True))</span>
<span class="sd">        [[True True]</span>
<span class="sd">        [True True]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">array</span><span class="p">(</span><span class="n">fill_value</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="n">_check_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">_check_input_for_asarray</span><span class="p">(</span><span class="n">fill_value</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">))</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">_check_shape_contain_zero</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">P</span><span class="o">.</span><span class="n">Fill</span><span class="p">()(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">)</span>

    <span class="c1"># if fill_value is array_like or shape contains zero. fall back to original</span>
    <span class="c1"># numpy creation</span>
    <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">onp</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">dtype_to_nptype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)))</span></div>


<div class="viewcode-block" id="arange"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.arange.html#mindspore.numpy.arange">[docs]</a><span class="k">def</span> <span class="nf">arange</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns evenly spaced values within a given interval.</span>

<span class="sd">    Returns `num` evenly spaced samples, calculated over the interval [`start`, `stop`].</span>
<span class="sd">    The endpoint of the interval can optionally be excluded.</span>
<span class="sd">    The current implementation is a direct wrapper on top of numpy.arange, except that</span>
<span class="sd">    the default dtype is float32 and int32, compare to float64 and int64 for numpy</span>
<span class="sd">    implementation.</span>

<span class="sd">    Args:</span>
<span class="sd">        start(Union[int, float]): Start of interval. The interval includes this value.</span>
<span class="sd">            When stop is provided as a position argument, start must be given, when stop</span>
<span class="sd">            is a normal argument, start can be optional, and default is 0.</span>
<span class="sd">            Please see additional examples below.</span>
<span class="sd">        stop(Union[int, float], optional): End of interval. The interval does not</span>
<span class="sd">            include this value, except in some cases where step is not an integer</span>
<span class="sd">            and floating point round-off affects the length of out.</span>
<span class="sd">        step(Union[int, float], optional): Spacing between values. For any output</span>
<span class="sd">            out, this is the distance between two adjacent values, out[i+1] - out[i].</span>
<span class="sd">            The default step size is 1. If step is specified as a position argument,</span>
<span class="sd">            start must also be given.</span>
<span class="sd">        dtype (Union[mstype.dtype, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.float32, or `float32`. If dtype is None, the data type</span>
<span class="sd">            of the new tensor will be inferred from start, stop and step. Default is None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        arangend tensor of evenly spaced values.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.arange(0, 5, 1))</span>
<span class="sd">        [0 1 2 3 4]</span>
<span class="sd">        &gt;&gt;&gt; print(np.arange(3))</span>
<span class="sd">        [0 1 2]</span>
<span class="sd">        &gt;&gt;&gt; print(np.arange(start=0, stop=3))</span>
<span class="sd">        [0 1 2]</span>
<span class="sd">        &gt;&gt;&gt; print(np.arange(0, stop=3, step=0.5))</span>
<span class="sd">        [0.  0.5 1.  1.5 2.  2.5]</span>
<span class="sd">        &gt;&gt;&gt; print(np.arange(stop=3)) # This will lead to TypeError</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># infer the dtype, if either of start, end, step is float, default dtype is</span>
    <span class="c1"># float32, else int32.</span>
    <span class="n">int_flag</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">final_dtype</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">args</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
                <span class="n">int_flag</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="s1">&#39;start&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;start&#39;</span><span class="p">],</span> <span class="nb">float</span><span class="p">))</span> <span class="ow">or</span> \
           <span class="p">(</span><span class="s1">&#39;stop&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;stop&#39;</span><span class="p">],</span> <span class="nb">float</span><span class="p">))</span> <span class="ow">or</span> \
           <span class="p">(</span><span class="s1">&#39;step&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">],</span> <span class="nb">float</span><span class="p">)):</span>
            <span class="n">int_flag</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">int_flag</span><span class="p">:</span>
        <span class="n">final_dtype</span> <span class="o">=</span> <span class="n">onp</span><span class="o">.</span><span class="n">int32</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">final_dtype</span> <span class="o">=</span> <span class="n">onp</span><span class="o">.</span><span class="n">float32</span>

    <span class="k">if</span> <span class="s1">&#39;dtype&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="ow">and</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;dtype&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">final_dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;dtype&#39;</span><span class="p">])</span>
        <span class="n">final_dtype</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">dtype_to_nptype</span><span class="p">(</span><span class="n">final_dtype</span><span class="p">)</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;dtype&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">final_dtype</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">onp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span></div>


<div class="viewcode-block" id="linspace"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.linspace.html#mindspore.numpy.linspace">[docs]</a><span class="k">def</span> <span class="nf">linspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">retstep</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns evenly spaced values within a given interval.</span>

<span class="sd">    The current implementation is a direct wrapper on top of numpy.linspace, except</span>
<span class="sd">    the default dtype is float32, compare to float64 for numpy,</span>

<span class="sd">    Args:</span>
<span class="sd">        start (Union[int, list(int), tuple(int),tensor]):The starting value of the sequence.</span>
<span class="sd">        stop (Union[int, list(int), tuple(int),tensor]):The end value of the sequence,</span>
<span class="sd">            unless `endpoint` is set to False. In that case, the sequence consists</span>
<span class="sd">            of all but the last of ``num + 1` evenly spaced samples, so that `stop`</span>
<span class="sd">            is excluded.  Note that the step size changes when `endpoint` is False.</span>
<span class="sd">        num (int, optional): Number of samples to generate. Default is 50.</span>
<span class="sd">        endpoint (bool, optional): If True, `stop` is the last sample. Otherwise, it is</span>
<span class="sd">            not included. Default is True.</span>
<span class="sd">        retstep (bool, optional): If True, return (`samples`, `step`), where `step` is</span>
<span class="sd">            the spacing between samples.</span>
<span class="sd">        dtype (Union[mstype.dtype, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.float32, or `float32`.If `dtype` is None, infer the data</span>
<span class="sd">            type from other input arguments. Default is None.</span>
<span class="sd">        axis (int, optional): The axis in the result to store the samples. Relevant</span>
<span class="sd">            only if start or stop are array-like.  By default (0), the samples will</span>
<span class="sd">            be along a new axis inserted at the beginning. Use -1 to get an axis at the end.</span>
<span class="sd">            Default is 0.</span>

<span class="sd">    Returns:</span>
<span class="sd">        samples (Tensor): There are `num` equally spaced samples in the closed interval</span>
<span class="sd">            ``[start, stop]`` or the half-open interval ``[start, stop)``</span>
<span class="sd">            (depending on whether `endpoint` is True or False).</span>

<span class="sd">        step (float, optional): Only returned if `retstep` is True.</span>
<span class="sd">            Size of spacing between samples.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.linspace(0, 5, 6))</span>
<span class="sd">        [0. 1. 2. 3. 4. 5.]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">start</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stop</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">stop</span> <span class="o">=</span> <span class="n">stop</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;num should be an integer, but got {type(num)}&quot;</span><span class="p">)</span>

    <span class="n">final_dtype</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">final_dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">final_dtype</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">dtype_to_nptype</span><span class="p">(</span><span class="n">final_dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">final_dtype</span> <span class="o">=</span> <span class="n">onp</span><span class="o">.</span><span class="n">float32</span>

    <span class="n">dtype</span> <span class="o">=</span> <span class="n">final_dtype</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">onp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">retstep</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">retstep</span><span class="p">:</span>
        <span class="n">array_out</span><span class="p">,</span> <span class="n">step_out</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">tensor_out</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">array_out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensor_out</span><span class="p">,</span> <span class="n">step_out</span>

    <span class="n">tensor_out</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tensor_out</span></div>


<div class="viewcode-block" id="logspace"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.logspace.html#mindspore.numpy.logspace">[docs]</a><span class="k">def</span> <span class="nf">logspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">base</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns numbers spaced evenly on a log scale.</span>

<span class="sd">    In linear space, the sequence starts at base ** start (base to the power of</span>
<span class="sd">    start) and ends with base ** stop (see endpoint below).</span>
<span class="sd">    The current implementation is a direct wrapper on top of numpy.logspace, except</span>
<span class="sd">    the default dtype is float32, compare to float64 for numpy,</span>

<span class="sd">    Args:</span>
<span class="sd">        start (Union[int, list(int), tuple(int), tensor]):The starting value of the sequence.</span>
<span class="sd">        stop (Union[int, list(int), tuple(int), tensor]):The end value of the sequence,</span>
<span class="sd">            unless `endpoint` is set to False. In that case, the sequence consists</span>
<span class="sd">            of all but the last of ``num + 1` evenly spaced samples, so that `stop`</span>
<span class="sd">            is excluded.  Note that the step size changes when `endpoint` is False.</span>
<span class="sd">        num (int, optional): Number of samples to generate. Default is 50.</span>
<span class="sd">        endpoint (bool, optional): If True, `stop` is the last sample. Otherwise, it is</span>
<span class="sd">            not included. Default is True.</span>
<span class="sd">        base (Union[int, float], optional): The base of the log space. The step size</span>
<span class="sd">            between the elements in ln(samples) / ln(base) (or log_base(samples))</span>
<span class="sd">            is uniform. Default is 10.0.</span>
<span class="sd">        dtype (Union[mstype.dtype, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.float32, or `float32`.If `dtype` is None, infer the data</span>
<span class="sd">            type from other input arguments. Default is None.</span>
<span class="sd">        axis (int, optional): The axis in the result to store the samples. Relevant</span>
<span class="sd">            only if start or stop is array-like.  By default (0), the samples will</span>
<span class="sd">            be along a new axis inserted at the beginning. Use -1 to get an axis at the end.</span>
<span class="sd">            Default is 0.</span>

<span class="sd">    Returns:</span>
<span class="sd">        samples (Tensor): num samples, equally spaced on a log scale.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.logspace(0, 5, 6, base=2.0))</span>
<span class="sd">        [ 1.  2.  4.  8. 16. 32.]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">start</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stop</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">stop</span> <span class="o">=</span> <span class="n">stop</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>

    <span class="n">final_dtype</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">final_dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">final_dtype</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">dtype_to_nptype</span><span class="p">(</span><span class="n">final_dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">final_dtype</span> <span class="o">=</span> <span class="n">onp</span><span class="o">.</span><span class="n">float32</span>

    <span class="n">dtype</span> <span class="o">=</span> <span class="n">final_dtype</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">onp</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">base</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>

    <span class="n">tensor_out</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tensor_out</span></div>


<div class="viewcode-block" id="eye"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.eye.html#mindspore.numpy.eye">[docs]</a><span class="k">def</span> <span class="nf">eye</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">DEFAULT_FLOAT_DTYPE</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a 2-D tensor with ones on the diagnoal and zeros elsewhere.</span>

<span class="sd">    Args:</span>
<span class="sd">        N (int): Number of rows in the output, must be larger than 0.</span>
<span class="sd">        M (int, optional): Number of columns in the output. If None, defaults to N,</span>
<span class="sd">            if defined, must be larger than 0. Deault is None.</span>
<span class="sd">        k (int, optional): Index of the diagonal: 0 (the default) refers to the main</span>
<span class="sd">            diagonal, a positive value refers to an upper diagonal, and a negative value</span>
<span class="sd">            to a lower diagonal. Default is 0.</span>
<span class="sd">        dtype (Union[mstype.dtype, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.float32, or `float32`. Default is mstype.float32.</span>

<span class="sd">    Returns:</span>
<span class="sd">        result (Tensor): A tensor of shape (N,M). A tensor where all elements</span>
<span class="sd">        are equal to zero, except for the k-th diagonal, whose values are equal to one.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.eye(2, 2))</span>
<span class="sd">        [[1. 0.]</span>
<span class="sd">        [0. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">make_eye</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Eye</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">M</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">N</span>
    <span class="n">M</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">N</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">M</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Fall back to original numpy creation method</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">onp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">make_eye</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">asarray</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="identity"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.identity.html#mindspore.numpy.identity">[docs]</a><span class="k">def</span> <span class="nf">identity</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">DEFAULT_FLOAT_DTYPE</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the identity tensor.</span>

<span class="sd">    Args:</span>
<span class="sd">        n (int): Number of rows and columns in the output, must be larger than 0.</span>
<span class="sd">        dtype (Union[mstype.dtype, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.float32, or `float32`. Default is mstype.float32.</span>

<span class="sd">    Returns:</span>
<span class="sd">        result (Tensor): A tensor of shape (n,n). A tensor where all elements</span>
<span class="sd">        are equal to zero, except for the diagonal, whose values are equal to one.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.identity(2))</span>
<span class="sd">        [[1. 0.]</span>
<span class="sd">        [0. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span></div>


<span class="nd">@constexpr</span>
<span class="k">def</span> <span class="nf">_prepare_shape_for_expand_dims</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates the expanded new shape based on the shape and given axes</span>

<span class="sd">    Args:</span>
<span class="sd">        shape (tuple): the shape of the tensor</span>
<span class="sd">        axes Union(int, tuple(int), list(int)): the axes with dimensions expanded.</span>

<span class="sd">    Returns:</span>
<span class="sd">        new_shape(tuple): the shape with dimensions expanded.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">new_shape</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">shape_idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">new_shape_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

    <span class="c1"># Convert to set</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">new_shape_length</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">axes</span> <span class="o">&gt;=</span> <span class="n">new_shape_length</span> <span class="ow">or</span> <span class="n">axes</span> <span class="o">&lt;</span> <span class="o">-</span><span class="n">new_shape_length</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;axis </span><span class="si">{axes}</span><span class="s2"> is out of bounds for tensor of dimension </span><span class="si">{new_shape_length}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="p">{</span><span class="n">axes</span><span class="p">}</span>

    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="n">new_shape_length</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">axis</span> <span class="o">&gt;=</span> <span class="n">new_shape_length</span> <span class="ow">or</span> <span class="n">axis</span> <span class="o">&lt;</span> <span class="o">-</span><span class="n">new_shape_length</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;axis </span><span class="si">{axis}</span><span class="s2"> is out of bounds for tensor of dimension </span><span class="si">{new_shape_length}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;only int, tuple and list are allowed for axes, but got {type(axes)}&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">new_shape_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_shape_length</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">new_shape_idx</span> <span class="ow">in</span> <span class="n">axes</span> <span class="ow">or</span> <span class="n">new_shape_idx</span> <span class="o">-</span> <span class="n">new_shape_length</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span>
            <span class="n">new_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="n">shape_idx</span><span class="p">])</span>
            <span class="n">shape_idx</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span>


<div class="viewcode-block" id="expand_dims"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.expand_dims.html#mindspore.numpy.expand_dims">[docs]</a><span class="k">def</span> <span class="nf">expand_dims</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Expands the shape of a tensor.</span>

<span class="sd">    Inserts a new axis that will appear at the axis position in the expanded tensor shape.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Tensor): Input tensor array.</span>
<span class="sd">        axis Union[int, list(int), tuple(int)]: Position in the expanded axes where</span>
<span class="sd">        the new axis is placed,</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, view of a tensor with the number of dimensions increased.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; x = np.ones((2,2))</span>
<span class="sd">        &gt;&gt;&gt; x = np.expand_dims(x,0)</span>
<span class="sd">        &gt;&gt;&gt; print(x.shape)</span>
<span class="sd">        (1, 2, 2)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="c1"># yield expanded shape based on the axes</span>
    <span class="n">new_shape</span> <span class="o">=</span> <span class="n">_prepare_shape_for_expand_dims</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">P</span><span class="o">.</span><span class="n">Reshape</span><span class="p">()(</span><span class="n">a</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">)</span></div>


<span class="nd">@constexpr</span>
<span class="k">def</span> <span class="nf">_prepare_shape_for_squeeze</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates the squeezed new shape based on the tensor and given axes.</span>

<span class="sd">    Args:</span>
<span class="sd">        shape (tuple): the shape of the tensor</span>
<span class="sd">        axes Union[None, int, tuple(int), list(int)]: the axes with dimensions squeezed.</span>

<span class="sd">    Returns:</span>
<span class="sd">        new_shape(tuple): the shape with dimensions squeezed.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">new_shape</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

    <span class="c1"># Convert to set</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">axes</span> <span class="o">&gt;=</span> <span class="n">ndim</span> <span class="ow">or</span> <span class="n">axes</span> <span class="o">&lt;</span> <span class="o">-</span><span class="n">ndim</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;axis </span><span class="si">{axes}</span><span class="s2"> is out of bounds for tensor of dimension </span><span class="si">{ndim}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="p">{</span><span class="n">axes</span><span class="p">}</span>

    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">axis</span> <span class="o">&gt;=</span> <span class="n">ndim</span> <span class="ow">or</span> <span class="n">axis</span> <span class="o">&lt;</span> <span class="o">-</span><span class="n">ndim</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;axis </span><span class="si">{axis}</span><span class="s2"> is out of bounds for tensor of dimension </span><span class="si">{ndim}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">axes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;only int, tuple and list are allowed for axes, but got {type(axes)}&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">axes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">new_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">shape</span> <span class="k">if</span> <span class="n">s</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">s</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="p">(</span><span class="n">idx</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">idx</span> <span class="o">-</span> <span class="n">ndim</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">):</span>
                <span class="n">new_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
            <span class="c1"># if an axis is selected with shape entry greater than one, an error is raised.</span>
            <span class="k">if</span> <span class="n">s</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="p">((</span><span class="n">idx</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">idx</span> <span class="o">-</span> <span class="n">ndim</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;axis </span><span class="si">{axes}</span><span class="s2"> has shape entry </span><span class="si">{s}</span><span class="s2"> &gt; 1, cannot be squeezed.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span>


<div class="viewcode-block" id="squeeze"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.squeeze.html#mindspore.numpy.squeeze">[docs]</a><span class="k">def</span> <span class="nf">squeeze</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Removes single-dimensional entries from the shape of an tensor.</span>

<span class="sd">    This is a temporary solution to support CPU backend. Will be changed</span>
<span class="sd">    once CPU backend supports P.Squeeze().</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Tensor): Input tensor array.</span>
<span class="sd">        axis: Union[None, int, list(int), tuple(list)]. Default is None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, with all or a subset of the dimensions of length 1 removed.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; x = np.ones((1,2,2,1))</span>
<span class="sd">        &gt;&gt;&gt; x = np.squeeze(x)</span>
<span class="sd">        &gt;&gt;&gt; print(x.shape)</span>
<span class="sd">        (2, 2)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="c1"># yield squeezed shape based on the axes</span>
    <span class="n">new_shape</span> <span class="o">=</span> <span class="n">_prepare_shape_for_squeeze</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">P</span><span class="o">.</span><span class="n">Reshape</span><span class="p">()(</span><span class="n">a</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">)</span></div>


<div class="viewcode-block" id="transpose"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.transpose.html#mindspore.numpy.transpose">[docs]</a><span class="k">def</span> <span class="nf">transpose</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reverses or permutes the axes of a tensor; returns the modified tensor.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Tensor): a tensor to be transposed</span>
<span class="sd">        axes (Union[None, tuple, list]): the axes order, if axes is None, transpose</span>
<span class="sd">        the entire tensor. Default is None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, the transposed tensor array.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; x = np.ones((1,2,3))</span>
<span class="sd">        &gt;&gt;&gt; x = np.transpose(x)</span>
<span class="sd">        &gt;&gt;&gt; print(x.shape)</span>
<span class="sd">        (3, 2, 1)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">axes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">length</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tuple_len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">perm</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">make_range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">length</span><span class="p">)</span>
        <span class="n">new_order</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tuple_reversed</span><span class="p">(</span><span class="n">perm</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">P</span><span class="o">.</span><span class="n">Transpose</span><span class="p">()(</span><span class="n">a</span><span class="p">,</span> <span class="n">new_order</span><span class="p">)</span>

    <span class="n">axes</span> <span class="o">=</span> <span class="n">_check_shape_compile</span><span class="p">(</span><span class="n">axes</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">P</span><span class="o">.</span><span class="n">Transpose</span><span class="p">()(</span><span class="n">a</span><span class="p">,</span> <span class="n">axes</span><span class="p">)</span></div>


<div class="viewcode-block" id="rollaxis"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.rollaxis.html#mindspore.numpy.rollaxis">[docs]</a><span class="k">def</span> <span class="nf">rollaxis</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rolls the specified axis backwards, until it lies in the given position.</span>
<span class="sd">    The positions of the other axes do not change relative to one another.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Tensor): A Tensor to be transposed.</span>
<span class="sd">        axis (int): The axis to be rolled.</span>
<span class="sd">        start (int):</span>
<span class="sd">            - When start &gt;= 0:</span>
<span class="sd">                - When start &lt;= axis: the axis is rolled back until it lies in</span>
<span class="sd">                  this position (start).</span>
<span class="sd">                - When start &gt; axis: the axis is rolled until it lies before this</span>
<span class="sd">                  position (start).</span>
<span class="sd">            - When start &lt; 0: the start will be normalized as follows:</span>
<span class="sd">                start ........... Normalized start</span>
<span class="sd">                -(x.ndim+1)       raise ValueError</span>
<span class="sd">                -x.ndim           0</span>
<span class="sd">                ...               ...</span>
<span class="sd">                -1                x.ndim-1</span>
<span class="sd">                0                 0</span>
<span class="sd">                ...               ...</span>
<span class="sd">                x.ndim            x.ndim</span>
<span class="sd">                x.ndim+1          raise ValueError</span>

<span class="sd">    Returns:</span>
<span class="sd">        Transposed Tensor. Has the same data type as the original tensor x.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If axis or start is not integer.</span>
<span class="sd">        ValueError: If axis is not in the range from -ndim to ndim-1 or</span>
<span class="sd">            start is not in the range from -ndim to ndim.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; x = np.ones((2,3,4))</span>
<span class="sd">        &gt;&gt;&gt; output = np.rollaxis(x, 0, 2)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<span class="sd">        (3, 2, 4)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_is_int</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>
    <span class="n">_check_is_int</span><span class="p">(</span><span class="n">start</span><span class="p">)</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tuple_len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">axis</span> <span class="o">=</span> <span class="n">_check_axes_range</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">ndim</span><span class="p">)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">_check_start_normalize</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">ndim</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">start</span> <span class="o">-</span> <span class="n">axis</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">start</span> <span class="o">-</span> <span class="n">axis</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span>
    <span class="n">perm</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">make_range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ndim</span><span class="p">)</span>
    <span class="n">new_perm</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">start</span> <span class="o">&lt;</span> <span class="n">axis</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&lt;</span> <span class="n">ndim</span><span class="p">:</span>
            <span class="n">new_perm</span> <span class="o">=</span> <span class="n">perm</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">start</span><span class="p">]</span> <span class="o">+</span> <span class="n">perm</span><span class="p">[</span><span class="n">axis</span><span class="p">:</span><span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> \
                <span class="n">perm</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">axis</span><span class="p">]</span> <span class="o">+</span> <span class="n">perm</span><span class="p">[</span><span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_perm</span> <span class="o">=</span> <span class="n">perm</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">start</span><span class="p">]</span> <span class="o">+</span> <span class="n">perm</span><span class="p">[</span><span class="n">axis</span><span class="p">:</span><span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">perm</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">axis</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">start</span> <span class="o">&gt;</span> <span class="n">axis</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">start</span> <span class="o">&lt;</span> <span class="n">ndim</span><span class="p">:</span>
            <span class="n">new_perm</span> <span class="o">=</span> <span class="n">perm</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">axis</span><span class="p">]</span> <span class="o">+</span> <span class="n">perm</span><span class="p">[</span><span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">start</span><span class="p">]</span> <span class="o">+</span> \
                <span class="n">perm</span><span class="p">[</span><span class="n">axis</span><span class="p">:</span><span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">perm</span><span class="p">[</span><span class="n">start</span><span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_perm</span> <span class="o">=</span> <span class="n">perm</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">axis</span><span class="p">]</span> <span class="o">+</span> <span class="n">perm</span><span class="p">[</span><span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">start</span><span class="p">]</span> <span class="o">+</span> \
                <span class="n">perm</span><span class="p">[</span><span class="n">axis</span><span class="p">:</span><span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">P</span><span class="o">.</span><span class="n">Transpose</span><span class="p">()(</span><span class="n">x</span><span class="p">,</span> <span class="n">new_perm</span><span class="p">)</span></div>


<div class="viewcode-block" id="swapaxes"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.swapaxes.html#mindspore.numpy.swapaxes">[docs]</a><span class="k">def</span> <span class="nf">swapaxes</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis1</span><span class="p">,</span> <span class="n">axis2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Interchanges two axes of a tensor.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Tensor): A tensor to be transposed.</span>
<span class="sd">        axis1 (int): First axis.</span>
<span class="sd">        axis2 (int): Second axis.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Transposed tensor, has the same data type as the original tensor x.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If axis1 or axis2 is not integer.</span>
<span class="sd">        ValueError: If axis1 or axis2 is not in the range from -ndim to ndim-1.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; x = np.ones((2,3,4))</span>
<span class="sd">        &gt;&gt;&gt; output = np.swapaxes(x, 0, 2)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<span class="sd">        (4,3,2)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_is_int</span><span class="p">(</span><span class="n">axis1</span><span class="p">)</span>
    <span class="n">_check_is_int</span><span class="p">(</span><span class="n">axis2</span><span class="p">)</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tuple_len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">axes</span> <span class="o">=</span> <span class="n">_check_axes_range</span><span class="p">((</span><span class="n">axis1</span><span class="p">,</span> <span class="n">axis2</span><span class="p">),</span> <span class="n">ndim</span><span class="p">)</span>
    <span class="n">axis1</span><span class="p">,</span> <span class="n">axis2</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">axis1</span> <span class="o">==</span> <span class="n">axis2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span>
    <span class="k">if</span> <span class="n">axis1</span> <span class="o">&gt;</span> <span class="n">axis2</span><span class="p">:</span>
        <span class="n">axis1</span><span class="p">,</span> <span class="n">axis2</span> <span class="o">=</span> <span class="n">axis2</span><span class="p">,</span> <span class="n">axis1</span>

    <span class="n">perm</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">make_range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ndim</span><span class="p">)</span>
    <span class="n">new_perm</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">axis2</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&lt;</span> <span class="n">ndim</span><span class="p">:</span>
        <span class="n">new_perm</span> <span class="o">=</span> <span class="n">perm</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">axis1</span><span class="p">]</span> <span class="o">+</span> <span class="n">perm</span><span class="p">[</span><span class="n">axis2</span><span class="p">:</span><span class="n">axis2</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> \
            <span class="n">perm</span><span class="p">[</span><span class="n">axis1</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">axis2</span><span class="p">]</span> <span class="o">+</span> <span class="n">perm</span><span class="p">[</span><span class="n">axis1</span><span class="p">:</span><span class="n">axis1</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">perm</span><span class="p">[</span><span class="n">axis2</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">new_perm</span> <span class="o">=</span> <span class="n">perm</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">axis1</span><span class="p">]</span> <span class="o">+</span> <span class="n">perm</span><span class="p">[</span><span class="n">axis2</span><span class="p">:</span><span class="n">axis2</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> \
            <span class="n">perm</span><span class="p">[</span><span class="n">axis1</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">axis2</span><span class="p">]</span> <span class="o">+</span> <span class="n">perm</span><span class="p">[</span><span class="n">axis1</span><span class="p">:</span><span class="n">axis1</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">P</span><span class="o">.</span><span class="n">Transpose</span><span class="p">()(</span><span class="n">x</span><span class="p">,</span> <span class="n">new_perm</span><span class="p">)</span></div>


<div class="viewcode-block" id="reshape"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.reshape.html#mindspore.numpy.reshape">[docs]</a><span class="k">def</span> <span class="nf">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reshapes a tensor without changing its data.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Tensor): A tensor to be reshaped.</span>
<span class="sd">        new_shape (Union[int, list(int), tuple(int)]): The new shape should be</span>
<span class="sd">            compatible with the original shape. If the tuple has only one element,</span>
<span class="sd">            the result will be a 1-D tensor of that length. One shape dimension</span>
<span class="sd">            can be -1. In this case, the value is inferred from the length of</span>
<span class="sd">            the tensor and remaining dimensions.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Reshaped Tensor. Has the same data type as the original tensor x.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If new_shape is not integer, list or tuple.</span>
<span class="sd">        ValueError: If new_shape does not compatible with the original shape.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; x = np.asarray([[-0.1, 0.3, 3.6], [0.4, 0.5, -3.2]])</span>
<span class="sd">        &gt;&gt;&gt; output = np.reshape(x, (3, 2))</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[-0.1  0.3]</span>
<span class="sd">         [ 3.6  0.4]</span>
<span class="sd">         [ 0.5 -3.2]]</span>
<span class="sd">        &gt;&gt;&gt; output = np.reshape(x, (3, -1))</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[-0.1  0.3]</span>
<span class="sd">         [ 3.6  0.4]</span>
<span class="sd">         [ 0.5 -3.2]]</span>
<span class="sd">        &gt;&gt;&gt; output = np.reshape(x, (6, ))</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [-0.1  0.3  3.6  0.4  0.5 -3.2]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">new_shape</span> <span class="o">=</span> <span class="n">_check_shape_compile</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">P</span><span class="o">.</span><span class="n">Reshape</span><span class="p">()(</span><span class="n">x</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">)</span></div>


<div class="viewcode-block" id="ravel"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.ravel.html#mindspore.numpy.ravel">[docs]</a><span class="k">def</span> <span class="nf">ravel</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a contiguous flattened tensor.</span>

<span class="sd">    A 1-D tensor, containing the elements of the input, is returned.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Tensor): A tensor to be flattened.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Flattened tensor, has the same data type as the original tensor x.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; x = np.ones((2,3,4))</span>
<span class="sd">        &gt;&gt;&gt; output = np.ravel(x)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<span class="sd">        (24,)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span></div>


<span class="nd">@constexpr</span>
<span class="k">def</span> <span class="nf">_move_axes_for_concatenate</span><span class="p">(</span><span class="n">arr_shape</span><span class="p">,</span> <span class="n">axis</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Moves axis 0 to the disiganated position, while keeps other axes&#39; relative</span>
<span class="sd">    positions unchanged, only used if a single tensor is concatenated.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">original_axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">arr_shape</span><span class="p">)))</span>
    <span class="n">new_axes</span> <span class="o">=</span> <span class="n">original_axes</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">0</span><span class="p">,)</span> <span class="o">+</span> <span class="n">original_axes</span><span class="p">[</span><span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span>
    <span class="n">new_shape</span> <span class="o">=</span> <span class="n">arr_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">arr_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">arr_shape</span><span class="p">[</span><span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">],)</span> <span class="o">+</span> \
        <span class="n">arr_shape</span><span class="p">[</span><span class="n">axis</span><span class="o">+</span><span class="mi">2</span><span class="p">:]</span>
    <span class="k">return</span> <span class="n">new_axes</span><span class="p">,</span> <span class="n">new_shape</span>


<div class="viewcode-block" id="concatenate"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.concatenate.html#mindspore.numpy.concatenate">[docs]</a><span class="k">def</span> <span class="nf">concatenate</span><span class="p">(</span><span class="n">arrays</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Joins a sequence of tensors along an existing axis.</span>

<span class="sd">    Args:</span>
<span class="sd">        arrays: Union[Tensor, tuple(Tensor), list(Tensor)], a tensor or a list</span>
<span class="sd">        of tensors to be concatenated.</span>

<span class="sd">        axis (int, optional): The axis along which the tensors will be joined,</span>
<span class="sd">            if axis is None, tensors are flattened before use. Default is 0.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, a tensor concatenated from a tensor or a list of tensors.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; x1 = np.ones((1,2,3))</span>
<span class="sd">        &gt;&gt;&gt; x2 = np.ones((1,2,1))</span>
<span class="sd">        &gt;&gt;&gt; x = np.concatenate((x1, x2), axis=-1)</span>
<span class="sd">        &gt;&gt;&gt; print(x.shape)</span>
<span class="sd">        (1, 2, 4)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">array_type</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">typeof</span><span class="p">(</span><span class="n">arrays</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">_check_is_tensor</span><span class="p">(</span><span class="n">array_type</span><span class="p">):</span>
        <span class="c1"># if the input is a single tensor</span>
        <span class="c1"># if only one tensor is provided, it is treated as a tuple along the</span>
        <span class="c1"># first dimension. For example, a tensor of shape (3,4,5) will be treated</span>
        <span class="c1"># as: tuple(tensor_1(4,5), tensor_2(4,5), tensor_3(4,5))</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">axis</span> <span class="o">&gt;=</span> <span class="n">MAX_NUMPY_DIMS</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ravel</span><span class="p">(</span><span class="n">arrays</span><span class="p">)</span>
        <span class="n">arr_shape</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">arrays</span><span class="p">)</span>
        <span class="n">_check_axes_range</span><span class="p">((</span><span class="n">axis</span><span class="p">,),</span> <span class="nb">len</span><span class="p">(</span><span class="n">arr_shape</span><span class="p">))</span>
        <span class="c1"># move axis 0 to the disiganated position, while keep other axes&#39; relative</span>
        <span class="c1"># positions unchanged</span>
        <span class="n">new_axes</span><span class="p">,</span> <span class="n">new_shape</span> <span class="o">=</span> <span class="n">_move_axes_for_concatenate</span><span class="p">(</span><span class="n">arr_shape</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
        <span class="n">arrays</span> <span class="o">=</span> <span class="n">transpose</span><span class="p">(</span><span class="n">arrays</span><span class="p">,</span> <span class="n">new_axes</span><span class="p">)</span>
        <span class="n">arrays</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">arrays</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">arrays</span>

    <span class="n">flattened_arrays</span> <span class="o">=</span> <span class="p">()</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">axis</span> <span class="o">&gt;=</span> <span class="n">MAX_NUMPY_DIMS</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">arr</span> <span class="ow">in</span> <span class="n">arrays</span><span class="p">:</span>
            <span class="n">flattened_arrays</span> <span class="o">+=</span> <span class="p">(</span><span class="n">ravel</span><span class="p">(</span><span class="n">arr</span><span class="p">),)</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">return</span> <span class="n">P</span><span class="o">.</span><span class="n">Concat</span><span class="p">(</span><span class="n">axis</span><span class="p">)(</span><span class="n">flattened_arrays</span><span class="p">)</span>

    <span class="c1"># convert a list of tensor to a tuple of tensor</span>
    <span class="k">if</span> <span class="n">_check_is_list</span><span class="p">(</span><span class="n">array_type</span><span class="p">):</span>
        <span class="n">arrays</span> <span class="o">=</span> <span class="n">_covert_list_tensor_to_tuple_tensor</span><span class="p">(</span><span class="n">arrays</span><span class="p">)</span>

    <span class="n">arr_shape</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">_check_axes_range</span><span class="p">((</span><span class="n">axis</span><span class="p">,),</span> <span class="nb">len</span><span class="p">(</span><span class="n">arr_shape</span><span class="p">))</span>

    <span class="c1"># if only one tensor in the tuple/list, return the tensor itself</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">arrays</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">P</span><span class="o">.</span><span class="n">Concat</span><span class="p">(</span><span class="n">axis</span><span class="p">)(</span><span class="n">arrays</span><span class="p">)</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, MindSpore

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>