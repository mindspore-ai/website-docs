<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.explainer &mdash; MindSpore r1.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="mindspore.mindrecord" href="mindspore.mindrecord.html" />
    <link rel="prev" title="mindspore.dataset.vision.py_transforms.UniformAugment" href="dataset_vision/mindspore.dataset.vision.py_transforms.UniformAugment.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">MindSpore Python API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.compression.html">mindspore.compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindspore.explainer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">mindspore.explainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.explainer.explanation">mindspore.explainer.explanation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.explainer.benchmark">mindspore.explainer.benchmark</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.profiler.html">mindspore.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.train.html">mindspore.train</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindArmour Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.html">mindarmour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.attacks.html">mindarmour.adv_robustness.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.defenses.html">mindarmour.adv_robustness.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.detectors.html">mindarmour.adv_robustness.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.evaluations.html">mindarmour.adv_robustness.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.fuzz_testing.html">mindarmour.fuzz_testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.privacy.diff_privacy.html">mindarmour.privacy.diff_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.privacy.evaluation.html">mindarmour.privacy.evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.utils.html">mindarmour.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindSpore Hub Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindspore_hub/mindspore_hub.html">mindspore_hub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindSpore Serving Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindspore_serving/mindspore_serving.html">mindspore_serving</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>mindspore.explainer</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/mindspore/mindspore.explainer.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mindspore-explainer">
<h1>mindspore.explainer<a class="headerlink" href="#mindspore-explainer" title="Permalink to this headline"></a></h1>
<section id="id1">
<h2>mindspore.explainer<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h2>
<span class="target" id="module-mindspore.explainer"></span><p>Provides explanation runner high-level APIs.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.explainer.ImageClassificationRunner">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.explainer.</span></span><span class="sig-name descname"><span class="pre">ImageClassificationRunner</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">summary_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/explainer/_image_classification_runner.html#ImageClassificationRunner"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.explainer.ImageClassificationRunner" title="Permalink to this definition"></a></dt>
<dd><p>A high-level API for users to generate and store results of the explanation methods and the evaluation methods.</p>
<p>Update in 2020.11: Adjust the storage structure and format of the data. Summary files generated by previous version
will be deprecated and will not be supported in MindInsight of current version.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>summary_dir</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The directory path to save the summary files which store the generated results.</p></li>
<li><p><strong>data</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><em>Dataset</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em><em>]</em>) – Tuple of dataset and the corresponding class label list. The dataset
should provides [images], [images, labels] or [images, labels, bboxes] as columns. The label list must
share the exact same length and order of the network outputs.</p></li>
<li><p><strong>network</strong> (<em>Cell</em>) – The network(with logit outputs) to be explained.</p></li>
<li><p><strong>activation_fn</strong> (<em>Cell</em>) – The activation layer that transforms logits to prediction probabilities. For
single label classification tasks, <cite>nn.Softmax</cite> is usually applied. As for multi-label classification tasks,
<cite>nn.Sigmoid</cite> is usually be applied. Users can also pass their own customized <cite>activation_fn</cite> as long as
when combining this function with network, the final output is the probability of the input.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer</span> <span class="kn">import</span> <span class="n">ImageClassificationRunner</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer.explanation</span> <span class="kn">import</span> <span class="n">GuidedBackprop</span><span class="p">,</span> <span class="n">Gradient</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer.benchmark</span> <span class="kn">import</span> <span class="n">Faithfulness</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Softmax</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Prepare the dataset for explaining and evaluation, e.g., Cifar10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="s1">&#39;/path/to/Cifar10_dataset&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;airplane&#39;</span><span class="p">,</span> <span class="s1">&#39;automobile&#39;</span><span class="p">,</span> <span class="s1">&#39;bird&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;deer&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;frog&#39;</span><span class="p">,</span> <span class="s1">&#39;horse&#39;</span><span class="p">,</span> <span class="s1">&#39;ship&#39;</span><span class="p">,</span> <span class="s1">&#39;truck&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># load checkpoint to a network, e.g. checkpoint of resnet50 trained on Cifar10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;checkpoint.ckpt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">Softmax</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gbp</span> <span class="o">=</span> <span class="n">GuidedBackprop</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gradient</span> <span class="o">=</span> <span class="n">Gradient</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainers</span> <span class="o">=</span> <span class="p">[</span><span class="n">gbp</span><span class="p">,</span> <span class="n">gradient</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">faithfulness</span> <span class="o">=</span> <span class="n">Faithfulness</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="n">activation_fn</span><span class="p">,</span> <span class="s2">&quot;NaiveFaithfulness&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">benchmarkers</span> <span class="o">=</span> <span class="p">[</span><span class="n">faithfulness</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">runner</span> <span class="o">=</span> <span class="n">ImageClassificationRunner</span><span class="p">(</span><span class="s2">&quot;./summary_dir&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">labels</span><span class="p">),</span> <span class="n">net</span><span class="p">,</span> <span class="n">activation_fn</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">runner</span><span class="o">.</span><span class="n">register_saliency</span><span class="p">(</span><span class="n">explainers</span><span class="o">=</span><span class="n">explainers</span><span class="p">,</span> <span class="n">benchmarkers</span><span class="o">=</span><span class="n">benchmarkers</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">runner</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.explainer.ImageClassificationRunner.register_saliency">
<span class="sig-name descname"><span class="pre">register_saliency</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">explainers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">benchmarkers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/explainer/_image_classification_runner.html#ImageClassificationRunner.register_saliency"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.explainer.ImageClassificationRunner.register_saliency" title="Permalink to this definition"></a></dt>
<dd><p>Register saliency explanation instances.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function call not be invoked more then once on each runner.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>explainers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><em>Attribution</em><em>]</em>) – The explainers to be evaluated,
see <cite>mindspore.explainer.explanation</cite>. All explainers’ class must be distinct and their network
must be the exact same instance of the runner’s network.</p></li>
<li><p><strong>benchmarkers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><em>AttributionMetric</em><em>]</em><em>, </em><em>optional</em>) – The benchmarkers for scoring the explainers,
see <cite>mindspore.explainer.benchmark</cite>. All benchmarkers’ class must be distinct.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Be raised for any data or settings’ value problem.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – Be raised for any data or settings’ type problem.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – Be raised if this function was invoked before.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.explainer.ImageClassificationRunner.run">
<span class="sig-name descname"><span class="pre">run</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/explainer/_image_classification_runner.html#ImageClassificationRunner.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.explainer.ImageClassificationRunner.run" title="Permalink to this definition"></a></dt>
<dd><p>Run the explain job and save the result as a summary in summary_dir.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>User should call register_saliency() once before running this function.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Be raised for any data or settings’ value problem.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – Be raised for any data or settings’ type problem.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – Be raised for any runtime problem.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-mindspore.explainer.explanation">
<span id="mindspore-explainer-explanation"></span><h2>mindspore.explainer.explanation<a class="headerlink" href="#module-mindspore.explainer.explanation" title="Permalink to this headline"></a></h2>
<p>Predefined Attribution explainers.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.explainer.explanation.Deconvolution">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.explainer.explanation.</span></span><span class="sig-name descname"><span class="pre">Deconvolution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/explainer/explanation/_attribution/_backprop/modified_relu.html#Deconvolution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.explainer.explanation.Deconvolution" title="Permalink to this definition"></a></dt>
<dd><p>Deconvolution explanation.</p>
<p>Deconvolution method is a modified version of Gradient method. For the original ReLU operation in the network to be
explained, Deconvolution modifies the propagation rule from directly backpropagating gradients to backprpagating
positive gradients.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The parsed <cite>network</cite> will be set to eval mode through <cite>network.set_grad(False)</cite> and <cite>network.set_train(False)</cite>.
If you want to train the <cite>network</cite> afterwards, please reset it back to training mode through the opposite
operations. To use <cite>Deconvolution</cite>, the <cite>ReLU</cite> operations in the network must be implemented with
<cite>mindspore.nn.Cell</cite> object rather than <cite>mindspore.ops.Operations.ReLU</cite>. Otherwise, the results will not be
correct.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>network</strong> (<em>Cell</em>) – The black-box model to be explained.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (Tensor) - The input data to be explained, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>targets</strong> (Tensor, int) - The label of interest. It should be a 1D or 0D tensor, or an integer.
If it is a 1D tensor, its length should be the same as <cite>inputs</cite>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer.explanation</span> <span class="kn">import</span> <span class="n">Deconvolution</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># init Deconvolution with a trained network.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>  <span class="c1"># please refer to model_zoo</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50.ckpt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">deconvolution</span> <span class="o">=</span> <span class="n">Deconvolution</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># parse data and the target label to be explained and get the saliency map</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">deconvolution</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.explainer.explanation.GradCAM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.explainer.explanation.</span></span><span class="sig-name descname"><span class="pre">GradCAM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/explainer/explanation/_attribution/_backprop/gradcam.html#GradCAM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.explainer.explanation.GradCAM" title="Permalink to this definition"></a></dt>
<dd><p>Provides GradCAM explanation method.</p>
<p><cite>GradCAM</cite> generates saliency map at intermediate layer. The attribution is obtained as:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\alpha_k^c = \frac{1}{Z} \sum_i \sum_j \frac{\partial{y^c}}{\partial{A_{i,j}^k}}\\attribution = ReLU(\sum_k \alpha_k^c A^k)\end{aligned}\end{align} \]</div>
<p>For more details, please refer to the original paper: <a class="reference external" href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.pdf">GradCAM</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The parsed <cite>network</cite> will be set to eval mode through <cite>network.set_grad(False)</cite> and <cite>network.set_train(False)</cite>.
If you want to train the <cite>network</cite> afterwards, please reset it back to training mode through the opposite
operations.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – The black-box model to be explained.</p></li>
<li><p><strong>layer</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – The layer name to generate the explanation, usually chosen as the last convolutional
layer for better practice. If it is ‘’, the explantion will be generated at the input layer.
Default: ‘’.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (Tensor) - The input data to be explained, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>targets</strong> (Tensor, int) - The label of interest. It should be a 1D or 0D tensor, or an integer.
If it is a 1D tensor, its length should be the same as <cite>inputs</cite>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer.explanation</span> <span class="kn">import</span> <span class="n">GradCAM</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># load a trained network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50.ckpt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># specify a layer name to generate explanation, usually the layer can be set as the last conv layer.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">layer_name</span> <span class="o">=</span> <span class="s1">&#39;layer4&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># init GradCAM with a trained network and specify the layer to obtain attribution</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gradcam</span> <span class="o">=</span> <span class="n">GradCAM</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="n">layer_name</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">gradcam</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.explainer.explanation.Gradient">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.explainer.explanation.</span></span><span class="sig-name descname"><span class="pre">Gradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/explainer/explanation/_attribution/_backprop/gradient.html#Gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.explainer.explanation.Gradient" title="Permalink to this definition"></a></dt>
<dd><p>Provides Gradient explanation method.</p>
<p>Gradient is the simplest attribution method which uses the naive gradients of outputs w.r.t inputs as the
explanation.</p>
<div class="math notranslate nohighlight">
\[attribution = \frac{\partial{y}}{\partial{x}}\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The parsed <cite>network</cite> will be set to eval mode through <cite>network.set_grad(False)</cite> and <cite>network.set_train(False)</cite>.
If you want to train the <cite>network</cite> afterwards, please reset it back to training mode through the opposite
operations.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>network</strong> (<em>Cell</em>) – The black-box model to be explained.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (Tensor) - The input data to be explained, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>targets</strong> (Tensor, int) - The label of interest. It should be a 1D or 0D tensor, or an integer.
If it is a 1D tensor, its length should be the same as <cite>inputs</cite>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer.explanation</span> <span class="kn">import</span> <span class="n">Gradient</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># init Gradient with a trained network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>  <span class="c1"># please refer to model_zoo</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50.ckpt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gradient</span> <span class="o">=</span> <span class="n">Gradient</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.explainer.explanation.GuidedBackprop">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.explainer.explanation.</span></span><span class="sig-name descname"><span class="pre">GuidedBackprop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/explainer/explanation/_attribution/_backprop/modified_relu.html#GuidedBackprop"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.explainer.explanation.GuidedBackprop" title="Permalink to this definition"></a></dt>
<dd><p>Guided-Backpropagation explanation.</p>
<p>Guided-Backpropagation method is an extension of Gradient method. On top of the original ReLU operation in the
network to be explained, Guided-Backpropagation introduces another ReLU operation to filter out the negative
gradients during backpropagation.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The parsed <cite>network</cite> will be set to eval mode through <cite>network.set_grad(False)</cite> and <cite>network.set_train(False)</cite>.
If you want to train the <cite>network</cite> afterwards, please reset it back to training mode through the opposite
operations. To use <cite>GuidedBackprop</cite>, the <cite>ReLU</cite> operations in the network must be implemented with
<cite>mindspore.nn.Cell</cite> object rather than <cite>mindspore.ops.Operations.ReLU</cite>. Otherwise, the results will not be
correct.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>network</strong> (<em>Cell</em>) – The black-box model to be explained.</p>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (Tensor) - The input data to be explained, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>targets</strong> (Tensor, int) - The label of interest. It should be a 1D or 0D tensor, or an integer.
If it is a 1D tensor, its length should be the same as <cite>inputs</cite>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer.explanation</span> <span class="kn">import</span> <span class="n">GuidedBackprop</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># init GuidedBackprop with a trained network.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>  <span class="c1"># please refer to model_zoo</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50.ckpt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gbp</span> <span class="o">=</span> <span class="n">GuidedBackprop</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># parse data and the target label to be explained and get the saliency map</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">gbp</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.explainer.explanation.Occlusion">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.explainer.explanation.</span></span><span class="sig-name descname"><span class="pre">Occlusion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbation_per_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/explainer/explanation/_attribution/_perturbation/occlusion.html#Occlusion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.explainer.explanation.Occlusion" title="Permalink to this definition"></a></dt>
<dd><p>Occlusion uses a sliding window to replace the pixels with a reference value (e.g. constant value), and computes
the output difference w.r.t the original output. The output difference caused by perturbed pixels are assigned as
feature importance to those pixels. For pixels involved in multiple sliding windows, the feature importance is the
averaged differences from multiple sliding windows.</p>
<p>For more details, please refer to the original paper via: <a class="reference external" href="https://arxiv.org/abs/1311.2901">https://arxiv.org/abs/1311.2901</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – The black-box model to be explained.</p></li>
<li><p><strong>activation_fn</strong> (<em>Cell</em>) – The activation layer that transforms logits to prediction probabilities. For
single label classification tasks, <cite>nn.Softmax</cite> is usually applied. As for multi-label classification tasks,
<cite>nn.Sigmoid</cite> is usually be applied. Users can also pass their own customized <cite>activation_fn</cite> as long as
when combining this function with network, the final output is the probability of the input.</p></li>
<li><p><strong>perturbation_per_eval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Number of perturbations for each inference during inferring the
perturbed samples. Within the memory capacity, usually the larger this number is, the faster the
explanation is obtained. Default: 32.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (Tensor) - The input data to be explained, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>targets</strong> (Tensor, int) - The label of interest. It should be a 1D or 0D tensor, or an integer.
If it is a 1D tensor, its length should be the same as <cite>inputs</cite>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer.explanation</span> <span class="kn">import</span> <span class="n">Occlusion</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># prepare your network and load the trained checkpoint file, e.g., resnet50.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50.ckpt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize Occlusion explainer with the pretrained model and activation function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span> <span class="c1"># softmax layer is applied to transform logits to probabilities</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">occlusion</span> <span class="o">=</span> <span class="n">Occlusion</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">activation_fn</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">occlusion</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.explainer.explanation.RISE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.explainer.explanation.</span></span><span class="sig-name descname"><span class="pre">RISE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbation_per_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/explainer/explanation/_attribution/_perturbation/rise.html#RISE"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.explainer.explanation.RISE" title="Permalink to this definition"></a></dt>
<dd><p>RISE: Randomized Input Sampling for Explanation of Black-box Model.</p>
<p>RISE is a perturbation-based method that generates attribution maps by sampling on multiple random binary masks.
The original image is randomly masked, and then fed into the black-box model to get predictions. The final
attribution map is the weighted sum of these random masks, with the weights being the corresponding output on the
node of interest:</p>
<div class="math notranslate nohighlight">
\[attribution = \sum_{i}f_c(I\odot M_i)  M_i\]</div>
<p>For more details, please refer to the original paper via: <a class="reference external" href="https://arxiv.org/abs/1806.07421">RISE</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – The black-box model to be explained.</p></li>
<li><p><strong>activation_fn</strong> (<em>Cell</em>) – The activation layer that transforms logits to prediction probabilities. For
single label classification tasks, <cite>nn.Softmax</cite> is usually applied. As for multi-label classification tasks,
<cite>nn.Sigmoid</cite> is usually be applied. Users can also pass their own customized <cite>activation_fn</cite> as long as
when combining this function with network, the final output is the probability of the input.</p></li>
<li><p><strong>perturbation_per_eval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Number of perturbations for each inference during inferring the
perturbed samples. Within the memory capacity, usually the larger this number is, the faster the
explanation is obtained. Default: 32.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (Tensor) - The input data to be explained, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>targets</strong> (Tensor, int) - The labels of interest to be explained. When <cite>targets</cite> is an integer,
all of the inputs will generates attribution map w.r.t this integer. When <cite>targets</cite> is a tensor, it
should be of shape <span class="math notranslate nohighlight">\((N, l)\)</span> (l being the number of labels for each sample) or <span class="math notranslate nohighlight">\((N,)\)</span> <span class="math notranslate nohighlight">\(()\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, ?, H, W)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer.explanation</span> <span class="kn">import</span> <span class="n">RISE</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Sigmoid</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># prepare your network and load the trained checkpoint file, e.g., resnet50.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50.ckpt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize RISE explainer with the pretrained model and activation function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span> <span class="c1"># softmax layer is applied to transform logits to probabilities</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rise</span> <span class="o">=</span> <span class="n">RISE</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">activation_fn</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># given an instance of RISE, saliency map can be generate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># when `targets` is an integer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">targets</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">rise</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># `targets` can also be a 2D tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">targets</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">rise</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-mindspore.explainer.benchmark">
<span id="mindspore-explainer-benchmark"></span><h2>mindspore.explainer.benchmark<a class="headerlink" href="#module-mindspore.explainer.benchmark" title="Permalink to this headline"></a></h2>
<p>Predefined XAI metrics.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.explainer.benchmark.ClassSensitivity">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.explainer.benchmark.</span></span><span class="sig-name descname"><span class="pre">ClassSensitivity</span></span><a class="reference internal" href="../_modules/mindspore/explainer/benchmark/_attribution/class_sensitivity.html#ClassSensitivity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.explainer.benchmark.ClassSensitivity" title="Permalink to this definition"></a></dt>
<dd><p>Class sensitivity metric used to evaluate attribution-based explanations.</p>
<p>Reasonable atrribution-based explainers are expected to generate distinct saliency maps for different labels,
especially for labels of highest confidence and low confidence. ClassSensitivity evaluates the explainer through
computing the correlation between saliency maps of highest-confidence and lowest-confidence labels. Explainer with
better class sensitivity will receive lower correlation score. To make the evaluation results intuitive, the
returned score will take negative on correlation and normalize.</p>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.explainer.benchmark.ClassSensitivity.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">explainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/explainer/benchmark/_attribution/class_sensitivity.html#ClassSensitivity.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.explainer.benchmark.ClassSensitivity.evaluate" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate class sensitivity on a single data sample.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>explainer</strong> (<em>Explanation</em>) – The explainer to be evaluated, see <cite>mindspore.explainer.explanation</cite>.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A data sample, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, 1D array of shape <span class="math notranslate nohighlight">\((N,)\)</span>, result of class sensitivity evaluated on <cite>explainer</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer.benchmark</span> <span class="kn">import</span> <span class="n">ClassSensitivity</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer.explanation</span> <span class="kn">import</span> <span class="n">Gradient</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># prepare your network and load the trained checkpoint file, e.g., resnet50.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50.ckpt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># prepare your explainer to be evaluated, e.g., Gradient.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gradient</span> <span class="o">=</span> <span class="n">Gradient</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">class_sensitivity</span> <span class="o">=</span> <span class="n">ClassSensitivity</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">class_sensitivity</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">input_x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.explainer.benchmark.Faithfulness">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.explainer.benchmark.</span></span><span class="sig-name descname"><span class="pre">Faithfulness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NaiveFaithfulness'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/explainer/benchmark/_attribution/faithfulness.html#Faithfulness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.explainer.benchmark.Faithfulness" title="Permalink to this definition"></a></dt>
<dd><p>Provides evaluation on faithfulness on XAI explanations.</p>
<p>Three specific metrics to obtain quantified results are supported: “NaiveFaithfulness”, “DeletionAUC”, and
“InsertionAUC”.</p>
<p>For metric “NaiveFaithfulness”, a series of perturbed images are created by modifying pixels
on original image. Then the perturbed images will be fed to the model and a series of output probability drops can
be obtained. The faithfulness is then quantified as the correlation between the propability drops and the saliency
map values on the same pixels (we normalize the correlation further to make them in range of [0, 1]).</p>
<p>For metric “DeletionAUC”, a series of perturbed images are created by accumulatively modifying pixels of the
original image to a base value (e.g. a constant). The perturbation starts from pixels with high saliency values
to pixels with low saliency values. Feeding the perturbed images into the model in order, an output probability
drop curve can be obtained. “DeletionAUC” is then obtained as the area under this probability drop curve.</p>
<p>For metric “InsertionAUC”, a series of perturbed images are created by accumulatively inserting pixels of the
original image to a reference image (e.g. a black image). The insertion starts from pixels with high saliency values
to pixels with low saliency values. Feeding the perturbed images into the model in order, an output probability
increase curve can be obtained. “InsertionAUC” is then obtained as the area under this curve.</p>
<p>For all the three metrics, higher value indicates better faithfulness.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_labels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of labels.</p></li>
<li><p><strong>activation_fn</strong> (<em>Cell</em>) – The activation layer that transforms logits to prediction probabilities. For
single label classification tasks, <cite>nn.Softmax</cite> is usually applied. As for multi-label classification tasks,
<cite>nn.Sigmoid</cite> is usually be applied. Users can also pass their own customized <cite>activation_fn</cite> as long as
when combining this function with network, the final output is the probability of the input.</p></li>
<li><p><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – The specifi metric to quantify faithfulness.
Options: “DeletionAUC”, “InsertionAUC”, “NaiveFaithfulness”.
Default: ‘NaiveFaithfulness’.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer.benchmark</span> <span class="kn">import</span> <span class="n">Faithfulness</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># init a `Faithfulness` object</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_labels</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metric</span> <span class="o">=</span> <span class="s2">&quot;InsertionAUC&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">faithfulness</span> <span class="o">=</span> <span class="n">Faithfulness</span><span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="n">activation_fn</span><span class="p">,</span> <span class="n">metric</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.explainer.benchmark.Faithfulness.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">explainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">saliency</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/explainer/benchmark/_attribution/faithfulness.html#Faithfulness.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.explainer.benchmark.Faithfulness.evaluate" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate faithfulness on a single data sample.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Currently only single sample (<span class="math notranslate nohighlight">\(N=1\)</span>) at each call is supported.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>explainer</strong> (<em>Explanation</em>) – The explainer to be evaluated, see <cite>mindspore.explainer.explanation</cite>.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A data sample, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>targets</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The label of interest. It should be a 1D or 0D tensor, or an integer.
If <cite>targets</cite> is a 1D tensor, its length should be the same as <cite>inputs</cite>.</p></li>
<li><p><strong>saliency</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) – The saliency map to be evaluated, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span>.
If it is None, the parsed <cite>explainer</cite> will generate the saliency map with <cite>inputs</cite> and <cite>targets</cite> and
continue the evaluation. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, 1D array of shape <span class="math notranslate nohighlight">\((N,)\)</span>, result of faithfulness evaluated on <cite>explainer</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer.explanation</span> <span class="kn">import</span> <span class="n">Gradient</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># init an explainer with a trained network, e.g., resnet50</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gradient</span> <span class="o">=</span> <span class="n">Gradient</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">targets</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># usage 1: input the explainer and the data to be explained,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># calculate the faithfulness with the specified metric</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">faithfulness</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># usage 2: input the generated saliency map</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">faithfulness</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">saliency</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.explainer.benchmark.Localization">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.explainer.benchmark.</span></span><span class="sig-name descname"><span class="pre">Localization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'PointingGame'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/explainer/benchmark/_attribution/localization.html#Localization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.explainer.benchmark.Localization" title="Permalink to this definition"></a></dt>
<dd><p>Provides evaluation on the localization capability of XAI methods.</p>
<p>Three specific metrics to obtain quantified results are supported: “PointingGame”, and “IoSR”
(Intersection over Salient Region).</p>
<p>For metric “PointingGame”, the localization capability is calculated as the ratio of data in which the max position
of their saliency maps lies within the bounding boxes. Specifically, for a single datum, given the saliency map and
its bounding box, if the max point of its saliency map lies within the bounding box, the evaluation result is 1
otherwise 0.</p>
<p>For metric “IoSR” (Intersection over Salient Region), the localization capability is calculated as the intersection
of the bounding box and the salient region over the area of the salient region. The salient region is defined as
the region whose value exceeds <span class="math notranslate nohighlight">\(\theta * \max{saliency}\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_labels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of classes in the dataset.</p></li>
<li><p><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – Specific metric to calculate localization capability.
Options: “PointingGame”, “IoSR”.
Default: “PointingGame”.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer.benchmark</span> <span class="kn">import</span> <span class="n">Localization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_labels</span> <span class="o">=</span> <span class="mi">100</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">localization</span> <span class="o">=</span> <span class="n">Localization</span><span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="s2">&quot;PointingGame&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.explainer.benchmark.Localization.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">explainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">saliency</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/explainer/benchmark/_attribution/localization.html#Localization.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.explainer.benchmark.Localization.evaluate" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate localization on a single data sample.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Currently only single sample (<span class="math notranslate nohighlight">\(N=1\)</span>) at each call is supported.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>explainer</strong> (<em>Explanation</em>) – The explainer to be evaluated, see <cite>mindspore.explainer.explanation</cite>.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A data sample, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>targets</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The label of interest. It should be a 1D or 0D tensor, or an integer.
If <cite>targets</cite> is a 1D tensor, its length should be the same as <cite>inputs</cite>.</p></li>
<li><p><strong>saliency</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) – The saliency map to be evaluated, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span>.
If it is None, the parsed <cite>explainer</cite> will generate the saliency map with <cite>inputs</cite> and <cite>targets</cite> and
continue the evaluation. Default: None.</p></li>
<li><p><strong>mask</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Ground truth bounding box/masks for the inputs w.r.t targets, a 4D tensor
or numpy.ndarray of shape <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, 1D array of shape <span class="math notranslate nohighlight">\((N,)\)</span>, result of localization evaluated on <cite>explainer</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer.explanation</span> <span class="kn">import</span> <span class="n">Gradient</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># init an explainer with a trained network, e.g., resnet50</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gradient</span> <span class="o">=</span> <span class="n">Gradient</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">masks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">masks</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">65</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">65</span><span class="p">:</span> <span class="mi">100</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">targets</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># usage 1: input the explainer and the data to be explained,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># calculate the faithfulness with the specified metric</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">localization</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">masks</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># usage 2: input the generated saliency map</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">saliency</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">localization</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">saliency</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">masks</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.explainer.benchmark.Robustness">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.explainer.benchmark.</span></span><span class="sig-name descname"><span class="pre">Robustness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/explainer/benchmark/_attribution/robustness.html#Robustness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.explainer.benchmark.Robustness" title="Permalink to this definition"></a></dt>
<dd><p>Robustness perturbs the inputs by adding random noise and choose the maximum sensitivity as evaluation score from
the perturbations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_labels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of classes in the dataset.</p></li>
<li><p><strong>activation_fn</strong> (<em>Cell</em>) – The activation layer that transforms logits to prediction probabilities. For
single label classification tasks, <cite>nn.Softmax</cite> is usually applied. As for multi-label classification tasks,
<cite>nn.Sigmoid</cite> is usually be applied. Users can also pass their own customized <cite>activation_fn</cite> as long as
when combining this function with network, the final output is the probability of the input.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer.benchmark</span> <span class="kn">import</span> <span class="n">Robustness</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Initialize a Robustness benchmarker passing num_labels of the dataset.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_labels</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">robustness</span> <span class="o">=</span> <span class="n">Robustness</span><span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="n">activation_fn</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.explainer.benchmark.Robustness.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">explainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">saliency</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/explainer/benchmark/_attribution/robustness.html#Robustness.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.explainer.benchmark.Robustness.evaluate" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate robustness on single sample.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Currently only single sample (<span class="math notranslate nohighlight">\(N=1\)</span>) at each call is supported.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>explainer</strong> (<em>Explanation</em>) – The explainer to be evaluated, see <cite>mindspore.explainer.explanation</cite>.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A data sample, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>.</p></li>
<li><p><strong>targets</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The label of interest. It should be a 1D or 0D tensor, or an integer.
If <cite>targets</cite> is a 1D tensor, its length should be the same as <cite>inputs</cite>.</p></li>
<li><p><strong>saliency</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) – The saliency map to be evaluated, a 4D tensor of shape <span class="math notranslate nohighlight">\((N, 1, H, W)\)</span>.
If it is None, the parsed <cite>explainer</cite> will generate the saliency map with <cite>inputs</cite> and <cite>targets</cite> and
continue the evaluation. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, 1D array of shape <span class="math notranslate nohighlight">\((N,)\)</span>, result of localization evaluated on <cite>explainer</cite>.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If batch_size is larger than 1.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer.explanation</span> <span class="kn">import</span> <span class="n">Gradient</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.explainer.benchmark</span> <span class="kn">import</span> <span class="n">Robustness</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># prepare your network and load the trained checkpoint file, e.g., resnet50.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50.ckpt&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># prepare your explainer to be evaluated, e.g., Gradient.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gradient</span> <span class="o">=</span> <span class="n">Gradient</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_label</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># robustness is a Robustness instance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">robustness</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">input_x</span><span class="p">,</span> <span class="n">target_label</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="dataset_vision/mindspore.dataset.vision.py_transforms.UniformAugment.html" class="btn btn-neutral float-left" title="mindspore.dataset.vision.py_transforms.UniformAugment" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mindspore.mindrecord.html" class="btn btn-neutral float-right" title="mindspore.mindrecord" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>