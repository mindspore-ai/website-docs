<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="mindspore.common.initializer" href="mindspore.common.initializer.html" />
    <link rel="prev" title="MindSpore Python API" href="../index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">MindSpore Python API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.compression.html">mindspore.compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.explainer.html">mindspore.explainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.profiler.html">mindspore.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.train.html">mindspore.train</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindArmour Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.html">mindarmour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.attacks.html">mindarmour.adv_robustness.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.defenses.html">mindarmour.adv_robustness.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.detectors.html">mindarmour.adv_robustness.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.evaluations.html">mindarmour.adv_robustness.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.fuzz_testing.html">mindarmour.fuzz_testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.privacy.diff_privacy.html">mindarmour.privacy.diff_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.privacy.evaluation.html">mindarmour.privacy.evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.privacy.sup_privacy.html">mindarmour.privacy.sup_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.utils.html">mindarmour.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindSpore Hub Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindspore_hub/mindspore_hub.html">mindspore_hub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindSpore Serving Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindspore_serving/mindspore_serving.html">mindspore_serving</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindQuantum Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindquantum/mindquantum.html">mindquantum</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>mindspore</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/mindspore/mindspore.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mindspore">
<h1>mindspore<a class="headerlink" href="#mindspore" title="Permalink to this headline"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dtype">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">dtype</span></span><a class="headerlink" href="#mindspore.dtype" title="Permalink to this definition"></a></dt>
<dd><p>Create a data type object of MindSpore.</p>
<p>The actual path of <code class="docutils literal notranslate"><span class="pre">dtype</span></code> is <code class="docutils literal notranslate"><span class="pre">/mindspore/common/dtype.py</span></code>.
Run the following command to import the package:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
</pre></div>
</div>
<ul>
<li><p><strong>Numeric Type</strong></p>
<p>Currently, MindSpore supports <code class="docutils literal notranslate"><span class="pre">Int</span></code> type, <code class="docutils literal notranslate"><span class="pre">Uint</span></code> type and <code class="docutils literal notranslate"><span class="pre">Float</span></code> type.
The following table lists the details.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 61%" />
<col style="width: 39%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Definition</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.int8</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.byte</span></code></p></td>
<td><p>8-bit integer</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.int16</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.short</span></code></p></td>
<td><p>16-bit integer</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.int32</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.intc</span></code></p></td>
<td><p>32-bit integer</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.int64</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.intp</span></code></p></td>
<td><p>64-bit integer</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.uint8</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.ubyte</span></code></p></td>
<td><p>unsigned 8-bit integer</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.uint16</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.ushort</span></code></p></td>
<td><p>unsigned 16-bit integer</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.uint32</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.uintc</span></code></p></td>
<td><p>unsigned 32-bit integer</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.uint64</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.uintp</span></code></p></td>
<td><p>unsigned 64-bit integer</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.float16</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.half</span></code></p></td>
<td><p>16-bit floating-point number</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.float32</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.single</span></code></p></td>
<td><p>32-bit floating-point number</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.float64</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.double</span></code></p></td>
<td><p>64-bit floating-point number</p></td>
</tr>
</tbody>
</table>
</li>
<li><p><strong>Other Type</strong></p>
<p>For other defined types, see the following table.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 85%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">tensor</span></code></p></td>
<td><p>MindSpore’s <code class="docutils literal notranslate"><span class="pre">tensor</span></code> type. Data format uses NCHW. For details, see <a class="reference external" href="https://www.gitee.com/mindspore/mindspore/blob/r1.2/mindspore/common/tensor.py">tensor</a>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">bool_</span></code></p></td>
<td><p>Boolean <code class="docutils literal notranslate"><span class="pre">True</span></code> or <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">int_</span></code></p></td>
<td><p>Integer scalar.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">uint</span></code></p></td>
<td><p>Unsigned integer scalar.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">float_</span></code></p></td>
<td><p>Floating-point scalar.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">number</span></code></p></td>
<td><p>Number, including <code class="docutils literal notranslate"><span class="pre">int_</span></code> , <code class="docutils literal notranslate"><span class="pre">uint</span></code> , <code class="docutils literal notranslate"><span class="pre">float_</span></code> and <code class="docutils literal notranslate"><span class="pre">bool_</span></code> .</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">list_</span></code></p></td>
<td><p>List constructed by <code class="docutils literal notranslate"><span class="pre">tensor</span></code> , such as <code class="docutils literal notranslate"><span class="pre">List[T0,T1,...,Tn]</span></code> , where the element <code class="docutils literal notranslate"><span class="pre">Ti</span></code> can be of different types.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">tuple_</span></code></p></td>
<td><p>Tuple constructed by <code class="docutils literal notranslate"><span class="pre">tensor</span></code> , such as <code class="docutils literal notranslate"><span class="pre">Tuple[T0,T1,...,Tn]</span></code> , where the element <code class="docutils literal notranslate"><span class="pre">Ti</span></code> can be of different types.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">function</span></code></p></td>
<td><p>Function. Return in two ways, when function is not None, returns Func directly, the other returns Func(args: List[T0,T1,…,Tn], retval: T) when function is None.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">type_type</span></code></p></td>
<td><p>Type definition of type.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">type_none</span></code></p></td>
<td><p>No matching return type, corresponding to the <code class="docutils literal notranslate"><span class="pre">type(None)</span></code> in Python.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">symbolic_key</span></code></p></td>
<td><p>The value of a variable is used as a key of the variable in <code class="docutils literal notranslate"><span class="pre">env_type</span></code> .</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">env_type</span></code></p></td>
<td><p>Used to store the gradient of the free variable of a function, where the key is the <code class="docutils literal notranslate"><span class="pre">symbolic_key</span></code> of the free variable’s node and the value is the gradient.</p></td>
</tr>
</tbody>
</table>
</li>
<li><p><strong>Tree Topology</strong></p>
<p>The relationships of the above types are as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>└─────── number
    │   ├─── bool_
    │   ├─── int_
    │   │   ├─── int8, byte
    │   │   ├─── int16, short
    │   │   ├─── int32, intc
    │   │   └─── int64, intp
    │   ├─── uint
    │   │   ├─── uint8, ubyte
    │   │   ├─── uint16, ushort
    │   │   ├─── uint32, uintc
    │   │   └─── uint64, uintp
    │   └─── float_
    │       ├─── float16
    │       ├─── float32
    │       └─── float64
    ├─── tensor
    │   ├─── Array[Float32]
    │   └─── ...
    ├─── list_
    │   ├─── List[Int32,Float32]
    │   └─── ...
    ├─── tuple_
    │   ├─── Tuple[Int32,Float32]
    │   └─── ...
    ├─── function
    │   ├─── Func
    │   ├─── Func[(Int32, Float32), Int32]
    │   └─── ...
    ├─── type_type
    ├─── type_none
    ├─── symbolic_key
    └─── env_type
</pre></div>
</div>
</li>
</ul>
</dd></dl>

<span class="target" id="module-mindspore"></span><dl class="py class">
<dt class="sig sig-object py" id="mindspore.DatasetHelper">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">DatasetHelper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_sink_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sink_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DatasetHelper" title="Permalink to this definition"></a></dt>
<dd><p>DatasetHelper is a class to process the MindData dataset and it provides the information of dataset.</p>
<p>According to different contexts, change the iterations of dataset and use the same iteration for loop in different
contexts.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The iteration of DatasetHelper will provide one epoch data.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<em>Dataset</em>) – The training dataset iterator.</p></li>
<li><p><strong>dataset_sink_mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If true use GetNext to fetch the data, or else feed the data
from host. Default: True.</p></li>
<li><p><strong>sink_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Control the amount of data in each sink.
If sink_size=-1, sink the complete dataset for each epoch.
If sink_size&gt;0, sink sink_size data for each epoch.
Default: -1.</p></li>
<li><p><strong>epoch_num</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Control the number of epoch data to send. Default: 1.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">DatasetHelper</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">WithLossCell</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset_helper</span> <span class="o">=</span> <span class="n">DatasetHelper</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">next_element</span> <span class="ow">in</span> <span class="n">dataset_helper</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">outputs</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="o">*</span><span class="n">next_element</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DatasetHelper.continue_send">
<span class="sig-name descname"><span class="pre">continue_send</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.continue_send"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DatasetHelper.continue_send" title="Permalink to this definition"></a></dt>
<dd><p>continue send data to device at the beginning of epoch.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DatasetHelper.get_data_info">
<span class="sig-name descname"><span class="pre">get_data_info</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.get_data_info"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DatasetHelper.get_data_info" title="Permalink to this definition"></a></dt>
<dd><p>Get the types and shape of current batch.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DatasetHelper.release">
<span class="sig-name descname"><span class="pre">release</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.release"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DatasetHelper.release" title="Permalink to this definition"></a></dt>
<dd><p>Free up resources about data sink.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DatasetHelper.sink_size">
<span class="sig-name descname"><span class="pre">sink_size</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.sink_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DatasetHelper.sink_size" title="Permalink to this definition"></a></dt>
<dd><p>Get sink_size for each iteration.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DatasetHelper.stop_send">
<span class="sig-name descname"><span class="pre">stop_send</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.stop_send"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DatasetHelper.stop_send" title="Permalink to this definition"></a></dt>
<dd><p>stop send data about data sink.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DatasetHelper.types_shapes">
<span class="sig-name descname"><span class="pre">types_shapes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.types_shapes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DatasetHelper.types_shapes" title="Permalink to this definition"></a></dt>
<dd><p>Get the types and shapes from dataset on the current configuration.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.DynamicLossScaleManager">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">DynamicLossScaleManager</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">init_loss_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16777216</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_window</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DynamicLossScaleManager" title="Permalink to this definition"></a></dt>
<dd><p>Dynamic loss-scale manager.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init_loss_scale</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Initialize loss scale. Default: 2**24.</p></li>
<li><p><strong>scale_factor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Coefficient of increase and decrease. Default: 2.</p></li>
<li><p><strong>scale_window</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Maximum continuous normal steps when there is no overflow. Default: 2000.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.loss_scale_manager</span> <span class="kn">import</span> <span class="n">DynamicLossScaleManager</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">DynamicLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DynamicLossScaleManager.get_drop_overflow_update">
<span class="sig-name descname"><span class="pre">get_drop_overflow_update</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager.get_drop_overflow_update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DynamicLossScaleManager.get_drop_overflow_update" title="Permalink to this definition"></a></dt>
<dd><p>Get the flag whether to drop optimizer update when there is an overflow.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DynamicLossScaleManager.get_loss_scale">
<span class="sig-name descname"><span class="pre">get_loss_scale</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager.get_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DynamicLossScaleManager.get_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Get loss scale value.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DynamicLossScaleManager.get_update_cell">
<span class="sig-name descname"><span class="pre">get_update_cell</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager.get_update_cell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DynamicLossScaleManager.get_update_cell" title="Permalink to this definition"></a></dt>
<dd><p>Returns the cell for <cite>TrainOneStepWithLossScaleCell</cite></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DynamicLossScaleManager.update_loss_scale">
<span class="sig-name descname"><span class="pre">update_loss_scale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overflow</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager.update_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DynamicLossScaleManager.update_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Update loss scale value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>overflow</strong> – Boolean. Whether it overflows.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.FixedLossScaleManager">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">FixedLossScaleManager</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_overflow_update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.FixedLossScaleManager" title="Permalink to this definition"></a></dt>
<dd><p>Fixed loss-scale manager.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss_scale</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Loss scale. Note that if <cite>drop_overflow_update</cite> is set to False, the value of <cite>loss_scale</cite>
in optimizer that you used need to be set to the same value as here. Default: 128.0.</p></li>
<li><p><strong>drop_overflow_update</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to execute optimizer if there is an overflow. If True, the optimizer will
not executed when overflow occurs. Default: True.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">FixedLossScaleManager</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#1) Drop the parameter update if there is an overflow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#2) Execute parameter update even if overflow occurs</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">(</span><span class="n">loss_scale</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.FixedLossScaleManager.get_drop_overflow_update">
<span class="sig-name descname"><span class="pre">get_drop_overflow_update</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager.get_drop_overflow_update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.FixedLossScaleManager.get_drop_overflow_update" title="Permalink to this definition"></a></dt>
<dd><p>Get the flag whether to drop optimizer update when there is an overflow.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.FixedLossScaleManager.get_loss_scale">
<span class="sig-name descname"><span class="pre">get_loss_scale</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager.get_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.FixedLossScaleManager.get_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Get loss scale value.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.FixedLossScaleManager.get_update_cell">
<span class="sig-name descname"><span class="pre">get_update_cell</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager.get_update_cell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.FixedLossScaleManager.get_update_cell" title="Permalink to this definition"></a></dt>
<dd><p>Returns the cell for <cite>TrainOneStepWithLossScaleCell</cite></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.FixedLossScaleManager.update_loss_scale">
<span class="sig-name descname"><span class="pre">update_loss_scale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overflow</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager.update_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.FixedLossScaleManager.update_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Update loss scale value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>overflow</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether it overflows.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.LossScaleManager">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">LossScaleManager</span></span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#LossScaleManager"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.LossScaleManager" title="Permalink to this definition"></a></dt>
<dd><p>Loss scale manager abstract class.</p>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.LossScaleManager.get_loss_scale">
<span class="sig-name descname"><span class="pre">get_loss_scale</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#LossScaleManager.get_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.LossScaleManager.get_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Get loss scale value.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.LossScaleManager.get_update_cell">
<span class="sig-name descname"><span class="pre">get_update_cell</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#LossScaleManager.get_update_cell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.LossScaleManager.get_update_cell" title="Permalink to this definition"></a></dt>
<dd><p>Get the loss scaling update logic cell.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.LossScaleManager.update_loss_scale">
<span class="sig-name descname"><span class="pre">update_loss_scale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overflow</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#LossScaleManager.update_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.LossScaleManager.update_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Update loss scale value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>overflow</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether it overflows.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.Model">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">Model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_network</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_indexes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amp_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'O0'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/model.html#Model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Model" title="Permalink to this definition"></a></dt>
<dd><p>High-Level API for Training or Testing.</p>
<p><cite>Model</cite> groups layers into an object with training and inference features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – A training or testing network.</p></li>
<li><p><strong>loss_fn</strong> (<em>Cell</em>) – Objective function, if loss_fn is None, the
network should contain the logic of loss and grads calculation, and the logic
of parallel if needed. Default: None.</p></li>
<li><p><strong>optimizer</strong> (<em>Cell</em>) – Optimizer for updating the weights. Default: None.</p></li>
<li><p><strong>metrics</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#set" title="(in Python v3.8)"><em>set</em></a><em>]</em>) – A Dictionary or a set of metrics to be evaluated by the model during
training and testing. eg: {‘accuracy’, ‘recall’}. Default: None.</p></li>
<li><p><strong>eval_network</strong> (<em>Cell</em>) – Network for evaluation. If not defined, <cite>network</cite> and <cite>loss_fn</cite> would be wrapped as
<cite>eval_network</cite>. Default: None.</p></li>
<li><p><strong>eval_indexes</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – When defining the <cite>eval_network</cite>, if <cite>eval_indexes</cite> is None, all outputs of the
<cite>eval_network</cite> would be passed to metrics, otherwise <cite>eval_indexes</cite> must contain three
elements, including the positions of loss value, predicted value and label. The loss
value would be passed to the <cite>Loss</cite> metric, the predicted value and label would be passed
to other metric. Default: None.</p></li>
<li><p><strong>amp_level</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>Option for argument <cite>level</cite> in <cite>mindspore.amp.build_train_network</cite>, level for mixed
precision training. Supports [“O0”, “O2”, “O3”, “auto”]. Default: “O0”.</p>
<ul>
<li><p>O0: Do not change.</p></li>
<li><p>O2: Cast network to float16, keep batchnorm run in float32, using dynamic loss scale.</p></li>
<li><p>O3: Cast network to float16, with additional property ‘keep_batchnorm_fp32=False’.</p></li>
<li><p>auto: Set to level to recommended level in different devices. Set level to O2 on GPU, Set
level to O3 Ascend. The recommended level is choose by the export experience, cannot
always generalize. User should specify the level for special network.</p></li>
</ul>
<p>O2 is recommended on GPU, O3 is recommended on Ascend.</p>
</p></li>
<li><p><strong>loss_scale_manager</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference internal" href="#mindspore.LossScaleManager" title="mindspore.LossScaleManager"><em>LossScaleManager</em></a><em>]</em>) – If it is None, the loss would not be scaled. Otherwise,
scale the loss by LossScaleManager and optimizer can not be None.It is a key argument.
e.g. Use <cite>loss_scale_manager=None</cite> to set the value.</p></li>
<li><p><strong>keep_batchnorm_fp32</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Keep Batchnorm running in <cite>float32</cite>. If it is set to true, the level setting before
will be overwritten. Default: True.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_class</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">num_channel</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="o">*</span><span class="mi">5</span><span class="o">*</span><span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;ones&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;ones&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="n">num_class</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;ones&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">x</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># For details about how to build the dataset, please refer to the tutorial</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># document on the official website.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Model.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">valid_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_sink_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/model.html#Model.eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Model.eval" title="Permalink to this definition"></a></dt>
<dd><p>Evaluation API where the iteration is controlled by python front-end.</p>
<p>Configure to pynative mode or CPU, the evaluating process will be performed with dataset non-sink mode.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If dataset_sink_mode is True, data will be sent to device. If device is Ascend, features
of data will be transferred one by one. The limitation of data transmission per time is 256M.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>valid_dataset</strong> (<em>Dataset</em>) – Dataset to evaluate the model.</p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>(</em><a class="reference internal" href="mindspore.train.html#mindspore.train.callback.Callback" title="mindspore.train.callback.Callback"><em>Callback</em></a><em>)</em><em>]</em>) – List of callback objects which should be executed
while training. Default: None.</p></li>
<li><p><strong>dataset_sink_mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Determines whether to pass the data through dataset channel.
Default: True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict, which returns the loss value and metrics values for the model in the test mode.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># For details about how to build the dataset, please refer to the tutorial</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># document on the official website.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Model.eval_network">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">eval_network</span></span><a class="headerlink" href="#mindspore.Model.eval_network" title="Permalink to this definition"></a></dt>
<dd><p>Get the model’s eval_network.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Model.infer_predict_layout">
<span class="sig-name descname"><span class="pre">infer_predict_layout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">predict_data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/model.html#Model.infer_predict_layout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Model.infer_predict_layout" title="Permalink to this definition"></a></dt>
<dd><p>Generate parameter layout for the predict network in auto or semi auto parallel mode.</p>
<p>Data could be a single tensor or multiple tensors.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Batch data should be put together in one tensor.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>predict_data</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – One tensor or multiple tensors of predict data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict, Parameter layout dictionary used for load distributed checkpoint</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.context</span> <span class="kn">import</span> <span class="n">ParallelMode</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">full_batch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parallel_mode</span><span class="o">=</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">SEMI_AUTO_PARALLEL</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">]),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">Net</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">infer_predict_layout</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Model.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">predict_data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/model.html#Model.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Model.predict" title="Permalink to this definition"></a></dt>
<dd><p>Generate output predictions for the input samples.</p>
<p>Data could be a single tensor, a list of tensor, or a tuple of tensor.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Batch data should be put together in one tensor.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>predict_data</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The predict data, can be bool, int, float, str, None, tensor,
or tuple, list and dict that store these types.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, array(s) of predictions.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">Net</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Model.predict_network">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">predict_network</span></span><a class="headerlink" href="#mindspore.Model.predict_network" title="Permalink to this definition"></a></dt>
<dd><p>Get the model’s predict_network.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Model.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_sink_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sink_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/model.html#Model.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Model.train" title="Permalink to this definition"></a></dt>
<dd><p>Training API where the iteration is controlled by python front-end.</p>
<p>When setting pynative mode or CPU, the training process will be performed with dataset not sink.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If dataset_sink_mode is True, data will be sent to device. If device is Ascend, features
of data will be transferred one by one. The limitation of data transmission per time is 256M.
If sink_size &gt; 0, each epoch the dataset can be traversed unlimited times until you get sink_size
elements of the dataset. Next epoch continues to traverse from the end position of the previous traversal.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Generally, total number of iterations on the data per epoch.
When dataset_sink_mode is set to true and sink_size&gt;0, each epoch sink sink_size
steps on the data instead of total number of iterations.</p></li>
<li><p><strong>train_dataset</strong> (<em>Dataset</em>) – A training dataset iterator. If there is no
loss_fn, a tuple with multiple data (data1, data2, data3, …) should be
returned and passed to the network. Otherwise, a tuple (data, label) should
be returned. The data and label would be passed to the network and loss
function respectively.</p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference internal" href="mindspore.train.html#mindspore.train.callback.Callback" title="mindspore.train.callback.Callback"><em>Callback</em></a><em>]</em><em>, </em><a class="reference internal" href="mindspore.train.html#mindspore.train.callback.Callback" title="mindspore.train.callback.Callback"><em>Callback</em></a><em>]</em>) – List of callback objects or callback object,
which should be executed while training.
Default: None.</p></li>
<li><p><strong>dataset_sink_mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Determines whether to pass the data through dataset channel. Default: True.
Configure pynative mode or CPU, the training process will be performed with
dataset not sink. Default: True.</p></li>
<li><p><strong>sink_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Control the amount of data in each sink.
If sink_size = -1, sink the complete dataset for each epoch.
If sink_size &gt; 0, sink sink_size data for each epoch.
If dataset_sink_mode is False, set sink_size as invalid.
Default: -1.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.loss_scale_manager</span> <span class="kn">import</span> <span class="n">FixedLossScaleManager</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># For details about how to build the dataset, please refer to the tutorial</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># document on the official website.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Model.train_network">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">train_network</span></span><a class="headerlink" href="#mindspore.Model.train_network" title="Permalink to this definition"></a></dt>
<dd><p>Get the model’s train_network.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.Parameter">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">Parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">default_input</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#Parameter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Parameter" title="Permalink to this definition"></a></dt>
<dd><p>Parameter types of cell models.</p>
<p>After initialized <cite>Parameter</cite> is a subtype of <cite>Tensor</cite>.</p>
<p>In auto_parallel mode of  “semi_auto_parallel” and “auto_parallel”, if init <cite>Parameter</cite> by
an <cite>Tensor</cite>, the type of Parameter will be <cite>Tensor</cite>. <cite>Tensor</cite>
will save the shape and type info of a tensor with no memory usage. The shape can be changed while
compiling for auto-parallel. Call <cite>init_data</cite> will return a Tensor Parameter with initialized data.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Each parameter of Cell is represented by Parameter class.
A Parameter has to belong to a Cell.
If there is an operator in the network that requires part of the inputs to be Parameter,
then the Parameters as this part of the inputs are not allowed to be cast.
It is recommended to use the default value of <cite>name</cite> when initialize a parameter as one attribute of a cell,
otherwise, the parameter name may be different than expected.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>default_input</strong> (<em>Union</em><em>[</em><a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>]</em>) – Parameter data, to be set initialized.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Name of the child parameter. Default: None.</p></li>
<li><p><strong>requires_grad</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – True if the parameter requires gradient. Default: True.</p></li>
<li><p><strong>layerwise_parallel</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – When layerwise_parallel is true in data parallel mode,
broadcast and gradients communication would not be applied to parameters. Default: False.</p></li>
<li><p><strong>parallel_optimizer</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – It is used to filter the weight shard operation in semi auto or auto parallel
mode. It works only when enable parallel optimizer in <cite>mindspore.context.set_auto_parallel_context()</cite>.
Default: True.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.common</span> <span class="kn">import</span> <span class="n">initializer</span> <span class="k">as</span> <span class="n">init</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Cell</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">matmul</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">MatMul</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="go">[[2.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="go">[[0.]]</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.cache_enable">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cache_enable</span></span><a class="headerlink" href="#mindspore.Parameter.cache_enable" title="Permalink to this definition"></a></dt>
<dd><p>Return whether the parameter is cache enable.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.cache_shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cache_shape</span></span><a class="headerlink" href="#mindspore.Parameter.cache_shape" title="Permalink to this definition"></a></dt>
<dd><p>Return the cache shape corresponding to the parameter if use cache.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Parameter.clone">
<span class="sig-name descname"><span class="pre">clone</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'same'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#Parameter.clone"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Parameter.clone" title="Permalink to this definition"></a></dt>
<dd><p>Clone the parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>init</strong> (<em>Union</em><em>[</em><a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/numbers.html#numbers.Number" title="(in Python v3.8)"><em>numbers.Number</em></a><em>]</em>) – Initialize the shape of the parameter.
Default: ‘same’.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Parameter, a new parameter.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.comm_fusion">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">comm_fusion</span></span><a class="headerlink" href="#mindspore.Parameter.comm_fusion" title="Permalink to this definition"></a></dt>
<dd><p>Get the fusion type for communication operators corresponding to this parameter.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Parameter.init_data">
<span class="sig-name descname"><span class="pre">init_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">set_sliced</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#Parameter.init_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Parameter.init_data" title="Permalink to this definition"></a></dt>
<dd><p>Initialize the parameter data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layout</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>)</em><em>]</em>) – <p>Parameter slice
layout [dev_mat, tensor_map, slice_shape]. Default: None.</p>
<ul>
<li><p>dev_mat (list(int)): Device matrix.</p></li>
<li><p>tensor_map (list(int)): Tensor map.</p></li>
<li><p>slice_shape (list(int)): Shape of slice.</p></li>
</ul>
</p></li>
<li><p><strong>set_sliced</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – True if the parameter is set sliced after initializing the data.
Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – If it is from Initializer, and parallel mode has changed after the Initializer created.</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Parameter, the <cite>Parameter</cite> after initializing data. If current <cite>Parameter</cite> was already initialized before,
returns the same initialized <cite>Parameter</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.inited_param">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">inited_param</span></span><a class="headerlink" href="#mindspore.Parameter.inited_param" title="Permalink to this definition"></a></dt>
<dd><p>Get the new parameter after call the init_data.</p>
<p>Default is a None, If <cite>self</cite> is a Parameter with out data, after call the
<cite>init_data</cite> the initialized Parameter with data will be recorded here.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.is_init">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_init</span></span><a class="headerlink" href="#mindspore.Parameter.is_init" title="Permalink to this definition"></a></dt>
<dd><p>Get the initialization status of the parameter.</p>
<p>In GE backend, the Parameter need a “init graph” to sync the data from host to device.
This flag indicates whether the data as been sync to the device.</p>
<p>This flag only work in GE, and it will be set to False in other backend.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.name">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#mindspore.Parameter.name" title="Permalink to this definition"></a></dt>
<dd><p>Get the name of the parameter.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.parallel_optimizer">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">parallel_optimizer</span></span><a class="headerlink" href="#mindspore.Parameter.parallel_optimizer" title="Permalink to this definition"></a></dt>
<dd><p>Return whether the parameter requires weight shard for parallel optimizer.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.requires_grad">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">requires_grad</span></span><a class="headerlink" href="#mindspore.Parameter.requires_grad" title="Permalink to this definition"></a></dt>
<dd><p>Return whether the parameter requires gradient.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Parameter.set_data">
<span class="sig-name descname"><span class="pre">set_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">slice_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#Parameter.set_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Parameter.set_data" title="Permalink to this definition"></a></dt>
<dd><p>Set <cite>set_data</cite> of current <cite>Parameter</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>Union</em><em>[</em><a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – new data.</p></li>
<li><p><strong>slice_shape</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If slice the parameter is set to true, the shape is not checked for consistency.
Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Parameter, the parameter after set data.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Parameter.set_param_ps">
<span class="sig-name descname"><span class="pre">set_param_ps</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">init_in_server</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#Parameter.set_param_ps"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Parameter.set_param_ps" title="Permalink to this definition"></a></dt>
<dd><p>Set whether the trainable parameter is updated by parameter server and whether the
trainable parameter is initialized on server.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It only works when a running task is in the parameter server mode.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>init_in_server</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether trainable parameter updated by parameter server is
initialized on server. Default: False.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.sliced">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sliced</span></span><a class="headerlink" href="#mindspore.Parameter.sliced" title="Permalink to this definition"></a></dt>
<dd><p>Get slice status of the parameter.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.unique">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">unique</span></span><a class="headerlink" href="#mindspore.Parameter.unique" title="Permalink to this definition"></a></dt>
<dd><p>whether the parameter is already unique or not.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ParameterTuple">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">ParameterTuple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">iterable</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#ParameterTuple"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ParameterTuple" title="Permalink to this definition"></a></dt>
<dd><p>Class for storing tuple of parameters.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is used to store the parameters of the network into the parameter tuple collection.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.ParameterTuple.clone">
<span class="sig-name descname"><span class="pre">clone</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'same'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#ParameterTuple.clone"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ParameterTuple.clone" title="Permalink to this definition"></a></dt>
<dd><p>Clone the parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Namespace of parameter.</p></li>
<li><p><strong>init</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Initialize the shape of the parameter. Default: ‘same’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple, the new Parameter tuple.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.RowTensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">RowTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dense_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#RowTensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.RowTensor" title="Permalink to this definition"></a></dt>
<dd><p>A sparse representation of a set of tensor slices at given indices.</p>
<p>An RowTensor is typically used to represent a subset of a larger
tensor dense of shape [L0, D1, .. , DN] where L0 &gt;&gt; D0.</p>
<p>The values in indices are the indices in the first dimension of the slices
that have been extracted from the larger tensor.</p>
<p>The dense tensor dense represented by an RowTensor slices has
<cite>dense[slices.indices[i], :, :, :, …] = slices.values[i, :, :, :, …]</cite>.</p>
<p>RowTensor can only be used in the <cite>Cell</cite>’s construct method.</p>
<p>It is not supported in pynative mode at the moment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A 1-D integer Tensor of shape [D0].</p></li>
<li><p><strong>values</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A Tensor of any dtype of shape [D0, D1, …, Dn].</p></li>
<li><p><strong>dense_shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em>) – An integer tuple which contains the shape
of the corresponding dense tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>RowTensor, composed of <cite>indices</cite>, <cite>values</cite>, and <cite>dense_shape</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dense_shape</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">dense_shape</span> <span class="o">=</span> <span class="n">dense_shape</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="n">RowTensor</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dense_shape</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">values</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">Net</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="go">[[1. 2.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="go">[0]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="go">(3, 2)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.SparseTensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">SparseTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dense_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#SparseTensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.SparseTensor" title="Permalink to this definition"></a></dt>
<dd><p>A sparse representation of a set of nonzero elememts from a tensor at given indices.</p>
<p>SparseTensor can only be used in the <cite>Cell</cite>’s construct method.</p>
<p>Pynative mode not supported at the moment.</p>
<p>For a tensor dense, its SparseTensor(indices, values, dense_shape) has
<cite>dense[indices[i]] = values[i]</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A 2-D integer Tensor of shape <cite>[N, ndims]</cite>,
where N and ndims are the number of <cite>values</cite> and number of dimensions in
the SparseTensor, respectively.</p></li>
<li><p><strong>values</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A 1-D tensor of any type and shape <cite>[N]</cite>, which
supplies the values for each element in <cite>indices</cite>.</p></li>
<li><p><strong>dense_shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em>) – A integer tuple of size <cite>ndims</cite>,
which specifies the dense_shape of the sparse tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>SparseTensor, composed of <cite>indices</cite>, <cite>values</cite>, and <cite>dense_shape</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dense_shape</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">dense_shape</span> <span class="o">=</span> <span class="n">dense_shape</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dense_shape</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">values</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">Net</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="go">[1. 2.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="go">[[0 1]</span>
<span class="go"> [1 2]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="go">(3, 4)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.Tensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">Tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor" title="Permalink to this definition"></a></dt>
<dd><p>Tensor is used for data storage.</p>
<p>Tensor inherits tensor object in C++.
Some functions are implemented in C++ and some functions are implemented in Python.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_data</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Input data of the tensor.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – Input data should be None, bool or numeric type defined in <cite>mindspore.dtype</cite>.
The argument is used to define the data type of the output tensor. If it is None, the data type of the
output tensor will be as same as the <cite>input_data</cite>. Default: None.</p></li>
<li><p><strong>shape</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – A list of integers, a tuple of integers or an integer as the shape of
output. If <cite>input_data</cite> is available, <cite>shape</cite> doesn’t need to be set. Default: None.</p></li>
<li><p><strong>init</strong> (<a class="reference internal" href="mindspore.common.initializer.html#mindspore.common.initializer.Initializer" title="mindspore.common.initializer.Initializer"><em>Initializer</em></a>) – the information of init data.
‘init’ is used for delayed initialization in parallel mode. Usually, it is not recommended to
use ‘init’ interface to initialize parameters in other conditions. If ‘init’ interface is used
to initialize parameters, the <cite>init_data</cite> API need to be called to convert <cite>Tensor</cite> to the actual data.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Outputs:</dt><dd><p>Tensor, with the same shape as <cite>input_data</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.common.tensor</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">One</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize a tensor with input data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t1</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">t1</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">t1</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize a tensor with a float scalar</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t2</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">t2</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">t2</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">ms</span><span class="o">.</span><span class="n">float64</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize a tensor with init</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t3</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="n">One</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">t3</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">t3</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">t3</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Tensor.T">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">T</span></span><a class="headerlink" href="#mindspore.Tensor.T" title="Permalink to this definition"></a></dt>
<dd><p>Return the transposed tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.abs">
<span class="sig-name descname"><span class="pre">abs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.abs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.abs" title="Permalink to this definition"></a></dt>
<dd><p>Return absolute value element-wisely.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Tensor, has the same data type as x.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.all">
<span class="sig-name descname"><span class="pre">all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.all"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.all" title="Permalink to this definition"></a></dt>
<dd><p>Check all array elements along a given axis evaluate to True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em>) – Dimensions of reduction,
when axis is None or empty tuple, reduce all dimensions. Default: ().</p></li>
<li><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to keep the reduced dimensions. Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same data type as x.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.any">
<span class="sig-name descname"><span class="pre">any</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.any"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.any" title="Permalink to this definition"></a></dt>
<dd><p>Check any array element along a given axis evaluate to True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em>) – Dimensions of reduction,
when axis is None or empty tuple, reduce all dimensions. Default: ().</p></li>
<li><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to keep the reduced dimensions. Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same data type as x.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.asnumpy">
<span class="sig-name descname"><span class="pre">asnumpy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.asnumpy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.asnumpy" title="Permalink to this definition"></a></dt>
<dd><p>Convert tensor to numpy array.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.astype">
<span class="sig-name descname"><span class="pre">astype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.astype"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.astype" title="Permalink to this definition"></a></dt>
<dd><p>Return a copy of the tensor, casted to a specified type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dtype</strong> (Union[<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>, str]) – Designated tensor dtype, can be in format
of <code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype.float32</span></code> or <cite>float32</cite>.
Default: <code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype.float32</span></code>.</p></li>
<li><p><strong>copy</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – By default, astype always returns a newly allocated
tensor. If this is set to false, the input tensor is returned instead
of a copy if possible. Default: True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, with the designated dtype.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Tensor.dtype">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><a class="headerlink" href="#mindspore.Tensor.dtype" title="Permalink to this definition"></a></dt>
<dd><p>Return the dtype of the tensor (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.expand_as">
<span class="sig-name descname"><span class="pre">expand_as</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.expand_as"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.expand_as" title="Permalink to this definition"></a></dt>
<dd><p>Expand the dimension of target tensor to the dimension of input tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The input tensor. The shape of input tensor must obey
the broadcasting rule.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same dimension as input tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.flatten">
<span class="sig-name descname"><span class="pre">flatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'C'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.flatten"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.flatten" title="Permalink to this definition"></a></dt>
<dd><p>Return a copy of the tensor collapsed into one dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>order</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – Can choose between ‘C’ and ‘F’. ‘C’ means to
flatten in row-major (C-style) order. ‘F’ means to flatten in column-major
(Fortran-style) order. Only ‘C’ and ‘F’ are supported. Default: ‘C’.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same data type as input.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.flush_from_cache">
<span class="sig-name descname"><span class="pre">flush_from_cache</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.flush_from_cache"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.flush_from_cache" title="Permalink to this definition"></a></dt>
<dd><p>Flush cache data to host if tensor is cache enable.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.from_numpy">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_numpy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">array</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.from_numpy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.from_numpy" title="Permalink to this definition"></a></dt>
<dd><p>Convert numpy array to Tensor without copy data.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Tensor.has_init">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">has_init</span></span><a class="headerlink" href="#mindspore.Tensor.has_init" title="Permalink to this definition"></a></dt>
<dd><p>tensor is inited.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.init_data">
<span class="sig-name descname"><span class="pre">init_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">slice_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt_shard_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.init_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.init_data" title="Permalink to this definition"></a></dt>
<dd><p>Get the tensor format data of this Tensor.
The init_data function can be called once for the same tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>slice_index</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Slice index of a parameter’s slices.
It is used when initialize a slice of a parameter, it guarantees that devices
using the same slice can generate the same tensor.</p></li>
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em>) – Shape of the slice, it is used when initialize a slice of the parameter.</p></li>
<li><p><strong>opt_shard_group</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Optimizer shard group which is used in auto or semi auto parallel mode
to get one shard of a parameter’s slice.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Tensor.itemsize">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">itemsize</span></span><a class="headerlink" href="#mindspore.Tensor.itemsize" title="Permalink to this definition"></a></dt>
<dd><p>Return the length of one tensor element in bytes.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.mean">
<span class="sig-name descname"><span class="pre">mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.mean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.mean" title="Permalink to this definition"></a></dt>
<dd><p>Reduce a dimension of a tensor by averaging all elements in the dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>]</em>) – Dimensions of reduction,
when axis is None or empty tuple, reduce all dimensions. Default: ().</p></li>
<li><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to keep the reduced dimensions. Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same data type as x.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Tensor.nbytes">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">nbytes</span></span><a class="headerlink" href="#mindspore.Tensor.nbytes" title="Permalink to this definition"></a></dt>
<dd><p>Return the total number of bytes taken by the tensor.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Tensor.ndim">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ndim</span></span><a class="headerlink" href="#mindspore.Tensor.ndim" title="Permalink to this definition"></a></dt>
<dd><p>Return the number of tensor dimensions.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.ravel">
<span class="sig-name descname"><span class="pre">ravel</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.ravel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.ravel" title="Permalink to this definition"></a></dt>
<dd><p>Return a contiguous flattened tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Tensor, a 1-D tensor, containing the same elements of the input.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.reshape">
<span class="sig-name descname"><span class="pre">reshape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.reshape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.reshape" title="Permalink to this definition"></a></dt>
<dd><p>Give a new shape to a tensor without changing its data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shape</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>]</em>) – The new shape should be compatible
with the original shape. If an integer, then the result will be a 1-D
array of that length. One shape dimension can be -1. In this case, the
value is inferred from the length of the array and remaining dimensions.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, with new specified shape.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Tensor.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#mindspore.Tensor.shape" title="Permalink to this definition"></a></dt>
<dd><p>Returns the shape of the tensor as a tuple.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Tensor.size">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">size</span></span><a class="headerlink" href="#mindspore.Tensor.size" title="Permalink to this definition"></a></dt>
<dd><p>Returns the total number of elements in tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.squeeze">
<span class="sig-name descname"><span class="pre">squeeze</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.squeeze"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.squeeze" title="Permalink to this definition"></a></dt>
<dd><p>Remove single-dimensional entries from the shape of a tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>]</em><em>, </em><em>optional</em>) – Default is None.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, with all or a subset of the dimensions of length 1 removed.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Tensor.strides">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">strides</span></span><a class="headerlink" href="#mindspore.Tensor.strides" title="Permalink to this definition"></a></dt>
<dd><p>Return the tuple of bytes to step in each dimension when traversing a tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.swapaxes">
<span class="sig-name descname"><span class="pre">swapaxes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.swapaxes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.swapaxes" title="Permalink to this definition"></a></dt>
<dd><p>Interchange two axes of a tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis1</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – First axis.</p></li>
<li><p><strong>axis2</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Second axis.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Transposed tensor, has the same data type as the input.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.to_tensor">
<span class="sig-name descname"><span class="pre">to_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">slice_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt_shard_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.to_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.to_tensor" title="Permalink to this definition"></a></dt>
<dd><p>Return init_data().</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.transpose">
<span class="sig-name descname"><span class="pre">transpose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">axes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.transpose"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.transpose" title="Permalink to this definition"></a></dt>
<dd><p>Return a view of the tensor with axes transposed.</p>
<p>For a 1-D tensor this has no effect, as a transposed vector is simply the
same vector. For a 2-D tensor, this is a standard matrix transpose. For a
n-D tensor, if axes are given, their order indicates how the axes are permuted.
If axes are not provided and tensor.shape = (i[0], i[1],…i[n-2], i[n-1]),
then tensor.transpose().shape = (i[n-1], i[n-2], … i[1], i[0]).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axes</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – If axes is None or
blank, tensor.transpose() will reverse the order of the axes. If axes is tuple(int)
or list(int), tensor.transpose() will transpose the tensor to the new axes order.
If axes is int, this form is simply intended as a convenience alternative to the
tuple/list form.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same dimension as input tensor, with axes suitably permuted.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.view">
<span class="sig-name descname"><span class="pre">view</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.view"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.view" title="Permalink to this definition"></a></dt>
<dd><p>Reshape the tensor according to the input shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shape</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – Dimension of the output tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same dimension as the input shape.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Tensor.virtual_flag">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">virtual_flag</span></span><a class="headerlink" href="#mindspore.Tensor.virtual_flag" title="Permalink to this definition"></a></dt>
<dd><p>Mark tensor is virtual.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.build_searched_strategy">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">build_searched_strategy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">strategy_filename</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#build_searched_strategy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.build_searched_strategy" title="Permalink to this definition"></a></dt>
<dd><p>Build strategy of every parameter in network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>strategy_filename</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Name of strategy file.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dictionary, whose key is parameter name and value is slice strategy of this parameter.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Strategy file is incorrect.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – Strategy_filename is not str.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.build_train_network">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">build_train_network</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'O0'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/amp.html#build_train_network"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.build_train_network" title="Permalink to this definition"></a></dt>
<dd><p>Build the mixed precision training cell automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Definition of the network.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><em>Cell</em><em>]</em>) – Definition of the loss_fn. If None, the <cite>network</cite> should have the loss inside.
Default: None.</p></li>
<li><p><strong>optimizer</strong> (<em>Optimizer</em>) – Optimizer to update the Parameter.</p></li>
<li><p><strong>level</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>Supports [“O0”, “O2”, “O3”, “auto”]. Default: “O0”.</p>
<ul>
<li><p>O0: Do not change.</p></li>
<li><p>O2: Cast network to float16, keep batchnorm and <cite>loss_fn</cite> (if set) run in float32,
using dynamic loss scale.</p></li>
<li><p>O3: Cast network to float16, with additional property ‘keep_batchnorm_fp32=False’.</p></li>
<li><p>auto: Set to level to recommended level in different devices. Set level to O2 on GPU, Set
level to O3 Ascend. The recommended level is choose by the export experience, cannot
always generalize. User should specify the level for special network.</p></li>
</ul>
<p>O2 is recommended on GPU, O3 is recommended on Ascend.</p>
</p></li>
<li><p><strong>cast_model_type</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – Supports <cite>mstype.float16</cite> or <cite>mstype.float32</cite>.
If set to <cite>mstype.float16</cite>, use <cite>float16</cite> mode to train. If set, overwrite the level setting.</p></li>
<li><p><strong>keep_batchnorm_fp32</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Keep Batchnorm run in <cite>float32</cite>. If set, overwrite the level setting.
Only <cite>cast_model_type</cite> is <cite>float16</cite>, <cite>keep_batchnorm_fp32</cite> will take effect.</p></li>
<li><p><strong>loss_scale_manager</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference internal" href="#mindspore.LossScaleManager" title="mindspore.LossScaleManager"><em>LossScaleManager</em></a><em>]</em>) – If None, not scale the loss, or else
scale the loss by <cite>LossScaleManager</cite>. If set, overwrite the level setting.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.connect_network_with_dataset">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">connect_network_with_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_helper</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#connect_network_with_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.connect_network_with_dataset" title="Permalink to this definition"></a></dt>
<dd><p>Connect the <cite>network</cite> with dataset in <cite>dataset_helper</cite>.</p>
<p>This function wraps the input network with ‘GetNext’ so that the data can be fetched automatically from the
data channel corresponding to the ‘queue_name’ and passed to the input network during forward computation.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In the case of running the network on Ascend/GPU in graph mode, this function will wrap the input network with
‘GetNext’, in other cases, the input network will be returned with no change.
The ‘GetNext’ is required to get data only in sink mode, so this function is not applicable to no-sink mode.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – The training network for dataset.</p></li>
<li><p><strong>dataset_helper</strong> (<a class="reference internal" href="#mindspore.DatasetHelper" title="mindspore.DatasetHelper"><em>DatasetHelper</em></a>) – A class to process the MindData dataset, it provides the type, shape and queue
name of the dataset to wrap the <cite>GetNext</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Cell, a new network wrapped with ‘GetNext’ in the case of running the task on Ascend in graph mode, otherwise
it is the input network.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">DatasetHelper</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># call create_dataset function to create a regular dataset, refer to mindspore.dataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset_helper</span> <span class="o">=</span> <span class="n">DatasetHelper</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_with_get_next</span> <span class="o">=</span> <span class="n">connect_network_with_dataset</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">dataset_helper</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.dtype_to_nptype">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">dtype_to_nptype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">type_</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/dtype.html#dtype_to_nptype"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dtype_to_nptype" title="Permalink to this definition"></a></dt>
<dd><p>Convert MindSpore dtype to numpy data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>type</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – MindSpore’s dtype.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The data type of numpy.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.dtype_to_pytype">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">dtype_to_pytype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">type_</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/dtype.html#dtype_to_pytype"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dtype_to_pytype" title="Permalink to this definition"></a></dt>
<dd><p>Convert MindSpore dtype to python data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>type</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – MindSpore’s dtype.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Type of python.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.export">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">export</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">net</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'AIR'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#export"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.export" title="Permalink to this definition"></a></dt>
<dd><p>Export the MindSpore prediction model to a file in the specified format.</p>
<p class="rubric">Notes</p>
<p>When exporting to AIR format, the size of a single tensor can not exceed 2GB.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net</strong> (<em>Cell</em>) – MindSpore network.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – Inputs of the <cite>net</cite>.</p></li>
<li><p><strong>file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – File name of the model to be exported.</p></li>
<li><p><strong>file_format</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>MindSpore currently supports ‘AIR’, ‘ONNX’ and ‘MINDIR’ format for exported model.</p>
<ul>
<li><p>AIR: Ascend Intermediate Representation. An intermediate representation format of Ascend model.
Recommended suffix for output file is ‘.air’.</p></li>
<li><p>ONNX: Open Neural Network eXchange. An open format built to represent machine learning models.
Recommended suffix for output file is ‘.onnx’.</p></li>
<li><p>MINDIR: MindSpore Native Intermediate Representation for Anf. An intermediate representation format
for MindSpore models.
Recommended suffix for output file is ‘.mindir’.</p></li>
</ul>
</p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – <p>Configuration options dictionary.</p>
<ul>
<li><p>quant_mode: The mode of quant.</p></li>
<li><p>mean: Input data mean. Default: 127.5.</p></li>
<li><p>std_dev: Input data variance. Default: 127.5.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.get_level">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">get_level</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/log.html#get_level"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.get_level" title="Permalink to this definition"></a></dt>
<dd><p>Get the logger level.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>str, the Log level includes 3(ERROR), 2(WARNING), 1(INFO), 0(DEBUG).</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">os</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;GLOG_v&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;0&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">log</span> <span class="k">as</span> <span class="n">logger</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logger</span><span class="o">.</span><span class="n">get_level</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.get_log_config">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">get_log_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/log.html#get_log_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.get_log_config" title="Permalink to this definition"></a></dt>
<dd><p>Get logger configurations.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dict, the dictionary of logger configurations.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">os</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;GLOG_v&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;1&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;GLOG_logtostderr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;0&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;GLOG_log_dir&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;/var/log&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;logger_maxBytes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;5242880&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;logger_backupCount&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;10&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">log</span> <span class="k">as</span> <span class="n">logger</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logger</span><span class="o">.</span><span class="n">get_log_config</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.get_py_obj_dtype">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">get_py_obj_dtype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/dtype.html#get_py_obj_dtype"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.get_py_obj_dtype" title="Permalink to this definition"></a></dt>
<dd><p>Get the MindSpore data type which corresponds to python type or variable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>obj</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#type" title="(in Python v3.8)"><em>type</em></a>) – An object of python type, or a variable in python type.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Type of MindSpore type.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.get_seed">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">get_seed</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/seed.html#get_seed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.get_seed" title="Permalink to this definition"></a></dt>
<dd><p>Get global random seed.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.issubclass_">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">issubclass_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">type_</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/dtype.html#issubclass_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.issubclass_" title="Permalink to this definition"></a></dt>
<dd><p>Determine whether <cite>type_</cite> is a subclass of <cite>dtype</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>type</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – Target MindSpore dtype.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – Compare MindSpore dtype.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>bool, True or False.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.load">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.load" title="Permalink to this definition"></a></dt>
<dd><p>Load MindIR.</p>
<p>The returned object can be executed by a <cite>GraphCell</cite>. However, there are some limitations to the current use
of <cite>GraphCell</cite>, see class <code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.nn.GraphCell</span></code> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – MindIR file name.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Object, a compiled graph that can executed by <cite>GraphCell</cite>.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – MindIR file is incorrect.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">export</span><span class="p">,</span> <span class="n">load</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">export</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">&quot;net&quot;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s2">&quot;MINDIR&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">graph</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">&quot;net.mindir&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GraphCell</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.load_checkpoint">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">load_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_file_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict_load</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#load_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.load_checkpoint" title="Permalink to this definition"></a></dt>
<dd><p>Loads checkpoint info from a specified file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Checkpoint file name.</p></li>
<li><p><strong>net</strong> (<em>Cell</em>) – Cell network. Default: None</p></li>
<li><p><strong>strict_load</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to strict load the parameter into net. If False, it will load parameter
in the param_dict into net with the same suffix. Default: False</p></li>
<li><p><strong>filter_prefix</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em><em>]</em>) – Parameters starting with the filter_prefix
will not be loaded. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict, key is parameter name, value is a Parameter.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Checkpoint file is incorrect.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">load_checkpoint</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ckpt_file_name</span> <span class="o">=</span> <span class="s2">&quot;./checkpoint/LeNet5-1_32.ckpt&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">ckpt_file_name</span><span class="p">,</span> <span class="n">filter_prefix</span><span class="o">=</span><span class="s2">&quot;conv1&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.load_distributed_checkpoint">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">load_distributed_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">checkpoint_filenames</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_strategy_filename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#load_distributed_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.load_distributed_checkpoint" title="Permalink to this definition"></a></dt>
<dd><p>Load checkpoint into net for distributed predication.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Network for distributed predication.</p></li>
<li><p><strong>checkpoint_filenames</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em>) – The name of Checkpoint files in order of rank id.</p></li>
<li><p><strong>predict_strategy</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – Strategy of predication process, whose key is parameter name, and value is a list or
a tuple that the first four elements are [dev_matrix, tensor_map, param_split_shape, field]. If None,
it means that the predication process just uses single device. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – The type of inputs do not match the requirements.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Failed to load checkpoint into net.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.load_param_into_net">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">load_param_into_net</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">net</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameter_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict_load</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#load_param_into_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.load_param_into_net" title="Permalink to this definition"></a></dt>
<dd><p>Loads parameters into network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net</strong> (<em>Cell</em>) – Cell network.</p></li>
<li><p><strong>parameter_dict</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – Parameter dictionary.</p></li>
<li><p><strong>strict_load</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to strict load the parameter into net. If False, it will load parameter
in the param_dict into net with the same suffix. Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – Argument is not a Cell, or parameter_dict is not a Parameter dictionary.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ckpt_file_name</span> <span class="o">=</span> <span class="s2">&quot;./checkpoint/LeNet5-1_32.ckpt&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">ckpt_file_name</span><span class="p">,</span> <span class="n">filter_prefix</span><span class="o">=</span><span class="s2">&quot;conv1&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_not_load</span> <span class="o">=</span> <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">param_not_load</span><span class="p">)</span>
<span class="go">[&#39;conv1.weight&#39;]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.merge_sliced_parameter">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">merge_sliced_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sliced_parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#merge_sliced_parameter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.merge_sliced_parameter" title="Permalink to this definition"></a></dt>
<dd><p>Merge parameter slices to one whole parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sliced_parameters</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference internal" href="#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a><em>]</em>) – Parameter slices in order of rank_id.</p></li>
<li><p><strong>strategy</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a><em>]</em>) – Parameter slice strategy, whose key is parameter name and
value is slice strategy of this parameter. If strategy is None, just merge
parameter slices in 0 axis order. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Parameter, the merged parameter which has the whole data.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Failed to merge.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – The sliced_parameters is incorrect or strategy is not dict.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#KeyError" title="(in Python v3.8)"><strong>KeyError</strong></a> – The parameter name is not in keys of strategy.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.common.parameter</span> <span class="kn">import</span> <span class="n">Parameter</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">merge_sliced_parameter</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sliced_parameters</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>                     <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.00023915</span><span class="p">,</span> <span class="mf">0.00013939</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00098059</span><span class="p">])),</span>
<span class="gp">... </span>                               <span class="s2">&quot;network.embedding_table&quot;</span><span class="p">),</span>
<span class="gp">... </span>                     <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.00015815</span><span class="p">,</span> <span class="mf">0.00015458</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00012125</span><span class="p">])),</span>
<span class="gp">... </span>                               <span class="s2">&quot;network.embedding_table&quot;</span><span class="p">),</span>
<span class="gp">... </span>                     <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.00042165</span><span class="p">,</span> <span class="mf">0.00029692</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00007941</span><span class="p">])),</span>
<span class="gp">... </span>                               <span class="s2">&quot;network.embedding_table&quot;</span><span class="p">),</span>
<span class="gp">... </span>                     <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.00084451</span><span class="p">,</span> <span class="mf">0.00089960</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00010431</span><span class="p">])),</span>
<span class="gp">... </span>                               <span class="s2">&quot;network.embedding_table&quot;</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">merged_parameter</span> <span class="o">=</span> <span class="n">merge_sliced_parameter</span><span class="p">(</span><span class="n">sliced_parameters</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.ms_function">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">ms_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_signature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/api.html#ms_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ms_function" title="Permalink to this definition"></a></dt>
<dd><p>Create a callable MindSpore graph from a python function.</p>
<p>This allows the MindSpore runtime to apply optimizations based on graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fn</strong> (<em>Function</em>) – The Python function that will be run as a graph. Default: None.</p></li>
<li><p><strong>obj</strong> (<em>Object</em>) – The Python Object that provides the information for identifying the compiled function.Default:
None.</p></li>
<li><p><strong>input_signature</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The Tensor which describes the input arguments. The shape and dtype of the Tensor
will be supplied to this function. If input_signature is specified, each input to <cite>fn</cite> must be a <cite>Tensor</cite>.
And the input parameters of <cite>fn</cite> cannot accept <cite>**kwargs</cite>. The shape and dtype of actual inputs should
keep the same as input_signature. Otherwise, TypeError will be raised. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Function, if <cite>fn</cite> is not None, returns a callable function that will execute the compiled function; If <cite>fn</cite> is
None, returns a decorator and when this decorator invokes with a single <cite>fn</cite> argument, the callable function is
equal to the case when <cite>fn</cite> is not None.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># create a callable MindSpore graph by calling ms_function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">tensor_add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">z</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tensor_add_graph</span> <span class="o">=</span> <span class="n">ms_function</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">tensor_add</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">tensor_add_graph</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># create a callable MindSpore graph through decorator @ms_function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nd">@ms_function</span>
<span class="gp">... </span><span class="k">def</span> <span class="nf">tensor_add_with_dec</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">z</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">tensor_add_with_dec</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># create a callable MindSpore graph through decorator @ms_function with input_signature parameter</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nd">@ms_function</span><span class="p">(</span><span class="n">input_signature</span><span class="o">=</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)),</span>
<span class="gp">... </span>                              <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))))</span>
<span class="gp">... </span><span class="k">def</span> <span class="nf">tensor_add_with_sig</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">z</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">tensor_add_with_sig</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.parse_print">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">parse_print</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">print_file_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#parse_print"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.parse_print" title="Permalink to this definition"></a></dt>
<dd><p>Loads Print data from a specified file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>print_file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The file name of saved print data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List, element of list is Tensor.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – The print file may be empty, please make sure enter the correct file name.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.pytype_to_dtype">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">pytype_to_dtype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/dtype.html#pytype_to_dtype"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.pytype_to_dtype" title="Permalink to this definition"></a></dt>
<dd><p>Convert python type to MindSpore type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>obj</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#type" title="(in Python v3.8)"><em>type</em></a>) – A python type object.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Type of MindSpore type.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.save_checkpoint">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">save_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_obj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_file_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integrated_save</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">async_save</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#save_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.save_checkpoint" title="Permalink to this definition"></a></dt>
<dd><p>Saves checkpoint info to a specified file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_obj</strong> (<em>Union</em><em>[</em><em>Cell</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>]</em>) – The cell object or data list(each element is a dictionary, like
[{“name”: param_name, “data”: param_data},…], the type of
param_name would be string, and the type of param_data would
be parameter or <cite>Tensor</cite>).</p></li>
<li><p><strong>ckpt_file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Checkpoint file name. If the file name already exists, it will be overwritten.</p></li>
<li><p><strong>integrated_save</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to integrated save in automatic model parallel scene. Default: True</p></li>
<li><p><strong>async_save</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether asynchronous execution saves the checkpoint to a file. Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If the parameter save_obj is not <cite>nn.Cell</cite> or list type. And if the parameter
    <cite>integrated_save</cite> and <cite>async_save</cite> are not bool type.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.set_seed">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">set_seed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/seed.html#set_seed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.set_seed" title="Permalink to this definition"></a></dt>
<dd><p>Set global random seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The global seed is used by numpy.random, mindspore.common.Initializer, mindspore.ops.composite.random_ops and
mindspore.nn.probability.distribution.</p>
<p>If global seed is not set, these packages will use their own default seed independently, numpy.random and
mindspore.common.Initializer will choose a random seed, mindspore.ops.composite.random_ops and
mindspore.nn.probability.distribution will use zero.</p>
<p>Seed set by numpy.random.seed() only used by numpy.random, while seed set by this API will also used by
numpy.random, so just set all seed by this API is recommended.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The seed to be set.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If seed is invalid (&lt; 0).</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If seed isn’t a int.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">composite</span> <span class="k">as</span> <span class="n">C</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Note: (1) Please make sure the code is running in PYNATIVE MODE;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># (2) Because Composite-level ops need parameters to be Tensors, for below examples,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># when using C.uniform operator, minval and maxval are initialised as:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">minval</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">maxval</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 1. If global seed is not set, numpy.random and initializer will choose a random seed:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get different results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W4</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 2. If global seed is set, numpy.random and initializer will use it:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get the same results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W2</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 3. If neither global seed nor op seed is set, mindspore.ops.composite.random_ops and</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.nn.probability.distribution will choose a random seed:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get different results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C4</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 4. If global seed is set, but op seed is not set, mindspore.ops.composite.random_ops and</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.nn.probability.distribution will calculate a seed according to global seed and</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># default op seed. Each call will change the default op seed, thus each call get different</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># results.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get the same results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 5. If both global seed and op seed are set, mindspore.ops.composite.random_ops and</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.nn.probability.distribution will calculate a seed according to global seed and</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># op seed counter. Each call will change the op seed counter, thus each call get different</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># results.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get the same results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 6. If op seed is set but global seed is not set, 0 will be used as global seed. Then</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.ops.composite.random_ops and mindspore.nn.probability.distribution act as in</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># condition 5.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get the same results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 7. Recall set_seed() in the program will reset numpy seed and op seed counter of</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.ops.composite.random_ops and mindspore.nn.probability.distribution.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># still get A1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># still get C1</span>
</pre></div>
</div>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../index.html" class="btn btn-neutral float-left" title="MindSpore Python API" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mindspore.common.initializer.html" class="btn btn-neutral float-right" title="mindspore.common.initializer" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>