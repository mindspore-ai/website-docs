<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.dataset.text &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="mindspore.dataset.transforms" href="mindspore.dataset.transforms.html" />
    <link rel="prev" title="mindspore.dataset.config" href="mindspore.dataset.config.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">MindSpore Python API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindspore.dataset.text</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.dataset.text.transforms">mindspore.dataset.text.transforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.dataset.text.utils">mindspore.dataset.text.utils</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.dynamic_lr.html">mindspore.nn.dynamic_lr</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.profiler.html">mindspore.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.train.html">mindspore.train</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindArmour Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.html">mindarmour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.attacks.html">mindarmour.adv_robustness.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.defenses.html">mindarmour.adv_robustness.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.detectors.html">mindarmour.adv_robustness.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.evaluations.html">mindarmour.adv_robustness.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.fuzz_testing.html">mindarmour.fuzz_testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.privacy.diff_privacy.html">mindarmour.privacy.diff_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.privacy.evaluation.html">mindarmour.privacy.evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.utils.html">mindarmour.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindSpore Hub Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindspore_hub/mindspore_hub.html">mindspore_hub</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>mindspore.dataset.text</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/mindspore/mindspore.dataset.text.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mindspore-dataset-text">
<h1>mindspore.dataset.text<a class="headerlink" href="#mindspore-dataset-text" title="Permalink to this headline"></a></h1>
<section id="module-mindspore.dataset.text.transforms">
<span id="mindspore-dataset-text-transforms"></span><h2>mindspore.dataset.text.transforms<a class="headerlink" href="#module-mindspore.dataset.text.transforms" title="Permalink to this headline"></a></h2>
<p>The module text.transforms is inherited from _c_dataengine
and is implemented based on ICU4C and cppjieba in C++.
It’s a high performance module to process NLP text.
Users can use Vocab to build their own dictionary,
use appropriate tokenizers to split sentences into different tokens,
and use Lookup to find the index of tokens in Vocab.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A constructor’s arguments for every class in this module must be saved into the
class attributes (self.xxx) to support save() and load().</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.dataset.text</span> <span class="k">as</span> <span class="nn">text</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset_file</span> <span class="o">=</span> <span class="s2">&quot;path/to/text_file_path&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># sentences as line data saved in a file</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">TextFileDataset</span><span class="p">(</span><span class="n">dataset_file</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># tokenize sentence to unicode characters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">UnicodeCharTokenizer</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># load vocabulary form list</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vocab</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">Vocab</span><span class="o">.</span><span class="n">from_list</span><span class="p">([</span><span class="s1">&#39;深&#39;</span><span class="p">,</span> <span class="s1">&#39;圳&#39;</span><span class="p">,</span> <span class="s1">&#39;欢&#39;</span><span class="p">,</span> <span class="s1">&#39;迎&#39;</span><span class="p">,</span> <span class="s1">&#39;您&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># lookup is an operation for mapping tokens to ids</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lookup</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">Lookup</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="p">[</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">lookup</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># if text line in dataset_file is:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 深圳欢迎您</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># then the output will be:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># {&#39;text&#39;: array([0, 1, 2, 3, 4], dtype=int32)}</span>
</pre></div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.BasicTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">BasicTokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lower_case</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_whitespace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalization_form</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">NormalizeForm.NONE</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preserve_unused_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_offsets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#BasicTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.BasicTokenizer" title="Permalink to this definition"></a></dt>
<dd><p>Tokenize a scalar tensor of UTF-8 string by specific rules.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lower_case</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, apply CaseFold, NormalizeUTF8(NFD mode), RegexReplace operation
on input text to fold the text to lower case and strip accents characters. If False, only apply
NormalizeUTF8(‘normalization_form’ mode) operation on input text (default=False).</p></li>
<li><p><strong>keep_whitespace</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, the whitespace will be kept in out tokens (default=False).</p></li>
<li><p><strong>normalization_form</strong> (<em>NormalizeForm</em><em>, </em><em>optional</em>) – Used to specify a specific normalize mode. This is
only effective when ‘lower_case’ is False. See NormalizeUTF8 for details (default=NormalizeForm.NONE).</p></li>
<li><p><strong>preserve_unused_token</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, do not split special tokens like
‘[CLS]’, ‘[SEP]’, ‘[UNK]’, ‘[PAD]’, ‘[MASK]’ (default=True).</p></li>
<li><p><strong>with_offsets</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If or not output offsets of tokens (default=False).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># If with_offsets=False, default output one column {[&quot;text&quot;, dtype=str]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">BasicTokenizer</span><span class="p">(</span><span class="n">lower_case</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                  <span class="n">keep_whitespace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                  <span class="n">normalization_form</span><span class="o">=</span><span class="n">NormalizeForm</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                  <span class="n">preserve_unused_token</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                  <span class="n">with_offsets</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># If with_offsets=False, then output three columns {[&quot;token&quot;, dtype=str],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#                                                   [&quot;offsets_start&quot;, dtype=uint32],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#                                                   [&quot;offsets_limit&quot;, dtype=uint32]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">BasicTokenizer</span><span class="p">(</span><span class="n">lower_case</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                  <span class="n">keep_whitespace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                  <span class="n">normalization_form</span><span class="o">=</span><span class="n">NormalizeForm</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                  <span class="n">preserve_unused_token</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                  <span class="n">with_offsets</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">output_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_start&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_limit&quot;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">column_order</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_start&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_limit&quot;</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.BertTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">BertTokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vocab</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">suffix_indicator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'##'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_bytes_per_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unknown_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'[UNK]'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lower_case</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_whitespace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalization_form</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">NormalizeForm.NONE</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preserve_unused_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_offsets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#BertTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.BertTokenizer" title="Permalink to this definition"></a></dt>
<dd><p>Tokenizer used for Bert text process.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab</strong> (<a class="reference internal" href="#mindspore.dataset.text.utils.Vocab" title="mindspore.dataset.text.utils.Vocab"><em>Vocab</em></a>) – A vocabulary object.</p></li>
<li><p><strong>suffix_indicator</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – Used to show that the subword is the last part of a word (default=’##’).</p></li>
<li><p><strong>max_bytes_per_token</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Tokens exceeding this length will not be further split (default=100).</p></li>
<li><p><strong>unknown_token</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – When a token cannot be found: if ‘unknown_token’ is empty string,
return the token directly, else return ‘unknown_token’(default=’[UNK]’).</p></li>
<li><p><strong>lower_case</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, apply CaseFold, NormalizeUTF8(NFD mode), RegexReplace operation
on input text to fold the text to lower case and strip accented characters. If False, only apply
NormalizeUTF8(‘normalization_form’ mode) operation on input text (default=False).</p></li>
<li><p><strong>keep_whitespace</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, the whitespace will be kept in out tokens (default=False).</p></li>
<li><p><strong>normalization_form</strong> (<em>NormalizeForm</em><em>, </em><em>optional</em>) – Used to specify a specific normalize mode,
only effective when ‘lower_case’ is False. See NormalizeUTF8 for details (default=’NONE’).</p></li>
<li><p><strong>preserve_unused_token</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, do not split special tokens like
‘[CLS]’, ‘[SEP]’, ‘[UNK]’, ‘[PAD]’, ‘[MASK]’ (default=True).</p></li>
<li><p><strong>with_offsets</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If or not output offsets of tokens (default=False).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># If with_offsets=False, default output one column {[&quot;text&quot;, dtype=str]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">BertTokenizer</span><span class="p">(</span><span class="n">vocab</span><span class="o">=</span><span class="n">vocab</span><span class="p">,</span> <span class="n">suffix_indicator</span><span class="o">=</span><span class="s1">&#39;##&#39;</span><span class="p">,</span> <span class="n">max_bytes_per_token</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                 <span class="n">unknown_token</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lower_case</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">keep_whitespace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                 <span class="n">normalization_form</span><span class="o">=</span><span class="n">NormalizeForm</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span> <span class="n">preserve_unused_token</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                 <span class="n">with_offsets</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># If with_offsets=False, then output three columns {[&quot;token&quot;, dtype=str],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#                                                   [&quot;offsets_start&quot;, dtype=uint32],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#                                                   [&quot;offsets_limit&quot;, dtype=uint32]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">BertTokenizer</span><span class="p">(</span><span class="n">vocab</span><span class="o">=</span><span class="n">vocab</span><span class="p">,</span> <span class="n">suffix_indicator</span><span class="o">=</span><span class="s1">&#39;##&#39;</span><span class="p">,</span> <span class="n">max_bytes_per_token</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                 <span class="n">unknown_token</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lower_case</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">keep_whitespace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                 <span class="n">normalization_form</span><span class="o">=</span><span class="n">NormalizeForm</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span> <span class="n">preserve_unused_token</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                 <span class="n">with_offsets</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">output_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_start&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_limit&quot;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">column_order</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_start&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_limit&quot;</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.CaseFold">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">CaseFold</span></span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#CaseFold"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.CaseFold" title="Permalink to this definition"></a></dt>
<dd><p>Apply case fold operation on utf-8 string tensor.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.JiebaTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">JiebaTokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hmm_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mp_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">JiebaMode.MIX</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_offsets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#JiebaTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.JiebaTokenizer" title="Permalink to this definition"></a></dt>
<dd><p>Tokenize Chinese string into words based on dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hmm_path</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Dictionary file is used by HMMSegment algorithm.
The dictionary can be obtained on the official website of cppjieba.</p></li>
<li><p><strong>mp_path</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Dictionary file is used by MPSegment algorithm.
The dictionary can be obtained on the official website of cppjieba.</p></li>
<li><p><strong>mode</strong> (<em>JiebaMode</em><em>, </em><em>optional</em>) – <p>Valid values can be any of [JiebaMode.MP, JiebaMode.HMM,
JiebaMode.MIX](default=JiebaMode.MIX).</p>
<ul>
<li><p>JiebaMode.MP, tokenize with MPSegment algorithm.</p></li>
<li><p>JiebaMode.HMM, tokenize with Hiddel Markov Model Segment algorithm.</p></li>
<li><p>JiebaMode.MIX, tokenize with a mix of MPSegment and HMMSegment algorithm.</p></li>
</ul>
</p></li>
<li><p><strong>with_offsets</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If or not output offsets of tokens (default=False).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># If with_offsets=False, default output one column {[&quot;text&quot;, dtype=str]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">JiebaTokenizer</span><span class="p">(</span><span class="n">HMM_FILE</span><span class="p">,</span> <span class="n">MP_FILE</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">JiebaMode</span><span class="o">.</span><span class="n">MP</span><span class="p">,</span> <span class="n">with_offsets</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># If with_offsets=False, then output three columns {[&quot;token&quot;, dtype=str], [&quot;offsets_start&quot;, dtype=uint32],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#                                                   [&quot;offsets_limit&quot;, dtype=uint32]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">JiebaTokenizer</span><span class="p">(</span><span class="n">HMM_FILE</span><span class="p">,</span> <span class="n">MP_FILE</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">JiebaMode</span><span class="o">.</span><span class="n">MP</span><span class="p">,</span> <span class="n">with_offsets</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">output_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_start&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_limit&quot;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">column_order</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_start&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_limit&quot;</span><span class="p">])</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.JiebaTokenizer.add_dict">
<span class="sig-name descname"><span class="pre">add_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">user_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#JiebaTokenizer.add_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.JiebaTokenizer.add_dict" title="Permalink to this definition"></a></dt>
<dd><p>Add user defined word to JiebaTokenizer’s dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>user_dict</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a><em>]</em>) – <p>Dictionary to be added, file path or Python dictionary,
Python Dict format: {word1:freq1, word2:freq2,…}.
Jieba dictionary format : word(required), freq(optional), such as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">word1</span> <span class="n">freq1</span>
<span class="n">word2</span>
<span class="n">word3</span> <span class="n">freq3</span>
</pre></div>
</div>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.JiebaTokenizer.add_word">
<span class="sig-name descname"><span class="pre">add_word</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">word</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#JiebaTokenizer.add_word"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.JiebaTokenizer.add_word" title="Permalink to this definition"></a></dt>
<dd><p>Add user defined word to JiebaTokenizer’s dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>word</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The word to be added to the JiebaTokenizer instance.
The added word will not be written into the built-in dictionary on disk.</p></li>
<li><p><strong>freq</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The frequency of the word to be added. The higher the frequency,
the better chance the word will be tokenized (default=None, use default frequency).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.Lookup">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">Lookup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vocab</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unknown_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">mindspore.int32</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#Lookup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.Lookup" title="Permalink to this definition"></a></dt>
<dd><p>Lookup operator that looks up a word to an id.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab</strong> (<a class="reference internal" href="#mindspore.dataset.text.utils.Vocab" title="mindspore.dataset.text.utils.Vocab"><em>Vocab</em></a>) – A vocabulary object.</p></li>
<li><p><strong>unknown_token</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – Word used for lookup if the word being looked up is out-of-vocabulary (OOV).
If unknown_token is OOV, a runtime error will be thrown (default=None).</p></li>
<li><p><strong>data_type</strong> (<a class="reference internal" href="mindspore.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a><em>, </em><em>optional</em>) – mindspore.dtype that lookup maps string to (default=mstype.int32)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.Ngram">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">Ngram</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">left_pad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">('',</span> <span class="pre">0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">right_pad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">('',</span> <span class="pre">0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">separator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'</span> <span class="pre">'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#Ngram"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.Ngram" title="Permalink to this definition"></a></dt>
<dd><p>TensorOp to generate n-gram from a 1-D string Tensor.</p>
<p>Refer to <a class="reference external" href="https://en.wikipedia.org/wiki/N-gram#Examples">https://en.wikipedia.org/wiki/N-gram#Examples</a> for an overview of what n-gram is and how it works.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – n in n-gram, n &gt;= 1. n is a list of positive integers. For example, if n=[4,3], then the result
would be a 4-gram followed by a 3-gram in the same tensor. If the number of words is not enough to make up
for a n-gram, an empty string will be returned. For example, 3 grams on [“mindspore”,”best”] will result in
an empty string produced.</p></li>
<li><p><strong>left_pad</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><em>optional</em>) – (“pad_token”, pad_width). Padding performed on left side of the sequence. pad_width
will be capped at n-1. left_pad=(“_”,2) would pad left side of the sequence with “__” (default=None).</p></li>
<li><p><strong>right_pad</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><em>optional</em>) – (“pad_token”, pad_width). Padding performed on right side of the sequence.
pad_width will be capped at n-1. right_pad=(“-“:2) would pad right side of the sequence with “–”
(default=None).</p></li>
<li><p><strong>separator</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – symbol used to join strings together. For example. if 2-gram is
[“mindspore”, “amazing”] with separator=”-”, the result would be [“mindspore-amazing”]
(default=None, which means whitespace is used).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.NormalizeUTF8">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">NormalizeUTF8</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">normalize_form</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">NormalizeForm.NFKC</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#NormalizeUTF8"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.NormalizeUTF8" title="Permalink to this definition"></a></dt>
<dd><p>Apply normalize operation on utf-8 string tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>normalize_form</strong> (<em>NormalizeForm</em><em>, </em><em>optional</em>) – <p>Valid values can be any of [NormalizeForm.NONE,
NormalizeForm.NFC, NormalizeForm.NFKC, NormalizeForm.NFD,
NormalizeForm.NFKD](default=NormalizeForm.NFKC).
See <a class="reference external" href="http://unicode.org/reports/tr15/">http://unicode.org/reports/tr15/</a> for details.</p>
<ul class="simple">
<li><p>NormalizeForm.NONE, do nothing for input string tensor.</p></li>
<li><p>NormalizeForm.NFC, normalize with Normalization Form C.</p></li>
<li><p>NormalizeForm.NFKC, normalize with Normalization Form KC.</p></li>
<li><p>NormalizeForm.NFD, normalize with Normalization Form D.</p></li>
<li><p>NormalizeForm.NFKD, normalize with Normalization Form KD.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.PythonTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">PythonTokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tokenizer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#PythonTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.PythonTokenizer" title="Permalink to this definition"></a></dt>
<dd><p>Callable class to be used for user-defined string tokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tokenizer</strong> (<em>Callable</em>) – Python function that takes a <cite>str</cite> and returns a list of <cite>str</cite> as tokens.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">my_tokenizer</span><span class="p">(</span><span class="n">line</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">return</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">PythonTokenizer</span><span class="p">(</span><span class="n">my_tokenizer</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.RegexReplace">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">RegexReplace</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pattern</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replace</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replace_all</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#RegexReplace"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.RegexReplace" title="Permalink to this definition"></a></dt>
<dd><p>Replace utf-8 string tensor with ‘replace’ according to regular expression ‘pattern’.</p>
<p>See <a class="reference external" href="http://userguide.icu-project.org/strings/regexp">http://userguide.icu-project.org/strings/regexp</a> for support regex pattern.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pattern</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – the regex expression patterns.</p></li>
<li><p><strong>replace</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – the string to replace matched element.</p></li>
<li><p><strong>replace_all</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If False, only replace first matched element;
if True, replace all matched elements (default=True).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.RegexTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">RegexTokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">delim_pattern</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_delim_pattern</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_offsets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#RegexTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.RegexTokenizer" title="Permalink to this definition"></a></dt>
<dd><p>Tokenize a scalar tensor of UTF-8 string by regex expression pattern.</p>
<p>See <a class="reference external" href="http://userguide.icu-project.org/strings/regexp">http://userguide.icu-project.org/strings/regexp</a> for support regex pattern.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>delim_pattern</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The pattern of regex delimiters.
The original string will be split by matched elements.</p></li>
<li><p><strong>keep_delim_pattern</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – The string matched by ‘delim_pattern’ can be kept as a token
if it can be matched by ‘keep_delim_pattern’. The default value is an empty str (‘’)
which means that delimiters will not be kept as an output token (default=’’).</p></li>
<li><p><strong>with_offsets</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If or not output offsets of tokens (default=False).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># If with_offsets=False, default output one column {[&quot;text&quot;, dtype=str]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">RegexTokenizer</span><span class="p">(</span><span class="n">delim_pattern</span><span class="p">,</span> <span class="n">keep_delim_pattern</span><span class="p">,</span> <span class="n">with_offsets</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># If with_offsets=False, then output three columns {[&quot;token&quot;, dtype=str],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#                                                   [&quot;offsets_start&quot;, dtype=uint32],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#                                                   [&quot;offsets_limit&quot;, dtype=uint32]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">RegexTokenizer</span><span class="p">(</span><span class="n">delim_pattern</span><span class="p">,</span> <span class="n">keep_delim_pattern</span><span class="p">,</span> <span class="n">with_offsets</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">output_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_start&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_limit&quot;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">column_order</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_start&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_limit&quot;</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.SentencePieceTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">SentencePieceTokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_type</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#SentencePieceTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.SentencePieceTokenizer" title="Permalink to this definition"></a></dt>
<dd><p>Tokenize scalar token or 1-D tokens to tokens by sentencepiece.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mode</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference internal" href="#mindspore.dataset.text.utils.SentencePieceVocab" title="mindspore.dataset.text.utils.SentencePieceVocab"><em>SentencePieceVocab</em></a><em>]</em>) – If the input parameter is a file, then it is of type string.
If the input parameter is a SentencePieceVocab object, then it is of type SentencePieceVocab.</p></li>
<li><p><strong>out_type</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – The type of output.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.SlidingWindow">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">SlidingWindow</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#SlidingWindow"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.SlidingWindow" title="Permalink to this definition"></a></dt>
<dd><p>TensorOp to construct a tensor from data (only 1-D for now), where each element in the dimension axis
is a slice of data starting at the corresponding position, with a specified width.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>width</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The width of the window. It must be an integer and greater than zero.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The axis along which the sliding window is computed (default=0).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Data before</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># |    col1     |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +-------------+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | [1,2,3,4,5] |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +-------------+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">SlidingWindow</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Data after</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># |     col1    |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +-------------+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># |  [[1,2,3],  |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># |   [2,3,4],  |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># |   [3,4,5]]  |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +--------------+</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.ToNumber">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">ToNumber</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_type</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#ToNumber"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.ToNumber" title="Permalink to this definition"></a></dt>
<dd><p>Tensor operation to convert every element of a string tensor to a number.</p>
<p>Strings are casted according to the rules specified in the following links:
<a class="reference external" href="https://en.cppreference.com/w/cpp/string/basic_string/stof">https://en.cppreference.com/w/cpp/string/basic_string/stof</a>,
<a class="reference external" href="https://en.cppreference.com/w/cpp/string/basic_string/stoul">https://en.cppreference.com/w/cpp/string/basic_string/stoul</a>,
except that any strings which represent negative numbers cannot be cast to an
unsigned integer type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data_type</strong> (<a class="reference internal" href="mindspore.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a>) – mindspore.dtype to be casted to. Must be
a numeric type.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – If strings are invalid to cast, or are out of range after being casted.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.TruncateSequencePair">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">TruncateSequencePair</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_length</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#TruncateSequencePair"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.TruncateSequencePair" title="Permalink to this definition"></a></dt>
<dd><p>Truncate a pair of rank-1 tensors such that the total length is less than max_length.</p>
<p>This operation takes two input tensors and returns two output Tenors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>max_length</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Maximum length required.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Data before</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># |  col1   |  col2   |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---------+---------|</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | [1,2,3] | [4,5]   |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---------+---------+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">TruncateSequencePair</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Data after</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># |  col1   |  col2   |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---------+---------+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | [1,2]   | [4,5]   |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---------+---------+</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.UnicodeCharTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">UnicodeCharTokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">with_offsets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#UnicodeCharTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.UnicodeCharTokenizer" title="Permalink to this definition"></a></dt>
<dd><p>Tokenize a scalar tensor of UTF-8 string to Unicode characters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>with_offsets</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If or not output offsets of tokens (default=False).</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># If with_offsets=False, default output one column {[&quot;text&quot;, dtype=str]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">UnicodeCharTokenizer</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># If with_offsets=False, then output three columns {[&quot;token&quot;, dtype=str], [&quot;offsets_start&quot;, dtype=uint32],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#                                                   [&quot;offsets_limit&quot;, dtype=uint32]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">UnicodeCharTokenizer</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">output_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_start&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_limit&quot;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">column_order</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_start&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_limit&quot;</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.UnicodeScriptTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">UnicodeScriptTokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">keep_whitespace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_offsets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#UnicodeScriptTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.UnicodeScriptTokenizer" title="Permalink to this definition"></a></dt>
<dd><p>Tokenize a scalar tensor of UTF-8 string on Unicode script boundaries.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>keep_whitespace</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If or not emit whitespace tokens (default=False).</p></li>
<li><p><strong>with_offsets</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If or not output offsets of tokens (default=False).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># If with_offsets=False, default output one column {[&quot;text&quot;, dtype=str]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">UnicodeScriptTokenizerOp</span><span class="p">(</span><span class="n">keep_whitespace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_offsets</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># If with_offsets=False, then output three columns {[&quot;token&quot;, dtype=str],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#                                                   [&quot;offsets_start&quot;, dtype=uint32],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#                                                   [&quot;offsets_limit&quot;, dtype=uint32]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">UnicodeScriptTokenizerOp</span><span class="p">(</span><span class="n">keep_whitespace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_offsets</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">output_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_start&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_limit&quot;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">column_order</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_start&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_limit&quot;</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.WhitespaceTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">WhitespaceTokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">with_offsets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#WhitespaceTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.WhitespaceTokenizer" title="Permalink to this definition"></a></dt>
<dd><p>Tokenize a scalar tensor of UTF-8 string on ICU4C defined whitespaces, such as: ‘ ‘, ‘\t’, ‘\r’, ‘\n’.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>with_offsets</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If or not output offsets of tokens (default=False).</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># If with_offsets=False, default output one column {[&quot;text&quot;, dtype=str]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">WhitespaceTokenizer</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># If with_offsets=False, then output three columns {[&quot;token&quot;, dtype=str],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#                                                   [&quot;offsets_start&quot;, dtype=uint32],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#                                                   [&quot;offsets_limit&quot;, dtype=uint32]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">WhitespaceTokenizer</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">output_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_start&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_limit&quot;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">column_order</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_start&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_limit&quot;</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.transforms.WordpieceTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.transforms.</span></span><span class="sig-name descname"><span class="pre">WordpieceTokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vocab</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">suffix_indicator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'##'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_bytes_per_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unknown_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'[UNK]'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_offsets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/transforms.html#WordpieceTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.transforms.WordpieceTokenizer" title="Permalink to this definition"></a></dt>
<dd><p>Tokenize scalar token or 1-D tokens to 1-D subword tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab</strong> (<a class="reference internal" href="#mindspore.dataset.text.utils.Vocab" title="mindspore.dataset.text.utils.Vocab"><em>Vocab</em></a>) – A  vocabulary object.</p></li>
<li><p><strong>suffix_indicator</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – Used to show that the subword is the last part of a word (default=’##’).</p></li>
<li><p><strong>max_bytes_per_token</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Tokens exceeding this length will not be further split (default=100).</p></li>
<li><p><strong>unknown_token</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – When a token cannot be found: if ‘unknown_token’ is empty string,
return the token directly, else return ‘unknown_token’ (default=’[UNK]’).</p></li>
<li><p><strong>with_offsets</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If or not output offsets of tokens (default=False).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># If with_offsets=False, default output one column {[&quot;text&quot;, dtype=str]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">WordpieceTokenizer</span><span class="p">(</span><span class="n">vocab</span><span class="o">=</span><span class="n">vocab</span><span class="p">,</span> <span class="n">unknown_token</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;UNK&#39;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                                      <span class="n">max_bytes_per_token</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">with_offsets</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># If with_offsets=False, then output three columns {[&quot;token&quot;, dtype=str], [&quot;offsets_start&quot;, dtype=uint32],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#                                                   [&quot;offsets_limit&quot;, dtype=uint32]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">WordpieceTokenizer</span><span class="p">(</span><span class="n">vocab</span><span class="o">=</span><span class="n">vocab</span><span class="p">,</span> <span class="n">unknown_token</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;UNK&#39;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                                      <span class="n">max_bytes_per_token</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">with_offsets</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">output_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_start&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_limit&quot;</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                <span class="n">column_order</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_start&quot;</span><span class="p">,</span> <span class="s2">&quot;offsets_limit&quot;</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-mindspore.dataset.text.utils">
<span id="mindspore-dataset-text-utils"></span><h2>mindspore.dataset.text.utils<a class="headerlink" href="#module-mindspore.dataset.text.utils" title="Permalink to this headline"></a></h2>
<p>The module text.utils provides some general methods for NLP text processing.
For example, you can use Vocab to build a dictionary,
use to_bytes and to_str to encode and decode strings into a specified format.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.utils.SentencePieceVocab">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.utils.</span></span><span class="sig-name descname"><span class="pre">SentencePieceVocab</span></span><a class="reference internal" href="../_modules/mindspore/dataset/text/utils.html#SentencePieceVocab"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.utils.SentencePieceVocab" title="Permalink to this definition"></a></dt>
<dd><p>SentencePiece obiect that is used to segmentate words</p>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.dataset.text.utils.SentencePieceVocab.from_dataset">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_names</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">character_coverage</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/utils.html#SentencePieceVocab.from_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.utils.SentencePieceVocab.from_dataset" title="Permalink to this definition"></a></dt>
<dd><p>Build a sentencepiece from a dataset</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<em>Dataset</em>) – Dataset to build sentencepiece.</p></li>
<li><p><strong>col_names</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – The list of the col name.</p></li>
<li><p><strong>vocab_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Vocabulary size.</p></li>
<li><p><strong>character_coverage</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Amount of characters covered by the model, good defaults are: 0.9995 for
languages. with rich character set like Japanese or Chinese and 1.0 for other languages with small
character set.</p></li>
<li><p><strong>model_type</strong> (<em>SentencePieceModel</em>) – Choose from unigram (default), bpe, char, or word. The input sentence
must be pretokenized when using word type.</p></li>
<li><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – A dictionary with no incoming parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>SentencePiece, SentencePiece object from dataset.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.dataset.text.utils.SentencePieceVocab.from_file">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_file</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">character_coverage</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/utils.html#SentencePieceVocab.from_file"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.utils.SentencePieceVocab.from_file" title="Permalink to this definition"></a></dt>
<dd><p>Build a SentencePiece object from a list of word.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – Path to the file which contains the sentencepiece list.</p></li>
<li><p><strong>vocab_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Vocabulary size, the type of uint32_t.</p></li>
<li><p><strong>character_coverage</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Amount of characters covered by the model, good defaults are: 0.9995 for
languages. with rich character set like Japanse or Chinese and 1.0 for other languages with small
character set.</p></li>
<li><p><strong>model_type</strong> (<em>SentencePieceModel</em>) – Choose from unigram (default), bpe, char, or word. The input sentence
must be pretokenized when using word type.</p></li>
<li><p><strong>params</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – <p>A dictionary with no incoming parameters(The parameters are derived from SentencePiece
library).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">input_sentence_size</span> <span class="mi">0</span>
<span class="n">max_sentencepiece_length</span> <span class="mi">16</span>
</pre></div>
</div>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.dataset.text.utils.SentencePieceVocab.save_model">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vocab</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/utils.html#SentencePieceVocab.save_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.utils.SentencePieceVocab.save_model" title="Permalink to this definition"></a></dt>
<dd><p>Save model to filepath</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab</strong> (<a class="reference internal" href="#mindspore.dataset.text.utils.SentencePieceVocab" title="mindspore.dataset.text.utils.SentencePieceVocab"><em>SentencePieceVocab</em></a>) – A sentencepiece object.</p></li>
<li><p><strong>path</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Path to store model.</p></li>
<li><p><strong>filename</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The name of the file.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dataset.text.utils.Vocab">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.utils.</span></span><span class="sig-name descname"><span class="pre">Vocab</span></span><a class="reference internal" href="../_modules/mindspore/dataset/text/utils.html#Vocab"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.utils.Vocab" title="Permalink to this definition"></a></dt>
<dd><p>Vocab object that is used to lookup a word.</p>
<p>It contains a map that maps each word(str) to an id (int).</p>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.dataset.text.utils.Vocab.from_dataset">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freq_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">special_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">special_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/utils.html#Vocab.from_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.utils.Vocab.from_dataset" title="Permalink to this definition"></a></dt>
<dd><p>Build a vocab from a dataset.</p>
<p>This would collect all unique words in a dataset and return a vocab within
the frequency range specified by user in freq_range. User would be warned if no words fall into the frequency.
Words in vocab are ordered from highest frequency to lowest frequency. Words with the same frequency would be
ordered lexicographically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<em>Dataset</em>) – dataset to build vocab from.</p></li>
<li><p><strong>columns</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em><em>, </em><em>optional</em>) – column names to get words from. It can be a list of column names.
(default=None, where all columns will be used. If any column isn’t string type, will return error).</p></li>
<li><p><strong>freq_range</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><em>optional</em>) – A tuple of integers (min_frequency, max_frequency). Words within the frequency
range would be kept. 0 &lt;= min_frequency &lt;= max_frequency &lt;= total_words. min_frequency=0 is the same as
min_frequency=1. max_frequency &gt; total_words is the same as max_frequency = total_words.
min_frequency/max_frequency can be None, which corresponds to 0/total_words separately
(default=None, all words are included).</p></li>
<li><p><strong>top_k</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – top_k &gt; 0. Number of words to be built into vocab. top_k most frequent words are
taken. top_k is taken after freq_range. If not enough top_k, all words will be taken (default=None,
all words are included).</p></li>
<li><p><strong>special_tokens</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><em>optional</em>) – a list of strings, each one is a special token. for example
special_tokens=[“&lt;pad&gt;”,”&lt;unk&gt;”] (default=None, no special tokens will be added).</p></li>
<li><p><strong>special_first</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – whether special_tokens will be prepended/appended to vocab. If special_tokens
is specified and special_first is set to True, special_tokens will be prepended (default=True).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Vocab, Vocab object built from dataset.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.dataset.text.utils.Vocab.from_dict">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">word_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/utils.html#Vocab.from_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.utils.Vocab.from_dict" title="Permalink to this definition"></a></dt>
<dd><p>Build a vocab object from a dict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>word_dict</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – dict contains word and id pairs, where word should be str and id be int. id is recommended
to start from 0 and be continuous. ValueError will be raised if id is negative.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.dataset.text.utils.Vocab.from_file">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_file</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delimiter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">special_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">special_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/utils.html#Vocab.from_file"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.utils.Vocab.from_file" title="Permalink to this definition"></a></dt>
<dd><p>Build a vocab object from a list of word.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – path to the file which contains the vocab list.</p></li>
<li><p><strong>delimiter</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – a delimiter to break up each line in file, the first element is taken to be
the word (default=””).</p></li>
<li><p><strong>vocab_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – number of words to read from file_path (default=None, all words are taken).</p></li>
<li><p><strong>special_tokens</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><em>optional</em>) – a list of strings, each one is a special token. for example
special_tokens=[“&lt;pad&gt;”,”&lt;unk&gt;”] (default=None, no special tokens will be added).</p></li>
<li><p><strong>special_first</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – whether special_tokens will be prepended/appended to vocab,
If special_tokens is specified and special_first is set to True,
special_tokens will be prepended (default=True).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.dataset.text.utils.Vocab.from_list">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_list</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">word_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">special_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">special_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/utils.html#Vocab.from_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.utils.Vocab.from_list" title="Permalink to this definition"></a></dt>
<dd><p>Build a vocab object from a list of word.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>word_list</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – a list of string where each element is a word of type string.</p></li>
<li><p><strong>special_tokens</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><em>optional</em>) – a list of strings, each one is a special token. for example
special_tokens=[“&lt;pad&gt;”,”&lt;unk&gt;”] (default=None, no special tokens will be added).</p></li>
<li><p><strong>special_first</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – whether special_tokens will be prepended/appended to vocab, If special_tokens
is specified and special_first is set to True, special_tokens will be prepended (default=True).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.dataset.text.utils.to_bytes">
<span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.utils.</span></span><span class="sig-name descname"><span class="pre">to_bytes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'utf8'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/utils.html#to_bytes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.utils.to_bytes" title="Permalink to this definition"></a></dt>
<dd><p>Convert NumPy array of <cite>str</cite> to array of <cite>bytes</cite> by encoding each element based on charset <cite>encoding</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>array</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Array of type <cite>str</cite> representing strings.</p></li>
<li><p><strong>encoding</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Indicating the charset for encoding.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, NumPy array of <cite>bytes</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.dataset.text.utils.to_str">
<span class="sig-prename descclassname"><span class="pre">mindspore.dataset.text.utils.</span></span><span class="sig-name descname"><span class="pre">to_str</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'utf8'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/dataset/text/utils.html#to_str"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dataset.text.utils.to_str" title="Permalink to this definition"></a></dt>
<dd><p>Convert NumPy array of <cite>bytes</cite> to array of <cite>str</cite> by decoding each element based on charset <cite>encoding</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>array</strong> (<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Array of type <cite>bytes</cite> representing strings.</p></li>
<li><p><strong>encoding</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Indicating the charset for decoding.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.ndarray, NumPy array of <cite>str</cite>.</p>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindspore.dataset.config.html" class="btn btn-neutral float-left" title="mindspore.dataset.config" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mindspore.dataset.transforms.html" class="btn btn-neutral float-right" title="mindspore.dataset.transforms" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>