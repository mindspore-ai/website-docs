

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindspore.nn.probability &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="mindspore.ops" href="mindspore.ops.html" />
    <link rel="prev" title="mindspore.nn.dynamic_lr" href="mindspore.nn.dynamic_lr.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">MindSpore Python API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.dynamic_lr.html">mindspore.nn.dynamic_lr</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindspore.nn.probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.nn.probability.bijector">mindspore.nn.probability.bijector</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.nn.probability.bnn_layers">mindspore.nn.probability.bnn_layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.nn.probability.distribution">mindspore.nn.probability.distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.nn.probability.dpn">mindspore.nn.probability.dpn</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.nn.probability.infer">mindspore.nn.probability.infer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.nn.probability.toolbox">mindspore.nn.probability.toolbox</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.nn.probability.transforms">mindspore.nn.probability.transforms</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.profiler.html">mindspore.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.train.html">mindspore.train</a></li>
</ul>
<p class="caption"><span class="caption-text">MindArmour Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.html">mindarmour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.attacks.html">mindarmour.adv_robustness.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.defenses.html">mindarmour.adv_robustness.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.detectors.html">mindarmour.adv_robustness.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.evaluations.html">mindarmour.adv_robustness.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.fuzz_testing.html">mindarmour.fuzz_testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.privacy.diff_privacy.html">mindarmour.privacy.diff_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.privacy.evaluation.html">mindarmour.privacy.evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.utils.html">mindarmour.utils</a></li>
</ul>
<p class="caption"><span class="caption-text">MindSpore Hub Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindspore_hub/mindspore_hub.html">mindspore_hub</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>mindspore.nn.probability</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/mindspore/mindspore.nn.probability.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="mindspore-nn-probability">
<h1>mindspore.nn.probability<a class="headerlink" href="#mindspore-nn-probability" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-mindspore.nn.probability.bijector">
<span id="mindspore-nn-probability-bijector"></span><h2>mindspore.nn.probability.bijector<a class="headerlink" href="#module-mindspore.nn.probability.bijector" title="Permalink to this headline">¶</a></h2>
<p>Bijectors are the high-level components used to construct the probabilistic network.</p>
<dl class="class">
<dt id="mindspore.nn.probability.bijector.Bijector">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.bijector.</code><code class="sig-name descname">Bijector</code><span class="sig-paren">(</span><em class="sig-param">is_constant_jacobian=False</em>, <em class="sig-param">is_injective=True</em>, <em class="sig-param">name=None</em>, <em class="sig-param">dtype=None</em>, <em class="sig-param">param=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/bijector/bijector.html#Bijector"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.Bijector" title="Permalink to this definition">¶</a></dt>
<dd><p>Bijecotr class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>is_constant_jacobian</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether the Bijector has constant derivative. Default: False.</p></li>
<li><p><strong>is_injective</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether the Bijector is a one-to-one mapping. Default: True.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The name of the Bijector. Default: None.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a>) – The type of the distributions that the Bijector can operate on. Default: None.</p></li>
<li><p><strong>param</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – The parameters used to initialize the Bijector. Default: None.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mindspore.nn.probability.bijector.Bijector.construct">
<code class="sig-name descname">construct</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/bijector/bijector.html#Bijector.construct"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.Bijector.construct" title="Permalink to this definition">¶</a></dt>
<dd><p>Override <cite>construct</cite> in Cell.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Names of supported functions include:
‘forward’, ‘inverse’, ‘forward_log_jacobian’, and ‘inverse_log_jacobian’.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The name of the function.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – A list of positional arguments that the function needs.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – A dictionary of keyword arguments that the function needs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.bijector.Bijector.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/bijector/bijector.html#Bijector.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.Bijector.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward transformation: transform the input value to another distribution.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.bijector.Bijector.forward_log_jacobian">
<code class="sig-name descname">forward_log_jacobian</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/bijector/bijector.html#Bijector.forward_log_jacobian"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.Bijector.forward_log_jacobian" title="Permalink to this definition">¶</a></dt>
<dd><p>Logarithm of the derivative of the forward transformation.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.bijector.Bijector.inverse">
<code class="sig-name descname">inverse</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/bijector/bijector.html#Bijector.inverse"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.Bijector.inverse" title="Permalink to this definition">¶</a></dt>
<dd><p>Inverse transformation: transform the input value back to the original distribution.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.bijector.Bijector.inverse_log_jacobian">
<code class="sig-name descname">inverse_log_jacobian</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/bijector/bijector.html#Bijector.inverse_log_jacobian"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.Bijector.inverse_log_jacobian" title="Permalink to this definition">¶</a></dt>
<dd><p>Logarithm of the derivative of the inverse transformation.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindspore.nn.probability.bijector.PowerTransform">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.bijector.</code><code class="sig-name descname">PowerTransform</code><span class="sig-paren">(</span><em class="sig-param">power=0</em>, <em class="sig-param">name='PowerTransform'</em>, <em class="sig-param">param=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/bijector/power_transform.html#PowerTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.PowerTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Power Bijector.
This Bijector performs the operation:</p>
<div class="math notranslate nohighlight">
\[Y = g(X) = (1 + X * c)^{1 / c}, X &gt;= -1 / c\]</div>
<p>where c &gt;= 0 is the power.</p>
<p>The power transform maps inputs from <cite>[-1/c, inf]</cite> to <cite>[0, inf]</cite>.</p>
<p>This Bijector is equivalent to the <cite>Exp</cite> bijector when <cite>c=0</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – When the power is less than 0 or is not known statically.</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>power</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The scale factor. Default: 0.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The name of the bijector. Default: ‘PowerTransform’.</p></li>
<li><p><strong>param</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – The parameters used to initialize the bijector. These parameters are only used when other
Bijectors inherit from powertransform to pass in parameters. In this case the derived Bijector may overwrite
the argument <cite>param</cite>. Default: None.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a PowerTransform bijector of power 0.5.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.bijector</span> <span class="k">as</span> <span class="nn">msb</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">msb</span><span class="o">.</span><span class="n">PowerTransform</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use a PowerTransform bijector in a network.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">p1</span> <span class="o">=</span> <span class="n">msb</span><span class="o">.</span><span class="n">PowerTransform</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing &#39;forward&#39; by the name of the function.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">forward_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">inverse_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindspore.nn.probability.bijector.Exp">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.bijector.</code><code class="sig-name descname">Exp</code><span class="sig-paren">(</span><em class="sig-param">name='Exp'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/bijector/exp.html#Exp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.Exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Exponential Bijector.
This Bijector performs the operation:</p>
<div class="math notranslate nohighlight">
\[Y = exp(x).\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The name of the Bijector. Default: ‘Exp’.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize an Exp bijector.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.bijector</span> <span class="k">as</span> <span class="nn">msb</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">msb</span><span class="o">.</span><span class="n">Exp</span><span class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use an Exp bijector in a network.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">e1</span> <span class="o">=</span> <span class="n">msb</span><span class="o">.</span><span class="n">Exp</span><span class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing `forward` by the name of the function.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">forward_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">inverse_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindspore.nn.probability.bijector.ScalarAffine">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.bijector.</code><code class="sig-name descname">ScalarAffine</code><span class="sig-paren">(</span><em class="sig-param">scale=1.0</em>, <em class="sig-param">shift=0.0</em>, <em class="sig-param">name='ScalarAffine'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/bijector/scalar_affine.html#ScalarAffine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.ScalarAffine" title="Permalink to this definition">¶</a></dt>
<dd><p>Scalar Affine Bijector.
This Bijector performs the operation:</p>
<div class="math notranslate nohighlight">
\[Y = a * X + b\]</div>
<p>where a is the scale factor and b is the shift factor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The scale factor. Default: 1.0.</p></li>
<li><p><strong>shift</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The shift factor. Default: 0.0.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The name of the bijector. Default: ‘ScalarAffine’.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a ScalarAffine bijector of scale 1 and shift 2.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scalaraffine</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">probability</span><span class="o">.</span><span class="n">bijector</span><span class="o">.</span><span class="n">ScalarAffine</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use a ScalarAffine bijector in a network.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">s1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">probability</span><span class="o">.</span><span class="n">bijector</span><span class="o">.</span><span class="n">ScalarAffine</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing &#39;forward&#39; by the name of the function.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">forward_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">inverse_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindspore.nn.probability.bijector.Softplus">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.bijector.</code><code class="sig-name descname">Softplus</code><span class="sig-paren">(</span><em class="sig-param">sharpness=1.0</em>, <em class="sig-param">name='Softplus'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/bijector/softplus.html#Softplus"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.bijector.Softplus" title="Permalink to this definition">¶</a></dt>
<dd><p>Softplus Bijector.
This Bijector performs the operation:</p>
<div class="math notranslate nohighlight">
\[Y = \frac{\log(1 + e ^ {kX})}{k}\]</div>
<p>where k is the sharpness factor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sharpness</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The scale factor. Default: 1.0.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The name of the Bijector. Default: ‘Softplus’.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a Softplus bijector of sharpness 2.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">probability</span><span class="o">.</span><span class="n">bijector</span><span class="o">.</span><span class="n">Softfplus</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use ScalarAffine bijector in a network.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">sp1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">probability</span><span class="o">.</span><span class="n">bijector</span><span class="o">.</span><span class="n">Softflus</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing &#39;forward&#39; by the name of the function.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sp1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sp1</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sp1</span><span class="o">.</span><span class="n">forward_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sp1</span><span class="o">.</span><span class="n">inverse_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="module-mindspore.nn.probability.bnn_layers">
<span id="mindspore-nn-probability-bnn-layers"></span><h2>mindspore.nn.probability.bnn_layers<a class="headerlink" href="#module-mindspore.nn.probability.bnn_layers" title="Permalink to this headline">¶</a></h2>
<p><cite>bnn_layers</cite> are the high-level components used to construct the bayesian neural network.</p>
<dl class="class">
<dt id="mindspore.nn.probability.bnn_layers.ConvReparam">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.bnn_layers.</code><code class="sig-name descname">ConvReparam</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">pad_mode='same'</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">group=1</em>, <em class="sig-param">has_bias=False</em>, <em class="sig-param">weight_prior_fn=NormalPrior</em>, <em class="sig-param">weight_posterior_fn=&lt;lambda name</em>, <em class="sig-param">shape: NormalPosterior(name=name</em>, <em class="sig-param">shape=shape)&gt;</em>, <em class="sig-param">bias_prior_fn=NormalPrior</em>, <em class="sig-param">bias_posterior_fn=&lt;lambda name</em>, <em class="sig-param">shape: NormalPosterior(name=name</em>, <em class="sig-param">shape=shape)&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/bnn_layers/conv_variational.html#ConvReparam"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.bnn_layers.ConvReparam" title="Permalink to this definition">¶</a></dt>
<dd><p>Convolutional variational layers with Reparameterization.</p>
<p>For more details, refer to the paper <a class="reference external" href="https://arxiv.org/abs/1312.6114">Auto-Encoding Variational Bayes</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of input channel <span class="math notranslate nohighlight">\(C_{in}\)</span>.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of output channel <span class="math notranslate nohighlight">\(C_{out}\)</span>.</p></li>
<li><p><strong>kernel_size</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The data type is an integer or
a tuple of 2 integers. The kernel size specifies the height and
width of the 2D convolution window. a single integer stands for the
value is for both height and width of the kernel. With the <cite>kernel_size</cite>
being a tuple of 2 integers, the first value is for the height and the other
is the width of the kernel.</p></li>
<li><p><strong>stride</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The distance of kernel moving,
an integer number represents that the height and width of movement
are both strides, or a tuple of two integers numbers represents that
height and width of movement respectively. Default: 1.</p></li>
<li><p><strong>pad_mode</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>Specifies the padding mode. The optional values are
“same”, “valid”, and “pad”. Default: “same”.</p>
<ul>
<li><p>same: Adopts the way of completion. Output height and width
will be the same as the input.
The total number of padding will be calculated for in horizontal and
vertical directions and evenly distributed to top and bottom,
left and right if possible. Otherwise, the last extra padding
will be done from the bottom and the right side. If this mode
is set, <cite>padding</cite> must be 0.</p></li>
<li><p>valid: Adopts the way of discarding. The possible largest
height and width of the output will be returned without padding.
Extra pixels will be discarded. If this mode is set, <cite>padding</cite>
must be 0.</p></li>
<li><p>pad: Implicit paddings on both sides of the input. The number
of <cite>padding</cite> will be padded to the input Tensor borders.
<cite>padding</cite> must be greater than or equal to 0.</p></li>
</ul>
</p></li>
<li><p><strong>padding</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – Implicit paddings on both sides of
the input. Default: 0.</p></li>
<li><p><strong>dilation</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – The data type is an integer or a tuple
of 2 integers. This parameter specifies the dilation rate of the
dilated convolution. If set to be <span class="math notranslate nohighlight">\(k &gt; 1\)</span>,
there will be <span class="math notranslate nohighlight">\(k - 1\)</span> pixels skipped for each sampling
location. Its value must be greater or equal to 1 and bounded
by the height and width of the input. Default: 1.</p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Splits filter into groups, <cite>in_ channels</cite> and
<cite>out_channels</cite> must be divisible by the number of groups.
Default: 1.</p></li>
<li><p><strong>has_bias</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Specifies whether the layer uses a bias vector.
Default: False.</p></li>
<li><p><strong>weight_prior_fn</strong> – The prior distribution for weight.
It must return a mindspore distribution instance.
Default: NormalPrior. (which creates an instance of standard
normal distribution). The current version only supports normal distribution.</p></li>
<li><p><strong>weight_posterior_fn</strong> – The posterior distribution for sampling weight.
It must be a function handle which returns a mindspore
distribution instance. Default: lambda name, shape: NormalPosterior(name=name, shape=shape).
The current version only supports normal distribution.</p></li>
<li><p><strong>bias_prior_fn</strong> – The prior distribution for bias vector. It must return
a mindspore distribution. Default: NormalPrior(which creates an
instance of standard normal distribution). The current version
only supports normal distribution.</p></li>
<li><p><strong>bias_posterior_fn</strong> – The posterior distribution for sampling bias vector.
It must be a function handle which returns a mindspore
distribution instance. Default: lambda name, shape: NormalPosterior(name=name, shape=shape).
The current version only supports normal distribution.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor) - The shape of the tensor is <span class="math notranslate nohighlight">\((N, C_{in}, H_{in}, W_{in})\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, with the shape being <span class="math notranslate nohighlight">\((N, C_{out}, H_{out}, W_{out})\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">ConvReparam</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">640</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(1, 240, 1024, 640)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindspore.nn.probability.bnn_layers.DenseReparam">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.bnn_layers.</code><code class="sig-name descname">DenseReparam</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">activation=None</em>, <em class="sig-param">has_bias=True</em>, <em class="sig-param">weight_prior_fn=NormalPrior</em>, <em class="sig-param">weight_posterior_fn=&lt;lambda name</em>, <em class="sig-param">shape: NormalPosterior(name=name</em>, <em class="sig-param">shape=shape)&gt;</em>, <em class="sig-param">bias_prior_fn=NormalPrior</em>, <em class="sig-param">bias_posterior_fn=&lt;lambda name</em>, <em class="sig-param">shape: NormalPosterior(name=name</em>, <em class="sig-param">shape=shape)&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/bnn_layers/dense_variational.html#DenseReparam"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.bnn_layers.DenseReparam" title="Permalink to this definition">¶</a></dt>
<dd><p>Dense variational layers with Reparameterization.</p>
<p>For more details, refer to the paper <a class="reference external" href="https://arxiv.org/abs/1312.6114">Auto-Encoding Variational Bayes</a>.</p>
<p>Applies dense-connected layer to the input. This layer implements the operation as:</p>
<div class="math notranslate nohighlight">
\[\text{outputs} = \text{activation}(\text{inputs} * \text{weight} + \text{bias}),\]</div>
<p>where <span class="math notranslate nohighlight">\(\text{activation}\)</span> is the activation function passed as the activation
argument (if passed in), <span class="math notranslate nohighlight">\(\text{activation}\)</span> is a weight matrix with the same
data type as the inputs created by the layer, <span class="math notranslate nohighlight">\(\text{weight}\)</span> is a weight
matrix sampling from posterior distribution of weight, and <span class="math notranslate nohighlight">\(\text{bias}\)</span> is a
bias vector with the same data type as the inputs created by the layer (only if
has_bias is True). The bias vector is sampling from posterior distribution of
<span class="math notranslate nohighlight">\(\text{bias}\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of input channel.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of output channel .</p></li>
<li><p><strong>has_bias</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Specifies whether the layer uses a bias vector. Default: False.</p></li>
<li><p><strong>activation</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – A regularization function applied to the output of the layer. The type of <cite>activation</cite>
can be a string (eg. ‘relu’) or a Cell (eg. nn.ReLU()). Note that if the type of activation is Cell, it must
be instantiated beforehand. Default: None.</p></li>
<li><p><strong>weight_prior_fn</strong> – The prior distribution for weight.
It must return a mindspore distribution instance.
Default: NormalPrior. (which creates an instance of standard
normal distribution). The current version only supports normal distribution.</p></li>
<li><p><strong>weight_posterior_fn</strong> – The posterior distribution for sampling weight.
It must be a function handle which returns a mindspore
distribution instance. Default: lambda name, shape: NormalPosterior(name=name, shape=shape).
The current version only supports normal distribution.</p></li>
<li><p><strong>bias_prior_fn</strong> – The prior distribution for bias vector. It must return
a mindspore distribution. Default: NormalPrior(which creates an
instance of standard normal distribution). The current version
only supports normal distribution.</p></li>
<li><p><strong>bias_posterior_fn</strong> – The posterior distribution for sampling bias vector.
It must be a function handle which returns a mindspore
distribution instance. Default: lambda name, shape: NormalPosterior(name=name, shape=shape).
The current version only supports normal distribution.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor) - The shape of the tensor is <span class="math notranslate nohighlight">\((N, in\_channels)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the shape of the tensor is <span class="math notranslate nohighlight">\((N, out\_channels)\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">DenseReparam</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2, 4)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindspore.nn.probability.bnn_layers.WithBNNLossCell">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.bnn_layers.</code><code class="sig-name descname">WithBNNLossCell</code><a class="reference internal" href="../_modules/mindspore/nn/probability/bnn_layers/bnn_cell_wrapper.html#WithBNNLossCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.bnn_layers.WithBNNLossCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a suitable WithLossCell for BNN to wrap the bayesian network with loss function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>backbone</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The target network.</p></li>
<li><p><strong>loss_fn</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The loss function used to compute loss.</p></li>
<li><p><strong>dnn_factor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The coefficient of backbone’s loss, which is computed by the loss function. Default: 1.</p></li>
<li><p><strong>bnn_factor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The coefficient of KL loss, which is the KL divergence of Bayesian layer. Default: 1.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>data</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, \ldots)\)</span>.</p></li>
<li><p><strong>label</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, \ldots)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, a scalar tensor with shape <span class="math notranslate nohighlight">\(()\)</span>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">is_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_with_criterion_object</span> <span class="o">=</span> <span class="n">WithBNNLossCell</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_with_criterion</span> <span class="o">=</span> <span class="n">net_with_criterion_object</span><span class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_with_criterion</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindspore.nn.probability.bnn_layers.NormalPrior">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.bnn_layers.</code><code class="sig-name descname">NormalPrior</code><span class="sig-paren">(</span><em class="sig-param">dtype=mindspore.float32</em>, <em class="sig-param">mean=0</em>, <em class="sig-param">std=0.1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/bnn_layers/layer_distribution.html#NormalPrior"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.bnn_layers.NormalPrior" title="Permalink to this definition">¶</a></dt>
<dd><p>To initialize a normal distribution of mean 0 and standard deviation 0.1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.html#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – The argument is used to define the data type of the output tensor.
Default: mindspore.float32.</p></li>
<li><p><strong>mean</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Mean of normal distribution. Default: 0.</p></li>
<li><p><strong>std</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Standard deviation of normal distribution. Default: 0.1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Cell, a normal distribution.</p>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="mindspore.nn.probability.bnn_layers.NormalPosterior">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.bnn_layers.</code><code class="sig-name descname">NormalPosterior</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">shape</em>, <em class="sig-param">dtype=mindspore.float32</em>, <em class="sig-param">loc_mean=0</em>, <em class="sig-param">loc_std=0.1</em>, <em class="sig-param">untransformed_scale_mean=-5</em>, <em class="sig-param">untransformed_scale_std=0.1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/bnn_layers/layer_distribution.html#NormalPosterior"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.bnn_layers.NormalPosterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Build Normal distributions with trainable parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Name prepended to trainable parameter.</p></li>
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – Shape of the mean and standard deviation.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.html#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – The argument is used to define the data type of the output tensor.
Default: mindspore.float32.</p></li>
<li><p><strong>loc_mean</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Mean of distribution to initialize trainable parameters. Default: 0.</p></li>
<li><p><strong>loc_std</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Standard deviation of distribution to initialize trainable parameters. Default: 0.1.</p></li>
<li><p><strong>untransformed_scale_mean</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Mean of distribution to initialize trainable parameters. Default: -5.</p></li>
<li><p><strong>untransformed_scale_std</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Standard deviation of distribution to initialize trainable parameters.
Default: 0.1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Cell, a normal distribution.</p>
</dd>
</dl>
<dl class="method">
<dt id="mindspore.nn.probability.bnn_layers.NormalPosterior.std_trans">
<code class="sig-name descname">std_trans</code><span class="sig-paren">(</span><em class="sig-param">std_pre</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/bnn_layers/layer_distribution.html#NormalPosterior.std_trans"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.bnn_layers.NormalPosterior.std_trans" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform std_pre to prevent its value being zero.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-mindspore.nn.probability.distribution">
<span id="mindspore-nn-probability-distribution"></span><h2>mindspore.nn.probability.distribution<a class="headerlink" href="#module-mindspore.nn.probability.distribution" title="Permalink to this headline">¶</a></h2>
<p>Distributions are the high-level components used to construct the probabilistic network.</p>
<dl class="class">
<dt id="mindspore.nn.probability.distribution.Distribution">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.distribution.</code><code class="sig-name descname">Distribution</code><span class="sig-paren">(</span><em class="sig-param">seed</em>, <em class="sig-param">dtype</em>, <em class="sig-param">name</em>, <em class="sig-param">param</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for all mathematical distributions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The seed is used in sampling. The global seed is used if it is None.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a>) – The type of the event samples.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The name of the distribution.</p></li>
<li><p><strong>param</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – The parameters used to initialize the distribution.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Derived class must override operations such as <cite>_mean</cite>, <cite>_prob</cite>,
and <cite>_log_prob</cite>. Required arguments, such as <cite>value</cite> for <cite>_prob</cite>,
must be passed in through <cite>args</cite> or <cite>kwargs</cite>. <cite>dist_spec_args</cite> which specifies
a new distribution are optional.</p>
<p><cite>dist_spec_args</cite> is unique for each type of distribution. For example, <cite>mean</cite> and <cite>sd</cite>
are the <cite>dist_spec_args</cite> for a Normal distribution, while <cite>rate</cite> is the <cite>dist_spec_args</cite>
for an Exponential distribution.</p>
<p>For all functions, passing in <cite>dist_spec_args</cite>, is optional.
Function calls with the additional <cite>dist_spec_args</cite> passed in will evaluate the result with
a new distribution specified by the <cite>dist_spec_args</cite>. However, it will not change the original distribution.</p>
</div>
<dl class="method">
<dt id="mindspore.nn.probability.distribution.Distribution.cdf">
<code class="sig-name descname">cdf</code><span class="sig-paren">(</span><em class="sig-param">value</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.cdf" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the cdf at given value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – value to be evaluated.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – the list of positional arguments forwarded to subclasses.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – the dictionary of keyword arguments forwarded to subclasses.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A distribution can be optionally passed to the function by passing its dist_spec_args through
<cite>args</cite> or <cite>kwargs</cite>.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.distribution.Distribution.construct">
<code class="sig-name descname">construct</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.construct"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.construct" title="Permalink to this definition">¶</a></dt>
<dd><p>Override <cite>construct</cite> in Cell.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Names of supported functions include:
‘prob’, ‘log_prob’, ‘cdf’, ‘log_cdf’, ‘survival_function’, ‘log_survival’
‘var’, ‘sd’, ‘entropy’, ‘kl_loss’, ‘cross_entropy’, and ‘sample’.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The name of the function.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – A list of positional arguments that the function needs.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – A dictionary of keyword arguments that the function needs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.distribution.Distribution.cross_entropy">
<code class="sig-name descname">cross_entropy</code><span class="sig-paren">(</span><em class="sig-param">dist</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.cross_entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.cross_entropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the cross_entropy between distribution a and b.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dist</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – type of the distribution.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – the list of positional arguments forwarded to subclasses.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – the dictionary of keyword arguments forwarded to subclasses.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>dist_spec_args of distribution b must be passed to the function through <cite>args</cite> or <cite>kwargs</cite>.
Passing in dist_spec_args of distribution a is optional.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.distribution.Distribution.entropy">
<code class="sig-name descname">entropy</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.entropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the entropy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – the list of positional arguments forwarded to subclasses.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – the dictionary of keyword arguments forwarded to subclasses.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A distribution can be optionally passed to the function by passing its <em>dist_spec_args</em> through
<em>args</em> or <em>kwargs</em>.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.distribution.Distribution.kl_loss">
<code class="sig-name descname">kl_loss</code><span class="sig-paren">(</span><em class="sig-param">dist</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.kl_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.kl_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the KL divergence, i.e. KL(a||b).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dist</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – type of the distribution.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – the list of positional arguments forwarded to subclasses.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – the dictionary of keyword arguments forwarded to subclasses.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>dist_spec_args of distribution b must be passed to the function through <cite>args</cite> or <cite>kwargs</cite>.
Passing in dist_spec_args of distribution a is optional.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.distribution.Distribution.log_cdf">
<code class="sig-name descname">log_cdf</code><span class="sig-paren">(</span><em class="sig-param">value</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.log_cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.log_cdf" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the log cdf at given value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – value to be evaluated.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – the list of positional arguments forwarded to subclasses.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – the dictionary of keyword arguments forwarded to subclasses.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A distribution can be optionally passed to the function by passing its dist_spec_args through
<cite>args</cite> or <cite>kwargs</cite>.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.distribution.Distribution.log_prob">
<code class="sig-name descname">log_prob</code><span class="sig-paren">(</span><em class="sig-param">value</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.log_prob" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the log probability(pdf or pmf) at the given value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – value to be evaluated.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – the list of positional arguments forwarded to subclasses.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – the dictionary of keyword arguments forwarded to subclasses.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A distribution can be optionally passed to the function by passing its dist_spec_args through
<cite>args</cite> or <cite>kwargs</cite>.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.distribution.Distribution.log_survival">
<code class="sig-name descname">log_survival</code><span class="sig-paren">(</span><em class="sig-param">value</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.log_survival"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.log_survival" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the log survival function at given value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – value to be evaluated.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – the list of positional arguments forwarded to subclasses.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – the dictionary of keyword arguments forwarded to subclasses.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A distribution can be optionally passed to the function by passing its dist_spec_args through
<cite>args</cite> or <cite>kwargs</cite>.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.distribution.Distribution.mean">
<code class="sig-name descname">mean</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.mean"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.mean" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the mean.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – the list of positional arguments forwarded to subclasses.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – the dictionary of keyword arguments forwarded to subclasses.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A distribution can be optionally passed to the function by passing its <em>dist_spec_args</em> through
<em>args</em> or <em>kwargs</em>.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.distribution.Distribution.mode">
<code class="sig-name descname">mode</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.mode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.mode" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – the list of positional arguments forwarded to subclasses.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – the dictionary of keyword arguments forwarded to subclasses.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A distribution can be optionally passed to the function by passing its <em>dist_spec_args</em> through
<em>args</em> or <em>kwargs</em>.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.distribution.Distribution.prob">
<code class="sig-name descname">prob</code><span class="sig-paren">(</span><em class="sig-param">value</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.prob" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the probability (pdf or pmf) at given value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – value to be evaluated.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – the list of positional arguments forwarded to subclasses.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – the dictionary of keyword arguments forwarded to subclasses.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A distribution can be optionally passed to the function by passing its dist_spec_args through
<cite>args</cite> or <cite>kwargs</cite>.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.distribution.Distribution.sample">
<code class="sig-name descname">sample</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Sampling function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – shape of the sample.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – the list of positional arguments forwarded to subclasses.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – the dictionary of keyword arguments forwarded to subclasses.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A distribution can be optionally passed to the function by passing its <em>dist_spec_args</em> through
<em>args</em> or <em>kwargs</em>.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.distribution.Distribution.sd">
<code class="sig-name descname">sd</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.sd"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.sd" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the standard deviation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – the list of positional arguments forwarded to subclasses.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – the dictionary of keyword arguments forwarded to subclasses.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A distribution can be optionally passed to the function by passing its <em>dist_spec_args</em> through
<em>args</em> or <em>kwargs</em>.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.distribution.Distribution.survival_function">
<code class="sig-name descname">survival_function</code><span class="sig-paren">(</span><em class="sig-param">value</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.survival_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.survival_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the survival function at given value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – value to be evaluated.</p></li>
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – the list of positional arguments forwarded to subclasses.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – the dictionary of keyword arguments forwarded to subclasses.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A distribution can be optionally passed to the function by passing its dist_spec_args through
<cite>args</cite> or <cite>kwargs</cite>.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.distribution.Distribution.var">
<code class="sig-name descname">var</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/distribution.html#Distribution.var"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Distribution.var" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the variance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – the list of positional arguments forwarded to subclasses.</p></li>
<li><p><strong>**kwargs</strong> (<em>dictionary</em>) – the dictionary of keyword arguments forwarded to subclasses.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A distribution can be optionally passed to the function by passing its <em>dist_spec_args</em> through
<em>args</em> or <em>kwargs</em>.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindspore.nn.probability.distribution.TransformedDistribution">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.distribution.</code><code class="sig-name descname">TransformedDistribution</code><span class="sig-paren">(</span><em class="sig-param">bijector</em>, <em class="sig-param">distribution</em>, <em class="sig-param">dtype</em>, <em class="sig-param">seed=None</em>, <em class="sig-param">name='transformed_distribution'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/transformed_distribution.html#TransformedDistribution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.TransformedDistribution" title="Permalink to this definition">¶</a></dt>
<dd><p>Transformed Distribution.
This class contains a bijector and a distribution and transforms the original distribution
to a new distribution through the operation defined by the bijector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bijector</strong> (<a class="reference internal" href="#mindspore.nn.probability.bijector.Bijector" title="mindspore.nn.probability.bijector.Bijector"><em>Bijector</em></a>) – The transformation to perform.</p></li>
<li><p><strong>distribution</strong> (<a class="reference internal" href="#mindspore.nn.probability.distribution.Distribution" title="mindspore.nn.probability.distribution.Distribution"><em>Distribution</em></a>) – The original distribution.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The name of the transformed distribution. Default: ‘transformed_distribution’.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The arguments used to initialize the original distribution cannot be None.
For example, mynormal = nn.Normal(dtype=dtyple.float32) cannot be used to initialized a
TransformedDistribution since <cite>mean</cite> and <cite>sd</cite> are not specified.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a transformed distribution, e.g. a lognormal distribution,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># using a Normal distribution as the base distribution, and an Exp bijector as the bijector function.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.bijector</span> <span class="k">as</span> <span class="nn">msb</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ln</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">TransformedDistribution</span><span class="p">(</span><span class="n">msb</span><span class="o">.</span><span class="n">Exp</span><span class="p">(),</span>
<span class="gp">&gt;&gt;&gt; </span>                                 <span class="n">msd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span>                                 <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use a transformed distribution in a network.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">ln</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">TransformedDistribution</span><span class="p">(</span><span class="n">msb</span><span class="o">.</span><span class="n">Exp</span><span class="p">(),</span>
<span class="gp">&gt;&gt;&gt; </span>                                              <span class="n">msd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span>                                              <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing &#39;sample&#39; by the name of the function.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindspore.nn.probability.distribution.Normal">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.distribution.</code><code class="sig-name descname">Normal</code><span class="sig-paren">(</span><em class="sig-param">mean=None</em>, <em class="sig-param">sd=None</em>, <em class="sig-param">seed=None</em>, <em class="sig-param">dtype=mindspore.float32</em>, <em class="sig-param">name='Normal'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/normal.html#Normal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Normal" title="Permalink to this definition">¶</a></dt>
<dd><p>Normal distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mean</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a>) – The mean of the Normal distribution.</p></li>
<li><p><strong>sd</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a>) – The standard deviation of the Normal distribution.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The seed used in sampling. The global seed is used if it is None. Default: None.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a>) – The type of the event samples. Default: mstype.float32.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The name of the distribution. Default: ‘Normal’.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><cite>sd</cite> must be greater than zero.
<cite>dist_spec_args</cite> are <cite>mean</cite> and <cite>sd</cite>.
<cite>dtype</cite> must be a float type because Normal distributions are continuous.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a Normal distribution of the mean 3.0 and the standard deviation 4.0.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The following creates two independent Normal distributions.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Normal</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># A Normal distribution can be initilize without arguments.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># In this case, `mean` and `sd` must be passed in through arguments.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use a Normal distribution in a network.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">n1</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Nomral</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">n2</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># The following calls are valid in construct.</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">mean_b</span><span class="p">,</span> <span class="n">sd_b</span><span class="p">,</span> <span class="n">mean_a</span><span class="p">,</span> <span class="n">sd_a</span><span class="p">):</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Private interfaces of probability functions corresponding to public interfaces, including</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># `prob`, `log_prob`, `cdf`, `log_cdf`, `survival_function`, and `log_survival`, have the same arguments as follows.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     value (Tensor): the value to be evaluated.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     mean (Tensor): the mean of distribution. Default: self._mean_value.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     sd (Tensor): the standard deviation of distribution. Default: self._sd_value.</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `prob`.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other probability functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing &#39;prob&#39; by the name of the function</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Evaluate with respect to distribution b.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">mean_b</span><span class="p">,</span> <span class="n">sd_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># `mean` and `sd` must be passed in during function calls</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n2</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">mean_a</span><span class="p">,</span> <span class="n">sd_a</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Functions `mean`, `sd`, `var`, and `entropy` have the same arguments.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     mean (Tensor): the mean of distribution. Default: self._mean_value.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     sd (Tensor): the standard deviation of distribution. Default: self._sd_value.</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Example of `mean`. `sd`, `var`, and `entropy` are similar.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="c1"># return 0.0</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_b</span><span class="p">,</span> <span class="n">sd_b</span><span class="p">)</span> <span class="c1"># return mean_b</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># `mean` and `sd` must be passed in during function calls.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n2</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mean_a</span><span class="p">,</span> <span class="n">sd_a</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Interfaces of &#39;kl_loss&#39; and &#39;cross_entropy&#39; are the same:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     dist (str): the type of the distributions. Only &quot;Normal&quot; is supported.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     mean_b (Tensor): the mean of distribution b.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     sd_b (Tensor): the standard deviation distribution b.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     mean_a (Tensor): the mean of distribution a. Default: self._mean_value.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     sd_a (Tensor): the standard deviation distribution a. Default: self._sd_value.</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `kl_loss`. `cross_entropy` is similar.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Normal&#39;</span><span class="p">,</span> <span class="n">mean_b</span><span class="p">,</span> <span class="n">sd_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Normal&#39;</span><span class="p">,</span> <span class="n">mean_b</span><span class="p">,</span> <span class="n">sd_b</span><span class="p">,</span> <span class="n">mean_a</span><span class="p">,</span> <span class="n">sd_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Additional `mean` and `sd` must be passed in.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n2</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Normal&#39;</span><span class="p">,</span> <span class="n">mean_b</span><span class="p">,</span> <span class="n">sd_b</span><span class="p">,</span> <span class="n">mean_a</span><span class="p">,</span> <span class="n">sd_a</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `sample`.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     shape (tuple): the shape of the sample. Default: ()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     mean (Tensor): the mean of the distribution. Default: self._mean_value.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     sd (Tensor): the standard deviation of the distribution. Default: self._sd_value.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">mean_b</span><span class="p">,</span> <span class="n">sd_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n2</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">mean_a</span><span class="p">,</span> <span class="n">sd_a</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindspore.nn.probability.distribution.Bernoulli">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.distribution.</code><code class="sig-name descname">Bernoulli</code><span class="sig-paren">(</span><em class="sig-param">probs=None</em>, <em class="sig-param">seed=None</em>, <em class="sig-param">dtype=mindspore.int32</em>, <em class="sig-param">name='Bernoulli'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/bernoulli.html#Bernoulli"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Bernoulli" title="Permalink to this definition">¶</a></dt>
<dd><p>Bernoulli Distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>probs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a>) – The probability of that the outcome is 1.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The seed used in sampling. The global seed is used if it is None. Default: None.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a>) – The type of the event samples. Default: mstype.int32.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The name of the distribution. Default: ‘Bernoulli’.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><cite>probs</cite> must be a proper probability (0 &lt; p &lt; 1).
<cite>dist_spec_args</cite> is <cite>probs</cite>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a Bernoulli distribution of the probability 0.5.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The following creates two independent Bernoulli distributions.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># A Bernoulli distribution can be initilized without arguments.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># In this case, `probs` must be passed in through arguments during function calls.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use the Bernoulli distribution in a network.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">b1</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">b2</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># All the following calls in construct are valid.</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">,</span> <span class="n">probs_a</span><span class="p">):</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Private interfaces of probability functions corresponding to public interfaces, including</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># `prob`, `log_prob`, `cdf`, `log_cdf`, `survival_function`, and `log_survival`, are the same as follows.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     value (Tensor): the value to be evaluated.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     probs1 (Tensor): the probability of success. Default: self.probs.</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `prob`.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other probability functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing `prob` by the name of the function.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Evaluate `prob` with respect to distribution b.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># `probs` must be passed in during function calls.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">probs_a</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Functions `mean`, `sd`, `var`, and `entropy` have the same arguments.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     probs1 (Tensor): the probability of success. Default: self.probs.</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `mean`. `sd`, `var`, and `entropy` are similar.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="c1"># return 0.5</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">probs_b</span><span class="p">)</span> <span class="c1"># return probs_b</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># `probs` must be passed in during function calls.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">probs_a</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Interfaces of `kl_loss` and `cross_entropy` are the same as follows:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     dist (str): the name of the distribution. Only &#39;Bernoulli&#39; is supported.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     probs1_b (Tensor): the probability of success of distribution b.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     probs1_a (Tensor): the probability of success of distribution a. Default: self.probs.</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of kl_loss. `cross_entropy` is similar.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Bernoulli&#39;</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Bernoulli&#39;</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">,</span> <span class="n">probs_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># An additional `probs_a` must be passed in.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Bernoulli&#39;</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">,</span> <span class="n">probs_a</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `sample`.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     shape (tuple): the shape of the sample. Default: ().</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     probs1 (Tensor): the probability of success. Default: self.probs.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">probs_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">probs_a</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore.nn.probability.distribution.Bernoulli.probs">
<em class="property">property </em><code class="sig-name descname">probs</code><a class="headerlink" href="#mindspore.nn.probability.distribution.Bernoulli.probs" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the probability of that the outcome is 1.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindspore.nn.probability.distribution.Exponential">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.distribution.</code><code class="sig-name descname">Exponential</code><span class="sig-paren">(</span><em class="sig-param">rate=None</em>, <em class="sig-param">seed=None</em>, <em class="sig-param">dtype=mindspore.float32</em>, <em class="sig-param">name='Exponential'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/exponential.html#Exponential"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Exponential" title="Permalink to this definition">¶</a></dt>
<dd><p>Example class: Exponential Distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rate</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a>) – The inverse scale.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The seed used in sampling. The global seed is used if it is None. Default: None.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a>) – The type of the event samples. Default: mstype.float32.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The name of the distribution. Default: ‘Exponential’.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><cite>rate</cite> must be strictly greater than 0.
<cite>dist_spec_args</cite> is <cite>rate</cite>.
<cite>dtype</cite> must be a float type because Exponential distributions are continuous.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize an Exponential distribution of the rate 0.5.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The following creates two independent Exponential distributions.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Exponential</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># An Exponential distribution can be initilized without arguments.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># In this case, `rate` must be passed in through `args` during function calls.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use an Exponential distribution in a network.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">e1</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">e2</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># All the following calls in construct are valid.</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">rate_b</span><span class="p">,</span> <span class="n">rate_a</span><span class="p">):</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Private interfaces of probability functions corresponding to public interfaces, including</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># `prob`, `log_prob`, `cdf`, `log_cdf`, `survival_function`, and `log_survival`, are the same as follows.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     value (Tensor): the value to be evaluated.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     rate (Tensor): the rate of the distribution. Default: self.rate.</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `prob`.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other probability functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing `prob` by the name of the function.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Evaluate with respect to distribution b.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">rate_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># `rate` must be passed in during function calls.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e2</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">rate_a</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Functions `mean`, `sd`, &#39;var&#39;, and &#39;entropy&#39; have the same arguments as follows.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     rate (Tensor): the rate of the distribution. Default: self.rate.</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `mean`. `sd`, `var`, and `entropy` are similar.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="c1"># return 2</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rate_b</span><span class="p">)</span> <span class="c1"># return 1 / rate_b</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># `rate` must be passed in during function calls.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e2</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rate_a</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Interfaces of `kl_loss` and `cross_entropy` are the same.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     dist (str): The name of the distribution. Only &#39;Exponential&#39; is supported.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     rate_b (Tensor): the rate of distribution b.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     rate_a (Tensor): the rate of distribution a. Default: self.rate.</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `kl_loss`. `cross_entropy` is similar.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Exponential&#39;</span><span class="p">,</span> <span class="n">rate_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Exponential&#39;</span><span class="p">,</span> <span class="n">rate_b</span><span class="p">,</span> <span class="n">rate_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># An additional `rate` must be passed in.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e2</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Exponential&#39;</span><span class="p">,</span> <span class="n">rate_b</span><span class="p">,</span> <span class="n">rate_a</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `sample`.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     shape (tuple): the shape of the sample. Default: ()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     probs1 (Tensor): the rate of the distribution. Default: self.rate.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">rate_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e2</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">rate_a</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore.nn.probability.distribution.Exponential.rate">
<em class="property">property </em><code class="sig-name descname">rate</code><a class="headerlink" href="#mindspore.nn.probability.distribution.Exponential.rate" title="Permalink to this definition">¶</a></dt>
<dd><p>Return <cite>rate</cite> of the distribution.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindspore.nn.probability.distribution.Uniform">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.distribution.</code><code class="sig-name descname">Uniform</code><span class="sig-paren">(</span><em class="sig-param">low=None</em>, <em class="sig-param">high=None</em>, <em class="sig-param">seed=None</em>, <em class="sig-param">dtype=mindspore.float32</em>, <em class="sig-param">name='Uniform'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/uniform.html#Uniform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Uniform" title="Permalink to this definition">¶</a></dt>
<dd><p>Example class: Uniform Distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>low</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a>) – The lower bound of the distribution.</p></li>
<li><p><strong>high</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a>) – The upper bound of the distribution.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The seed uses in sampling. The global seed is used if it is None. Default: None.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a>) – The type of the event samples. Default: mstype.float32.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The name of the distribution. Default: ‘Uniform’.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><cite>low</cite> must be stricly less than <cite>high</cite>.
<cite>dist_spec_args</cite> are <cite>high</cite> and <cite>low</cite>.
<cite>dtype</cite> must be float type because Uniform distributions are continuous.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a Uniform distribution of the lower bound 0.0 and the higher bound 1.0.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The following creates two independent Uniform distributions.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># A Uniform distribution can be initilized without arguments.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># In this case, `high` and `low` must be passed in through arguments during function calls.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use a Uniform distribution in a network.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">u1</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">u2</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># All the following calls in construct are valid.</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">low_b</span><span class="p">,</span> <span class="n">high_b</span><span class="p">,</span> <span class="n">low_a</span><span class="p">,</span> <span class="n">high_a</span><span class="p">):</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Private interfaces of probability functions corresponding to public interfaces, including</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># `prob`, `log_prob`, `cdf`, `log_cdf`, `survival_function`, and `log_survival`, have the same arguments.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     value (Tensor): the value to be evaluated.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     low (Tensor): the lower bound of distribution. Default: self.low.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     high (Tensor): the higher bound of distribution. Default: self.high.</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `prob`.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other probability functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing &#39;prob&#39; by the name of the function.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Evaluate with respect to distribution b.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">low_b</span><span class="p">,</span> <span class="n">high_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># `high` and `low` must be passed in during function calls.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u2</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">low_a</span><span class="p">,</span> <span class="n">high_a</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Functions `mean`, `sd`, `var`, and `entropy` have the same arguments.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     low (Tensor): the lower bound of distribution. Default: self.low.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     high (Tensor): the higher bound of distribution. Default: self.high.</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `mean`. `sd`, `var`, and `entropy` are similar.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="c1"># return 0.5</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">low_b</span><span class="p">,</span> <span class="n">high_b</span><span class="p">)</span> <span class="c1"># return (low_b + high_b) / 2</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># `high` and `low` must be passed in during function calls.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u2</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">low_a</span><span class="p">,</span> <span class="n">high_a</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Interfaces of &#39;kl_loss&#39; and &#39;cross_entropy&#39; are the same.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     dist (str): the type of the distributions. Should be &quot;Uniform&quot; in this case.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     low_b (Tensor): the lower bound of distribution b.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     high_b (Tensor): the upper bound of distribution b.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     low_a (Tensor): the lower bound of distribution a. Default: self.low.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     high_a (Tensor): the upper bound of distribution a. Default: self.high.</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `kl_loss`. `cross_entropy` is similar.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Uniform&#39;</span><span class="p">,</span> <span class="n">low_b</span><span class="p">,</span> <span class="n">high_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Uniform&#39;</span><span class="p">,</span> <span class="n">low_b</span><span class="p">,</span> <span class="n">high_b</span><span class="p">,</span> <span class="n">low_a</span><span class="p">,</span> <span class="n">high_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Additional `high` and `low` must be passed in.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u2</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Uniform&#39;</span><span class="p">,</span> <span class="n">low_b</span><span class="p">,</span> <span class="n">high_b</span><span class="p">,</span> <span class="n">low_a</span><span class="p">,</span> <span class="n">high_a</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `sample`.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     shape (tuple): the shape of the sample. Default: ()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     low (Tensor): the lower bound of the distribution. Default: self.low.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     high (Tensor): the upper bound of the distribution. Default: self.high.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">low_b</span><span class="p">,</span> <span class="n">high_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u2</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">low_a</span><span class="p">,</span> <span class="n">high_a</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore.nn.probability.distribution.Uniform.high">
<em class="property">property </em><code class="sig-name descname">high</code><a class="headerlink" href="#mindspore.nn.probability.distribution.Uniform.high" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the upper bound of the distribution.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.distribution.Uniform.low">
<em class="property">property </em><code class="sig-name descname">low</code><a class="headerlink" href="#mindspore.nn.probability.distribution.Uniform.low" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the lower bound of the distribution.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindspore.nn.probability.distribution.Categorical">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.distribution.</code><code class="sig-name descname">Categorical</code><span class="sig-paren">(</span><em class="sig-param">probs=None</em>, <em class="sig-param">logits=None</em>, <em class="sig-param">seed=None</em>, <em class="sig-param">dtype=mindspore.int32</em>, <em class="sig-param">name='Categorical'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/categorical.html#Categorical"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Categorical" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a categorical distribution parameterized by either probabilities or logits (but not both).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>probs</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a>) – Event probabilities.</p></li>
<li><p><strong>logits</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Event log-odds.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The global seed is used in sampling. Global seed is used if it is None. Default: None.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a>) – The type of the distribution. Default: mstype.int32.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The name of the distribution. Default: Categorical.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><cite>probs</cite> must be non-negative, finite and have a non-zero sum, and it will be normalized to sum to 1.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a Categorical distribution of prob is [0.5, 0.5]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use Categorical in a network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">probs</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">ca</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="n">probs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># All the following calls in construct are valid</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to logits</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca</span><span class="o">.</span><span class="n">probs</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># value must be Tensor(mstype.float32, bool, mstype.int32)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Usage of enumerate_support</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca</span><span class="o">.</span><span class="n">enumerate_support</span><span class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Usage of entropy</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Sample</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,))</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore.nn.probability.distribution.Categorical.enumerate_support">
<code class="sig-name descname">enumerate_support</code><span class="sig-paren">(</span><em class="sig-param">expand=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/categorical.html#Categorical.enumerate_support"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Categorical.enumerate_support" title="Permalink to this definition">¶</a></dt>
<dd><p>Enumerate categories.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>expand</strong> (<em>Bool</em>) – Whether to expand.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.distribution.Categorical.logits">
<em class="property">property </em><code class="sig-name descname">logits</code><a class="headerlink" href="#mindspore.nn.probability.distribution.Categorical.logits" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the logits.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.distribution.Categorical.probs">
<em class="property">property </em><code class="sig-name descname">probs</code><a class="headerlink" href="#mindspore.nn.probability.distribution.Categorical.probs" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the probability.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindspore.nn.probability.distribution.Geometric">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.distribution.</code><code class="sig-name descname">Geometric</code><span class="sig-paren">(</span><em class="sig-param">probs=None</em>, <em class="sig-param">seed=None</em>, <em class="sig-param">dtype=mindspore.int32</em>, <em class="sig-param">name='Geometric'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/distribution/geometric.html#Geometric"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.distribution.Geometric" title="Permalink to this definition">¶</a></dt>
<dd><p>Geometric Distribution.
It represents that there are k failures before the first sucess, namely taht there are in total k+1 Bernoulli trails
when the first success is achieved.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>probs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference internal" href="mindspore.html#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a>) – The probability of success.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The seed used in sampling. Global seed is used if it is None. Default: None.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.html#mindspore.dtype" title="mindspore.dtype"><em>mindspore.dtype</em></a>) – The type of the event samples. Default: mstype.int32.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The name of the distribution. Default: ‘Geometric’.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><cite>probs</cite> must be a proper probability (0 &lt; p &lt; 1).
<cite>dist_spec_args</cite> is <cite>probs</cite>.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To initialize a Geometric distribution of the probability 0.5.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Geometric</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The following creates two independent Geometric distributions.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Geometric</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># A Geometric distribution can be initilized without arguments.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># In this case, `probs` must be passed in through arguments during function calls.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Geometric</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To use a Geometric distribution in a network.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">g1</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Geometric</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">g2</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Geometric</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># The following calls are valid in construct.</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">,</span> <span class="n">probs_a</span><span class="p">):</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Private interfaces of probability functions corresponding to public interfaces, including</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># `prob`, `log_prob`, `cdf`, `log_cdf`, `survival_function`, and `log_survival`, have the same arguments as follows.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     value (Tensor): the value to be evaluated.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     probs1 (Tensor): the probability of success of a Bernoulli trail. Default: self.probs.</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `prob`.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Similar calls can be made to other probability functions</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># by replacing `prob` by the name of the function.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Evaluate with respect to distribution b.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># `probs` must be passed in during function calls.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g2</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">probs_a</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Functions `mean`, `sd`, `var`, and `entropy` have the same arguments.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     probs1 (Tensor): the probability of success of a Bernoulli trail. Default: self.probs.</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `mean`. `sd`, `var`, and `entropy` are similar.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="c1"># return 1.0</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">probs_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Probs must be passed in during function calls</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g2</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">probs_a</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Interfaces of &#39;kl_loss&#39; and &#39;cross_entropy&#39; are the same.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     dist (str): the name of the distribution. Only &#39;Geometric&#39; is supported.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     probs1_b (Tensor): the probability of success of a Bernoulli trail of distribution b.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     probs1_a (Tensor): the probability of success of a Bernoulli trail of distribution a. Default: self.probs.</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `kl_loss`. `cross_entropy` is similar.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Geometric&#39;</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Geometric&#39;</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">,</span> <span class="n">probs_a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># An additional `probs` must be passed in.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g2</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Geometric&#39;</span><span class="p">,</span> <span class="n">probs_b</span><span class="p">,</span> <span class="n">probs_a</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Examples of `sample`.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1"># Args:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     shape (tuple): the shape of the sample. Default: ()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="c1">#     probs1 (Tensor): the probability of success of a Bernoulli trail. Default: self.probs.</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g1</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">probs_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ans</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g2</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">probs_a</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore.nn.probability.distribution.Geometric.probs">
<em class="property">property </em><code class="sig-name descname">probs</code><a class="headerlink" href="#mindspore.nn.probability.distribution.Geometric.probs" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the probability of success of the Bernoulli trail.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-mindspore.nn.probability.dpn">
<span id="mindspore-nn-probability-dpn"></span><h2>mindspore.nn.probability.dpn<a class="headerlink" href="#module-mindspore.nn.probability.dpn" title="Permalink to this headline">¶</a></h2>
<p>Deep probability network such as BNN and VAE network.</p>
<dl class="class">
<dt id="mindspore.nn.probability.dpn.VAE">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.dpn.</code><code class="sig-name descname">VAE</code><span class="sig-paren">(</span><em class="sig-param">encoder</em>, <em class="sig-param">decoder</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">latent_size</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/dpn/vae/vae.html#VAE"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.dpn.VAE" title="Permalink to this definition">¶</a></dt>
<dd><p>Variational Auto-Encoder (VAE).</p>
<p>The VAE defines a generative model, <cite>Z</cite> is sampled from the prior, then used to reconstruct <cite>X</cite> by a decoder.
For more details, refer to <a class="reference external" href="https://arxiv.org/abs/1312.6114">Auto-Encoding Variational Bayes</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When the encoder and decoder are defined, the shape of the encoder’s output tensor and decoder’s input tensor
must be <span class="math notranslate nohighlight">\((N, hidden\_size)\)</span>.
The latent_size must be less than or equal to the hidden_size.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The Deep Neural Network (DNN) model defined as encoder.</p></li>
<li><p><strong>decoder</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The DNN model defined as decoder.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The size of encoder’s output tensor.</p></li>
<li><p><strong>latent_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The size of the latent space.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input</strong> (Tensor) - The shape of input tensor is <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>, which is the same as the input of
encoder.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><ul class="simple">
<li><p><strong>output</strong> (Tuple) - (recon_x(Tensor), x(Tensor), mu(Tensor), std(Tensor)).</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mindspore.nn.probability.dpn.VAE.generate_sample">
<code class="sig-name descname">generate_sample</code><span class="sig-paren">(</span><em class="sig-param">generate_nums</em>, <em class="sig-param">shape</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/dpn/vae/vae.html#VAE.generate_sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.dpn.VAE.generate_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Randomly sample from latent space to generate samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>generate_nums</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of samples to generate.</p></li>
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – The shape of sample, it must be (generate_nums, C, H, W) or (-1, C, H, W).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, the generated samples.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.dpn.VAE.reconstruct_sample">
<code class="sig-name descname">reconstruct_sample</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/dpn/vae/vae.html#VAE.reconstruct_sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.dpn.VAE.reconstruct_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Reconstruct samples from original data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The input tensor to be reconstructed, the shape is (N, C, H, W).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, the reconstructed sample.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindspore.nn.probability.dpn.ConditionalVAE">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.dpn.</code><code class="sig-name descname">ConditionalVAE</code><span class="sig-paren">(</span><em class="sig-param">encoder</em>, <em class="sig-param">decoder</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">latent_size</em>, <em class="sig-param">num_classes</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/dpn/vae/cvae.html#ConditionalVAE"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.dpn.ConditionalVAE" title="Permalink to this definition">¶</a></dt>
<dd><p>Conditional Variational Auto-Encoder (CVAE).</p>
<p>The difference with VAE is that CVAE uses labels information.
For more details, refer to <a class="reference external" href="http://papers.nips.cc/paper/5775-learning-structured-output-representation-using-deep-conditional-generative-models">Learning Structured Output Representation using Deep Conditional Generative Models</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When encoder and decoder ard defined, the shape of the encoder’s output tensor and decoder’s input tensor
must be <span class="math notranslate nohighlight">\((N, hidden\_size)\)</span>.
The latent_size must be less than or equal to the hidden_size.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The Deep Neural Network (DNN) model defined as encoder.</p></li>
<li><p><strong>decoder</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The DNN model defined as decoder.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The size of encoder’s output tensor.</p></li>
<li><p><strong>latent_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The size of the latent space.</p></li>
<li><p><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of classes.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_x</strong> (Tensor) - The shape of input tensor is <span class="math notranslate nohighlight">\((N, C, H, W)\)</span>, which is the same as the input of
encoder.</p></li>
<li><p><strong>input_y</strong> (Tensor) - The tensor of the target data, the shape is <span class="math notranslate nohighlight">\((N,)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><ul class="simple">
<li><p><strong>output</strong> (tuple) - (recon_x(Tensor), x(Tensor), mu(Tensor), std(Tensor)).</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mindspore.nn.probability.dpn.ConditionalVAE.construct">
<code class="sig-name descname">construct</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/dpn/vae/cvae.html#ConditionalVAE.construct"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.dpn.ConditionalVAE.construct" title="Permalink to this definition">¶</a></dt>
<dd><p>The input are x and y, so the WithLossCell method needs to be rewritten when using cvae interface.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.dpn.ConditionalVAE.generate_sample">
<code class="sig-name descname">generate_sample</code><span class="sig-paren">(</span><em class="sig-param">sample_y</em>, <em class="sig-param">generate_nums</em>, <em class="sig-param">shape</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/dpn/vae/cvae.html#ConditionalVAE.generate_sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.dpn.ConditionalVAE.generate_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Randomly sample from the latent space to generate samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sample_y</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – Define the label of samples. Tensor of shape (generate_nums, ) and type mindspore.int32.</p></li>
<li><p><strong>generate_nums</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of samples to generate.</p></li>
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – The shape of sample, which must be the format of (generate_nums, C, H, W) or (-1, C, H, W).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, the generated samples.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.dpn.ConditionalVAE.reconstruct_sample">
<code class="sig-name descname">reconstruct_sample</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/dpn/vae/cvae.html#ConditionalVAE.reconstruct_sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.dpn.ConditionalVAE.reconstruct_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Reconstruct samples from original data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The input tensor to be reconstructed, the shape is (N, C, H, W).</p></li>
<li><p><strong>y</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The label of the input tensor, the shape is (N,).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, the reconstructed sample.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-mindspore.nn.probability.infer">
<span id="mindspore-nn-probability-infer"></span><h2>mindspore.nn.probability.infer<a class="headerlink" href="#module-mindspore.nn.probability.infer" title="Permalink to this headline">¶</a></h2>
<p>Inference algorithms in Probabilistic Programming.</p>
<dl class="class">
<dt id="mindspore.nn.probability.infer.SVI">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.infer.</code><code class="sig-name descname">SVI</code><span class="sig-paren">(</span><em class="sig-param">net_with_loss</em>, <em class="sig-param">optimizer</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/infer/variational/svi.html#SVI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.infer.SVI" title="Permalink to this definition">¶</a></dt>
<dd><p>Stochastic Variational Inference(SVI).</p>
<p>Variational inference casts the inference problem as an optimization. Some distributions over the hidden
variables are indexed by a set of free parameters, which are optimized to make distributions closest to
the posterior of interest.
For more details, refer to <a class="reference external" href="https://arxiv.org/abs/1601.00670">Variational Inference: A Review for Statisticians</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net_with_loss</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Cell with loss function.</p></li>
<li><p><strong>optimizer</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Optimizer for updating the weights.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mindspore.nn.probability.infer.SVI.get_train_loss">
<code class="sig-name descname">get_train_loss</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/infer/variational/svi.html#SVI.get_train_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.infer.SVI.get_train_loss" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>numpy.dtype, the loss after training.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.infer.SVI.run">
<code class="sig-name descname">run</code><span class="sig-paren">(</span><em class="sig-param">train_dataset</em>, <em class="sig-param">epochs=10</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/infer/variational/svi.html#SVI.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.infer.SVI.run" title="Permalink to this definition">¶</a></dt>
<dd><p>Optimize the parameters by training the probability network, and return the trained network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epochs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Total number of iterations on the data. Default: 10.</p></li>
<li><p><strong>train_dataset</strong> (<em>Dataset</em>) – A training dataset iterator.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Outputs:</dt><dd><p>Cell, the trained probability network.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindspore.nn.probability.infer.ELBO">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.infer.</code><code class="sig-name descname">ELBO</code><span class="sig-paren">(</span><em class="sig-param">latent_prior='Normal'</em>, <em class="sig-param">output_prior='Normal'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/infer/variational/elbo.html#ELBO"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.infer.ELBO" title="Permalink to this definition">¶</a></dt>
<dd><p>The Evidence Lower Bound (ELBO).</p>
<p>Variational inference minimizes the Kullback-Leibler (KL) divergence from the variational distribution to
the posterior distribution. It maximizes the ELBO, a lower bound on the logarithm of
the marginal probability of the observations log p(x). The ELBO is equal to the negative KL divergence up to
an additive constant.
For more details, refer to <a class="reference external" href="https://arxiv.org/abs/1601.00670">Variational Inference: A Review for Statisticians</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>latent_prior</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The prior distribution of latent space. Default: Normal.
- Normal: The prior distribution of latent space is Normal.</p></li>
<li><p><strong>output_prior</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The distribution of output data. Default: Normal.
- Normal: If the distribution of output data is Normal, the reconstruct loss is MSELoss.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>input_data</strong> (Tuple) - (recon_x(Tensor), x(Tensor), mu(Tensor), std(Tensor)).</p></li>
<li><p><strong>target_data</strong> (Tensor) - the target tensor of shape <span class="math notranslate nohighlight">\((N,)\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, loss float tensor.</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-mindspore.nn.probability.toolbox">
<span id="mindspore-nn-probability-toolbox"></span><h2>mindspore.nn.probability.toolbox<a class="headerlink" href="#module-mindspore.nn.probability.toolbox" title="Permalink to this headline">¶</a></h2>
<p>Uncertainty toolbox.</p>
<dl class="class">
<dt id="mindspore.nn.probability.toolbox.UncertaintyEvaluation">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.toolbox.</code><code class="sig-name descname">UncertaintyEvaluation</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">train_dataset</em>, <em class="sig-param">task_type</em>, <em class="sig-param">num_classes=None</em>, <em class="sig-param">epochs=1</em>, <em class="sig-param">epi_uncer_model_path=None</em>, <em class="sig-param">ale_uncer_model_path=None</em>, <em class="sig-param">save_model=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/toolbox/uncertainty_evaluation.html#UncertaintyEvaluation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.toolbox.UncertaintyEvaluation" title="Permalink to this definition">¶</a></dt>
<dd><p>Toolbox for Uncertainty Evaluation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The model for uncertainty evaluation.</p></li>
<li><p><strong>train_dataset</strong> (<em>Dataset</em>) – A dataset iterator to train model.</p></li>
<li><p><strong>task_type</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Option for the task types of model
- regression: A regression model.
- classification: A classification model.</p></li>
<li><p><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of labels of classification.
If the task type is classification, it must be set; otherwise, it is not needed.
Default: None.</p></li>
<li><p><strong>epochs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Total number of iterations on the data. Default: 1.</p></li>
<li><p><strong>epi_uncer_model_path</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The save or read path of the epistemic uncertainty model. Default: None.</p></li>
<li><p><strong>ale_uncer_model_path</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The save or read path of the aleatoric uncertainty model. Default: None.</p></li>
<li><p><strong>save_model</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to save the uncertainty model or not, if true, the epi_uncer_model_path
and ale_uncer_model_path must not be None. If false, the model to evaluate will be loaded from
the the path of the uncertainty model; if the path is not given , it will not save or load the
uncertainty model. Default: False.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s1">&#39;checkpoint_lenet.ckpt&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;workspace/mnist/train&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">evaluation</span> <span class="o">=</span> <span class="n">UncertaintyEvaluation</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">network</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                   <span class="n">train_dataset</span><span class="o">=</span><span class="n">ds_train</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                   <span class="n">task_type</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                   <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                   <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                   <span class="n">epi_uncer_model_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                   <span class="n">ale_uncer_model_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                   <span class="n">save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">epistemic_uncertainty</span> <span class="o">=</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">eval_epistemic_uncertainty</span><span class="p">(</span><span class="n">eval_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aleatoric_uncertainty</span> <span class="o">=</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">eval_aleatoric_uncertainty</span><span class="p">(</span><span class="n">eval_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">epistemic_uncertainty</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(32, 10)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aleatoric_uncertainty</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(32,)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore.nn.probability.toolbox.UncertaintyEvaluation.eval_aleatoric_uncertainty">
<code class="sig-name descname">eval_aleatoric_uncertainty</code><span class="sig-paren">(</span><em class="sig-param">eval_data</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/toolbox/uncertainty_evaluation.html#UncertaintyEvaluation.eval_aleatoric_uncertainty"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.toolbox.UncertaintyEvaluation.eval_aleatoric_uncertainty" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the aleatoric uncertainty of inference results, which also called data uncertainty.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>eval_data</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The data samples to be evaluated, the shape must be (N,C,H,W).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.dtype, the aleatoric uncertainty of inference results of data samples.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.toolbox.UncertaintyEvaluation.eval_epistemic_uncertainty">
<code class="sig-name descname">eval_epistemic_uncertainty</code><span class="sig-paren">(</span><em class="sig-param">eval_data</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/toolbox/uncertainty_evaluation.html#UncertaintyEvaluation.eval_epistemic_uncertainty"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.toolbox.UncertaintyEvaluation.eval_epistemic_uncertainty" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the epistemic uncertainty of inference results, which also called model uncertainty.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>eval_data</strong> (<a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The data samples to be evaluated, the shape must be (N,C,H,W).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>numpy.dtype, the epistemic uncertainty of inference results of data samples.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-mindspore.nn.probability.transforms">
<span id="mindspore-nn-probability-transforms"></span><h2>mindspore.nn.probability.transforms<a class="headerlink" href="#module-mindspore.nn.probability.transforms" title="Permalink to this headline">¶</a></h2>
<p>The high-level components used to transform model between Deep Neural Network (DNN) and Bayesian Neural Network (BNN).</p>
<dl class="class">
<dt id="mindspore.nn.probability.transforms.TransformToBNN">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.nn.probability.transforms.</code><code class="sig-name descname">TransformToBNN</code><span class="sig-paren">(</span><em class="sig-param">trainable_dnn</em>, <em class="sig-param">dnn_factor=1</em>, <em class="sig-param">bnn_factor=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/transforms/transform_bnn.html#TransformToBNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.transforms.TransformToBNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform Deep Neural Network (DNN) model to Bayesian Neural Network (BNN) model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainable_dnn</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – A trainable DNN model (backbone) wrapped by TrainOneStepCell.</p></li>
<li><p><strong>dnn_factor</strong> (<em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The coefficient of backbone’s loss, which is computed by loss function. Default: 1.</p></li>
<li><p><strong>bnn_factor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The coefficient of KL loss, which is KL divergence of Bayesian layer. Default: 1.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="o">*</span><span class="mi">224</span><span class="o">*</span><span class="mi">224</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span> <span class="c1"># padding=0</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">out</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">is_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">WithLossCell</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_network</span> <span class="o">=</span> <span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">net_with_loss</span><span class="p">,</span> <span class="n">optim</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bnn_transformer</span> <span class="o">=</span> <span class="n">TransformToBNN</span><span class="p">(</span><span class="n">train_network</span><span class="p">,</span> <span class="mi">60000</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore.nn.probability.transforms.TransformToBNN.transform_to_bnn_layer">
<code class="sig-name descname">transform_to_bnn_layer</code><span class="sig-paren">(</span><em class="sig-param">dnn_layer_type</em>, <em class="sig-param">bnn_layer_type</em>, <em class="sig-param">get_args=None</em>, <em class="sig-param">add_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/transforms/transform_bnn.html#TransformToBNN.transform_to_bnn_layer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.transforms.TransformToBNN.transform_to_bnn_layer" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform a specific type of layers in DNN model to corresponding BNN layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dnn_layer_type</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The type of DNN layer to be transformed to BNN layer. The optional values are
nn.Dense and nn.Conv2d.</p></li>
<li><p><strong>bnn_layer_type</strong> (<a class="reference internal" href="mindspore.nn.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The type of BNN layer to be transformed to. The optional values are
DenseReparam and ConvReparam.</p></li>
<li><p><strong>get_args</strong> – The arguments gotten from the DNN layer. Default: None.</p></li>
<li><p><strong>add_args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – The new arguments added to BNN layer. Note that the arguments in <cite>add_args</cite> must not
duplicate arguments in <cite>get_args</cite>. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Cell, a trainable model wrapped by TrainOneStepCell, whose specific type of layer is transformed to the
corresponding bayesian layer.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">is_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">WithLossCell</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_network</span> <span class="o">=</span> <span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">net_with_loss</span><span class="p">,</span> <span class="n">optim</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bnn_transformer</span> <span class="o">=</span> <span class="n">TransformToBNN</span><span class="p">(</span><span class="n">train_network</span><span class="p">,</span> <span class="mi">60000</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_bnn_network</span> <span class="o">=</span> <span class="n">bnn_transformer</span><span class="o">.</span><span class="n">transform_to_bnn_layer</span><span class="p">(</span><span class="n">Dense</span><span class="p">,</span> <span class="n">DenseReparam</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.nn.probability.transforms.TransformToBNN.transform_to_bnn_model">
<code class="sig-name descname">transform_to_bnn_model</code><span class="sig-paren">(</span><em class="sig-param">get_dense_args=&lt;function TransformToBNN.&lt;lambda&gt;&gt;</em>, <em class="sig-param">get_conv_args=&lt;function TransformToBNN.&lt;lambda&gt;&gt;</em>, <em class="sig-param">add_dense_args=None</em>, <em class="sig-param">add_conv_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/nn/probability/transforms/transform_bnn.html#TransformToBNN.transform_to_bnn_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.nn.probability.transforms.TransformToBNN.transform_to_bnn_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the whole DNN model to BNN model, and wrap BNN model by TrainOneStepCell.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>get_dense_args</strong> – The arguments gotten from the DNN full connection layer. Default: lambda dp:
{“in_channels”: dp.in_channels, “out_channels”: dp.out_channels, “has_bias”: dp.has_bias}.</p></li>
<li><p><strong>get_conv_args</strong> – The arguments gotten from the DNN convolutional layer. Default: lambda dp:
{“in_channels”: dp.in_channels, “out_channels”: dp.out_channels, “pad_mode”: dp.pad_mode,
“kernel_size”: dp.kernel_size, “stride”: dp.stride, “has_bias”: dp.has_bias}.</p></li>
<li><p><strong>add_dense_args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – The new arguments added to BNN full connection layer. Note that the arguments in
<cite>add_dense_args</cite> must not duplicate arguments in <cite>get_dense_args</cite>. Default: None.</p></li>
<li><p><strong>add_conv_args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – The new arguments added to BNN convolutional layer. Note that the arguments in
<cite>add_conv_args</cite> must not duplicate arguments in <cite>get_conv_args</cite>. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Cell, a trainable BNN model wrapped by TrainOneStepCell.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">is_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">WithLossCell</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_network</span> <span class="o">=</span> <span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">net_with_loss</span><span class="p">,</span> <span class="n">optim</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bnn_transformer</span> <span class="o">=</span> <span class="n">TransformToBNN</span><span class="p">(</span><span class="n">train_network</span><span class="p">,</span> <span class="mi">60000</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_bnn_network</span> <span class="o">=</span> <span class="n">bnn_transformer</span><span class="o">.</span><span class="n">transform_to_bnn_model</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="mindspore.ops.html" class="btn btn-neutral float-right" title="mindspore.ops" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="mindspore.nn.dynamic_lr.html" class="btn btn-neutral float-left" title="mindspore.nn.dynamic_lr" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, MindSpore

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>