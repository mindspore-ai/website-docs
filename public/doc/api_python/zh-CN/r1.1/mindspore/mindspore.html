<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore &mdash; MindSpore r1.1 documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="mindspore.common.initializer" href="mindspore.common.initializer.html" />
    <link rel="prev" title="MindSpore Python API" href="../index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">MindSpore Python API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.compression.html">mindspore.compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.explainer.html">mindspore.explainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.profiler.html">mindspore.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.train.html">mindspore.train</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindArmour Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.html">mindarmour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.attacks.html">mindarmour.adv_robustness.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.defenses.html">mindarmour.adv_robustness.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.detectors.html">mindarmour.adv_robustness.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.adv_robustness.evaluations.html">mindarmour.adv_robustness.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.fuzz_testing.html">mindarmour.fuzz_testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.privacy.diff_privacy.html">mindarmour.privacy.diff_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.privacy.evaluation.html">mindarmour.privacy.evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindarmour/mindarmour.utils.html">mindarmour.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindSpore Hub Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindspore_hub/mindspore_hub.html">mindspore_hub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindSpore Serving Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindspore_serving/mindspore_serving.html">mindspore_serving</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>mindspore</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/mindspore/mindspore.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mindspore">
<h1>mindspore<a class="headerlink" href="#mindspore" title="Permalink to this headline"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.dtype">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">dtype</span></span><a class="headerlink" href="#mindspore.dtype" title="Permalink to this definition"></a></dt>
<dd><p>Create a data type object of MindSpore.</p>
<p>The actual path of <code class="docutils literal notranslate"><span class="pre">dtype</span></code> is <code class="docutils literal notranslate"><span class="pre">/mindspore/common/dtype.py</span></code>.
Run the following command to import the package:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
</pre></div>
</div>
<ul>
<li><p><strong>Numeric Type</strong></p>
<p>Currently, MindSpore supports <code class="docutils literal notranslate"><span class="pre">Int</span></code> type, <code class="docutils literal notranslate"><span class="pre">Uint</span></code> type and <code class="docutils literal notranslate"><span class="pre">Float</span></code> type.
The following table lists the details.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 61%" />
<col style="width: 39%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Definition</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.int8</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.byte</span></code></p></td>
<td><p>8-bit integer</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.int16</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.short</span></code></p></td>
<td><p>16-bit integer</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.int32</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.intc</span></code></p></td>
<td><p>32-bit integer</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.int64</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.intp</span></code></p></td>
<td><p>64-bit integer</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.uint8</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.ubyte</span></code></p></td>
<td><p>unsigned 8-bit integer</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.uint16</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.ushort</span></code></p></td>
<td><p>unsigned 16-bit integer</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.uint32</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.uintc</span></code></p></td>
<td><p>unsigned 32-bit integer</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.uint64</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.uintp</span></code></p></td>
<td><p>unsigned 64-bit integer</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.float16</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.half</span></code></p></td>
<td><p>16-bit floating-point number</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.float32</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.single</span></code></p></td>
<td><p>32-bit floating-point number</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.float64</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.double</span></code></p></td>
<td><p>64-bit floating-point number</p></td>
</tr>
</tbody>
</table>
</li>
<li><p><strong>Other Type</strong></p>
<p>For other defined types, see the following table.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 85%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">tensor</span></code></p></td>
<td><p>MindSpore’s <code class="docutils literal notranslate"><span class="pre">tensor</span></code> type. Data format uses NCHW. For details, see <a class="reference external" href="https://www.gitee.com/mindspore/mindspore/blob/r1.1/mindspore/common/tensor.py">tensor</a>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">MetaTensor</span></code></p></td>
<td><p>A tensor only has data type and shape. For details, see <a class="reference external" href="https://www.gitee.com/mindspore/mindspore/blob/r1.1/mindspore/common/tensor.py">MetaTensor</a>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">bool_</span></code></p></td>
<td><p>Boolean <code class="docutils literal notranslate"><span class="pre">True</span></code> or <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">int_</span></code></p></td>
<td><p>Integer scalar.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">uint</span></code></p></td>
<td><p>Unsigned integer scalar.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">float_</span></code></p></td>
<td><p>Floating-point scalar.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">number</span></code></p></td>
<td><p>Number, including <code class="docutils literal notranslate"><span class="pre">int_</span></code> , <code class="docutils literal notranslate"><span class="pre">uint</span></code> , <code class="docutils literal notranslate"><span class="pre">float_</span></code> and <code class="docutils literal notranslate"><span class="pre">bool_</span></code> .</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">list_</span></code></p></td>
<td><p>List constructed by <code class="docutils literal notranslate"><span class="pre">tensor</span></code> , such as <code class="docutils literal notranslate"><span class="pre">List[T0,T1,...,Tn]</span></code> , where the element <code class="docutils literal notranslate"><span class="pre">Ti</span></code> can be of different types.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">tuple_</span></code></p></td>
<td><p>Tuple constructed by <code class="docutils literal notranslate"><span class="pre">tensor</span></code> , such as <code class="docutils literal notranslate"><span class="pre">Tuple[T0,T1,...,Tn]</span></code> , where the element <code class="docutils literal notranslate"><span class="pre">Ti</span></code> can be of different types.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">function</span></code></p></td>
<td><p>Function. Return in two ways, when function is not None, returns Func directly, the other returns Func(args: List[T0,T1,…,Tn], retval: T) when function is None.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">type_type</span></code></p></td>
<td><p>Type definition of type.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">type_none</span></code></p></td>
<td><p>No matching return type, corresponding to the <code class="docutils literal notranslate"><span class="pre">type(None)</span></code> in Python.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">symbolic_key</span></code></p></td>
<td><p>The value of a variable is used as a key of the variable in <code class="docutils literal notranslate"><span class="pre">env_type</span></code> .</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">env_type</span></code></p></td>
<td><p>Used to store the gradient of the free variable of a function, where the key is the <code class="docutils literal notranslate"><span class="pre">symbolic_key</span></code> of the free variable’s node and the value is the gradient.</p></td>
</tr>
</tbody>
</table>
</li>
<li><p><strong>Tree Topology</strong></p>
<p>The relationships of the above types are as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>└─────── number
    │   ├─── bool_
    │   ├─── int_
    │   │   ├─── int8, byte
    │   │   ├─── int16, short
    │   │   ├─── int32, intc
    │   │   └─── int64, intp
    │   ├─── uint
    │   │   ├─── uint8, ubyte
    │   │   ├─── uint16, ushort
    │   │   ├─── uint32, uintc
    │   │   └─── uint64, uintp
    │   └─── float_
    │       ├─── float16
    │       ├─── float32
    │       └─── float64
    ├─── tensor
    │   ├─── Array[Float32]
    │   └─── ...
    ├─── list_
    │   ├─── List[Int32,Float32]
    │   └─── ...
    ├─── tuple_
    │   ├─── Tuple[Int32,Float32]
    │   └─── ...
    ├─── function
    │   ├─── Func
    │   ├─── Func[(Int32, Float32), Int32]
    │   └─── ...
    ├─── MetaTensor
    ├─── type_type
    ├─── type_none
    ├─── symbolic_key
    └─── env_type
</pre></div>
</div>
</li>
</ul>
</dd></dl>

<span class="target" id="module-mindspore"></span><dl class="py class">
<dt class="sig sig-object py" id="mindspore.DatasetHelper">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">DatasetHelper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_sink_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sink_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DatasetHelper" title="Permalink to this definition"></a></dt>
<dd><p>DatasetHelper is a class to process the MindData dataset and it provides the information of dataset.</p>
<p>According to different contexts, change the iterations of dataset and use the same iteration for loop in different
contexts.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The iteration of DatasetHelper will provide one epoch data.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<em>DataSet</em>) – The training dataset iterator.</p></li>
<li><p><strong>dataset_sink_mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If true use GetNext to fetch the data, or else feed the data from host. Default: True.</p></li>
<li><p><strong>sink_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Control the amount of data in each sink.
If sink_size=-1, sink the complete dataset for each epoch.
If sink_size&gt;0, sink sink_size data for each epoch. Default: -1.</p></li>
<li><p><strong>epoch_num</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Control the number of epoch data to send. Default: 1.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">WithLossCell</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset_helper</span> <span class="o">=</span> <span class="n">DatasetHelper</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">next_element</span> <span class="ow">in</span> <span class="n">dataset_helper</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">outputs</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="o">*</span><span class="n">next_element</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DatasetHelper.continue_send">
<span class="sig-name descname"><span class="pre">continue_send</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.continue_send"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DatasetHelper.continue_send" title="Permalink to this definition"></a></dt>
<dd><p>continue send data to device at the beginning of epoch.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DatasetHelper.release">
<span class="sig-name descname"><span class="pre">release</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.release"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DatasetHelper.release" title="Permalink to this definition"></a></dt>
<dd><p>Free up resources about data sink.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DatasetHelper.sink_size">
<span class="sig-name descname"><span class="pre">sink_size</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.sink_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DatasetHelper.sink_size" title="Permalink to this definition"></a></dt>
<dd><p>Get sink_size for each iteration.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DatasetHelper.stop_send">
<span class="sig-name descname"><span class="pre">stop_send</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.stop_send"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DatasetHelper.stop_send" title="Permalink to this definition"></a></dt>
<dd><p>stop send data about data sink.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DatasetHelper.types_shapes">
<span class="sig-name descname"><span class="pre">types_shapes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.types_shapes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DatasetHelper.types_shapes" title="Permalink to this definition"></a></dt>
<dd><p>Get the types and shapes from dataset on the current configuration.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.DynamicLossScaleManager">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">DynamicLossScaleManager</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">init_loss_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16777216</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_window</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DynamicLossScaleManager" title="Permalink to this definition"></a></dt>
<dd><p>Dynamic loss-scale manager.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init_loss_scale</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Initialize loss scale. Default: 2**24.</p></li>
<li><p><strong>scale_factor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Coefficient of increase and decrease. Default: 2.</p></li>
<li><p><strong>scale_window</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Maximum continuous normal steps when there is no overflow. Default: 2000.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">DynamicLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DynamicLossScaleManager.get_drop_overflow_update">
<span class="sig-name descname"><span class="pre">get_drop_overflow_update</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager.get_drop_overflow_update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DynamicLossScaleManager.get_drop_overflow_update" title="Permalink to this definition"></a></dt>
<dd><p>Get the flag whether to drop optimizer update when there is an overflow.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DynamicLossScaleManager.get_loss_scale">
<span class="sig-name descname"><span class="pre">get_loss_scale</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager.get_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DynamicLossScaleManager.get_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Get loss scale value.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DynamicLossScaleManager.get_update_cell">
<span class="sig-name descname"><span class="pre">get_update_cell</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager.get_update_cell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DynamicLossScaleManager.get_update_cell" title="Permalink to this definition"></a></dt>
<dd><p>Returns the cell for <cite>TrainOneStepWithLossScaleCell</cite></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.DynamicLossScaleManager.update_loss_scale">
<span class="sig-name descname"><span class="pre">update_loss_scale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overflow</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager.update_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.DynamicLossScaleManager.update_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Update loss scale value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>overflow</strong> – Boolean. Whether it overflows.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.FixedLossScaleManager">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">FixedLossScaleManager</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_overflow_update</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.FixedLossScaleManager" title="Permalink to this definition"></a></dt>
<dd><p>Fixed loss-scale manager.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss_scale</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Loss scale. Default: 128.0.</p></li>
<li><p><strong>drop_overflow_update</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – whether to execute optimizer if there is an overflow. Default: True.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.FixedLossScaleManager.get_drop_overflow_update">
<span class="sig-name descname"><span class="pre">get_drop_overflow_update</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager.get_drop_overflow_update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.FixedLossScaleManager.get_drop_overflow_update" title="Permalink to this definition"></a></dt>
<dd><p>Get the flag whether to drop optimizer update when there is an overflow.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.FixedLossScaleManager.get_loss_scale">
<span class="sig-name descname"><span class="pre">get_loss_scale</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager.get_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.FixedLossScaleManager.get_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Get loss scale value.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.FixedLossScaleManager.get_update_cell">
<span class="sig-name descname"><span class="pre">get_update_cell</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager.get_update_cell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.FixedLossScaleManager.get_update_cell" title="Permalink to this definition"></a></dt>
<dd><p>Returns the cell for <cite>TrainOneStepWithLossScaleCell</cite></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.FixedLossScaleManager.update_loss_scale">
<span class="sig-name descname"><span class="pre">update_loss_scale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overflow</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager.update_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.FixedLossScaleManager.update_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Update loss scale value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>overflow</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether it overflows.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.LossScaleManager">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">LossScaleManager</span></span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#LossScaleManager"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.LossScaleManager" title="Permalink to this definition"></a></dt>
<dd><p>Loss scale manager abstract class.</p>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.LossScaleManager.get_loss_scale">
<span class="sig-name descname"><span class="pre">get_loss_scale</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#LossScaleManager.get_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.LossScaleManager.get_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Get loss scale value.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.LossScaleManager.get_update_cell">
<span class="sig-name descname"><span class="pre">get_update_cell</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#LossScaleManager.get_update_cell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.LossScaleManager.get_update_cell" title="Permalink to this definition"></a></dt>
<dd><p>Get the loss scaling update logic cell.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.LossScaleManager.update_loss_scale">
<span class="sig-name descname"><span class="pre">update_loss_scale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overflow</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#LossScaleManager.update_loss_scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.LossScaleManager.update_loss_scale" title="Permalink to this definition"></a></dt>
<dd><p>Update loss scale value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>overflow</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether it overflows.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.MetaTensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">MetaTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#MetaTensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.MetaTensor" title="Permalink to this definition"></a></dt>
<dd><p>The base class of the MetaTensor.
Initialization of tensor basic attributes and model weight values.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Array, an array after being initialized.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.MetaTensor.to_tensor">
<span class="sig-name descname"><span class="pre">to_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">slice_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt_shard_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#MetaTensor.to_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.MetaTensor.to_tensor" title="Permalink to this definition"></a></dt>
<dd><p>Get the tensor format data of this MetaTensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>slice_index</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Slice index of a parameter’s slices.
It is used when initialize a slice of a parameter, it guarantees that devices
using the same slice can generate the same tensor.</p></li>
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – Shape of the slice, it is used when initialize a slice of the parameter.</p></li>
<li><p><strong>opt_shard_group</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Optimizer shard group which is used in auto or semi auto parallel mode
to get one shard of a parameter’s slice.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.Model">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">Model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_network</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_indexes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amp_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'O0'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/model.html#Model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Model" title="Permalink to this definition"></a></dt>
<dd><p>High-Level API for Training or Testing.</p>
<p><cite>Model</cite> groups layers into an object with training and inference features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – A training or testing network.</p></li>
<li><p><strong>loss_fn</strong> (<em>Cell</em>) – Objective function, if loss_fn is None, the
network should contain the logic of loss and grads calculation, and the logic
of parallel if needed. Default: None.</p></li>
<li><p><strong>optimizer</strong> (<em>Cell</em>) – Optimizer for updating the weights. Default: None.</p></li>
<li><p><strong>metrics</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#set" title="(in Python v3.8)"><em>set</em></a><em>]</em>) – A Dictionary or a set of metrics to be evaluated by the model during
training and testing. eg: {‘accuracy’, ‘recall’}. Default: None.</p></li>
<li><p><strong>eval_network</strong> (<em>Cell</em>) – Network for evaluation. If not defined, <cite>network</cite> and <cite>loss_fn</cite> would be wrapped as
<cite>eval_network</cite>. Default: None.</p></li>
<li><p><strong>eval_indexes</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – When defining the <cite>eval_network</cite>, if <cite>eval_indexes</cite> is None, all outputs of the
<cite>eval_network</cite> would be passed to metrics, otherwise <cite>eval_indexes</cite> must contain three
elements, including the positions of loss value, predicted value and label. The loss
value would be passed to the <cite>Loss</cite> metric, the predicted value and label would be passed
to other metric. Default: None.</p></li>
<li><p><strong>amp_level</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>Option for argument <cite>level</cite> in <cite>mindspore.amp.build_train_network</cite>, level for mixed
precision training. Supports [“O0”, “O2”, “O3”, “auto”]. Default: “O0”.</p>
<ul>
<li><p>O0: Do not change.</p></li>
<li><p>O2: Cast network to float16, keep batchnorm run in float32, using dynamic loss scale.</p></li>
<li><p>O3: Cast network to float16, with additional property ‘keep_batchnorm_fp32=False’.</p></li>
<li><p>auto: Set to level to recommended level in different devices. Set level to O2 on GPU, Set
level to O3 Ascend. The recommended level is choose by the export experience, cannot
always generalize. User should specify the level for special network.</p></li>
</ul>
<p>O2 is recommended on GPU, O3 is recommended on Ascend.</p>
</p></li>
<li><p><strong>loss_scale_manager</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference internal" href="#mindspore.LossScaleManager" title="mindspore.LossScaleManager"><em>LossScaleManager</em></a><em>]</em>) – If it is None, the loss would not be scaled. Otherwise,
scale the loss by LossScaleManager and optimizer can not be None.It is a key argument.
e.g. Use <cite>loss_scale_manager=None</cite> to set the value.</p></li>
<li><p><strong>keep_batchnorm_fp32</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Keep Batchnorm running in <cite>float32</cite>. If it is set to true, the level setting before
will be overwritten. Default: True.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_class</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">num_channel</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="o">*</span><span class="mi">5</span><span class="o">*</span><span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;ones&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;ones&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="n">num_class</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;ones&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">x</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># For details about how to build the dataset, please refer to the tutorial document on the official website.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Model.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">valid_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_sink_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/model.html#Model.eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Model.eval" title="Permalink to this definition"></a></dt>
<dd><p>Evaluation API where the iteration is controlled by python front-end.</p>
<p>Configure to pynative mode or CPU, the evaluating process will be performed with dataset non-sink mode.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If dataset_sink_mode is True, data will be sent to device. If device is Ascend, features
of data will be transferred one by one. The limitation of data transmission per time is 256M.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>valid_dataset</strong> (<em>Dataset</em>) – Dataset to evaluate the model.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – List of callback objects which should be executed while training. Default: None.</p></li>
<li><p><strong>dataset_sink_mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Determines whether to pass the data through dataset channel. Default: True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict, which returns the loss value and metrics values for the model in the test mode.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Model.infer_predict_layout">
<span class="sig-name descname"><span class="pre">infer_predict_layout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">predict_data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/model.html#Model.infer_predict_layout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Model.infer_predict_layout" title="Permalink to this definition"></a></dt>
<dd><p>Generate parameter layout for the predict network in auto or semi auto parallel mode.</p>
<p>Data could be a single tensor or multiple tensors.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Batch data should be put together in one tensor.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>predict_data</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – One tensor or multiple tensors of predict data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Parameter layout dictionary used for load distributed checkpoint</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>parameter_layout_dict (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)">dict</a>)</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">full_batch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parallel_mode</span><span class="o">=</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">SEMI_AUTO_PARALLEL</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">Net</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">infer_predict_layout</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Model.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">predict_data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/model.html#Model.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Model.predict" title="Permalink to this definition"></a></dt>
<dd><p>Generate output predictions for the input samples.</p>
<p>Data could be a single tensor, a list of tensor, or a tuple of tensor.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Batch data should be put together in one tensor.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>predict_data</strong> – The predict data, can be bool, int, float, str, None, tensor,
or tuple, list and dict that store these types.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, array(s) of predictions.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">Net</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Model.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_sink_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sink_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/model.html#Model.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Model.train" title="Permalink to this definition"></a></dt>
<dd><p>Training API where the iteration is controlled by python front-end.</p>
<p>When setting pynative mode or CPU, the training process will be performed with dataset not sink.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If dataset_sink_mode is True, data will be sent to device. If device is Ascend, features
of data will be transferred one by one. The limitation of data transmission per time is 256M.
If sink_size &gt; 0, each epoch the dataset can be traversed unlimited times until you get sink_size
elements of the dataset. Next epoch continues to traverse from the end position of the previous traversal.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Generally, total number of iterations on the data per epoch.
When dataset_sink_mode is set to true and sink_size&gt;0, each epoch sink sink_size
steps on the data instead of total number of iterations.</p></li>
<li><p><strong>train_dataset</strong> (<em>Dataset</em>) – A training dataset iterator. If there is no
loss_fn, a tuple with multiple data (data1, data2, data3, …) should be
returned and passed to the network. Otherwise, a tuple (data, label) should
be returned. The data and label would be passed to the network and loss
function respectively.</p></li>
<li><p><strong>callbacks</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – List of callback objects which should be executed while training. Default: None.</p></li>
<li><p><strong>dataset_sink_mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Determines whether to pass the data through dataset channel. Default: True.
Configure pynative mode or CPU, the training process will be performed with
dataset not sink.</p></li>
<li><p><strong>sink_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Control the amount of data in each sink.
If sink_size = -1, sink the complete dataset for each epoch.
If sink_size &gt; 0, sink sink_size data for each epoch.
If dataset_sink_mode is False, set sink_size as invalid. Default: -1.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.loss_scale_manager</span> <span class="kn">import</span> <span class="n">FixedLossScaleManager</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.Parameter">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">Parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">default_input</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#Parameter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Parameter" title="Permalink to this definition"></a></dt>
<dd><p>Parameter types of cell models.</p>
<p>After initialized <cite>Parameter</cite> is a subtype of <cite>Tensor</cite>.</p>
<p>In auto_parallel mode of  “semi_auto_parallel” and “auto_parallel”, if init <cite>Parameter</cite> by
an <cite>MetaTensor</cite>, the type of Parameter will be <cite>MetaTensor</cite> not <cite>Tensor</cite>. <cite>MetaTensor_</cite>
only saves the shape and type info of a tensor with no memory usage. The shape can be changed while
compiling for auto-parallel. Call <cite>init_data</cite> will return a Tensor Parameter with initialized data.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Each parameter of Cell is represented by Parameter class.
A Parameter has to belong to a Cell.
If there is an operator in the network that requires part of the inputs to be Parameter,
then the Parameters as this part of the inputs are not allowed to be cast.
It is recommended to use the default value of <cite>name</cite> when initialize a parameter as one attribute of a cell,
otherwise, the parameter name may be different than expected.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>default_input</strong> (<em>Union</em><em>[</em><a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference internal" href="#mindspore.MetaTensor" title="mindspore.MetaTensor"><em>MetaTensor</em></a><em>, </em><em>Number</em><em>]</em>) – Parameter data, to be set initialized.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Name of the child parameter. Default: None.</p></li>
<li><p><strong>requires_grad</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – True if the parameter requires gradient. Default: True.</p></li>
<li><p><strong>layerwise_parallel</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – A kind of model parallel mode. When layerwise_parallel is true in parallel mode,
broadcast and gradients communication would not be applied to parameters. Default: False.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.common</span> <span class="kn">import</span> <span class="n">initializer</span> <span class="k">as</span> <span class="n">init</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Cell</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">matmul</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">MatMul</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="go">[[2.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))))</span>
<span class="go">Parameter (name=w)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="go">[[0.]]</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Parameter.clone">
<span class="sig-name descname"><span class="pre">clone</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'same'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#Parameter.clone"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Parameter.clone" title="Permalink to this definition"></a></dt>
<dd><p>Clone the parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>init</strong> (<em>Union</em><em>[</em><a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference internal" href="#mindspore.MetaTensor" title="mindspore.MetaTensor"><em>MetaTensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/numbers.html#numbers.Number" title="(in Python v3.8)"><em>numbers.Number</em></a><em>]</em>) – Initialize the shape of the parameter.
Default: ‘same’.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Parameter, a new parameter.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Parameter.init_data">
<span class="sig-name descname"><span class="pre">init_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">set_sliced</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#Parameter.init_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Parameter.init_data" title="Permalink to this definition"></a></dt>
<dd><p>Initialize the parameter data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layout</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – <p>Parameter slice layout [dev_mat, tensor_map, slice_shape].</p>
<ul>
<li><p>dev_mat (list[int]): Device matrix.</p></li>
<li><p>tensor_map (list[int]): Tensor map.</p></li>
<li><p>slice_shape (list[int]): Shape of slice.</p></li>
</ul>
</p></li>
<li><p><strong>set_sliced</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – True if the parameter is set sliced after initializing the data.
Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – If it is from Initializer, and parallel mode has changed after the Initializer created.</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Parameter, the <cite>Parameter</cite> after initializing data. If current <cite>Parameter</cite> was already initialized before,
returns the same initialized <cite>Parameter</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.inited_param">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">inited_param</span></span><a class="headerlink" href="#mindspore.Parameter.inited_param" title="Permalink to this definition"></a></dt>
<dd><p>Get the new parameter after call the init_data.</p>
<p>Default is a None, If <cite>self</cite> is a Parameter with out data, after call the
<cite>init_data</cite> the initialized Parameter with data will be recorded here.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.is_init">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_init</span></span><a class="headerlink" href="#mindspore.Parameter.is_init" title="Permalink to this definition"></a></dt>
<dd><p>Get the initialization status of the parameter.</p>
<p>In GE backend, the Parameter need a “init graph” to sync the data from host to device.
This flag indicates whether the data as been sync to the device.</p>
<p>This flag only work in GE, and it will be set to False in other backend.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.name">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#mindspore.Parameter.name" title="Permalink to this definition"></a></dt>
<dd><p>Get the name of the parameter.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.requires_grad">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">requires_grad</span></span><a class="headerlink" href="#mindspore.Parameter.requires_grad" title="Permalink to this definition"></a></dt>
<dd><p>Return whether the parameter requires gradient.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Parameter.set_data">
<span class="sig-name descname"><span class="pre">set_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">slice_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#Parameter.set_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Parameter.set_data" title="Permalink to this definition"></a></dt>
<dd><p>Set <cite>set_data</cite> of current <cite>Parameter</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>Union</em><em>[</em><a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference internal" href="#mindspore.MetaTensor" title="mindspore.MetaTensor"><em>MetaTensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – new data.</p></li>
<li><p><strong>slice_shape</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If slice the parameter is set to true, the shape is not checked for consistency.
Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Parameter, the parameter after set data.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Parameter.set_param_ps">
<span class="sig-name descname"><span class="pre">set_param_ps</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">init_in_server</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#Parameter.set_param_ps"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Parameter.set_param_ps" title="Permalink to this definition"></a></dt>
<dd><p>Set whether the trainable parameter is updated by parameter server and whether the
trainable parameter is initialized on server.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It only works when a running task is in the parameter server mode.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>init_in_server</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether trainable parameter updated by parameter server is
initialized on server. Default: False.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.sliced">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sliced</span></span><a class="headerlink" href="#mindspore.Parameter.sliced" title="Permalink to this definition"></a></dt>
<dd><p>Get slice status of the parameter.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.unique">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">unique</span></span><a class="headerlink" href="#mindspore.Parameter.unique" title="Permalink to this definition"></a></dt>
<dd><p>whether the parameter is already unique or not.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ParameterTuple">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">ParameterTuple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">iterable</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#ParameterTuple"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ParameterTuple" title="Permalink to this definition"></a></dt>
<dd><p>Class for storing tuple of parameters.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is used to store the parameters of the network into the parameter tuple collection.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.ParameterTuple.clone">
<span class="sig-name descname"><span class="pre">clone</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'same'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#ParameterTuple.clone"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ParameterTuple.clone" title="Permalink to this definition"></a></dt>
<dd><p>Clone the parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Namespace of parameter.</p></li>
<li><p><strong>init</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Initialize the shape of the parameter. Default: ‘same’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple, the new Parameter tuple.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.RowTensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">RowTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dense_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#RowTensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.RowTensor" title="Permalink to this definition"></a></dt>
<dd><p>A sparse representation of a set of tensor slices at given indices.</p>
<p>An RowTensor is typically used to represent a subset of a larger
tensor dense of shape [L0, D1, .. , DN] where L0 &gt;&gt; D0.</p>
<p>The values in indices are the indices in the first dimension of the slices
that have been extracted from the larger tensor.</p>
<p>The dense tensor dense represented by an RowTensor slices has
<cite>dense[slices.indices[i], :, :, :, …] = slices.values[i, :, :, :, …]</cite>.</p>
<p>RowTensor can only be used in the <cite>Cell</cite>’s construct method.</p>
<p>It is not supported in pynative mode at the moment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A 1-D integer Tensor of shape [D0].</p></li>
<li><p><strong>values</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A Tensor of any dtype of shape [D0, D1, …, Dn].</p></li>
<li><p><strong>dense_shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – An integer tuple which contains the shape
of the corresponding dense tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>RowTensor, composed of <cite>indices</cite>, <cite>values</cite>, and <cite>dense_shape</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dense_shape</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">dense_shape</span> <span class="o">=</span> <span class="n">dense_shape</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="n">RowTensor</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dense_shape</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">values</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">Net</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="go">[[1. 2.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="go">[0]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="go">(3, 2)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.SparseTensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">SparseTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dense_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#SparseTensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.SparseTensor" title="Permalink to this definition"></a></dt>
<dd><p>A sparse representation of a set of nonzero elememts from a tensor at given indices.</p>
<p>SparseTensor can only be used in the <cite>Cell</cite>’s construct method.</p>
<p>Pynative mode not supported at the moment.</p>
<p>For a tensor dense, its SparseTensor(indices, values, dense_shape) has
<cite>dense[indices[i]] = values[i]</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A 2-D integer Tensor of shape <cite>[N, ndims]</cite>,
where N and ndims are the number of values and number of dimensions in
the SparseTensor, respectively.</p></li>
<li><p><strong>values</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A 1-D tensor of any type and shape <cite>[N]</cite>, which
supplies the values for each element in indices.</p></li>
<li><p><strong>dense_shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – A integer tuple of size <cite>ndims</cite>,
which specifies the dense_shape of the sparse tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>SparseTensor, composed of <cite>indices</cite>, <cite>values</cite>, and <cite>dense_shape</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dense_shape</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">dense_shape</span> <span class="o">=</span> <span class="n">dense_shape</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dense_shape</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">values</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">Net</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="go">[1. 2.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="go">[[0 1]</span>
<span class="go"> [1 2]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="go">(3, 4)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.Tensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">Tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor" title="Permalink to this definition"></a></dt>
<dd><p>Tensor is used for data storage.</p>
<p>Tensor inherits tensor object in C++.
Some functions are implemented in C++ and some functions are implemented in Python.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_data</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Input data of the tensor.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – Input data should be None, bool or numeric type defined in <cite>mindspore.dtype</cite>.
The argument is used to define the data type of the output tensor. If it is None, the data type of the
output tensor will be as same as the <cite>input_data</cite>. Default: None.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Outputs:</dt><dd><p>Tensor, with the same shape as <cite>input_data</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize a tensor with input data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t1</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">t1</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">t1</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize a tensor with a float scalar</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t2</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">t2</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">t2</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float64</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.abs">
<span class="sig-name descname"><span class="pre">abs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.abs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.abs" title="Permalink to this definition"></a></dt>
<dd><p>Return absolute value element-wisely.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Tensor, has the same data type as x.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.all">
<span class="sig-name descname"><span class="pre">all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.all"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.all" title="Permalink to this definition"></a></dt>
<dd><p>Check all array elements along a given axis evaluate to True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em>) – Dimensions of reduction,
when axis is None or empty tuple, reduce all dimensions.
Default: (), reduce all dimensions.</p></li>
<li><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to keep the reduced dimensions.
Default : False, don’t keep these reduced dimensions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same data type as x.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.any">
<span class="sig-name descname"><span class="pre">any</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.any"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.any" title="Permalink to this definition"></a></dt>
<dd><p>Check any array element along a given axis evaluate to True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em>) – Dimensions of reduction,
when axis is None or empty tuple, reduce all dimensions.
Default: (), reduce all dimensions.</p></li>
<li><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to keep the reduced dimensions.
Default : False, don’t keep these reduced dimensions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same data type as x.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.asnumpy">
<span class="sig-name descname"><span class="pre">asnumpy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.asnumpy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.asnumpy" title="Permalink to this definition"></a></dt>
<dd><p>Convert tensor to numpy array.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Tensor.dtype">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><a class="headerlink" href="#mindspore.Tensor.dtype" title="Permalink to this definition"></a></dt>
<dd><p>The dtype of tensor is a mindspore type.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.expand_as">
<span class="sig-name descname"><span class="pre">expand_as</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.expand_as"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.expand_as" title="Permalink to this definition"></a></dt>
<dd><p>Expand the dimension of target tensor to the dimension of input tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shape</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The input tensor. The shape of input tensor must obey
the broadcasting rule.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same dimension as input tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.from_numpy">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_numpy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">array</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.from_numpy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.from_numpy" title="Permalink to this definition"></a></dt>
<dd><p>Convert numpy array to Tensor without copy data.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.mean">
<span class="sig-name descname"><span class="pre">mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.mean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.mean" title="Permalink to this definition"></a></dt>
<dd><p>Reduces a dimension of a tensor by averaging all elements in the dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>]</em>) – Dimensions of reduction,
when axis is None or empty tuple, reduce all dimensions.
Default: (), reduce all dimensions.</p></li>
<li><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to keep the reduced dimensions.
Default : False, don’t keep these reduced dimensions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same data type as x.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Tensor.ndim">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ndim</span></span><a class="headerlink" href="#mindspore.Tensor.ndim" title="Permalink to this definition"></a></dt>
<dd><p>The ndim of tensor is an integer.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Tensor.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#mindspore.Tensor.shape" title="Permalink to this definition"></a></dt>
<dd><p>The shape of tensor is a tuple.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Tensor.size">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">size</span></span><a class="headerlink" href="#mindspore.Tensor.size" title="Permalink to this definition"></a></dt>
<dd><p>The size reflects the total number of elements in tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Tensor.view">
<span class="sig-name descname"><span class="pre">view</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.view"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Tensor.view" title="Permalink to this definition"></a></dt>
<dd><p>Reshape the tensor according to the input shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shape</strong> (<em>Union</em><em>(</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>, </em><em>*int</em><em>)</em>) – Dimension of the output tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same dimension as the input shape.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Tensor.virtual_flag">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">virtual_flag</span></span><a class="headerlink" href="#mindspore.Tensor.virtual_flag" title="Permalink to this definition"></a></dt>
<dd><p>Mark tensor is virtual.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.build_searched_strategy">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">build_searched_strategy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">strategy_filename</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#build_searched_strategy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.build_searched_strategy" title="Permalink to this definition"></a></dt>
<dd><p>Build strategy of every parameter in network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>strategy_filename</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Name of strategy file.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dictionary, whose key is parameter name and value is slice strategy of this parameter.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Strategy file is incorrect.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – Strategy_filename is not str.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.build_train_network">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">build_train_network</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'O0'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/amp.html#build_train_network"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.build_train_network" title="Permalink to this definition"></a></dt>
<dd><p>Build the mixed precision training cell automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Definition of the network.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><em>Cell</em><em>]</em>) – Definition of the loss_fn. If None, the <cite>network</cite> should have the loss inside.
Default: None.</p></li>
<li><p><strong>optimizer</strong> (<em>Optimizer</em>) – Optimizer to update the Parameter.</p></li>
<li><p><strong>level</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>Supports [“O0”, “O2”, “O3”, “auto”]. Default: “O0”.</p>
<ul>
<li><p>O0: Do not change.</p></li>
<li><p>O2: Cast network to float16, keep batchnorm and <cite>loss_fn</cite> (if set) run in float32,
using dynamic loss scale.</p></li>
<li><p>O3: Cast network to float16, with additional property ‘keep_batchnorm_fp32=False’.</p></li>
<li><p>auto: Set to level to recommended level in different devices. Set level to O2 on GPU, Set
level to O3 Ascend. The recommended level is choose by the export experience, cannot
always generalize. User should specify the level for special network.</p></li>
</ul>
<p>O2 is recommended on GPU, O3 is recommended on Ascend.</p>
</p></li>
<li><p><strong>cast_model_type</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – Supports <cite>mstype.float16</cite> or <cite>mstype.float32</cite>.
If set to <cite>mstype.float16</cite>, use <cite>float16</cite> mode to train. If set, overwrite the level setting.</p></li>
<li><p><strong>keep_batchnorm_fp32</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Keep Batchnorm run in <cite>float32</cite>. If set, overwrite the level setting.
Only <cite>cast_model_type</cite> is <cite>float16</cite>, <cite>keep_batchnorm_fp32</cite> will take effect.</p></li>
<li><p><strong>loss_scale_manager</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference internal" href="#mindspore.LossScaleManager" title="mindspore.LossScaleManager"><em>LossScaleManager</em></a><em>]</em>) – If None, not scale the loss, or else
scale the loss by LossScaleManager. If set, overwrite the level setting.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.connect_network_with_dataset">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">connect_network_with_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_helper</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#connect_network_with_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.connect_network_with_dataset" title="Permalink to this definition"></a></dt>
<dd><p>Connect the <cite>network</cite> with dataset in <cite>dataset_helper</cite>.</p>
<p>This function wraps the input network with ‘GetNext’ so that the data can be fetched automatically from the
data channel corresponding to the ‘queue_name’ and passed to the input network during forward computation.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In the case of running the network on Ascend/GPU in graph mode, this function will wrap the input network with
‘GetNext’, in other cases, the input network will be returned with no change.
The ‘GetNext’ is required to get data only in sink mode, so this function is not applicable to no-sink mode.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – The training network for dataset.</p></li>
<li><p><strong>dataset_helper</strong> (<a class="reference internal" href="#mindspore.DatasetHelper" title="mindspore.DatasetHelper"><em>DatasetHelper</em></a>) – A class to process the MindData dataset, it provides the type, shape and queue
name of the dataset to wrap the <cite>GetNext</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Outputs:</dt><dd><p>Cell, a new network wrapped with ‘GetNext’ in the case of running the task on Ascend in graph mode, otherwise
it is the input network.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># call create_dataset function to create a regular dataset, refer to mindspore.dataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset_helper</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">DatasetHelper</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_with_get_next</span> <span class="o">=</span> <span class="n">connect_network_with_dataset</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">dataset_helper</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.dtype_to_nptype">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">dtype_to_nptype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">type_</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/dtype.html#dtype_to_nptype"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dtype_to_nptype" title="Permalink to this definition"></a></dt>
<dd><p>Convert MindSpore dtype to numpy data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>type</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – MindSpore’s dtype.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The data type of numpy.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.dtype_to_pytype">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">dtype_to_pytype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">type_</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/dtype.html#dtype_to_pytype"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.dtype_to_pytype" title="Permalink to this definition"></a></dt>
<dd><p>Convert MindSpore dtype to python data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>type</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – MindSpore’s dtype.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Type of python.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.export">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">export</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">net</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'AIR'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#export"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.export" title="Permalink to this definition"></a></dt>
<dd><p>Export the MindSpore prediction model to a file in the specified format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net</strong> (<em>Cell</em>) – MindSpore network.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – Inputs of the <cite>net</cite>.</p></li>
<li><p><strong>file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – File name of the model to be exported.</p></li>
<li><p><strong>file_format</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>MindSpore currently supports ‘AIR’, ‘ONNX’ and ‘MINDIR’ format for exported model.</p>
<ul>
<li><p>AIR: Ascend Intermediate Representation. An intermediate representation format of Ascend model.
Recommended suffix for output file is ‘.air’.</p></li>
<li><p>ONNX: Open Neural Network eXchange. An open format built to represent machine learning models.
Recommended suffix for output file is ‘.onnx’.</p></li>
<li><p>MINDIR: MindSpore Native Intermediate Representation for Anf. An intermediate representation format
for MindSpore models.
Recommended suffix for output file is ‘.mindir’.</p></li>
</ul>
</p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – <p>Configuration options dictionary.</p>
<ul>
<li><p>quant_mode: The mode of quant.</p></li>
<li><p>mean: Input data mean. Default: 127.5.</p></li>
<li><p>std_dev: Input data variance. Default: 127.5.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.get_level">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">get_level</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/log.html#get_level"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.get_level" title="Permalink to this definition"></a></dt>
<dd><p>Get the logger level.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>str, the Log level includes 3(ERROR), 2(WARNING), 1(INFO), 0(DEBUG).</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">os</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;GLOG_v&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;0&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">log</span> <span class="k">as</span> <span class="n">logger</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logger</span><span class="o">.</span><span class="n">get_level</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.get_log_config">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">get_log_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/log.html#get_log_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.get_log_config" title="Permalink to this definition"></a></dt>
<dd><p>Get logger configurations.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dict, the dictionary of logger configurations.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">os</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;GLOG_v&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;1&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;GLOG_logtostderr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;0&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;GLOG_log_dir&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;/var/log/mindspore&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;logger_maxBytes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;5242880&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;logger_backupCount&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;10&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">log</span> <span class="k">as</span> <span class="n">logger</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logger</span><span class="o">.</span><span class="n">get_log_config</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.get_py_obj_dtype">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">get_py_obj_dtype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/dtype.html#get_py_obj_dtype"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.get_py_obj_dtype" title="Permalink to this definition"></a></dt>
<dd><p>Get the MindSpore data type which corresponds to python type or variable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>obj</strong> – An object of python type, or a variable in python type.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Type of MindSpore type.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.get_seed">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">get_seed</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/seed.html#get_seed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.get_seed" title="Permalink to this definition"></a></dt>
<dd><p>Get global random seed.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.issubclass_">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">issubclass_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">type_</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/dtype.html#issubclass_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.issubclass_" title="Permalink to this definition"></a></dt>
<dd><p>Determine whether <cite>type_</cite> is a subclass of <cite>dtype</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>type</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – Target MindSpore dtype.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – Compare MindSpore dtype.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>bool, True or False.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.load_checkpoint">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">load_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_file_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict_load</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#load_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.load_checkpoint" title="Permalink to this definition"></a></dt>
<dd><p>Loads checkpoint info from a specified file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Checkpoint file name.</p></li>
<li><p><strong>net</strong> (<em>Cell</em>) – Cell network. Default: None</p></li>
<li><p><strong>strict_load</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to strict load the parameter into net. If False, it will load parameter
in the param_dict into net with the same suffix. Default: False</p></li>
<li><p><strong>filter_prefix</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em><em>]</em>) – Parameters starting with the filter_prefix
will not be loaded. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict, key is parameter name, value is a Parameter.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Checkpoint file is incorrect.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ckpt_file_name</span> <span class="o">=</span> <span class="s2">&quot;./checkpoint/LeNet5-1_32.ckpt&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">ckpt_file_name</span><span class="p">,</span> <span class="n">filter_prefix</span><span class="o">=</span><span class="s2">&quot;conv1&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.load_distributed_checkpoint">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">load_distributed_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">checkpoint_filenames</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predict_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#load_distributed_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.load_distributed_checkpoint" title="Permalink to this definition"></a></dt>
<dd><p>Load checkpoint into net for distributed predication.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<em>Cell</em>) – Network for distributed predication.</p></li>
<li><p><strong>checkpoint_filenames</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em>) – The name of Checkpoint files in order of rank id.</p></li>
<li><p><strong>predict_strategy</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – Strategy of predication process, whose key is parameter name, and value is a list or
a tuple that the first four elements are [dev_matrix, tensor_map, param_split_shape, field]. If None,
it means that the predication process just uses single device. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – The type of inputs do not match the requirements.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Failed to load checkpoint into net.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.load_param_into_net">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">load_param_into_net</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">net</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameter_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict_load</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#load_param_into_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.load_param_into_net" title="Permalink to this definition"></a></dt>
<dd><p>Loads parameters into network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net</strong> (<em>Cell</em>) – Cell network.</p></li>
<li><p><strong>parameter_dict</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – Parameter dictionary.</p></li>
<li><p><strong>strict_load</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to strict load the parameter into net. If False, it will load parameter
in the param_dict into net with the same suffix. Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – Argument is not a Cell, or parameter_dict is not a Parameter dictionary.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ckpt_file_name</span> <span class="o">=</span> <span class="s2">&quot;./checkpoint/LeNet5-1_32.ckpt&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">ckpt_file_name</span><span class="p">,</span> <span class="n">filter_prefix</span><span class="o">=</span><span class="s2">&quot;conv1&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_not_load</span> <span class="o">=</span> <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">param_not_load</span><span class="p">)</span>
<span class="go">[&#39;conv1.weight&#39;]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.merge_sliced_parameter">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">merge_sliced_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sliced_parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#merge_sliced_parameter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.merge_sliced_parameter" title="Permalink to this definition"></a></dt>
<dd><p>Merge parameter slices to one whole parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sliced_parameters</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference internal" href="#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a><em>]</em>) – Parameter slices in order of rank_id.</p></li>
<li><p><strong>strategy</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – <p>Parameter slice strategy, the default is None.
If strategy is None, just merge parameter slices in 0 axis order.</p>
<ul>
<li><p>key (str): Parameter name.</p></li>
<li><p>value (&lt;class ‘node_strategy_pb2.ParallelLayouts’&gt;): Slice strategy of this parameter.</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Parameter, the merged parameter which has the whole data.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Failed to merge.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – The sliced_parameters is incorrect or strategy is not dict.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#KeyError" title="(in Python v3.8)"><strong>KeyError</strong></a> – The parameter name is not in keys of strategy.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sliced_parameters</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>                     <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.00023915</span><span class="p">,</span> <span class="mf">0.00013939</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00098059</span><span class="p">])),</span>
<span class="gp">... </span>                               <span class="s2">&quot;network.embedding_table&quot;</span><span class="p">),</span>
<span class="gp">... </span>                     <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.00015815</span><span class="p">,</span> <span class="mf">0.00015458</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00012125</span><span class="p">])),</span>
<span class="gp">... </span>                               <span class="s2">&quot;network.embedding_table&quot;</span><span class="p">),</span>
<span class="gp">... </span>                     <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.00042165</span><span class="p">,</span> <span class="mf">0.00029692</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00007941</span><span class="p">])),</span>
<span class="gp">... </span>                               <span class="s2">&quot;network.embedding_table&quot;</span><span class="p">),</span>
<span class="gp">... </span>                     <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.00084451</span><span class="p">,</span> <span class="mf">0.00089960</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00010431</span><span class="p">])),</span>
<span class="gp">... </span>                               <span class="s2">&quot;network.embedding_table&quot;</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">merged_parameter</span> <span class="o">=</span> <span class="n">merge_sliced_parameter</span><span class="p">(</span><span class="n">sliced_parameters</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.ms_function">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">ms_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_signature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/api.html#ms_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ms_function" title="Permalink to this definition"></a></dt>
<dd><p>Create a callable MindSpore graph from a python function.</p>
<p>This allows the MindSpore runtime to apply optimizations based on graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fn</strong> (<em>Function</em>) – The Python function that will be run as a graph. Default: None.</p></li>
<li><p><strong>obj</strong> (<em>Object</em>) – The Python Object that provides the information for identifying the compiled function.Default:
None.</p></li>
<li><p><strong>input_signature</strong> (<a class="reference internal" href="#mindspore.MetaTensor" title="mindspore.MetaTensor"><em>MetaTensor</em></a>) – The MetaTensor which describes the input arguments. The MetaTensor specifies
the shape and dtype of the Tensor and they will be supplied to this function. If input_signature
is specified, each input to <cite>fn</cite> must be a <cite>Tensor</cite>. And the input parameters of <cite>fn</cite> cannot accept
<cite>**kwargs</cite>. The shape and dtype of actual inputs should keep the same as input_signature. Otherwise,
TypeError will be raised. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Function, if <cite>fn</cite> is not None, returns a callable function that will execute the compiled function; If <cite>fn</cite> is
None, returns a decorator and when this decorator invokes with a single <cite>fn</cite> argument, the callable function is
equal to the case when <cite>fn</cite> is not None.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># create a callable MindSpore graph by calling ms_function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">tensor_add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">z</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tensor_add_graph</span> <span class="o">=</span> <span class="n">ms_function</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">tensor_add</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">tensor_add_graph</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># create a callable MindSpore graph through decorator @ms_function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nd">@ms_function</span>
<span class="gp">... </span><span class="k">def</span> <span class="nf">tensor_add_with_dec</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">z</span>
<span class="gp">...</span>
<span class="go"> &gt;&gt;&gt; out = tensor_add_with_dec(x, y)</span>
<span class="go">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># create a callable MindSpore graph through decorator @ms_function with input_signature parameter</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nd">@ms_function</span><span class="p">(</span><span class="n">input_signature</span><span class="o">=</span><span class="p">(</span><span class="n">MetaTensor</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
<span class="gp">... </span>                              <span class="n">MetaTensor</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))))</span>
<span class="gp">... </span><span class="k">def</span> <span class="nf">tensor_add_with_sig</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">z</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">tensor_add_with_sig</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.parse_print">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">parse_print</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">print_file_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#parse_print"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.parse_print" title="Permalink to this definition"></a></dt>
<dd><p>Loads Print data from a specified file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>print_file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The file name of saved print data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List, element of list is Tensor.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – The print file may be empty, please make sure enter the correct file name.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.pytype_to_dtype">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">pytype_to_dtype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/dtype.html#pytype_to_dtype"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.pytype_to_dtype" title="Permalink to this definition"></a></dt>
<dd><p>Convert python type to MindSpore type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>obj</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#type" title="(in Python v3.8)"><em>type</em></a>) – A python type object.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Type of MindSpore type.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.save_checkpoint">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">save_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_obj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_file_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integrated_save</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">async_save</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#save_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.save_checkpoint" title="Permalink to this definition"></a></dt>
<dd><p>Saves checkpoint info to a specified file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_obj</strong> (<em>nn.Cell</em><em> or </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – The cell object or data list(each element is a dictionary, like
[{“name”: param_name, “data”: param_data},…], the type of param_name would
be string, and the type of param_data would be parameter or tensor).</p></li>
<li><p><strong>ckpt_file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Checkpoint file name. If the file name already exists, it will be overwritten.</p></li>
<li><p><strong>integrated_save</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to integrated save in automatic model parallel scene. Default: True</p></li>
<li><p><strong>async_save</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether asynchronous execution saves the checkpoint to a file. Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If the parameter save_obj is not nn.Cell or list type.And if the parameter integrated_save and
    async_save are not bool type.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mindspore.set_seed">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">set_seed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/seed.html#set_seed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.set_seed" title="Permalink to this definition"></a></dt>
<dd><p>Set global random seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The global seed is used by numpy.random, mindspore.common.Initializer, mindspore.ops.composite.random_ops and
mindspore.nn.probability.distribution.</p>
<p>If global seed is not set, these packages will use their own default seed independently, numpy.random and
mindspore.common.Initializer will choose a random seed, mindspore.ops.composite.random_ops and
mindspore.nn.probability.distribution will use zero.</p>
<p>Seed set by numpy.random.seed() only used by numpy.random, while seed set by this API will also used by
numpy.random, so just set all seed by this API is recommended.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The seed to be set.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If seed is invalid (&lt; 0).</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If seed isn’t a int.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">composite</span> <span class="k">as</span> <span class="n">C</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Note: (1) Please make sure the code is running in PYNATIVE MODE;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># (2) Becasuse Composite-level ops need parameters to be Tensors, for below examples,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># when using C.uniform operator, minval and maxval are initialised as:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">minval</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">maxval</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 1. If global seed is not set, numpy.random and initializer will choose a random seed:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get diferent results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W4</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 2. If global seed is set, numpy.random and initializer will use it:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get the same results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W2</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 3. If neither global seed nor op seed is set, mindspore.ops.composite.random_ops and</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.nn.probability.distribution will choose a random seed:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get different results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C4</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 4. If global seed is set, but op seed is not set, mindspore.ops.composite.random_ops and</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.nn.probability.distribution will caculate a seed according to global seed and</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># default op seed. Each call will change the default op seed, thus each call get different</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># results.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get the same results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 5. If both global seed and op seed are set, mindspore.ops.composite.random_ops and</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.nn.probability.distribution will caculate a seed according to global seed and</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># op seed counter. Each call will change the op seed counter, thus each call get different</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># results.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get the same results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 6. If op seed is set but global seed is not set, 0 will be used as global seed. Then</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.ops.composite.random_ops and mindspore.nn.probability.distribution act as in</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># condition 5.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get the same results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 7. Recall set_seed() in the program will reset numpy seed and op seed counter of</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.ops.composite.random_ops and mindspore.nn.probability.distribution.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># still get A1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># still get C1</span>
</pre></div>
</div>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../index.html" class="btn btn-neutral float-left" title="MindSpore Python API" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mindspore.common.initializer.html" class="btn btn-neutral float-right" title="mindspore.common.initializer" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>