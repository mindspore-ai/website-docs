<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.numpy.array_creations &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">MindSpore Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.compression.html">mindspore.compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.explainer.html">mindspore.explainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.profiler.html">mindspore.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore/mindspore.train.html">mindspore.train</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindArmour Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.html">mindarmour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.adv_robustness.attacks.html">mindarmour.adv_robustness.attacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.adv_robustness.defenses.html">mindarmour.adv_robustness.defenses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.adv_robustness.detectors.html">mindarmour.adv_robustness.detectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.adv_robustness.evaluations.html">mindarmour.adv_robustness.evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.fuzz_testing.html">mindarmour.fuzz_testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.privacy.diff_privacy.html">mindarmour.privacy.diff_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.privacy.evaluation.html">mindarmour.privacy.evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.privacy.sup_privacy.html">mindarmour.privacy.sup_privacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindarmour/mindarmour.utils.html">mindarmour.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindSpore Hub Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore_hub/mindspore_hub.html">mindspore_hub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindSpore Serving Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../mindspore_serving/mindspore_serving.html">mindspore_serving</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindQuantum Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../mindquantum/mindquantum.html">mindquantum</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>mindspore.numpy.array_creations</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for mindspore.numpy.array_creations</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2020-2021 Huawei Technologies Co., Ltd</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ============================================================================</span>
<span class="sd">&quot;&quot;&quot;array operations, the function docs are adapted from Numpy API.&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">onp</span>

<span class="kn">from</span> <span class="nn">..common</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">..common</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">from</span> <span class="nn">..ops</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">..ops.primitive</span> <span class="kn">import</span> <span class="n">constexpr</span>
<span class="kn">from</span> <span class="nn">..nn.layer.basic</span> <span class="kn">import</span> <span class="n">tril</span> <span class="k">as</span> <span class="n">nn_tril</span>
<span class="kn">from</span> <span class="nn">..nn.layer.basic</span> <span class="kn">import</span> <span class="n">triu</span> <span class="k">as</span> <span class="n">nn_triu</span>
<span class="kn">from</span> <span class="nn">.._c_expression</span> <span class="kn">import</span> <span class="n">Tensor</span> <span class="k">as</span> <span class="n">Tensor_</span>

<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">_check_input_for_asarray</span><span class="p">,</span> <span class="n">_deep_list</span><span class="p">,</span> <span class="n">_deep_tensor_to_nparray</span><span class="p">,</span> \
    <span class="n">_broadcast_to_shape</span><span class="p">,</span> <span class="n">_check_input_tensor</span><span class="p">,</span> <span class="n">_convert_64_to_32</span><span class="p">,</span> <span class="n">_get_dtype_from_scalar</span><span class="p">,</span> \
    <span class="n">_expand</span>
<span class="kn">from</span> <span class="nn">.utils_const</span> <span class="kn">import</span> <span class="n">_raise_value_error</span><span class="p">,</span> <span class="n">_empty</span><span class="p">,</span> <span class="n">_check_axis_valid</span><span class="p">,</span> <span class="n">_max</span><span class="p">,</span> <span class="n">_min</span><span class="p">,</span> \
    <span class="n">_check_same_type</span><span class="p">,</span> <span class="n">_is_shape_empty</span><span class="p">,</span> <span class="n">_check_shape</span><span class="p">,</span> <span class="n">_check_dtype</span><span class="p">,</span> <span class="n">_tile_size</span><span class="p">,</span> <span class="n">_abs</span><span class="p">,</span> \
    <span class="n">_raise_type_error</span><span class="p">,</span> <span class="n">_expanded_shape</span><span class="p">,</span> <span class="n">_check_is_float</span><span class="p">,</span> <span class="n">_iota</span><span class="p">,</span> <span class="n">_type_convert</span><span class="p">,</span> \
    <span class="n">_canonicalize_axis</span><span class="p">,</span> <span class="n">_list_comprehensions</span><span class="p">,</span> <span class="n">_ceil</span><span class="p">,</span> <span class="n">_tuple_getitem</span><span class="p">,</span> <span class="n">_tuple_slice</span>
<span class="kn">from</span> <span class="nn">.array_ops</span> <span class="kn">import</span> <span class="n">transpose</span><span class="p">,</span> <span class="n">ravel</span><span class="p">,</span> <span class="n">concatenate</span><span class="p">,</span> <span class="n">broadcast_arrays</span><span class="p">,</span> <span class="n">reshape</span><span class="p">,</span> <span class="n">broadcast_to</span>
<span class="kn">from</span> <span class="nn">.dtypes</span> <span class="kn">import</span> <span class="n">nan</span>

<span class="c1"># According to official numpy reference, the dimension of a numpy array must be less</span>
<span class="c1"># than 32</span>
<span class="n">MAX_NUMPY_DIMS</span> <span class="o">=</span> <span class="mi">32</span>
<span class="c1"># All types that can be accepted as &quot;array_like&quot; parameters in graph mode.</span>
<span class="n">ARRAY_TYPES</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>


<div class="viewcode-block" id="array"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.array.html#mindspore.numpy.array">[docs]</a><span class="k">def</span> <span class="nf">array</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ndmin</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a tensor.</span>

<span class="sd">    This function creates tensors from an array-like object.</span>

<span class="sd">    Args:</span>
<span class="sd">        obj (Union[int, float, bool, list, tuple]): Input data, in any form that</span>
<span class="sd">            can be converted to a `Tensor`. This includes Tensor, list, tuple and numbers.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.int32, or \&#39;int32\&#39;. If dtype is :class:`None`, the data type</span>
<span class="sd">            of the new tensor will be inferred from obj. Default is :class:`None`.</span>
<span class="sd">        copy (bool): If `True`, then the object is copied. Otherwise, a copy will</span>
<span class="sd">            only be made if necessary. Default: `True`.</span>
<span class="sd">        ndmin (int): Specifies the minimum number of dimensions that the resulting</span>
<span class="sd">            tensor should have. Ones will be pre-pended to the shape as needed to</span>
<span class="sd">            meet this requirement. Default: 0</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, generated tensor with the specified dtype.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If input `obj` has different sizes at different dimensions.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.array([1,2,3]))</span>
<span class="sd">        [1 2 3]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">asarray</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ndmin</span> <span class="o">&gt;</span> <span class="n">res</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">_expand</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">ndmin</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">copy</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">copy_</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">dtype</span> <span class="o">!=</span> <span class="n">res</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">res</span></div>


<span class="nd">@constexpr</span>
<span class="k">def</span> <span class="nf">asarray_const</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Converts the input to tensor. Note here `a` cannot be tensor itself.&quot;&quot;&quot;</span>
    <span class="n">_check_input_for_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">bool</span><span class="p">))</span> <span class="ow">and</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">_get_dtype_from_scalar</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="c1"># Convert all tuple/nested tuples to lists</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">_deep_list</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="c1"># Convert all tensor sub-elements to numpy arrays</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">_deep_tensor_to_nparray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">onp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">onp</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;object&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Input array must have the same size across all dimensions.&#39;</span><span class="p">)</span>
        <span class="c1"># If dtype is not specified, we keep consistent with numpy decision</span>
        <span class="c1"># only exceptions are: we use int/float32</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">pytype_to_dtype</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span>
            <span class="k">elif</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">:</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">onp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">onp</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;object&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;For Tensor conversion, the input_data is </span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s2"> that contains unsupported element.&quot;</span><span class="p">)</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">pytype_to_dtype</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>


<div class="viewcode-block" id="asarray"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.asarray.html#mindspore.numpy.asarray">[docs]</a><span class="k">def</span> <span class="nf">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts the input to tensor.</span>

<span class="sd">    This function converts tensors from an array-like object.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Union[int, float, bool, list, tuple, Tensor]): Input data, in any form that can</span>
<span class="sd">            be converted to a `Tensor`. This includes Tensor, list, tuple and numbers.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.int32, or \&#39;int32\&#39;. If dtype is :class:`None`, the data type</span>
<span class="sd">            of the new tensor will be inferred from obj. Default is :class:`None`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, generated tensor with the specified dtype.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If input `a` has different sizes at different dimensions.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.asarray([1,2,3]))</span>
<span class="sd">        [1 2 3]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">a</span>
        <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">asarray_const</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span></div>


<span class="nd">@constexpr</span>
<span class="k">def</span> <span class="nf">asfarray_const</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Converts the input to tensor. Note here `a` cannot be tensor itself.&quot;&quot;&quot;</span>
    <span class="n">_check_input_for_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="c1"># Convert all tuple/nested tuples to lists</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">_deep_list</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="c1"># Convert all tensor sub-elements to numpy arrays</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">_deep_tensor_to_nparray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">onp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">onp</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;object&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;For Tensor conversion, the input_data is </span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s2"> that contains unsupported element.&quot;</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>


<div class="viewcode-block" id="asfarray"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.asfarray.html#mindspore.numpy.asfarray">[docs]</a><span class="k">def</span> <span class="nf">asfarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Similar to asarray, converts the input to a float tensor.</span>

<span class="sd">    If non-float dtype is defined, this function will return a float32 tensor instead.</span>

<span class="sd">    Args:</span>
<span class="sd">       a (Union[int, float, bool, list, tuple, Tensor]): Input data, in any form that can</span>
<span class="sd">            be converted to a `Tensor`. This includes Tensor, list, tuple and numbers.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.int32, or \&#39;int32\&#39;. If dtype is :class:`None`, the data type</span>
<span class="sd">            of the new tensor will be inferred from `a`. Default is :class:`mindspore.float32`.</span>


<span class="sd">    Returns:</span>
<span class="sd">        Tensor, generated tensor with the specified float dtype.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If input `a` has different sizes at different dimensions.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.asfarray([1,2,3]))</span>
<span class="sd">        [1. 2. 3.]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="c1"># pylint: disable=consider-using-in</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="o">!=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float16</span> <span class="ow">and</span> <span class="n">dtype</span> <span class="o">!=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span> <span class="ow">and</span> <span class="n">dtype</span> <span class="o">!=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">asfarray_const</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">copy_</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a tensor copy of the given object.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Union[int, float, bool, list, tuple, Tensor]): Input data, in any form that can</span>
<span class="sd">            be converted to a `Tensor`. This includes Tensor, list, tuple and numbers.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, has the same data as `a`.</span>

<span class="sd">     Raises:</span>
<span class="sd">        TypeError: If input `a` has type not specified above.</span>
<span class="sd">        ValueError: If input `a` has different sizes at different dimensions.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; x = np.ones((2,2))</span>
<span class="sd">        &gt;&gt;&gt; print(np.copy(x))</span>
<span class="sd">        [[1. 1.]</span>
<span class="sd">         [1. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">asarray_const</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="c1"># The current implementation registers a new memory location for copied tensor by</span>
    <span class="c1"># doing some reduandent operations.</span>
    <span class="n">origin_dtype</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
    <span class="k">if</span> <span class="n">origin_dtype</span> <span class="o">==</span> <span class="n">mstype</span><span class="o">.</span><span class="n">bool_</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">origin_dtype</span> <span class="o">!=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">a</span> <span class="o">/</span> <span class="n">ones_like</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">origin_dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">a</span>


<div class="viewcode-block" id="ones"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.ones.html#mindspore.numpy.ones">[docs]</a><span class="k">def</span> <span class="nf">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new tensor of given shape and type, filled with ones.</span>

<span class="sd">    Args:</span>
<span class="sd">        shape (Union[int, tuple, list]): the shape of the new tensor.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype.</span>
<span class="sd">            Default is :class:`mstype.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, with the designated `shape` and `dtype`, filled with ones.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If `shape` entries have values :math:`&lt; 0`.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.ones((2,2)))</span>
<span class="sd">        [[1. 1.]</span>
<span class="sd">        [1. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">_check_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">_is_shape_empty</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="zeros"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.zeros.html#mindspore.numpy.zeros">[docs]</a><span class="k">def</span> <span class="nf">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new tensor of given shape and type, filled with zeros.</span>

<span class="sd">    Args:</span>
<span class="sd">        shape (Union[int, tuple, list]): the shape of the new tensor.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype.</span>
<span class="sd">            Default is :class:`mstype.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, with the designated `shape` and `dtype`, filled with zeros.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If `shape` entries have values :math:`&lt; 0`.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.zeros((2,2)))</span>
<span class="sd">        [[0. 0.]</span>
<span class="sd">        [0. 0.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">_check_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">_is_shape_empty</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="full"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.full.html#mindspore.numpy.full">[docs]</a><span class="k">def</span> <span class="nf">full</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new tensor of given shape and type, filled with `fill_value`.</span>

<span class="sd">    Args:</span>
<span class="sd">        shape (Union[int, tuple(int), list(int)]): Shape of the new tensor, e.g.,</span>
<span class="sd">            :math:`(2, 3)` or :math:`2`.</span>
<span class="sd">        fill_value (Union[int, float, bool, list, tuple]): Scalar or array_like</span>
<span class="sd">            fill value.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype,</span>
<span class="sd">            if `dtype` is :class:`None`, the data type of the new tensor will be inferred from</span>
<span class="sd">            `fill_value`. Default is :class:`None`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, with the designated shape and dtype, filled with `fill_value`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If `shape` has entries &lt; 0.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.full((2,2), True))</span>
<span class="sd">        [[True True]</span>
<span class="sd">        [True True]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">_check_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="n">ARRAY_TYPES</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;fill value should be int, float, bool, list, tuple, Tensor, but got&quot;</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)):</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">_get_dtype_from_scalar</span><span class="p">(</span><span class="n">fill_value</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">fill_value</span><span class="o">.</span><span class="n">dtype</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_shape_empty</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)):</span>
            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">fill_value</span> <span class="o">=</span> <span class="n">asarray_const</span><span class="p">(</span><span class="n">fill_value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">broadcast_to</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
    <span class="c1"># if shape contains zero, use c.Tensor()</span>
    <span class="k">return</span> <span class="n">_convert_64_to_32</span><span class="p">(</span><span class="n">empty_compile</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">))</span></div>


<div class="viewcode-block" id="arange"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.arange.html#mindspore.numpy.arange">[docs]</a><span class="k">def</span> <span class="nf">arange</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns evenly spaced values within a given interval.</span>

<span class="sd">    Args:</span>
<span class="sd">        start(Union[int, float]): Start of interval. The interval includes this value.</span>
<span class="sd">            When `stop` is provided as a position argument, `start` must be given, when `stop`</span>
<span class="sd">            is a normal argument, `start` can be optional, and default is 0.</span>
<span class="sd">            Please see additional examples below.</span>
<span class="sd">        stop(Union[int, float], optional): End of interval. The interval does not</span>
<span class="sd">            include this value, except in some cases where `step` is not an integer</span>
<span class="sd">            and floating point round-off affects the length of out.</span>
<span class="sd">        step(Union[int, float], optional): Spacing between values. For any output</span>
<span class="sd">            `out`, this is the distance between two adjacent values, :math:`out[i+1] - out[i]`.</span>
<span class="sd">            The default step size is 1. If `step` is specified as a position argument,</span>
<span class="sd">            `start` must also be given.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype.</span>
<span class="sd">            If dtype is None, the data type of the new tensor will be inferred from start,</span>
<span class="sd">            stop and step. Default is None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor with evenly spaced values.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError(PyNative Mode) or RuntimeError(Graph Mode): If input arguments</span>
<span class="sd">            have types not specified above, or arguments are not given in the correct</span>
<span class="sd">            orders specified above.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.arange(0, 5, 1))</span>
<span class="sd">        [0 1 2 3 4]</span>
<span class="sd">        &gt;&gt;&gt; print(np.arange(3))</span>
<span class="sd">        [0 1 2]</span>
<span class="sd">        &gt;&gt;&gt; print(np.arange(start=0, stop=3))</span>
<span class="sd">        [0 1 2]</span>
<span class="sd">        &gt;&gt;&gt; print(np.arange(0, stop=3, step=0.5))</span>
<span class="sd">        [0.  0.5 1.  1.5 2.  2.5]</span>
<span class="sd">        &gt;&gt;&gt; print(np.arange(stop=3)) # This will lead to TypeError</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># This implementation was inspired by jax.numpy.arange</span>
    <span class="c1"># infer the dtype</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">_get_dtype_from_scalar</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">stop</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">step</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="c1"># (start, stop, step) -&gt; (0, start, 1)</span>
        <span class="n">num</span> <span class="o">=</span> <span class="n">_ceil</span><span class="p">(</span><span class="n">start</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">_iota</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">step</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># (start, stop, step) -&gt; (start, stop, 1)</span>
        <span class="n">num</span> <span class="o">=</span> <span class="n">_ceil</span><span class="p">(</span><span class="n">stop</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">_iota</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span> <span class="o">+</span> <span class="n">start</span>
    <span class="k">elif</span> <span class="n">stop</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="c1"># (start, stop, step) -&gt; (0, start, step)</span>
        <span class="n">num</span> <span class="o">=</span> <span class="n">_ceil</span><span class="p">(</span><span class="n">start</span> <span class="o">/</span> <span class="n">step</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">_iota</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span> <span class="o">*</span> <span class="n">step</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">num</span> <span class="o">=</span> <span class="n">_ceil</span><span class="p">((</span><span class="n">stop</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">/</span> <span class="n">step</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">_iota</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span> <span class="o">*</span> <span class="n">step</span> <span class="o">+</span> <span class="n">start</span>
    <span class="k">return</span> <span class="n">out</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_type_checking_for_xspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;utility parameter checking function for linspace, logspace, geomspace.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">ARRAY_TYPES</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;start should be int, float, bool, list, tuple, Tensor, but got&quot;</span><span class="p">,</span> <span class="n">start</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stop</span><span class="p">,</span> <span class="n">ARRAY_TYPES</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;end should be int, float, bool, list, tuple, Tensor, but got&quot;</span><span class="p">,</span> <span class="n">stop</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">_type_convert</span><span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">start</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stop</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">stop</span> <span class="o">=</span> <span class="n">_type_convert</span><span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">stop</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;num should be an integer, but got &quot;</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">endpoint</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;endpoint should be an boolean, but got &quot;</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span>
    <span class="n">start</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">broadcast_arrays</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span>


<span class="k">def</span> <span class="nf">_compute_shapes</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes shapes for local variables for np.linspace&quot;&quot;&quot;</span>
    <span class="n">bounds_shape</span> <span class="o">=</span> <span class="n">start</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">bounds_shape</span> <span class="o">=</span> <span class="n">_tuple_slice</span><span class="p">(</span><span class="n">bounds_shape</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">_tuple_slice</span><span class="p">(</span><span class="n">bounds_shape</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">iota_shape</span> <span class="o">=</span> <span class="n">_list_comprehensions</span><span class="p">(</span><span class="n">start</span><span class="o">.</span><span class="n">ndim</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">iota_shape</span> <span class="o">=</span> <span class="n">_tuple_slice</span><span class="p">(</span><span class="n">iota_shape</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">num</span><span class="p">,)</span> <span class="o">+</span> <span class="n">_tuple_slice</span><span class="p">(</span><span class="n">iota_shape</span><span class="p">,</span> <span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">num_tensor</span> <span class="o">=</span> <span class="n">_type_convert</span><span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">div</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_tensor</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">endpoint</span> <span class="k">else</span> <span class="n">num_tensor</span>
    <span class="k">return</span> <span class="n">bounds_shape</span><span class="p">,</span> <span class="n">iota_shape</span><span class="p">,</span> <span class="n">div</span>


<div class="viewcode-block" id="linspace"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.linspace.html#mindspore.numpy.linspace">[docs]</a><span class="k">def</span> <span class="nf">linspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">retstep</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns evenly spaced values within a given interval.</span>

<span class="sd">    Args:</span>
<span class="sd">        start (Union[int, list(int), tuple(int), tensor]): The starting value of the sequence.</span>
<span class="sd">        stop (Union[int, list(int), tuple(int), tensor]): The end value of the sequence,</span>
<span class="sd">            unless `endpoint` is set to False. In that case, the sequence consists</span>
<span class="sd">            of all but the last of `num + 1` evenly spaced samples, so that `stop`</span>
<span class="sd">            is excluded.  Note that the step size changes when `endpoint` is False.</span>
<span class="sd">        num (int, optional): Number of samples to generate. Default is 50.</span>
<span class="sd">        endpoint (bool, optional): If True, `stop` is the last sample. Otherwise, it is</span>
<span class="sd">            not included. Default is True.</span>
<span class="sd">        retstep (bool, optional): If True, return (`samples`, `step`), where `step` is</span>
<span class="sd">            the spacing between samples.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype,</span>
<span class="sd">            If `dtype` is None, infer the data type from other input arguments. Default is None.</span>
<span class="sd">        axis (int, optional): The axis in the result to store the samples. Relevant</span>
<span class="sd">            only if start or stop are array-like.  By default :math:`(0)`, the samples will</span>
<span class="sd">            be along a new axis inserted at the beginning. Use :math:`-1` to get an axis at the end.</span>
<span class="sd">            Default is :math:`0`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, with `num` equally spaced samples in the closed interval</span>
<span class="sd">        :math:`[start, stop]` or the half-open interval :math:`[start, stop)`</span>
<span class="sd">        (depending on whether `endpoint` is True or False).</span>

<span class="sd">        Step, the size of spacing between samples, only returned if `retstep` is True.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.linspace(0, 5, 6))</span>
<span class="sd">        [0. 1. 2. 3. 4. 5.]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># This implementation was inspired by jax.numpy.linspace and numpy.linspace</span>
    <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">_type_checking_for_xspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="n">_canonicalize_axis</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">start</span><span class="o">.</span><span class="n">ndim</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">retstep</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;retstep should be an boolean, but got &quot;</span><span class="p">,</span> <span class="n">retstep</span><span class="p">)</span>
    <span class="n">bounds_shape</span><span class="p">,</span> <span class="n">iota_shape</span><span class="p">,</span> <span class="n">div</span> <span class="o">=</span> <span class="n">_compute_shapes</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">num</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="p">(</span><span class="n">stop</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">/</span> <span class="n">div</span>
        <span class="c1"># This is similar to how numpy and jax compute linspace</span>
        <span class="n">start_expand</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">bounds_shape</span><span class="p">)</span>
        <span class="n">incremental_expand</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">_iota</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">num</span><span class="p">),</span> <span class="n">iota_shape</span><span class="p">)</span>
        <span class="n">delta_expand</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">bounds_shape</span><span class="p">)</span>
        <span class="n">start_expand</span><span class="p">,</span> <span class="n">incremental_expand</span><span class="p">,</span> <span class="n">delta_expand</span> <span class="o">=</span> <span class="n">broadcast_arrays</span><span class="p">(</span>
            <span class="n">start_expand</span><span class="p">,</span> <span class="n">incremental_expand</span><span class="p">,</span> <span class="n">delta_expand</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">start_expand</span> <span class="o">+</span> <span class="p">(</span><span class="n">incremental_expand</span> <span class="o">*</span> <span class="n">delta_expand</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">num</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">nan</span> <span class="k">if</span> <span class="n">endpoint</span> <span class="k">else</span> <span class="n">stop</span> <span class="o">-</span> <span class="n">start</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">bounds_shape</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># num == 0</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">nan</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">_type_convert</span><span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="p">[])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">retstep</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">out</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">),</span> <span class="n">delta</span>
    <span class="k">return</span> <span class="n">out</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="logspace"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.logspace.html#mindspore.numpy.logspace">[docs]</a><span class="k">def</span> <span class="nf">logspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">base</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns numbers spaced evenly on a log scale.</span>

<span class="sd">    In linear space, the sequence starts at base ** start (base to the power of</span>
<span class="sd">    start) and ends with base ** stop (see endpoint below).</span>

<span class="sd">    Args:</span>
<span class="sd">        start (Union[int, list(int), tuple(int), tensor]): ``base ** start`` is the starting</span>
<span class="sd">            value of the sequence.</span>
<span class="sd">        stop (Union[int, list(int), tuple(int), tensor]): ``base ** stop`` is the final value of</span>
<span class="sd">            the sequence, unless `endpoint` is False. In that case, ``num + 1`` values are spaced</span>
<span class="sd">            over the interval in log-space, of which all but the last (a sequence of length num)</span>
<span class="sd">            are returned.</span>
<span class="sd">        num (int, optional): Number of samples to generate. Default is 50.</span>
<span class="sd">        endpoint (bool, optional): If True, `stop` is the last sample. Otherwise, it is</span>
<span class="sd">            not included. Default is True.</span>
<span class="sd">        base (Union[int, float], optional): The base of the log space. The step size</span>
<span class="sd">            between the elements in :math:`ln(samples) / ln(base)` (or :math:`log_{base}(samples)`)</span>
<span class="sd">            is uniform. Default is :math:`10.0`.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype.</span>
<span class="sd">            If `dtype` is None, infer the data type from other input arguments. Default is None.</span>
<span class="sd">        axis (int, optional): The axis in the result to store the samples. Relevant</span>
<span class="sd">            only if start or stop is array-like.  By default (:math:`0`), the samples will</span>
<span class="sd">            be along a new axis inserted at the beginning. Use :math:`-1` to get an axis at the end.</span>
<span class="sd">            Default is :math:`0`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, equally spaced on a log scale.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.logspace(0, 5, 6, base=2.0))</span>
<span class="sd">        [ 1.  2.  4.  8. 16. 32.]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># This implementation was inspired by jax.numpy.linspace and numpy.linspace</span>
    <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">_type_checking_for_xspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="n">_canonicalize_axis</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">start</span><span class="o">.</span><span class="n">ndim</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;base should be a number, but got &quot;</span><span class="p">,</span> <span class="n">base</span><span class="p">)</span>
    <span class="n">linspace_res</span> <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="n">endpoint</span><span class="p">,</span> <span class="n">retstep</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_pow</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">linspace_res</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">geomspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns numbers spaced evenly on a log scale (a geometric progression).</span>

<span class="sd">    This is similar to logspace, but with endpoints specified directly. Each output sample</span>
<span class="sd">    is a constant multiple of the previous.</span>

<span class="sd">    Args:</span>
<span class="sd">        start (Union[int, list(int), tuple(int), tensor]): The starting value of the sequence.</span>
<span class="sd">        stop (Union[int, list(int), tuple(int), tensor]): The final value of the sequence,</span>
<span class="sd">            unless endpoint is False. In that case, num + 1 values are spaced over the</span>
<span class="sd">            interval in log-space, of which all but the last (a sequence of length num) are</span>
<span class="sd">            returned.</span>
<span class="sd">        num (int, optional): Number of samples to generate. Default is 50.</span>
<span class="sd">        endpoint (bool, optional): If True, `stop` is the last sample. Otherwise, it is</span>
<span class="sd">            not included. Default is True.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.float32, or `float32`.If `dtype` is None, infer the data</span>
<span class="sd">            type from other input arguments. Default is None.</span>
<span class="sd">        axis (int, optional): The axis in the result to store the samples. Relevant</span>
<span class="sd">            only if start or stop is array-like.  By default (0), the samples will</span>
<span class="sd">            be along a new axis inserted at the beginning. Use -1 to get an axis at the end.</span>
<span class="sd">            Default is 0.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, with samples equally spaced on a log scale.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; output = np.geomspace(1, 256, num=9)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [  1.   2.   4.   8.  16.  32.  64. 128. 256.]</span>
<span class="sd">        &gt;&gt;&gt; output = np.geomspace(1, 256, num=8, endpoint=False)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [  1.   2.   4.   8.  16.  32.  64. 128.]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">_type_checking_for_xspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="n">_canonicalize_axis</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">start</span><span class="o">.</span><span class="n">ndim</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">root</span> <span class="o">=</span> <span class="n">num</span>
    <span class="k">if</span> <span class="n">endpoint</span><span class="p">:</span>
        <span class="n">root</span> <span class="o">-=</span> <span class="mi">1</span>
    <span class="n">bases</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_pow</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor_div</span><span class="p">(</span><span class="n">stop</span><span class="p">,</span> <span class="n">start</span><span class="p">),</span> <span class="n">asarray_const</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">root</span><span class="p">)))</span>
    <span class="n">exponents</span> <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="n">zeros</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">bases</span><span class="p">)),</span> <span class="n">F</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">bases</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">bases</span><span class="p">),</span> <span class="n">root</span><span class="p">),</span>
                         <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">bases</span><span class="p">)</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span> <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">bases</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">axis</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">axis</span>
    <span class="n">expanded_shape</span> <span class="o">=</span> <span class="n">_tuple_getitem</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">_tuple_getitem</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="n">bases</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">bases</span><span class="p">,</span> <span class="n">expanded_shape</span><span class="p">)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">expanded_shape</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_mul</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor_pow</span><span class="p">(</span><span class="n">bases</span><span class="p">,</span> <span class="n">exponents</span><span class="p">),</span> <span class="n">start</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>


<div class="viewcode-block" id="eye"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.eye.html#mindspore.numpy.eye">[docs]</a><span class="k">def</span> <span class="nf">eye</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a 2-D tensor with ones on the diagnoal and zeros elsewhere.</span>

<span class="sd">    Args:</span>
<span class="sd">        N (int): Number of rows in the output, must be larger than 0.</span>
<span class="sd">        M (int, optional): Number of columns in the output. If is :class:`None`, defaults to `N`,</span>
<span class="sd">            if defined, must be larger than 0. Deault is :class:`None`.</span>
<span class="sd">        k (int, optional): Index of the diagonal: 0 (the default) refers to the main</span>
<span class="sd">            diagonal, a positive value refers to an upper diagonal, and a negative value</span>
<span class="sd">            to a lower diagonal. Default is 0.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype.</span>
<span class="sd">            Default is mstype.float32.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tensor of shape (N, M). A tensor where all elements are equal to zero,</span>
<span class="sd">        except for the k-th diagonal, whose values are equal to one.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.eye(2, 2))</span>
<span class="sd">        [[1. 0.]</span>
<span class="sd">        [0. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">M</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">N</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;Input tensor dimensions should be integers.&quot;</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">N</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">M</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Fill the shape with any value is fine.</span>
        <span class="k">return</span> <span class="n">full</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>

    <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;=</span> <span class="n">M</span> <span class="ow">or</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="n">N</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">full</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">out_left</span> <span class="o">=</span> <span class="n">full</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">k</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
            <span class="n">out_right</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="n">M</span><span class="o">-</span><span class="n">k</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">concatenate</span><span class="p">((</span><span class="n">out_left</span><span class="p">,</span> <span class="n">out_right</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">out_upper</span> <span class="o">=</span> <span class="n">full</span><span class="p">((</span><span class="o">-</span><span class="n">k</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
            <span class="n">out_lower</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">N</span><span class="o">+</span><span class="n">k</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">concatenate</span><span class="p">((</span><span class="n">out_upper</span><span class="p">,</span> <span class="n">out_lower</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span></div>


<div class="viewcode-block" id="identity"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.identity.html#mindspore.numpy.identity">[docs]</a><span class="k">def</span> <span class="nf">identity</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the identity tensor.</span>

<span class="sd">    Args:</span>
<span class="sd">        n (int): Number of rows and columns in the output, must be larger than 0.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype,</span>
<span class="sd">            default is :class:`mstype.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tensor of shape `(n, n)`, where all elements are equal to zero,</span>
<span class="sd">        except for the diagonal, whose values are equal to one.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.identity(2))</span>
<span class="sd">        [[1. 0.]</span>
<span class="sd">        [0. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;Input tensor dimensions should be integers.&quot;</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span></div>


<span class="nd">@constexpr</span>
<span class="k">def</span> <span class="nf">empty_compile</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns an empty Tensor.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Tensor_</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>


<div class="viewcode-block" id="empty"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.empty.html#mindspore.numpy.empty">[docs]</a><span class="k">def</span> <span class="nf">empty</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new array of given shape and type, without initializing</span>
<span class="sd">    entries.</span>

<span class="sd">    Note:</span>
<span class="sd">        Numpy argument `order` is not supported.</span>
<span class="sd">        Object arrays are not supported.</span>

<span class="sd">    Args:</span>
<span class="sd">        shape (Union[int, tuple(int)]): Shape of the empty array, e.g.,</span>
<span class="sd">            (2, 3) or 2.</span>
<span class="sd">        dtype (:class:`mindspore.dtype`, optional): Desired output data-type for the</span>
<span class="sd">            array, e.g, mstype.int8. Default is mstype.float32.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, array of uninitialized (arbitrary) data of the given</span>
<span class="sd">        shape and dtype.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: if the input shape or dtype is invalid.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; output = np.empty((2, 3))</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        # result may vary</span>
<span class="sd">        Tensor(shape=[2, 3], dtype=Float32, value=</span>
<span class="sd">        &lt;uninitialized&gt;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">_check_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">empty_compile</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_get_shape</span><span class="p">(</span><span class="n">array_like</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns the shape of the array like object.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">array_like</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">array_like</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">return</span> <span class="n">asarray_const</span><span class="p">(</span><span class="n">array_like</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>


<span class="k">def</span> <span class="nf">_get_dtype</span><span class="p">(</span><span class="n">array_like</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns the data type of the array like object.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">array_like</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">array_like</span><span class="o">.</span><span class="n">dtype</span>
    <span class="k">return</span> <span class="n">asarray_const</span><span class="p">(</span><span class="n">array_like</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span>


<span class="k">def</span> <span class="nf">_x_like</span><span class="p">(</span><span class="n">prototype</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">constructor</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a tensor with the same shape and type as prototype,</span>
<span class="sd">    using constructor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prototype</span><span class="p">,</span> <span class="n">ARRAY_TYPES</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;prototype should be int, float, bool, list, tuple, Tensor, but got&quot;</span><span class="p">,</span> <span class="n">prototype</span><span class="p">)</span>
    <span class="n">dtype_out</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="n">shape_out</span> <span class="o">=</span> <span class="n">shape</span>
    <span class="k">if</span> <span class="n">dtype_out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype_out</span> <span class="o">=</span> <span class="n">_get_dtype</span><span class="p">(</span><span class="n">prototype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">shape_out</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape_out</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">shape_out</span><span class="p">:</span>
        <span class="n">shape_out</span> <span class="o">=</span> <span class="n">_get_shape</span><span class="p">(</span><span class="n">prototype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">fill_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">constructor</span><span class="p">(</span><span class="n">shape_out</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">dtype_out</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">constructor</span><span class="p">(</span><span class="n">shape_out</span><span class="p">,</span> <span class="n">dtype_out</span><span class="p">)</span>


<div class="viewcode-block" id="empty_like"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.empty_like.html#mindspore.numpy.empty_like">[docs]</a><span class="k">def</span> <span class="nf">empty_like</span><span class="p">(</span><span class="n">prototype</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new array with the same shape and type as a given array.</span>

<span class="sd">    Note:</span>
<span class="sd">        Input array must have the same size across a dimension.</span>
<span class="sd">        If `prototype` is not a Tensor, dtype is float32 by default if not provided.</span>

<span class="sd">    Args:</span>
<span class="sd">        prototype (Union[Tensor, list, tuple]): The shape and data-type of `prototype`</span>
<span class="sd">            define these same attributes of the returned array.</span>
<span class="sd">        dtype (:class:`mindspore.dtype`, optional): Overrides the data type of the</span>
<span class="sd">            result.</span>
<span class="sd">        shape (int or sequence of ints, optional): Overrides the shape</span>
<span class="sd">            of the result.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, array of uninitialized (arbitrary) data with the same</span>
<span class="sd">        shape and type as `prototype`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: if `prototype` is not a Tensor, list or tuple.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; a = np.ones((4,1,2))</span>
<span class="sd">        &gt;&gt;&gt; output = np.empty_like(a)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        # result may vary</span>
<span class="sd">        Tensor(shape=[4, 1, 2], dtype=Float32, value=</span>
<span class="sd">        &lt;uninitialized&gt;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_x_like</span><span class="p">(</span><span class="n">prototype</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">empty</span><span class="p">)</span></div>


<div class="viewcode-block" id="ones_like"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.ones_like.html#mindspore.numpy.ones_like">[docs]</a><span class="k">def</span> <span class="nf">ones_like</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns an array of ones with the same shape and type as a given array.</span>

<span class="sd">    Note:</span>
<span class="sd">        Input array must have the same size across a dimension.</span>
<span class="sd">        If `a` is not a Tensor, dtype is float32 by default if not provided.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Union[Tensor, list, tuple]): The shape and data-type of a define these same</span>
<span class="sd">            attributes of the returned array.</span>
<span class="sd">        dtype (:class:`mindspore.dtype`, optional): Overrides the data type of the</span>
<span class="sd">            result.</span>
<span class="sd">        shape (int or sequence of ints, optional): Overrides the shape</span>
<span class="sd">            of the result.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, array of ones with the same shape and type as `a`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: if `a` is not a Tensor, list or tuple.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; a = np.ones((4,1,2))</span>
<span class="sd">        &gt;&gt;&gt; output = np.ones_like(a)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[[1. 1.]]</span>
<span class="sd">        [[1. 1.]]</span>
<span class="sd">        [[1. 1.]]</span>
<span class="sd">        [[1. 1.]]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_x_like</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">ones</span><span class="p">)</span></div>


<div class="viewcode-block" id="zeros_like"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.zeros_like.html#mindspore.numpy.zeros_like">[docs]</a><span class="k">def</span> <span class="nf">zeros_like</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns an array of zeros with the same shape and type as a given array.</span>

<span class="sd">    Note:</span>
<span class="sd">        Input array must have the same size across a dimension.</span>
<span class="sd">        If `a` is not a Tensor, dtype is float32 by default if not provided.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Union[Tensor, list, tuple]): The shape and data-type of a define these same</span>
<span class="sd">            attributes of the returned array.</span>
<span class="sd">        dtype (:class:`mindspore.dtype`, optional): Overrides the data type of the</span>
<span class="sd">            result.</span>
<span class="sd">        shape (int or sequence of ints, optional): Overrides the shape</span>
<span class="sd">            of the result.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, array of zeros with the same shape and type as `a`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: if `a` is not a Tensor, list or tuple.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; a = np.ones((4,1,2))</span>
<span class="sd">        &gt;&gt;&gt; output = np.zeros_like(a)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[[0. 0.]]</span>
<span class="sd">        [[0. 0.]]</span>
<span class="sd">        [[0. 0.]]</span>
<span class="sd">        [[0. 0.]]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_x_like</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">zeros</span><span class="p">)</span></div>


<div class="viewcode-block" id="full_like"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.full_like.html#mindspore.numpy.full_like">[docs]</a><span class="k">def</span> <span class="nf">full_like</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a full array with the same shape and type as a given array.</span>

<span class="sd">    Note:</span>
<span class="sd">        Input array must have the same size across a dimension.</span>
<span class="sd">        If `a` is not a Tensor, dtype is float32 by default if not provided.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Union[Tensor, list, tuple]): The shape and data-type of `a` define these same</span>
<span class="sd">            attributes of the returned array.</span>
<span class="sd">        fill_value (scalar): Fill value.</span>
<span class="sd">        dtype (:class:`mindspore.dtype`, optional): Overrides the data type of the</span>
<span class="sd">            result.</span>
<span class="sd">        shape (int or sequence of ints, optional): Overrides the shape</span>
<span class="sd">            of the result.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, array of fill_value with the same shape and type as `a`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: if `a` is not a Tensor, list or tuple.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; a = np.ones((4,1,2))</span>
<span class="sd">        &gt;&gt;&gt; output = np.full_like(a, 0.5)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[[0.5 0.5]]</span>
<span class="sd">        [[0.5 0.5]]</span>
<span class="sd">        [[0.5 0.5]]</span>
<span class="sd">        [[0.5 0.5]]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_x_like</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">full</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">fill_value</span><span class="p">)</span></div>


<div class="viewcode-block" id="tri"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.tri.html#mindspore.numpy.tri">[docs]</a><span class="k">def</span> <span class="nf">tri</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a tensor with ones at and below the given diagonal and zeros elsewhere.</span>

<span class="sd">    Args:</span>
<span class="sd">        N(int): Number of rows in the array.</span>
<span class="sd">        M(int, optional): Number of columns in the array. By default, `M` is taken</span>
<span class="sd">            equal to N.</span>
<span class="sd">        k(int, optional): The sub-diagonal at and below which the array is filled.</span>
<span class="sd">            :math:`k = 0` is the main diagonal, while :math:`k &lt; 0` is below it, and :math:`k &gt; 0` is above.</span>
<span class="sd">            The default is 0.</span>
<span class="sd">        dtype(:class:`mindspore.dtype`, optional): Data type of the returned array. The default</span>
<span class="sd">            is :class:`mindspore.dtype`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor with shape `(N, M)`, with its lower triangle filled with</span>
<span class="sd">        ones and zeros elsewhere; in other words :math:`T[i,j] = 1` for :math:`j &lt;= i + k`,</span>
<span class="sd">        :math:`0` otherwise.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; output = np.tri(3, 3, 1)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[1. 1. 0.]</span>
<span class="sd">        [1. 1. 1.]</span>
<span class="sd">        [1. 1. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">M</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">N</span>
    <span class="k">return</span> <span class="n">nn_tril</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span></div>


<div class="viewcode-block" id="tril"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.tril.html#mindspore.numpy.tril">[docs]</a><span class="k">def</span> <span class="nf">tril</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a lower triangle of a tensor.</span>

<span class="sd">    Returns a copy of a tensor with elements above the `k-th` diagonal zeroed.</span>

<span class="sd">    Args:</span>
<span class="sd">        m (Union[Tensor, list, tuple]): The shape and data-type of `m` define these same</span>
<span class="sd">            attributes of the returned tensor.</span>
<span class="sd">        k (int, optional): Diagonal above which to zero elements. :math:`k = 0` (the default)</span>
<span class="sd">            is the main diagonal, :math:`k &lt; 0` is below it and :math:`k &gt; 0` is above.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Lower triangle of `m`, of same shape and data-type as `m`.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If input `m`\&#39;s rank :math:`&lt; 1`.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; output = np.tril(np.ones((3, 3)))</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[1. 0. 0.]</span>
<span class="sd">        [1. 1. 0.]</span>
<span class="sd">        [1. 1. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">asarray_const</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">assist</span> <span class="o">=</span> <span class="n">nn_tril</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_mul</span><span class="p">(</span><span class="n">assist</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="triu"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.triu.html#mindspore.numpy.triu">[docs]</a><span class="k">def</span> <span class="nf">triu</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns an upper triangle of a tensor.</span>

<span class="sd">    Returns a copy of a tensor with elements below the `k-th` diagonal zeroed.</span>

<span class="sd">    Args:</span>
<span class="sd">        m (Union[Tensor, list, tuple]): The shape and data-type of `m` define these same</span>
<span class="sd">            attributes of the returned tensor.</span>
<span class="sd">        k (int, optional): Diagonal below which to zero elements. :math:`k = 0` (the default)</span>
<span class="sd">            is the main diagonal, :math:`k &lt; 0` is below it and :math:`k &gt; 0` is above.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Upper triangle of `m`, of same shape and data-type as `m`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If input `m`\&#39;s rank &lt; 1.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; output = np.triu(np.ones((3, 3)))</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[1. 1. 1.]</span>
<span class="sd">        [0. 1. 1.]</span>
<span class="sd">        [0. 0. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">asarray_const</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">assist</span> <span class="o">=</span> <span class="n">nn_triu</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_mul</span><span class="p">(</span><span class="n">assist</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="diagonal"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.diagonal.html#mindspore.numpy.diagonal">[docs]</a><span class="k">def</span> <span class="nf">diagonal</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns specified diagonals.</span>

<span class="sd">    If `a` is 2-D, returns the diagonal of `a` with the given offset, i.e., the</span>
<span class="sd">    collection of elements of the form ``a[i, i+offset]``. If `a` has more than two</span>
<span class="sd">    dimensions, then the axes specified by `axis1` and `axis2` are used to determine</span>
<span class="sd">    the 2-D sub-array whose diagonal is returned. The shape of the resulting</span>
<span class="sd">    array can be determined by removing `axis1` and `axis2` and appending an index</span>
<span class="sd">    to the right equal to the size of the resulting diagonals.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Tensor): Array from which the diagonals are taken.</span>
<span class="sd">        offset (int, optional): Offset of the diagonal from the main diagonal.</span>
<span class="sd">            Can be positive or negative. Defaults to main diagonal.</span>
<span class="sd">        axis1 (int, optional): Axis to be used as the first axis of the 2-D</span>
<span class="sd">            sub-arrays from which the diagonals should be taken. Defaults to</span>
<span class="sd">            first axis (0).</span>
<span class="sd">        axis2 (int, optional): Axis to be used as the second axis of the 2-D</span>
<span class="sd">            sub-arrays from which the diagonals should be taken. Defaults to</span>
<span class="sd">            second axis.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, if `a` is 2-D, then `a` 1-D array containing the diagonal. If</span>
<span class="sd">        ``a.ndim &gt; 2``, then the dimensions specified by `axis1` and `axis2` are removed,</span>
<span class="sd">        and a new axis inserted at the end corresponding to the diagonal.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: if the input tensor has less than two dimensions.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; a = np.arange(4).reshape(2,2)</span>
<span class="sd">        &gt;&gt;&gt; print(a)</span>
<span class="sd">        [[0 1]</span>
<span class="sd">        [2 3]]</span>
<span class="sd">        &gt;&gt;&gt; output = np.diagonal(a)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [0 3]</span>
<span class="sd">        &gt;&gt;&gt; output = np.diagonal(a, 1)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [1]</span>
<span class="sd">        &gt;&gt;&gt; a = np.arange(8).reshape(2, 2, 2)</span>
<span class="sd">        &gt;&gt;&gt; print(a)</span>
<span class="sd">        [[[0 1]</span>
<span class="sd">        [2 3]]</span>
<span class="sd">        [[4 5]</span>
<span class="sd">        [6 7]]]</span>
<span class="sd">        &gt;&gt;&gt; output = np.diagonal(a, 0, 0, 1)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[0 6]</span>
<span class="sd">        [1 7]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ndim</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_raise_value_error</span><span class="p">(</span><span class="s1">&#39;diagonal requires an array of at least two dimensions&#39;</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">_is_shape_empty</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">a</span><span class="p">)):</span>
        <span class="k">return</span> <span class="n">_empty</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,))</span>

    <span class="n">cast_type</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_is_float</span><span class="p">(</span><span class="n">dtype</span><span class="p">):</span>
        <span class="c1"># reduce_sum only supports float types</span>
        <span class="n">cast_type</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">cast_type</span><span class="p">)</span>

    <span class="n">axes</span> <span class="o">=</span> <span class="n">_check_axis_valid</span><span class="p">((</span><span class="n">axis1</span><span class="p">,</span> <span class="n">axis2</span><span class="p">),</span> <span class="n">ndim</span><span class="p">)</span>
    <span class="n">perm</span> <span class="o">=</span> <span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndim</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span>
            <span class="n">perm</span> <span class="o">+=</span> <span class="p">(</span><span class="n">i</span><span class="p">,)</span>
    <span class="n">perm</span> <span class="o">+=</span> <span class="n">axes</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">transpose</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">perm</span><span class="p">)</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">cast_type</span><span class="p">)</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">_broadcast_to_shape</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>

    <span class="n">prod</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_mul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">prod</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">begin</span> <span class="o">=</span> <span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndim</span><span class="o">-</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">begin</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,)</span>
    <span class="n">last_dim_begin</span> <span class="o">=</span> <span class="n">_max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="n">offset</span><span class="p">)</span>
    <span class="n">begin</span> <span class="o">+=</span> <span class="p">(</span><span class="n">last_dim_begin</span><span class="p">,)</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">res</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">last_dim_end</span> <span class="o">=</span> <span class="n">_min</span><span class="p">(</span>
        <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">_max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">offset</span><span class="p">))</span> <span class="o">-</span> <span class="n">last_dim_begin</span>
    <span class="k">if</span> <span class="n">last_dim_end</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_empty</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">size</span> <span class="o">+</span> <span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
    <span class="n">size</span> <span class="o">+=</span> <span class="p">(</span><span class="n">last_dim_end</span><span class="p">,)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_slice</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_same_type</span><span class="p">(</span><span class="n">cast_type</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="trace"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.trace.html#mindspore.numpy.trace">[docs]</a><span class="k">def</span> <span class="nf">trace</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the sum along diagonals of the array.</span>

<span class="sd">    If `a` is 2-D, the sum along its diagonal with the given offset is returned,</span>
<span class="sd">    i.e., the sum of elements ``a[i,i+offset]`` for all `i`.</span>
<span class="sd">    If `a` has more than two dimensions, then the axes specified by `axis1` and</span>
<span class="sd">    `axis2` are used to determine the 2-D sub-arrays whose traces are returned.</span>
<span class="sd">    The shape of the resulting array is the same as that of a with `axis1` and</span>
<span class="sd">    `axis2` removed.</span>

<span class="sd">    Note:</span>
<span class="sd">        On GPU, the supported dtypes are np.float16, and np.float32.</span>
<span class="sd">        On CPU, the supported dtypes are np.float16, np.float32, and np.float64.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Tensor): Array from which the diagonals are taken.</span>
<span class="sd">        offset (int, optional): Offset of the diagonal from the main diagonal.</span>
<span class="sd">            Can be positive or negative. Defaults to main diagonal.</span>
<span class="sd">        axis1 (int, optional): Axis to be used as the first axis of the 2-D</span>
<span class="sd">            sub-arrays from which the diagonals should be taken. Defaults to</span>
<span class="sd">            first axis (0).</span>
<span class="sd">        axis2 (int, optional): Axis to be used as the second axis of the 2-D</span>
<span class="sd">            sub-arrays from which the diagonals should be taken. Defaults to</span>
<span class="sd">            second axis.</span>
<span class="sd">        dtype (:class:`mindspore.dtype`, optional): defaults to None. Overrides the dtype of the</span>
<span class="sd">            output Tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, sum_along_diagonals. If `a` is 2-D, the sum along the diagonal</span>
<span class="sd">        is returned. If `a` has larger dimensions, then an array of sums along</span>
<span class="sd">        diagonals is returned.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: if the input tensor has less than two dimensions.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; output = np.trace(np.eye(3))</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        3.0</span>
<span class="sd">        &gt;&gt;&gt; a = np.arange(8).reshape((2,2,2))</span>
<span class="sd">        &gt;&gt;&gt; output = np.trace(a)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [6 8]</span>
<span class="sd">        &gt;&gt;&gt; a = np.arange(24).reshape((2,2,2,3))</span>
<span class="sd">        &gt;&gt;&gt; output = np.trace(a).shape</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        (2, 3)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">diagonal</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis1</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="n">axis2</span><span class="p">)</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_empty</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">cast_type</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_is_float</span><span class="p">(</span><span class="n">dtype</span><span class="p">):</span>
        <span class="c1"># reduce sum only supports float types</span>
        <span class="n">cast_type</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">cast_type</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_same_type</span><span class="p">(</span><span class="n">cast_type</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>


<span class="k">def</span> <span class="nf">_index</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cartesian</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;If cartesian=True, index 0 is swapped with index 1.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">cartesian</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">size</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">i</span>


<div class="viewcode-block" id="meshgrid"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.meshgrid.html#mindspore.numpy.meshgrid">[docs]</a><span class="k">def</span> <span class="nf">meshgrid</span><span class="p">(</span><span class="o">*</span><span class="n">xi</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">indexing</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns coordinate matrices from coordinate vectors.</span>

<span class="sd">    Make `N-D` coordinate arrays for vectorized evaluations of `N-D`</span>
<span class="sd">    scalar/vector fields over `N-D` grids, given one-dimensional</span>
<span class="sd">    coordinate arrays `x1, x2,, xn`.</span>

<span class="sd">    Note:</span>
<span class="sd">        Numpy argument copy is not supported, and a copy is always</span>
<span class="sd">        returned.</span>

<span class="sd">    Args:</span>
<span class="sd">        *xi (Tensor): 1-D arrays representing the coordinates</span>
<span class="sd">            of a grid.</span>
<span class="sd">        indexing (xy, ij, optional): Cartesian (xy, default) or</span>
<span class="sd">            matrix (ij) indexing of output. In the 2-D case with</span>
<span class="sd">            inputs of length `M` and `N`, the outputs are of shape `(N, M)`</span>
<span class="sd">            for xy indexing and `(M, N)` for ij indexing. In the 3-D</span>
<span class="sd">            case with inputs of length `M`, `N` and `P`, outputs are of shape</span>
<span class="sd">            `(N, M, P)` for xy indexing and `(M, N, P)` for ij indexing.</span>
<span class="sd">        sparse (bool, optional): If True a sparse grid is returned in</span>
<span class="sd">            order to conserve memory. Default is False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple of tensors, for vectors `x1, x2,, xn` with lengths</span>
<span class="sd">        ``Ni=len(xi)``, return `(N1, N2, N3,...Nn)` shaped arrays if</span>
<span class="sd">        ``indexing=ij`` or `(N2, N1, N3,...Nn)` shaped arrays if</span>
<span class="sd">        ``indexing=xy`` with the elements of `xi` repeated to fill the matrix</span>
<span class="sd">        along the first dimension for `x1`, the second for `x2` and so on.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: if the input is not a tensor, or sparse is not boolean, or</span>
<span class="sd">            indexing is not &#39;xy&#39; or &#39;ij&#39;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; x = np.linspace(0, 1, 3)</span>
<span class="sd">        &gt;&gt;&gt; y = np.linspace(0, 1, 2)</span>
<span class="sd">        &gt;&gt;&gt; xv, yv = np.meshgrid(x, y)</span>
<span class="sd">        &gt;&gt;&gt; print(xv)</span>
<span class="sd">        [[0.  0.5 1. ]</span>
<span class="sd">        [0.  0.5 1. ]]</span>
<span class="sd">        &gt;&gt;&gt; print(yv)</span>
<span class="sd">        [[0.  0.  0.]</span>
<span class="sd">        [1.  1.  1.]]</span>
<span class="sd">        &gt;&gt;&gt; xv, yv = np.meshgrid(x, y, sparse=True)</span>
<span class="sd">        &gt;&gt;&gt; print(xv)</span>
<span class="sd">        [[0.  0.5  1. ]]</span>
<span class="sd">        &gt;&gt;&gt; print(yv)</span>
<span class="sd">        [[0.]</span>
<span class="sd">        [1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_input_tensor</span><span class="p">(</span><span class="o">*</span><span class="n">xi</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sparse</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s1">&#39;argument sparse should be boolean&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">indexing</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="s1">&#39;ij&#39;</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;Valid values for `indexing` are &#39;xy&#39; and &#39;ij&#39;.&quot;</span><span class="p">)</span>

    <span class="n">shape_out</span> <span class="o">=</span> <span class="p">()</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xi</span><span class="p">:</span>
        <span class="n">shape_out</span> <span class="o">+=</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">,)</span>
    <span class="k">if</span> <span class="n">_is_shape_empty</span><span class="p">(</span><span class="n">shape_out</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ones</span><span class="p">(</span><span class="n">shape_out</span><span class="p">)</span>

    <span class="n">grids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xi</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">grids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">grids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ravel</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">grids</span><span class="p">)</span>

    <span class="n">cartesian</span> <span class="o">=</span> <span class="n">indexing</span> <span class="o">==</span> <span class="s1">&#39;xy&#39;</span>
    <span class="n">shape_out</span> <span class="o">=</span> <span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">grids</span><span class="p">)):</span>
        <span class="n">grid_index</span> <span class="o">=</span> <span class="n">_index</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">ndim</span><span class="p">,</span> <span class="n">cartesian</span><span class="o">=</span><span class="n">cartesian</span><span class="p">)</span>
        <span class="n">shape_out</span> <span class="o">+=</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">grids</span><span class="p">[</span><span class="n">grid_index</span><span class="p">])[</span><span class="mi">0</span><span class="p">],)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">grids</span><span class="p">):</span>
        <span class="n">grid_index</span> <span class="o">=</span> <span class="n">_index</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">ndim</span><span class="p">,</span> <span class="n">cartesian</span><span class="o">=</span><span class="n">cartesian</span><span class="p">)</span>
        <span class="n">shape_expanded</span> <span class="o">=</span> <span class="n">_expanded_shape</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="n">shape_out</span><span class="p">[</span><span class="n">grid_index</span><span class="p">],</span> <span class="n">grid_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape_expanded</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">sparse</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">_tile_size</span><span class="p">(</span><span class="n">shape_expanded</span><span class="p">,</span> <span class="n">shape_out</span><span class="p">,</span> <span class="n">ndim</span><span class="p">))</span>
        <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>


<span class="k">class</span> <span class="nc">NdGrid</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Construct a multi-dimensional &quot;meshgrid&quot;.</span>

<span class="sd">    ``grid = NdGrid()`` creates an instance which will return a mesh-grid</span>
<span class="sd">    when indexed.</span>
<span class="sd">    If instantiated with an argument of ``sparse=True``, the mesh-grid is</span>
<span class="sd">    open (or not fleshed out) so that only one-dimension of each</span>
<span class="sd">    returned argument is greater than 1.</span>

<span class="sd">    Args:</span>
<span class="sd">        sparse (bool): Whether the grid is sparse or not. Default is</span>
<span class="sd">            False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor or tuple of tensor, a meshgrid. If ``sparse=False``, returns</span>
<span class="sd">        tensors are all of the same dimensions; and if ``sparse=True``,</span>
<span class="sd">        returns tensors with only one dimension not equal to `1`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span> <span class="o">=</span> <span class="n">sparse</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keys</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
            <span class="n">keys</span> <span class="o">=</span> <span class="p">(</span><span class="n">keys</span><span class="p">,)</span>

        <span class="n">xi</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">stop</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">_raise_type_error</span><span class="p">(</span><span class="s1">&#39;slice indices must be integers&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">step</span><span class="p">:</span>
                <span class="n">step</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">step</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">step</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="nb">complex</span><span class="p">):</span>
                <span class="n">v</span> <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">k</span><span class="o">.</span><span class="n">stop</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">step</span><span class="p">)))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">v</span> <span class="o">=</span> <span class="n">arange</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">k</span><span class="o">.</span><span class="n">stop</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="n">xi</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="n">grids</span> <span class="o">=</span> <span class="n">meshgrid</span><span class="p">(</span><span class="o">*</span><span class="n">xi</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sparse</span><span class="p">,</span> <span class="n">indexing</span><span class="o">=</span><span class="s1">&#39;ij&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">grids</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">grids</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">grids</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">grids</span><span class="p">,</span> <span class="n">Tensor_</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">grids</span>
        <span class="n">expanded</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">grid</span> <span class="ow">in</span> <span class="n">grids</span><span class="p">:</span>
            <span class="n">expanded</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">expanded</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">res</span>


<span class="k">class</span> <span class="nc">MGridClass</span><span class="p">(</span><span class="n">NdGrid</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    mgrid is an :class:`NdGrid` instance with ``sparse=False``.</span>

<span class="sd">    The dimension and number of the output arrays are equal to the number</span>
<span class="sd">    of indexing dimensions. If the step length is not a complex number,</span>
<span class="sd">    then the stop is not inclusive. However, if the step length is a complex</span>
<span class="sd">    number (e.g. 5j), then the integer part of its magnitude is interpreted</span>
<span class="sd">    as specifying the number of points to create between the start and</span>
<span class="sd">    stop values, where the stop value is inclusive.</span>

<span class="sd">    Note:</span>
<span class="sd">        Not supported in graph mode.</span>
<span class="sd">        Unlike Numpy, if the step length is a complex number with a real</span>
<span class="sd">        component, the step length is handled as equivalent to</span>
<span class="sd">        ``int(abs(step))``.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor or tuple of tensor, a meshgrid.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: if slicing indices are not integers.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.numpy import mgrid</span>
<span class="sd">        &gt;&gt;&gt; output = mgrid[0:5, 0:5]</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[[0 0 0 0 0]</span>
<span class="sd">        [1 1 1 1 1]</span>
<span class="sd">        [2 2 2 2 2]</span>
<span class="sd">        [3 3 3 3 3]</span>
<span class="sd">        [4 4 4 4 4]]</span>
<span class="sd">        [[0 1 2 3 4]</span>
<span class="sd">        [0 1 2 3 4]</span>
<span class="sd">        [0 1 2 3 4]</span>
<span class="sd">        [0 1 2 3 4]</span>
<span class="sd">        [0 1 2 3 4]]]</span>
<span class="sd">        &gt;&gt;&gt; output = mgrid[-1:1:5j]</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [-1.  -0.5  0.   0.5  1. ]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MGridClass</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">OGridClass</span><span class="p">(</span><span class="n">NdGrid</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ogrid is an :class:`NdGrid` instance with ``sparse=True``.</span>

<span class="sd">    The dimension and number of the output arrays are equal to the number</span>
<span class="sd">    of indexing dimensions. If the step length is not a complex number,</span>
<span class="sd">    then the stop is not inclusive. However, if the step length is a complex</span>
<span class="sd">    number (e.g. 5j), then the integer part of its magnitude is interpreted</span>
<span class="sd">    as specifying the number of points to create between the start and</span>
<span class="sd">    stop values, where the stop value is inclusive.</span>

<span class="sd">    Note:</span>
<span class="sd">        Not supported in graph mode.</span>
<span class="sd">        Unlike Numpy, if the step length is a complex number with a real</span>
<span class="sd">        component, the step length is handled as equivalent to</span>
<span class="sd">        ``int(abs(step))``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: if slicing indices are not integers.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.numpy import ogrid</span>
<span class="sd">        &gt;&gt;&gt; output = ogrid[0:5,0:5]</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [Tensor(shape=[5, 1], dtype=Int32, value=</span>
<span class="sd">        [[0],</span>
<span class="sd">        [1],</span>
<span class="sd">        [2]</span>
<span class="sd">        [3],</span>
<span class="sd">        [4]]), Tensor(shape=[1, 5], dtype=Int32, value=</span>
<span class="sd">        [[0, 1, 2, 3, 4]])]</span>
<span class="sd">        &gt;&gt;&gt; output = ogrid[-1:1:5j]</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [-1.  -0.5  0.   0.5  1. ]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OGridClass</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="n">mgrid</span> <span class="o">=</span> <span class="n">MGridClass</span><span class="p">()</span>


<span class="n">ogrid</span> <span class="o">=</span> <span class="n">OGridClass</span><span class="p">()</span>


<div class="viewcode-block" id="diag"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.diag.html#mindspore.numpy.diag">[docs]</a><span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extracts a diagonal or construct a diagonal array.</span>

<span class="sd">    Args:</span>
<span class="sd">        v (Tensor): If `v` is a 2-D array, return a copy of its `k-th` diagonal.</span>
<span class="sd">            If `v` is a 1-D array, return a 2-D array with v on the `k-th` diagonal.</span>
<span class="sd">        k (int, optional): Diagonal in question. The default is 0. Use ``k&gt;0`` for</span>
<span class="sd">            diagonals above the main diagonal, and ``k&lt;0`` for diagonals below the</span>
<span class="sd">            main diagonal.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, the extracted diagonal or constructed diagonal array.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: if input is not 1-D or 2-D.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; x = np.arange(9).reshape((3,3))</span>
<span class="sd">        &gt;&gt;&gt; print(x)</span>
<span class="sd">        [[0 1 2]</span>
<span class="sd">        [3 4 5]</span>
<span class="sd">        [6 7 8]]</span>
<span class="sd">        &gt;&gt;&gt; output = np.diag(x)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [0 4 8]</span>
<span class="sd">        &gt;&gt;&gt; output = np.diag(x, k=1)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [1 5]</span>
<span class="sd">        &gt;&gt;&gt; output = np.diag(x, k=-1)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [3 7]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">diagflat</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">_is_shape_empty</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">_empty</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
        <span class="n">e</span> <span class="o">=</span> <span class="n">eye</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">k</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="n">prod</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_mul</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>

        <span class="n">cast_type</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_is_float</span><span class="p">(</span><span class="n">dtype</span><span class="p">):</span>
            <span class="c1"># reduce sum only supports float types</span>
            <span class="n">cast_type</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span>
            <span class="n">prod</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">prod</span><span class="p">,</span> <span class="n">cast_type</span><span class="p">)</span>

        <span class="n">res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">prod</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="n">_max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="n">k</span><span class="p">):</span> <span class="n">_min</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">_max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">k</span><span class="p">))]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_same_type</span><span class="p">(</span><span class="n">cast_type</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">res</span>
    <span class="k">return</span> <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;Input must be 1- or 2-d.&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="diagflat"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.diagflat.html#mindspore.numpy.diagflat">[docs]</a><span class="k">def</span> <span class="nf">diagflat</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a two-dimensional array with the flattened input as a diagonal.</span>

<span class="sd">    Note:</span>
<span class="sd">        On GPU, the supported dtypes are np.float16, and np.float32.</span>

<span class="sd">    Args:</span>
<span class="sd">        v (Tensor): Input data, which is flattened and set as the `k-th` diagonal</span>
<span class="sd">            of the output.</span>
<span class="sd">        k (int, optional): Diagonal to set; 0, the default, corresponds to the</span>
<span class="sd">            main diagonal, a positive (negative) `k` giving the number of the</span>
<span class="sd">            diagonal above (below) the main.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, The 2-D output array.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: if the input is not a tensor.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; output = np.diagflat(np.asarray([[1,2], [3,4]]))</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[1 0 0 0]</span>
<span class="sd">        [0 2 0 0]</span>
<span class="sd">        [0 0 3 0]</span>
<span class="sd">        [0 0 0 4]]</span>
<span class="sd">        &gt;&gt;&gt; output = np.diagflat(np.asarray([1,2]), 1)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[0 1 0]</span>
<span class="sd">        [0 0 2]</span>
<span class="sd">        [0 0 0]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_input_tensor</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">k_abs</span> <span class="o">=</span> <span class="n">_abs</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">_is_shape_empty</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">v</span><span class="p">)):</span>
        <span class="k">return</span> <span class="n">zeros</span><span class="p">((</span><span class="n">k_abs</span><span class="p">,</span> <span class="n">k_abs</span><span class="p">),</span> <span class="n">dtype</span><span class="p">)</span>

    <span class="n">v</span> <span class="o">=</span> <span class="n">ravel</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">v</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">eye</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_mul</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">pad_y</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">((</span><span class="n">size</span><span class="p">,</span> <span class="n">k_abs</span><span class="p">),</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="n">pad_x</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">((</span><span class="n">k_abs</span><span class="p">,</span> <span class="n">size</span> <span class="o">+</span> <span class="n">k_abs</span><span class="p">),</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">((</span><span class="n">res</span><span class="p">,</span> <span class="n">pad_y</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">((</span><span class="n">pad_x</span><span class="p">,</span> <span class="n">res</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">((</span><span class="n">pad_y</span><span class="p">,</span> <span class="n">res</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">((</span><span class="n">res</span><span class="p">,</span> <span class="n">pad_x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="diag_indices"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.diag_indices.html#mindspore.numpy.diag_indices">[docs]</a><span class="k">def</span> <span class="nf">diag_indices</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the indices to access the main diagonal of an array.</span>

<span class="sd">    This returns a tuple of indices that can be used to access the main</span>
<span class="sd">    diagonal of an array a with ``a.ndim &gt;= 2`` dimensions and shape `(n, n, , n)`.</span>
<span class="sd">    For ``a.ndim = 2`` this is the usual diagonal, for ``a.ndim &gt; 2`` this is the set</span>
<span class="sd">    of indices to access ``a[i, i, ..., i]`` for ``i = [0..n-1]``.</span>

<span class="sd">    Args:</span>
<span class="sd">        n (int): The size, along each dimension, of the arrays for which</span>
<span class="sd">            the returned indices can be used.</span>
<span class="sd">        ndim (int, optional): The number of dimensions.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple of Tensor.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: if input are not integers.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; output = np.diag_indices(5, 3)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        (Tensor(shape=[5], dtype=Int32, value= [0, 1, 2, 3, 4]),</span>
<span class="sd">        Tensor(shape=[5], dtype=Int32, value= [0, 1, 2, 3, 4]),</span>
<span class="sd">        Tensor(shape=[5], dtype=Int32, value= [0, 1, 2, 3, 4]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s1">&#39;input must be integers&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_list_comprehensions</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="n">n</span><span class="p">),</span> <span class="kc">True</span><span class="p">)</span></div>


<div class="viewcode-block" id="ix_"><a class="viewcode-back" href="../../../mindspore/numpy/mindspore.numpy.ix_.html#mindspore.numpy.ix_">[docs]</a><span class="k">def</span> <span class="nf">ix_</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs an open mesh from multiple sequences.</span>

<span class="sd">    This function takes `N` 1-D sequences and returns `N` outputs with `N`</span>
<span class="sd">    dimensions each, such that the shape is 1 in all but one dimension</span>
<span class="sd">    and the dimension with the non-unit shape value cycles through all</span>
<span class="sd">    N dimensions.</span>
<span class="sd">    Using ix\_ one can quickly construct index arrays that will index</span>
<span class="sd">    the cross product. ``a[np.ix_([1,3],[2,5])]`` returns the array</span>
<span class="sd">    ``[[a[1,2] a[1,5]], [a[3,2] a[3,5]]]``.</span>

<span class="sd">    Note:</span>
<span class="sd">        Boolean masks are not supported.</span>

<span class="sd">    Args:</span>
<span class="sd">        *args (Tensor): 1-D sequences.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple of Tensor, `N` arrays with `N` dimensions each, with `N` the</span>
<span class="sd">        number of input sequences. Together these arrays form an open</span>
<span class="sd">        mesh.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: if the input is not a tensor.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; ixgrid = np.ix_(np.array([0, 1]), np.array([2, 4]))</span>
<span class="sd">        &gt;&gt;&gt; print(ixgrid)</span>
<span class="sd">        (Tensor(shape=[2, 1], dtype=Int32, value=</span>
<span class="sd">        [[0],</span>
<span class="sd">        [1]]), Tensor(shape=[1, 2], dtype=Int32, value=</span>
<span class="sd">        [[2, 4]]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_input_tensor</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">arr</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_raise_value_error</span><span class="p">(</span><span class="s1">&#39;Cross index must be 1 dimensional&#39;</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">+=</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">_expanded_shape</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="n">arr</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">i</span><span class="p">)),)</span>
    <span class="k">return</span> <span class="n">res</span></div>


<span class="k">def</span> <span class="nf">vander</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">increasing</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates a Vandermonde matrix.</span>

<span class="sd">    The columns of the output matrix are powers of the input vector. The order of</span>
<span class="sd">    the powers is determined by the increasing boolean argument. Specifically, when</span>
<span class="sd">    increasing is `False`, the i-th output column is the input vector raised element-wise</span>
<span class="sd">    to the power of :math:`N - i - 1`. Such a matrix with a geometric progression in each row</span>
<span class="sd">    is named for Alexandre-Theophile Vandermonde.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Union[list, tuple, Tensor]): 1-D input array.</span>
<span class="sd">        N (int, optional): Number of columns in the output. If N is not specified, a</span>
<span class="sd">            square array is returned (``N = len(x)``).</span>
<span class="sd">        increasing (bool, optional): Order of the powers of the columns. If True, the</span>
<span class="sd">            powers increase from left to right, if False (the default) they are reversed.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Vandermonde matrix. If `increasing` is `False`, the first column is :math:`x^{(N-1)}`,</span>
<span class="sd">        the second :math:`x^{(N-2)}` and so forth. If `increasing` is `True`, the columns are</span>
<span class="sd">        :math:`x^0, x^1, ..., x^{(N-1)}`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If inputs have types not specified above.</span>
<span class="sd">        ValueError: If `x` is not 1-D, or `N` &lt; 0.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.vander([1,2,3,4,5]))</span>
<span class="sd">        [[  1   1   1   1   1]</span>
<span class="sd">         [ 16   8   4   2   1]</span>
<span class="sd">         [ 81  27   9   3   1]</span>
<span class="sd">         [256  64  16   4   1]</span>
<span class="sd">         [625 125  25   5   1]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">asarray_const</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;Input x must be list, tuple or Tensor, but got &quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;Input x must be 1-D, but got dimension=&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">N</span> <span class="ow">or</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;Input N must be an integer.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">N</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;Input N must &gt; 0.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">increasing</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;increasing must be a bool.&quot;</span><span class="p">)</span>
    <span class="n">exponent</span> <span class="o">=</span> <span class="n">_iota</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">increasing</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">exponent</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">exponent</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">exponent</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">indices</span><span class="p">(</span><span class="n">dimensions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns an array representing the indices of a grid.</span>

<span class="sd">    Computes an array where the subarrays contain index values 0, 1, </span>
<span class="sd">    varying only along the corresponding axis.</span>

<span class="sd">    Args:</span>
<span class="sd">        dimensions (tuple or list of ints): The shape of the grid.</span>
<span class="sd">        dtype (data type, optional): Data type of the result.</span>
<span class="sd">        sparse (boolean, optional): Defaults to False. Return a sparse</span>
<span class="sd">            representation of the grid instead of a dense representation.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor or tuple of Tensor, If `sparse` is False, returns one array</span>
<span class="sd">        of grid indices, ``grid.shape = (len(dimensions),) + tuple(dimensions)``.</span>
<span class="sd">        If sparse is True, returns a tuple of arrays, with</span>
<span class="sd">        ``grid[i].shape = (1, ..., 1, dimensions[i], 1, ..., 1)`` with</span>
<span class="sd">        ``dimensions[i]`` in the `ith` place</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: if input dimensions is not a tuple or list.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; grid = np.indices((2, 3))</span>
<span class="sd">        &gt;&gt;&gt; print(grid)</span>
<span class="sd">        [Tensor(shape=[2, 3], dtype=Int32, value=</span>
<span class="sd">        [[0, 0, 0],</span>
<span class="sd">        [1, 1, 1]]), Tensor(shape=[2, 3], dtype=Int32, value=</span>
<span class="sd">        [[0, 1, 2],</span>
<span class="sd">        [0, 1, 2]])]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dimensions</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s1">&#39;Shape of the grid must be tuple or list&#39;</span><span class="p">)</span>
    <span class="n">grids</span> <span class="o">=</span> <span class="p">()</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">dimensions</span><span class="p">:</span>
        <span class="n">grids</span> <span class="o">+=</span> <span class="p">(</span><span class="n">arange</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),)</span>
    <span class="k">return</span> <span class="n">meshgrid</span><span class="p">(</span><span class="o">*</span><span class="n">grids</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="n">sparse</span><span class="p">,</span> <span class="n">indexing</span><span class="o">=</span><span class="s1">&#39;ij&#39;</span><span class="p">)</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>