<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Backend Running &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Programming Language Extensions" href="programming_language_extensions.html" />
    <link rel="prev" title="Platform and System" href="platform_and_system.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="supported_operators.html">Supported Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="network_models.html">Network Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="platform_and_system.html">Platform and System</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Backend Running</a></li>
<li class="toctree-l1"><a class="reference internal" href="programming_language_extensions.html">Programming Language Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="supported_features.html">Supported Features</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Backend Running</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/backend_running.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="backend-running">
<h1>Backend Running<a class="headerlink" href="#backend-running" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">Environmental</span> <span class="pre">Setup</span></code> <code class="docutils literal notranslate"><span class="pre">Operation</span> <span class="pre">Mode</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Training</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/tree/r1.0/docs/faq/source_en/backend_running.md" target="_blank"><img src="./_static/logo_source.png"></a></p>
<p><font size=3><strong>Q: What can I do if the network performance is abnormal and weight initialization takes a long time during training after MindSpore is installed?</strong></font></p>
<p>A: The <code class="docutils literal notranslate"><span class="pre">SciPy</span> <span class="pre">1.4</span></code> series versions may be used in the environment. Run the <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">list</span> <span class="pre">|</span> <span class="pre">grep</span> <span class="pre">scipy</span></code> command to view the <code class="docutils literal notranslate"><span class="pre">SciPy</span></code> version and change the <code class="docutils literal notranslate"><span class="pre">SciPy</span></code> version to that required by MindSpore. You can view the third-party library dependency in the <code class="docutils literal notranslate"><span class="pre">requirement.txt</span></code> file.
<a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/version/requirements.txt">https://gitee.com/mindspore/mindspore/blob/version/requirements.txt</a></p>
<blockquote>
<div><p>Replace version with the specific version branch of MindSpore.</p>
</div></blockquote>
<br/>
<p><font size=3><strong>Q: Can MindSpore be used to customize a loss function that can return multiple values?</strong></font></p>
<p>A: After customizing the <code class="docutils literal notranslate"><span class="pre">loss</span> <span class="pre">function</span></code>, you need to customize <code class="docutils literal notranslate"><span class="pre">TrainOneStepCell</span></code>. The number of <code class="docutils literal notranslate"><span class="pre">sens</span></code> for implementing gradient calculation is the same as the number of <code class="docutils literal notranslate"><span class="pre">network</span></code> outputs. For details, see the following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">MyLoss</span><span class="p">()</span>

<span class="n">loss_with_net</span> <span class="o">=</span> <span class="n">MyWithLossCell</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>

<span class="n">train_net</span> <span class="o">=</span> <span class="n">MyTrainOneStepCell</span><span class="p">(</span><span class="n">loss_with_net</span><span class="p">,</span> <span class="n">optim</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="o">=</span><span class="n">train_net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: How does MindSpore implement the early stopping function?</strong></font></p>
<p>A: You can customize the <code class="docutils literal notranslate"><span class="pre">callback</span></code> method to implement the early stopping function.
Example: When the loss value decreases to a certain value, the training stops.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">EarlyStop</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">control_loss</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">EarlyStep</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_control_loss</span> <span class="o">=</span> <span class="n">control_loss</span>

    <span class="k">def</span> <span class="nf">step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">net_outputs</span>
        <span class="k">if</span> <span class="n">loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_control_loss</span><span class="p">:</span>
            <span class="c1"># Stop training.</span>
            <span class="n">run_context</span><span class="o">.</span><span class="n">_stop_requested</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">stop_cb</span> <span class="o">=</span> <span class="n">EarlyStop</span><span class="p">(</span><span class="n">control_loss</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch_size</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">stop_cb</span><span class="p">])</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: What can I do if an error message <code class="docutils literal notranslate"><span class="pre">wrong</span> <span class="pre">shape</span> <span class="pre">of</span> <span class="pre">image</span></code> is displayed when I use a model trained by MindSpore to perform prediction on a <code class="docutils literal notranslate"><span class="pre">28</span> <span class="pre">x</span> <span class="pre">28</span></code> digital image with white text on a black background?</strong></font></p>
<p>A: The MNIST gray scale image dataset is used for MindSpore training. Therefore, when the model is used, the data must be set to a <code class="docutils literal notranslate"><span class="pre">28</span> <span class="pre">x</span> <span class="pre">28</span></code> gray scale image, that is, a single channel.</p>
<br/>
<p><font size=3><strong>Q: What can I do if the error message <code class="docutils literal notranslate"><span class="pre">device</span> <span class="pre">target</span> <span class="pre">[CPU]</span> <span class="pre">is</span> <span class="pre">not</span> <span class="pre">supported</span> <span class="pre">in</span> <span class="pre">pynative</span> <span class="pre">mode</span></code> is displayed for the operation operator of MindSpore?</strong></font></p>
<p>A: Currently, the PyNative mode supports only Ascend and GPU and does not support the CPU.</p>
<br/>
<p><font size=3><strong>Q: For Ascend users, how to get more detailed logs when the <code class="docutils literal notranslate"><span class="pre">run</span> <span class="pre">task</span> <span class="pre">error</span></code> is reported?</strong></font></p>
<p>A: More detailed logs info can be obtained by modify slog config file. You can get different level by modify <code class="docutils literal notranslate"><span class="pre">/var/log/npu/conf/slog/slog.conf</span></code>. The values are as follows: 0:debug、1:info、2:warning、3:error、4:null(no output log), default 1.</p>
<br/>
<p><font size=3><strong>Q: What can I do if the error message <code class="docutils literal notranslate"><span class="pre">Pynative</span> <span class="pre">run</span> <span class="pre">op</span> <span class="pre">ExpandDims</span> <span class="pre">failed</span></code> is displayed when the ExpandDims operator is used? The code is as follows:</strong></font></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span>
<span class="n">mode</span><span class="o">=</span><span class="n">cintext</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span>
<span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;ascend&#39;</span><span class="p">)</span>
<span class="n">input_tensor</span><span class="o">=</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]]),</span><span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">expand_dims</span><span class="o">=</span><span class="n">ops</span><span class="o">.</span><span class="n">ExpandDims</span><span class="p">()</span>
<span class="n">output</span><span class="o">=</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>A: The problem is that the Graph mode is selected but the PyNative mode is used. As a result, an error is reported. MindSpore supports the following running modes which are optimized in terms of debugging or running:</p>
<ul class="simple">
<li><p>PyNative mode: dynamic graph mode. In this mode, operators in the neural network are delivered and executed one by one, facilitating the compilation and debugging of the neural network model.</p></li>
<li><p>Graph mode: static graph mode. In this mode, the neural network model is compiled into an entire graph and then delivered for execution. This mode uses technologies such as graph optimization to improve the running performance and facilitates large-scale deployment and cross-platform running.</p></li>
</ul>
<p>You can select a proper mode and writing method to complete the training by referring to the official website <a class="reference external" href="https://www.mindspore.cn/tutorial/training/en/r1.0/advanced_use/debug_in_pynative_mode.html">tutorial</a>.</p>
<br/>
<p><font size=3><strong>Q: How to fix the error below when running MindSpore distributed training with GPU:</strong></font></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Loading libgpu_collective.so failed. Many reasons could cause this:
1.libgpu_collective.so is not installed.
2.nccl is not installed or found.
3.mpi is not installed or found
</pre></div>
</div>
<p>A: This message means that MindSpore failed to load library <code class="docutils literal notranslate"><span class="pre">libgpu_collective.so</span></code>. The Possible causes are:</p>
<ul class="simple">
<li><p>OpenMPI or NCCL is not installed in this environment.</p></li>
<li><p>NCCL version is not updated to <code class="docutils literal notranslate"><span class="pre">v2.7.6</span></code>: MindSpore <code class="docutils literal notranslate"><span class="pre">v1.1.0</span></code> supports GPU P2P communication operator which relies on NCCL <code class="docutils literal notranslate"><span class="pre">v2.7.6</span></code>. <code class="docutils literal notranslate"><span class="pre">libgpu_collective.so</span></code> can’t be loaded successfully if NCCL is not updated to this version.</p></li>
</ul>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="platform_and_system.html" class="btn btn-neutral float-left" title="Platform and System" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="programming_language_extensions.html" class="btn btn-neutral float-right" title="Programming Language Extensions" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>