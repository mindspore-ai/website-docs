<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Network Models &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Platform and System" href="platform_and_system.html" />
    <link rel="prev" title="Supported Operators" href="supported_operators.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="supported_operators.html">Supported Operators</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Network Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="platform_and_system.html">Platform and System</a></li>
<li class="toctree-l1"><a class="reference internal" href="backend_running.html">Backend Running</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="programming_language_extensions.html">Programming Language Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="supported_features.html">Supported Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_use.html">MindInsight use</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_lite.html">MindSpore Lite Use</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_cpp_library.html">MindSpore C++ Library Use</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_serving.html">MindSpore Serving Class</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Network Models</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/network_models.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="network-models">
<h1>Network Models<a class="headerlink" href="#network-models" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Data</span> <span class="pre">Processing</span></code> <code class="docutils literal notranslate"><span class="pre">Environmental</span> <span class="pre">Setup</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Export</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Training</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.2/docs/faq/source_en/network_models.md"><img alt="View Source On Gitee" src="_images/logo_source.png" /></a></p>
<p><font size=3><strong>Q: How do I understand the <code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">model.train</span></code> of MindSpore?</strong></font></p>
<p>A: When <code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, data processing and network computing are performed in pipeline mode. That is, when data processing is performed step by step, after a <code class="docutils literal notranslate"><span class="pre">batch</span></code> of data is processed, the data is placed in a queue which is used to cache the processed data. Then, network computing obtains data from the queue for training. In this case, data processing and network computing are performed in pipeline mode. The entire training duration is the longest data processing/network computing duration.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code> is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, data processing and network computing are performed in serial mode. That is, after a <code class="docutils literal notranslate"><span class="pre">batch</span></code> of data is processed, it is transferred to the network for computation. After the computation is complete, the next <code class="docutils literal notranslate"><span class="pre">batch</span></code> of data is processed and transferred to the network for computation. This process repeats until the training is complete. The total time consumed is the time consumed for data processing plus the time consumed for network computing.</p>
<br/>
<p><font size=3><strong>Q: Can MindSpore train image data of different sizes by batch?</strong></font></p>
<p>A: You can refer to the usage of YOLOv3 which contains the resizing of different images. For details about the script, see <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/model_zoo/official/cv/yolov3_darknet53/src/yolo_dataset.py">yolo_dataset</a>.</p>
<br/>
<p><font size=3><strong>Q: Can the <code class="docutils literal notranslate"><span class="pre">vgg16</span></code> model be loaded and transferred on a GPU using the Hub?</strong></font></p>
<p>A: Yes, but you need to manually modify the following two arguments:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Add the **kwargs argument as follows:</span>
<span class="k">def</span> <span class="nf">vgg16</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">phase</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Add the **kwargs argument as follows:</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Vgg</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s1">&#39;16&#39;</span><span class="p">],</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_norm</span><span class="p">,</span> <span class="n">phase</span><span class="o">=</span><span class="n">phase</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: How to obtain middle-layer features of a VGG model?</strong></font></p>
<p>A: Obtaining the middle-layer features of a network is not closely related to the specific framework. For the <code class="docutils literal notranslate"><span class="pre">vgg</span></code> model defined in <code class="docutils literal notranslate"><span class="pre">torchvison</span></code>, the <code class="docutils literal notranslate"><span class="pre">features</span></code> field can be used to obtain the middle-layer features. The <code class="docutils literal notranslate"><span class="pre">vgg</span></code> source code of <code class="docutils literal notranslate"><span class="pre">torchvison</span></code> is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">VGG</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">init_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VGG</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">vgg16</span></code> defined in ModelZoo of MindSpore can be obtained through the <code class="docutils literal notranslate"><span class="pre">layers</span></code> field as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">network</span> <span class="o">=</span> <span class="n">vgg16</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: When MindSpore is used for model training, there are four input parameters for <code class="docutils literal notranslate"><span class="pre">CTCLoss</span></code>: <code class="docutils literal notranslate"><span class="pre">inputs</span></code>, <code class="docutils literal notranslate"><span class="pre">labels_indices</span></code>, <code class="docutils literal notranslate"><span class="pre">labels_values</span></code>, and <code class="docutils literal notranslate"><span class="pre">sequence_length</span></code>. How do I use <code class="docutils literal notranslate"><span class="pre">CTCLoss</span></code> for model training?</strong></font></p>
<p>A: The <code class="docutils literal notranslate"><span class="pre">dataset</span></code> received by the defined <code class="docutils literal notranslate"><span class="pre">model.train</span></code> API can consist of multiple pieces of data, for example, (<code class="docutils literal notranslate"><span class="pre">data1</span></code>, <code class="docutils literal notranslate"><span class="pre">data2</span></code>, <code class="docutils literal notranslate"><span class="pre">data3</span></code>, …). Therefore, the <code class="docutils literal notranslate"><span class="pre">dataset</span></code> can contain <code class="docutils literal notranslate"><span class="pre">inputs</span></code>, <code class="docutils literal notranslate"><span class="pre">labels_indices</span></code>, <code class="docutils literal notranslate"><span class="pre">labels_values</span></code>, and <code class="docutils literal notranslate"><span class="pre">sequence_length</span></code> information. You only need to define the dataset in the corresponding format and transfer it to <code class="docutils literal notranslate"><span class="pre">model.train</span></code>. For details, see <a class="reference external" href="https://www.mindspore.cn/doc/programming_guide/en/r1.2/dataset_loading.html">Data Processing API</a>.</p>
<br/>
<p><font size=3><strong>Q: How do I load the PyTorch weight to MindSpore during model transfer?</strong></font></p>
<p>A: First, enter the <code class="docutils literal notranslate"><span class="pre">PTH</span></code> file of PyTorch. Take <code class="docutils literal notranslate"><span class="pre">ResNet-18</span></code> as an example. The network structure of MindSpore is the same as that of PyTorch. After transferring, the file can be directly loaded to the network. Only <code class="docutils literal notranslate"><span class="pre">BN</span></code> and <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> are used during loading. If the network names of MindSpore and PyTorch at other layers are different, change the names to the same.</p>
<br/>
<p><font size=3><strong>Q: After a model is trained, how do I save the model output in text or <code class="docutils literal notranslate"><span class="pre">npy</span></code> format?</strong></font></p>
<p>A: The network output is <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>. You need to use the <code class="docutils literal notranslate"><span class="pre">asnumpy()</span></code> method to convert the <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> to <code class="docutils literal notranslate"><span class="pre">NumPy</span></code> and then save the data. For details, see the following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;output.npy&quot;</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: Must data be converted into MindRecords when MindSpore is used for segmentation training?</strong></font></p>
<p>A: <a class="reference external" href="https://github.com/mindspore-ai/mindspore/blob/r1.2/model_zoo/official/cv/deeplabv3/src/data/build_seg_data.py">build_seg_data.py</a> is used to generate MindRecords based on a dataset. You can directly use or adapt it to your dataset. Alternatively, you can use <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> if you want to read the dataset by yourself.</p>
<p><a class="reference external" href="https://www.mindspore.cn/doc/programming_guide/en/r1.2/dataset_loading.html#loading-user-defined-dataset">GenratorDataset example</a></p>
<p><a class="reference external" href="https://www.mindspore.cn/doc/api_python/en/r1.2/mindspore/dataset/mindspore.dataset.GeneratorDataset.html#mindspore.dataset.GeneratorDataset">GeneratorDataset API description</a></p>
<br/>
<p><font size=3><strong>Q: Can MindSpore read a TensorFlow checkpoint?</strong></font></p>
<p>A: The checkpoint format of MindSpore is different from that of TensorFlow. Although both use the Protocol Buffers, their definitions are different. Currently, MindSpore cannot read the TensorFlow or Pytorch checkpoints.</p>
<br/>
<p><font size=3><strong>Q: How do I perform training without processing data in MindRecord format?</strong></font></p>
<p>A: You can use the customized data loading method <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>. For details, click <a class="reference external" href="https://www.mindspore.cn/tutorial/en/r0.7/use/data_preparation/loading_the_datasets.html#id5">here</a>.</p>
<br/>
<p><font size=3><strong>Q: What framework models and formats can be directly read by MindSpore? Can the PTH Model Obtained Through Training in PyTorch Be Loaded to the MindSpore Framework for Use?</strong></font></p>
<p>A: MindSpore uses protocol buffers (protobuf) to store training parameters and cannot directly read framework models. A model file stores parameters and their values. You can use APIs of other frameworks to read parameters, obtain the key-value pairs of parameters, and load the key-value pairs to MindSpore. If you want to use the .ckpt file trained by a framework, read the parameters and then call the <code class="docutils literal notranslate"><span class="pre">save_checkpoint</span></code> API of MindSpore to save the file as a .ckpt file that can be read by MindSpore.</p>
<br/>
<p><font size=3><strong>Q: How do I use models trained by MindSpore on Ascend 310? Can they be converted to models used by HiLens Kit?</strong></font></p>
<p>A: Yes. HiLens Kit uses Ascend 310 as the inference core. Therefore, the two questions are essentially the same. Ascend 310 requires a dedicated OM model. Use MindSpore to export the ONNX or AIR model and convert it into an OM model supported by Ascend 310. For details, see <a class="reference external" href="https://www.mindspore.cn/tutorial/inference/en/r1.2/multi_platform_inference_ascend_310.html">Multi-platform Inference</a>.</p>
<br/>
<p><font size=3><strong>Q: How do I modify parameters (such as the dropout value) on MindSpore?</strong></font></p>
<p>A: When building a network, use <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">self.training:</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">dropput(x)</span></code>. During verification, set <code class="docutils literal notranslate"><span class="pre">network.set_train(mode_false)</span></code> before execution to disable the dropout function. During training, set <code class="docutils literal notranslate"><span class="pre">network.set_train(mode_false)</span></code> to True to enable the dropout function.</p>
<br/>
<p><font size=3><strong>Q: Where can I view the sample code or tutorial of MindSpore training and inference?</strong></font></p>
<p>A: Please visit the <a class="reference external" href="https://www.mindspore.cn/tutorial/training/en/r1.2/index.html">MindSpore official website training</a> and <a class="reference external" href="https://www.mindspore.cn/tutorial/inference/en/r1.2/index.html">MindSpore official website inference</a>.</p>
<br/>
<p><font size=3><strong>Q: What types of model is currently supported by MindSpore for training?</strong></font></p>
<p>A: MindSpore has basic support for common training scenarios, please refer to <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/RELEASE.md#">Release note</a> for detailed information.</p>
<br/>
<p><font size=3><strong>Q: What are the available recommendation or text generation networks or models provided by MindSpore?</strong></font></p>
<p>A: Currently, recommendation models such as Wide &amp; Deep, DeepFM, and NCF are under development. In the natural language processing (NLP) field, Bert_NEZHA is available and models such as MASS are under development. You can rebuild the network into a text generation network based on the scenario requirements. Please stay tuned for updates on the <a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.2/model_zoo">MindSpore Model Zoo</a>.</p>
<br/>
<p><font size=3><strong>Q: How simple can the MindSpore model training code be?</strong></font></p>
<p>A: MindSpore provides Model APIs except for network definitions. In most scenarios, model training can be completed using only a few lines of code.</p>
<br/>
<p><font size=3><strong>Q: How do I use MindSpore to fit functions such as <span class="math notranslate nohighlight">\(f(x)=a \times sin(x)+b\)</span>?</strong></font></p>
<p>A: The following is based on the official MindSpore linear fitting case.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># The fitting function is：f(x)=2*sin(x)+3.</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dataset</span> <span class="k">as</span> <span class="n">ds</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">Normal</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">Model</span><span class="p">,</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">LossMonitor</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">3.0</span><span class="p">):</span>
    <span class="c1"># f(x)=w * sin(x) + b</span>
    <span class="c1"># f(x)=2 * sin(x) +3</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">noise</span>
        <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">num_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">repeat_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">get_data</span><span class="p">(</span><span class="n">num_data</span><span class="p">)),</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">,</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repeat_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_data</span>

<span class="k">class</span> <span class="nc">LinearNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">),</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>

    <span class="n">num_data</span> <span class="o">=</span> <span class="mi">1600</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">repeat_size</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.005</span>
    <span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>

    <span class="n">net</span> <span class="o">=</span> <span class="n">LinearNet</span><span class="p">()</span>
    <span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>

    <span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">num_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">repeat_size</span><span class="o">=</span><span class="n">repeat_size</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">LossMonitor</span><span class="p">(),</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: How do I use MindSpore to fit quadratic functions such as <span class="math notranslate nohighlight">\(f(x)=ax^2+bx+c\)</span>?</strong></font></p>
<p>A: The following code is referenced from the official <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.2/tutorials/tutorial_code/linear_regression.py">MindSpore tutorial code</a>.</p>
<p>Modify the following items to fit <span class="math notranslate nohighlight">\(f(x) = ax^2 + bx + c\)</span>:</p>
<ol class="arabic simple">
<li><p>Dataset generation.</p></li>
<li><p>Network fitting.</p></li>
<li><p>Optimizer.</p></li>
</ol>
<p>The following explains detailed information about the modification:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># The selected optimizer does not support CPUs. Therefore, the GPU computing platform is used for training. You need to install MindSpore of the GPU version.</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;GPU&quot;</span><span class="p">)</span>

<span class="c1"># Assume that the function to be fitted is f(x)=2x^2+3x+4. Modify the data generation function as follows:</span>
<span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">3.0</span> <span class="p">,</span><span class="n">c</span> <span class="o">=</span> <span class="mi">4</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># For details about how to generate the value of y, see the to-be-fitted objective function ax^2+bx+c.</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="n">a</span> <span class="o">+</span> <span class="n">x</span> <span class="o">*</span> <span class="n">b</span> <span class="o">+</span> <span class="n">c</span> <span class="o">+</span> <span class="n">noise</span>
        <span class="c1"># When fitting a*x^2 + b*x +c, a and b are weight parameters, and c is the offset parameter bias. The training data corresponding to the two weights is x^2 and x, respectively. Therefore, the dataset generation mode is changed as follows:</span>
        <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">num_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">repeat_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">get_data</span><span class="p">(</span><span class="n">num_data</span><span class="p">)),</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">,</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repeat_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_data</span>

<span class="k">class</span> <span class="nc">LinearNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Two training parameters are input for the full connection function. Therefore, the input value is changed to 2. The first Normal(0.02) automatically allocates random weights to the two input parameters, and the second Normal is the random bias.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">),</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">num_data</span> <span class="o">=</span> <span class="mi">1600</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">repeat_size</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.005</span>
    <span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>

    <span class="n">net</span> <span class="o">=</span> <span class="n">LinearNet</span><span class="p">()</span>
    <span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="c1"># RMSProp optimizer with better effect is selected for quadratic function fitting. Currently, Ascend and GPU computing platforms are supported.</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RMSProp</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>

    <span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">num_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">repeat_size</span><span class="o">=</span><span class="n">repeat_size</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">LossMonitor</span><span class="p">(),</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q：What should I do if a Protobuf memory limit error is reported during the process of using ckpt or exporting a model?</strong></font></p>
<p>A：When a single Protobuf data is too large, because Protobuf itself limits the size of the data stream, a memory limit error will be reported. At this time, the restriction can be lifted by setting the environment variable <code class="docutils literal notranslate"><span class="pre">PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python</span></code>.</p>
<p><font size=3>**Q: When the third-party component gensim is used to train the NLP network, the error “ValueError” may be reported. What can I do? **</font></p>
<p>A：The following error information is displayed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt;<span class="w"> </span>import<span class="w"> </span>gensim
Traceback<span class="w"> </span><span class="o">(</span>most<span class="w"> </span>recent<span class="w"> </span>call<span class="w"> </span>last<span class="o">)</span>:
<span class="w">  </span>File<span class="w"> </span><span class="s2">&quot;&lt;stdin&gt;&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>&lt;module&gt;
<span class="w">  </span>File<span class="w"> </span><span class="s2">&quot;/home/miniconda3/envs/ci39_cj/lib/python3.9/site-packages/gensim/__init__.py&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">11</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>&lt;module&gt;
<span class="w">    </span>from<span class="w"> </span>gensim<span class="w"> </span>import<span class="w"> </span>parsing,<span class="w"> </span>corpora,<span class="w"> </span>matutils,<span class="w"> </span>interfaces,<span class="w"> </span>models,<span class="w"> </span>similarities,<span class="w"> </span>utils<span class="w">  </span><span class="c1"># noqa:F401</span>
<span class="w">  </span>File<span class="w"> </span><span class="s2">&quot;/home/miniconda3/envs/ci39_cj/lib/python3.9/site-packages/gensim/corpora/__init__.py&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">6</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>&lt;module&gt;
<span class="w">    </span>from<span class="w"> </span>.indexedcorpus<span class="w"> </span>import<span class="w"> </span>IndexedCorpus<span class="w">  </span><span class="c1"># noqa:F401 must appear before the other classes</span>
<span class="w">  </span>File<span class="w"> </span><span class="s2">&quot;/home/miniconda3/envs/ci39_cj/lib/python3.9/site-packages/gensim/corpora/indexedcorpus.py&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">14</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>&lt;module&gt;
<span class="w">    </span>from<span class="w"> </span>gensim<span class="w"> </span>import<span class="w"> </span>interfaces,<span class="w"> </span>utils
<span class="w">  </span>File<span class="w"> </span><span class="s2">&quot;/home/miniconda3/envs/ci39_cj/lib/python3.9/site-packages/gensim/interfaces.py&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">19</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>&lt;module&gt;
<span class="w">    </span>from<span class="w"> </span>gensim<span class="w"> </span>import<span class="w"> </span>utils,<span class="w"> </span>matutils
<span class="w">  </span>File<span class="w"> </span><span class="s2">&quot;/home/miniconda3/envs/ci39_cj/lib/python3.9/site-packages/gensim/matutils.py&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">1024</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>&lt;module&gt;
<span class="w">    </span>from<span class="w"> </span>gensim._matutils<span class="w"> </span>import<span class="w"> </span>logsumexp,<span class="w"> </span>mean_absolute_difference,<span class="w"> </span>dirichlet_expectation
<span class="w">  </span>File<span class="w"> </span><span class="s2">&quot;gensim/_matutils.pyx&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>init<span class="w"> </span>gensim._matutils
ValueError:<span class="w"> </span>numpy.ndarray<span class="w"> </span>size<span class="w"> </span>changed,<span class="w"> </span>may<span class="w"> </span>indicate<span class="w"> </span>binary<span class="w"> </span>incompatibility.<span class="w"> </span>Expected<span class="w"> </span><span class="m">88</span><span class="w"> </span>from<span class="w"> </span>C<span class="w"> </span>header,<span class="w"> </span>got<span class="w"> </span><span class="m">80</span><span class="w"> </span>from<span class="w"> </span>PyObject
</pre></div>
</div>
<p>For details about the error cause, see the <a class="reference external" href="https://github.com/RaRe-Technologies/gensim/issues/3095">gensim</a> or <a class="reference external" href="https://github.com/numpy/numpy/issues/18709">numpy</a> official website.</p>
<p>Solutions:
Method 1: Reinstall the Numpy and Gensim and run the following commands: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">uninstall</span> <span class="pre">gensim</span> <span class="pre">numpy</span> <span class="pre">-y</span> <span class="pre">&amp;&amp;</span> <span class="pre">pip</span> <span class="pre">install</span> <span class="pre">numpy==1.18.5</span> <span class="pre">gensim</span></code>
Method 2: If the problem persists, delete the cache file of the wheel installation package and then perform method 1. (The cache directory of the wheel installation package is <code class="docutils literal notranslate"><span class="pre">~/.cache/pip/wheels</span></code>)</p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="supported_operators.html" class="btn btn-neutral float-left" title="Supported Operators" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="platform_and_system.html" class="btn btn-neutral float-right" title="Platform and System" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>