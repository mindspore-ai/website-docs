<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>网络模型类 &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="平台系统类" href="platform_and_system.html" />
    <link rel="prev" title="算子支持类" href="supported_operators.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">安装类</a></li>
<li class="toctree-l1"><a class="reference internal" href="supported_operators.html">算子支持类</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">网络模型类</a></li>
<li class="toctree-l1"><a class="reference internal" href="platform_and_system.html">平台系统类</a></li>
<li class="toctree-l1"><a class="reference internal" href="backend_running.html">后端运行类</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage_migrate_3rd.html">第三方框架迁移使用类</a></li>
<li class="toctree-l1"><a class="reference internal" href="programming_language_extensions.html">编程语言拓展类</a></li>
<li class="toctree-l1"><a class="reference internal" href="supported_features.html">特性支持类</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindinsight_use.html">可视化组件MindInsight使用类</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_lite.html">端侧使用类</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_cpp_library.html">C++接口使用类</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore_serving.html">MindSpore Serving类</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>网络模型类</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/network_models.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1>网络模型类<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">数据处理</span></code> <code class="docutils literal notranslate"><span class="pre">环境准备</span></code> <code class="docutils literal notranslate"><span class="pre">模型导出</span></code> <code class="docutils literal notranslate"><span class="pre">模型训练</span></code> <code class="docutils literal notranslate"><span class="pre">初级</span></code> <code class="docutils literal notranslate"><span class="pre">中级</span></code> <code class="docutils literal notranslate"><span class="pre">高级</span></code></p>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.2/docs/faq/source_zh_cn/network_models.md"><img alt="查看源文件" src="_images/logo_source.png" /></a></p>
<p><font size=3><strong>Q：MindSpore中<code class="docutils literal notranslate"><span class="pre">model.train</span></code>的<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code>参数该如何理解？</strong></font></p>
<p>A：当<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode=True</span></code>时，数据处理会和网络计算构成Pipeline方式，即：数据处理在逐步处理数据时，处理完一个<code class="docutils literal notranslate"><span class="pre">batch</span></code>的数据，会把数据放到一个队列里，这个队列用于缓存已经处理好的数据，然后网络计算从这个队列里面取数据用于训练，那么此时数据处理与网络计算就<code class="docutils literal notranslate"><span class="pre">Pipeline</span></code>起来了，整个训练耗时就是数据处理/网络计算耗时最长的那个。</p>
<p>当<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode=False</span></code>时，数据处理会和网络计算构成串行的过程，即：数据处理在处理完一个<code class="docutils literal notranslate"><span class="pre">batch</span></code>后，把这个<code class="docutils literal notranslate"><span class="pre">batch</span></code>的数据传递给网络用于计算，在计算完成后，数据处理再处理下一个<code class="docutils literal notranslate"><span class="pre">batch</span></code>，然后把这个新的<code class="docutils literal notranslate"><span class="pre">batch</span></code>数据传递给网络用于计算，如此的循环往复，直到训练完。该方法的总耗时是数据处理的耗时+网络计算的耗时=训练总耗时。</p>
<br/>
<p><font size=3><strong>Q：MindSpore能否支持按批次对不同尺寸的图片数据进行训练？</strong></font></p>
<p>A：你可以参考yolov3对于此场景的使用，里面有对于图像的不同缩放,脚本见<a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/model_zoo/official/cv/yolov3_darknet53/src/yolo_dataset.py">yolo_dataset</a>。</p>
<br/>
<p><font size=3><strong>Q：通过Hub可以使用GPU加载<code class="docutils literal notranslate"><span class="pre">vgg16</span></code>模型以及是否可以做迁移模型吗？</strong></font></p>
<p>A：请手动修改规避，修改如下两点即可：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 增加**kwargs参数：如下</span>
<span class="k">def</span> <span class="nf">vgg16</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">phase</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 增加**kwargs参数：如下</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Vgg</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s1">&#39;16&#39;</span><span class="p">],</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_norm</span><span class="p">,</span> <span class="n">phase</span><span class="o">=</span><span class="n">phase</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q：如何得到VGG模型中间层特征？</strong></font></p>
<p>A：你好，获取网络中间层的特征，其实跟具体框架没有太大关系了。<code class="docutils literal notranslate"><span class="pre">torchvison</span></code>里定义的<code class="docutils literal notranslate"><span class="pre">vgg</span></code>模型，可以通过<code class="docutils literal notranslate"><span class="pre">features</span></code>字段获取”中间层特征”，<code class="docutils literal notranslate"><span class="pre">torchvison</span></code>的<code class="docutils literal notranslate"><span class="pre">vgg</span></code>源码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">VGG</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">init_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VGG</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
</pre></div>
</div>
<p>在MindSpore的ModelZoo里定义的<code class="docutils literal notranslate"><span class="pre">vgg16</span></code>，可以通过<code class="docutils literal notranslate"><span class="pre">layers</span></code>字段获取，如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">network</span> <span class="o">=</span> <span class="n">vgg16</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q：使用MindSpore进行模型训练时，<code class="docutils literal notranslate"><span class="pre">CTCLoss</span></code>的输入参数有四个：<code class="docutils literal notranslate"><span class="pre">inputs</span></code>, <code class="docutils literal notranslate"><span class="pre">labels_indices</span></code>, <code class="docutils literal notranslate"><span class="pre">labels_values</span></code>, <code class="docutils literal notranslate"><span class="pre">sequence_length</span></code>，如何使用<code class="docutils literal notranslate"><span class="pre">CTCLoss</span></code>进行训练？</strong></font></p>
<p>A：定义的<code class="docutils literal notranslate"><span class="pre">model.train</span></code>接口里接收的<code class="docutils literal notranslate"><span class="pre">dataset</span></code>可以是多个数据组成，形如(<code class="docutils literal notranslate"><span class="pre">data1</span></code>, <code class="docutils literal notranslate"><span class="pre">data2</span></code>, <code class="docutils literal notranslate"><span class="pre">data3</span></code>, …)，所以<code class="docutils literal notranslate"><span class="pre">dataset</span></code>是可以包含<code class="docutils literal notranslate"><span class="pre">inputs</span></code>,<code class="docutils literal notranslate"><span class="pre">labels_indices</span></code>,<code class="docutils literal notranslate"><span class="pre">labels_values</span></code>,<code class="docutils literal notranslate"><span class="pre">sequence_length</span></code>的信息的。只需要定义好相应形式的<code class="docutils literal notranslate"><span class="pre">dataset</span></code>，传入<code class="docutils literal notranslate"><span class="pre">model.train</span></code>里就可以。具体的可以了解下相应的<a class="reference external" href="https://www.mindspore.cn/doc/programming_guide/zh-CN/r1.2/dataset_loading.html">数据处理接口</a></p>
<br/>
<p><font size=3><strong>Q：模型转移时如何把PyTorch的权重加载到MindSpore中？</strong></font></p>
<p>A：首先输入PyTorch的<code class="docutils literal notranslate"><span class="pre">pth</span></code>文件，以<code class="docutils literal notranslate"><span class="pre">ResNet-18</span></code>为例，MindSpore的网络结构和PyTorch保持一致，转完之后可直接加载进网络，这边参数只用到<code class="docutils literal notranslate"><span class="pre">BN</span></code>和<code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>，若有其他层<code class="docutils literal notranslate"><span class="pre">ms</span></code>和PyTorch名称不一致，需要同样的修改名称。</p>
<br/>
<p><font size=3><strong>Q：模型已经训练好，如何将模型的输出结果保存为文本或者<code class="docutils literal notranslate"><span class="pre">npy</span></code>的格式？</strong></font></p>
<p>A：您好，我们网络的输出为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>，需要使用<code class="docutils literal notranslate"><span class="pre">asnumpy()</span></code>方法将<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>转换为<code class="docutils literal notranslate"><span class="pre">numpy</span></code>，再进行下一步保存。具体可参考：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;output.npy&quot;</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q：使用MindSpore做分割训练，必须将数据转为MindRecords吗？</strong></font></p>
<p>A：<a class="reference external" href="https://github.com/mindspore-ai/mindspore/blob/r1.2/model_zoo/official/cv/deeplabv3/src/data/build_seg_data.py">build_seg_data.py</a>是将数据集生成MindRecord的脚本，可以直接使用/适配下你的数据集。或者如果你想尝试自己实现数据集的读取，可以使用<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>自定义数据集加载。</p>
<p><a class="reference external" href="https://www.mindspore.cn/doc/programming_guide/zh-CN/r1.2/dataset_loading.html#id5">GenratorDataset 示例</a></p>
<p><a class="reference external" href="https://www.mindspore.cn/doc/api_python/zh-CN/r1.2/mindspore/dataset/mindspore.dataset.GeneratorDataset.html#mindspore.dataset.GeneratorDataset">GenratorDataset API说明</a></p>
<br/>
<p><font size=3><strong>Q：MindSpore可以读取TensorFlow的ckpt文件吗？</strong></font></p>
<p>A：MindSpore的<code class="docutils literal notranslate"><span class="pre">ckpt</span></code>和TensorFlow的<code class="docutils literal notranslate"><span class="pre">ckpt</span></code>格式是不通用的，虽然都是使用<code class="docutils literal notranslate"><span class="pre">protobuf</span></code>协议，但是<code class="docutils literal notranslate"><span class="pre">proto</span></code>的定义是不同的。当前MindSpore不支持读取TensorFlow或PyTorch的<code class="docutils literal notranslate"><span class="pre">ckpt</span></code>文件。</p>
<br/>
<p><font size=3><strong>Q：如何不将数据处理为MindRecord格式，直接进行训练呢？</strong></font></p>
<p>A：可以使用自定义的数据加载方式 <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>，具体可以参考<a class="reference external" href="https://www.mindspore.cn/doc/programming_guide/zh-CN/r1.2/dataset_loading.html">数据集加载</a>文档中的自定义数据集加载。</p>
<br/>
<p><font size=3><strong>Q：MindSpore现支持直接读取哪些其他框架的模型和哪些格式呢？比如PyTorch下训练得到的pth模型可以加载到MindSpore框架下使用吗？</strong></font></p>
<p>A： MindSpore采用protbuf存储训练参数，无法直接读取其他框架的模型。对于模型文件本质保存的就是参数和对应的值，可以用其他框架的API将参数读取出来之后，拿到参数的键值对，然后再加载到MindSpore中使用。比如想用其他框架训练好的ckpt文件，可以先把参数读取出来，再调用MindSpore的<code class="docutils literal notranslate"><span class="pre">save_checkpoint</span></code>接口，就可以保存成MindSpore可以读取的ckpt文件格式了。</p>
<br/>
<p><font size=3><strong>Q：用MindSpore训练出的模型如何在Ascend 310上使用？可以转换成适用于HiLens Kit用的吗？</strong></font></p>
<p>A：Ascend 310需要运行专用的OM模型,先使用MindSpore导出ONNX或AIR模型，再转化为Ascend 310支持的OM模型。具体可参考<a class="reference external" href="https://www.mindspore.cn/tutorial/inference/zh-CN/r1.2/multi_platform_inference_ascend_310.html">多平台推理</a>。可以，HiLens Kit是以Ascend 310为推理核心，所以前后两个问题本质上是一样的，需要转换为OM模型.</p>
<br/>
<p><font size=3><strong>Q：MindSpore如何进行参数（如dropout值）修改？</strong></font></p>
<p>A：在构造网络的时候可以通过 <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">self.training:</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">dropput(x)</span></code>，验证的时候，执行前设置<code class="docutils literal notranslate"><span class="pre">network.set_train(mode_false)</span></code>，就可以不适用dropout，训练时设置为True就可以使用dropout。</p>
<br/>
<p><font size=3><strong>Q：从哪里可以查看MindSpore训练及推理的样例代码或者教程？</strong></font></p>
<p>A：可以访问<a class="reference external" href="https://www.mindspore.cn/tutorial/training/zh-CN/r1.2/index.html">MindSpore官网教程训练</a>和<a class="reference external" href="https://www.mindspore.cn/tutorial/inference/zh-CN/r1.2/index.html">MindSpore官网教程推理</a>。</p>
<br/>
<p><font size=3><strong>Q：MindSpore支持哪些模型的训练？</strong></font></p>
<p>A：MindSpore针对典型场景均有模型训练支持，支持情况详见<a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.2/RELEASE.md#">Release note</a>。</p>
<br/>
<p><font size=3><strong>Q：MindSpore有哪些现成的推荐类或生成类网络或模型可用？</strong></font></p>
<p>A：目前正在开发Wide &amp; Deep、DeepFM、NCF等推荐类模型，NLP领域已经支持Bert_NEZHA，正在开发MASS等模型，用户可根据场景需要改造为生成类网络，可以关注<a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.2/model_zoo">MindSpore Model Zoo</a>。</p>
<br/>
<p><font size=3><strong>Q：MindSpore模型训练代码能有多简单？</strong></font></p>
<p>A：除去网络定义，MindSpore提供了Model类的接口，大多数场景只需几行代码就可完成模型训练。</p>
<br/>
<p><font size=3><strong>Q：如何使用MindSpore拟合<span class="math notranslate nohighlight">\(f(x)=a \times sin(x)+b\)</span>这类函数？</strong></font></p>
<p>A：以下拟合案例是基于MindSpore线性拟合官方案例改编而成。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># The fitting function is：f(x)=2*sin(x)+3.</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dataset</span> <span class="k">as</span> <span class="n">ds</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">Normal</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">Model</span><span class="p">,</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">LossMonitor</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>

 <span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">3.0</span><span class="p">):</span>
    <span class="c1"># f(x)=w * sin(x) + b</span>
    <span class="c1"># f(x)=2 * sin(x) +3</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">noise</span>
        <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">num_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">repeat_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">get_data</span><span class="p">(</span><span class="n">num_data</span><span class="p">)),</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">,</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repeat_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_data</span>

<span class="k">class</span> <span class="nc">LinearNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">),</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">num_data</span> <span class="o">=</span> <span class="mi">1600</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">repeat_size</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.005</span>
    <span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>

    <span class="n">net</span> <span class="o">=</span> <span class="n">LinearNet</span><span class="p">()</span>
    <span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>

    <span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">num_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">repeat_size</span><span class="o">=</span><span class="n">repeat_size</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">LossMonitor</span><span class="p">(),</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q：如何使用MindSpore拟合<span class="math notranslate nohighlight">\(f(x)=ax^2+bx+c\)</span>这类的二次函数？</strong></font></p>
<p>A：以下代码引用自MindSpore的官方教程的<a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.2/tutorials/tutorial_code/linear_regression.py">代码仓</a></p>
<p>在以下几处修改即可很好的拟合<span class="math notranslate nohighlight">\(f(x)=ax^2+bx+c\)</span>：</p>
<ol class="arabic simple">
<li><p>数据集生成。</p></li>
<li><p>拟合网络。</p></li>
<li><p>优化器。</p></li>
</ol>
<p>修改的详细信息如下，附带解释。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Since the selected optimizer does not support CPU, so the training computing platform is changed to GPU, which requires readers to install the corresponding GPU version of MindSpore.</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;GPU&quot;</span><span class="p">)</span>

<span class="c1"># Assuming that the function to be fitted this time is f(x)=2x^2+3x+4, the data generation function is modified as follows：</span>
<span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">3.0</span> <span class="p">,</span><span class="n">c</span> <span class="o">=</span> <span class="mi">4</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># The y value is generated by the fitting target function ax^2+bx+c.</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="n">a</span> <span class="o">+</span> <span class="n">x</span> <span class="o">*</span> <span class="n">b</span> <span class="o">+</span> <span class="n">c</span> <span class="o">+</span> <span class="n">noise</span>
        <span class="c1"># When a*x^2+b*x+c is fitted, a and b are weight parameters and c is offset parameter bias. The training data corresponding to the two weights are x^2 and x respectively, so the data set generation mode  is changed as follows:</span>
        <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">num_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">repeat_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">get_data</span><span class="p">(</span><span class="n">num_data</span><span class="p">)),</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">,</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repeat_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_data</span>

<span class="k">class</span> <span class="nc">LinearNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Because the full join function inputs two training parameters, the input value is changed to 2, the first Nomral(0.02) will automatically assign random weights to the input two parameters, and the second Normal is the random bias.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">),</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">num_data</span> <span class="o">=</span> <span class="mi">1600</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">repeat_size</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.005</span>
    <span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>

    <span class="n">net</span> <span class="o">=</span> <span class="n">LinearNet</span><span class="p">()</span>
    <span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="c1"># RMSProp optimalizer with better effect is selected for quadratic function fitting, Currently, Ascend and GPU computing platforms are supported.</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RMSProp</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>

    <span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">num_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">repeat_size</span><span class="o">=</span><span class="n">repeat_size</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">LossMonitor</span><span class="p">(),</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q：在使用ckpt或导出模型的过程中，报Protobuf内存限制错误，如何处理？</strong></font></p>
<p>A：当单条Protobuf数据过大时，因为Protobuf自身对数据流大小的限制，会报出内存限制的错误。这时可通过设置环境变量<code class="docutils literal notranslate"><span class="pre">PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python</span></code>解除限制。</p>
<p><font size=3><strong>Q: 训练nlp类网络，当使用第三方组件gensim时，可能会报错：ValueError，如何解决？</strong></font></p>
<p>A：以下为报错信息：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt;<span class="w"> </span>import<span class="w"> </span>gensim
Traceback<span class="w"> </span><span class="o">(</span>most<span class="w"> </span>recent<span class="w"> </span>call<span class="w"> </span>last<span class="o">)</span>:
<span class="w">  </span>File<span class="w"> </span><span class="s2">&quot;&lt;stdin&gt;&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>&lt;module&gt;
<span class="w">  </span>File<span class="w"> </span><span class="s2">&quot;/home/miniconda3/envs/ci39_cj/lib/python3.9/site-packages/gensim/__init__.py&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">11</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>&lt;module&gt;
<span class="w">    </span>from<span class="w"> </span>gensim<span class="w"> </span>import<span class="w"> </span>parsing,<span class="w"> </span>corpora,<span class="w"> </span>matutils,<span class="w"> </span>interfaces,<span class="w"> </span>models,<span class="w"> </span>similarities,<span class="w"> </span>utils<span class="w">  </span><span class="c1"># noqa:F401</span>
<span class="w">  </span>File<span class="w"> </span><span class="s2">&quot;/home/miniconda3/envs/ci39_cj/lib/python3.9/site-packages/gensim/corpora/__init__.py&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">6</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>&lt;module&gt;
<span class="w">    </span>from<span class="w"> </span>.indexedcorpus<span class="w"> </span>import<span class="w"> </span>IndexedCorpus<span class="w">  </span><span class="c1"># noqa:F401 must appear before the other classes</span>
<span class="w">  </span>File<span class="w"> </span><span class="s2">&quot;/home/miniconda3/envs/ci39_cj/lib/python3.9/site-packages/gensim/corpora/indexedcorpus.py&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">14</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>&lt;module&gt;
<span class="w">    </span>from<span class="w"> </span>gensim<span class="w"> </span>import<span class="w"> </span>interfaces,<span class="w"> </span>utils
<span class="w">  </span>File<span class="w"> </span><span class="s2">&quot;/home/miniconda3/envs/ci39_cj/lib/python3.9/site-packages/gensim/interfaces.py&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">19</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>&lt;module&gt;
<span class="w">    </span>from<span class="w"> </span>gensim<span class="w"> </span>import<span class="w"> </span>utils,<span class="w"> </span>matutils
<span class="w">  </span>File<span class="w"> </span><span class="s2">&quot;/home/miniconda3/envs/ci39_cj/lib/python3.9/site-packages/gensim/matutils.py&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">1024</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>&lt;module&gt;
<span class="w">    </span>from<span class="w"> </span>gensim._matutils<span class="w"> </span>import<span class="w"> </span>logsumexp,<span class="w"> </span>mean_absolute_difference,<span class="w"> </span>dirichlet_expectation
<span class="w">  </span>File<span class="w"> </span><span class="s2">&quot;gensim/_matutils.pyx&quot;</span>,<span class="w"> </span>line<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="k">in</span><span class="w"> </span>init<span class="w"> </span>gensim._matutils
ValueError:<span class="w"> </span>numpy.ndarray<span class="w"> </span>size<span class="w"> </span>changed,<span class="w"> </span>may<span class="w"> </span>indicate<span class="w"> </span>binary<span class="w"> </span>incompatibility.<span class="w"> </span>Expected<span class="w"> </span><span class="m">88</span><span class="w"> </span>from<span class="w"> </span>C<span class="w"> </span>header,<span class="w"> </span>got<span class="w"> </span><span class="m">80</span><span class="w"> </span>from<span class="w"> </span>PyObject
</pre></div>
</div>
<p>报错原因请参考<a class="reference external" href="https://github.com/RaRe-Technologies/gensim/issues/3095">gensim</a>官网，或者<a class="reference external" href="https://github.com/numpy/numpy/issues/18709">numpy</a>官网:</p>
<p>解决方案：
方法一：重新安装numpy及gensim, 执行命令：<code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">uninstall</span> <span class="pre">gensim</span> <span class="pre">numpy</span> <span class="pre">-y</span> <span class="pre">&amp;&amp;</span> <span class="pre">pip</span> <span class="pre">install</span> <span class="pre">numpy</span> <span class="pre">gensim</span></code> ；
方法二：如果还是有问题，请删除wheel安装包的缓存文件，然后执行方法一（wheel安装包缓存目录为：<code class="docutils literal notranslate"><span class="pre">~/.cache/pip/wheels</span></code>）。</p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="supported_operators.html" class="btn btn-neutral float-left" title="算子支持类" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="platform_and_system.html" class="btn btn-neutral float-right" title="平台系统类" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>