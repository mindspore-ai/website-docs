

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>MindSpore Distributed Operator List &mdash; MindSpore r1.1 documentation</title>
  

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="MindSpore Lite Operator List" href="operator_list_lite.html" />
    <link rel="prev" title="MindSpore Implicit Type Conversion Operator List" href="operator_list_implicit.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/overall.html">Overall Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindspore.html">MindSpore Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindinsight.html">MindInsight Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindarmour.html">MindArmour Design</a></li>
</ul>
<p class="caption"><span class="caption-text">Specification Note</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="network_list.html">Network List</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="operator_list.html">Operator List</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="operator_list_ms.html">MindSpore Operator List</a></li>
<li class="toctree-l2"><a class="reference internal" href="operator_list_implicit.html">MindSpore Implicit Type Conversion Operator List</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">MindSpore Distributed Operator List</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#distributed-operator">Distributed Operator</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="operator_list_lite.html">MindSpore Lite Operator List</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="syntax_list.html">Syntax Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_lite.html">Model List (Lite)</a></li>
<li class="toctree-l1"><a class="reference internal" href="env_var_list.html">Environment Variables List</a></li>
</ul>
<p class="caption"><span class="caption-text">Others</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="roadmap.html">RoadMap</a></li>
<li class="toctree-l1"><a class="reference internal" href="help_seeking_path.html">Seeking Help and Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="community.html">Participating in MindSpore Community</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="operator_list.html">Operator List</a> &raquo;</li>
        
      <li>MindSpore Distributed Operator List</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/operator_list_parallel.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="mindspore-distributed-operator-list">
<h1>MindSpore Distributed Operator List<a class="headerlink" href="#mindspore-distributed-operator-list" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Development</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<!-- TOC --><ul class="simple">
<li><p><a class="reference external" href="#mindspore-distributed-operator-list">MindSpore Distributed Operator List</a></p>
<ul>
<li><p><a class="reference external" href="#distributed-operator">Distributed Operator</a></p></li>
</ul>
</li>
</ul>
<!-- /TOC --><p><a href="https://gitee.com/mindspore/docs/blob/r1.1/docs/note/source_en/operator_list_parallel.md" target="_blank"><img src="./_static/logo_source.png"></a></p>
<div class="section" id="distributed-operator">
<h2>Distributed Operator<a class="headerlink" href="#distributed-operator" title="Permalink to this headline">¶</a></h2>
<table border="1" class="docutils">
<thead>
<tr>
<th align="left">op name</th>
<th align="left">constraints</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Abs.html">mindspore.ops.Abs</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.ACos.html">mindspore.ops.ACos</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Acosh.html">mindspore.ops.Acosh</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Add.html">mindspore.ops.Add</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.ApproximateEqual.html">mindspore.ops.ApproximateEqual</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.ArgMaxWithValue.html">mindspore.ops.ArgMaxWithValue</a></td>
<td align="left">When the input_x is splited on the axis dimension, the distributed result may be inconsistent with that on the single machine.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.ArgMinWithValue.html">mindspore.ops.ArgMinWithValue</a></td>
<td align="left">When the input_x is splited on the axis dimension, the distributed result may be inconsistent with that on the single machine.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Asin.html">mindspore.ops.Asin</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Asinh.html">mindspore.ops.Asinh</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Assign.html">mindspore.ops.Assign</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.AssignAdd.html">mindspore.ops.AssignAdd</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.AssignSub.html">mindspore.ops.AssignSub</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Atan.html">mindspore.ops.Atan</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Atan2.html">mindspore.ops.Atan2</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Atanh.html">mindspore.ops.Atanh</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.BatchMatMul.html">mindspore.ops.BatchMatMul</a></td>
<td align="left"><code>transpore_a=True</code> is not supported.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.BesselI0e.html">mindspore.ops.BesselI0e</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.BesselI1e.html">mindspore.ops.BesselI1e</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.BiasAdd.html">mindspore.ops.BiasAdd</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.BroadcastTo.html">mindspore.ops.BroadcastTo</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Cast.html">mindspore.ops.Cast</a></td>
<td align="left">The shard strategy is ignored in the Auto Parallel and Semi Auto Parallel mode.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Ceil.html">mindspore.ops.Ceil</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Concat.html">mindspore.ops.Concat</a></td>
<td align="left">The input_x can't be split into the dimension of axis, otherwise it's inconsistent with the single machine in the mathematical logic.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Cos.html">mindspore.ops.Cos</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Cosh.html">mindspore.ops.Cosh</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Div.html">mindspore.ops.Div</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.DivNoNan.html">mindspore.ops.DivNoNan</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.DropoutDoMask.html">mindspore.ops.DropoutDoMask</a></td>
<td align="left">Need to be used in conjunction with <code>DropoutGenMask</code>，configuring shard strategy is not supported.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.DropoutGenMask.html">mindspore.ops.DropoutGenMask</a></td>
<td align="left">Need to be used in conjunction with <code>DropoutDoMask</code>.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Elu.html">mindspore.ops.Elu</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.EmbeddingLookup.html">mindspore.ops.EmbeddingLookup</a></td>
<td align="left">The same as GatherV2.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Equal.html">mindspore.ops.Equal</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Erf.html">mindspore.ops.Erf</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Erfc.html">mindspore.ops.Erfc</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Exp.html">mindspore.ops.Exp</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.ExpandDims.html">mindspore.ops.ExpandDims</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Expm1.html">mindspore.ops.Expm1</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Floor.html">mindspore.ops.Floor</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.FloorDiv.html">mindspore.ops.FloorDiv</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.FloorMod.html">mindspore.ops.FloorMod</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.GatherV2.html">mindspore.ops.GatherV2</a></td>
<td align="left">Only support 1-dim and 2-dim parameters and the last dimension of the input_params should be 32-byte aligned; Scalar input_indices is not supported; Repeated calculation is not supported when the parameters are split in the dimension of the axis; Split input_indices and input_params at the same time is not supported.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Gather.html">mindspore.ops.Gather</a></td>
<td align="left">Only support 1-dim and 2-dim parameters and the last dimension of the input_params should be 32-byte aligned; Scalar input_indices is not supported; Repeated calculation is not supported when the parameters are split in the dimension of the axis; Split input_indices and input_params at the same time is not supported.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Gelu.html">mindspore.ops.Gelu</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.GeLU.html">mindspore.ops.GeLU</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Greater.html">mindspore.ops.Greater</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.GreaterEqual.html">mindspore.ops.GreaterEqual</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Inv.html">mindspore.ops.Inv</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.L2Normalize.html">mindspore.ops.L2Normalize</a></td>
<td align="left">The input_x can't be split into the dimension of axis, otherwise it's inconsistent with the single machine in the mathematical logic.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Less.html">mindspore.ops.Less</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.LessEqual.html">mindspore.ops.LessEqual</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.LogicalAnd.html">mindspore.ops.LogicalAnd</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.LogicalNot.html">mindspore.ops.LogicalNot</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.LogicalOr.html">mindspore.ops.LogicalOr</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Log.html">mindspore.ops.Log</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Log1p.html">mindspore.ops.Log1p</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.LogSoftmax.html">mindspore.ops.LogSoftmax</a></td>
<td align="left">The logits can't be split into the dimension of axis, otherwise it's inconsistent with the single machine in the mathematical logic.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.MatMul.html">mindspore.ops.MatMul</a></td>
<td align="left"><code>transpose_a=True</code> is not supported.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Maximum.html">mindspore.ops.Maximum</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Minimum.html">mindspore.ops.Minimum</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Mod.html">mindspore.ops.Mod</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Mul.html">mindspore.ops.Mul</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Neg.html">mindspore.ops.Neg</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.NotEqual.html">mindspore.ops.NotEqual</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.OneHot.html">mindspore.ops.OneHot</a></td>
<td align="left">Only support 1-dim indices. Must configure strategy for the output and the first and second inputs.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.OnesLike.html">mindspore.ops.OnesLike</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Pack.html">mindspore.ops.Pack</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Pow.html">mindspore.ops.Pow</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.PReLU.html">mindspore.ops.PReLU</a></td>
<td align="left">When the shape of weight is not [1], the shard strategy in channel dimension of input_x should be consistent with weight.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.RealDiv.html">mindspore.ops.RealDiv</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Reciprocal.html">mindspore.ops.Reciprocal</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.ReduceMax.html">mindspore.ops.ReduceMax</a></td>
<td align="left">When the input_x is splited on the axis dimension, the distributed result may be inconsistent with that on the single machine.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.ReduceMin.html">mindspore.ops.ReduceMin</a></td>
<td align="left">When the input_x is splited on the axis dimension, the distributed result may be inconsistent with that on the single machine.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.ReduceSum.html">mindspore.ops.ReduceSum</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.ReduceMean.html">mindspore.ops.ReduceMean</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.ReLU.html">mindspore.ops.ReLU</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.ReLU6.html">mindspore.ops.ReLU6</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.ReLUV2.html">mindspore.ops.ReLUV2</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Reshape.html">mindspore.ops.Reshape</a></td>
<td align="left">Configuring shard strategy is not supported. In auto parallel mode, if multiple operators are followed by the reshape operator, different shard strategys are not allowed to be configured for these operators.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Round.html">mindspore.ops.Round</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Rsqrt.html">mindspore.ops.Rsqrt</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Sigmoid.html">mindspore.ops.Sigmoid</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.SigmoidCrossEntropyWithLogits.html">mindspore.ops.SigmoidCrossEntropyWithLogits</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Sign.html">mindspore.ops.Sign</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Sin.html">mindspore.ops.Sin</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Sinh.html">mindspore.ops.Sinh</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Softmax.html">mindspore.ops.Softmax</a></td>
<td align="left">The logits can't be split into the dimension of axis, otherwise it's inconsistent with the single machine in the mathematical logic.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.SoftmaxCrossEntropyWithLogits.html">mindspore.ops.SoftmaxCrossEntropyWithLogits</a></td>
<td align="left">The last dimension of logits and labels can't be splited; Only supports using output[0].</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Softplus.html">mindspore.ops.Softplus</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Softsign.html">mindspore.ops.Softsign</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.SparseGatherV2.html">mindspore.ops.SparseGatherV2</a></td>
<td align="left">The same as GatherV2.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Split.html">mindspore.ops.Split</a></td>
<td align="left">The input_x can't be split into the dimension of axis, otherwise it's inconsistent with the single machine in the mathematical logic.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Sqrt.html">mindspore.ops.Sqrt</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Square.html">mindspore.ops.Square</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Squeeze.html">mindspore.ops.Squeeze</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.StridedSlice.html">mindspore.ops.StridedSlice</a></td>
<td align="left">Only support mask with all 0 values; The dimension needs to be split should be all extracted; Split is supported when the strides of dimension is 1.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Slice.html">mindspore.ops.Slice</a></td>
<td align="left">The dimension needs to be split should be all extracted.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Sub.html">mindspore.ops.Sub</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Tan.html">mindspore.ops.Tan</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Tanh.html">mindspore.ops.Tanh</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.TensorAdd.html">mindspore.ops.TensorAdd</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Tile.html">mindspore.ops.Tile</a></td>
<td align="left">Only support configuring shard strategy for multiples.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.TopK.html">mindspore.ops.TopK</a></td>
<td align="left">The input_x can't be split into the last dimension, otherwise it's inconsistent with the single machine in the mathematical logic.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Transpose.html">mindspore.ops.Transpose</a></td>
<td align="left">None</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.Unique.html">mindspore.ops.Unique</a></td>
<td align="left">Only support the repeat calculate shard strategy (1,).</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.UnsortedSegmentSum.html">mindspore.ops.UnsortedSegmentSum</a></td>
<td align="left">The shard of input_x and segment_ids must be the same as the dimension of segment_ids.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.UnsortedSegmentMin.html">mindspore.ops.UnsortedSegmentMin</a></td>
<td align="left">The shard of input_x and segment_ids must be the same as the dimension of segment_ids. Note that if the segment id i is missing, then the output[i] will be filled with the maximum of the input type. The user needs to mask the maximum value to avoid value overflow. The communication operation such as AllReudce will raise an Run Task Error due to overflow.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.UnsortedSegmentMax.html">mindspore.ops.UnsortedSegmentMax</a></td>
<td align="left">The shard of input_x and segment_ids must be the same as the dimension of segment_ids. Note that if the segment id i is missing, then the output[i] will be filled with the minimum of the input type. The user needs to mask the minimum value to avoid value overflow. The communication operation such as AllReudce will raise an Run Task Error due to overflow.</td>
</tr>
<tr>
<td align="left"><a href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.ZerosLike.html">mindspore.ops.ZerosLike</a></td>
<td align="left">None</td>
</tr>
</tbody>
</table><blockquote>
<div><p>Repeated calculation means that the device is not fully used. For example, the cluster has 8 devices to run distributed training, the splitting strategy only cuts the input into 4 copies. In this case, double counting will occur.</p>
</div></blockquote>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="operator_list_lite.html" class="btn btn-neutral float-right" title="MindSpore Lite Operator List" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="operator_list_implicit.html" class="btn btn-neutral float-left" title="MindSpore Implicit Type Conversion Operator List" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, MindSpore

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>