

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Operators &mdash; MindSpore r1.1 documentation</title>
  

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Parameter" href="parameter.html" />
    <link rel="prev" title="Compute Component" href="compute_component.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_type.html">Data Type</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="compute_component.html">Compute Component</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Operators</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#operator-usage">Operator Usage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#mindspore-ops-operations">mindspore.ops.operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mindspore-ops-functional">mindspore.ops.functional</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mindspore-ops-composite">mindspore.ops.composite</a></li>
<li class="toctree-l4"><a class="reference internal" href="#combination-usage-of-operations-functional-composite-three-types-of-operators">Combination usage of operations/functional/composite three types of operators</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#operator-functions">Operator Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tensor-operations">Tensor Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#scalar-operations">Scalar Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vector-operations">Vector Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#matrix-operations">Matrix Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#network-operations">Network Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#array-operations">Array Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#image-operations">Image Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#encoding-operations">Encoding Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#debugging-operations">Debugging Operations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="parameter.html">Parameter</a></li>
<li class="toctree-l2"><a class="reference internal" href="cell.html">Cell Building and Its Subclasses</a></li>
<li class="toctree-l2"><a class="reference internal" href="network_component.html">Common Network Components</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="data_pipeline.html">Data Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="execution_management.html">Execution Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_parallel.html">Parallel Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_usage.html">Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="network_list.html">Network List</a></li>
<li class="toctree-l1"><a class="reference internal" href="operator_list.html">Operator List</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="compute_component.html">Compute Component</a> &raquo;</li>
        
      <li>Operators</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/operators.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="operators">
<h1>Operators<a class="headerlink" href="#operators" title="Permalink to this headline">Â¶</a></h1>
<!-- TOC --><ul class="simple">
<li><p><a class="reference external" href="#operators">Operators</a></p>
<ul>
<li><p><a class="reference external" href="#overview">Overview</a></p></li>
<li><p><a class="reference external" href="#operator-usage">Operator Usage</a></p>
<ul>
<li><p><a class="reference external" href="#mindsporeopsoperations">mindspore.ops.operations</a></p></li>
<li><p><a class="reference external" href="#mindsporeopsfunctional">mindspore.ops.functional</a></p></li>
<li><p><a class="reference external" href="#mindsporeopscomposite">mindspore.ops.composite</a></p></li>
<li><p><a class="reference external" href="#combination-usage-of-operationsfunctionalcomposite-three-types-of-operators">Combination usage of operations/functional/composite three types of operators</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#operator-functions">Operator Functions</a></p>
<ul>
<li><p><a class="reference external" href="#tensor-operations">Tensor Operations</a></p></li>
<li><p><a class="reference external" href="#scalar-operations">Scalar Operations</a></p>
<ul>
<li><p><a class="reference external" href="#addition">Addition</a></p></li>
<li><p><a class="reference external" href="#element-wise-multiplication">Element-wise Multiplication</a></p></li>
<li><p><a class="reference external" href="#trigonometric-function">Trigonometric Function</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#vector-operations">Vector Operations</a></p>
<ul>
<li><p><a class="reference external" href="#squeeze">Squeeze</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#matrix-operations">Matrix Operations</a></p>
<ul>
<li><p><a class="reference external" href="#matrix-multiplication">Matrix Multiplication</a></p></li>
<li><p><a class="reference external" href="#broadcast-mechanism">Broadcast Mechanism</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#network-operations">Network Operations</a></p>
<ul>
<li><p><a class="reference external" href="#feature-extraction">Feature Extraction</a></p></li>
<li><p><a class="reference external" href="#activation-function">Activation Function</a></p></li>
<li><p><a class="reference external" href="#loss-function">Loss Function</a></p></li>
<li><p><a class="reference external" href="#optimization-algorithm">Optimization Algorithm</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#array-operations">Array Operations</a></p>
<ul>
<li><p><a class="reference external" href="#dtype">DType</a></p></li>
<li><p><a class="reference external" href="#cast">Cast</a></p></li>
<li><p><a class="reference external" href="#shape">Shape</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#image-operations">Image Operations</a></p></li>
<li><p><a class="reference external" href="#encoding-operations">Encoding Operations</a></p>
<ul>
<li><p><a class="reference external" href="#boundingboxencode">BoundingBoxEncode</a></p></li>
<li><p><a class="reference external" href="#boundingboxdecode">BoundingBoxDecode</a></p></li>
<li><p><a class="reference external" href="#iou-computing">IOU Computing</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#debugging-operations">Debugging Operations</a></p>
<ul>
<li><p><a class="reference external" href="#debug">Debug</a></p></li>
<li><p><a class="reference external" href="#hookbackward">HookBackward</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- /TOC --><p><a href="https://gitee.com/mindspore/docs/blob/r1.1/docs/programming_guide/source_en/operators.md" target="_blank"><img src="./_static/logo_source.png"></a></p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">Â¶</a></h2>
<p>Operators of MindSpore can be classified based on the operator usage and operator functions. The following example code runs in PyNative mode.</p>
</div>
<div class="section" id="operator-usage">
<h2>Operator Usage<a class="headerlink" href="#operator-usage" title="Permalink to this headline">Â¶</a></h2>
<p>APIs related to operators include operations, functional, and composite. Operators related to these three APIs can be directly obtained using ops.</p>
<ul class="simple">
<li><p>The operations API provides a single primitive operator. An operator corresponds to a primitive and is the smallest execution object. An operator can be used only after being instantiated.</p></li>
<li><p>The composite API provides some predefined composite operators and complex operators involving graph transformation, such as <code class="docutils literal notranslate"><span class="pre">GradOperation</span></code>.</p></li>
<li><p>The functional API provides objects instantiated by the operations and composite to simplify the operator calling process.</p></li>
</ul>
<div class="section" id="mindspore-ops-operations">
<h3>mindspore.ops.operations<a class="headerlink" href="#mindspore-ops-operations" title="Permalink to this headline">Â¶</a></h3>
<p>The operations API provides all primitive operator APIs, which are the lowest-order operator APIs open to users. For details about the supported operators, see <a class="reference external" href="https://www.mindspore.cn/doc/note/en/r1.1/operator_list.html">Operator List</a>.</p>
<p>Primitive operators directly encapsulate the implementation of operators at bottom layers such as Ascend, GPU, AICPU, and CPU, providing basic operator capabilities for users.</p>
<p>Primitive operator APIs are the basis for building high-order APIs, automatic differentiation, and network models.</p>
<p>A code example is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">input_y</span> <span class="o">=</span> <span class="mf">3.0</span>
<span class="nb">pow</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Pow</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="nb">pow</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output =&quot;</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>output = [ 1.  8. 64.]
</pre></div>
</div>
</div>
<div class="section" id="mindspore-ops-functional">
<h3>mindspore.ops.functional<a class="headerlink" href="#mindspore-ops-functional" title="Permalink to this headline">Â¶</a></h3>
<p>To simplify the calling process of operators without attributes, MindSpore provides the functional version of some operators. For details about the input parameter requirements, see the input and output requirements of the original operator. For details about the supported operators, see <a class="reference external" href="https://www.mindspore.cn/doc/note/en/r1.1/operator_list_ms.html#mindspore-ops-functional">Operator List</a>.</p>
<p>For example, the functional version of the <code class="docutils literal notranslate"><span class="pre">P.Pow</span></code> operator is <code class="docutils literal notranslate"><span class="pre">F.tensor_pow</span></code>.</p>
<p>A code example is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">input_y</span> <span class="o">=</span> <span class="mf">3.0</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_pow</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output =&quot;</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>output = [ 1.  8. 64.]
</pre></div>
</div>
</div>
<div class="section" id="mindspore-ops-composite">
<h3>mindspore.ops.composite<a class="headerlink" href="#mindspore-ops-composite" title="Permalink to this headline">Â¶</a></h3>
<p>The composite API provides some operator combinations, including some operators related to clip_by_value and random, and functions (such as <code class="docutils literal notranslate"><span class="pre">GradOperation</span></code>, <code class="docutils literal notranslate"><span class="pre">HyperMap</span></code>, and <code class="docutils literal notranslate"><span class="pre">Map</span></code>) related to graph transformation.</p>
<p>The operator combination can be directly used as a common function. For example, use <code class="docutils literal notranslate"><span class="pre">normal</span></code> to generate a random distribution:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">composite</span> <span class="k">as</span> <span class="n">C</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>

<span class="n">mean</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">stddev</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">normal</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">mean</span><span class="p">,</span> <span class="n">stddev</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output =&quot;</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>output = [[2.4911082  0.7941146  1.3117087]
 [0.30582333  1.772938  1.525996]]
</pre></div>
</div>
<blockquote>
<div><p>The preceding code runs on the GPU version of MindSpore.</p>
</div></blockquote>
<p>For functions involving graph transformation, users can use <code class="docutils literal notranslate"><span class="pre">MultitypeFuncGraph</span></code> to define a group of overloaded functions. The implementation varies according to the function type.</p>
<p>A code example is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore.ops.composite</span> <span class="kn">import</span> <span class="n">MultitypeFuncGraph</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">add</span> <span class="o">=</span> <span class="n">MultitypeFuncGraph</span><span class="p">(</span><span class="s1">&#39;add&#39;</span><span class="p">)</span>
<span class="nd">@add</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;Number&quot;</span><span class="p">,</span> <span class="s2">&quot;Number&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">add_scalar</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">scalar_add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="nd">@add</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;Tensor&quot;</span><span class="p">,</span> <span class="s2">&quot;Tensor&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">add_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">tensor_add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">tensor1</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.2</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="n">tensor2</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.2</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;tensor&#39;</span><span class="p">,</span> <span class="n">add</span><span class="p">(</span><span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;scalar&#39;</span><span class="p">,</span> <span class="n">add</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>tensor [[2.4, 4.2]
 [4.4, 6.4]]
scalar 3
</pre></div>
</div>
<p>In addition, the high-order function <code class="docutils literal notranslate"><span class="pre">GradOperation</span></code> provides the method of computing the gradient function corresponding to the input function. For details, see <a class="reference external" href="https://www.mindspore.cn/doc/api_python/en/r1.1/mindspore/ops/mindspore.ops.GradOperation.html">mindspore.ops</a>.</p>
</div>
<div class="section" id="combination-usage-of-operations-functional-composite-three-types-of-operators">
<h3>Combination usage of operations/functional/composite three types of operators<a class="headerlink" href="#combination-usage-of-operations-functional-composite-three-types-of-operators" title="Permalink to this headline">Â¶</a></h3>
<p>In order to make it easier to use, in addition to the several usages introduced above, we have encapsulated the three operators of operations/functional/composite into mindspore.ops. It is recommended to directly call the interface in mindspore.ops.</p>
<p>The code sample is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">P</span>
<span class="nb">pow</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Pow</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="nb">pow</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Pow</span><span class="p">()</span>
</pre></div>
</div>
<blockquote>
<div><p>The above two methods have the same effect.</p>
</div></blockquote>
</div>
</div>
<div class="section" id="operator-functions">
<h2>Operator Functions<a class="headerlink" href="#operator-functions" title="Permalink to this headline">Â¶</a></h2>
<p>Operators can be classified into seven functional modules: tensor operations, network operations, array operations, image operations, encoding operations, debugging operations, and quantization operations. For details about the supported operators on the Ascend AI processors, GPU, and CPU, see <a class="reference external" href="https://www.mindspore.cn/doc/note/en/r1.1/operator_list.html">Operator List</a>.</p>
<div class="section" id="tensor-operations">
<h3>Tensor Operations<a class="headerlink" href="#tensor-operations" title="Permalink to this headline">Â¶</a></h3>
<p>The tensor operations include the tensor structure operation and the tensor mathematical operation.</p>
<p>Tensor structure operations include tensor creation, index sharding, dimension transformation, and integration and splitting.</p>
<p>Tensor mathematical operations include scalar operations, vector operations, and matrix operations.</p>
<p>The following describes how to use the tensor mathematical operation and operation broadcast mechanism.</p>
</div>
<div class="section" id="scalar-operations">
<h3>Scalar Operations<a class="headerlink" href="#scalar-operations" title="Permalink to this headline">Â¶</a></h3>
<p>Tensor mathematical operators can be classified into scalar operator, vector operator, and matrix operator.</p>
<p>Scalar operators include addition, subtraction, multiplication, division, exponentiation, common functions such as trigonometric function, exponential function, and logarithmic function, and logical comparison operators.</p>
<p>Scalar operators are characterized by performing element-by-element operations on tensors.</p>
<p>Some scalar operators overload commonly used mathematical operators. In addition, the broadcast feature similar to NumPy is supported.</p>
<p>The following code implements the exponentiation, where the base is input_x and the exponent is input_y:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">input_y</span> <span class="o">=</span> <span class="mf">3.0</span>
<span class="nb">print</span><span class="p">(</span><span class="n">input_x</span><span class="o">**</span><span class="n">input_y</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[ 1.  8. 64.]
</pre></div>
</div>
<div class="section" id="addition">
<h4>Addition<a class="headerlink" href="#addition" title="Permalink to this headline">Â¶</a></h4>
<p>The following code implements the addition of <code class="docutils literal notranslate"><span class="pre">input_x</span></code> and <code class="docutils literal notranslate"><span class="pre">input_y</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">input_x</span> <span class="o">+</span> <span class="n">input_y</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[4.0 5.0 7.0]
</pre></div>
</div>
</div>
<div class="section" id="element-wise-multiplication">
<h4>Element-wise Multiplication<a class="headerlink" href="#element-wise-multiplication" title="Permalink to this headline">Â¶</a></h4>
<p>The following code implements the element-wise multiplication:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">mul</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Mul</span><span class="p">()</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">mul</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[4. 10. 18]
</pre></div>
</div>
</div>
<div class="section" id="trigonometric-function">
<h4>Trigonometric Function<a class="headerlink" href="#trigonometric-function" title="Permalink to this headline">Â¶</a></h4>
<p>The following code implements Acos:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">acos</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ACos</span><span class="p">()</span>
<span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.74</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.30</span><span class="p">,</span> <span class="mf">0.56</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">acos</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[0.7377037, 1.5307858, 1.2661037, 0.97641146]
</pre></div>
</div>
</div>
</div>
<div class="section" id="vector-operations">
<h3>Vector Operations<a class="headerlink" href="#vector-operations" title="Permalink to this headline">Â¶</a></h3>
<p>Vector operators perform operations on only one particular axis, mapping a vector to a scalar or another vector.</p>
<div class="section" id="squeeze">
<h4>Squeeze<a class="headerlink" href="#squeeze" title="Permalink to this headline">Â¶</a></h4>
<p>The following code implements the compression of a channel whose dimension of the third channel is 1:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">squeeze</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[1. 1.]
 [1. 1.]
 [1. 1.]]
</pre></div>
</div>
</div>
</div>
<div class="section" id="matrix-operations">
<h3>Matrix Operations<a class="headerlink" href="#matrix-operations" title="Permalink to this headline">Â¶</a></h3>
<p>Matrix operations include matrix multiplication, matrix norm, matrix determinant, matrix eigenvalue calculation, and matrix decomposition.</p>
<div class="section" id="matrix-multiplication">
<h4>Matrix Multiplication<a class="headerlink" href="#matrix-multiplication" title="Permalink to this headline">Â¶</a></h4>
<p>The following code implements the matrix multiplication of input_x and input_y:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">matmul</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">MatMul</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">matmul</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[3. 3. 3. 3.]]
</pre></div>
</div>
</div>
<div class="section" id="broadcast-mechanism">
<h4>Broadcast Mechanism<a class="headerlink" href="#broadcast-mechanism" title="Permalink to this headline">Â¶</a></h4>
<p>Broadcast indicates that when the number of channels of each input variable is inconsistent, change the number of channels to obtain the result.</p>
<ul class="simple">
<li><p>The following code implements the broadcast mechanism:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">broadcast_to</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">BroadcastTo</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">broadcast_to</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[1. 2. 3.]
 [1. 2. 3.]]
</pre></div>
</div>
</div>
</div>
<div class="section" id="network-operations">
<h3>Network Operations<a class="headerlink" href="#network-operations" title="Permalink to this headline">Â¶</a></h3>
<p>Network operations include feature extraction, activation function, loss function, and optimization algorithm.</p>
<div class="section" id="feature-extraction">
<h4>Feature Extraction<a class="headerlink" href="#feature-extraction" title="Permalink to this headline">Â¶</a></h4>
<p>Feature extraction is a common operation in machine learning. The core of feature extraction is to extract more representative tensors than the original input.</p>
<p>Convolution Operation</p>
<p>The following code implements the 2D convolution operation which is one of the common convolution operations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>

<span class="nb">input</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">conv2d</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">out_channel</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[288. 288. 288. ... 288. 288. 288.]
   [288. 288. 288. ... 288. 288. 288.]
   [288. 288. 288. ... 288. 288. 288.]
   ...
   [288. 288. 288. ... 288. 288. 288.]
   [288. 288. 288. ... 288. 288. 288.]
   [288. 288. 288. ... 288. 288. 288.]]

   ...
   [288. 288. 288. ... 288. 288. 288.]
   [288. 288. 288. ... 288. 288. 288.]
   [288. 288. 288. ... 288. 288. 288.]]]]
</pre></div>
</div>
<p>Convolutional Backward Propagation Operator Operation</p>
<p>The following code implements the propagation operation of backward gradient operators. The outputs are stored in dout and weight:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>

<span class="n">dout</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">30</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]))</span>
<span class="n">conv2d_backprop_input</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Conv2DBackpropInput</span><span class="p">(</span><span class="n">out_channel</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">conv2d_backprop_input</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[ 32. 64. 96. ... 96. 64. 32.]
   [ 64. 128. 192. ... 192. 128. 64.]
   [ 96. 192. 288. ... 288. 192. 96.]
   ...
   [ 96. 192. 288. ... 288. 192. 96.]
   [ 64. 128. 192. ... 192. 128. 64.]
   [ 32. 64. 96. ... 96. 64. 32.]]

  [[ 32. 64. 96. ... 96. 64. 32.]
   [ 64. 128. 192. ... 192. 128. 64.]
   [ 96. 192. 288. ... 288. 192. 96.]
   ...
   [ 96. 192. 288. ... 288. 192. 96.]
   [ 64. 128. 192. ... 192. 128. 64.]
   [ 32. 64. 96. ... 96. 64. 32.]]]]
</pre></div>
</div>
</div>
<div class="section" id="activation-function">
<h4>Activation Function<a class="headerlink" href="#activation-function" title="Permalink to this headline">Â¶</a></h4>
<p>The following code implements the computation of the Softmax activation function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">softmax</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[0.01165623 0.03168492 0.08612854 0.23412167 0.6364086]
</pre></div>
</div>
</div>
<div class="section" id="loss-function">
<h4>Loss Function<a class="headerlink" href="#loss-function" title="Permalink to this headline">Â¶</a></h4>
<p>L1Loss</p>
<p>The following code implements the L1 loss function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">SmoothL1Loss</span><span class="p">()</span>
<span class="n">input_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">target_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">target_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[0.  0.  0.5]
</pre></div>
</div>
</div>
<div class="section" id="optimization-algorithm">
<h4>Optimization Algorithm<a class="headerlink" href="#optimization-algorithm" title="Permalink to this headline">Â¶</a></h4>
<p>SGD</p>
<p>The following code implements the stochastic gradient descent (SGD) algorithm. The output is stored in result.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>

<span class="n">sgd</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">SGD</span><span class="p">()</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.7</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">gradient</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">accum</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">momentum</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">stat</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">sgd</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">gradient</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">accum</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">stat</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>(Tensor(shape=[4], dtype=Float32, value= [ 1.98989999e+00, -4.90300000e-01,  1.69520009e+00,  3.98009992e+00]),)
</pre></div>
</div>
</div>
</div>
<div class="section" id="array-operations">
<h3>Array Operations<a class="headerlink" href="#array-operations" title="Permalink to this headline">Â¶</a></h3>
<p>Array operations refer to operations on arrays.</p>
<div class="section" id="dtype">
<h4>DType<a class="headerlink" href="#dtype" title="Permalink to this headline">Â¶</a></h4>
<p>Returns a Tensor variable that has the same data type as the input and adapts to MindSpore. It is usually used in a MindSpore project.</p>
<p>The following is a code example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>

<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">typea</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">DType</span><span class="p">()(</span><span class="n">input_tensor</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">typea</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Float32
</pre></div>
</div>
</div>
<div class="section" id="cast">
<h4>Cast<a class="headerlink" href="#cast" title="Permalink to this headline">Â¶</a></h4>
<p>Converts the input data type and outputs variables of the same type as the target data type.</p>
<p>The following is a code example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>

<span class="n">input_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">input_np</span><span class="p">)</span>
<span class="n">type_dst</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float16</span>
<span class="n">cast</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Cast</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">type_dst</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Float16
</pre></div>
</div>
</div>
<div class="section" id="shape">
<h4>Shape<a class="headerlink" href="#shape" title="Permalink to this headline">Â¶</a></h4>
<p>Returns the shape of the input data.</p>
<p>The following code implements the operation of returning the input data input_tensor:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>

<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">shape</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Shape</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">shape</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>(3, 2, 1)
</pre></div>
</div>
</div>
</div>
<div class="section" id="image-operations">
<h3>Image Operations<a class="headerlink" href="#image-operations" title="Permalink to this headline">Â¶</a></h3>
<p>The image operations include image preprocessing operations, for example, image cropping (for obtaining a large quantity of training samples) and resizing (for constructing an image pyramid).</p>
<p>The following code implements the cropping and resizing operations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">NUM_BOXES</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">IMAGE_HEIGHT</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">IMAGE_WIDTH</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">CHANNELS</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">IMAGE_HEIGHT</span><span class="p">,</span> <span class="n">IMAGE_WIDTH</span><span class="p">,</span> <span class="n">CHANNELS</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">boxes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">NUM_BOXES</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">box_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">NUM_BOXES</span><span class="p">],</span> <span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">crop_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">24</span><span class="p">)</span>
<span class="n">crop_and_resize</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">CropAndResize</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">crop_and_resize</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">image</span><span class="p">),</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">boxes</span><span class="p">),</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">box_index</span><span class="p">),</span> <span class="n">crop_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[ 6.51672244e-01 -1.85958534e-01 5.19907832e-01]
[ 1.53466597e-01 4.10562098e-01 6.26138210e-01]
[ 6.62892580e-01 3.81776541e-01 4.69261825e-01]
...
[-5.83377600e-01 -3.53377648e-02 -6.01786733e-01]
[ 1.36125124e+00 5.84172308e-02 -6.41442612e-02]
[-9.11651254e-01 -1.19495761e+00 1.96810793e-02]]

[[ 6.06956100e-03 -3.73778701e-01 1.88935513e-03]
[-1.06859171e+00 2.00272346e+00 1.37180305e+00]
[ 1.69524819e-01 2.90421434e-02 -4.12243098e-01]
...

[[-2.04489112e-01 2.36615837e-01 1.33802962e+00]
[ 1.08329034e+00 -9.00492966e-01 -8.21497202e-01]
[ 7.54147097e-02 -3.72897685e-01 -2.91040149e-02]
...
[ 1.12317121e+00 8.98950577e-01 4.22795087e-01]
[ 5.13781667e-01 5.12095273e-01 -3.68211865e-01]
[-7.04941899e-02 -1.09924078e+00 6.89047515e-01]]]]
</pre></div>
</div>
<blockquote>
<div><p>The preceding code runs on MindSpore of the Ascend version.</p>
</div></blockquote>
</div>
<div class="section" id="encoding-operations">
<h3>Encoding Operations<a class="headerlink" href="#encoding-operations" title="Permalink to this headline">Â¶</a></h3>
<p>The encoding operations include BoundingBox Encoding, BoundingBox Decoding, and IOU computing.</p>
<div class="section" id="boundingboxencode">
<h4>BoundingBoxEncode<a class="headerlink" href="#boundingboxencode" title="Permalink to this headline">Â¶</a></h4>
<p>The box of the area where the object is located is encoded to obtain more concise information similar to PCA, facilitating subsequent tasks such as feature extraction, object detection, and image restoration.</p>
<p>The following code implements BoundingBox Encoding for anchor_box and groundtruth_box:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">mindspore</span>

<span class="n">anchor_box</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span><span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">groundtruth_box</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span><span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">boundingbox_encode</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">BoundingBoxEncode</span><span class="p">(</span><span class="n">means</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span> <span class="n">stds</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">boundingbox_encode</span><span class="p">(</span><span class="n">anchor_box</span><span class="p">,</span> <span class="n">groundtruth_box</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[ ï¼1.  0.25  0.  0.40551758]
 [ ï¼1.  0.25  0.  0.40551758]]
</pre></div>
</div>
</div>
<div class="section" id="boundingboxdecode">
<h4>BoundingBoxDecode<a class="headerlink" href="#boundingboxdecode" title="Permalink to this headline">Â¶</a></h4>
<p>After decoding the area location information, the encoder uses this operator to decode the information.</p>
<p>Code implementation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">mindspore</span>

<span class="n">anchor_box</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]],</span><span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">deltas</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">]],</span><span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">boundingbox_decode</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">BoundingBoxDecode</span><span class="p">(</span><span class="n">means</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span> <span class="n">stds</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">max_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">768</span><span class="p">,</span> <span class="mi">1280</span><span class="p">),</span> <span class="n">wh_ratio_clip</span><span class="o">=</span><span class="mf">0.016</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">boundingbox_decode</span><span class="p">(</span><span class="n">anchor_box</span><span class="p">,</span> <span class="n">deltas</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[4.1953125  0.  0.  5.1953125]
 [2.140625  0.  3.859375  60.59375]]
</pre></div>
</div>
</div>
<div class="section" id="iou-computing">
<h4>IOU Computing<a class="headerlink" href="#iou-computing" title="Permalink to this headline">Â¶</a></h4>
<p>Computes the proportion of the intersection area and union area of the box where the predicted object is located and the box where the real object is located. It is often used as a loss function to optimize the model.</p>
<p>The following code implements the IOU computing between anchor_boxes and gt_boxes. The output is stored in out:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span>

<span class="n">iou</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">IOU</span><span class="p">()</span>
<span class="n">anchor_boxes</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="n">gt_boxes</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">iou</span><span class="p">(</span><span class="n">anchor_boxes</span><span class="p">,</span> <span class="n">gt_boxes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[0.  -0.  0.]
 [0.  -0.  0.]
 [0.   0.  0.]]
</pre></div>
</div>
</div>
</div>
<div class="section" id="debugging-operations">
<h3>Debugging Operations<a class="headerlink" href="#debugging-operations" title="Permalink to this headline">Â¶</a></h3>
<p>The debugging operations refer to some common operators and operations used to debug a network, for example, HookBackward. These operations are very convenient and important for entry-level deep learning, greatly improving learning experience.</p>
<div class="section" id="hookbackward">
<h4>HookBackward<a class="headerlink" href="#hookbackward" title="Permalink to this headline">Â¶</a></h4>
<p>Displays the gradient of intermediate variables. It is a common operator. Currently, only the PyNative mode is supported.</p>
<p>The following code implements the function of printing the gradient of the intermediate variable (x,y in this example):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>

<span class="k">def</span> <span class="nf">hook_fn</span><span class="p">(</span><span class="n">grad_out</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">grad_out</span><span class="p">)</span>

<span class="n">grad_all</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">GradOperation</span><span class="p">(</span><span class="n">get_all</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">hook</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">HookBackward</span><span class="p">(</span><span class="n">hook_fn</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">hook_test</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">hook</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">z</span> <span class="o">*</span> <span class="n">y</span>
    <span class="k">return</span> <span class="n">z</span>

<span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">grad_all</span><span class="p">(</span><span class="n">hook_test</span><span class="p">)(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">backward</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>(Tensor(shape=[], dtype=Float32, value=2),)
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="parameter.html" class="btn btn-neutral float-right" title="Parameter" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="compute_component.html" class="btn btn-neutral float-left" title="Compute Component" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, MindSpore

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>