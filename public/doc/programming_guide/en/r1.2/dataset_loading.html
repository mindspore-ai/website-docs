<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Loading Dataset &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Sampler" href="sampler.html" />
    <link rel="prev" title="Data Pipeline" href="data_pipeline.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_type.html">Data Type</a></li>
<li class="toctree-l1"><a class="reference internal" href="compute_component.html">Compute Component</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="data_pipeline.html">Data Pipeline</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Loading Dataset</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#loading-common-dataset">Loading Common Dataset</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#cifar-10-100-dataset">CIFAR-10/100 Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#voc-dataset">VOC Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#coco-dataset">COCO Dataset</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#loading-datasets-in-specific-format">Loading Datasets in Specific Format</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#mindrecord">MindRecord</a></li>
<li class="toctree-l4"><a class="reference internal" href="#manifest">Manifest</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tfrecord">TFRecord</a></li>
<li class="toctree-l4"><a class="reference internal" href="#numpy">NumPy</a></li>
<li class="toctree-l4"><a class="reference internal" href="#csv">CSV</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#loading-user-defined-dataset">Loading User-defined Dataset</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#constructing-dataset-generator-function">Constructing Dataset Generator Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="#constructing-iterable-dataset-class">Constructing Iterable Dataset Class</a></li>
<li class="toctree-l4"><a class="reference internal" href="#constructing-random-accessible-dataset-class">Constructing Random Accessible Dataset Class</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="sampler.html">Sampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="pipeline.html">Processing Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="augmentation.html">Data Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="tokenizer.html">Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="dataset_conversion.html">MindSpore Data Format Conversion</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_augmentation.html">Auto Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="cache.html">Single-Node Tensor Cache</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="execution_management.html">Execution Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_parallel.html">Parallel Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_usage.html">Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="network_list.html">Network List</a></li>
<li class="toctree-l1"><a class="reference internal" href="operator_list.html">Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="syntax_list.html">Syntax list</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="data_pipeline.html">Data Pipeline</a> &raquo;</li>
      <li>Loading Dataset</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/dataset_loading.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="loading-dataset">
<h1>Loading Dataset<a class="headerlink" href="#loading-dataset" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.2/docs/programming_guide/source_en/dataset_loading.md" target="_blank"><img src="./_static/logo_source.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>MindSpore can load common image datasets. You can directly use the classes in <code class="docutils literal notranslate"><span class="pre">mindspore.dataset</span></code> to load datasets. The following table lists the supported common datasets and corresponding classes.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Image Dataset</p></th>
<th class="head"><p>Dataset Class</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>MNIST</p></td>
<td><p>MnistDataset</p></td>
<td><p>MNIST is a large handwritten digital image dataset. It has 60,000 training images and 10,000 test images and is often used to train various image processing systems.</p></td>
</tr>
<tr class="row-odd"><td><p>CIFAR-10</p></td>
<td><p>Cifar10Dataset</p></td>
<td><p>CIFAR-10 is a small image dataset that contains 60,000 32 x 32 color images of 10 categories. On average, each category contains 6,000 images, of which 5,000 images are training images and 1,000 images are test images.</p></td>
</tr>
<tr class="row-even"><td><p>CIFAR-100</p></td>
<td><p>Cifar100Dataset</p></td>
<td><p>CIFAR-100 is similar to CIFAR-10, but it has 100 categories. On average, there are 600 images in each category, among which 500 images are training images and 100 images are test images.</p></td>
</tr>
<tr class="row-odd"><td><p>CelebA</p></td>
<td><p>CelebADataset</p></td>
<td><p>CelebA is a large face image dataset that contains more than 200,000 face images of celebrities. Each image has 40 feature labels.</p></td>
</tr>
<tr class="row-even"><td><p>PASCAL-VOC</p></td>
<td><p>VOCDataset</p></td>
<td><p>PASCAL-VOC is a common image dataset, which is widely used in computer vision fields such as object detection and image segmentation.</p></td>
</tr>
<tr class="row-odd"><td><p>COCO</p></td>
<td><p>CocoDataset</p></td>
<td><p>COCO is a large dataset for object detection, image segmentation, and pose estimation.</p></td>
</tr>
<tr class="row-even"><td><p>CLUE</p></td>
<td><p>CLUEDataset</p></td>
<td><p>CLUE is a large Chinese semantic comprehension dataset.</p></td>
</tr>
</tbody>
</table>
<p>MindSpore can also load datasets in different data storage formats. You can directly use the corresponding classes in <code class="docutils literal notranslate"><span class="pre">mindspore.dataset</span></code> to load data files in the disk. The following table lists the supported data formats and corresponding classes.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Data Format</p></th>
<th class="head"><p>Dataset Class</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>MindRecord</p></td>
<td><p>MindDataset</p></td>
<td><p>MindRecord is a self-developed data format of MindSpore. It features efficient read/write and easy distributed processing.</p></td>
</tr>
<tr class="row-odd"><td><p>Manifest</p></td>
<td><p>ManifestDataset</p></td>
<td><p>Manifest is a data format supported by Huawei ModelArts. It describes the original files and labeling information and can be used for labeling, training, and inference.</p></td>
</tr>
<tr class="row-even"><td><p>TFRecord</p></td>
<td><p>TFRecordDataset</p></td>
<td><p>TFRecord is a binary data file format defined by TensorFlow.</p></td>
</tr>
<tr class="row-odd"><td><p>NumPy</p></td>
<td><p>NumpySlicesDataset</p></td>
<td><p>NumPy data source refers to the NumPy array dataset that has been read into the memory.</p></td>
</tr>
<tr class="row-even"><td><p>Text File</p></td>
<td><p>TextFileDataset</p></td>
<td><p>Text File refers to common data in text format.</p></td>
</tr>
<tr class="row-odd"><td><p>CSV File</p></td>
<td><p>CSVDataset</p></td>
<td><p>CSV refers to comma-separated values. Files in this format store tabular data in plain text.</p></td>
</tr>
</tbody>
</table>
<p>MindSpore also supports user-defined dataset loading using <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>. You can implement your own dataset classes as required.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Dataset Class</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>GeneratorDataset</p></td>
<td><p>User defined class or function to load and process dataset.</p></td>
</tr>
<tr class="row-odd"><td><p>NumpySlicesDataset</p></td>
<td><p>User defined data source to construct dataset using NumPy.</p></td>
</tr>
</tbody>
</table>
<blockquote>
<div><p>For details about the API for dataset loading, see <a class="reference external" href="https://www.mindspore.cn/doc/api_python/en/r1.2/mindspore/mindspore.dataset.html">MindSpore API</a>.</p>
</div></blockquote>
</section>
<section id="loading-common-dataset">
<h2>Loading Common Dataset<a class="headerlink" href="#loading-common-dataset" title="Permalink to this headline"></a></h2>
<p>The following describes how to load common datasets.</p>
<section id="cifar-10-100-dataset">
<h3>CIFAR-10/100 Dataset<a class="headerlink" href="#cifar-10-100-dataset" title="Permalink to this headline"></a></h3>
<p>Download <a class="reference external" href="https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz">CIFAR-10 dataset</a> and decompress it, the directory structure is as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>!wget<span class="w"> </span>-N<span class="w"> </span>https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/cifar-10-binary.tar.gz
!mkdir<span class="w"> </span>-p<span class="w"> </span>datasets
!tar<span class="w"> </span>-xzf<span class="w"> </span>cifar-10-binary.tar.gz<span class="w"> </span>-C<span class="w"> </span>datasets
!mkdir<span class="w"> </span>-p<span class="w"> </span>datasets/cifar-10-batches-bin/train<span class="w"> </span>datasets/cifar-10-batches-bin/test
!mv<span class="w"> </span>-f<span class="w"> </span>datasets/cifar-10-batches-bin/test_batch.bin<span class="w"> </span>datasets/cifar-10-batches-bin/test
!mv<span class="w"> </span>-f<span class="w"> </span>datasets/cifar-10-batches-bin/data_batch*.bin<span class="w"> </span>datasets/cifar-10-batches-bin/batches.meta.txt<span class="w"> </span>datasets/cifar-10-batches-bin/train
!tree<span class="w"> </span>./datasets/cifar-10-batches-bin
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./datasets/cifar-10-batches-bin
├── readme.html
├── test
│   └── test_batch.bin
└── train
    ├── batches.meta.txt
    ├── data_batch_1.bin
    ├── data_batch_2.bin
    ├── data_batch_3.bin
    ├── data_batch_4.bin
    └── data_batch_5.bin

2 directories, 8 files
</pre></div>
</div>
<p>The following example uses the <code class="docutils literal notranslate"><span class="pre">Cifar10Dataset</span></code> API to load the CIFAR-10 dataset, uses the sequential sampler to obtain five samples, and displays the shape and label of the corresponding image.</p>
<p>The methods for loading the CIFAR-100 and MNIST datasets are similar.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="n">DATA_DIR</span> <span class="o">=</span> <span class="s2">&quot;./datasets/cifar-10-batches-bin/train/&quot;</span>

<span class="n">sampler</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">SequentialSampler</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Image shape:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;, Label:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Image shape: (32, 32, 3) , Label: 6
Image shape: (32, 32, 3) , Label: 9
Image shape: (32, 32, 3) , Label: 9
Image shape: (32, 32, 3) , Label: 4
Image shape: (32, 32, 3) , Label: 1
</pre></div>
</div>
</section>
<section id="voc-dataset">
<h3>VOC Dataset<a class="headerlink" href="#voc-dataset" title="Permalink to this headline"></a></h3>
<p>There are multiple versions of the VOC dataset, here uses VOC2012 as an example. Download <a class="reference external" href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar">VOC2012 dataset</a> and decompress it. The directory structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─ VOCtrainval_11-May-2012
    └── VOCdevkit
        └── VOC2012
            ├── Annotations
            ├── ImageSets
            ├── JPEGImages
            ├── SegmentationClass
            └── SegmentationObject
</pre></div>
</div>
<p>The following example uses the <code class="docutils literal notranslate"><span class="pre">VOCDataset</span></code> API to load the VOC2012 dataset, displays the original image shape and target image shape when segmentation and detection tasks are specified.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="n">DATA_DIR</span> <span class="o">=</span> <span class="s2">&quot;VOCtrainval_11-May-2012/VOCdevkit/VOC2012/&quot;</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">VOCDataset</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&quot;Segmentation&quot;</span><span class="p">,</span> <span class="n">usage</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">decode</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[Segmentation]:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;image shape:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;target shape:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">VOCDataset</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&quot;Detection&quot;</span><span class="p">,</span> <span class="n">usage</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">decode</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[Detection]:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;image shape:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;bbox shape:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;bbox&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[Segmentation]:
image shape: (281, 500, 3)
target shape: (281, 500, 3)
image shape: (375, 500, 3)
target shape: (375, 500, 3)
[Detection]:
image shape: (442, 500, 3)
bbox shape: (2, 4)
</pre></div>
</div>
</section>
<section id="coco-dataset">
<h3>COCO Dataset<a class="headerlink" href="#coco-dataset" title="Permalink to this headline"></a></h3>
<p>There are multiple versions of the COCO dataset. Here, the validation dataset of COCO2017 is taken as an example. Download COCO2017 <a class="reference external" href="http://images.cocodataset.org/zips/val2017.zip">validation dataset</a>, <a class="reference external" href="http://images.cocodataset.org/annotations/annotations_trainval2017.zip">detection task annotation</a> and <a class="reference external" href="http://images.cocodataset.org/annotations/panoptic_annotations_trainval2017.zip">panoptic task annotation</a> and decompress them, take only a part of the validation dataset and store it as the following directory structure:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─ COCO
    ├── val2017
    └── annotations
        ├── instances_val2017.json
        ├── panoptic_val2017.json
        └── person_keypoints_val2017.json
</pre></div>
</div>
<p>The following example uses the <code class="docutils literal notranslate"><span class="pre">CocoDataset</span></code> API to load the COCO dataset, and displays the data when object detection, stuff segmentation, keypoint detection, and panoptic segmentation tasks are specified.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="n">DATA_DIR</span> <span class="o">=</span> <span class="s2">&quot;COCO/val2017/&quot;</span>
<span class="n">ANNOTATION_FILE</span> <span class="o">=</span> <span class="s2">&quot;COCO/annotations/instances_val2017.json&quot;</span>
<span class="n">KEYPOINT_FILE</span> <span class="o">=</span> <span class="s2">&quot;COCO/annotations/person_keypoints_val2017.json&quot;</span>
<span class="n">PANOPTIC_FILE</span> <span class="o">=</span> <span class="s2">&quot;COCO/annotations/panoptic_val2017.json&quot;</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">CocoDataset</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">annotation_file</span><span class="o">=</span><span class="n">ANNOTATION_FILE</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&quot;Detection&quot;</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Detection:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">CocoDataset</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">annotation_file</span><span class="o">=</span><span class="n">ANNOTATION_FILE</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&quot;Stuff&quot;</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Stuff:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">CocoDataset</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">annotation_file</span><span class="o">=</span><span class="n">KEYPOINT_FILE</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&quot;Keypoint&quot;</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Keypoint:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">CocoDataset</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">annotation_file</span><span class="o">=</span><span class="n">PANOPTIC_FILE</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&quot;Panoptic&quot;</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Panoptic:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Detection: dict_keys([&#39;image&#39;, &#39;bbox&#39;, &#39;category_id&#39;, &#39;iscrowd&#39;])
Stuff: dict_keys([&#39;image&#39;, &#39;segmentation&#39;, &#39;iscrowd&#39;])
Keypoint: dict_keys([&#39;image&#39;, &#39;keypoints&#39;, &#39;num_keypoints&#39;])
Panoptic: dict_keys([&#39;image&#39;, &#39;bbox&#39;, &#39;category_id&#39;, &#39;iscrowd&#39;, &#39;area&#39;])
</pre></div>
</div>
</section>
</section>
<section id="loading-datasets-in-specific-format">
<h2>Loading Datasets in Specific Format<a class="headerlink" href="#loading-datasets-in-specific-format" title="Permalink to this headline"></a></h2>
<p>The following describes how to load dataset files in specific formats.</p>
<section id="mindrecord">
<h3>MindRecord<a class="headerlink" href="#mindrecord" title="Permalink to this headline"></a></h3>
<p>MindRecord is a data format defined by MindSpore. Using MindRecord can improve performance.</p>
<blockquote>
<div><p>For details about how to convert a dataset into the MindRecord data format, see <a class="reference external" href="https://www.mindspore.cn/doc/programming_guide/en/r1.2/dataset_conversion.html">Data Format Conversion</a>.</p>
</div></blockquote>
<p>Before executing this example, you need to download the corresponding test data <code class="docutils literal notranslate"><span class="pre">test_mindrecord.zip</span></code> and unzip it to the specified location, execute the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>!wget<span class="w"> </span>-N<span class="w"> </span>https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/datasets/test_mindrecord.zip
!unzip<span class="w"> </span>-o<span class="w"> </span>./test_mindrecord.zip<span class="w"> </span>-d<span class="w"> </span>./datasets/mindspore_dataset_loading/
!tree<span class="w"> </span>./datasets/mindspore_dataset_loading/
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./datasets/mindspore_dataset_loading/
├── test.mindrecord
└── test.mindrecord.db

0 directories, 2 files
</pre></div>
</div>
<p>The following example uses the <code class="docutils literal notranslate"><span class="pre">MindDataset</span></code> API to load MindRecord files, and displays labels of the loaded data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="n">DATA_FILE</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;./datasets/mindspore_dataset_loading/test.mindrecord&quot;</span><span class="p">]</span>
<span class="n">mindrecord_dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">MindDataset</span><span class="p">(</span><span class="n">DATA_FILE</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">mindrecord_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;chinese&#39;, &#39;english&#39;])
dict_keys([&#39;chinese&#39;, &#39;english&#39;])
dict_keys([&#39;chinese&#39;, &#39;english&#39;])
</pre></div>
</div>
</section>
<section id="manifest">
<h3>Manifest<a class="headerlink" href="#manifest" title="Permalink to this headline"></a></h3>
<p>Manifest is a data format file supported by Huawei ModelArts. For details, see <a class="reference external" href="https://support.huaweicloud.com/en-us/engineers-modelarts/modelarts_23_0009.html">Specifications for Importing the Manifest File</a>.</p>
<p>In this example, you need to download the test data <code class="docutils literal notranslate"><span class="pre">test_manifest.zip</span></code> and unzip it to the specified location, and execute the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>!wget<span class="w"> </span>-N<span class="w"> </span>https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/datasets/test_manifest.zip
!unzip<span class="w"> </span>-o<span class="w"> </span>./test_manifest.zip<span class="w"> </span>-d<span class="w"> </span>./datasets/mindspore_dataset_loading/test_manifest/
!tree<span class="w"> </span>./datasets/mindspore_dataset_loading/test_manifest/
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./datasets/mindspore_dataset_loading/test_manifest/
├── eval
│   ├── 1.JPEG
│   └── 2.JPEG
├── test_manifest.json
└── train
    ├── 1.JPEG
    └── 2.JPEG

2 directories, 5 files
</pre></div>
</div>
<p>The following example uses the <code class="docutils literal notranslate"><span class="pre">ManifestDataset</span></code> API to load a Manifest file, and displays labels of the loaded data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="n">DATA_FILE</span> <span class="o">=</span> <span class="s2">&quot;./datasets/mindspore_dataset_loading/test_manifest/test_manifest.json&quot;</span>
<span class="n">manifest_dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">ManifestDataset</span><span class="p">(</span><span class="n">DATA_FILE</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">manifest_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>0
1
</pre></div>
</div>
</section>
<section id="tfrecord">
<h3>TFRecord<a class="headerlink" href="#tfrecord" title="Permalink to this headline"></a></h3>
<p>TFRecord is a binary data file format defined by TensorFlow.</p>
<p>The following example uses the <code class="docutils literal notranslate"><span class="pre">TFRecordDataset</span></code> API to load TFRecord files and introduces two methods for setting the format of datasets.</p>
<p>Download the <code class="docutils literal notranslate"><span class="pre">tfrecord</span></code> test data <code class="docutils literal notranslate"><span class="pre">test_tftext.zip</span></code> and unzip it to the specified location, execute the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>!wget<span class="w"> </span>-N<span class="w"> </span>https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/datasets/test_tftext.zip
!unzip<span class="w"> </span>-o<span class="w"> </span>./test_tftext.zip<span class="w"> </span>-d<span class="w"> </span>./datasets/mindspore_dataset_loading/test_tfrecord/
!tree<span class="w"> </span>./datasets/mindspore_dataset_loading/test_tfrecord/
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./datasets/mindspore_dataset_loading/test_tfrecord/
└── test_tftext.tfrecord

0 directories, 1 file
</pre></div>
</div>
<ol class="arabic">
<li><p>Specify the dataset path or TFRecord file list to create a <code class="docutils literal notranslate"><span class="pre">TFRecordDataset</span></code> object, this example uses test_tftext.tfrecord.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="n">DATA_FILE</span> <span class="o">=</span> <span class="s2">&quot;./datasets/mindspore_dataset_loading/test_tfrecord/test_tftext.tfrecord&quot;</span>
<span class="n">tfrecord_dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">TFRecordDataset</span><span class="p">(</span><span class="n">DATA_FILE</span><span class="p">)</span>

<span class="k">for</span> <span class="n">tf_data</span> <span class="ow">in</span> <span class="n">tfrecord_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tf_data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;chinese&#39;, &#39;line&#39;, &#39;words&#39;])
dict_keys([&#39;chinese&#39;, &#39;line&#39;, &#39;words&#39;])
dict_keys([&#39;chinese&#39;, &#39;line&#39;, &#39;words&#39;])
</pre></div>
</div>
</li>
<li><p>Compile a schema file or create a schema object to set the dataset format and features.</p>
<ul>
<li><p>Compile a schema file.</p>
<p>Write the dataset format and features to the schema file in JSON format. The following is an example:</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">columns</span></code>: column information field, which needs to be defined based on the actual column name of the dataset. In the preceding example, the dataset columns are <code class="docutils literal notranslate"><span class="pre">image</span></code>, <code class="docutils literal notranslate"><span class="pre">label</span></code>, and <code class="docutils literal notranslate"><span class="pre">id</span></code>.</p>
<p>When creating <code class="docutils literal notranslate"><span class="pre">TFRecordDataset</span></code>, transfer the path of the schema file.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="n">data_json</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;columns&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;chinese&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;uint8&quot;</span><span class="p">,</span>
            <span class="s2">&quot;rank&quot;</span><span class="p">:</span> <span class="mi">1</span>
            <span class="p">},</span>
        <span class="s2">&quot;line&quot;</span> <span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;int8&quot;</span><span class="p">,</span>
            <span class="s2">&quot;rank&quot;</span><span class="p">:</span> <span class="mi">1</span>
            <span class="p">},</span>
        <span class="s2">&quot;words&quot;</span> <span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;uint8&quot;</span><span class="p">,</span>
            <span class="s2">&quot;rank&quot;</span><span class="p">:</span> <span class="mi">0</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s2">&quot;dataset_schema_path&quot;</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s2">&quot;dataset_schema_path&quot;</span><span class="p">)</span>
<span class="n">SCHEMA_DIR</span> <span class="o">=</span> <span class="s2">&quot;dataset_schema_path/schema.json&quot;</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">SCHEMA_DIR</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">data_json</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">tfrecord_dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">TFRecordDataset</span><span class="p">(</span><span class="n">DATA_FILE</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="n">SCHEMA_DIR</span><span class="p">)</span>

<span class="k">for</span> <span class="n">tf_data</span> <span class="ow">in</span> <span class="n">tfrecord_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tf_data</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>dict_values([Tensor(shape=[57], dtype=UInt8, value= [230, 177, 159, 229, 183, 158, 229, 184, 130, 233, 149, 191, 230, 177, 159, 229, 164, 167, 230, 161, 165, 229, 143, 130,
 229, 138, 160, 228, 186, 134, 233, 149, 191, 230, 177, 159, 229, 164, 167, 230, 161, 165, 231, 154, 132, 233, 128, 154,
 232, 189, 166, 228, 187, 170, 229, 188, 143]), Tensor(shape=[22], dtype=Int8, value= [ 71, 111, 111, 100,  32, 108, 117,  99, 107,  32, 116, 111,  32, 101, 118, 101, 114, 121, 111, 110, 101,  46]), Tensor(shape=[32], dtype=UInt8, value= [229, 165, 179,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32, 101, 118, 101, 114, 121, 111, 110, 101,
  99,  32,  32,  32,  32,  32,  32,  32])])
dict_values([Tensor(shape=[12], dtype=UInt8, value= [231, 148, 183, 233, 187, 152, 229, 165, 179, 230, 179, 170]), Tensor(shape=[19], dtype=Int8, value= [ 66, 101,  32, 104,  97, 112, 112, 121,  32, 101, 118, 101, 114, 121,  32, 100,  97, 121,  46]), Tensor(shape=[20], dtype=UInt8, value= [ 66, 101,  32,  32,  32, 104,  97, 112, 112, 121, 100,  97, 121,  32,  32,  98,  32,  32,  32,  32])])
dict_values([Tensor(shape=[48], dtype=UInt8, value= [228, 187, 138, 229, 164, 169, 229, 164, 169, 230, 176, 148, 229, 164, 170, 229, 165, 189, 228, 186, 134, 230, 136, 145,
 228, 187, 172, 228, 184, 128, 232, 181, 183, 229, 142, 187, 229, 164, 150, 233, 157, 162, 231, 142, 169, 229, 144, 167
 ]), Tensor(shape=[20], dtype=Int8, value= [ 84, 104, 105, 115,  32, 105, 115,  32,  97,  32, 116, 101, 120, 116,  32, 102, 105, 108, 101,  46]), Tensor(shape=[16], dtype=UInt8, value= [ 84, 104, 105, 115, 116, 101, 120, 116, 102, 105, 108, 101,  97,  32,  32,  32])])
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Create a schema object.</p>
<p>Create a schema object, add user-defined fields to the schema object, and pass the schema object when creating a dataset object.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="n">schema</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Schema</span><span class="p">()</span>
<span class="n">schema</span><span class="o">.</span><span class="n">add_column</span><span class="p">(</span><span class="s1">&#39;chinese&#39;</span><span class="p">,</span> <span class="n">de_type</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="n">schema</span><span class="o">.</span><span class="n">add_column</span><span class="p">(</span><span class="s1">&#39;line&#39;</span><span class="p">,</span> <span class="n">de_type</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="n">tfrecord_dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">TFRecordDataset</span><span class="p">(</span><span class="n">DATA_FILE</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">)</span>

<span class="k">for</span> <span class="n">tf_data</span> <span class="ow">in</span> <span class="n">tfrecord_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tf_data</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{&#39;chinese&#39;: Tensor(shape=[12], dtype=UInt8, value= [231, 148, 183, 233, 187, 152, 229, 165, 179, 230, 179, 170]), &#39;line&#39;: Tensor(shape=[19], dtype=UInt8, value= [ 66, 101,  32, 104,  97, 112, 112, 121,  32, 101, 118, 101, 114, 121,  32, 100,  97, 121,  46])}
{&#39;chinese&#39;: Tensor(shape=[48], dtype=UInt8, value= [228, 187, 138, 229, 164, 169, 229, 164, 169, 230, 176, 148, 229, 164, 170, 229, 165, 189, 228, 186, 134, 230, 136, 145,
228, 187, 172, 228, 184, 128, 232, 181, 183, 229, 142, 187, 229, 164, 150, 233, 157, 162, 231, 142, 169, 229, 144, 167
]), &#39;line&#39;: Tensor(shape=[20], dtype=UInt8, value= [ 84, 104, 105, 115,  32, 105, 115,  32,  97,  32, 116, 101, 120, 116,  32, 102, 105, 108, 101,  46])}
{&#39;chinese&#39;: Tensor(shape=[57], dtype=UInt8, value= [230, 177, 159, 229, 183, 158, 229, 184, 130, 233, 149, 191, 230, 177, 159, 229, 164, 167, 230, 161, 165, 229, 143, 130,
229, 138, 160, 228, 186, 134, 233, 149, 191, 230, 177, 159, 229, 164, 167, 230, 161, 165, 231, 154, 132, 233, 128, 154,
232, 189, 166, 228, 187, 170, 229, 188, 143]), &#39;line&#39;: Tensor(shape=[22], dtype=UInt8, value= [ 71, 111, 111, 100,  32, 108, 117,  99, 107,  32, 116, 111,  32, 101, 118, 101, 114, 121, 111, 110, 101,  46])}
</pre></div>
</div>
</li>
</ol>
<p>Comparing step 2 and step 3 above, we can see:</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-left head"><p>step</p></th>
<th class="text-left head"><p>chinese</p></th>
<th class="text-left head"><p>line</p></th>
<th class="text-left head"><p>words</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>2</p></td>
<td class="text-left"><p>UInt8</p></td>
<td class="text-left"><p>Int8</p></td>
<td class="text-left"><p>UInt8</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>3</p></td>
<td class="text-left"><p>UInt8</p></td>
<td class="text-left"><p>UInt8</p></td>
<td class="text-left"><p></p></td>
</tr>
</tbody>
</table>
<p>The data in the columns in the example step 2 has changed from chinese (UInt8), line (Int8) and words (UInt8) to the chinese (UInt8) and line (UInt8) in the example step 3. Through the Schema object, set the data type and characteristics of the dataset, so that the data type and characteristics in the column are changed accordingly.</p>
</section>
<section id="numpy">
<h3>NumPy<a class="headerlink" href="#numpy" title="Permalink to this headline"></a></h3>
<p>If all data has been read into the memory, you can directly use the <code class="docutils literal notranslate"><span class="pre">NumpySlicesDataset</span></code> class to load the data.</p>
<p>The following examples describe how to use <code class="docutils literal notranslate"><span class="pre">NumpySlicesDataset</span></code> to load array, list, and dict data.</p>
<ul>
<li><p>Load NumPy array data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;col1&quot;</span><span class="p">,</span> <span class="s2">&quot;col2&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[0.89286015 0.33197981] [0.33540785]
[0.82122912 0.04169663] [0.62251943]
[0.10765668 0.59505206] [0.43814143]
[0.52981736 0.41880743] [0.73588211]
</pre></div>
</div>
</li>
<li><p>Load Python list data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="n">data1</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;col1&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[1 2]
[3 4]
</pre></div>
</div>
</li>
<li><p>Load Python dict data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="n">data1</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]}</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;col1&quot;</span><span class="p">,</span> <span class="s2">&quot;col2&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="k">for</span> <span class="n">np_dic_data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">np_dic_data</span><span class="p">)</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{&#39;col1&#39;: Tensor(shape=[], dtype=Int64, value= 1), &#39;col2&#39;: Tensor(shape=[], dtype=Int64, value= 3)}
{&#39;col1&#39;: Tensor(shape=[], dtype=Int64, value= 2), &#39;col2&#39;: Tensor(shape=[], dtype=Int64, value= 4)}
</pre></div>
</div>
</li>
</ul>
</section>
<section id="csv">
<h3>CSV<a class="headerlink" href="#csv" title="Permalink to this headline"></a></h3>
<p>The following example uses <code class="docutils literal notranslate"><span class="pre">CSVDataset</span></code> to load CSV dataset files, and displays labels of the loaded data.</p>
<p>Download the test data <code class="docutils literal notranslate"><span class="pre">test_csv.zip</span></code> and unzip it to the specified location, execute the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>!wget<span class="w"> </span>-N<span class="w"> </span>https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/datasets/test_csv.zip
!unzip<span class="w"> </span>-o<span class="w"> </span>./test_csv.zip<span class="w"> </span>-d<span class="w"> </span>./datasets/mindspore_dataset_loading/test_csv/
!tree<span class="w"> </span>./datasets/mindspore_dataset_loading/test_csv/
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./datasets/mindspore_dataset_loading/test_csv/
├── test1.csv
└── test2.csv

0 directories, 2 files
</pre></div>
</div>
<p>The method of loading a text dataset file is similar to that of loading a CSV file.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="n">DATA_FILE</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;./datasets/mindspore_dataset_loading/test_csv/test1.csv&quot;</span><span class="p">,</span><span class="s2">&quot;./datasets/mindspore_dataset_loading/test_csv/test2.csv&quot;</span><span class="p">]</span>
<span class="n">csv_dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">CSVDataset</span><span class="p">(</span><span class="n">DATA_FILE</span><span class="p">)</span>

<span class="k">for</span> <span class="n">csv_data</span> <span class="ow">in</span> <span class="n">csv_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">csv_data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
dict_keys([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
dict_keys([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
dict_keys([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
</pre></div>
</div>
</section>
</section>
<section id="loading-user-defined-dataset">
<h2>Loading User-defined Dataset<a class="headerlink" href="#loading-user-defined-dataset" title="Permalink to this headline"></a></h2>
<p>For the datasets that cannot be directly loaded by MindSpore, you can construct the <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> object to load them in a customized method or convert them into the MindRecord data format. The following demonstrates some different methods to load user-defined datasets. For comparison, keep the generated random data the same.</p>
<section id="constructing-dataset-generator-function">
<h3>Constructing Dataset Generator Function<a class="headerlink" href="#constructing-dataset-generator-function" title="Permalink to this headline"></a></h3>
<p>Construct a generator function that defines the data return method, and then use this function to construct the user-defined dataset object. This method is applicable for simple scenarios.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">58</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">GeneratorFunc</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="k">yield</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">GeneratorFunc</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">],</span> <span class="n">item</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[0.36510558 0.45120592] [0.78888122]
[0.49606035 0.07562207] [0.38068183]
[0.57176158 0.28963401] [0.16271622]
[0.30880446 0.37487617] [0.54738768]
[0.81585667 0.96883469] [0.77994068]
</pre></div>
</div>
</section>
<section id="constructing-iterable-dataset-class">
<h3>Constructing Iterable Dataset Class<a class="headerlink" href="#constructing-iterable-dataset-class" title="Permalink to this headline"></a></h3>
<p>Construct a dataset class to implement the <code class="docutils literal notranslate"><span class="pre">__iter__</span></code> and <code class="docutils literal notranslate"><span class="pre">__next__</span></code> methods, and then use the object of this class to construct the user-defined dataset object. Compared with directly defining the generating function, using the dataset class can achieve more customized functions.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="k">class</span> <span class="nc">IterDatasetGenerator</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">58</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__index</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">StopIteration</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">item</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">__index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">__label</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">__index</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__index</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">return</span> <span class="n">item</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">)</span>

<span class="n">dataset_generator</span> <span class="o">=</span> <span class="n">IterDatasetGenerator</span><span class="p">()</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">dataset_generator</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[0.36510558 0.45120592] [0.78888122]
[0.49606035 0.07562207] [0.38068183]
[0.57176158 0.28963401] [0.16271622]
[0.30880446 0.37487617] [0.54738768]
[0.81585667 0.96883469] [0.77994068]
</pre></div>
</div>
</section>
<section id="constructing-random-accessible-dataset-class">
<h3>Constructing Random Accessible Dataset Class<a class="headerlink" href="#constructing-random-accessible-dataset-class" title="Permalink to this headline"></a></h3>
<p>Construct a dataset class to implement the <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> method, and then use the object of this class to construct a user-defined dataset object. This method is applicable for achieving distributed training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="k">class</span> <span class="nc">GetDatasetGenerator</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">58</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">__label</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">)</span>

<span class="n">dataset_generator</span> <span class="o">=</span> <span class="n">GetDatasetGenerator</span><span class="p">()</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">dataset_generator</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[0.36510558 0.45120592] [0.78888122]
[0.49606035 0.07562207] [0.38068183]
[0.57176158 0.28963401] [0.16271622]
[0.30880446 0.37487617] [0.54738768]
[0.81585667 0.96883469] [0.77994068]
</pre></div>
</div>
<p>If you want to perform distributed training, you need to implement the <code class="docutils literal notranslate"><span class="pre">__iter__</span></code> method in the sampler class additionally. The index of the sampled data is returned each time. The code that needs to be added is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>

<span class="k">class</span> <span class="nc">MySampler</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">local_rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__num_data</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__local_rank</span> <span class="o">=</span> <span class="n">local_rank</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__world_size</span> <span class="o">=</span> <span class="n">world_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">samples_per_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__num_data</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__world_size</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_num_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">samples_per_rank</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">__world_size</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__num_data</span><span class="p">))</span>
        <span class="n">indices</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">indices</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">total_num_samples</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)])</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">__local_rank</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">total_num_samples</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">__world_size</span><span class="p">]</span>
        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">samples_per_rank</span>

<span class="n">dataset_generator</span> <span class="o">=</span> <span class="n">GetDatasetGenerator</span><span class="p">()</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">MySampler</span><span class="p">(</span><span class="n">dataset_generator</span><span class="p">,</span> <span class="n">local_rank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">dataset_generator</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[0.36510558 0.45120592] [0.78888122]
[0.57176158 0.28963401] [0.16271622]
[0.81585667 0.96883469] [0.77994068]
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="data_pipeline.html" class="btn btn-neutral float-left" title="Data Pipeline" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="sampler.html" class="btn btn-neutral float-right" title="Sampler" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>