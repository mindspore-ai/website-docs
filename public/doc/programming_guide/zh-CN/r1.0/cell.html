<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Cell构建及其子类 &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="常用网络组件" href="network_component.html" />
    <link rel="prev" title="Parameter" href="parameter.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_type.html">数据类型</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="compute_component.html">计算组件</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="operator.html">算子</a></li>
<li class="toctree-l2"><a class="reference internal" href="parameter.html">Parameter</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Cell构建及其子类</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">概述</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">关键成员函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#construct">construct方法</a></li>
<li class="toctree-l4"><a class="reference internal" href="#parameters-dict">parameters_dict</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cells-and-names">cells_and_names</a></li>
<li class="toctree-l4"><a class="reference internal" href="#set-grad">set_grad</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#nnops">nn模块与ops模块的关系</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">模型层</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id4">内置模型层</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id5">应用实例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id6">损失函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id7">内置损失函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id8">应用实例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id9">优化算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id10">构建自定义网络</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="network_component.html">常用网络组件</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="data_pipeline.html">数据管道</a></li>
<li class="toctree-l1"><a class="reference internal" href="execution_management.html">执行管理</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_parallel.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_use.html">进阶用法</a></li>
<li class="toctree-l1"><a class="reference internal" href="network_list.html">网络支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="operator_list.html">算子支持</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="compute_component.html">计算组件</a> &raquo;</li>
      <li>Cell构建及其子类</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/cell.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="cell">
<h1>Cell构建及其子类<a class="headerlink" href="#cell" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.0/docs/programming_guide/source_zh_cn/cell.md"><img alt="查看源文件" src="_images/logo_source.png" /></a></p>
<section id="id1">
<h2>概述<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h2>
<p>MindSpore的<code class="docutils literal notranslate"><span class="pre">Cell</span></code>类是构建所有网络的基类，也是网络的基本单元。当用户需要自定义网络时，需要继承<code class="docutils literal notranslate"><span class="pre">Cell</span></code>类，并重写<code class="docutils literal notranslate"><span class="pre">__init__</span></code>方法和<code class="docutils literal notranslate"><span class="pre">contruct</span></code>方法。</p>
<p>损失函数、优化器和模型层等本质上也属于网络结构，也需要继承<code class="docutils literal notranslate"><span class="pre">Cell</span></code>类才能实现功能，同样用户也可以根据业务需求自定义这部分内容。</p>
<p>本节内容首先将会介绍<code class="docutils literal notranslate"><span class="pre">Cell</span></code>类的关键成员函数，然后介绍基于<code class="docutils literal notranslate"><span class="pre">Cell</span></code>实现的MindSpore内置损失函数、优化器和模型层及使用方法，最后通过实例介绍如何利用<code class="docutils literal notranslate"><span class="pre">Cell</span></code>类构建自定义网络。</p>
</section>
<section id="id2">
<h2>关键成员函数<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h2>
<section id="construct">
<h3>construct方法<a class="headerlink" href="#construct" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Cell</span></code>类重写了<code class="docutils literal notranslate"><span class="pre">__call__</span></code>方法，在<code class="docutils literal notranslate"><span class="pre">Cell</span></code>类的实例被调用时，会执行<code class="docutils literal notranslate"><span class="pre">construct</span></code>方法。网络结构在<code class="docutils literal notranslate"><span class="pre">construct</span></code>方法里面定义。</p>
<p>下面的样例中，我们构建了一个简单的网络实现卷积计算功能。构成网络的算子在<code class="docutils literal notranslate"><span class="pre">__init__</span></code>中定义，在<code class="docutils literal notranslate"><span class="pre">construct</span></code>方法里面使用，用例的网络结构为<code class="docutils literal notranslate"><span class="pre">Conv2d</span></code>-&gt;<code class="docutils literal notranslate"><span class="pre">BiasAdd</span></code>。</p>
<p>在<code class="docutils literal notranslate"><span class="pre">construct</span></code>方法中，<code class="docutils literal notranslate"><span class="pre">x</span></code>为输入数据，<code class="docutils literal notranslate"><span class="pre">output</span></code>是经过网络结构计算后得到的计算结果。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore.common.parameter</span> <span class="kn">import</span> <span class="n">Parameter</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">initializer</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2d</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias_add</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">BiasAdd</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span>
            <span class="n">initializer</span><span class="p">(</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">]),</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv.weight&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</section>
<section id="parameters-dict">
<h3>parameters_dict<a class="headerlink" href="#parameters-dict" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">parameters_dict</span></code>方法识别出网络结构中所有的参数，返回一个以key为参数名，value为参数值的<code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code>。</p>
<p><code class="docutils literal notranslate"><span class="pre">Cell</span></code>类中返回参数的方法还有许多，例如<code class="docutils literal notranslate"><span class="pre">get_parameters</span></code>、<code class="docutils literal notranslate"><span class="pre">trainable_params</span></code>等，具体使用方法可以参见<a class="reference external" href="https://www.mindspore.cn/doc/api_python/zh-CN/r1.0/mindspore/mindspore.nn.html#mindspore.nn.Cell">API文档</a>。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters_dict</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;conv.weight&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>样例中的<code class="docutils literal notranslate"><span class="pre">Net</span></code>采用上文构造网络的用例，打印了网络中所有参数的名字和<code class="docutils literal notranslate"><span class="pre">conv.weight</span></code>参数的结果。</p>
<p>输出如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>odict_keys([&#39;conv.weight&#39;])
Parameter (name=conv.weight, value=[[[[-3.95042636e-03  1.08830128e-02 -6.51786150e-03]
   [ 8.66129529e-03  7.36288540e-03 -4.32638079e-03]
   [-1.47628486e-02  8.24100431e-03 -2.71035335e-03]]
   ......
   [ 1.58852488e-02 -1.03505487e-02  1.72988791e-02]]]])
</pre></div>
</div>
</section>
<section id="cells-and-names">
<h3>cells_and_names<a class="headerlink" href="#cells-and-names" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">cells_and_names</span></code>方法是一个迭代器，返回网络中每个<code class="docutils literal notranslate"><span class="pre">Cell</span></code>的名字和它的内容本身。</p>
<p>用例简单实现了获取与打印每个<code class="docutils literal notranslate"><span class="pre">Cell</span></code>名字的功能，其中根据网络结构可知，存在1个<code class="docutils literal notranslate"><span class="pre">Cell</span></code>为<code class="docutils literal notranslate"><span class="pre">nn.Conv2d</span></code>。</p>
<p>其中<code class="docutils literal notranslate"><span class="pre">nn.Conv2d</span></code>是MindSpore以<code class="docutils literal notranslate"><span class="pre">Cell</span></code>为基类封装好的一个卷积层，其具体内容将在“模型层”中进行介绍。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">Net1</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net1</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Net1</span><span class="p">()</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="n">names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">if</span> <span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">else</span> <span class="kc">None</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-------names-------&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">names</span><span class="p">)</span>
</pre></div>
</div>
<p>输出如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>(&#39;&#39;, Net1&lt;
  (conv): Conv2d&lt;input_channels=3, output_channels=64, kernel_size=(3, 3),stride=(1, 1),  pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False,weight_init=normal, bias_init=zeros&gt;
  &gt;)
(&#39;conv&#39;, Conv2d&lt;input_channels=3, output_channels=64, kernel_size=(3, 3),stride=(1, 1),  pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False,weight_init=normal, bias_init=zeros&gt;)
-------names-------
[&#39;conv&#39;]
</pre></div>
</div>
</section>
<section id="set-grad">
<h3>set_grad<a class="headerlink" href="#set-grad" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">set_grad</span></code>接口功能是使用户构建反向网络，在不传入参数调用时，默认设置<code class="docutils literal notranslate"><span class="pre">requires_grad</span></code>为True，需要在计算网络反向的场景中使用。</p>
<p>以<code class="docutils literal notranslate"><span class="pre">TrainOneStepCell</span></code>为例，其接口功能是使网络进行单步训练，需要计算网络反向，因此初始化方法里需要使用<code class="docutils literal notranslate"><span class="pre">set_grad</span></code>。</p>
<p><code class="docutils literal notranslate"><span class="pre">TrainOneStepCell</span></code>部分代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TrainOneStepCell</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">sens</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TrainOneStepCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">set_grad</span><span class="p">()</span>
        <span class="o">......</span>
</pre></div>
</div>
<p>如果用户使用<code class="docutils literal notranslate"><span class="pre">TrainOneStepCell</span></code>等类似接口无需使用<code class="docutils literal notranslate"><span class="pre">set_grad</span></code>， 内部已封装实现。</p>
<p>若用户需要自定义此类训练功能的接口，需要在其内部调用，或者在外部设置<code class="docutils literal notranslate"><span class="pre">network.set_grad</span></code>。</p>
</section>
</section>
<section id="nnops">
<h2>nn模块与ops模块的关系<a class="headerlink" href="#nnops" title="Permalink to this headline"></a></h2>
<p>MindSpore的nn模块是Python实现的模型组件，是对低阶API的封装，主要包括各种模型层、损失函数、优化器等。</p>
<p>同时nn也提供了部分与<code class="docutils literal notranslate"><span class="pre">Primitive</span></code>算子同名的接口，主要作用是对<code class="docutils literal notranslate"><span class="pre">Primitive</span></code>算子进行进一步封装，为用户提供更友好的API。</p>
<p>重新分析上文介绍<code class="docutils literal notranslate"><span class="pre">construct</span></code>方法的用例，此用例是MindSpore的<code class="docutils literal notranslate"><span class="pre">nn.Conv2d</span></code>源码简化内容，内部会调用<code class="docutils literal notranslate"><span class="pre">ops.Conv2D</span></code>。<code class="docutils literal notranslate"><span class="pre">nn.Conv2d</span></code>卷积API增加输入参数校验功能并判断是否<code class="docutils literal notranslate"><span class="pre">bias</span></code>等，是一个高级封装的模型层。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore.common.parameter</span> <span class="kn">import</span> <span class="n">Parameter</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">initializer</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2d</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias_add</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">BiasAdd</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span>
            <span class="n">initializer</span><span class="p">(</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">]),</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv.weight&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</section>
<section id="id3">
<h2>模型层<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h2>
<p>在讲述了<code class="docutils literal notranslate"><span class="pre">Cell</span></code>的使用方法后可知，MindSpore能够以<code class="docutils literal notranslate"><span class="pre">Cell</span></code>为基类构造网络结构。</p>
<p>为了方便用户的使用，MindSpore框架内置了大量的模型层，用户可以通过接口直接调用。</p>
<p>同样，用户也可以自定义模型，此内容在“构建自定义网络”中介绍。</p>
<section id="id4">
<h3>内置模型层<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h3>
<p>MindSpore框架在<code class="docutils literal notranslate"><span class="pre">mindspore.nn</span></code>的layer层内置了丰富的接口，主要内容如下：</p>
<ul>
<li><p>激活层</p>
<p>激活层内置了大量的激活函数，在定义网络结构中经常使用。激活函数为网络加入了非线性运算，使得网络能够拟合效果更好。</p>
<p>主要接口有<code class="docutils literal notranslate"><span class="pre">Softmax</span></code>、<code class="docutils literal notranslate"><span class="pre">Relu</span></code>、<code class="docutils literal notranslate"><span class="pre">Elu</span></code>、<code class="docutils literal notranslate"><span class="pre">Tanh</span></code>、<code class="docutils literal notranslate"><span class="pre">Sigmoid</span></code>等。</p>
</li>
<li><p>基础层</p>
<p>基础层实现了网络中一些常用的基础结构，例如全连接层、Onehot编码、Dropout、平铺层等都在此部分实现。</p>
<p>主要接口有<code class="docutils literal notranslate"><span class="pre">Dense</span></code>、<code class="docutils literal notranslate"><span class="pre">Flatten</span></code>、<code class="docutils literal notranslate"><span class="pre">Dropout</span></code>、<code class="docutils literal notranslate"><span class="pre">Norm</span></code>、<code class="docutils literal notranslate"><span class="pre">OneHot</span></code>等。</p>
</li>
<li><p>容器层</p>
<p>容器层主要功能是实现一些存储多个Cell的数据结构。</p>
<p>主要接口有<code class="docutils literal notranslate"><span class="pre">SequentialCell</span></code>、<code class="docutils literal notranslate"><span class="pre">CellList</span></code>等。</p>
</li>
<li><p>卷积层</p>
<p>卷积层提供了一些卷积计算的功能，如普通卷积、深度卷积和卷积转置等。</p>
<p>主要接口有<code class="docutils literal notranslate"><span class="pre">Conv2d</span></code>、<code class="docutils literal notranslate"><span class="pre">Conv1d</span></code>、<code class="docutils literal notranslate"><span class="pre">Conv2dTranspose</span></code>、<code class="docutils literal notranslate"><span class="pre">Conv1dTranspose</span></code>等。</p>
</li>
<li><p>池化层</p>
<p>池化层提供了平均池化和最大池化等计算的功能。</p>
<p>主要接口有<code class="docutils literal notranslate"><span class="pre">AvgPool2d</span></code>、<code class="docutils literal notranslate"><span class="pre">MaxPool2d</span></code>和<code class="docutils literal notranslate"><span class="pre">AvgPool1d</span></code>。</p>
</li>
<li><p>嵌入层</p>
<p>嵌入层提供word embedding的计算功能，将输入的单词映射为稠密向量。</p>
<p>主要接口有<code class="docutils literal notranslate"><span class="pre">Embedding</span></code>、<code class="docutils literal notranslate"><span class="pre">EmbeddingLookup</span></code>、<code class="docutils literal notranslate"><span class="pre">EmbeddingLookUpSplitMode</span></code>等。</p>
</li>
<li><p>长短记忆循环层</p>
<p>长短记忆循环层提供LSTM计算功能。其中<code class="docutils literal notranslate"><span class="pre">LSTM</span></code>内部会调用<code class="docutils literal notranslate"><span class="pre">LSTMCell</span></code>接口，<code class="docutils literal notranslate"><span class="pre">LSTMCell</span></code>是一个LSTM单元，对一个LSTM层做运算，当涉及多LSTM网络层运算时，使用<code class="docutils literal notranslate"><span class="pre">LSTM</span></code>接口。</p>
<p>主要接口有<code class="docutils literal notranslate"><span class="pre">LSTM</span></code>和<code class="docutils literal notranslate"><span class="pre">LSTMCell</span></code>。</p>
</li>
<li><p>标准化层</p>
<p>标准化层提供了一些标准化的方法，即通过线性变换等方式将数据转换成均值和标准差。</p>
<p>主要接口有<code class="docutils literal notranslate"><span class="pre">BatchNorm1d</span></code>、<code class="docutils literal notranslate"><span class="pre">BatchNorm2d</span></code>、<code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code>、<code class="docutils literal notranslate"><span class="pre">GroupNorm</span></code>、<code class="docutils literal notranslate"><span class="pre">GlobalBatchNorm</span></code>等。</p>
</li>
<li><p>数学计算层</p>
<p>数学计算层提供一些算子拼接而成的计算功能，例如数据生成和一些数学计算等。</p>
<p>主要接口有<code class="docutils literal notranslate"><span class="pre">ReduceLogSumExp</span></code>、<code class="docutils literal notranslate"><span class="pre">Range</span></code>、<code class="docutils literal notranslate"><span class="pre">LinSpace</span></code>、<code class="docutils literal notranslate"><span class="pre">LGamma</span></code>等。</p>
</li>
<li><p>图片层</p>
<p>图片计算层提供了一些矩阵计算相关的功能，将图片数据进行一些变换与计算。</p>
<p>主要接口有<code class="docutils literal notranslate"><span class="pre">ImageGradients</span></code>、<code class="docutils literal notranslate"><span class="pre">SSIM</span></code>、<code class="docutils literal notranslate"><span class="pre">MSSSIM</span></code>、<code class="docutils literal notranslate"><span class="pre">PSNR</span></code>、<code class="docutils literal notranslate"><span class="pre">CentralCrop</span></code>等。</p>
</li>
<li><p>量化层</p>
<p>量化是指将数据从float的形式转换成一段数据范围的int类型，所以量化层提供了一些数据量化的方法和模型层结构封装。</p>
<p>主要接口有<code class="docutils literal notranslate"><span class="pre">Conv2dBnAct</span></code>、<code class="docutils literal notranslate"><span class="pre">DenseBnAct</span></code>、<code class="docutils literal notranslate"><span class="pre">Conv2dBnFoldQuant</span></code>、<code class="docutils literal notranslate"><span class="pre">LeakyReLUQuant</span></code>等。</p>
</li>
</ul>
</section>
<section id="id5">
<h3>应用实例<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h3>
<p>MindSpore的模型层在<code class="docutils literal notranslate"><span class="pre">mindspore.nn</span></code>下，使用方法如下所示：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span> <span class="o">*</span> <span class="mi">222</span> <span class="o">*</span> <span class="mi">222</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
<p>依然是上述网络构造的用例，从这个用例中可以看出，程序调用了<code class="docutils literal notranslate"><span class="pre">Conv2d</span></code>、<code class="docutils literal notranslate"><span class="pre">BatchNorm2d</span></code>、<code class="docutils literal notranslate"><span class="pre">ReLU</span></code>、<code class="docutils literal notranslate"><span class="pre">Flatten</span></code>和<code class="docutils literal notranslate"><span class="pre">Dense</span></code>模型层的接口。</p>
<p>在<code class="docutils literal notranslate"><span class="pre">Net</span></code>初始化方法里被定义，然后在<code class="docutils literal notranslate"><span class="pre">construct</span></code>方法里真正运行，这些模型层接口有序的连接，形成一个可执行的网络。</p>
</section>
</section>
<section id="id6">
<h2>损失函数<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h2>
<p>目前MindSpore主要支持的损失函数有<code class="docutils literal notranslate"><span class="pre">L1Loss</span></code>、<code class="docutils literal notranslate"><span class="pre">MSELoss</span></code>、<code class="docutils literal notranslate"><span class="pre">SmoothL1Loss</span></code>、<code class="docutils literal notranslate"><span class="pre">SoftmaxCrossEntropyWithLogits</span></code>和<code class="docutils literal notranslate"><span class="pre">CosineEmbeddingLoss</span></code>。</p>
<p>MindSpore的损失函数全部是<code class="docutils literal notranslate"><span class="pre">Cell</span></code>的子类实现，所以也支持用户自定义损失函数，其构造方法在“构建自定义网络”中进行介绍。</p>
<section id="id7">
<h3>内置损失函数<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h3>
<ul>
<li><p>L1Loss</p>
<p>计算两个输入数据的绝对值误差，用于回归模型。<code class="docutils literal notranslate"><span class="pre">reduction</span></code>参数默认值为mean，返回loss平均值结果，若<code class="docutils literal notranslate"><span class="pre">reduction</span></code>值为sum，返回loss累加结果，若<code class="docutils literal notranslate"><span class="pre">reduction</span></code>值为none，返回每个loss的结果。</p>
</li>
<li><p>MSELoss</p>
<p>计算两个输入数据的平方误差，用于回归模型。<code class="docutils literal notranslate"><span class="pre">reduction</span></code>参数同<code class="docutils literal notranslate"><span class="pre">L1Loss</span></code>。</p>
</li>
<li><p>SmoothL1Loss</p>
<p><code class="docutils literal notranslate"><span class="pre">SmoothL1Loss</span></code>为平滑L1损失函数，用于回归模型，阈值<code class="docutils literal notranslate"><span class="pre">sigma</span></code>默认参数为1。
`</p>
</li>
<li><p>SoftmaxCrossEntropyWithLogits</p>
<p>交叉熵损失函数，用于分类模型。当标签数据不是one-hot编码形式时，需要输入参数<code class="docutils literal notranslate"><span class="pre">sparse</span></code>为True。<code class="docutils literal notranslate"><span class="pre">reduction</span></code>参数默认值为none，其参数含义同<code class="docutils literal notranslate"><span class="pre">L1Loss</span></code>。</p>
</li>
<li><p>CosineEmbeddingLoss</p>
<p><code class="docutils literal notranslate"><span class="pre">CosineEmbeddingLoss</span></code>用于衡量两个输入相似程度，用于分类模型。<code class="docutils literal notranslate"><span class="pre">margin</span></code>默认为0.0，<code class="docutils literal notranslate"><span class="pre">reduction</span></code>参数同<code class="docutils literal notranslate"><span class="pre">L1Loss</span></code>。</p>
</li>
</ul>
</section>
<section id="id8">
<h3>应用实例<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h3>
<p>MindSpore的损失函数全部在mindspore.nn下，使用方法如下所示：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()</span>
<span class="n">input_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">target_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">target_data</span><span class="p">))</span>
</pre></div>
</div>
<p>输出结果：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="mf">1.5</span>
</pre></div>
</div>
<p>此用例构造了两个Tensor数据，利用<code class="docutils literal notranslate"><span class="pre">nn.L1Loss</span></code>接口定义了loss，将<code class="docutils literal notranslate"><span class="pre">input_data</span></code>和<code class="docutils literal notranslate"><span class="pre">target_data</span></code>传入loss，执行L1Loss的计算，结果为1.5。若loss = nn.L1Loss(reduction=’sum’)，则结果为9.0。若loss = nn.L1Loss(reduction=’none’)，结果为[[1. 0. 2.] [1. 2. 3.]]。</p>
</section>
</section>
<section id="id9">
<h2>优化算法<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">mindspore.nn.optim</span></code>是MindSpore框架中实现各种优化算法的模块，详细说明参见<a class="reference external" href="https://www.mindspore.cn/doc/programming_guide/zh-CN/r1.0/optim.html">优化算法</a>。</p>
</section>
<section id="id10">
<h2>构建自定义网络<a class="headerlink" href="#id10" title="Permalink to this headline"></a></h2>
<p>无论是网络结构，还是前文提到的模型层、损失函数和优化器等，本质上都是一个<code class="docutils literal notranslate"><span class="pre">Cell</span></code>，因此都可以自定义实现。</p>
<p>首先构造一个继承<code class="docutils literal notranslate"><span class="pre">Cell</span></code>的子类，然后在<code class="docutils literal notranslate"><span class="pre">__init__</span></code>方法里面定义算子和模型层等，在<code class="docutils literal notranslate"><span class="pre">construct</span></code>方法里面构造网络结构。</p>
<p>以LeNet网络为例，在<code class="docutils literal notranslate"><span class="pre">__init__</span></code>方法中定义了卷积层，池化层和全连接层等结构单元，然后在<code class="docutils literal notranslate"><span class="pre">construct</span></code>方法将定义的内容连接在一起，形成一个完整LeNet的网络结构。</p>
<p>LeNet网络实现方式如下所示：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">LeNet5</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeNet5</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="parameter.html" class="btn btn-neutral float-left" title="Parameter" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="network_component.html" class="btn btn-neutral float-right" title="常用网络组件" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>