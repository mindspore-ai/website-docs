<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>深度概率编程库 &mdash; MindSpore r1.1 documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="网络支持" href="network_list.html" />
    <link rel="prev" title="功能扩展" href="extension.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_type.html">数据类型</a></li>
<li class="toctree-l1"><a class="reference internal" href="compute_component.html">计算组件</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_pipeline.html">数据管道</a></li>
<li class="toctree-l1"><a class="reference internal" href="execution_management.html">执行管理</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_parallel.html">分布式并行</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="advanced_usage.html">进阶用法</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="train.html">训练</a></li>
<li class="toctree-l2"><a class="reference internal" href="infer.html">推理</a></li>
<li class="toctree-l2"><a class="reference internal" href="performance_optimization.html">性能优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="customized.html">自定义算子</a></li>
<li class="toctree-l2"><a class="reference internal" href="security_and_privacy.html">AI安全与隐私保护</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="extension.html">功能扩展</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">深度概率编程库</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id2">概率分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id6">概率分布映射</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id9">深度概率网络</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id10">概率推断算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id11">贝叶斯层</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id12">贝叶斯转换</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id13">贝叶斯工具箱</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="network_list.html">网络支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="operator_list.html">算子支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="syntax_list.html">语法支持</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="advanced_usage.html">进阶用法</a> &raquo;</li>
          <li><a href="extension.html">功能扩展</a> &raquo;</li>
      <li>深度概率编程库</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/probability.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1>深度概率编程库<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.1/docs/programming_guide/source_zh_cn/probability.md" target="_blank"><img src="./_static/logo_source.png"></a></p>
<p>MindSpore深度概率编程的目标是将深度学习和贝叶斯学习结合，包括概率分布、概率分布映射、深度概率网络、概率推断算法、贝叶斯层、贝叶斯转换和贝叶斯工具箱，面向不同的开发者。对于专业的贝叶斯学习用户，提供概率采样、推理算法和模型构建库；另一方面，为不熟悉贝叶斯深度学习的用户提供了高级的API，从而不用更改深度学习编程逻辑，即可利用贝叶斯模型。</p>
<section id="id2">
<h2>概率分布<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h2>
<p>概率分布（<code class="docutils literal notranslate"><span class="pre">mindspore.nn.probability.distribution</span></code>）是概率编程的基础。<code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 类提供多样的概率统计接口，例如概率密度函数 <em>pdf</em> 、累积密度函数 <em>cdf</em> 、散度计算 <em>kl_loss</em> 、抽样 <em>sample</em> 等。现有的概率分布实例包括高斯分布，伯努利分布，指数型分布，几何分布和均匀分布。</p>
<section id="id3">
<h3>概率分布类<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Distribution</span></code>：所有概率分布的基类。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Bernoulli</span></code>：伯努利分布。参数为试验成功的概率。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Exponential</span></code>：指数型分布。参数为率参数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Geometric</span></code>：几何分布。参数为一次伯努利试验成功的概率。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Normal</span></code>：正态（高斯）分布。参数为均值和标准差。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Uniform</span></code>：均匀分布。参数为数轴上的最小值和最大值。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Categorical</span></code>：类别分布。每种类别出现的概率。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LogNormal</span></code>：对数正态分布。参数为位置参数和规模参数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Gumbel</span></code>: 耿贝尔极值分布。参数为位置参数和规模参数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Logistic</span></code>：逻辑斯谛分布。参数为位置参数和规模参数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Cauchy</span></code>：柯西分布。参数为位置参数和规模参数。</p></li>
</ul>
<section id="distribution">
<h4>Distribution基类<a class="headerlink" href="#distribution" title="Permalink to this headline"></a></h4>
<p><code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 是所有概率分布的基类。</p>
<p>接口介绍：<code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 类支持的函数包括 <code class="docutils literal notranslate"><span class="pre">prob</span></code>、<code class="docutils literal notranslate"><span class="pre">log_prob</span></code>、<code class="docutils literal notranslate"><span class="pre">cdf</span></code>、<code class="docutils literal notranslate"><span class="pre">log_cdf</span></code>、<code class="docutils literal notranslate"><span class="pre">survival_function</span></code>、<code class="docutils literal notranslate"><span class="pre">log_survival</span></code>、<code class="docutils literal notranslate"><span class="pre">mean</span></code>、<code class="docutils literal notranslate"><span class="pre">sd</span></code>、<code class="docutils literal notranslate"><span class="pre">var</span></code>、<code class="docutils literal notranslate"><span class="pre">entropy</span></code>、<code class="docutils literal notranslate"><span class="pre">kl_loss</span></code>、<code class="docutils literal notranslate"><span class="pre">cross_entropy</span></code> 和 <code class="docutils literal notranslate"><span class="pre">sample</span></code> 。分布不同，所需传入的参数也不同。只有在派生类中才能使用，由派生类的函数实现决定参数。</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">prob</span></code> ：概率密度函数（PDF）/ 概率质量函数（PMF）。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">log_prob</span></code> ：对数似然函数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cdf</span></code> ：累积分布函数（CDF）。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">log_cdf</span></code> ：对数累积分布函数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">survival_function</span></code> ：生存函数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">log_survival</span></code> ：对数生存函数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code> ：均值。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sd</span></code> ：标准差。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">var</span></code> ：方差。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entropy</span></code> ：熵。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kl_loss</span></code> ：Kullback-Leibler 散度。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cross_entropy</span></code> ：两个概率分布的交叉熵。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample</span></code> ：概率分布的随机抽样。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_args</span></code> ：概率分布在网络中使用的参数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_type</span></code> ：概率分布的类型。</p></li>
</ul>
</section>
<section id="bernoulli">
<h4>伯努利分布(Bernoulli)<a class="headerlink" href="#bernoulli" title="Permalink to this headline"></a></h4>
<p>伯努利分布，继承自 <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 类。</p>
<p>属性:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Bernoulli.probs</span></code>：返回伯努利试验成功的概率，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 基类调用 <code class="docutils literal notranslate"><span class="pre">Bernoulli</span></code> 中私有接口以实现基类中的公有接口。<code class="docutils literal notranslate"><span class="pre">Bernoulli</span></code> 支持的公有接口为：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code>，<code class="docutils literal notranslate"><span class="pre">mode</span></code>，<code class="docutils literal notranslate"><span class="pre">var</span></code>，<code class="docutils literal notranslate"><span class="pre">sd</span></code>：可选择传入 试验成功的概率 <em>probs1</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entropy</span></code>：可选择传入 试验成功的概率 <em>probs1</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cross_entropy</span></code>，<code class="docutils literal notranslate"><span class="pre">kl_loss</span></code>：必须传入 <em>dist</em> 和 <em>probs1_b</em> 。<em>dist</em> 为另一分布的类型，目前只支持此处为 <em>‘Bernoulli’</em> 。 <em>probs1_b</em> 为分布 <em>b</em> 的试验成功概率。可选择传入分布 <em>a</em> 的参数 <em>probs1_a</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prob</span></code>，<code class="docutils literal notranslate"><span class="pre">log_prob</span></code>，<code class="docutils literal notranslate"><span class="pre">cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">log_cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">survival_function</span></code>，<code class="docutils literal notranslate"><span class="pre">log_survival</span></code>：必须传入 <em>value</em> 。可选择传入试验成功的概率 <em>probs</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample</span></code>：可选择传入样本形状 <em>shape</em> 和试验成功的概率 <em>probs1</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_args</span></code> ：可选择传入试验成功的概率 <em>probs</em>。返回值为<code class="docutils literal notranslate"><span class="pre">(probs,)</span></code>，类型为tuple。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_type</span></code> ：返回 <em>‘Bernoulli’</em> 。</p></li>
</ul>
</section>
<section id="exponential">
<h4>指数分布(Exponential)<a class="headerlink" href="#exponential" title="Permalink to this headline"></a></h4>
<p>指数分布，继承自 <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 类。</p>
<p>属性:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Exponential.rate</span></code>：返回分布的率参数，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 基类调用 <code class="docutils literal notranslate"><span class="pre">Exponential</span></code> 私有接口以实现基类中的公有接口。<code class="docutils literal notranslate"><span class="pre">Exponential</span></code> 支持的公有接口为：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code>，<code class="docutils literal notranslate"><span class="pre">mode</span></code>，<code class="docutils literal notranslate"><span class="pre">var</span></code>，<code class="docutils literal notranslate"><span class="pre">sd</span></code>：可选择传入率参数 <em>rate</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entropy</span></code>：可选择传入率参数 <em>rate</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cross_entropy</span></code>，<code class="docutils literal notranslate"><span class="pre">kl_loss</span></code>：必须传入 <em>dist</em> 和 <em>rate_b</em> 。 <em>dist</em> 为另一分布的类型的名称， 目前只支持此处为 <em>‘Exponential’</em> 。<em>rate_b</em> 为分布 <em>b</em> 的率参数。可选择传入分布 <em>a</em> 的参数 <em>rate_a</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prob</span></code>，<code class="docutils literal notranslate"><span class="pre">log_prob</span></code>，<code class="docutils literal notranslate"><span class="pre">cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">log_cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">survival_function</span></code>，<code class="docutils literal notranslate"><span class="pre">log_survival</span></code>：必须传入 <em>value</em> 。可选择传入率参数 <em>rate</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample</span></code>：可选择传入样本形状 <em>shape</em> 和率参数 <em>rate</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_args</span></code> ：可选择传入率参数 <em>rate</em> 。返回值为<code class="docutils literal notranslate"><span class="pre">(rate,)</span></code>，类型为tuple。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_type</span></code> ：返回 <em>‘Exponential’</em> 。</p></li>
</ul>
</section>
<section id="geometric">
<h4>几何分布(Geometric)<a class="headerlink" href="#geometric" title="Permalink to this headline"></a></h4>
<p>几何分布，继承自 <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 类。</p>
<p>属性:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Geometric.probs</span></code>：返回伯努利试验成功的概率，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 基类调用 <code class="docutils literal notranslate"><span class="pre">Geometric</span></code> 中私有接口以实现基类中的公有接口。<code class="docutils literal notranslate"><span class="pre">Geometric</span></code> 支持的公有接口为：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code>，<code class="docutils literal notranslate"><span class="pre">mode</span></code>，<code class="docutils literal notranslate"><span class="pre">var</span></code>，<code class="docutils literal notranslate"><span class="pre">sd</span></code>：可选择传入试验成功的概率 <em>probs1</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entropy</span></code>：可选择传入 试验成功的概率 <em>probs1</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cross_entropy</span></code>，<code class="docutils literal notranslate"><span class="pre">kl_loss</span></code>：必须传入 <em>dist</em> 和 <em>probs1_b</em> 。<em>dist</em> 为另一分布的类型的名称，目前只支持此处为 <em>‘Geometric’</em> 。 <em>probs1_b</em> 为分布 <em>b</em> 的试验成功概率。可选择传入分布 <em>a</em> 的参数 <em>probs1_a</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prob</span></code>，<code class="docutils literal notranslate"><span class="pre">log_prob</span></code>，<code class="docutils literal notranslate"><span class="pre">cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">log_cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">survival_function</span></code>，<code class="docutils literal notranslate"><span class="pre">log_survival</span></code>：必须传入 <em>value</em> 。可选择传入试验成功的概率 <em>probs1</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample</span></code>：可选择传入样本形状 <em>shape</em> 和试验成功的概率 <em>probs1</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_args</span></code> ：可选择传入试验成功的概率 <em>probs1</em> 。返回值为<code class="docutils literal notranslate"><span class="pre">(probs1,)</span></code>，类型为tuple。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_type</span></code> ：返回 <em>‘Geometric’</em> 。</p></li>
</ul>
</section>
<section id="normal">
<h4>正态分布(Normal)<a class="headerlink" href="#normal" title="Permalink to this headline"></a></h4>
<p>正态（高斯）分布，继承自 <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 类。</p>
<p><code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 基类调用 <code class="docutils literal notranslate"><span class="pre">Normal</span></code> 中私有接口以实现基类中的公有接口。<code class="docutils literal notranslate"><span class="pre">Normal</span></code> 支持的公有接口为：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code>，<code class="docutils literal notranslate"><span class="pre">mode</span></code>，<code class="docutils literal notranslate"><span class="pre">var</span></code>，<code class="docutils literal notranslate"><span class="pre">sd</span></code>：可选择传入分布的参数均值 <em>mean</em> 和标准差 <em>sd</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entropy</span></code>：可选择传入分布的参数均值 <em>mean</em> 和标准差 <em>sd</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cross_entropy</span></code>，<code class="docutils literal notranslate"><span class="pre">kl_loss</span></code>：必须传入 <em>dist</em> ，<em>mean_b</em> 和 <em>sd_b</em> 。<em>dist</em> 为另一分布的类型的名称，目前只支持此处为 <em>‘Normal’</em> 。<em>mean_b</em> 和 <em>sd_b</em> 为分布 <em>b</em> 的均值和标准差。可选择传入分布的参数 <em>a</em> 均值 <em>mean_a</em> 和标准差 <em>sd_a</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prob</span></code>，<code class="docutils literal notranslate"><span class="pre">log_prob</span></code>，<code class="docutils literal notranslate"><span class="pre">cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">log_cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">survival_function</span></code>，<code class="docutils literal notranslate"><span class="pre">log_survival</span></code>：必须传入 <em>value</em> 。可选择分布的参数包括均值 <em>mean_a</em> 和标准差 <em>sd_a</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample</span></code>：可选择传入样本形状 <em>shape</em> 和分布的参数包括均值 <em>mean_a</em> 和标准差 <em>sd_a</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_args</span></code> ：可选择传入分布的参数均值 <em>mean</em> 和标准差 <em>sd</em> 。返回值为<code class="docutils literal notranslate"><span class="pre">(mean,</span> <span class="pre">sd)</span></code>，类型为tuple。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_type</span></code> ：返回 <em>‘Normal’</em> 。</p></li>
</ul>
</section>
<section id="uniform">
<h4>均匀分布(Uniform)<a class="headerlink" href="#uniform" title="Permalink to this headline"></a></h4>
<p>均匀分布，继承自 <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 类。</p>
<p>属性:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Uniform.low</span></code>：返回分布的最小值，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Uniform.high</span></code>：返回分布的最大值，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 基类调用 <code class="docutils literal notranslate"><span class="pre">Uniform</span></code> 以实现基类中的公有接口。<code class="docutils literal notranslate"><span class="pre">Uniform</span></code> 支持的公有接口为：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code>，<code class="docutils literal notranslate"><span class="pre">mode</span></code>，<code class="docutils literal notranslate"><span class="pre">var</span></code>，<code class="docutils literal notranslate"><span class="pre">sd</span></code>：可选择传入分布的参数最大值 <em>high</em> 和最小值 <em>low</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entropy</span></code>：可选择传入分布的参数最大值 <em>high</em> 和最小值 <em>low</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cross_entropy</span></code>，<code class="docutils literal notranslate"><span class="pre">kl_loss</span></code>：必须传入 <em>dist</em> ，<em>high_b</em> 和 <em>low_b</em> 。<em>dist</em> 为另一分布的类型的名称，目前只支持此处为 <em>‘Uniform’</em> 。 <em>high_b</em> 和 <em>low_b</em> 为分布 <em>b</em> 的参数。可选择传入分布 <em>a</em> 的参数即最大值 <em>high_a</em> 和最小值 <em>low_a</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prob</span></code>，<code class="docutils literal notranslate"><span class="pre">log_prob</span></code>，<code class="docutils literal notranslate"><span class="pre">cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">log_cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">survival_function</span></code>，<code class="docutils literal notranslate"><span class="pre">log_survival</span></code>：必须传入 <em>value</em> 。可选择传入分布的参数最大值 <em>high</em> 和最小值 <em>low</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample</span></code>：可选择传入 <em>shape</em> 和分布的参数即最大值 <em>high</em> 和最小值 <em>low</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_args</span></code> ：可选择传入分布的参数最大值 <em>high</em> 和最小值 <em>low</em> 。返回值为<code class="docutils literal notranslate"><span class="pre">(low,</span> <span class="pre">high)</span></code>，类型为tuple。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_type</span></code> ：返回 <em>‘Uniform’</em> 。</p></li>
</ul>
</section>
<section id="categorical">
<h4>多类别分布（Categorical）<a class="headerlink" href="#categorical" title="Permalink to this headline"></a></h4>
<p>多类别分布，继承自 <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 类。</p>
<p>属性:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Categorical.probs</span></code>：返回各种类别的概率，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 基类调用 <code class="docutils literal notranslate"><span class="pre">Categorical</span></code> 以实现基类中的公有接口。<code class="docutils literal notranslate"><span class="pre">Categorical</span></code> 支持的公有接口为：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code>，<code class="docutils literal notranslate"><span class="pre">mode</span></code>，<code class="docutils literal notranslate"><span class="pre">var</span></code>，<code class="docutils literal notranslate"><span class="pre">sd</span></code>：可选择传入分布的参数类别概率 <em>probs</em>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entropy</span></code>：可选择传入分布的参数类别概率 <em>probs</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cross_entropy</span></code>，<code class="docutils literal notranslate"><span class="pre">kl_loss</span></code>：必须传入 <em>dist</em> ，<em>probs_b</em> 。<em>dist</em> 为另一分布的类型的名称，目前只支持此处为 <em>‘Categorical’</em> 。 <em>probs_b</em> 为分布 <em>b</em> 的参数。可选择传入分布 <em>a</em> 的参数即 <em>probs_a</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prob</span></code>，<code class="docutils literal notranslate"><span class="pre">log_prob</span></code>，<code class="docutils literal notranslate"><span class="pre">cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">log_cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">survival_function</span></code>，<code class="docutils literal notranslate"><span class="pre">log_survival</span></code>：必须传入 <em>value</em> 。可选择传入分布的参数类别概率 <em>probs</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample</span></code>：可选择传入 <em>shape</em> 和类别概率 <em>probs</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_args</span></code> ：可选择传入分布的参数类别概率 <em>probs</em> 。返回值为<code class="docutils literal notranslate"><span class="pre">(probs,)</span></code>，类型为tuple。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_type</span></code> ：返回 <em>‘Categorical’</em> 。</p></li>
</ul>
</section>
<section id="lognormal">
<h4>对数正态分布(LogNormal)<a class="headerlink" href="#lognormal" title="Permalink to this headline"></a></h4>
<p>对数正态分布，继承自 <code class="docutils literal notranslate"><span class="pre">TransformedDistribution</span></code> 类，由 <code class="docutils literal notranslate"><span class="pre">Exp</span></code> Bijector 和 <code class="docutils literal notranslate"><span class="pre">Normal</span></code> Distribution 构成。</p>
<p>属性：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">LogNormal.loc</span></code>：返回分布的位置参数，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LogNormal.scale</span></code>：返回分布的规模参数，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 基类调用 <code class="docutils literal notranslate"><span class="pre">LogNormal</span></code>及 <code class="docutils literal notranslate"><span class="pre">TransformedDistribution</span></code> 中私有接口以实现基类中的公有接口。<code class="docutils literal notranslate"><span class="pre">LogNormal</span></code> 支持的公有接口为：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code>，<code class="docutils literal notranslate"><span class="pre">mode</span></code>，<code class="docutils literal notranslate"><span class="pre">var</span></code>，<code class="docutils literal notranslate"><span class="pre">sd</span></code>：可选择传入分布的位置参数<em>loc</em>和规模参数<em>scale</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entropy</span></code>：可选择传入分布的位置参数 <em>loc</em> 和规模参数 <em>scale</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cross_entropy</span></code>，<code class="docutils literal notranslate"><span class="pre">kl_loss</span></code>：必须传入 <em>dist</em> ，<em>loc_b</em> 和 <em>scale_b</em> 。<em>dist</em> 为另一分布的类型的名称，目前只支持此处为 <em>‘LogNormal’</em> 。<em>loc_b</em> 和 <em>scale_b</em> 为分布 <em>b</em> 的均值和标准差。可选择传入分布的参数 <em>a</em> 均值 <em>loc_a</em> 和标准差 <em>sclae_a</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prob</span></code>，<code class="docutils literal notranslate"><span class="pre">log_prob</span></code>，<code class="docutils literal notranslate"><span class="pre">cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">log_cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">survival_function</span></code>，<code class="docutils literal notranslate"><span class="pre">log_survival</span></code>：必须传入 <em>value</em> 。可选择分布的参数包括均值 <em>loc_a</em> 和标准差 <em>scale_a</em> 。<code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 基类调用 <code class="docutils literal notranslate"><span class="pre">TransformedDistribution</span></code>私有接口。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample</span></code>：可选择传入样本形状 <em>shape</em> 和分布的参数包括均值 <em>loc_a</em> 和标准差 <em>scale_a</em> 。<code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 基类调用 <code class="docutils literal notranslate"><span class="pre">TransformedDistribution</span></code>私有接口。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_args</span></code> ：可选择传入分布的位置参数 <em>loc</em> 和规模参数<em>scale</em> 。返回值为<code class="docutils literal notranslate"><span class="pre">(loc,</span> <span class="pre">scale)</span></code>，类型为tuple。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_type</span></code> ：返回 <em>‘LogNormal’</em> 。</p></li>
</ul>
</section>
<section id="cauchy">
<h4>柯西分布(Cauchy)<a class="headerlink" href="#cauchy" title="Permalink to this headline"></a></h4>
<p>柯西分布，继承自 <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 类。</p>
<p>属性：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Cauchy.loc</span></code>：返回分布的位置参数，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Cauchy.scale</span></code>：返回分布的规模参数，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 基类调用 <code class="docutils literal notranslate"><span class="pre">Cauchy</span></code> 中私有接口以实现基类中的公有接口。<code class="docutils literal notranslate"><span class="pre">Cauchy</span></code> 支持的公有接口为：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">entropy</span></code>：可选择传入分布的位置参数<em>loc</em>和规模参数<em>scale</em>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cross_entropy</span></code>，<code class="docutils literal notranslate"><span class="pre">kl_loss</span></code>：必须传入 <em>dist</em> ，<em>loc_b</em> 和 <em>scale_b</em> 。<em>dist</em> 为另一分布的类型的名称，目前只支持此处为 <em>‘Cauchy’</em> 。<em>loc_b</em> 和 <em>scale_b</em> 为分布 <em>b</em> 的位置参数和规模参数。可选择传入分布的参数 <em>a</em> 位置 <em>loc_a</em> 和规模 <em>scale_a</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prob</span></code>，<code class="docutils literal notranslate"><span class="pre">log_prob</span></code>，<code class="docutils literal notranslate"><span class="pre">cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">log_cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">survival_function</span></code>，<code class="docutils literal notranslate"><span class="pre">log_survival</span></code>：必须传入 <em>value</em> 。可选择传入分布的位置参数 <em>loc</em> 和规模参数 <em>scale</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample</span></code>：可选择传入样本形状 <em>shape</em> 和分布的参数包括分布的位置参数 <em>loc</em> 和规模参数 <em>scale</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_args</span></code> ：可选择传入分布的位置参数 <em>loc</em> 和规模参数 <em>scale</em> 。返回值为<code class="docutils literal notranslate"><span class="pre">(loc,</span> <span class="pre">scale)</span></code>，类型为tuple。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_type</span></code> ：返回 <em>‘Cauchy’</em> 。</p></li>
</ul>
</section>
<section id="gumbel">
<h4>耿贝尔极值分布(Gumbel)<a class="headerlink" href="#gumbel" title="Permalink to this headline"></a></h4>
<p>耿贝尔极值分布，继承自 <code class="docutils literal notranslate"><span class="pre">TransformedDistribution</span></code> 类，由 <code class="docutils literal notranslate"><span class="pre">GumbelCDF</span></code> Bijector和 <code class="docutils literal notranslate"><span class="pre">Uniform</span></code> Distribution 构成。</p>
<p>属性：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Gumbel.loc</span></code>：返回分布的位置参数，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Gumbel.scale</span></code>：返回分布的规模参数，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 基类调用 <code class="docutils literal notranslate"><span class="pre">Gumbel</span></code> 中私有接口以实现基类中的公有接口。<code class="docutils literal notranslate"><span class="pre">Gumbel</span></code> 支持的公有接口为：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code>，<code class="docutils literal notranslate"><span class="pre">mode</span></code>，<code class="docutils literal notranslate"><span class="pre">var</span></code>，<code class="docutils literal notranslate"><span class="pre">sd</span></code>：无参数 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entropy</span></code>：无参数 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cross_entropy</span></code>，<code class="docutils literal notranslate"><span class="pre">kl_loss</span></code>：必须传入 <em>dist</em> ，<em>loc_b</em> 和 <em>scale_b</em> 。<em>dist</em> 为另一分布的类型的名称，目前只支持此处为 <em>‘Gumbel’</em> 。<em>loc_b</em> 和 <em>scale_b</em> 为分布 <em>b</em> 的位置参数和规模参数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prob</span></code>，<code class="docutils literal notranslate"><span class="pre">log_prob</span></code>，<code class="docutils literal notranslate"><span class="pre">cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">log_cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">survival_function</span></code>，<code class="docutils literal notranslate"><span class="pre">log_survival</span></code>：必须传入 <em>value</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample</span></code>：可选择传入样本形状 <em>shape</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_args</span></code> ：可选择传入分布的位置参数 <em>loc</em> 和规模参数 <em>scale</em> 。返回值为<code class="docutils literal notranslate"><span class="pre">(loc,</span> <span class="pre">scale)</span></code>，类型为tuple。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_type</span></code> ：返回 <em>‘Gumbel’</em> 。</p></li>
</ul>
</section>
<section id="logistic">
<h4>逻辑斯谛分布(Logistic)<a class="headerlink" href="#logistic" title="Permalink to this headline"></a></h4>
<p>逻辑斯谛分布，继承自 <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 类。</p>
<p>属性：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Logistic.loc</span></code>：返回分布的位置参数，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Logistic.scale</span></code>：返回分布的规模参数，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 基类调用 <code class="docutils literal notranslate"><span class="pre">Logistic</span></code> 中私有接口以实现基类中的公有接口。<code class="docutils literal notranslate"><span class="pre">Logistic</span></code> 支持的公有接口为：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code>，<code class="docutils literal notranslate"><span class="pre">mode</span></code>，<code class="docutils literal notranslate"><span class="pre">var</span></code>，<code class="docutils literal notranslate"><span class="pre">sd</span></code>：可选择传入分布的位置参数 <em>loc</em> 和规模参数 <em>scale</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entropy</span></code>：可选择传入分布的位置参数 <em>loc</em> 和规模参数 <em>scale</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prob</span></code>，<code class="docutils literal notranslate"><span class="pre">log_prob</span></code>，<code class="docutils literal notranslate"><span class="pre">cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">log_cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">survival_function</span></code>，<code class="docutils literal notranslate"><span class="pre">log_survival</span></code>：必须传入 <em>value</em> 。可选择传入分布的位置参数 <em>loc</em> 和规模参数 <em>scale</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample</span></code>：可选择传入样本形状 <em>shape</em> 和分布的参数包括分布的位置参数 <em>loc</em> 和规模参数 <em>scale</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_args</span></code> ：可选择传入分布的位置参数 <em>loc</em> 和规模参数 <em>scale</em> 。返回值为<code class="docutils literal notranslate"><span class="pre">(loc,</span> <span class="pre">scale)</span></code>，类型为tuple。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_type</span></code> ：返回 <em>‘Logistic’</em> 。</p></li>
</ul>
</section>
<section id="poisson">
<h4>泊松分布(Poisson)<a class="headerlink" href="#poisson" title="Permalink to this headline"></a></h4>
<p>泊松分布，继承自 <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 类。</p>
<p>属性：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Poisson.rate</span></code>：返回分布的率参数，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 基类调用 <code class="docutils literal notranslate"><span class="pre">Poisson</span></code> 中私有接口以实现基类中的公有接口。<code class="docutils literal notranslate"><span class="pre">Poisson</span></code> 支持的公有接口为：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code>，<code class="docutils literal notranslate"><span class="pre">mode</span></code>，<code class="docutils literal notranslate"><span class="pre">var</span></code>，<code class="docutils literal notranslate"><span class="pre">sd</span></code>：可选择传入分布的率参数 <em>rate</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prob</span></code>，<code class="docutils literal notranslate"><span class="pre">log_prob</span></code>，<code class="docutils literal notranslate"><span class="pre">cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">log_cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">survival_function</span></code>，<code class="docutils literal notranslate"><span class="pre">log_survival</span></code>：必须传入 <em>value</em> 。可选择传入分布的率参数 <em>rate</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample</span></code>：可选择传入样本形状 <em>shape</em> 和分布的率参数 <em>rate</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_args</span></code> ：可选择传入分布的率参数 <em>rate</em> 。返回值为<code class="docutils literal notranslate"><span class="pre">(rate,)</span></code>，类型为tuple。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_type</span></code> ：返回 <em>‘Poisson’</em> 。</p></li>
</ul>
</section>
<section id="gamma">
<h4>伽马分布(Gamma)<a class="headerlink" href="#gamma" title="Permalink to this headline"></a></h4>
<p>伽马分布，继承自 <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 类。</p>
<p>属性：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Gamma.concentration</span></code>：返回分布的参数 <code class="docutils literal notranslate"><span class="pre">concentration</span></code> ，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Gamma.rate</span></code>：返回分布的参数 <code class="docutils literal notranslate"><span class="pre">rate</span></code> ，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 基类调用 <code class="docutils literal notranslate"><span class="pre">Gamma</span></code> 中私有接口以实现基类中的公有接口。<code class="docutils literal notranslate"><span class="pre">Gamma</span></code> 支持的公有接口为：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code>，<code class="docutils literal notranslate"><span class="pre">mode</span></code>，<code class="docutils literal notranslate"><span class="pre">sd</span></code>，<code class="docutils literal notranslate"><span class="pre">var</span></code>：可选择传入分布的参数 <em>concentration</em> 和参数 <em>rate</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entropy</span></code>：可选择传入分布的参数 <em>concentration</em> 和参数 <em>rate</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prob</span></code>，<code class="docutils literal notranslate"><span class="pre">log_prob</span></code>，<code class="docutils literal notranslate"><span class="pre">cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">log_cdf</span></code>，<code class="docutils literal notranslate"><span class="pre">survival_function</span></code>，<code class="docutils literal notranslate"><span class="pre">log_survival</span></code>：必须传入 <em>value</em> 。可选择传入分布的参数 <em>concentration</em> 和参数 <em>rate</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cross_entropy</span></code>，<code class="docutils literal notranslate"><span class="pre">kl_loss</span></code>：必须传入 <em>dist</em> ，<em>concentration_b</em> 和 <em>rate_b</em> 。<em>dist</em> 为另一分布的类型的名称，目前只支持此处为 <em>‘Gamma’</em> 。<em>concentration_b</em> 和 <em>rate_b</em> 为分布 <em>b</em> 的参数。可选择传入分布 <em>a</em> 的参数即 <em>concentration_a</em> 和 <em>rate_a</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample</span></code>：可选择传入样本形状 <em>shape</em> 和分布的参数包括分布的参数 <em>concentration</em> 和参数 <em>rate</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_args</span></code> ：可选择传入分布的参数 <em>concentration</em> 和参数 <em>rate</em> 。返回值为<code class="docutils literal notranslate"><span class="pre">(concentration,</span> <span class="pre">rate)</span></code>，类型为tuple。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_type</span></code> ：返回 <em>‘Gamma’</em> 。</p></li>
</ul>
</section>
<section id="beta">
<h4>贝塔分布(Beta)<a class="headerlink" href="#beta" title="Permalink to this headline"></a></h4>
<p>贝塔分布，继承自 <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 类。</p>
<p>属性：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Beta.concentration1</span></code>：返回分布的参数 <code class="docutils literal notranslate"><span class="pre">concentration1</span></code> ，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Beta.concentration0</span></code>：返回分布的参数 <code class="docutils literal notranslate"><span class="pre">concentration0</span></code> ，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 基类调用 <code class="docutils literal notranslate"><span class="pre">Beta</span></code> 中私有接口以实现基类中的公有接口。<code class="docutils literal notranslate"><span class="pre">Beta</span></code> 支持的公有接口为：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code>，<code class="docutils literal notranslate"><span class="pre">mode</span></code>，<code class="docutils literal notranslate"><span class="pre">sd</span></code>，<code class="docutils literal notranslate"><span class="pre">var</span></code>：可选择传入分布的参数 <em>concentration1</em> 和参数 <em>concentration0</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entropy</span></code>：可选择传入分布的参数 <em>concentration1</em> 和参数 <em>concentration0</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prob</span></code>，<code class="docutils literal notranslate"><span class="pre">log_prob</span></code>：必须传入 <em>value</em> 。可选择传入分布的参数 <em>concentration1</em> 和参数 <em>concentration0</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cross_entropy</span></code>，<code class="docutils literal notranslate"><span class="pre">kl_loss</span></code>：必须传入 <em>dist</em> ，<em>concentration1_b</em> 和 <em>concentration1_b</em> 。<em>dist</em> 为另一分布的类型的名称，目前只支持此处为 <em>‘Beta’</em> 。<em>concentration1_b</em> 和 <em>concentration1_b</em> 为分布 <em>b</em> 的参数。可选择传入分布 <em>a</em> 的参数即 <em>concentration1_a</em> 和 <em>concentration0_a</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample</span></code>：可选择传入样本形状 <em>shape</em> 和分布的参数包括分布的位置参数 <em>loc</em> 和规模参数 <em>scale</em> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_args</span></code> ：可选择传入分布的参数 <em>concentration1</em> 和参数 <em>concentration0</em> 。返回值为<code class="docutils literal notranslate"><span class="pre">(concentration1,</span> <span class="pre">concentration0)</span></code>，类型为tuple。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_dist_type</span></code> ：返回 <em>‘Beta’</em> 。</p></li>
</ul>
</section>
</section>
<section id="pynative">
<h3>概率分布类在PyNative模式下的应用<a class="headerlink" href="#pynative" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 子类可在 <strong>PyNative</strong> 模式下使用。</p>
<p>以 <code class="docutils literal notranslate"><span class="pre">Normal</span></code> 为例， 创建一个均值为0.0、标准差为1.0的正态分布，然后计算相关函数。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">import</span> <span class="nn">mindspore.context</span> <span class="k">as</span> <span class="nn">context</span>
<span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>

<span class="n">my_normal</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">mean</span> <span class="o">=</span> <span class="n">my_normal</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">var</span> <span class="o">=</span> <span class="n">my_normal</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
<span class="n">entropy</span> <span class="o">=</span> <span class="n">my_normal</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>

<span class="n">value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">prob</span> <span class="o">=</span> <span class="n">my_normal</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
<span class="n">cdf</span> <span class="o">=</span> <span class="n">my_normal</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

<span class="n">mean_b</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">sd_b</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">kl</span> <span class="o">=</span> <span class="n">my_normal</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s1">&#39;Normal&#39;</span><span class="p">,</span> <span class="n">mean_b</span><span class="p">,</span> <span class="n">sd_b</span><span class="p">)</span>

<span class="c1"># get the distribution args as a tuple</span>
<span class="n">dist_arg</span> <span class="o">=</span> <span class="n">my_normal</span><span class="o">.</span><span class="n">get_dist_args</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mean: &quot;</span><span class="p">,</span> <span class="n">mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;var: &quot;</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;entropy: &quot;</span><span class="p">,</span> <span class="n">entropy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;prob: &quot;</span><span class="p">,</span> <span class="n">prob</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cdf: &quot;</span><span class="p">,</span> <span class="n">cdf</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;kl: &quot;</span><span class="p">,</span> <span class="n">kl</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dist_arg: &quot;</span><span class="p">,</span> <span class="n">dist_arg</span><span class="p">)</span>
</pre></div>
</div>
<p>输出为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>mean:  0.0
var:  1.0
entropy:  1.4189385
prob:  [0.35206532 0.3989423  0.35206532]
cdf:  [0.30853754 0.5        0.69146246]
kl:  0.44314718
dist_arg: (Tensor(shape=[], dtype=Float32, value= 0), Tensor(shape=[], dtype=Float32, value= 1))
</pre></div>
</div>
</section>
<section id="id4">
<h3>概率分布类在图模式下的应用<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h3>
<p>在图模式下，<code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 子类可用在网络中。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">import</span> <span class="nn">mindspore.context</span> <span class="k">as</span> <span class="nn">context</span>
<span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normal</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">sd</span><span class="p">):</span>
        <span class="n">pdf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normal</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="n">kl</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normal</span><span class="o">.</span><span class="n">kl_loss</span><span class="p">(</span><span class="s2">&quot;Normal&quot;</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">sd</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pdf</span><span class="p">,</span> <span class="n">kl</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">sd</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">pdf</span><span class="p">,</span> <span class="n">kl</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">sd</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pdf: &quot;</span><span class="p">,</span> <span class="n">pdf</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;kl: &quot;</span><span class="p">,</span> <span class="n">kl</span><span class="p">)</span>
</pre></div>
</div>
<p>输出为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>pdf:  [0.35206532 0.3989423  0.35206532]
kl:  0.5
</pre></div>
</div>
</section>
<section id="transformeddistribution">
<h3>TransformedDistribution类接口设计<a class="headerlink" href="#transformeddistribution" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">TransformedDistribution</span></code> 继承自 <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> ，是可通过映射f(x)变化得到的数学分布的基类。其接口包括：</p>
<ol class="arabic simple">
<li><p>属性</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">bijector</span></code>：返回分布的变换方法。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">distribution</span></code>：返回原始分布。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">is_linear_transformation</span></code>：返回线性变换标志。</p></li>
</ul>
</li>
<li><p>接口函数（以下接口函数的参数与构造函数中 <code class="docutils literal notranslate"><span class="pre">distribution</span></code> 的对应接口的参数相同）。</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cdf</span></code>：累积分布函数（CDF）。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">log_cdf</span></code>：对数累积分布函数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">survival_function</span></code>：生存函数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">log_survival</span></code>：对数生存函数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prob</span></code>：概率密度函数（PDF）/ 概率质量函数（PMF）。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">log_prob</span></code>：对数似然函数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sample</span></code>：随机取样。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code>：无参数。只有当 <code class="docutils literal notranslate"><span class="pre">Bijector.is_constant_jacobian=true</span></code> 时可调用。</p></li>
</ul>
</li>
</ol>
</section>
<section id="pynativetransformeddistribution">
<h3>PyNative模式下调用TransformedDistribution实例<a class="headerlink" href="#pynativetransformeddistribution" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">TransformedDistribution</span></code> 子类可在 <strong>PyNative</strong> 模式下使用。</p>
<p>这里构造一个 <code class="docutils literal notranslate"><span class="pre">TransformedDistribution</span></code> 实例，使用 <code class="docutils literal notranslate"><span class="pre">Normal</span></code> 分布作为需要变换的分布类，使用 <code class="docutils literal notranslate"><span class="pre">Exp</span></code> 作为映射变换，可以生成 <code class="docutils literal notranslate"><span class="pre">LogNormal</span></code> 分布。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.nn.probability.bijector</span> <span class="k">as</span> <span class="nn">msb</span>
<span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="kn">import</span> <span class="nn">mindspore.context</span> <span class="k">as</span> <span class="nn">context</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">dtype</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>

<span class="n">normal</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">exp</span> <span class="o">=</span> <span class="n">msb</span><span class="o">.</span><span class="n">Exp</span><span class="p">()</span>
<span class="n">LogNormal</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">TransformedDistribution</span><span class="p">(</span><span class="n">exp</span><span class="p">,</span> <span class="n">normal</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;LogNormal&quot;</span><span class="p">)</span>

<span class="c1"># compute cumulative distribution function</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">tx</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">cdf</span> <span class="o">=</span> <span class="n">LogNormal</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>

<span class="c1"># generate samples from the distribution</span>
<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">LogNormal</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># get information of the distribution</span>
<span class="nb">print</span><span class="p">(</span><span class="n">LogNormal</span><span class="p">)</span>
<span class="c1"># get information of the underlying distribution and the bijector separately</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;underlying distribution:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">LogNormal</span><span class="o">.</span><span class="n">distribution</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;bijector:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">LogNormal</span><span class="o">.</span><span class="n">bijector</span><span class="p">)</span>
<span class="c1"># get the computation results</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cdf:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">cdf</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sample shape:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">sample</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>输出为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>TransformedDistribution&lt;
  (_bijector): Exp&lt;exp&gt;
  (_distribution): Normal&lt;mean = 0.0, standard deviation = 1.0&gt;
  &gt;
underlying distribution:
 Normal&lt;mean = 0.0, standard deviation = 1.0&gt;
bijector:
 Exp&lt;exp&gt;
cdf:
 [0.7558914 0.9462397 0.9893489]
sample shape:
(3, 2)
</pre></div>
</div>
<p>当构造 <code class="docutils literal notranslate"><span class="pre">TransformedDistribution</span></code> 映射变换的 <code class="docutils literal notranslate"><span class="pre">is_constant_jacobian</span> <span class="pre">=</span> <span class="pre">true</span></code> 时（如 <code class="docutils literal notranslate"><span class="pre">ScalarAffine</span></code>)，构造的 <code class="docutils literal notranslate"><span class="pre">TransformedDistribution</span></code> 实例可以使用直接使用 <code class="docutils literal notranslate"><span class="pre">mean</span></code> 接口计算均值，例如：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">normal</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">scalaraffine</span> <span class="o">=</span> <span class="n">msb</span><span class="o">.</span><span class="n">ScalarAffine</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span>
<span class="n">trans_dist</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">TransformedDistribution</span><span class="p">(</span><span class="n">scalaraffine</span><span class="p">,</span> <span class="n">normal</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">trans_dist</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span>
</pre></div>
</div>
<p>输出为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>2.0
</pre></div>
</div>
</section>
<section id="id5">
<h3>图模式下调用TransformedDistribution实例<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h3>
<p>在图模式下，<code class="docutils literal notranslate"><span class="pre">TransformedDistribution</span></code> 类可用在网络中。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">dtype</span>
<span class="kn">import</span> <span class="nn">mindspore.context</span> <span class="k">as</span> <span class="nn">context</span>
<span class="kn">import</span> <span class="nn">mindspore.nn.probability.bijector</span> <span class="k">as</span> <span class="nn">msb</span>
<span class="kn">import</span> <span class="nn">mindspore.nn.probability.distribution</span> <span class="k">as</span> <span class="nn">msd</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;transformed_distribution&#39;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># create TransformedDistribution distribution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exp</span> <span class="o">=</span> <span class="n">msb</span><span class="o">.</span><span class="n">Exp</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normal</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lognormal</span> <span class="o">=</span> <span class="n">msd</span><span class="o">.</span><span class="n">TransformedDistribution</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">exp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">normal</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">cdf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lognormal</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lognormal</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cdf</span><span class="p">,</span> <span class="n">sample</span>

<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;LogNormal&quot;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">tx</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">cdf</span><span class="p">,</span> <span class="n">sample</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cdf: &quot;</span><span class="p">,</span> <span class="n">cdf</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sample shape: &quot;</span><span class="p">,</span> <span class="n">sample</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>输出为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>cdf:  [0.7558914  0.86403143 0.9171715  0.9462397 ]
sample shape:  (2, 3)
</pre></div>
</div>
</section>
</section>
<section id="id6">
<h2>概率分布映射<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h2>
<p>Bijector（<code class="docutils literal notranslate"><span class="pre">mindspore.nn.probability.bijector</span></code>）是概率编程的基本组成部分。Bijector描述了一种随机变量的变换方法，可以通过一个已有的随机变量X和一个映射函数f生成一个新的随机变量<span class="math notranslate nohighlight">\(Y = f(x)\)</span>。
<code class="docutils literal notranslate"><span class="pre">Bijector</span></code> 提供了映射相关的四种变换方法。它可以当做算子直接使用，也可以作用在某个随机变量 <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 类实例上生成新的随机变量的 <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 类实例。</p>
<section id="bijector">
<h3>Bijector类接口设计<a class="headerlink" href="#bijector" title="Permalink to this headline"></a></h3>
<section id="id7">
<h4>Bijector基类<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h4>
<p><code class="docutils literal notranslate"><span class="pre">Bijector</span></code> 类是所有概率分布映射的基类。其接口包括：</p>
<ol class="arabic simple">
<li><p>属性</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>：返回 <code class="docutils literal notranslate"><span class="pre">name</span></code> 的值。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dtype</span></code>：返回 <code class="docutils literal notranslate"><span class="pre">dtype</span></code> 的值。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">parameters</span></code>：返回 <code class="docutils literal notranslate"><span class="pre">parameter</span></code> 的值。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">is_constant_jacobian</span></code>：返回 <code class="docutils literal notranslate"><span class="pre">is_constant_jacobian</span></code> 的值。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">is_injective</span></code>：返回 <code class="docutils literal notranslate"><span class="pre">is_injective</span></code> 的值。</p></li>
</ul>
</li>
<li><p>映射函数</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">forward</span></code>：正向映射，创建派生类后由派生类的 <code class="docutils literal notranslate"><span class="pre">_forward</span></code> 决定参数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse</span></code>：反向映射，创建派生类后由派生类的 <code class="docutils literal notranslate"><span class="pre">_inverse</span></code> 决定参数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">forward_log_jacobian</span></code>：正向映射的导数的对数，创建派生类后由派生类的 <code class="docutils literal notranslate"><span class="pre">_forward_log_jacobian</span></code> 决定参数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse_log_jacobian</span></code>：反向映射的导数的对数，创建派生类后由派生类的 <code class="docutils literal notranslate"><span class="pre">_inverse_log_jacobian</span></code> 决定参数。</p></li>
</ul>
</li>
</ol>
<p><code class="docutils literal notranslate"><span class="pre">Bijector</span></code> 作为函数调用：输入是一个 <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> 类：生成一个 <code class="docutils literal notranslate"><span class="pre">TransformedDistribution</span></code> <strong>（不可在图内调用）</strong>。</p>
</section>
<section id="powertransform">
<h4>幂函数变换映射(PowerTransform)<a class="headerlink" href="#powertransform" title="Permalink to this headline"></a></h4>
<p><code class="docutils literal notranslate"><span class="pre">PowerTransform</span></code> 做如下变量替换：<code class="docutils literal notranslate"><span class="pre">Y</span> <span class="pre">=</span> <span class="pre">g(X)</span> <span class="pre">=</span> <span class="pre">{(1</span> <span class="pre">+</span> <span class="pre">X</span> <span class="pre">*</span> <span class="pre">power)}^{1</span> <span class="pre">/</span> <span class="pre">power}</span></code>。其接口包括：</p>
<ol class="arabic simple">
<li><p>属性</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">power</span></code>：返回 <code class="docutils literal notranslate"><span class="pre">power</span></code> 的值，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
</ul>
</li>
<li><p>映射函数</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">forward</span></code>：正向映射，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse</span></code>：反向映射，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">forward_log_jacobian</span></code>：正向映射的导数的对数，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse_log_jacobian</span></code>：反向映射的导数的对数，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
</ul>
</li>
</ol>
</section>
<section id="exp">
<h4>指数变换映射(Exp)<a class="headerlink" href="#exp" title="Permalink to this headline"></a></h4>
<p><code class="docutils literal notranslate"><span class="pre">Exp</span></code> 做如下变量替换：<code class="docutils literal notranslate"><span class="pre">Y</span> <span class="pre">=</span> <span class="pre">g(X)=</span> <span class="pre">exp(X)</span></code>。其接口包括：</p>
<p>映射函数</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">forward</span></code>：正向映射，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse</span></code>：反向映射，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">forward_log_jacobian</span></code>：正向映射的导数的对数，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse_log_jacobian</span></code>：反向映射的导数的对数，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
</ul>
</section>
<section id="scalaraffine">
<h4>标量仿射变换映射(ScalarAffine)<a class="headerlink" href="#scalaraffine" title="Permalink to this headline"></a></h4>
<p><code class="docutils literal notranslate"><span class="pre">ScalarAffine</span></code> 做如下变量替换：<code class="docutils literal notranslate"><span class="pre">Y</span> <span class="pre">=</span> <span class="pre">g(X)</span> <span class="pre">=</span> <span class="pre">scale</span> <span class="pre">*</span> <span class="pre">X</span> <span class="pre">+</span> <span class="pre">shift</span></code>。其接口包括：</p>
<ol class="arabic simple">
<li><p>属性</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">scale</span></code>：返回<code class="docutils literal notranslate"><span class="pre">scale</span></code>的值，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">shift</span></code>：返回<code class="docutils literal notranslate"><span class="pre">shift</span></code>的值，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
</ul>
</li>
<li><p>映射函数</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">forward</span></code>：正向映射，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse</span></code>：反向映射，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">forward_log_jacobian</span></code>：正向映射的导数的对数，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse_log_jacobian</span></code>：反向映射的导数的对数，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
</ul>
</li>
</ol>
</section>
<section id="softplus-softplus">
<h4>Softplus变换映射(Softplus)<a class="headerlink" href="#softplus-softplus" title="Permalink to this headline"></a></h4>
<p><code class="docutils literal notranslate"><span class="pre">Softplus</span></code> 做如下变量替换：<code class="docutils literal notranslate"><span class="pre">Y</span> <span class="pre">=</span> <span class="pre">g(X)</span> <span class="pre">=</span> <span class="pre">log(1</span> <span class="pre">+</span> <span class="pre">e</span> <span class="pre">^</span> <span class="pre">{sharpness</span> <span class="pre">*</span> <span class="pre">X})</span> <span class="pre">/</span> <span class="pre">sharpness</span></code>。其接口包括：</p>
<ol class="arabic simple">
<li><p>属性</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sharpness</span></code>：返回 <code class="docutils literal notranslate"><span class="pre">sharpness</span></code> 的值，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
</ul>
</li>
<li><p>映射函数</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">forward</span></code>：正向映射，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse</span></code>：反向映射，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">forward_log_jacobian</span></code>：正向映射的导数的对数，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse_log_jacobian</span></code>：反向映射的导数的对数，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
</ul>
</li>
</ol>
</section>
<section id="gumbelcdf">
<h4>耿贝尔累计密度函数映射(GumbelCDF)<a class="headerlink" href="#gumbelcdf" title="Permalink to this headline"></a></h4>
<p><code class="docutils literal notranslate"><span class="pre">GumbelCDF</span></code> 做如下变量替换：<span class="math notranslate nohighlight">\(Y = g(X) = \exp(-\exp(-\frac{X - loc}{scale}))\)</span>。其接口包括：</p>
<ol class="arabic simple">
<li><p>属性</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">loc</span></code>：返回<code class="docutils literal notranslate"><span class="pre">loc</span></code>的值，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scale</span></code>：返回<code class="docutils literal notranslate"><span class="pre">scale</span></code>的值，类型为<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p></li>
</ul>
</li>
<li><p>映射函数</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">forward</span></code>：正向映射，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse</span></code>：反向映射，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">forward_log_jacobian</span></code>：正向映射的导数的对数，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse_log_jacobian</span></code>：反向映射的导数的对数，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
</ul>
</li>
</ol>
</section>
<section id="invert">
<h4>逆映射(Invert)<a class="headerlink" href="#invert" title="Permalink to this headline"></a></h4>
<p><code class="docutils literal notranslate"><span class="pre">Invert</span></code> 对一个映射做逆变换，其接口包括：</p>
<ol class="arabic simple">
<li><p>属性</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">bijector</span></code>：返回初始化时使用的<em>Bijector</em>，类型为<code class="docutils literal notranslate"><span class="pre">Bijector</span></code>。</p></li>
</ul>
</li>
<li><p>映射函数</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">forward</span></code>：正向映射，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse</span></code>：反向映射，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">forward_log_jacobian</span></code>：正向映射的导数的对数，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse_log_jacobian</span></code>：反向映射的导数的对数，输入为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 。</p></li>
</ul>
</li>
</ol>
</section>
</section>
<section id="pynativebijector">
<h3>PyNative模式下调用Bijector实例<a class="headerlink" href="#pynativebijector" title="Permalink to this headline"></a></h3>
<p>在执行之前，我们需要导入需要的库文件包。双射类最主要的库是 <code class="docutils literal notranslate"><span class="pre">mindspore.nn.probability.bijector</span></code>，导入后我们使用 <code class="docutils literal notranslate"><span class="pre">msb</span></code> 作为库的缩写并进行调用。</p>
<p>下面我们以 <code class="docutils literal notranslate"><span class="pre">PowerTransform</span></code> 为例。创建一个指数为2的 <code class="docutils literal notranslate"><span class="pre">PowerTransform</span></code> 对象。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.nn.probability.bijector</span> <span class="k">as</span> <span class="nn">msb</span>
<span class="kn">import</span> <span class="nn">mindspore.context</span> <span class="k">as</span> <span class="nn">context</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">dtype</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>

<span class="n">powertransform</span> <span class="o">=</span> <span class="n">msb</span><span class="o">.</span><span class="n">PowerTransform</span><span class="p">(</span><span class="n">power</span><span class="o">=</span><span class="mf">2.</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">tx</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">forward</span> <span class="o">=</span> <span class="n">powertransform</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
<span class="n">inverse</span> <span class="o">=</span> <span class="n">powertransform</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
<span class="n">forward_log_jaco</span> <span class="o">=</span> <span class="n">powertransform</span><span class="o">.</span><span class="n">forward_log_jacobian</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
<span class="n">inverse_log_jaco</span> <span class="o">=</span> <span class="n">powertransform</span><span class="o">.</span><span class="n">inverse_log_jacobian</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">powertransform</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;forward: &quot;</span><span class="p">,</span> <span class="n">forward</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;inverse: &quot;</span><span class="p">,</span> <span class="n">inverse</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;forward_log_jacobian: &quot;</span><span class="p">,</span> <span class="n">forward_log_jaco</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;inverse_log_jacobian: &quot;</span><span class="p">,</span> <span class="n">inverse_log_jaco</span><span class="p">)</span>
</pre></div>
</div>
<p>输出：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>PowerTransform&lt;power = 2.0&gt;
forward:  [2.236068  2.6457515 3.        3.3166249]
inverse:  [ 1.5       4.        7.5      12.000001]
forward_log_jacobian:  [-0.804719  -0.9729551 -1.0986123 -1.1989477]
inverse_log_jacobian:  [0.6931472 1.0986123 1.3862944 1.609438 ]
</pre></div>
</div>
</section>
<section id="id8">
<h3>图模式下调用Bijector实例<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h3>
<p>在图模式下，<code class="docutils literal notranslate"><span class="pre">Bijector</span></code> 子类可用在网络中。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">import</span> <span class="nn">mindspore.context</span> <span class="k">as</span> <span class="nn">context</span>
<span class="kn">import</span> <span class="nn">mindspore.nn.probability.bijector</span> <span class="k">as</span> <span class="nn">msb</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># create a PowerTransform bijector</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">powertransform</span> <span class="o">=</span> <span class="n">msb</span><span class="o">.</span><span class="n">PowerTransform</span><span class="p">(</span><span class="n">power</span><span class="o">=</span><span class="mf">2.</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">forward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">powertransform</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="n">inverse</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">powertransform</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="n">forward_log_jaco</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">powertransform</span><span class="o">.</span><span class="n">forward_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="n">inverse_log_jaco</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">powertransform</span><span class="o">.</span><span class="n">inverse_log_jacobian</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">forward</span><span class="p">,</span> <span class="n">inverse</span><span class="p">,</span> <span class="n">forward_log_jaco</span><span class="p">,</span> <span class="n">inverse_log_jaco</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">tx</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">forward</span><span class="p">,</span> <span class="n">inverse</span><span class="p">,</span> <span class="n">forward_log_jaco</span><span class="p">,</span> <span class="n">inverse_log_jaco</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;forward: &quot;</span><span class="p">,</span> <span class="n">forward</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;inverse: &quot;</span><span class="p">,</span> <span class="n">inverse</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;forward_log_jacobian: &quot;</span><span class="p">,</span> <span class="n">forward_log_jaco</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;inverse_log_jacobian: &quot;</span><span class="p">,</span> <span class="n">inverse_log_jaco</span><span class="p">)</span>
</pre></div>
</div>
<p>输出为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>forward:  [2.236068  2.6457515 3.        3.3166249]
inverse:  [ 1.5       4.        7.5      12.000001]
forward_log_jacobian:  [-0.804719  -0.9729551 -1.0986123 -1.1989477]
inverse_log_jacobian:  [0.6931472 1.0986123 1.3862944 1.609438 ]
</pre></div>
</div>
</section>
</section>
<section id="id9">
<h2>深度概率网络<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h2>
<p>使用MindSpore深度概率编程库（<code class="docutils literal notranslate"><span class="pre">mindspore.nn.probability.dpn</span></code>）来构造变分自编码器（VAE）进行推理尤为简单。我们只需要自定义编码器和解码器（DNN模型），调用VAE或CVAE接口形成其派生网络，然后调用ELBO接口进行优化，最后使用SVI接口进行变分推理。这样做的好处是，不熟悉变分推理的用户可以像构建DNN模型一样来构建概率模型，而熟悉的用户可以调用这些接口来构建更为复杂的概率模型。VAE的接口在<code class="docutils literal notranslate"><span class="pre">mindspore.nn.probability.dpn</span></code>下面，dpn代表的是Deep probabilistic network，这里提供了一些基本的深度概率网络的接口，例如VAE。</p>
<section id="vae">
<h3>VAE<a class="headerlink" href="#vae" title="Permalink to this headline"></a></h3>
<p>首先，我们需要先自定义encoder和decoder，调用<code class="docutils literal notranslate"><span class="pre">mindspore.nn.probability.dpn.VAE</span></code>接口来构建VAE网络，我们除了传入encoder和decoder之外，还需要传入encoder输出变量的维度hidden size，以及VAE网络存储潜在变量的维度latent size，一般latent size会小于hidden size。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore.nn.probability.dpn</span> <span class="kn">import</span> <span class="n">VAE</span>

<span class="n">IMAGE_SHAPE</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">800</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">800</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Reshape</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">IMAGE_SHAPE</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span>


<span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">()</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">()</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">VAE</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">latent_size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="conditionalvae">
<h3>ConditionalVAE<a class="headerlink" href="#conditionalvae" title="Permalink to this headline"></a></h3>
<p>类似地，ConditionalVAE与VAE的使用方法比较相近，不同的是，ConditionalVAE利用了数据集的标签信息，属于有监督学习算法，其生成效果一般会比VAE好。</p>
<p>首先，先自定义encoder和decoder，并调用<code class="docutils literal notranslate"><span class="pre">mindspore.nn.probability.dpn.ConditionalVAE</span></code>接口来构建ConditionalVAE网络，这里的encoder和VAE的不同，因为需要传入数据集的标签信息；decoder和上述的一样。ConditionalVAE接口的传入则还需要传入数据集的标签类别个数，其余和VAE接口一样。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore.nn.probability.dpn</span> <span class="kn">import</span> <span class="n">ConditionalVAE</span>

<span class="n">IMAGE_SHAPE</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1024</span> <span class="o">+</span> <span class="n">num_classes</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">concat</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Concat</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">one_hot</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">OneHot</span><span class="p">(</span><span class="n">depth</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">input_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="n">input_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
        <span class="n">input_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">input_x</span>


<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Reshape</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">IMAGE_SHAPE</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span>


<span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">()</span>
<span class="n">cvae</span> <span class="o">=</span> <span class="n">ConditionalVAE</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">latent_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>加载数据集，我们可以使用Mnist数据集，具体的数据加载和预处理过程可以参考这里<a class="reference external" href="https://www.mindspore.cn/tutorial/training/zh-CN/r1.1/quick_start/quick_start.html">实现一个图片分类应用</a>，这里会用到create_dataset函数创建数据迭代器。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>接下来，需要用到infer接口进行VAE网络的变分推断。</p>
</section>
</section>
<section id="id10">
<h2>概率推断算法<a class="headerlink" href="#id10" title="Permalink to this headline"></a></h2>
<p>调用ELBO接口（<code class="docutils literal notranslate"><span class="pre">mindspore.nn.probability.infer.ELBO</span></code>）来定义VAE网络的损失函数，调用<code class="docutils literal notranslate"><span class="pre">WithLossCell</span></code>封装VAE网络和损失函数，并定义优化器，之后传入SVI接口（<code class="docutils literal notranslate"><span class="pre">mindspore.nn.probability.infer.SVI</span></code>）。SVI的<code class="docutils literal notranslate"><span class="pre">run</span></code>函数可理解为VAE网络的训练，可以指定训练的<code class="docutils literal notranslate"><span class="pre">epochs</span></code>，返回结果为训练好的网络；<code class="docutils literal notranslate"><span class="pre">get_train_loss</span></code>函数可以返回训练好后模型的loss。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.nn.probability.infer</span> <span class="kn">import</span> <span class="n">ELBO</span><span class="p">,</span> <span class="n">SVI</span>

<span class="n">net_loss</span> <span class="o">=</span> <span class="n">ELBO</span><span class="p">(</span><span class="n">latent_prior</span><span class="o">=</span><span class="s1">&#39;Normal&#39;</span><span class="p">,</span> <span class="n">output_prior</span><span class="o">=</span><span class="s1">&#39;Normal&#39;</span><span class="p">)</span>
<span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">WithLossCell</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">vae</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="n">vi</span> <span class="o">=</span> <span class="n">SVI</span><span class="p">(</span><span class="n">net_with_loss</span><span class="o">=</span><span class="n">net_with_loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">vi</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_dataset</span><span class="o">=</span><span class="n">ds_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">trained_loss</span> <span class="o">=</span> <span class="n">vi</span><span class="o">.</span><span class="n">get_train_loss</span><span class="p">()</span>
</pre></div>
</div>
<p>最后，得到训练好的VAE网络后，我们可以使用<code class="docutils literal notranslate"><span class="pre">vae.generate_sample</span></code>生成新样本，需要传入待生成样本的个数，及生成样本的shape，shape需要保持和原数据集中的样本shape一样；当然，我们也可以使用<code class="docutils literal notranslate"><span class="pre">vae.reconstruct_sample</span></code>重构原来数据集中的样本，来测试VAE网络的重建能力。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">generated_sample</span> <span class="o">=</span> <span class="n">vae</span><span class="o">.</span><span class="n">generate_sample</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">IMAGE_SHAPE</span><span class="p">)</span>
<span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">ds_train</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="n">sample_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">reconstructed_sample</span> <span class="o">=</span> <span class="n">vae</span><span class="o">.</span><span class="n">reconstruct_sample</span><span class="p">(</span><span class="n">sample_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The shape of the generated sample is &#39;</span><span class="p">,</span> <span class="n">generated_sample</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>我们可以看一下新生成样本的shape：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>The shape of the generated sample is  (64, 1, 32, 32)
</pre></div>
</div>
<p>ConditionalVAE训练过程和VAE的过程类似，但需要注意的是使用训练好的ConditionalVAE网络生成新样本和重建新样本时，需要输入标签信息，例如下面生成的新样本就是64个0-7的数字。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sample_label</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">)]</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">generated_sample</span> <span class="o">=</span> <span class="n">cvae</span><span class="o">.</span><span class="n">generate_sample</span><span class="p">(</span><span class="n">sample_label</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">IMAGE_SHAPE</span><span class="p">)</span>
<span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">ds_train</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="n">sample_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">sample_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">reconstructed_sample</span> <span class="o">=</span> <span class="n">cvae</span><span class="o">.</span><span class="n">reconstruct_sample</span><span class="p">(</span><span class="n">sample_x</span><span class="p">,</span> <span class="n">sample_y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The shape of the generated sample is &#39;</span><span class="p">,</span> <span class="n">generated_sample</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>查看一下新生成的样本的shape：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>The shape of the generated sample is  (64, 1, 32, 32)
</pre></div>
</div>
<p>如果希望新生成的样本更好，更清晰，用户可以自己定义更复杂的encoder和decoder，这里的示例只用了两层全连接层，仅供示例的指导。</p>
</section>
<section id="id11">
<h2>贝叶斯层<a class="headerlink" href="#id11" title="Permalink to this headline"></a></h2>
<p>下面的范例使用MindSpore的<code class="docutils literal notranslate"><span class="pre">nn.probability.bnn_layers</span></code>中的API实现BNN图片分类模型。MindSpore的<code class="docutils literal notranslate"><span class="pre">nn.probability.bnn_layers</span></code>中的API包括<code class="docutils literal notranslate"><span class="pre">NormalPrior</span></code>，<code class="docutils literal notranslate"><span class="pre">NormalPosterior</span></code>，<code class="docutils literal notranslate"><span class="pre">ConvReparam</span></code>，<code class="docutils literal notranslate"><span class="pre">DenseReparam</span></code>，<code class="docutils literal notranslate"><span class="pre">DenseLocalReparam</span></code>和<code class="docutils literal notranslate"><span class="pre">WithBNNLossCell</span></code>。BNN与DNN的最大区别在于，BNN层的weight和bias不再是确定的值，而是服从一个分布。其中，<code class="docutils literal notranslate"><span class="pre">NormalPrior</span></code>，<code class="docutils literal notranslate"><span class="pre">NormalPosterior</span></code>分别用来生成服从正态分布的先验分布和后验分布；<code class="docutils literal notranslate"><span class="pre">ConvReparam</span></code>和<code class="docutils literal notranslate"><span class="pre">DenseReparam</span></code>分别是使用reparameterization方法实现的贝叶斯卷积层和全连接层；<code class="docutils literal notranslate"><span class="pre">DenseLocalReparam</span></code>是使用Local Reparameterization方法实现的贝叶斯全连接层；<code class="docutils literal notranslate"><span class="pre">WithBNNLossCell</span></code>是用来封装BNN和损失函数的。</p>
<p>如何使用<code class="docutils literal notranslate"><span class="pre">nn.probability.bnn_layers</span></code>中的API构建贝叶斯神经网络并实现图片分类，可以参考教程<a class="reference external" href="https://www.mindspore.cn/tutorial/training/zh-CN/r1.1/advanced_use/apply_deep_probability_programming.html#id3">使用贝叶斯网络</a>。</p>
</section>
<section id="id12">
<h2>贝叶斯转换<a class="headerlink" href="#id12" title="Permalink to this headline"></a></h2>
<p>对于不熟悉贝叶斯模型的研究人员，MDP提供了贝叶斯转换接口（<code class="docutils literal notranslate"><span class="pre">mindspore.nn.probability.transform</span></code>），支持DNN (Deep Neural Network)模型一键转换成BNN (Bayesian Neural Network)模型。</p>
<p>其中的模型转换API<code class="docutils literal notranslate"><span class="pre">TransformToBNN</span></code>的<code class="docutils literal notranslate"><span class="pre">__init__</span></code>函数定义如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TransformToBNN</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainable_dnn</span><span class="p">,</span> <span class="n">dnn_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bnn_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">trainable_dnn</span><span class="o">.</span><span class="n">network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">trainable_dnn</span><span class="o">.</span><span class="n">optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backbone</span> <span class="o">=</span> <span class="n">net_with_loss</span><span class="o">.</span><span class="n">backbone_network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">net_with_loss</span><span class="p">,</span> <span class="s2">&quot;_loss_fn&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dnn_factor</span> <span class="o">=</span> <span class="n">dnn_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bnn_factor</span> <span class="o">=</span> <span class="n">bnn_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bnn_loss_file</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>
</div>
<p>参数<code class="docutils literal notranslate"><span class="pre">trainable_bnn</span></code>是经过<code class="docutils literal notranslate"><span class="pre">TrainOneStepCell</span></code>包装的可训练DNN模型，<code class="docutils literal notranslate"><span class="pre">dnn_factor</span></code>和<code class="docutils literal notranslate"><span class="pre">bnn_factor</span></code>分别为由损失函数计算得到的网络整体损失的系数和每个贝叶斯层的KL散度的系数。
API<code class="docutils literal notranslate"><span class="pre">TransformToBNN</span></code>主要实现了两个功能：</p>
<ul>
<li><p>功能一：转换整个模型</p>
<p><code class="docutils literal notranslate"><span class="pre">transform_to_bnn_model</span></code>方法可以将整个DNN模型转换为BNN模型。其定义如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>  <span class="k">def</span> <span class="nf">transform_to_bnn_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                             <span class="n">get_dense_args</span><span class="o">=</span><span class="k">lambda</span> <span class="n">dp</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;in_channels&quot;</span><span class="p">:</span> <span class="n">dp</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="s2">&quot;has_bias&quot;</span><span class="p">:</span> <span class="n">dp</span><span class="o">.</span><span class="n">has_bias</span><span class="p">,</span>
                                                        <span class="s2">&quot;out_channels&quot;</span><span class="p">:</span> <span class="n">dp</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="s2">&quot;activation&quot;</span><span class="p">:</span> <span class="n">dp</span><span class="o">.</span><span class="n">activation</span><span class="p">},</span>
                             <span class="n">get_conv_args</span><span class="o">=</span><span class="k">lambda</span> <span class="n">dp</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;in_channels&quot;</span><span class="p">:</span> <span class="n">dp</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="s2">&quot;out_channels&quot;</span><span class="p">:</span> <span class="n">dp</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span>
                                                       <span class="s2">&quot;pad_mode&quot;</span><span class="p">:</span> <span class="n">dp</span><span class="o">.</span><span class="n">pad_mode</span><span class="p">,</span> <span class="s2">&quot;kernel_size&quot;</span><span class="p">:</span> <span class="n">dp</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
                                                       <span class="s2">&quot;stride&quot;</span><span class="p">:</span> <span class="n">dp</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="s2">&quot;has_bias&quot;</span><span class="p">:</span> <span class="n">dp</span><span class="o">.</span><span class="n">has_bias</span><span class="p">,</span>
                                                       <span class="s2">&quot;padding&quot;</span><span class="p">:</span> <span class="n">dp</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="s2">&quot;dilation&quot;</span><span class="p">:</span> <span class="n">dp</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span>
                                                       <span class="s2">&quot;group&quot;</span><span class="p">:</span> <span class="n">dp</span><span class="o">.</span><span class="n">group</span><span class="p">},</span>
                             <span class="n">add_dense_args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                             <span class="n">add_conv_args</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">      </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">      Transform the whole DNN model to BNN model, and wrap BNN model by TrainOneStepCell.</span>

<span class="sd">      Args:</span>
<span class="sd">          get_dense_args (function): The arguments gotten from the DNN full connection layer. Default: lambda dp:</span>
<span class="sd">              {&quot;in_channels&quot;: dp.in_channels, &quot;out_channels&quot;: dp.out_channels, &quot;has_bias&quot;: dp.has_bias}.</span>
<span class="sd">          get_conv_args (function): The arguments gotten from the DNN convolutional layer. Default: lambda dp:</span>
<span class="sd">              {&quot;in_channels&quot;: dp.in_channels, &quot;out_channels&quot;: dp.out_channels, &quot;pad_mode&quot;: dp.pad_mode,</span>
<span class="sd">              &quot;kernel_size&quot;: dp.kernel_size, &quot;stride&quot;: dp.stride, &quot;has_bias&quot;: dp.has_bias}.</span>
<span class="sd">          add_dense_args (dict): The new arguments added to BNN full connection layer. Default: {}.</span>
<span class="sd">          add_conv_args (dict): The new arguments added to BNN convolutional layer. Default: {}.</span>

<span class="sd">      Returns:</span>
<span class="sd">          Cell, a trainable BNN model wrapped by TrainOneStepCell.</span>
<span class="sd">     &quot;&quot;&quot;</span>

</pre></div>
</div>
<p>参数<code class="docutils literal notranslate"><span class="pre">get_dense_args</span></code>指定从DNN模型的全连接层中获取哪些参数，默认值是DNN模型的全连接层和BNN的全连接层所共有的参数，参数具体的含义可以参考<a class="reference external" href="https://www.mindspore.cn/doc/api_python/zh-CN/r1.1/mindspore/nn/mindspore.nn.Dense.html">API说明文档</a>；<code class="docutils literal notranslate"><span class="pre">get_conv_args</span></code>指定从DNN模型的卷积层中获取哪些参数，默认值是DNN模型的卷积层和BNN的卷积层所共有的参数，参数具体的含义可以参考<a class="reference external" href="https://www.mindspore.cn/doc/api_python/zh-CN/r1.1/mindspore/nn/mindspore.nn.Conv2d.html">API说明文档</a>；参数<code class="docutils literal notranslate"><span class="pre">add_dense_args</span></code>和<code class="docutils literal notranslate"><span class="pre">add_conv_args</span></code>分别指定了要为BNN层指定哪些新的参数值。需要注意的是，<code class="docutils literal notranslate"><span class="pre">add_dense_args</span></code>中的参数不能与<code class="docutils literal notranslate"><span class="pre">get_dense_args</span></code>重复，<code class="docutils literal notranslate"><span class="pre">add_conv_args</span></code>和<code class="docutils literal notranslate"><span class="pre">get_conv_args</span></code>也是如此。</p>
</li>
<li><p>功能二：转换指定类型的层</p>
<p><code class="docutils literal notranslate"><span class="pre">transform_to_bnn_layer</span></code>方法可以将DNN模型中指定类型的层（<code class="docutils literal notranslate"><span class="pre">nn.Dense</span></code>或者<code class="docutils literal notranslate"><span class="pre">nn.Conv2d</span></code>）转换为对应的贝叶斯层。其定义如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span> <span class="k">def</span> <span class="nf">transform_to_bnn_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dnn_layer</span><span class="p">,</span> <span class="n">bnn_layer</span><span class="p">,</span> <span class="n">get_args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">add_args</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">      </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">      Transform a specific type of layers in DNN model to corresponding BNN layer.</span>

<span class="sd">      Args:</span>
<span class="sd">          dnn_layer_type (Cell): The type of DNN layer to be transformed to BNN layer. The optional values are</span>
<span class="sd">          nn.Dense, nn.Conv2d.</span>
<span class="sd">          bnn_layer_type (Cell): The type of BNN layer to be transformed to. The optional values are</span>
<span class="sd">              DenseReparameterization, ConvReparameterization.</span>
<span class="sd">          get_args (dict): The arguments gotten from the DNN layer. Default: None.</span>
<span class="sd">          add_args (dict): The new arguments added to BNN layer. Default: None.</span>

<span class="sd">      Returns:</span>
<span class="sd">          Cell, a trainable model wrapped by TrainOneStepCell, whose sprcific type of layer is transformed to the corresponding bayesian layer.</span>
<span class="sd">      &quot;&quot;&quot;</span>
</pre></div>
</div>
<p>参数<code class="docutils literal notranslate"><span class="pre">dnn_layer</span></code>指定将哪个类型的DNN层转换成BNN层，<code class="docutils literal notranslate"><span class="pre">bnn_layer</span></code>指定DNN层将转换成哪个类型的BNN层，<code class="docutils literal notranslate"><span class="pre">get_args</span></code>和<code class="docutils literal notranslate"><span class="pre">add_args</span></code>分别指定从DNN层中获取哪些参数和要为BNN层的哪些参数重新赋值。</p>
</li>
</ul>
<p>如何在MindSpore中使用API<code class="docutils literal notranslate"><span class="pre">TransformToBNN</span></code>可以参考教程<a class="reference external" href="https://www.mindspore.cn/tutorial/training/zh-CN/r1.1/advanced_use/apply_deep_probability_programming.html#dnnbnn">DNN一键转换成BNN</a></p>
</section>
<section id="id13">
<h2>贝叶斯工具箱<a class="headerlink" href="#id13" title="Permalink to this headline"></a></h2>
<section id="id14">
<h3>不确定性评估<a class="headerlink" href="#id14" title="Permalink to this headline"></a></h3>
<p>贝叶斯神经网络的优势之一就是可以获取不确定性，MDP在上层提供了不确定性估计的工具箱（<code class="docutils literal notranslate"><span class="pre">mindspore.nn.probability.toolbox</span></code>），用户可以很方便地使用该工具箱计算不确定性。不确定性意味着深度学习模型对预测结果的不确定程度。目前，大多数深度学习算法只能给出高置信度的预测结果，而不能判断预测结果的确定性，不确定性主要有两种类型：偶然不确定性和认知不确定性。</p>
<ul class="simple">
<li><p>偶然不确定性（Aleatoric Uncertainty）：描述数据中的内在噪声，即无法避免的误差，这个现象不能通过增加采样数据来削弱。</p></li>
<li><p>认知不确定性（Epistemic Uncertainty）：模型自身对输入数据的估计可能因为训练不佳、训练数据不够等原因而不准确，可以通过增加训练数据等方式来缓解。</p></li>
</ul>
<p>不确定性评估工具箱的接口如下：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model</span></code>：待评估不确定性的已训练好的模型。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train_dataset</span></code>：用于训练的数据集，迭代器类型。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">task_type</span></code>：模型的类型，字符串，输入“regression”或者“classification”。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">num_classes</span></code>：如果是分类模型，需要指定类别的标签数量。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">epochs</span></code>：用于训练不确定模型的迭代数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">epi_uncer_model_path</span></code>：用于存储或加载计算认知不确定性的模型的路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ale_uncer_model_path</span></code>：用于存储或加载计算偶然不确定性的模型的路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">save_model</span></code>：布尔类型，是否需要存储模型。</p></li>
</ul>
<p>在使用前，需要先训练好模型，以LeNet5为例，使用方式如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.nn.probability.toolbox.uncertainty_evaluation</span> <span class="kn">import</span> <span class="n">UncertaintyEvaluation</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="c1"># get trained model</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
    <span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="s1">&#39;checkpoint_lenet.ckpt&#39;</span><span class="p">)</span>
    <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
    <span class="c1"># get train and eval dataset</span>
    <span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;workspace/mnist/train&#39;</span><span class="p">)</span>
    <span class="n">ds_eval</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;workspace/mnist/test&#39;</span><span class="p">)</span>
    <span class="n">evaluation</span> <span class="o">=</span> <span class="n">UncertaintyEvaluation</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">network</span><span class="p">,</span>
                                       <span class="n">train_dataset</span><span class="o">=</span><span class="n">ds_train</span><span class="p">,</span>
                                       <span class="n">task_type</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">,</span>
                                       <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                       <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                       <span class="n">epi_uncer_model_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                       <span class="n">ale_uncer_model_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                       <span class="n">save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">eval_data</span> <span class="ow">in</span> <span class="n">ds_eval</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
        <span class="n">eval_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">eval_data</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">],</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">epistemic_uncertainty</span> <span class="o">=</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">eval_epistemic_uncertainty</span><span class="p">(</span><span class="n">eval_data</span><span class="p">)</span>
        <span class="n">aleatoric_uncertainty</span> <span class="o">=</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">eval_aleatoric_uncertainty</span><span class="p">(</span><span class="n">eval_data</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The shape of epistemic uncertainty is &#39;</span><span class="p">,</span> <span class="n">epistemic_uncertainty</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The shape of aleatoric uncertainty is &#39;</span><span class="p">,</span> <span class="n">aleatoric_uncertainty</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">eval_epistemic_uncertainty</span></code>计算的是认知不确定性，也叫模型不确定性，对于每一个样本的每个预测标签都会有一个不确定值；<code class="docutils literal notranslate"><span class="pre">eval_aleatoric_uncertainty</span></code>计算的是偶然不确定性，也叫数据不确定性，对于每一个样本都会有一个不确定值。
所以输出为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>The shape of epistemic uncertainty is (32, 10)
The shape of aleatoric uncertainty is (32,)
</pre></div>
</div>
<p>uncertainty的值大于等于0，越大表示不确定性越高。</p>
</section>
<section id="id15">
<h3>异常检测<a class="headerlink" href="#id15" title="Permalink to this headline"></a></h3>
<p>异常检测(Anomaly Detection)可以找到与“主要数据分布不同”的异常值，比如在数据预处理中找出异常点，有助于提升模型的拟合能力。</p>
<p>MDP在上层基于变分自编码器（VAE）提供了异常检测的工具箱(<code class="docutils literal notranslate"><span class="pre">VAEAnomalyDetection</span></code>)，与VAE的使用类似，我们只需要自定义编码器和解码器（DNN模型），初始化相关参数，便可以使用该工具箱检测异常点。</p>
<p>基于VAE的异常检测工具箱的接口如下：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">encoder</span></code>：编码器（Cell类型）</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">decoder</span></code>：解码器（Cell类型）</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">hidden_size</span></code>：编码器输出张量的大小</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">latent_size</span></code>：隐空间的大小</p></li>
</ul>
<p>编码器和解码器可使用以上的Encoder和Decoder，设置hidden_size和latent_size，进行类的初始化，之后传入数据集可以进行异常点的检测。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.nn.probability.toolbox.vae_anomaly_detection</span> <span class="kn">import</span> <span class="n">VAEAnomalyDetection</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">()</span>
    <span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">()</span>
    <span class="n">ood</span> <span class="o">=</span> <span class="n">VAEAnomalyDetection</span><span class="p">(</span><span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
                              <span class="n">hidden_size</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">latent_size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;workspace/mnist/train&#39;</span><span class="p">)</span>
    <span class="n">ds_eval</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;workspace/mnist/test&#39;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ood</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">ds_train</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">ds_eval</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">sample_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">ood</span><span class="o">.</span><span class="n">predict_outlier_score</span><span class="p">(</span><span class="n">sample_x</span><span class="p">)</span>
        <span class="n">outlier</span> <span class="o">=</span> <span class="n">ood</span><span class="o">.</span><span class="n">predict_outlier</span><span class="p">(</span><span class="n">sample_x</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">outlier</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">score</span></code>输出的是样本的异常分数；<code class="docutils literal notranslate"><span class="pre">outlier</span></code>是布尔类型，True代表是异常点，False代表不是异常点。</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="extension.html" class="btn btn-neutral float-left" title="功能扩展" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="network_list.html" class="btn btn-neutral float-right" title="网络支持" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>