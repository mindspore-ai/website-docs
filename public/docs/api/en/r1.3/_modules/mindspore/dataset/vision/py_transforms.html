<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.dataset.vision.py_transforms &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">MindSpore Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.compression.html">mindspore.compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.explainer.html">mindspore.explainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.profiler.html">mindspore.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.train.html">mindspore.train</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindSpore C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.3/api_cpp/class_list.html">Lite</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
      <li>mindspore.dataset.vision.py_transforms</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for mindspore.dataset.vision.py_transforms</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2019 Huawei Technologies Co., Ltd</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">The module vision.py_transforms is mainly implemented based on Python PIL, which</span>
<span class="sd">provides many kinds of image augmentation methods and conversion methods between</span>
<span class="sd">PIL image and numpy.ndarray. For users who prefer using Python PIL in computer vision</span>
<span class="sd">tasks, this module is a good choice to process images. Users can also self-define</span>
<span class="sd">their own augmentation methods with Python PIL.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numbers</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">py_transforms_util</span> <span class="k">as</span> <span class="n">util</span>
<span class="kn">from</span> <span class="nn">.c_transforms</span> <span class="kn">import</span> <span class="n">parse_padding</span>
<span class="kn">from</span> <span class="nn">.validators</span> <span class="kn">import</span> <span class="n">check_prob</span><span class="p">,</span> <span class="n">check_center_crop</span><span class="p">,</span> <span class="n">check_five_crop</span><span class="p">,</span> <span class="n">check_resize_interpolation</span><span class="p">,</span> <span class="n">check_random_resize_crop</span><span class="p">,</span> \
    <span class="n">check_normalize_py</span><span class="p">,</span> <span class="n">check_normalizepad_py</span><span class="p">,</span> <span class="n">check_random_crop</span><span class="p">,</span> <span class="n">check_random_color_adjust</span><span class="p">,</span> <span class="n">check_random_rotation</span><span class="p">,</span> \
    <span class="n">check_ten_crop</span><span class="p">,</span> <span class="n">check_num_channels</span><span class="p">,</span> <span class="n">check_pad</span><span class="p">,</span> <span class="n">check_rgb_to_hsv</span><span class="p">,</span> <span class="n">check_hsv_to_rgb</span><span class="p">,</span> \
    <span class="n">check_random_perspective</span><span class="p">,</span> <span class="n">check_random_erasing</span><span class="p">,</span> <span class="n">check_cutout</span><span class="p">,</span> <span class="n">check_linear_transform</span><span class="p">,</span> <span class="n">check_random_affine</span><span class="p">,</span> \
    <span class="n">check_mix_up</span><span class="p">,</span> <span class="n">check_positive_degrees</span><span class="p">,</span> <span class="n">check_uniform_augment_py</span><span class="p">,</span> <span class="n">check_auto_contrast</span><span class="p">,</span> <span class="n">check_rgb_to_bgr</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">Inter</span><span class="p">,</span> <span class="n">Border</span>
<span class="kn">from</span> <span class="nn">.py_transforms_util</span> <span class="kn">import</span> <span class="n">is_pil</span>

<span class="n">DE_PY_INTER_MODE</span> <span class="o">=</span> <span class="p">{</span><span class="n">Inter</span><span class="o">.</span><span class="n">NEAREST</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">NEAREST</span><span class="p">,</span>
                    <span class="n">Inter</span><span class="o">.</span><span class="n">ANTIALIAS</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">ANTIALIAS</span><span class="p">,</span>
                    <span class="n">Inter</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">,</span>
                    <span class="n">Inter</span><span class="o">.</span><span class="n">CUBIC</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">CUBIC</span><span class="p">}</span>

<span class="n">DE_PY_BORDER_TYPE</span> <span class="o">=</span> <span class="p">{</span><span class="n">Border</span><span class="o">.</span><span class="n">CONSTANT</span><span class="p">:</span> <span class="s1">&#39;constant&#39;</span><span class="p">,</span>
                     <span class="n">Border</span><span class="o">.</span><span class="n">EDGE</span><span class="p">:</span> <span class="s1">&#39;edge&#39;</span><span class="p">,</span>
                     <span class="n">Border</span><span class="o">.</span><span class="n">REFLECT</span><span class="p">:</span> <span class="s1">&#39;reflect&#39;</span><span class="p">,</span>
                     <span class="n">Border</span><span class="o">.</span><span class="n">SYMMETRIC</span><span class="p">:</span> <span class="s1">&#39;symmetric&#39;</span><span class="p">}</span>


<span class="k">def</span> <span class="nf">not_random</span><span class="p">(</span><span class="n">function</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Specify the function as &quot;not random&quot;, i.e., it produces deterministic result.</span>
<span class="sd">    A Python function can only be cached after it is specified as &quot;not random&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">function</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="n">function</span>


<div class="viewcode-block" id="ToTensor"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.ToTensor.html#mindspore.dataset.vision.py_transforms.ToTensor">[docs]</a><span class="k">class</span> <span class="nc">ToTensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert the input PIL Image or numpy.ndarray of shape (H, W, C) in the range [0, 255] to numpy.ndarray of</span>
<span class="sd">    shape (C, H, W) in the range [0.0, 1.0] with the desired dtype.</span>

<span class="sd">    Note:</span>
<span class="sd">        The values in the input image will be rescaled from [0, 255] to [0.0, 1.0].</span>
<span class="sd">        The dtype will be cast to `output_type`.</span>
<span class="sd">        The number of channels remains the same.</span>

<span class="sd">    Args:</span>
<span class="sd">        output_type (numpy.dtype, optional): The dtype of the numpy.ndarray output (default=np.float32).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input is not PIL Image or numpy.ndarray.</span>
<span class="sd">        TypeError: If the dimension of input is not 2 or 3.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; # create a list of transformations to be applied to the &quot;image&quot; column of each data row</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_type</span> <span class="o">=</span> <span class="n">output_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (Union[PIL Image, numpy.ndarray]): PIL Image or numpy.ndarray to be type converted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, converted numpy.ndarray with desired type.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_type</span><span class="p">)</span></div>


<div class="viewcode-block" id="ToType"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.ToType.html#mindspore.dataset.vision.py_transforms.ToType">[docs]</a><span class="k">class</span> <span class="nc">ToType</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert the input numpy.ndarray image to the desired dtype.</span>

<span class="sd">    Args:</span>
<span class="sd">        output_type (numpy.dtype): The dtype of the numpy.ndarray output, e.g. numpy.float32.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input is not numpy.ndarray.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; transforms_list =Compose([py_vision.Decode(),</span>
<span class="sd">        ...                           py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                           py_vision.ToTensor(),</span>
<span class="sd">        ...                           py_vision.ToType(np.float32)])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_type</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_type</span> <span class="o">=</span> <span class="n">output_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (numpy.ndarray): numpy.ndarray to be dtype converted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, converted numpy.ndarray with desired dtype.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">to_type</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_type</span><span class="p">)</span></div>


<div class="viewcode-block" id="HWC2CHW"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.HWC2CHW.html#mindspore.dataset.vision.py_transforms.HWC2CHW">[docs]</a><span class="k">class</span> <span class="nc">HWC2CHW</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transpose the input numpy.ndarray image of shape (H, W, C) to (C, H, W).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input is not numpy.ndarray.</span>
<span class="sd">        TypeError: If the dimension of input is not 3.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.HWC2CHW()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (numpy.ndarray): numpy.ndarray of shape (H, W, C) to be transposed.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, transposed numpy.ndarray of shape (C, H, W).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">hwc_to_chw</span><span class="p">(</span><span class="n">img</span><span class="p">)</span></div>


<div class="viewcode-block" id="ToPIL"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.ToPIL.html#mindspore.dataset.vision.py_transforms.ToPIL">[docs]</a><span class="k">class</span> <span class="nc">ToPIL</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert the input decoded numpy.ndarray image to PIL Image.</span>

<span class="sd">    Note:</span>
<span class="sd">        The conversion mode will be determined from type according to `PIL.Image.fromarray`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input is not numpy.ndarray or PIL Image.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; # data is already decoded, but not in PIL Image format</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.ToPIL(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (numpy.ndarray): Decoded numpy.ndarray image to be converted to PIL Image.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, converted PIL Image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">to_pil</span><span class="p">(</span><span class="n">img</span><span class="p">)</span></div>


<div class="viewcode-block" id="Decode"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Decode.html#mindspore.dataset.vision.py_transforms.Decode">[docs]</a><span class="k">class</span> <span class="nc">Decode</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Decode the input raw image to PIL Image format in RGB mode.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If the input is not raw data.</span>
<span class="sd">        ValueError: If the input image is already decoded.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (Bytes-like Object): Raw image data to be decoded.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, decoded PIL Image in RGB mode.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">img</span><span class="p">)</span></div>


<div class="viewcode-block" id="Normalize"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Normalize.html#mindspore.dataset.vision.py_transforms.Normalize">[docs]</a><span class="k">class</span> <span class="nc">Normalize</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Normalize the input numpy.ndarray image of shape (C, H, W) with the specified mean and standard deviation.</span>

<span class="sd">    .. math::</span>

<span class="sd">        output_{c} = \frac{input_{c} - mean_{c}}{std_{c}}</span>

<span class="sd">    Note:</span>
<span class="sd">        The values of the input image need to be in the range [0.0, 1.0]. If not so, call `ToTensor` first.</span>

<span class="sd">    Args:</span>
<span class="sd">        mean (Union[float, sequence]): list or tuple of mean values for each channel, arranged in channel order. The</span>
<span class="sd">            values must be in the range [0.0, 1.0].</span>
<span class="sd">            If a single float is provided, it will be filled to the same length as the channel.</span>
<span class="sd">        std (Union[float, sequence]): list or tuple of standard deviation values for each channel, arranged in channel</span>
<span class="sd">            order. The values must be in the range (0.0, 1.0].</span>
<span class="sd">            If a single float is provided, it will be filled to the same length as the channel.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input is not numpy.ndarray.</span>
<span class="sd">        TypeError: If the dimension of input is not 3.</span>
<span class="sd">        NotImplementedError: If the dtype of input is a subdtype of np.integer.</span>
<span class="sd">        ValueError: If the length of the mean and std are not equal.</span>
<span class="sd">        ValueError: If the length of the mean or std is neither equal to the channel length nor 1.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.Normalize((0.491, 0.482, 0.447), (0.247, 0.243, 0.262))])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_normalize_py</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (numpy.ndarray): numpy.ndarray to be normalized.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, normalized numpy.ndarray.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="p">)</span></div>


<div class="viewcode-block" id="NormalizePad"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.NormalizePad.html#mindspore.dataset.vision.py_transforms.NormalizePad">[docs]</a><span class="k">class</span> <span class="nc">NormalizePad</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Normalize the input numpy.ndarray image of shape (C, H, W) with the specified mean and standard deviation,</span>
<span class="sd">    then pad an extra channel filled with zeros.</span>

<span class="sd">    .. math::</span>
<span class="sd">        output_{c} = \begin{cases}</span>
<span class="sd">        \frac{input_{c} - mean_{c}}{std_{c}}, &amp; \text{if} \quad 0 \le c &lt; 3 \text{;}\\</span>
<span class="sd">        0, &amp; \text{if} \quad c = 3 \text{.}</span>
<span class="sd">        \end{cases}</span>

<span class="sd">    Note:</span>
<span class="sd">        The values of the input image need to be in the range [0.0, 1.0]. If not so, call `ToTensor` first.</span>

<span class="sd">    Args:</span>
<span class="sd">        mean (Union[float, sequence]): list or tuple of mean values for each channel, arranged in channel order. The</span>
<span class="sd">            values must be in the range [0.0, 1.0].</span>
<span class="sd">            If a single float is provided, it will be filled to the same length as the channel.</span>
<span class="sd">        std (Union[float, sequence]): list or tuple of standard deviation values for each channel, arranged in channel</span>
<span class="sd">            order. The values must be in the range (0.0, 1.0].</span>
<span class="sd">            If a single float is provided, it will be filled to the same length as the channel.</span>
<span class="sd">        dtype (str): The dtype of the numpy.ndarray output when `pad_channel` is set True. Only &quot;float32&quot; and &quot;float16&quot;</span>
<span class="sd">            are supported (default=&quot;float32&quot;).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input is not numpy.ndarray.</span>
<span class="sd">        TypeError: If the dimension of input is not 3.</span>
<span class="sd">        NotImplementedError: If the dtype of input is a subdtype of np.integer.</span>
<span class="sd">        ValueError: If the length of the mean and std are not equal.</span>
<span class="sd">        ValueError: If the length of the mean or std is neither equal to the channel length nor 1.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.NormalizePad((0.491, 0.482, 0.447), (0.247, 0.243, 0.262), &quot;float32&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_normalizepad_py</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (numpy.ndarray): numpy.ndarray to be normalized and padded.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, normalized and padded numpy.ndarray.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="p">,</span> <span class="n">pad_channel</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomCrop"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomCrop.html#mindspore.dataset.vision.py_transforms.RandomCrop">[docs]</a><span class="k">class</span> <span class="nc">RandomCrop</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Crop the input PIL Image at a random location with the specified size.</span>

<span class="sd">    Args:</span>
<span class="sd">        size (Union[int, sequence]): The output size of the cropped image.</span>
<span class="sd">            If size is an integer, a square crop of size (size, size) is returned.</span>
<span class="sd">            If size is a sequence of length 2, it should be (height, width).</span>
<span class="sd">        padding (Union[int, sequence], optional): The number of pixels to pad the image (default=None).</span>
<span class="sd">            If padding is not None, first pad image with padding values.</span>
<span class="sd">            If a single number is provided, pad all borders with this value.</span>
<span class="sd">            If a tuple or list of 2 values are provided, pad the (left and top)</span>
<span class="sd">            with the first value and (right and bottom) with the second value.</span>
<span class="sd">            If 4 values are provided as a list or tuple,</span>
<span class="sd">            pad the left, top, right and bottom respectively.</span>
<span class="sd">        pad_if_needed (bool, optional): Pad the image if either side is smaller than</span>
<span class="sd">            the given output size (default=False).</span>
<span class="sd">        fill_value (int or tuple, optional): filling value (default=0).</span>
<span class="sd">            The pixel intensity of the borders if the padding_mode is Border.CONSTANT.</span>
<span class="sd">            If it is a 3-tuple, it is used to fill R, G, B channels respectively.</span>
<span class="sd">        padding_mode (str, optional): The method of padding (default=Border.CONSTANT). It can be any of</span>
<span class="sd">            [Border.CONSTANT, Border.EDGE, Border.REFLECT, Border.SYMMETRIC].</span>

<span class="sd">            - Border.CONSTANT, means it fills the border with constant values.</span>

<span class="sd">            - Border.EDGE, means it pads with the last value on the edge.</span>

<span class="sd">            - Border.REFLECT, means it reflects the values on the edge omitting the last</span>
<span class="sd">              value of edge.</span>

<span class="sd">            - Border.SYMMETRIC, means it reflects the values on the edge repeating the last</span>
<span class="sd">              value of edge.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomCrop(224),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_crop</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pad_if_needed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="n">Border</span><span class="o">.</span><span class="n">CONSTANT</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">padding</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="n">parse_padding</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_if_needed</span> <span class="o">=</span> <span class="n">pad_if_needed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span> <span class="o">=</span> <span class="n">fill_value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span> <span class="o">=</span> <span class="n">DE_PY_BORDER_TYPE</span><span class="p">[</span><span class="n">padding_mode</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): Image to be randomly cropped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, cropped image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_if_needed</span><span class="p">,</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomHorizontalFlip"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomHorizontalFlip.html#mindspore.dataset.vision.py_transforms.RandomHorizontalFlip">[docs]</a><span class="k">class</span> <span class="nc">RandomHorizontalFlip</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly flip the input image horizontally with a given probability.</span>

<span class="sd">    Args:</span>
<span class="sd">        prob (float, optional): Probability of the image being flipped (default=0.5).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_prob</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): Image to be flipped horizontally.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, randomly horizontal flipped image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_horizontal_flip</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomVerticalFlip"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomVerticalFlip.html#mindspore.dataset.vision.py_transforms.RandomVerticalFlip">[docs]</a><span class="k">class</span> <span class="nc">RandomVerticalFlip</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly flip the input image vertically with a given probability.</span>

<span class="sd">    Args:</span>
<span class="sd">        prob (float, optional): Probability of the image being flipped (default=0.5).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomVerticalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_prob</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): Image to be flipped vertically.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, randomly vertical flipped image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_vertical_flip</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob</span><span class="p">)</span></div>


<div class="viewcode-block" id="Resize"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Resize.html#mindspore.dataset.vision.py_transforms.Resize">[docs]</a><span class="k">class</span> <span class="nc">Resize</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Resize the input PIL image to the given size.</span>

<span class="sd">    Args:</span>
<span class="sd">        size (Union[int, sequence]): The output size of the resized image.</span>
<span class="sd">            If size is an integer, the smaller edge of the image will be resized to this value with</span>
<span class="sd">            the same image aspect ratio.</span>
<span class="sd">            If size is a sequence of length 2, it should be (height, width).</span>
<span class="sd">        interpolation (Inter mode, optional): Image interpolation mode (default=Inter.BILINEAR).</span>
<span class="sd">            It can be any of [Inter.NEAREST, Inter.ANTIALIAS, Inter.BILINEAR, Inter.BICUBIC].</span>

<span class="sd">            - Inter.NEAREST, means the interpolation method is nearest-neighbor interpolation.</span>

<span class="sd">            - Inter.ANTIALIAS, means the interpolation method is antialias interpolation.</span>

<span class="sd">            - Inter.BILINEAR, means the interpolation method is bilinear interpolation.</span>

<span class="sd">            - Inter.BICUBIC, means the interpolation method is bicubic interpolation.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.Resize(256),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_resize_interpolation</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">BILINEAR</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span> <span class="o">=</span> <span class="n">DE_PY_INTER_MODE</span><span class="p">[</span><span class="n">interpolation</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): Image to be resized.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, resized image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomResizedCrop"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomResizedCrop.html#mindspore.dataset.vision.py_transforms.RandomResizedCrop">[docs]</a><span class="k">class</span> <span class="nc">RandomResizedCrop</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extract crop from the input image and resize it to a random size and aspect ratio.</span>

<span class="sd">    Args:</span>
<span class="sd">        size (Union[int, sequence]): The size of the output image.</span>
<span class="sd">            If size is an integer, a square crop of size (size, size) is returned.</span>
<span class="sd">            If size is a sequence of length 2, it should be (height, width).</span>
<span class="sd">        scale (list, tuple, optional): Range (min, max) of respective size of the original size</span>
<span class="sd">            to be cropped (default=(0.08, 1.0)).</span>
<span class="sd">        ratio (list, tuple, optional): Range (min, max) of aspect ratio to be cropped (default=(3. / 4., 4. / 3.)).</span>
<span class="sd">        interpolation (Inter mode, optional): Image interpolation mode (default=Inter.BILINEAR).</span>
<span class="sd">            It can be any of [Inter.NEAREST, Inter.ANTIALIAS, Inter.BILINEAR, Inter.BICUBIC].</span>

<span class="sd">            - Inter.NEAREST, means the interpolation method is nearest-neighbor interpolation.</span>

<span class="sd">            - Inter.ANTIALIAS, means the interpolation method is antialias interpolation.</span>

<span class="sd">            - Inter.BILINEAR, means the interpolation method is bilinear interpolation.</span>

<span class="sd">            - Inter.BICUBIC, means the interpolation method is bicubic interpolation.</span>

<span class="sd">        max_attempts (int, optional): The maximum number of attempts to propose a valid</span>
<span class="sd">            crop area (default=10). If exceeded, fall back to use center crop instead.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomResizedCrop(224),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_resize_crop</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.08</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="mf">3.</span> <span class="o">/</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">4.</span> <span class="o">/</span> <span class="mf">3.</span><span class="p">),</span>
                 <span class="n">interpolation</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">BILINEAR</span><span class="p">,</span> <span class="n">max_attempts</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span> <span class="o">=</span> <span class="n">ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span> <span class="o">=</span> <span class="n">DE_PY_INTER_MODE</span><span class="p">[</span><span class="n">interpolation</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_attempts</span> <span class="o">=</span> <span class="n">max_attempts</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): Image to be randomly cropped and resized.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, randomly cropped and resized image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_resize_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_attempts</span><span class="p">)</span></div>


<div class="viewcode-block" id="CenterCrop"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.CenterCrop.html#mindspore.dataset.vision.py_transforms.CenterCrop">[docs]</a><span class="k">class</span> <span class="nc">CenterCrop</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Crop the central reigion of the input PIL image to the given size.</span>

<span class="sd">    Args:</span>
<span class="sd">        size (Union[int, sequence]): The output size of the cropped image.</span>
<span class="sd">            If size is an integer, a square crop of size (size, size) is returned.</span>
<span class="sd">            If size is a sequence of length 2, it should be (height, width).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.CenterCrop(64),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_center_crop</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): Image to be center cropped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, cropped image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">center_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomColorAdjust"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomColorAdjust.html#mindspore.dataset.vision.py_transforms.RandomColorAdjust">[docs]</a><span class="k">class</span> <span class="nc">RandomColorAdjust</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform a random brightness, contrast, saturation, and hue adjustment on the input PIL image.</span>

<span class="sd">    Args:</span>
<span class="sd">        brightness (Union[float, tuple], optional): Brightness adjustment factor (default=(1, 1)). Cannot be negative.</span>
<span class="sd">            If it is a float, the factor is uniformly chosen from the range [max(0, 1-brightness), 1+brightness].</span>
<span class="sd">            If it is a sequence, it should be [min, max] for the range.</span>
<span class="sd">        contrast (Union[float, tuple], optional): Contrast adjustment factor (default=(1, 1)). Cannot be negative.</span>
<span class="sd">            If it is a float, the factor is uniformly chosen from the range [max(0, 1-contrast), 1+contrast].</span>
<span class="sd">            If it is a sequence, it should be [min, max] for the range.</span>
<span class="sd">        saturation (Union[float, tuple], optional): Saturation adjustment factor (default=(1, 1)). Cannot be negative.</span>
<span class="sd">            If it is a float, the factor is uniformly chosen from the range [max(0, 1-saturation), 1+saturation].</span>
<span class="sd">            If it is a sequence, it should be [min, max] for the range.</span>
<span class="sd">        hue (Union[float, tuple], optional): Hue adjustment factor (default=(0, 0)).</span>
<span class="sd">            If it is a float, the range will be [-hue, hue]. Value should be 0 &lt;= hue &lt;= 0.5.</span>
<span class="sd">            If it is a sequence, it should be [min, max] where -0.5 &lt;= min &lt;= max &lt;= 0.5.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomColorAdjust(0.4, 0.4, 0.4, 0.1),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_color_adjust</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">brightness</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">contrast</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">saturation</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">hue</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">brightness</span> <span class="o">=</span> <span class="n">brightness</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">contrast</span> <span class="o">=</span> <span class="n">contrast</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">saturation</span> <span class="o">=</span> <span class="n">saturation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hue</span> <span class="o">=</span> <span class="n">hue</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): Image to have its color adjusted randomly.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, Image after random adjustment of its color.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_color_adjust</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">brightness</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">contrast</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">saturation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hue</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomRotation"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomRotation.html#mindspore.dataset.vision.py_transforms.RandomRotation">[docs]</a><span class="k">class</span> <span class="nc">RandomRotation</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rotate the input PIL image by a random angle.</span>

<span class="sd">    Note:</span>
<span class="sd">        See https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.rotate.</span>

<span class="sd">    Args:</span>
<span class="sd">        degrees (Union[int, float, sequence]): Range of random rotation degrees.</span>
<span class="sd">            If degrees is a number, the range will be converted to (-degrees, degrees).</span>
<span class="sd">            If degrees is a sequence, it should be (min, max).</span>
<span class="sd">        resample (Inter mode, optional): An optional resampling filter (default=Inter.NEAREST).</span>
<span class="sd">            If omitted, or if the image has mode &quot;1&quot; or &quot;P&quot;, it is set to be Inter.NEAREST.</span>
<span class="sd">            It can be any of [Inter.NEAREST, Inter.ANTIALIAS, Inter.BILINEAR, Inter.BICUBIC].</span>

<span class="sd">            - Inter.NEAREST, means the resampling method is nearest-neighbor interpolation.</span>

<span class="sd">            - Inter.ANTIALIAS, means the resampling method is antialias interpolation.</span>

<span class="sd">            - Inter.BILINEAR, means the resampling method is bilinear interpolation.</span>

<span class="sd">            - Inter.BICUBIC, means the resampling method is bicubic interpolation.</span>

<span class="sd">        expand (bool, optional):  Optional expansion flag (default=False). If set to True, expand the output</span>
<span class="sd">            image to make it large enough to hold the entire rotated image.</span>
<span class="sd">            If set to False or omitted, make the output image the same size as the input.</span>
<span class="sd">            Note that the expand flag assumes rotation around the center and no translation.</span>
<span class="sd">        center (tuple, optional): Optional center of rotation (a 2-tuple) (default=None).</span>
<span class="sd">            Origin is the top left corner. Default None sets to the center of the image.</span>
<span class="sd">        fill_value (int or tuple, optional): Optional fill color for the area outside the rotated</span>
<span class="sd">            image (default=0).</span>
<span class="sd">            If it is a 3-tuple, it is used for R, G, B channels respectively.</span>
<span class="sd">            If it is an integer, it is used for all RGB channels. Default is 0.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomRotation(30),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_rotation</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degrees</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">NEAREST</span><span class="p">,</span> <span class="n">expand</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">=</span> <span class="n">degrees</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resample</span> <span class="o">=</span> <span class="n">DE_PY_INTER_MODE</span><span class="p">[</span><span class="n">resample</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">expand</span> <span class="o">=</span> <span class="n">expand</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">center</span> <span class="o">=</span> <span class="n">center</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span> <span class="o">=</span> <span class="n">fill_value</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): Image to be rotated.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, rotated image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_rotation</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">resample</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">expand</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">center</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span><span class="p">)</span></div>


<div class="viewcode-block" id="FiveCrop"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.FiveCrop.html#mindspore.dataset.vision.py_transforms.FiveCrop">[docs]</a><span class="k">class</span> <span class="nc">FiveCrop</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate 5 cropped images (one central image and four corners images).</span>

<span class="sd">    Args:</span>
<span class="sd">        size (int or sequence): The output size of the crop.</span>
<span class="sd">            If size is an integer, a square crop of size (size, size) is returned.</span>
<span class="sd">            If size is a sequence of length 2, it should be (height, width).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.FiveCrop(size=200),</span>
<span class="sd">        ...                            # 4D stack of 5 images</span>
<span class="sd">        ...                            lambda *images: numpy.stack([py_vision.ToTensor()(image) for image in images])])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_five_crop</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): PIL image to be cropped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            img_tuple (tuple), a tuple of 5 PIL images</span>
<span class="sd">                (top_left, top_right, bottom_left, bottom_right, center).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">five_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">)</span></div>


<div class="viewcode-block" id="TenCrop"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.TenCrop.html#mindspore.dataset.vision.py_transforms.TenCrop">[docs]</a><span class="k">class</span> <span class="nc">TenCrop</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate 10 cropped images (first 5 images from FiveCrop, second 5 images from their flipped version</span>
<span class="sd">    as per input flag to flip vertically or horizontally).</span>

<span class="sd">    Args:</span>
<span class="sd">        size (Union[int, sequence]): The output size of the crop.</span>
<span class="sd">            If size is an integer, a square crop of size (size, size) is returned.</span>
<span class="sd">            If size is a sequence of length 2, it should be (height, width).</span>
<span class="sd">        use_vertical_flip (bool, optional): Flip the image vertically instead of horizontally</span>
<span class="sd">            if set to True (default=False).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.TenCrop(size=200),</span>
<span class="sd">        ...                            # 4D stack of 10 images</span>
<span class="sd">        ...                            lambda *images: numpy.stack([py_vision.ToTensor()(image) for image in images])])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_ten_crop</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">use_vertical_flip</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_vertical_flip</span> <span class="o">=</span> <span class="n">use_vertical_flip</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): PIL image to be cropped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            img_tuple (tuple), a tuple of 10 PIL images</span>
<span class="sd">                (top_left, top_right, bottom_left, bottom_right, center) of original image +</span>
<span class="sd">                (top_left, top_right, bottom_left, bottom_right, center) of flipped image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">ten_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_vertical_flip</span><span class="p">)</span></div>


<div class="viewcode-block" id="Grayscale"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Grayscale.html#mindspore.dataset.vision.py_transforms.Grayscale">[docs]</a><span class="k">class</span> <span class="nc">Grayscale</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert the input PIL image to grayscale image.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_output_channels (int): Number of channels of the output grayscale image (1 or 3).</span>
<span class="sd">            Default is 1. If set to 3, the returned image has 3 identical RGB channels.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.Grayscale(3),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_num_channels</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_output_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_output_channels</span> <span class="o">=</span> <span class="n">num_output_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): PIL image to be converted to grayscale.</span>

<span class="sd">        Returns:</span>
<span class="sd">            img (PIL image), grayscaled image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">grayscale</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">num_output_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_output_channels</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomGrayscale"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomGrayscale.html#mindspore.dataset.vision.py_transforms.RandomGrayscale">[docs]</a><span class="k">class</span> <span class="nc">RandomGrayscale</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly convert the input image into grayscale image with a given probability.</span>

<span class="sd">    Args:</span>
<span class="sd">        prob (float, optional): Probability of the image being converted to grayscale (default=0.1).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomGrayscale(0.3),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_prob</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): PIL image to be converted to grayscale randomly.</span>

<span class="sd">        Returns:</span>
<span class="sd">            img (PIL image), Randomly apply grayscale to image, same number of channels as the input image.</span>
<span class="sd">                If input image has 1 channel, the output grayscale image is 1 channel.</span>
<span class="sd">                If input image has 3 channels, the output image has 3 identical grayscale channels.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">img</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;L&#39;</span><span class="p">:</span>
            <span class="n">num_output_channels</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">num_output_channels</span> <span class="o">=</span> <span class="mi">3</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">&gt;</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">grayscale</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">num_output_channels</span><span class="o">=</span><span class="n">num_output_channels</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span></div>


<div class="viewcode-block" id="Pad"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Pad.html#mindspore.dataset.vision.py_transforms.Pad">[docs]</a><span class="k">class</span> <span class="nc">Pad</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Pad the input PIL image according to padding parameters.</span>

<span class="sd">    Args:</span>
<span class="sd">        padding (Union[int, sequence]): The number of pixels to pad the image.</span>
<span class="sd">            If a single number is provided, pad all borders with this value.</span>
<span class="sd">            If a tuple or list of 2 values is provided, pad the left and top</span>
<span class="sd">            with the first value and the right and bottom with the second value.</span>
<span class="sd">            If 4 values are provided as a list or tuple,</span>
<span class="sd">            pad the left, top, right and bottom respectively.</span>
<span class="sd">        fill_value (Union[int, tuple], optional): The pixel intensity of the borders, only valid for</span>
<span class="sd">            padding_mode Border.CONSTANT (default=0).</span>
<span class="sd">            If it is an integer, it is used for all RGB channels.</span>
<span class="sd">            If it is a 3-tuple, it is used to fill R, G, B channels respectively.</span>
<span class="sd">        padding_mode (Border mode, optional): The method of padding (default=Border.CONSTANT).</span>
<span class="sd">            It can be any of [Border.CONSTANT, Border.EDGE, Border.REFLECT, Border.SYMMETRIC].</span>

<span class="sd">            - Border.CONSTANT, means it fills the border with constant values.</span>

<span class="sd">            - Border.EDGE, means it pads with the last value on the edge.</span>

<span class="sd">            - Border.REFLECT, means it reflects the values on the edge omitting the last</span>
<span class="sd">              value of edge.</span>

<span class="sd">            - Border.SYMMETRIC, means it reflects the values on the edge repeating the last</span>
<span class="sd">              value of edge.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            # adds 10 pixels (default black) to each side of the border of the image</span>
<span class="sd">        ...                            py_vision.Pad(padding=10),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_pad</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="n">Border</span><span class="o">.</span><span class="n">CONSTANT</span><span class="p">):</span>
        <span class="n">parse_padding</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span> <span class="o">=</span> <span class="n">fill_value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span> <span class="o">=</span> <span class="n">DE_PY_BORDER_TYPE</span><span class="p">[</span><span class="n">padding_mode</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): Image to be padded.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, padded image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomPerspective"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomPerspective.html#mindspore.dataset.vision.py_transforms.RandomPerspective">[docs]</a><span class="k">class</span> <span class="nc">RandomPerspective</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly apply perspective transformation to the input PIL image with a given probability.</span>

<span class="sd">    Args:</span>
<span class="sd">        distortion_scale (float, optional): The scale of distortion, a float value between 0 and 1 (default=0.5).</span>
<span class="sd">        prob (float, optional): Probability of the image being applied perspective transformation (default=0.5).</span>
<span class="sd">        interpolation (Inter mode, optional): Image interpolation mode (default=Inter.BICUBIC).</span>
<span class="sd">            It can be any of [Inter.BILINEAR, Inter.NEAREST, Inter.BICUBIC].</span>

<span class="sd">            - Inter.BILINEAR, means the interpolation method is bilinear interpolation.</span>

<span class="sd">            - Inter.NEAREST, means the interpolation method is nearest-neighbor interpolation.</span>

<span class="sd">            - Inter.BICUBIC, means the interpolation method is bicubic interpolation.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomPerspective(prob=0.1),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_perspective</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">distortion_scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distortion_scale</span> <span class="o">=</span> <span class="n">distortion_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span> <span class="o">=</span> <span class="n">DE_PY_INTER_MODE</span><span class="p">[</span><span class="n">interpolation</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): PIL image to apply perspective transformation randomly.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, image after being randomly perspective transformed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_pil</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input image should be a Pillow image.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">&gt;</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">():</span>
            <span class="n">start_points</span><span class="p">,</span> <span class="n">end_points</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">get_perspective_params</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">distortion_scale</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">perspective</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">start_points</span><span class="p">,</span> <span class="n">end_points</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span></div>


<div class="viewcode-block" id="RandomErasing"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomErasing.html#mindspore.dataset.vision.py_transforms.RandomErasing">[docs]</a><span class="k">class</span> <span class="nc">RandomErasing</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Erase the pixels, within a selected rectangle region, to the given value.</span>

<span class="sd">    Randomly applied on the input NumPy image array of shape (C, H, W) with a given probability.</span>

<span class="sd">    Zhun Zhong et al. &#39;Random Erasing Data Augmentation&#39; 2017 See https://arxiv.org/pdf/1708.04896.pdf</span>

<span class="sd">    Args:</span>
<span class="sd">        prob (float, optional): Probability of applying RandomErasing (default=0.5).</span>
<span class="sd">        scale (sequence of floats, optional): Range of the relative erase area to the</span>
<span class="sd">            original image (default=(0.02, 0.33)).</span>
<span class="sd">        ratio (sequence of floats, optional): Range of the aspect ratio of the erase</span>
<span class="sd">            area (default=(0.3, 3.3)).</span>
<span class="sd">        value (Union[int, sequence, string]): Erasing value (default=0).</span>
<span class="sd">            If value is a single intieger, it is applied to all pixels to be erased.</span>
<span class="sd">            If value is a sequence of length 3, it is applied to R, G, B channels respectively.</span>
<span class="sd">            If value is a string &#39;random&#39;, the erase value will be obtained from a standard normal distribution.</span>
<span class="sd">        inplace (bool, optional): Apply this transform in-place (default=False).</span>
<span class="sd">        max_attempts (int, optional): The maximum number of attempts to propose a valid</span>
<span class="sd">            erase_area (default=10). If exceeded, return the original image.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.RandomErasing(value=&#39;random&#39;)])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_erasing</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">),</span> <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.3</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_attempts</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span> <span class="o">=</span> <span class="n">ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span> <span class="o">=</span> <span class="n">inplace</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_attempts</span> <span class="o">=</span> <span class="n">max_attempts</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">np_img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            np_img (numpy.ndarray): NumPy image array of shape (C, H, W) to be randomly erased.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np_img (numpy.ndarray), Erased NumPy image array.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">bounded</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">&gt;</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">():</span>
            <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">erase_h</span><span class="p">,</span> <span class="n">erase_w</span><span class="p">,</span> <span class="n">erase_value</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">get_erase_params</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span><span class="p">,</span>
                                                                        <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">bounded</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_attempts</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">erase</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">erase_h</span><span class="p">,</span> <span class="n">erase_w</span><span class="p">,</span> <span class="n">erase_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np_img</span></div>


<div class="viewcode-block" id="Cutout"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Cutout.html#mindspore.dataset.vision.py_transforms.Cutout">[docs]</a><span class="k">class</span> <span class="nc">Cutout</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly cut (mask) out a given number of square patches from the input NumPy image array of shape (C, H, W).</span>

<span class="sd">    Terrance DeVries and Graham W. Taylor &#39;Improved Regularization of Convolutional Neural Networks with Cutout&#39; 2017</span>
<span class="sd">    See https://arxiv.org/pdf/1708.04552.pdf</span>

<span class="sd">    Args:</span>
<span class="sd">        length (int): The side length of each square patch.</span>
<span class="sd">        num_patches (int, optional): Number of patches to be cut out of an image (default=1).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.Cutout(80)])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_cutout</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">num_patches</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">length</span> <span class="o">=</span> <span class="n">length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_patches</span> <span class="o">=</span> <span class="n">num_patches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">np_img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            np_img (numpy.ndarray): NumPy image array of shape (C, H, W) to be cut out.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np_img (numpy.ndarray), NumPy image array with square patches cut out.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;img should be NumPy array. Got </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">np_img</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">np_img</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;img dimension should be 3. Got </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np_img</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">image_h</span><span class="p">,</span> <span class="n">image_w</span> <span class="o">=</span> <span class="n">np_img</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">length</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">length</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">image_h</span> <span class="o">*</span> <span class="n">image_w</span><span class="p">)</span>
        <span class="n">bounded</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_patches</span><span class="p">):</span>
            <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">erase_h</span><span class="p">,</span> <span class="n">erase_w</span><span class="p">,</span> <span class="n">erase_value</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">get_erase_params</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">scale</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">bounded</span><span class="p">,</span>
                                                                        <span class="mi">1</span><span class="p">)</span>
            <span class="n">np_img</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">erase</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">erase_h</span><span class="p">,</span> <span class="n">erase_w</span><span class="p">,</span> <span class="n">erase_value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np_img</span></div>


<div class="viewcode-block" id="LinearTransformation"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.LinearTransformation.html#mindspore.dataset.vision.py_transforms.LinearTransformation">[docs]</a><span class="k">class</span> <span class="nc">LinearTransformation</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply linear transformation to the input NumPy image array, given a square transformation matrix and</span>
<span class="sd">    a mean vector.</span>

<span class="sd">    The transformation first flattens the input array and subtracts the mean vector from it. It then computes</span>
<span class="sd">    the dot product with the transformation matrix, and reshapes it back to its original shape.</span>

<span class="sd">    Args:</span>
<span class="sd">        transformation_matrix (numpy.ndarray): a square transformation matrix of shape (D, D), where</span>
<span class="sd">            :math:`D = C \times H \times W`.</span>
<span class="sd">        mean_vector (numpy.ndarray): a NumPy ndarray of shape (D,) where :math:`D = C \times H \times W`.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; height, width = 32, 32</span>
<span class="sd">        &gt;&gt;&gt; dim = 3 * height * width</span>
<span class="sd">        &gt;&gt;&gt; transformation_matrix = np.ones([dim, dim])</span>
<span class="sd">        &gt;&gt;&gt; mean_vector = np.zeros(dim)</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.Resize((height,width)),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.LinearTransformation(transformation_matrix, mean_vector)])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_linear_transform</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transformation_matrix</span><span class="p">,</span> <span class="n">mean_vector</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformation_matrix</span> <span class="o">=</span> <span class="n">transformation_matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_vector</span> <span class="o">=</span> <span class="n">mean_vector</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">np_img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            np_img (numpy.ndarray): NumPy image array of shape (C, H, W) to be linear transformed.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np_img (numpy.ndarray), Linear transformed image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">linear_transform</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformation_matrix</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_vector</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomAffine"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomAffine.html#mindspore.dataset.vision.py_transforms.RandomAffine">[docs]</a><span class="k">class</span> <span class="nc">RandomAffine</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply Random affine transformation to the input PIL image.</span>

<span class="sd">    Args:</span>
<span class="sd">        degrees (Union[int, float, sequence]): Range of the rotation degrees.</span>
<span class="sd">            If degrees is a number, the range will be (-degrees, degrees).</span>
<span class="sd">            If degrees is a sequence, it should be (min, max).</span>
<span class="sd">        translate (sequence, optional): Sequence (tx, ty) of maximum translation in</span>
<span class="sd">            x(horizontal) and y(vertical) directions (default=None).</span>
<span class="sd">            The horizontal shift and vertical shift are selected randomly from the range:</span>
<span class="sd">            (-tx*width, tx*width) and (-ty*height, ty*height), respectively.</span>
<span class="sd">            If None, no translations are applied.</span>
<span class="sd">        scale (sequence, optional): Scaling factor interval (default=None, original scale is used).</span>
<span class="sd">        shear (Union[int, float, sequence], optional): Range of shear factor (default=None).</span>
<span class="sd">            If shear is an integer, then a shear parallel to the X axis in the range of (-shear, +shear) is applied.</span>
<span class="sd">            If shear is a tuple or list of size 2, then a shear parallel to the X axis in the range of</span>
<span class="sd">            (shear[0], shear[1]) is applied.</span>
<span class="sd">            If shear is a tuple of list of size 4, then a shear parallel to X axis in the range of</span>
<span class="sd">            (shear[0], shear[1]) and a shear parallel to Y axis in the range of (shear[2], shear[3]) is applied.</span>
<span class="sd">            If shear is None, no shear is applied.</span>
<span class="sd">        resample (Inter mode, optional): An optional resampling filter (default=Inter.NEAREST).</span>
<span class="sd">            If omitted, or if the image has mode &quot;1&quot; or &quot;P&quot;, it is set to be Inter.NEAREST.</span>
<span class="sd">            It can be any of [Inter.BILINEAR, Inter.NEAREST, Inter.BICUBIC].</span>

<span class="sd">            - Inter.BILINEAR, means resample method is bilinear interpolation.</span>

<span class="sd">            - Inter.NEAREST, means resample method is nearest-neighbor interpolation.</span>

<span class="sd">            - Inter.BICUBIC, means resample method is bicubic interpolation.</span>

<span class="sd">        fill_value (Union[tuple, int], optional): Optional filling value to fill the area outside the transform</span>
<span class="sd">            in the output image. There must be three elements in the tuple and the value of a single element is</span>
<span class="sd">            within the range [0, 255].</span>
<span class="sd">            Used only in Pillow versions &gt; 5.0.0 (default=0, filling is performed).</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If degrees is negative.</span>
<span class="sd">        ValueError: If translation value is not between 0 and 1.</span>
<span class="sd">        ValueError: If scale is not positive.</span>
<span class="sd">        ValueError: If shear is a number but is not positive.</span>
<span class="sd">        TypeError: If degrees is not a number or a list or a tuple.</span>
<span class="sd">            If degrees is a list or tuple, its length is not 2.</span>
<span class="sd">        TypeError: If translate is specified but is not list or a tuple of length 2.</span>
<span class="sd">        TypeError: If scale is not a list or tuple of length 2.</span>
<span class="sd">        TypeError: If shear is not a list or tuple of length 2 or 4.</span>
<span class="sd">        TypeError: If fill_value is not a single integer or a 3-tuple.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_affine</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degrees</span><span class="p">,</span> <span class="n">translate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shear</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">NEAREST</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="c1"># Parameter checking</span>
        <span class="c1"># rotation</span>
        <span class="k">if</span> <span class="n">shear</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shear</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">):</span>
                <span class="n">shear</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">shear</span><span class="p">,</span> <span class="n">shear</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shear</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="n">shear</span> <span class="o">=</span> <span class="p">[</span><span class="n">shear</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shear</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]</span>
                <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shear</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                    <span class="n">shear</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">shear</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">degrees</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">):</span>
            <span class="n">degrees</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">degrees</span><span class="p">,</span> <span class="n">degrees</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">=</span> <span class="n">degrees</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">translate</span> <span class="o">=</span> <span class="n">translate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_ranges</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shear</span> <span class="o">=</span> <span class="n">shear</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resample</span> <span class="o">=</span> <span class="n">DE_PY_INTER_MODE</span><span class="p">[</span><span class="n">resample</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span> <span class="o">=</span> <span class="n">fill_value</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): Image to apply affine transformation.</span>

<span class="sd">        Returns:</span>
<span class="sd">            img (PIL image), Randomly affine transformed image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_affine</span><span class="p">(</span><span class="n">img</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">translate</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">scale_ranges</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">shear</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">resample</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span><span class="p">)</span></div>


<div class="viewcode-block" id="MixUp"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.MixUp.html#mindspore.dataset.vision.py_transforms.MixUp">[docs]</a><span class="k">class</span> <span class="nc">MixUp</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply mix up transformation to the input image and label. Make one input data combined with others.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch_size (int): Batch size of dataset.</span>
<span class="sd">        alpha (float):  Mix up rate.</span>
<span class="sd">        is_single (bool): Identify if single batch or multi-batch mix up transformation is to be used</span>
<span class="sd">            (Default=True, which is single batch).</span>


<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; # Setup multi-batch mixup transformation</span>
<span class="sd">        &gt;&gt;&gt; transform = [py_vision.MixUp(batch_size=16, alpha=0.2, is_single=False)]</span>
<span class="sd">        &gt;&gt;&gt; # Apply the transform to the dataset through dataset.map()</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(input_columns=&quot;image&quot;,</span>
<span class="sd">        ...                                                 operations=transform)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_mix_up</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">is_single</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_first</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_single</span> <span class="o">=</span> <span class="n">is_single</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            image (numpy.ndarray): NumPy image to apply mix up transformation.</span>
<span class="sd">            label(numpy.ndarray): NumPy label to apply mix up transformation.</span>

<span class="sd">        Returns:</span>
<span class="sd">            image (numpy.ndarray): NumPy image after applying mix up transformation.</span>
<span class="sd">            label(numpy.ndarray): NumPy label after applying mix up transformation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_single</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">mix_up_single</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">mix_up_muti</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span></div>


<span class="k">class</span> <span class="nc">RgbToBgr</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a NumPy RGB image or a batch of NumPy RGB images to BGR images.</span>

<span class="sd">    Args:</span>
<span class="sd">        is_hwc (bool): The flag of image shape, (H, W, C) or (N, H, W, C) if True</span>
<span class="sd">                       and (C, H, W) or (N, C, H, W) if False (default=False).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.CenterCrop(20),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.RgbToBgr()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_rgb_to_bgr</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">is_hwc</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span> <span class="o">=</span> <span class="n">is_hwc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rgb_imgs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            rgb_imgs (numpy.ndarray): NumPy RGB images array of shape (H, W, C) or (N, H, W, C),</span>
<span class="sd">                                      or (C, H, W) or (N, C, H, W) to be converted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bgr_img (numpy.ndarray), NumPy BGR images array with same shape of rgb_imgs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">rgb_to_bgrs</span><span class="p">(</span><span class="n">rgb_imgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span><span class="p">)</span>



<div class="viewcode-block" id="RgbToHsv"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RgbToHsv.html#mindspore.dataset.vision.py_transforms.RgbToHsv">[docs]</a><span class="k">class</span> <span class="nc">RgbToHsv</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a NumPy RGB image or a batch of NumPy RGB images to HSV images.</span>

<span class="sd">    Args:</span>
<span class="sd">        is_hwc (bool): The flag of image shape, (H, W, C) or (N, H, W, C) if True</span>
<span class="sd">                       and (C, H, W) or (N, C, H, W) if False (default=False).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.CenterCrop(20),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.RgbToHsv()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_rgb_to_hsv</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">is_hwc</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span> <span class="o">=</span> <span class="n">is_hwc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rgb_imgs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            rgb_imgs (numpy.ndarray): NumPy RGB images array of shape (H, W, C) or (N, H, W, C),</span>
<span class="sd">                                      or (C, H, W) or (N, C, H, W) to be converted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np_hsv_img (numpy.ndarray), NumPy HSV images with same shape of rgb_imgs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">rgb_to_hsvs</span><span class="p">(</span><span class="n">rgb_imgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span><span class="p">)</span></div>


<div class="viewcode-block" id="HsvToRgb"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.HsvToRgb.html#mindspore.dataset.vision.py_transforms.HsvToRgb">[docs]</a><span class="k">class</span> <span class="nc">HsvToRgb</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a NumPy HSV image or one batch NumPy HSV images to RGB images.</span>

<span class="sd">    Args:</span>
<span class="sd">        is_hwc (bool): The flag of image shape, (H, W, C) or (N, H, W, C) if True</span>
<span class="sd">                       and (C, H, W) or (N, C, H, W) if False (default=False).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.CenterCrop(20),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.HsvToRgb()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_hsv_to_rgb</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">is_hwc</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span> <span class="o">=</span> <span class="n">is_hwc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hsv_imgs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            hsv_imgs (numpy.ndarray): NumPy HSV images array of shape (H, W, C) or (N, H, W, C),</span>
<span class="sd">                                      or (C, H, W) or (N, C, H, W) to be converted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            rgb_imgs (numpy.ndarray), NumPy RGB image with same shape of hsv_imgs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">hsv_to_rgbs</span><span class="p">(</span><span class="n">hsv_imgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomColor"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomColor.html#mindspore.dataset.vision.py_transforms.RandomColor">[docs]</a><span class="k">class</span> <span class="nc">RandomColor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Adjust the color of the input PIL image by a random degree.</span>

<span class="sd">    Args:</span>
<span class="sd">        degrees (sequence): Range of random color adjustment degrees.</span>
<span class="sd">            It should be in (min, max) format (default=(0.1,1.9)).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomColor((0.5, 2.0)),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_positive_degrees</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degrees</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">=</span> <span class="n">degrees</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): Image to be color adjusted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            img (PIL image), Color adjusted image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_color</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomSharpness"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomSharpness.html#mindspore.dataset.vision.py_transforms.RandomSharpness">[docs]</a><span class="k">class</span> <span class="nc">RandomSharpness</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Adjust the sharpness of the input PIL image by a fixed or random degree. Degree of 0.0 gives a blurred image,</span>
<span class="sd">    degree of 1.0 gives the original image, and degree of 2.0 gives a sharpened image.</span>

<span class="sd">    Args:</span>
<span class="sd">        degrees (sequence): Range of random sharpness adjustment degrees.</span>
<span class="sd">            It should be in (min, max) format (default=(0.1,1.9)).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomSharpness((0.5, 1.5)),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_positive_degrees</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degrees</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">=</span> <span class="n">degrees</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): Image to be sharpness adjusted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            img (PIL image), Color adjusted image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_sharpness</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span><span class="p">)</span></div>


<div class="viewcode-block" id="AutoContrast"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.AutoContrast.html#mindspore.dataset.vision.py_transforms.AutoContrast">[docs]</a><span class="k">class</span> <span class="nc">AutoContrast</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Automatically maximize the contrast of the input PIL image.</span>

<span class="sd">    Args:</span>
<span class="sd">        cutoff (float, optional): Percent of pixels to cut off from the histogram,</span>
<span class="sd">            the value must be in the range [0.0, 50.0) (default=0.0).</span>
<span class="sd">        ignore (Union[int, sequence], optional): Pixel values to ignore (default=None).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.AutoContrast(),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_auto_contrast</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cutoff</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">ignore</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span> <span class="o">=</span> <span class="n">cutoff</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignore</span> <span class="o">=</span> <span class="n">ignore</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): Image to be augmented with AutoContrast.</span>

<span class="sd">        Returns:</span>
<span class="sd">            img (PIL image), Augmented image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">auto_contrast</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore</span><span class="p">)</span></div>


<div class="viewcode-block" id="Invert"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Invert.html#mindspore.dataset.vision.py_transforms.Invert">[docs]</a><span class="k">class</span> <span class="nc">Invert</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Invert colors of input PIL image.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.Invert(),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): Image to be color Inverted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            img (PIL image), Color inverted image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">invert_color</span><span class="p">(</span><span class="n">img</span><span class="p">)</span></div>


<div class="viewcode-block" id="Equalize"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Equalize.html#mindspore.dataset.vision.py_transforms.Equalize">[docs]</a><span class="k">class</span> <span class="nc">Equalize</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Equalize the histogram of input PIL image.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.Equalize(),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): Image to be equalized.</span>

<span class="sd">        Returns:</span>
<span class="sd">            img (PIL image), Equalized image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">equalize</span><span class="p">(</span><span class="n">img</span><span class="p">)</span></div>


<div class="viewcode-block" id="UniformAugment"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.UniformAugment.html#mindspore.dataset.vision.py_transforms.UniformAugment">[docs]</a><span class="k">class</span> <span class="nc">UniformAugment</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Uniformly select and apply a number of transforms sequentially from</span>
<span class="sd">    a list of transforms. Randomly assign a probability to each transform for</span>
<span class="sd">    each image to decide whether to apply the transform or not.</span>

<span class="sd">    All the transforms in transform list must have the same input/output data type.</span>

<span class="sd">    Args:</span>
<span class="sd">         transforms (list): List of transformations to be chosen from to apply.</span>
<span class="sd">         num_ops (int, optional): number of transforms to sequentially apply (default=2).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms = [py_vision.CenterCrop(64),</span>
<span class="sd">        ...               py_vision.RandomColor(),</span>
<span class="sd">        ...               py_vision.RandomSharpness(),</span>
<span class="sd">        ...               py_vision.RandomRotation(30)]</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.UniformAugment(transforms),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_uniform_augment_py</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">num_ops</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">transforms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_ops</span> <span class="o">=</span> <span class="n">num_ops</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): Image to apply transformation.</span>

<span class="sd">        Returns:</span>
<span class="sd">            img (PIL image), Transformed image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">uniform_augment</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_ops</span><span class="p">)</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>