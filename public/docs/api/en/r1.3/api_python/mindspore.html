

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindspore &mdash; MindSpore master documentation</title>
  

  
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="mindspore.common.initializer" href="mindspore.common.initializer.html" />
    <link rel="prev" title="MindSpore API" href="../index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">MindSpore Python API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.compression.html">mindspore.compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.explainer.html">mindspore.explainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.profiler.html">mindspore.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.train.html">mindspore.train</a></li>
</ul>
<p class="caption"><span class="caption-text">MindSpore C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.3/api_cpp/class_list.html">Lite</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>mindspore</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/api_python/mindspore.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="mindspore">
<h1>mindspore<a class="headerlink" href="#mindspore" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="mindspore.dtype">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">dtype</code><a class="headerlink" href="#mindspore.dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a data type object of MindSpore.</p>
<p>The actual path of <code class="docutils literal notranslate"><span class="pre">dtype</span></code> is <code class="docutils literal notranslate"><span class="pre">/mindspore/common/dtype.py</span></code>.
Run the following command to import the package:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
</pre></div>
</div>
<ul>
<li><p><strong>Numeric Type</strong></p>
<p>Currently, MindSpore supports <code class="docutils literal notranslate"><span class="pre">Int</span></code> type, <code class="docutils literal notranslate"><span class="pre">Uint</span></code> type and <code class="docutils literal notranslate"><span class="pre">Float</span></code> type.
The following table lists the details.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 61%" />
<col style="width: 39%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Definition</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.int8</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.byte</span></code></p></td>
<td><p>8-bit integer</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.int16</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.short</span></code></p></td>
<td><p>16-bit integer</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.int32</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.intc</span></code></p></td>
<td><p>32-bit integer</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.int64</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.intp</span></code></p></td>
<td><p>64-bit integer</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.uint8</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.ubyte</span></code></p></td>
<td><p>unsigned 8-bit integer</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.uint16</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.ushort</span></code></p></td>
<td><p>unsigned 16-bit integer</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.uint32</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.uintc</span></code></p></td>
<td><p>unsigned 32-bit integer</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.uint64</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.uintp</span></code></p></td>
<td><p>unsigned 64-bit integer</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.float16</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.half</span></code></p></td>
<td><p>16-bit floating-point number</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.float32</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.single</span></code></p></td>
<td><p>32-bit floating-point number</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mindspore.float64</span></code> ,  <code class="docutils literal notranslate"><span class="pre">mindspore.double</span></code></p></td>
<td><p>64-bit floating-point number</p></td>
</tr>
</tbody>
</table>
</li>
<li><p><strong>Other Type</strong></p>
<p>For other defined types, see the following table.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 85%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">tensor</span></code></p></td>
<td><p>MindSpore’s <code class="docutils literal notranslate"><span class="pre">tensor</span></code> type. Data format uses NCHW. For details, see <a class="reference external" href="https://www.gitee.com/mindspore/mindspore/blob/r1.3/mindspore/common/tensor.py">tensor</a>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">bool_</span></code></p></td>
<td><p>Boolean <code class="docutils literal notranslate"><span class="pre">True</span></code> or <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">int_</span></code></p></td>
<td><p>Integer scalar.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">uint</span></code></p></td>
<td><p>Unsigned integer scalar.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">float_</span></code></p></td>
<td><p>Floating-point scalar.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">number</span></code></p></td>
<td><p>Number, including <code class="docutils literal notranslate"><span class="pre">int_</span></code> , <code class="docutils literal notranslate"><span class="pre">uint</span></code> , <code class="docutils literal notranslate"><span class="pre">float_</span></code> and <code class="docutils literal notranslate"><span class="pre">bool_</span></code> .</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">list_</span></code></p></td>
<td><p>List constructed by <code class="docutils literal notranslate"><span class="pre">tensor</span></code> , such as <code class="docutils literal notranslate"><span class="pre">List[T0,T1,...,Tn]</span></code> , where the element <code class="docutils literal notranslate"><span class="pre">Ti</span></code> can be of different types.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">tuple_</span></code></p></td>
<td><p>Tuple constructed by <code class="docutils literal notranslate"><span class="pre">tensor</span></code> , such as <code class="docutils literal notranslate"><span class="pre">Tuple[T0,T1,...,Tn]</span></code> , where the element <code class="docutils literal notranslate"><span class="pre">Ti</span></code> can be of different types.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">function</span></code></p></td>
<td><p>Function. Return in two ways, when function is not None, returns Func directly, the other returns Func(args: List[T0,T1,…,Tn], retval: T) when function is None.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">type_type</span></code></p></td>
<td><p>Type definition of type.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">type_none</span></code></p></td>
<td><p>No matching return type, corresponding to the <code class="docutils literal notranslate"><span class="pre">type(None)</span></code> in Python.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">symbolic_key</span></code></p></td>
<td><p>The value of a variable is used as a key of the variable in <code class="docutils literal notranslate"><span class="pre">env_type</span></code> .</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">env_type</span></code></p></td>
<td><p>Used to store the gradient of the free variable of a function, where the key is the <code class="docutils literal notranslate"><span class="pre">symbolic_key</span></code> of the free variable’s node and the value is the gradient.</p></td>
</tr>
</tbody>
</table>
</li>
<li><p><strong>Tree Topology</strong></p>
<p>The relationships of the above types are as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>└─────── number
    │   ├─── bool_
    │   ├─── int_
    │   │   ├─── int8, byte
    │   │   ├─── int16, short
    │   │   ├─── int32, intc
    │   │   └─── int64, intp
    │   ├─── uint
    │   │   ├─── uint8, ubyte
    │   │   ├─── uint16, ushort
    │   │   ├─── uint32, uintc
    │   │   └─── uint64, uintp
    │   └─── float_
    │       ├─── float16
    │       ├─── float32
    │       └─── float64
    ├─── tensor
    │   ├─── Array[Float32]
    │   └─── ...
    ├─── list_
    │   ├─── List[Int32,Float32]
    │   └─── ...
    ├─── tuple_
    │   ├─── Tuple[Int32,Float32]
    │   └─── ...
    ├─── function
    │   ├─── Func
    │   ├─── Func[(Int32, Float32), Int32]
    │   └─── ...
    ├─── type_type
    ├─── type_none
    ├─── symbolic_key
    └─── env_type
</pre></div>
</div>
</li>
</ul>
</dd></dl>

<span class="target" id="module-mindspore"></span><dl class="function">
<dt id="mindspore.run_check">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">run_check</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/run_check/run_check.html#run_check"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.run_check" title="Permalink to this definition">¶</a></dt>
<dd><p>Provide a convenient API to check if the installation is successful or failed.
If there is no return value, the verification status will be displayed directly.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mindspore</span><span class="o">.</span><span class="n">run_check</span><span class="p">()</span>
<span class="go">MindSpore version: xxx</span>
<span class="go">The result of multiplication calculation is correct, MindSpore has been installed successfully!</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="mindspore.dtype_to_nptype">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">dtype_to_nptype</code><span class="sig-paren">(</span><em class="sig-param">type_</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/dtype.html#dtype_to_nptype"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.dtype_to_nptype" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert MindSpore dtype to numpy data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>type_</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – MindSpore’s dtype.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The data type of numpy.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mindspore.issubclass_">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">issubclass_</code><span class="sig-paren">(</span><em class="sig-param">type_</em>, <em class="sig-param">dtype</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/dtype.html#issubclass_"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.issubclass_" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine whether <cite>type_</cite> is a subclass of <cite>dtype</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>type_</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – Target MindSpore dtype.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – Compare MindSpore dtype.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>bool, True or False.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mindspore.dtype_to_pytype">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">dtype_to_pytype</code><span class="sig-paren">(</span><em class="sig-param">type_</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/dtype.html#dtype_to_pytype"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.dtype_to_pytype" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert MindSpore dtype to python data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>type_</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – MindSpore’s dtype.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Type of python.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mindspore.pytype_to_dtype">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">pytype_to_dtype</code><span class="sig-paren">(</span><em class="sig-param">obj</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/dtype.html#pytype_to_dtype"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.pytype_to_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert python type to MindSpore type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>obj</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#type" title="(in Python v3.8)"><em>type</em></a>) – A python type object.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Type of MindSpore type.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mindspore.get_py_obj_dtype">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">get_py_obj_dtype</code><span class="sig-paren">(</span><em class="sig-param">obj</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/dtype.html#get_py_obj_dtype"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.get_py_obj_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the MindSpore data type, which corresponds to python type or variable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>obj</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#type" title="(in Python v3.8)"><em>type</em></a>) – An object of python type, or a variable of python type.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Type of MindSpore type.</p>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="mindspore.Tensor">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">Tensor</code><span class="sig-paren">(</span><em class="sig-param">input_data=None</em>, <em class="sig-param">dtype=None</em>, <em class="sig-param">shape=None</em>, <em class="sig-param">init=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Tensor is used for data storage.</p>
<p>Tensor inherits tensor object in C++.
Some functions are implemented in C++ and some functions are implemented in Python.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_data</strong> (<em>Union</em><em>[</em><a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>]</em>) – Input data of the tensor.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – Input data should be None, bool or numeric type defined in <cite>mindspore.dtype</cite>.
The argument is used to define the data type of the output tensor. If it is None, the data type of the
output tensor will be the same as the <cite>input_data</cite>. Default: None.</p></li>
<li><p><strong>shape</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – A list of integers, a tuple of integers or an integer as the shape of
output. If <cite>input_data</cite> is available, <cite>shape</cite> doesn’t need to be set. Default: None.</p></li>
<li><p><strong>init</strong> (<a class="reference internal" href="mindspore.common.initializer.html#mindspore.common.initializer.Initializer" title="mindspore.common.initializer.Initializer"><em>Initializer</em></a>) – The information of init data.
‘init’ is used for delayed initialization in parallel mode. Usually, it is not recommended to use
‘init’ interface to initialize parameters in other conditions. If ‘init’ interface is used to initialize
parameters, the <cite>Tensor.init_data</cite> API needs to be called to convert <cite>Tensor</cite> to the actual data.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Outputs:</dt><dd><p>Tensor. If <cite>dtype</cite> and <cite>shape</cite> are not set, return a tensor with the same dtype and shape as <cite>input_data</cite>.
If <cite>dtype</cite> or <cite>shape</cite> is set, the dtype or shape of the output Tensor is consistent with the setting.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">One</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize a tensor with input data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t1</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">t1</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">t1</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize a tensor with a float scalar</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t2</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">t2</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">t2</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">ms</span><span class="o">.</span><span class="n">float64</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize a tensor with init</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t3</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="n">One</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">t3</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">t3</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">t3</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore.Tensor.T">
<em class="property">property </em><code class="sig-name descname">T</code><a class="headerlink" href="#mindspore.Tensor.T" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the transposed tensor.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.abs">
<code class="sig-name descname">abs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.abs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.abs" title="Permalink to this definition">¶</a></dt>
<dd><p>Return absolute value element-wisely.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Tensor, with absolute value element-wisely.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">1.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[1.1 2.1]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.all">
<code class="sig-name descname">all</code><span class="sig-paren">(</span><em class="sig-param">axis=()</em>, <em class="sig-param">keep_dims=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.all"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.all" title="Permalink to this definition">¶</a></dt>
<dd><p>Check all array elements along a given axis evaluate to True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em>) – Dimensions of reduction,
when the axis is None or empty tuple, reduce all dimensions. Default: ().</p></li>
<li><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to keep the reduced dimensions. Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, if all array elements along the given axis evaluate to True, its value is True,
otherwise its value is False. If the axis is None or empty tuple, reduce all dimensions.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">False</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.any">
<code class="sig-name descname">any</code><span class="sig-paren">(</span><em class="sig-param">axis=()</em>, <em class="sig-param">keep_dims=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.any"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.any" title="Permalink to this definition">¶</a></dt>
<dd><p>Check any array element along a given axis evaluate to True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em>) – Dimensions of reduction,
when the axis is None or empty tuple, reduce all dimensions. Default: ().</p></li>
<li><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to keep the reduced dimensions. Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, if any array element along the given axis evaluates to True, its value is True,
otherwise its value is False. If the axis is None or empty tuple, reduce all dimensions.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.argmax">
<code class="sig-name descname">argmax</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.argmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.argmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the indices of the maximum values along an axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – By default, the index is into
the flattened tensor, otherwise along the specified axis.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, indices into the input tensor. It has the same
shape as self.shape with the dimension along axis removed.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – if the axis is out of range.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">argmax</span><span class="p">())</span>
<span class="go">5</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.argmin">
<code class="sig-name descname">argmin</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.argmin"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.argmin" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the indices of the minimum values along an axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – By default, the index is into
the flattened tensor, otherwise along the specified axis.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, indices into the input tensor. It has the same
shape as self.shape with the dimension along axis removed.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – if the axis is out of range.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">argmin</span><span class="p">())</span>
<span class="go">0</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.asnumpy">
<code class="sig-name descname">asnumpy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.asnumpy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.asnumpy" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert tensor to numpy array.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.astype">
<code class="sig-name descname">astype</code><span class="sig-paren">(</span><em class="sig-param">dtype</em>, <em class="sig-param">copy=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.astype"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.astype" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a copy of the tensor, cast to a specified type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dtype</strong> (Union[<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>, str]) – Designated tensor dtype, can be in format
of <code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype.float32</span></code> or <cite>float32</cite>.
Default: <code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype.float32</span></code>.</p></li>
<li><p><strong>copy</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – By default, astype always returns a newly allocated
tensor. If this is set to false, the input tensor is returned instead
of a copy if possible. Default: True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, with the designated dtype.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If <cite>dtype</cite> has types not specified above, or values cannot be understood.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;int32&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="go">Int32</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.choose">
<code class="sig-name descname">choose</code><span class="sig-paren">(</span><em class="sig-param">choices</em>, <em class="sig-param">mode=&quot;clip&quot;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.choose"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.choose" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct an array from an index array and a list of arrays to choose from.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>choices</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>]</em>) – Choice arrays. <cite>a</cite> and all of the <cite>choices</cite> must
be broadcasted to the same shape. If <cite>choices</cite> is itself an array, then
its outermost dimension (i.e., the one corresponding to <code class="docutils literal notranslate"><span class="pre">choices.shape[0]</span></code>)
is taken as defining the “sequence”.</p></li>
<li><p><strong>mode</strong> (<em>‘raise’</em><em>, </em><em>‘wrap’</em><em>, </em><em>‘clip’</em><em>, </em><em>optional</em>) – <p>Specifies how indices outside
<code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">n-1]</span></code> will be treated:</p>
<p>‘raise’ – raise an error (default);</p>
<p>‘wrap’ – wrap around;</p>
<p>‘clip’ – clip to the range. ‘clip’ mode means that all indices that are
too large are replaced by the index that addresses the last element
along that axis. Note that this disables indexing with negative numbers.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, the merged result.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – if the input tensor and any of the <cite>choices</cite> cannot be broadcast.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">choices</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">],</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">23</span><span class="p">],</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">33</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">choose</span><span class="p">(</span><span class="n">choices</span><span class="p">))</span>
<span class="go">[20 31 12  3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.clip">
<code class="sig-name descname">clip</code><span class="sig-paren">(</span><em class="sig-param">xmin</em>, <em class="sig-param">xmax</em>, <em class="sig-param">dtype=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.clip"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.clip" title="Permalink to this definition">¶</a></dt>
<dd><p>Clips (limits) the values in a Tensor.</p>
<p>Given an interval, values outside the interval are clipped to the interval edges.
For example, if an interval of <span class="math notranslate nohighlight">\([0, 1]\)</span> is specified, values smaller than 0 become 0,
and values larger than 1 become 1.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Currently, clip with <cite>xmin=nan</cite> or <cite>xmax=nan</cite> is not supported.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xmin</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><em>scalar</em><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a>) – Minimum value. If None, clipping is not performed
on lower interval edge. Not more than one of <cite>xmin</cite> and <cite>xmax</cite> may be None.</p></li>
<li><p><strong>xmax</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><em>scalar</em><em>, </em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a>) – Maximum value. If None, clipping is not performed
on upper interval edge. Not more than one of <cite>xmin</cite> and <cite>xmax</cite> may be None.
If <cite>xmin</cite> or <cite>xmax</cite> are tensors, then the three tensors will be broadcasted
to match their shapes.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>, optional) – Overrides the dtype of the
output Tensor. Default is None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, a tensor with the elements of input tensor, but where values
&lt; <cite>xmin</cite> are replaced with <cite>xmin</cite>, and those &gt; <cite>xmax</cite> with <cite>xmax</cite>.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If inputs have types not specified above.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the shapes of <cite>x1</cite> and <cite>x2</cite> cannot broadcast, or both <cite>xmin</cite> and <cite>xmax</cite> are <cite>None</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[1. 2. 2. 0. 0. 2. 2. 0.]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.copy">
<code class="sig-name descname">copy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.copy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a copy of the tensor.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The current implementation does not support <cite>order</cite> argument.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Copied tensor.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[1. 1. 1.]</span>
<span class="go">[1. 1. 1.]</span>
<span class="go">[1. 1. 1.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.cumsum">
<code class="sig-name descname">cumsum</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em>, <em class="sig-param">dtype=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.cumsum"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.cumsum" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the cumulative sum of the elements along a given axis.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <code class="docutils literal notranslate"><span class="pre">self.dtype</span></code> is <code class="xref py py-class docutils literal notranslate"><span class="pre">int8</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int16</span></code> or <a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, the result
<cite>dtype</cite> will be elevated to <code class="xref py py-class docutils literal notranslate"><span class="pre">int32</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int64</span></code> is not supported.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Axis along which the cumulative sum is computed. The
default (None) is to compute the cumsum over the flattened array.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>, optional) – If not specified, stay the same as original,
tensor, unless it has an integer dtype with a precision less than <code class="xref py py-class docutils literal notranslate"><span class="pre">float32</span></code>.
In that case, <code class="xref py py-class docutils literal notranslate"><span class="pre">float32</span></code> is used. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – if the axis is out of range.</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Tensor.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[1. 1. 1.]</span>
<span class="go">[2. 2. 2.]</span>
<span class="go">[3. 3. 3.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.diagonal">
<code class="sig-name descname">diagonal</code><span class="sig-paren">(</span><em class="sig-param">offset=0</em>, <em class="sig-param">axis1=0</em>, <em class="sig-param">axis2=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.diagonal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.diagonal" title="Permalink to this definition">¶</a></dt>
<dd><p>Return specified diagonals.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>offset</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Offset of the diagonal from the main diagonal.
Can be positive or negative. Defaults to main diagonal.</p></li>
<li><p><strong>axis1</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Axis to be used as the first axis of the 2-D
sub-arrays from which the diagonals should be taken. Defaults to
first axis (0).</p></li>
<li><p><strong>axis2</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Axis to be used as the second axis of the 2-D
sub-arrays from which the diagonals should be taken. Defaults to
second axis.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, if <cite>a</cite> is 2-D, then <cite>a</cite> 1-D array containing the diagonal.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – if the input tensor has less than two dimensions.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">[[0 1]</span>
<span class="go">[2 3]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[0 3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.dtype">
<em class="property">property </em><code class="sig-name descname">dtype</code><a class="headerlink" href="#mindspore.Tensor.dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the dtype of the tensor (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>).</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.expand_as">
<code class="sig-name descname">expand_as</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.expand_as"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.expand_as" title="Permalink to this definition">¶</a></dt>
<dd><p>Expand the dimension of target tensor to the dimension of input tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The input tensor. The shape of input tensor must obey
the broadcasting rule.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same dimension as input tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.fill">
<code class="sig-name descname">fill</code><span class="sig-paren">(</span><em class="sig-param">value</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.fill"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.fill" title="Permalink to this definition">¶</a></dt>
<dd><p>Fill the array with a scalar value.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Unlike Numpy, tensor.fill() will always returns a new tensor, instead of
filling the original tensor.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>value</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>]</em>) – All elements of a will be assigned this value.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, with the original dtype and shape as input tensor.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If input arguments have types not specified above.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
<span class="go">[[1. 1.]</span>
<span class="go">[1. 1.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.flatten">
<code class="sig-name descname">flatten</code><span class="sig-paren">(</span><em class="sig-param">order=&quot;C&quot;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.flatten"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.flatten" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a copy of the tensor collapsed into one dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>order</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – Can choose between ‘C’ and ‘F’. ‘C’ means to
flatten in row-major (C-style) order. ‘F’ means to flatten in column-major
(Fortran-style) order. Only ‘C’ and ‘F’ are supported. Default: ‘C’.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same data type as input.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If <cite>order</cite> is not string type.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>order</cite> is string type, but not ‘C’ or ‘F’.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(24,)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.flush_from_cache">
<code class="sig-name descname">flush_from_cache</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.flush_from_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.flush_from_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Flush cache data to host if tensor is cache enable.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.from_numpy">
<em class="property">static </em><code class="sig-name descname">from_numpy</code><span class="sig-paren">(</span><em class="sig-param">array</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.from_numpy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.from_numpy" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert numpy array to Tensor without copy data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>array</strong> (<em>numpy.array</em>) – The input array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same data type as input array.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.has_init">
<em class="property">property </em><code class="sig-name descname">has_init</code><a class="headerlink" href="#mindspore.Tensor.has_init" title="Permalink to this definition">¶</a></dt>
<dd><p>tensor is inited.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.init_data">
<code class="sig-name descname">init_data</code><span class="sig-paren">(</span><em class="sig-param">slice_index=None</em>, <em class="sig-param">shape=None</em>, <em class="sig-param">opt_shard_group=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.init_data"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.init_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the tensor format data of this Tensor.
The init_data function can be called once for the same tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>slice_index</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Slice index of a parameter’s slices.
It is used when initialize a slice of a parameter, it guarantees that devices
using the same slice can generate the same tensor. Default: None.</p></li>
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – Shape of the slice, it is used when initialize a slice of the parameter. Default: None.</p></li>
<li><p><strong>opt_shard_group</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Optimizer shard group which is used in auto or semi auto parallel mode
to get one shard of a parameter’s slice. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Initialized Tensor.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.common.initializer</span> <span class="k">as</span> <span class="nn">init</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">init</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="n">init</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">init_data</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">[[1. 1.]</span>
<span class="go"> [1. 1.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.item">
<code class="sig-name descname">item</code><span class="sig-paren">(</span><em class="sig-param">index=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.item"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.item" title="Permalink to this definition">¶</a></dt>
<dd><p>Getitem from the Tensor with the index.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Tensor.item returns a Tensor scalar instead of a Python scalar.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>]</em>) – The index in Tensor. Default: None.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A Tensor scalar, dtype is the same with the original Tensor.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the length of the <cite>index</cite> is not euqal to self.ndim.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">2.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.itemset">
<code class="sig-name descname">itemset</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.itemset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.itemset" title="Permalink to this definition">¶</a></dt>
<dd><p>Insert scalar into a tensor (scalar is cast to tensor’s dtype, if possible).</p>
<p>There must be at least 1 argument, and define the last argument as item.
Then, tensor.itemset(*args) is equivalent to <span class="math notranslate nohighlight">\(tensor[args] = item\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>args</strong> (<em>Union</em><em>[</em><em>(</em><a class="reference external" href="https://docs.python.org/library/numbers.html#numbers.Number" title="(in Python v3.8)"><em>numbers.Number</em></a><em>)</em><em>, </em><em>(</em><em>int/tuple</em><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/library/numbers.html#numbers.Number" title="(in Python v3.8)"><em>numbers.Number</em></a><em>)</em><em>]</em>) – The arguments that
specify the index and value. If <cite>args</cite> contain one argument (a scalar),
it is only used in case tensor is of size 1. If <cite>args</cite> contain two
arguments, the last argument is the value to be set and must be a
scalar, the first argument specifies a single tensor element location.
It is either an int or a tuple.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A new Tensor, with value set by <span class="math notranslate nohighlight">\(tensor[args] = item\)</span>.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the length of the first argument is not euqal to self.ndim.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#IndexError" title="(in Python v3.8)"><strong>IndexError</strong></a> – If only one argument is provided, and the original Tensor is not scalar.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">itemset</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">[[1. 4. 3.]</span>
<span class="go">[4. 5. 6.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.itemsize">
<em class="property">property </em><code class="sig-name descname">itemsize</code><a class="headerlink" href="#mindspore.Tensor.itemsize" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the length of one tensor element in bytes.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.max">
<code class="sig-name descname">max</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em>, <em class="sig-param">keepdims=False</em>, <em class="sig-param">initial=None</em>, <em class="sig-param">where=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.max"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.max" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the maximum of a tensor or maximum along an axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>tuple of ints</em><em>]</em><em>, </em><em>optional</em>) – Axis or
axes along which to operate. By default, flattened input is used. If
this is a tuple of ints, the maximum is selected over multiple axes,
instead of a single axis or all the axes as before. Default: None.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If this is set to True, the axes which are reduced are left in the
result as dimensions with size one. With this option, the result will
broadcast correctly against the input array. Default: False.</p></li>
<li><p><strong>initial</strong> (<em>scalar</em><em>, </em><em>optional</em>) – The minimum value of an output element. Must be present to allow
computation on empty slice. Default: None.</p></li>
<li><p><strong>where</strong> (<em>bool Tensor</em><em>, </em><em>optional</em>) – A boolean array which is broadcasted to match the dimensions of array,
and selects elements to include in the reduction. If non-default value
is passed, initial must also be provided. Default: True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor or scalar, maximum of input tensor. If <cite>axis</cite> is None, the result is a scalar
value. If <cite>axis</cite> is given, the result is an array of dimension <code class="docutils literal notranslate"><span class="pre">self.ndim</span> <span class="pre">-</span> <span class="pre">1</span></code>.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – if arguments have types not specified above.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">3.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.mean">
<code class="sig-name descname">mean</code><span class="sig-paren">(</span><em class="sig-param">axis=()</em>, <em class="sig-param">keep_dims=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.mean"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.mean" title="Permalink to this definition">¶</a></dt>
<dd><p>Reduce a dimension of a tensor by averaging all elements in the dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>]</em>) – Dimensions of reduction,
when the axis is None or empty tuple, reduce all dimensions. Default: ().</p></li>
<li><p><strong>keep_dims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to keep the reduced dimensions. Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same data type as input tensor.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">2.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.min">
<code class="sig-name descname">min</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em>, <em class="sig-param">keepdims=False</em>, <em class="sig-param">initial=None</em>, <em class="sig-param">where=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.min"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.min" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the minimum of a tensor or minimum along an axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>tuple of ints</em><em>]</em><em>, </em><em>optional</em>) – Axis or
axes along which to operate. By default, flattened input is used. If
this is a tuple of ints, the minimum is selected over multiple axes,
instead of a single axis or all the axes as before. Default: None.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If this is set to True, the axes which are reduced are left in the
result as dimensions with size one. With this option, the result will
broadcast correctly against the input array. Default: False.</p></li>
<li><p><strong>initial</strong> (<em>scalar</em><em>, </em><em>optional</em>) – The maximum value of an output element. Must be present to allow
computation on empty slice. Default: None.</p></li>
<li><p><strong>where</strong> (<em>bool Tensor</em><em>, </em><em>optional</em>) – A boolean array which is broadcasted to match the dimensions of array,
and selects elements to include in the reduction. If non-default value
is passed, initial must also be provided. Default: True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor or scalar, minimum of input tensor. If the axis is None, the result is a scalar
value. If <cite>axis</cite> is given, the result is an array of dimension <code class="docutils literal notranslate"><span class="pre">self.ndim</span> <span class="pre">-</span> <span class="pre">1</span></code>.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – if arguments have types not specified above.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.nbytes">
<em class="property">property </em><code class="sig-name descname">nbytes</code><a class="headerlink" href="#mindspore.Tensor.nbytes" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the total number of bytes taken by the tensor.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.ndim">
<em class="property">property </em><code class="sig-name descname">ndim</code><a class="headerlink" href="#mindspore.Tensor.ndim" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the number of tensor dimensions.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.ptp">
<code class="sig-name descname">ptp</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em>, <em class="sig-param">keepdims=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.ptp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.ptp" title="Permalink to this definition">¶</a></dt>
<dd><p>The name of the function comes from the acronym for ‘peak to peak’.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Numpy arguments <cite>dtype</cite> and <cite>out</cite> are not supported.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>]</em>) – Axis or axes along which the range is computed.
The default is to compute the variance of the flattened array. Default: None.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If this is set to True, the axes which are reduced are left in the result as
dimensions with size one. With this option, the result will broadcast correctly against the array.
Default is False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – if <cite>self</cite> is not a tensor, or <cite>axis</cite> and <cite>keepdims</cite> have types not specified above.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ptp</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="go">[8. 6.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ptp</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="go">[2. 0. 5. 2.]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.ravel">
<code class="sig-name descname">ravel</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.ravel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.ravel" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a contiguous flattened tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Tensor, a 1-D tensor, containing the same elements of the input.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(24,)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.repeat">
<code class="sig-name descname">repeat</code><span class="sig-paren">(</span><em class="sig-param">repeats</em>, <em class="sig-param">axis=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.repeat"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.repeat" title="Permalink to this definition">¶</a></dt>
<dd><p>Repeat elements of an array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>repeats</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>]</em>) – The number of repetitions for each element.
<cite>repeats</cite> is broadcasted to fit the shape of the given axis.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The axis along which to repeat values. By default,
use the flattened input tensor, and return a flat output tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same shape as input tensor except along the given axis.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – if the axis is out of range.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – if arguments have types not specified above.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
<span class="go">[3 3 3 3]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="go">[1 1 2 2 3 3 4 4]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="go">[[1 1 1 2 2 2]</span>
<span class="go">[3 3 3 4 4 4]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">repeat</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="go">[[1 2]</span>
<span class="go">[3 4]</span>
<span class="go">[3 4]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.reshape">
<code class="sig-name descname">reshape</code><span class="sig-paren">(</span><em class="sig-param">*shape</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.reshape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.reshape" title="Permalink to this definition">¶</a></dt>
<dd><p>Give a new shape to a tensor without changing its data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shape</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>]</em>) – The new shape should be compatible
with the original shape. If an integer, then the result will be a 1-D
array of that length. One shape dimension can be -1. In this case, the
value is inferred from the length of the array and remaining dimensions.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, with new specified shape.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If new_shape is not integer, list or tuple, or <cite>x</cite> is not tensor.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If new_shape is not compatible with the original shape.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[-0.1  0.3]</span>
<span class="go">[ 3.6  0.4]</span>
<span class="go">[ 0.5 -3.2]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.resize">
<code class="sig-name descname">resize</code><span class="sig-paren">(</span><em class="sig-param">*new_shape</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.resize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.resize" title="Permalink to this definition">¶</a></dt>
<dd><p>Changes shape and size of array in-place.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Instead of changing the size of the input array and returns nothing as in numpy,
this method returns a new Tensor with the input size.
Numpy argument <cite>refcheck</cite> is not supported.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>new_shape</strong> (<em>Union</em><em>[</em><em>ints</em><em>, </em><em>tuple of ints</em><em>]</em>) – Shape of resized array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">[[0 1 2]</span>
<span class="go">[3 0 0]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.searchsorted">
<code class="sig-name descname">searchsorted</code><span class="sig-paren">(</span><em class="sig-param">v</em>, <em class="sig-param">side=&quot;left&quot;</em>, <em class="sig-param">sorter=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.searchsorted"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.searchsorted" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds indices where elements should be inserted to maintain order.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>]</em>) – Values to insert into <cite>a</cite>.</p></li>
<li><p><strong>side</strong> (<em>'left'</em><em>, </em><em>'right'</em><em>, </em><em>optional</em>) – If ‘left’, the index of the first suitable
location found is given. If ‘right’, return the last such index. If there is
no suitable index, return either 0 or N (where N is the length of <cite>a</cite>).
Default: <cite>left</cite>.</p></li>
<li><p><strong>sorter</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>]</em>) – 1-D optional array of
integer indices that sort array <cite>a</cite> into ascending order. They are typically
the result of argsort.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, array of insertion points with the same shape as <cite>v</cite>.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – if argument for <cite>side</cite> or <cite>sorter</cite> is invalid.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
<span class="go">2</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.shape">
<em class="property">property </em><code class="sig-name descname">shape</code><a class="headerlink" href="#mindspore.Tensor.shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the shape of the tensor as a tuple.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.size">
<em class="property">property </em><code class="sig-name descname">size</code><a class="headerlink" href="#mindspore.Tensor.size" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the total number of elements in tensor.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.squeeze">
<code class="sig-name descname">squeeze</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.squeeze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.squeeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove single-dimensional entries from the shape of a tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>]</em><em>, </em><em>optional</em>) – Selects a subset of the entries of
length one in the shape. If an axis is selected with shape entry greater than one,
an error is raised. Default is None.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, with all or a subset of the dimensions of length 1 removed.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If input arguments have types not specified above.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If specified axis has shape entry <span class="math notranslate nohighlight">\(&gt; 1\)</span>.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(2, 2)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.std">
<code class="sig-name descname">std</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em>, <em class="sig-param">ddof=0</em>, <em class="sig-param">keepdims=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.std"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.std" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the standard deviation along the specified axis.
The standard deviation is the square root of the average of the squared deviations
from the mean, i.e., <span class="math notranslate nohighlight">\(std = sqrt(mean(abs(x - x.mean())**2))\)</span>.</p>
<p>Return the standard deviation, which is computed for the flattened array by default,
otherwise over the specified axis.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Numpy arguments <cite>dtype</cite>, <cite>out</cite> and <cite>where</cite> are not supported.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>]</em>) – <p>Axis or axes along which the standard
deviation is computed. Default: <cite>None</cite>.</p>
<p>If <cite>None</cite>, compute the standard deviation of the flattened array.</p>
</p></li>
<li><p><strong>ddof</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Means Delta Degrees of Freedom. The divisor used in calculations is <span class="math notranslate nohighlight">\(N - ddof\)</span>,
where <span class="math notranslate nohighlight">\(N\)</span> represents the number of elements. Default: 0.</p></li>
<li><p><strong>keepdims</strong> – Default: <cite>False</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Standard deviation tensor.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">1.118034</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.strides">
<em class="property">property </em><code class="sig-name descname">strides</code><a class="headerlink" href="#mindspore.Tensor.strides" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the tuple of bytes to step in each dimension when traversing a tensor.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.sum">
<code class="sig-name descname">sum</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em>, <em class="sig-param">dtype=None</em>, <em class="sig-param">keepdims=False</em>, <em class="sig-param">initial=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.sum"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.sum" title="Permalink to this definition">¶</a></dt>
<dd><p>Return sum of array elements over a given axis.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Numpy arguments <cite>out</cite>, <cite>where</cite>, <cite>casting</cite>, <cite>order</cite>, <cite>subok</cite>, <cite>signature</cite>, and
<cite>extobj</cite> are not supported.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>]</em>) – Axis or axes along which a sum is performed. Default: None.
If None, sum all of the elements of the input array.
If the axis is negative, it counts from the last to the first axis.
If the axis is a tuple of ints, a sum is performed on all of the axes specified in the tuple
instead of a single axis or all the axes as before.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>, optional) – defaults to None. Overrides the dtype of the
output Tensor.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If this is set to True, the axes which are reduced are left in the result as
dimensions with size one. With this option, the result will broadcast correctly against the input array.
If the default value is passed, then keepdims will not be passed through to the sum method of
sub-classes of ndarray, however any non-default value will be. If the sub-class’ method does not
implement keepdims any exceptions will be raised. Default: <cite>False</cite>.</p></li>
<li><p><strong>initial</strong> (<em>scalar</em>) – Starting value for the sum. Default: <cite>None</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor. A tensor with the same shape as input, with the specified axis removed.
If input tensor is a 0-d array, or if the axis is None, a scalar is returned.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If input is not array_like, or <cite>axis</cite> is not int or tuple of ints,
    or <cite>keepdims</cite> is not integer, or <cite>initial</cite> is not scalar.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If any axis is out of range or duplicate axes exist.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">input_x</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">input_x</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="go">[10. 35.]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.swapaxes">
<code class="sig-name descname">swapaxes</code><span class="sig-paren">(</span><em class="sig-param">axis1</em>, <em class="sig-param">axis2</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.swapaxes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.swapaxes" title="Permalink to this definition">¶</a></dt>
<dd><p>Interchange two axes of a tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis1</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – First axis.</p></li>
<li><p><strong>axis2</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Second axis.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Transposed tensor, has the same data type as the input.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If <cite>axis1</cite> or <cite>axis2</cite> is not integer.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>axis1</cite> or <cite>axis2</cite> is not in the range of <span class="math notranslate nohighlight">\([-ndim, ndim-1]\)</span>.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(4,3,2)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.take">
<code class="sig-name descname">take</code><span class="sig-paren">(</span><em class="sig-param">indices</em>, <em class="sig-param">axis=None</em>, <em class="sig-param">mode=&quot;clip&quot;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.take"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.take" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes elements from an array along an axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The indices with shape <cite>(Nj…)</cite> of the values to extract.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The axis over which to select values. By default,
the flattened input array is used. Default: <cite>None</cite>.</p></li>
<li><p><strong>mode</strong> (<em>‘raise’</em><em>, </em><em>‘wrap’</em><em>, </em><em>‘clip’</em><em>, </em><em>optional</em>) – <ul>
<li><p>edge: Pads with the edge values of <cite>arr</cite>.</p></li>
<li><p>raise: Raises an error;</p></li>
<li><p>wrap: Wraps around;</p></li>
<li><p>clip: Clips to the range. <cite>clip</cite> mode means that all indices that are
too large are replaced by the index that addresses the last element
along that axis. Note that this disables indexing with negative numbers.</p></li>
</ul>
<p>Default: <cite>clip</cite>.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, the indexed result.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – if <cite>axis</cite> is out of range, or <cite>mode</cite> has values other than (‘raise’, ‘wrap’, ‘clip’)</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[4 3 6]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.to_tensor">
<code class="sig-name descname">to_tensor</code><span class="sig-paren">(</span><em class="sig-param">slice_index=None</em>, <em class="sig-param">shape=None</em>, <em class="sig-param">opt_shard_group=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.to_tensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.to_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Return init_data() and get the tensor format data of this Tensor.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The usage of <cite>to_tensor</cite> is deprecated. Please use <cite>init_data</cite>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>slice_index</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Slice index of a parameter’s slices.
It is used when initialize a slice of a parameter, it guarantees that devices
using the same slice can generate the same tensor. Default: None.</p></li>
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – Shape of the slice, it is used when initialize a slice of the parameter. Default: None.</p></li>
<li><p><strong>opt_shard_group</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Optimizer shard group which is used in auto or semi auto parallel mode
to get one shard of a parameter’s slice. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Initialized Tensor.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.common.initializer</span> <span class="k">as</span> <span class="nn">init</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">init</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="n">init</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">[[1. 1.]</span>
<span class="go"> [1. 1.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.trace">
<code class="sig-name descname">trace</code><span class="sig-paren">(</span><em class="sig-param">offset=0</em>, <em class="sig-param">axis1=0</em>, <em class="sig-param">axis2=1</em>, <em class="sig-param">dtype=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.trace"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.trace" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the sum along diagonals of the array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>offset</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Offset of the diagonal from the main diagonal.
Can be positive or negative. Defaults to main diagonal.</p></li>
<li><p><strong>axis1</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Axis to be used as the first axis of the 2-D
sub-arrays from which the diagonals should be taken. Defaults to
first axis (0).</p></li>
<li><p><strong>axis2</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Axis to be used as the second axis of the 2-D
sub-arrays from which the diagonals should be taken. Defaults to
second axis.</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>, optional) – defaults to None. Overrides the dtype of the
output Tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, sum_along_diagonals.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – if the input tensor has less than two dimensions.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">trace</span><span class="p">())</span>
<span class="go">3.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.transpose">
<code class="sig-name descname">transpose</code><span class="sig-paren">(</span><em class="sig-param">*axes</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.transpose"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.transpose" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a view of the tensor with axes transposed.</p>
<ul class="simple">
<li><p>For a 1-D tensor this has no effect, as a transposed vector is simply the same vector.</p></li>
<li><p>For a 2-D tensor, this is a standard matrix transpose.</p></li>
<li><p>For an n-D tensor, if axes are given, their order indicates how the axes are permuted.</p></li>
</ul>
<p>If axes are not provided and <code class="docutils literal notranslate"><span class="pre">tensor.shape</span> <span class="pre">=</span> <span class="pre">(i[0],</span> <span class="pre">i[1],...i[n-2],</span> <span class="pre">i[n-1])</span></code>,
then <code class="docutils literal notranslate"><span class="pre">tensor.transpose().shape</span> <span class="pre">=</span> <span class="pre">(i[n-1],</span> <span class="pre">i[n-2],</span> <span class="pre">...</span> <span class="pre">i[1],</span> <span class="pre">i[0])</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axes</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – If axes is None or
blank, the method will reverse the order of the axes. If axes is tuple(int)
or list(int), tensor.transpose() will transpose the tensor to the new axes order.
If axes is int, this form is simply intended as a convenience alternative to the
tuple/list form.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same dimension as input tensor, with axes suitably permuted.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If input arguments have types not specified above.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the number of <cite>axes</cite> is not euqal to a.ndim.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(3, 2, 1)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.var">
<code class="sig-name descname">var</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em>, <em class="sig-param">ddof=0</em>, <em class="sig-param">keepdims=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.var"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.var" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the variance along the specified axis.</p>
<p>The variance is the average of the squared deviations from the mean, i.e.,
<span class="math notranslate nohighlight">\(var = mean(abs(x - x.mean())**2)\)</span>.</p>
<p>Return the variance, which is computed for the flattened array by default,
otherwise over the specified axis.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Numpy arguments <cite>dtype</cite>, <cite>out</cite> and <cite>where</cite> are not supported.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>]</em>) – Axis or axes along which the variance is computed.
The default is to compute the variance of the flattened array. Default: <cite>None</cite>.</p></li>
<li><p><strong>ddof</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Means Delta Degrees of Freedom. Default: 0.
The divisor used in calculations is <span class="math notranslate nohighlight">\(N - ddof\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> represents the number of elements.</p></li>
<li><p><strong>keepdims</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Default: <cite>False</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Standard deviation tensor.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">1.25</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.view">
<code class="sig-name descname">view</code><span class="sig-paren">(</span><em class="sig-param">*shape</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#Tensor.view"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Tensor.view" title="Permalink to this definition">¶</a></dt>
<dd><p>Reshape the tensor according to the input shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shape</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – Dimension of the output tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, has the same dimension as the input shape.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.virtual_flag">
<em class="property">property </em><code class="sig-name descname">virtual_flag</code><a class="headerlink" href="#mindspore.Tensor.virtual_flag" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to mark whether the tensor is virtual. If the tensor is virtual, return True.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindspore.RowTensor">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">RowTensor</code><span class="sig-paren">(</span><em class="sig-param">indices</em>, <em class="sig-param">values</em>, <em class="sig-param">dense_shape</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#RowTensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.RowTensor" title="Permalink to this definition">¶</a></dt>
<dd><p>A sparse representation of a set of tensor slices at given indices.</p>
<p>An RowTensor is typically used to represent a subset of a larger
tensor dense of shape [L0, D1, .. , DN] where L0 &gt;&gt; D0.</p>
<p>The values in indices are the indices in the first dimension of the slices
that have been extracted from the larger tensor.</p>
<p>The dense tensor dense represented by an RowTensor slices has
<cite>dense[slices.indices[i], :, :, :, …] = slices.values[i, :, :, :, …]</cite>.</p>
<p>RowTensor can only be used in the <cite>Cell</cite>’s construct method.</p>
<p>It is not supported in pynative mode at the moment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A 1-D integer Tensor of shape [D0].</p></li>
<li><p><strong>values</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A Tensor of any dtype of shape [D0, D1, …, Dn].</p></li>
<li><p><strong>dense_shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em>) – An integer tuple which contains the shape
of the corresponding dense tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>RowTensor, composed of <cite>indices</cite>, <cite>values</cite>, and <cite>dense_shape</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">RowTensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dense_shape</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">dense_shape</span> <span class="o">=</span> <span class="n">dense_shape</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="n">RowTensor</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dense_shape</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">values</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">Net</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="go">[[1. 2.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="go">[0]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="go">(3, 2)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindspore.SparseTensor">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">SparseTensor</code><span class="sig-paren">(</span><em class="sig-param">indices</em>, <em class="sig-param">values</em>, <em class="sig-param">dense_shape</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/tensor.html#SparseTensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.SparseTensor" title="Permalink to this definition">¶</a></dt>
<dd><p>A sparse representation of a set of nonzero elememts from a tensor at given indices.</p>
<p>SparseTensor can only be used in the <cite>Cell</cite>’s construct method.</p>
<p>Pynative mode not supported at the moment.</p>
<p>For a tensor dense, its SparseTensor(indices, values, dense_shape) has
<cite>dense[indices[i]] = values[i]</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A 2-D integer Tensor of shape <cite>[N, ndims]</cite>,
where N and ndims are the number of <cite>values</cite> and number of dimensions in
the SparseTensor, respectively.</p></li>
<li><p><strong>values</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – A 1-D tensor of any type and shape <cite>[N]</cite>, which
supplies the values for each element in <cite>indices</cite>.</p></li>
<li><p><strong>dense_shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em>) – A integer tuple of size <cite>ndims</cite>,
which specifies the dense_shape of the sparse tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>SparseTensor, composed of <cite>indices</cite>, <cite>values</cite>, and <cite>dense_shape</cite>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">SparseTensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dense_shape</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">dense_shape</span> <span class="o">=</span> <span class="n">dense_shape</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dense_shape</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">values</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">Net</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="go">[1. 2.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="go">[[0 1]</span>
<span class="go"> [1 2]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="go">(3, 4)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="mindspore.ms_function">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">ms_function</code><span class="sig-paren">(</span><em class="sig-param">fn=None</em>, <em class="sig-param">obj=None</em>, <em class="sig-param">input_signature=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/api.html#ms_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.ms_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a callable MindSpore graph from a Python function.</p>
<p>This allows the MindSpore runtime to apply optimizations based on graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fn</strong> (<em>Function</em>) – The Python function that will be run as a graph. Default: None.</p></li>
<li><p><strong>obj</strong> (<em>Object</em>) – The Python object is used to distinguish the compiled function. Default: None.</p></li>
<li><p><strong>input_signature</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – The Tensor which describes the input arguments. The shape and dtype of the Tensor
will be supplied to this function. If input_signature is specified, each input to <cite>fn</cite> must be a <cite>Tensor</cite>.
And the input parameters of <cite>fn</cite> cannot accept <cite>**kwargs</cite>. The shape and dtype of actual inputs should
keep the same as input_signature. Otherwise, TypeError will be raised. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Function, if <cite>fn</cite> is not None, returns a callable function that will execute the compiled function; If <cite>fn</cite> is
None, returns a decorator and when this decorator invokes with a single <cite>fn</cite> argument, the callable function is
equal to the case when <cite>fn</cite> is not None.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ms_function</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># create a callable MindSpore graph by calling ms_function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">tensor_add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">z</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tensor_add_graph</span> <span class="o">=</span> <span class="n">ms_function</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">tensor_add</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">tensor_add_graph</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># create a callable MindSpore graph through decorator @ms_function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nd">@ms_function</span>
<span class="gp">... </span><span class="k">def</span> <span class="nf">tensor_add_with_dec</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">z</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">tensor_add_with_dec</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># create a callable MindSpore graph through decorator @ms_function with input_signature parameter</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nd">@ms_function</span><span class="p">(</span><span class="n">input_signature</span><span class="o">=</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)),</span>
<span class="gp">... </span>                              <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))))</span>
<span class="gp">... </span><span class="k">def</span> <span class="nf">tensor_add_with_sig</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">z</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">tensor_add_with_sig</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mindspore.Parameter">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">Parameter</code><span class="sig-paren">(</span><em class="sig-param">default_input</em>, <em class="sig-param">name=None</em>, <em class="sig-param">requires_grad=True</em>, <em class="sig-param">layerwise_parallel=False</em>, <em class="sig-param">parallel_optimizer=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#Parameter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>An object holding weights of cells, after initialized <cite>Parameter</cite> is a subtype of <cite>Tensor</cite>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In auto_parallel mode of  “semi_auto_parallel” and “auto_parallel”, if init <cite>Parameter</cite> by
a <cite>Tensor</cite>, the type of Parameter will be <cite>Tensor</cite>. <cite>Tensor</cite>
will save the shape and type info of a tensor with no memory usage. The shape can be changed while
compiling for auto-parallel. Call <cite>init_data</cite> will return a Tensor Parameter with initialized data.
If there is an operator in the network that requires part of the inputs to be Parameter,
then the Parameters as this part of the inputs are not allowed to be cast.
It is recommended to use the default value of <cite>name</cite> when initialize a parameter as one attribute of a cell,
otherwise, the parameter name may be different from expected.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>default_input</strong> (<em>Union</em><em>[</em><a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>]</em>) – Parameter data,
to initialize the parameter data.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Name of the child parameter. Default: None.</p></li>
<li><p><strong>requires_grad</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – True if the parameter requires gradient. Default: True.</p></li>
<li><p><strong>layerwise_parallel</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – When layerwise_parallel is true in data/hybrid parallel mode,
broadcast and gradients communication would not be applied to parameters. Default: False.</p></li>
<li><p><strong>parallel_optimizer</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – It is used to filter the weight shard operation in semi auto or auto parallel
mode. It works only when enable parallel optimizer in <cite>mindspore.context.set_auto_parallel_context()</cite>.
Default: True.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">matmul</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">MatMul</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="go">[[2.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="go">[[0.]]</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore.Parameter.cache_enable">
<em class="property">property </em><code class="sig-name descname">cache_enable</code><a class="headerlink" href="#mindspore.Parameter.cache_enable" title="Permalink to this definition">¶</a></dt>
<dd><p>Return whether the parameter is cache enable.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Parameter.cache_shape">
<em class="property">property </em><code class="sig-name descname">cache_shape</code><a class="headerlink" href="#mindspore.Parameter.cache_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the cache shape corresponding to the parameter if use cache.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Parameter.clone">
<code class="sig-name descname">clone</code><span class="sig-paren">(</span><em class="sig-param">init=&quot;same&quot;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#Parameter.clone"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Parameter.clone" title="Permalink to this definition">¶</a></dt>
<dd><p>Clone the parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>init</strong> (<em>Union</em><em>[</em><a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/numbers.html#numbers.Number" title="(in Python v3.8)"><em>numbers.Number</em></a><em>]</em>) – Initialize the shape and dtype of the parameter.
If <cite>init</cite> is a <cite>Tensor</cite> or <cite>numbers.Number</cite>, clone a new parameter with the same shape
and dtype, and the data of the new parameter will be set according to <cite>init</cite>. If <cite>init</cite>
is a <cite>str</cite>, the <cite>init</cite> should be the alias of the class inheriting from <cite>Initializer</cite>.
For example, if <cite>init</cite> is ‘same’, clone a new parameter with the same data, shape, and
dtype. Default: ‘same’.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Parameter, a new parameter.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.Parameter.comm_fusion">
<em class="property">property </em><code class="sig-name descname">comm_fusion</code><a class="headerlink" href="#mindspore.Parameter.comm_fusion" title="Permalink to this definition">¶</a></dt>
<dd><p>Get and set the fusion type (int) for communication operators corresponding to this parameter.</p>
<p>In <cite>AUTO_PARALLEL</cite> and <cite>SEMI_AUTO_PARALLEL</cite> mode, some communication operators used for parameters or
gradients aggregation are inserted automatically. Set the fusion type for communication operators generated
for this parameter. The value of fusion must be greater than or equal to 0. When the value of fusion is 0,
operators will not be fused together.</p>
<p>Only support in Ascend environment with Graph mode.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Parameter.data">
<em class="property">property </em><code class="sig-name descname">data</code><a class="headerlink" href="#mindspore.Parameter.data" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the parameter object.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Parameter.init_data">
<code class="sig-name descname">init_data</code><span class="sig-paren">(</span><em class="sig-param">layout=None</em>, <em class="sig-param">set_sliced=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#Parameter.init_data"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Parameter.init_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize the parameter’s data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layout</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>)</em><em>)</em><em>]</em>) – <p>Parameter slice
layout [dev_mat, tensor_map, slice_shape]. Default: None.</p>
<ul>
<li><p>dev_mat (list(int)): Device matrix.</p></li>
<li><p>tensor_map (list(int)): Tensor map.</p></li>
<li><p>slice_shape (list(int)): Shape of slice.</p></li>
</ul>
</p></li>
<li><p><strong>set_sliced</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – True if the parameter is set sliced after initializing the data.
Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – If it is from Initializer, and parallel mode has changed after the Initializer created.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the length of the layout is less than 3.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If <cite>layout</cite> is not tuple.</p></li>
</ul>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Parameter, the <cite>Parameter</cite> after initializing data. If current <cite>Parameter</cite> was already initialized before,
returns the same initialized <cite>Parameter</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.Parameter.inited_param">
<em class="property">property </em><code class="sig-name descname">inited_param</code><a class="headerlink" href="#mindspore.Parameter.inited_param" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the new parameter after call the init_data.</p>
<p>Default is a None, If <cite>self</cite> is a Parameter without data, after call the
<cite>init_data</cite> the initialized Parameter with data will be recorded here.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Parameter.is_init">
<em class="property">property </em><code class="sig-name descname">is_init</code><a class="headerlink" href="#mindspore.Parameter.is_init" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the initialization status of the parameter.</p>
<p>This flag only work in GE, and it will be set to False in other backend.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Parameter.layerwise_parallel">
<em class="property">property </em><code class="sig-name descname">layerwise_parallel</code><a class="headerlink" href="#mindspore.Parameter.layerwise_parallel" title="Permalink to this definition">¶</a></dt>
<dd><p>When layerwise_parallel is true in data/hybrid parallel mode, broadcast and gradients communication would not
be applied to parameters.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Parameter.name">
<em class="property">property </em><code class="sig-name descname">name</code><a class="headerlink" href="#mindspore.Parameter.name" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the name of the parameter.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Parameter.parallel_optimizer">
<em class="property">property </em><code class="sig-name descname">parallel_optimizer</code><a class="headerlink" href="#mindspore.Parameter.parallel_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>It is used to filter the weight shard operation in semi auto or auto parallel mode. It works only
when enable parallel optimizer in <cite>mindspore.context.set_auto_parallel_context()</cite>.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Parameter.parallel_optimizer_comm_recompute">
<em class="property">property </em><code class="sig-name descname">parallel_optimizer_comm_recompute</code><a class="headerlink" href="#mindspore.Parameter.parallel_optimizer_comm_recompute" title="Permalink to this definition">¶</a></dt>
<dd><p>Get and Set the whether do recompute for communication operators corresponding to this parameter
when applying parallel optimizer.</p>
<p>In <cite>AUTO_PARALLEL</cite> and <cite>SEMI_AUTO_PARALLEL</cite> mode, when applying parallel optimizer, some all_gather operators
used for parameters gathering are inserted automatically.
The interface is used to control the recompute attr for those all_gather operators.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Only <cite>Ascend</cite> and <cite>Graph</cite> mode is supported.</p></li>
<li><p>It is recommended to use cell.recompute(parallel_optimizer_comm_recompute=True/False) to configure
the all_gather operators introducing by parallel optimizer rather than using this interface directly.</p></li>
</ul>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Parameter.requires_grad">
<em class="property">property </em><code class="sig-name descname">requires_grad</code><a class="headerlink" href="#mindspore.Parameter.requires_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Return whether the parameter requires gradient.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Parameter.set_data">
<code class="sig-name descname">set_data</code><span class="sig-paren">(</span><em class="sig-param">data</em>, <em class="sig-param">slice_shape=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#Parameter.set_data"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Parameter.set_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Set Parameter’s data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>Union</em><em>[</em><a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – new data.</p></li>
<li><p><strong>slice_shape</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If slice the parameter is set to true, the shape is not checked for consistency.
Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Parameter, the parameter after set data.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.Parameter.set_param_fl">
<code class="sig-name descname">set_param_fl</code><span class="sig-paren">(</span><em class="sig-param">push_to_server=False</em>, <em class="sig-param">pull_from_server=False</em>, <em class="sig-param">requires_aggr=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#Parameter.set_param_fl"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Parameter.set_param_fl" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the way of parameter and server interaction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>push_to_server</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether the parameter should be pushed to server. Default: False.</p></li>
<li><p><strong>pull_from_server</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether the parameter should be pulled from server. Default: False.</p></li>
<li><p><strong>requires_aggr</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether the parameter should be aggregated in the server. Default: True.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.Parameter.set_param_ps">
<code class="sig-name descname">set_param_ps</code><span class="sig-paren">(</span><em class="sig-param">init_in_server=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#Parameter.set_param_ps"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Parameter.set_param_ps" title="Permalink to this definition">¶</a></dt>
<dd><p>Set whether the trainable parameter is updated by parameter server and whether the
trainable parameter is initialized on server.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It only works when a running task is in the parameter server mode.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>init_in_server</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether trainable parameter updated by parameter server is
initialized on server. Default: False.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.Parameter.sliced">
<em class="property">property </em><code class="sig-name descname">sliced</code><a class="headerlink" href="#mindspore.Parameter.sliced" title="Permalink to this definition">¶</a></dt>
<dd><p>Get slice status of the parameter.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Parameter.unique">
<em class="property">property </em><code class="sig-name descname">unique</code><a class="headerlink" href="#mindspore.Parameter.unique" title="Permalink to this definition">¶</a></dt>
<dd><p>whether the parameter is already unique or not.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindspore.ParameterTuple">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">ParameterTuple</code><a class="reference internal" href="../_modules/mindspore/common/parameter.html#ParameterTuple"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.ParameterTuple" title="Permalink to this definition">¶</a></dt>
<dd><p>Class for storing tuple of parameters.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is used to store the parameters of the network into the parameter tuple collection.</p>
</div>
<dl class="method">
<dt id="mindspore.ParameterTuple.clone">
<code class="sig-name descname">clone</code><span class="sig-paren">(</span><em class="sig-param">prefix</em>, <em class="sig-param">init=&quot;same&quot;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/parameter.html#ParameterTuple.clone"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.ParameterTuple.clone" title="Permalink to this definition">¶</a></dt>
<dd><p>Clone the parameters in ParameterTuple element-wisely to generate a new ParameterTuple.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Namespace of parameter.</p></li>
<li><p><strong>init</strong> (<em>Union</em><em>[</em><a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/numbers.html#numbers.Number" title="(in Python v3.8)"><em>numbers.Number</em></a><em>]</em>) – Initialize the shape and dtype of the parameters.
The definition of <cite>init</cite> is the same as in <cite>Parameter</cite> API. If <cite>init</cite> is ‘same’, the
parameters in the new parameter tuple are the same as those in the original parameter tuple.
Default: ‘same’.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – If parameter’s name is not end with embedding_table.</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Tuple, the new Parameter tuple.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="mindspore.set_seed">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">set_seed</code><span class="sig-paren">(</span><em class="sig-param">seed</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/seed.html#set_seed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.set_seed" title="Permalink to this definition">¶</a></dt>
<dd><p>Set global seed.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The global seed is used by numpy.random, mindspore.common.Initializer, mindspore.ops.composite.random_ops and
mindspore.nn.probability.distribution.</p>
<p>If global seed is not set, these packages will use their own default seed independently, numpy.random and
mindspore.common.Initializer will choose a random seed, mindspore.ops.composite.random_ops and
mindspore.nn.probability.distribution will use zero.</p>
<p>Seed set by numpy.random.seed() only used by numpy.random, while seed set by this API will also used by
numpy.random, so just set all seed by this API is recommended.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The seed to be set.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If seed is invalid (&lt; 0).</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If seed isn’t a int.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">set_seed</span><span class="p">,</span> <span class="n">Parameter</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">initializer</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Note: (1) Please make sure the code is running in PYNATIVE MODE;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># (2) Because Composite-level ops need parameters to be Tensors, for below examples,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># when using ops.uniform operator, minval and maxval are initialised as:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">minval</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">maxval</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 1. If global seed is not set, numpy.random and initializer will choose a random seed:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get different results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W4</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 2. If global seed is set, numpy.random and initializer will use it:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get the same results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w1&quot;</span><span class="p">)</span> <span class="c1"># W2</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 3. If neither global seed nor op seed is set, mindspore.ops.composite.random_ops and</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.nn.probability.distribution will choose a random seed:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get different results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C4</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 4. If global seed is set, but op seed is not set, mindspore.ops.composite.random_ops and</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.nn.probability.distribution will calculate a seed according to global seed and</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># default op seed. Each call will change the default op seed, thus each call get different</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># results.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get the same results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 5. If both global seed and op seed are set, mindspore.ops.composite.random_ops and</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.nn.probability.distribution will calculate a seed according to global seed and</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># op seed counter. Each call will change the op seed counter, thus each call get different</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># results.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get the same results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 6. If op seed is set but global seed is not set, 0 will be used as global seed. Then</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.ops.composite.random_ops and mindspore.nn.probability.distribution act as in</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># condition 5.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rerun the program will get the same results:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C2</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 7. Recall set_seed() in the program will reset numpy seed and op seed counter of</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.ops.composite.random_ops and mindspore.nn.probability.distribution.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># A1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c1</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># C1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># still get A1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># still get C1</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="mindspore.get_seed">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">get_seed</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/common/seed.html#get_seed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.get_seed" title="Permalink to this definition">¶</a></dt>
<dd><p>Get global seed.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Integer. The global seed.</p>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="mindspore.Model">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">Model</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">loss_fn=None</em>, <em class="sig-param">optimizer=None</em>, <em class="sig-param">metrics=None</em>, <em class="sig-param">eval_network=None</em>, <em class="sig-param">eval_indexes=None</em>, <em class="sig-param">amp_level=&quot;O0&quot;</em>, <em class="sig-param">boost_level=&quot;O0&quot;</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/model.html#Model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Model" title="Permalink to this definition">¶</a></dt>
<dd><p>High-Level API for training or inference.</p>
<p><cite>Model</cite> groups layers into an object with training and inference features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – A training or testing network.</p></li>
<li><p><strong>loss_fn</strong> (<a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Objective function, if loss_fn is None, the
network should contain the logic of loss and grads calculation,
and parallel if needed. Default: None.</p></li>
<li><p><strong>optimizer</strong> (<a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Optimizer for updating the weights. Default: None.</p></li>
<li><p><strong>metrics</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#set" title="(in Python v3.8)"><em>set</em></a><em>]</em>) – A Dictionary or a set of metrics to be evaluated by the model during
training and inference. eg: {‘accuracy’, ‘recall’}. Default: None.</p></li>
<li><p><strong>eval_network</strong> (<a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Network for evaluation. If not defined, <cite>network</cite> and <cite>loss_fn</cite> would be wrapped as
<cite>eval_network</cite> . Default: None.</p></li>
<li><p><strong>eval_indexes</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – When defining the <cite>eval_network</cite>, if <cite>eval_indexes</cite> is None, all outputs of the
<cite>eval_network</cite> would be passed to metrics, otherwise <cite>eval_indexes</cite> must contain three
elements, including the positions of loss value, predicted value and label. The loss
value would be passed to the <cite>Loss</cite> metric, the predicted value and label would be passed
to other metric. Default: None.</p></li>
<li><p><strong>amp_level</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>Option for argument <cite>level</cite> in <cite>mindspore.amp.build_train_network</cite> , level for mixed
precision training. Supports [“O0”, “O2”, “O3”, “auto”]. Default: “O0”.</p>
<ul>
<li><p>O0: Do not change.</p></li>
<li><p>O2: Cast network to float16, keep batchnorm run in float32, using dynamic loss scale.</p></li>
<li><p>O3: Cast network to float16, with additional property <cite>keep_batchnorm_fp32=False</cite> .</p></li>
<li><p>auto: Set to level to recommended level in different devices. Set level to O2 on GPU, Set
level to O3 Ascend. The recommended level is choose by the export experience, cannot
always general. User should specify the level for special network.</p></li>
</ul>
<p>O2 is recommended on GPU, O3 is recommended on Ascend.The more detailed explanation of <cite>amp_level</cite> setting
can be found at <cite>mindspore.amp.build_train_network</cite> .</p>
</p></li>
<li><p><strong>boost_level</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>Option for argument <cite>level</cite> in <cite>mindspore.boost</cite> , level for boost mode
training. Supports [“O0”, “O1”, “O2”]. Default: “O0”.</p>
<ul>
<li><p>O0: Do not change.</p></li>
<li><p>O1: Enable the boost mode, the performance is improved by about 20%, and
the accuracy is the same as the original accuracy.</p></li>
<li><p>O2: Enable the boost mode, the performance is improved by about 30%, and
the accuracy is reduced by less than 3%.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_class</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">num_channel</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="o">*</span><span class="mi">5</span><span class="o">*</span><span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;ones&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;ones&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="n">num_class</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;ones&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">x</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># For details about how to build the dataset, please refer to the tutorial</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># document on the official website.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore.Model.build">
<code class="sig-name descname">build</code><span class="sig-paren">(</span><em class="sig-param">train_dataset=None</em>, <em class="sig-param">valid_dataset=None</em>, <em class="sig-param">sink_size=-1</em>, <em class="sig-param">epoch=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/model.html#Model.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Model.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Build computational graphs and data graphs with the sink mode.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This is an experimental prototype that is subject to change and/or deletion.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Pre-build process only supports <cite>GRAPH_MODE</cite> and <cite>Ascend</cite> target currently.
The interface builds the computational graphs, when the interface is executed first,
‘model.train’ only performs the graphs execution.
It only support dataset sink mode.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> (<em>Dataset</em>) – A training dataset iterator. If <cite>train_dataset</cite> is defined, training graphs will be
initialized. Default: None.</p></li>
<li><p><strong>valid_dataset</strong> (<em>Dataset</em>) – An evaluating dataset iterator. If <cite>valid_dataset</cite> is defined, evaluation graphs
will be initialized, and <cite>metrics</cite> in <cite>Model</cite> can not be None. Default: None.</p></li>
<li><p><strong>sink_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Control the amount of data in each sink. Default: -1.</p></li>
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Control the training epochs. Default: 1.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">FixedLossScaleManager</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># For details about how to build the dataset, please refer to the tutorial</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># document on the official website.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Model.eval">
<code class="sig-name descname">eval</code><span class="sig-paren">(</span><em class="sig-param">valid_dataset</em>, <em class="sig-param">callbacks=None</em>, <em class="sig-param">dataset_sink_mode=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/model.html#Model.eval"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Model.eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluation API where the iteration is controlled by python front-end.</p>
<p>Configure to pynative mode or CPU, the evaluating process will be performed with dataset non-sink mode.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If dataset_sink_mode is True, data will be sent to device. If the device is Ascend, features
of data will be transferred one by one. The limitation of data transmission per time is 256M.
When dataset_sink_mode is True, the step_end method of the Callback class will be executed when
the epoch_end method is called.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>valid_dataset</strong> (<em>Dataset</em>) – Dataset to evaluate the model.</p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>(</em><a class="reference internal" href="mindspore.train.html#mindspore.train.callback.Callback" title="mindspore.train.callback.Callback"><em>Callback</em></a><em>)</em><em>]</em>) – List of callback objects which should be executed
while training. Default: None.</p></li>
<li><p><strong>dataset_sink_mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Determines whether to pass the data through dataset channel.
Default: True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict, the key is the metric name defined by users and the value is the metrics value for
the model in the test mode.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># For details about how to build the dataset, please refer to the tutorial</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># document on the official website.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Model.eval_network">
<em class="property">property </em><code class="sig-name descname">eval_network</code><a class="headerlink" href="#mindspore.Model.eval_network" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the model’s eval_network.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Model.infer_predict_layout">
<code class="sig-name descname">infer_predict_layout</code><span class="sig-paren">(</span><em class="sig-param">*predict_data</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/model.html#Model.infer_predict_layout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Model.infer_predict_layout" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate parameter layout for the predict network in auto or semi auto parallel mode.</p>
<p>Data could be a single tensor or multiple tensors.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Batch data should be put together in one tensor.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>predict_data</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – One tensor or multiple tensors of predict data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict, Parameter layout dictionary used for load distributed checkpoint.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – If get_context is not GRAPH_MODE.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># This example should be run with multiple devices. Refer to the tutorial &gt; Distributed Training on</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.cn.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.context</span> <span class="kn">import</span> <span class="n">ParallelMode</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">full_batch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parallel_mode</span><span class="o">=</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">SEMI_AUTO_PARALLEL</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">Net</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">predict_map</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">infer_predict_layout</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Model.infer_train_layout">
<code class="sig-name descname">infer_train_layout</code><span class="sig-paren">(</span><em class="sig-param">train_dataset</em>, <em class="sig-param">dataset_sink_mode=True</em>, <em class="sig-param">sink_size=-1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/model.html#Model.infer_train_layout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Model.infer_train_layout" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate parameter layout for the train network in auto or semi auto parallel mode.
Only dataset sink mode is supported for now.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This is an experimental prototype that is subject to change and/or deletion.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This is a pre-compile function. The arguments should be the same with model.train() function.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> (<em>Dataset</em>) – A training dataset iterator. If there is no
loss_fn, a tuple with multiple data (data1, data2, data3, …) should be
returned and passed to the network. Otherwise, a tuple (data, label) should
be returned. The data and label would be passed to the network and loss
function respectively.</p></li>
<li><p><strong>dataset_sink_mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Determines whether to pass the data through dataset channel.
Configure pynative mode or CPU, the training process will be performed with
dataset not sink. Default: True.</p></li>
<li><p><strong>sink_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Control the amount of data in each sink.
If sink_size = -1, sink the complete dataset for each epoch.
If sink_size &gt; 0, sink sink_size data for each epoch.
If dataset_sink_mode is False, set sink_size as invalid.
Default: -1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict, Parameter layout dictionary used for load distributed checkpoint</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># This example should be run with multiple devices. Refer to the tutorial &gt; Distributed Training on</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.cn.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">FixedLossScaleManager</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.context</span> <span class="kn">import</span> <span class="n">ParallelMode</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">parallel_mode</span><span class="o">=</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">SEMI_AUTO_PARALLEL</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># For details about how to build the dataset, please refer to the tutorial</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># document on the official website.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">layout_dict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">infer_train_layout</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Model.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">*predict_data</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/model.html#Model.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Model.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate output predictions for the input samples.</p>
<p>Data could be a single tensor, a list of tensor, or a tuple of tensor.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This is a pre-compile function. The arguments should be the same with model.predict() function.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>predict_data</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>]</em><em>]</em>) – The predict data, can be a single tensor,
a list of tensor, or a tuple of tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, array(s) of predictions.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">Net</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Model.predict_network">
<em class="property">property </em><code class="sig-name descname">predict_network</code><a class="headerlink" href="#mindspore.Model.predict_network" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the model’s predict_network.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Model.train">
<code class="sig-name descname">train</code><span class="sig-paren">(</span><em class="sig-param">epoch</em>, <em class="sig-param">train_dataset</em>, <em class="sig-param">callbacks=None</em>, <em class="sig-param">dataset_sink_mode=True</em>, <em class="sig-param">sink_size=-1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/model.html#Model.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Model.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Training API where the iteration is controlled by python front-end.</p>
<p>When setting pynative mode or CPU, the training process will be performed with dataset not sink.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If dataset_sink_mode is True, data will be sent to device. If the device is Ascend, features
of data will be transferred one by one. The limitation of data transmission per time is 256M.
When dataset_sink_mode is True, the step_end method of the Callback class will be executed when
the epoch_end method is called.
If sink_size &gt; 0, each epoch of the dataset can be traversed unlimited times until you get sink_size
elements of the dataset. The next epoch continues to traverse from the end position of the previous
traversal. The interface builds the computational graphs and then executes the computational graphs.
However, when the ‘model.build’ is executed first, it only performs the graphs execution.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Generally, total number of iterations on the data per epoch.
When dataset_sink_mode is set to true and sink_size&gt;0, each epoch sink sink_size
steps on the data instead of total number of iterations.</p></li>
<li><p><strong>train_dataset</strong> (<em>Dataset</em>) – A training dataset iterator. If there is no
loss_fn, a tuple with multiple data (data1, data2, data3, …) should be
returned and passed to the network. Otherwise, a tuple (data, label) should
be returned. The data and label would be passed to the network and loss
function respectively.</p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference internal" href="mindspore.train.html#mindspore.train.callback.Callback" title="mindspore.train.callback.Callback"><em>Callback</em></a><em>]</em><em>, </em><a class="reference internal" href="mindspore.train.html#mindspore.train.callback.Callback" title="mindspore.train.callback.Callback"><em>Callback</em></a><em>]</em>) – List of callback objects or callback object,
which should be executed while training.
Default: None.</p></li>
<li><p><strong>dataset_sink_mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Determines whether to pass the data through dataset channel.
Configure pynative mode or CPU, the training process will be performed with
dataset not sink. Default: True.</p></li>
<li><p><strong>sink_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Control the amount of data in each sink.
If sink_size = -1, sink the complete dataset for each epoch.
If sink_size &gt; 0, sink sink_size data for each epoch.
If dataset_sink_mode is False, set sink_size as invalid.
Default: -1.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">FixedLossScaleManager</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># For details about how to build the dataset, please refer to the tutorial</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># document on the official website.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Model.train_network">
<em class="property">property </em><code class="sig-name descname">train_network</code><a class="headerlink" href="#mindspore.Model.train_network" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the model’s train_network.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindspore.DatasetHelper">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">DatasetHelper</code><span class="sig-paren">(</span><em class="sig-param">dataset</em>, <em class="sig-param">dataset_sink_mode=True</em>, <em class="sig-param">sink_size=-1</em>, <em class="sig-param">epoch_num=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.DatasetHelper" title="Permalink to this definition">¶</a></dt>
<dd><p>DatasetHelper is a class to process the MindData dataset and provides the information of dataset.</p>
<p>According to different contexts, change the iterations of dataset and use the same iteration for loop in different
contexts.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The iteration of DatasetHelper will provide one epoch data.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<em>Dataset</em>) – The dataset iterator. The dataset can be generated by dataset generator API in
<a class="reference internal" href="mindspore.dataset.html#module-mindspore.dataset" title="mindspore.dataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dataset</span></code></a>, such as <a class="reference internal" href="dataset/mindspore.dataset.ImageFolderDataset.html#mindspore.dataset.ImageFolderDataset" title="mindspore.dataset.ImageFolderDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dataset.ImageFolderDataset</span></code></a>.</p></li>
<li><p><strong>dataset_sink_mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If the value is true, GetNext is employed to fetch the data, otherwise the data is fed
from host. Default: True.</p></li>
<li><p><strong>sink_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Control the amount of data in each sink.
If sink_size=-1, sink the complete dataset for each epoch.
If sink_size&gt;0, sink sink_size data for each epoch.
Default: -1.</p></li>
<li><p><strong>epoch_num</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of passes of the entire dataset to be sent. Default: 1.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">DatasetHelper</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">set_helper</span> <span class="o">=</span> <span class="n">DatasetHelper</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Object of DatasetHelper is iterable</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">next_element</span> <span class="ow">in</span> <span class="n">set_helper</span><span class="p">:</span>
<span class="gp">... </span>    <span class="c1"># `next_element` includes data and label, using data to run the net</span>
<span class="gp">... </span>    <span class="n">data</span> <span class="o">=</span> <span class="n">next_element</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">... </span>    <span class="n">net</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore.DatasetHelper.continue_send">
<code class="sig-name descname">continue_send</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.continue_send"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.DatasetHelper.continue_send" title="Permalink to this definition">¶</a></dt>
<dd><p>Continue to send data to device at the beginning of epoch.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.DatasetHelper.dynamic_min_max_shapes">
<code class="sig-name descname">dynamic_min_max_shapes</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.dynamic_min_max_shapes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.DatasetHelper.dynamic_min_max_shapes" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the minimum and maximum data length of dynamic source dataset.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">DatasetHelper</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># config dynamic shape</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span><span class="o">.</span><span class="n">set_dynamic_columns</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;data1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">83</span><span class="p">],</span> <span class="s2">&quot;data2&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">]})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset_helper</span> <span class="o">=</span> <span class="n">DatasetHelper</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">min_shapes</span><span class="p">,</span> <span class="n">max_shapes</span> <span class="o">=</span> <span class="n">dataset_helper</span><span class="o">.</span><span class="n">dynamic_min_max_shapes</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.DatasetHelper.get_data_info">
<code class="sig-name descname">get_data_info</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.get_data_info"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.DatasetHelper.get_data_info" title="Permalink to this definition">¶</a></dt>
<dd><p>In sink mode, it returns the types and shapes of the current data.
Generally, it works in dynamic shape scenarios.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">DatasetHelper</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset_helper</span> <span class="o">=</span> <span class="n">DatasetHelper</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">types</span><span class="p">,</span> <span class="n">shapes</span> <span class="o">=</span> <span class="n">dataset_helper</span><span class="o">.</span><span class="n">get_data_info</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.DatasetHelper.release">
<code class="sig-name descname">release</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.release"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.DatasetHelper.release" title="Permalink to this definition">¶</a></dt>
<dd><p>Free up resources about data sink.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.DatasetHelper.sink_size">
<code class="sig-name descname">sink_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.sink_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.DatasetHelper.sink_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Get sink_size for each iteration.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">DatasetHelper</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset_helper</span> <span class="o">=</span> <span class="n">DatasetHelper</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sink_size</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># if sink_size==-1, then will return the full size of source dataset.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sink_size</span> <span class="o">=</span> <span class="n">dataset_helper</span><span class="o">.</span><span class="n">sink_size</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.DatasetHelper.stop_send">
<code class="sig-name descname">stop_send</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.stop_send"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.DatasetHelper.stop_send" title="Permalink to this definition">¶</a></dt>
<dd><p>Stop send data about data sink.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.DatasetHelper.types_shapes">
<code class="sig-name descname">types_shapes</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#DatasetHelper.types_shapes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.DatasetHelper.types_shapes" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the types and shapes from dataset on the current configuration.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">DatasetHelper</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset_helper</span> <span class="o">=</span> <span class="n">DatasetHelper</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">types</span><span class="p">,</span> <span class="n">shapes</span> <span class="o">=</span> <span class="n">dataset_helper</span><span class="o">.</span><span class="n">types_shapes</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="mindspore.connect_network_with_dataset">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">connect_network_with_dataset</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">dataset_helper</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/dataset_helper.html#connect_network_with_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.connect_network_with_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Connect the <cite>network</cite> with dataset in <cite>dataset_helper</cite>.</p>
<p>This function wraps the input network with ‘GetNext’ so that the data can be fetched automatically from the
data channel corresponding to the ‘queue_name’ and passed to the input network during forward computation.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In the case of running the network on Ascend/GPU in graph mode, this function will wrap the input network with
‘GetNext’, in other cases, the input network will be returned with no change.
The ‘GetNext’ is required to get data only in sink mode, so this function is not applicable to no-sink mode.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The training network for dataset.</p></li>
<li><p><strong>dataset_helper</strong> (<a class="reference internal" href="#mindspore.DatasetHelper" title="mindspore.DatasetHelper"><em>DatasetHelper</em></a>) – A class to process the MindData dataset, it provides the type, shape and queue
name of the dataset to wrap the <cite>GetNext</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Cell, a new network wrapped with ‘GetNext’ in the case of running the task on Ascend in graph mode, otherwise
it is the input network.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">DatasetHelper</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># call create_dataset function to create a regular dataset, refer to mindspore.dataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset_helper</span> <span class="o">=</span> <span class="n">DatasetHelper</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net_with_get_next</span> <span class="o">=</span> <span class="n">connect_network_with_dataset</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">dataset_helper</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="mindspore.build_train_network">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">build_train_network</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">optimizer</em>, <em class="sig-param">loss_fn=None</em>, <em class="sig-param">level=&quot;O0&quot;</em>, <em class="sig-param">boost_level=&quot;O0&quot;</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/amp.html#build_train_network"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.build_train_network" title="Permalink to this definition">¶</a></dt>
<dd><p>Build the mixed precision training cell automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Definition of the network.</p></li>
<li><p><strong>loss_fn</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a><em>]</em>) – Definition of the loss_fn. If None, the <cite>network</cite> should have the loss inside.
Default: None.</p></li>
<li><p><strong>optimizer</strong> (<a class="reference internal" href="nn/mindspore.nn.Optimizer.html#mindspore.nn.Optimizer" title="mindspore.nn.Optimizer"><em>Optimizer</em></a>) – Optimizer to update the Parameter.</p></li>
<li><p><strong>level</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>Supports [“O0”, “O2”, “O3”, “auto”]. Default: “O0”.</p>
<ul>
<li><p>O0: Do not change.</p></li>
<li><p>O2: Cast network to float16, keep batchnorm and <cite>loss_fn</cite> (if set) run in float32,
using dynamic loss scale.</p></li>
<li><p>O3: Cast network to float16, with additional property <cite>keep_batchnorm_fp32=False</cite> .</p></li>
<li><p>auto: Set to level to recommended level in different devices. Set level to O2 on GPU, Set
level to O3 Ascend. The recommended level is choose by the export experience, cannot
always general. User should specify the level for special network.</p></li>
</ul>
<p>O2 is recommended on GPU, O3 is recommended on Ascend.Property of <cite>keep_batchnorm_fp32</cite> , <cite>cast_model_type</cite>
and <cite>loss_scale_manager</cite> determined by <cite>level</cite> setting may be overwritten by settings in <cite>kwargs</cite> .</p>
</p></li>
<li><p><strong>boost_level</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>Option for argument <cite>level</cite> in <cite>mindspore.boost</cite> , level for boost mode
training. Supports [“O0”, “O1”, “O2”]. Default: “O0”.</p>
<ul>
<li><p>O0: Do not change.</p></li>
<li><p>O1: Enable the boost mode, the performance is improved by about 20%, and
the accuracy is the same as the original accuracy.</p></li>
<li><p>O2: Enable the boost mode, the performance is improved by about 30%, and
the accuracy is reduced by less than 3%.</p></li>
</ul>
<p>If O1 or O2 mode is set, the boost related library will take effect automatically.</p>
</p></li>
<li><p><strong>cast_model_type</strong> (<a class="reference internal" href="#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – Supports <cite>mstype.float16</cite> or <cite>mstype.float32</cite> . If set, the
network will be casted to <cite>cast_model_type</cite> ( <cite>mstype.float16</cite> or <cite>mstype.float32</cite> ), but not to be casted
to the type determined by <cite>level</cite> setting.</p></li>
<li><p><strong>keep_batchnorm_fp32</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Keep Batchnorm run in <cite>float32</cite> when the network is set to cast to <cite>float16</cite> . If
set, the <cite>level</cite> setting will take no effect on this property.</p></li>
<li><p><strong>loss_scale_manager</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference internal" href="#mindspore.LossScaleManager" title="mindspore.LossScaleManager"><em>LossScaleManager</em></a><em>]</em>) – If None, not scale the loss, otherwise scale the loss by
<cite>LossScaleManager</cite> . If set, the <cite>level</cite> setting will take no effect on this property.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Auto mixed precision only supported on device GPU and Ascend. If device is CPU, a <cite>ValueError</cite>
    exception will be raised.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If device is CPU, property <cite>loss_scale_manager</cite> only can be set as <cite>None</cite> or <cite>FixedLossScaleManager</cite>
    (with property <cite>drop_overflow_update=False</cite> ), or a <cite>ValueError</cite> exception will be raised.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="mindspore.LossScaleManager">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">LossScaleManager</code><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#LossScaleManager"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.LossScaleManager" title="Permalink to this definition">¶</a></dt>
<dd><p>Loss scale manager abstract class.</p>
<p>Derive FixedLossScaleManager and DynamicLossScaleManager that override all LossScaleManager’s method.</p>
<dl class="method">
<dt id="mindspore.LossScaleManager.get_loss_scale">
<code class="sig-name descname">get_loss_scale</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#LossScaleManager.get_loss_scale"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.LossScaleManager.get_loss_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Get loss scale value.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.LossScaleManager.get_update_cell">
<code class="sig-name descname">get_update_cell</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#LossScaleManager.get_update_cell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.LossScaleManager.get_update_cell" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the loss scaling update logic cell.</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.LossScaleManager.update_loss_scale">
<code class="sig-name descname">update_loss_scale</code><span class="sig-paren">(</span><em class="sig-param">overflow</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#LossScaleManager.update_loss_scale"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.LossScaleManager.update_loss_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Update loss scale value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>overflow</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether it overflows.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindspore.FixedLossScaleManager">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">FixedLossScaleManager</code><span class="sig-paren">(</span><em class="sig-param">loss_scale=128.0</em>, <em class="sig-param">drop_overflow_update=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.FixedLossScaleManager" title="Permalink to this definition">¶</a></dt>
<dd><p>Loss scale with a fixed value, inherits from LossScaleManager.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss_scale</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Loss scale. Note that if <cite>drop_overflow_update</cite> is set to False, the value of <cite>loss_scale</cite>
in optimizer that you used need to be set to the same value as here. Default: 128.0.</p></li>
<li><p><strong>drop_overflow_update</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to execute optimizer if there is an overflow. If True, the optimizer will
not executed when overflow occurs. Default: True.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">FixedLossScaleManager</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#1) Drop the parameter update if there is an overflow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#2) Execute parameter update even if overflow occurs</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale</span> <span class="o">=</span> <span class="mf">1024.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">(</span><span class="n">loss_scale</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore.FixedLossScaleManager.get_drop_overflow_update">
<code class="sig-name descname">get_drop_overflow_update</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager.get_drop_overflow_update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.FixedLossScaleManager.get_drop_overflow_update" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the flag whether to drop optimizer update when there is an overflow.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>bool, <cite>drop_overflow_update</cite> value.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.FixedLossScaleManager.get_loss_scale">
<code class="sig-name descname">get_loss_scale</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager.get_loss_scale"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.FixedLossScaleManager.get_loss_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Get loss scale value.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>bool, <cite>loss_scale</cite> value.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.FixedLossScaleManager.get_update_cell">
<code class="sig-name descname">get_update_cell</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager.get_update_cell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.FixedLossScaleManager.get_update_cell" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the update cell for <cite>TrainOneStepWithLossScaleCell</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None or Cell. Cell object, used to update <cite>loss_scale</cite>, when <cite>drop_overflow_update</cite> is True. None when
<cite>drop_overflow_update</cite> is False.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.FixedLossScaleManager.update_loss_scale">
<code class="sig-name descname">update_loss_scale</code><span class="sig-paren">(</span><em class="sig-param">overflow</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#FixedLossScaleManager.update_loss_scale"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.FixedLossScaleManager.update_loss_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Update loss scale value. The interface at <cite>FixedLossScaleManager</cite> will do nothing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>overflow</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether it overflows.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mindspore.DynamicLossScaleManager">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">DynamicLossScaleManager</code><span class="sig-paren">(</span><em class="sig-param">init_loss_scale=2 ** 24</em>, <em class="sig-param">scale_factor=2</em>, <em class="sig-param">scale_window=2000</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.DynamicLossScaleManager" title="Permalink to this definition">¶</a></dt>
<dd><p>Loss scale that dynamically adjusts itself, inherits from LossScaleManager.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init_loss_scale</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Initialize loss scale. Default: 2**24.</p></li>
<li><p><strong>scale_factor</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Coefficient of increase and decrease. Default: 2.</p></li>
<li><p><strong>scale_window</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Maximum continuous normal steps when there is no overflow. Default: 2000.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">DynamicLossScaleManager</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">DynamicLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore.DynamicLossScaleManager.get_drop_overflow_update">
<code class="sig-name descname">get_drop_overflow_update</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager.get_drop_overflow_update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.DynamicLossScaleManager.get_drop_overflow_update" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the flag whether to drop optimizer update when there is an overflow.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>bool, always return True at <cite>DynamicLossScaleManager</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.DynamicLossScaleManager.get_loss_scale">
<code class="sig-name descname">get_loss_scale</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager.get_loss_scale"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.DynamicLossScaleManager.get_loss_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Get loss scale value.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>bool, <cite>loss_scale</cite> value.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.DynamicLossScaleManager.get_update_cell">
<code class="sig-name descname">get_update_cell</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager.get_update_cell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.DynamicLossScaleManager.get_update_cell" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the update cell for <cite>TrainOneStepWithLossScaleCell</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Cell, cell object used to update <cite>loss_scale</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.DynamicLossScaleManager.update_loss_scale">
<code class="sig-name descname">update_loss_scale</code><span class="sig-paren">(</span><em class="sig-param">overflow</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/loss_scale_manager.html#DynamicLossScaleManager.update_loss_scale"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.DynamicLossScaleManager.update_loss_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Update loss scale value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>overflow</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether it overflows.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="mindspore.save_checkpoint">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">save_checkpoint</code><span class="sig-paren">(</span><em class="sig-param">save_obj</em>, <em class="sig-param">ckpt_file_name</em>, <em class="sig-param">integrated_save=True</em>, <em class="sig-param">async_save=False</em>, <em class="sig-param">append_dict=None</em>, <em class="sig-param">enc_key=None</em>, <em class="sig-param">enc_mode=&quot;AES-GCM&quot;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#save_checkpoint"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save checkpoint to a specified file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_obj</strong> (<em>Union</em><em>[</em><a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>]</em>) – The cell object or data list(each element is a dictionary, like
[{“name”: param_name, “data”: param_data},…], the type of
param_name would be string, and the type of param_data would
be parameter or Tensor).</p></li>
<li><p><strong>ckpt_file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Checkpoint file name. If the file name already exists, it will be overwritten.</p></li>
<li><p><strong>integrated_save</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to integrated save in automatic model parallel scene. Default: True</p></li>
<li><p><strong>async_save</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to open a independent thread to save the checkpoint file. Default: False</p></li>
<li><p><strong>append_dict</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – Additional information that needs to be saved.  The key of dict must be str,
the value of dict must be one of int float and bool. Default: None</p></li>
<li><p><strong>enc_key</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#bytes" title="(in Python v3.8)"><em>bytes</em></a><em>]</em>) – Byte type key used for encryption. If the value is None, the encryption
is not required. Default: None.</p></li>
<li><p><strong>enc_mode</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – This parameter is valid only when enc_key is not set to None. Specifies the encryption
mode, currently supports ‘AES-GCM’ and ‘AES-CBC’. Default: ‘AES-GCM’.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If the parameter save_obj is not <cite>nn.Cell</cite> or list type. And if the parameter
    <cite>integrated_save</cite> and <cite>async_save</cite> are not bool type.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">save_checkpoint</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="s2">&quot;lenet.ckpt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="mindspore.load_checkpoint">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">load_checkpoint</code><span class="sig-paren">(</span><em class="sig-param">ckpt_file_name</em>, <em class="sig-param">net=None</em>, <em class="sig-param">strict_load=False</em>, <em class="sig-param">filter_prefix=None</em>, <em class="sig-param">dec_key=None</em>, <em class="sig-param">dec_mode=&quot;AES-GCM&quot;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#load_checkpoint"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.load_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Load checkpoint info from a specified file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Checkpoint file name.</p></li>
<li><p><strong>net</strong> (<a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The network where the parameters will be loaded. Default: None</p></li>
<li><p><strong>strict_load</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to strict load the parameter into net. If False, it will load parameter
into net when parameter name’s suffix in checkpoint file is the same as the
parameter in the network. When the types are inconsistent perform type conversion
on the parameters of the same type, such as float32 to float16. Default: False.</p></li>
<li><p><strong>filter_prefix</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em><em>]</em>) – Parameters starting with the filter_prefix
will not be loaded. Default: None.</p></li>
<li><p><strong>dec_key</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#bytes" title="(in Python v3.8)"><em>bytes</em></a><em>]</em>) – Byte type key used for decryption. If the value is None, the decryption
is not required. Default: None.</p></li>
<li><p><strong>dec_mode</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – This parameter is valid only when dec_key is not set to None. Specifies the decryption
mode, currently supports ‘AES-GCM’ and ‘AES-CBC’. Default: ‘AES-GCM’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict, key is parameter name, value is a Parameter.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Checkpoint file is incorrect.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">load_checkpoint</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ckpt_file_name</span> <span class="o">=</span> <span class="s2">&quot;./checkpoint/LeNet5-1_32.ckpt&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">ckpt_file_name</span><span class="p">,</span> <span class="n">filter_prefix</span><span class="o">=</span><span class="s2">&quot;conv1&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">param_dict</span><span class="p">[</span><span class="s2">&quot;conv2.weight&quot;</span><span class="p">])</span>
<span class="go">Parameter (name=conv2.weight, shape=(16, 6, 5, 5), dtype=Float32, requires_grad=True)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="mindspore.load_param_into_net">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">load_param_into_net</code><span class="sig-paren">(</span><em class="sig-param">net</em>, <em class="sig-param">parameter_dict</em>, <em class="sig-param">strict_load=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#load_param_into_net"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.load_param_into_net" title="Permalink to this definition">¶</a></dt>
<dd><p>Load parameters into network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net</strong> (<a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The network where the parameters will be loaded.</p></li>
<li><p><strong>parameter_dict</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – The dictionary generated by load checkpoint file.</p></li>
<li><p><strong>strict_load</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to strict load the parameter into net. If False, it will load parameter
into net when parameter name’s suffix in checkpoint file is the same as the
parameter in the network. When the types are inconsistent perform type conversion
on the parameters of the same type, such as float32 to float16. Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List, parameter name not loaded into the network</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – Argument is not a Cell, or parameter_dict is not a Parameter dictionary.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ckpt_file_name</span> <span class="o">=</span> <span class="s2">&quot;./checkpoint/LeNet5-1_32.ckpt&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">ckpt_file_name</span><span class="p">,</span> <span class="n">filter_prefix</span><span class="o">=</span><span class="s2">&quot;conv1&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_not_load</span> <span class="o">=</span> <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">param_not_load</span><span class="p">)</span>
<span class="go">[&#39;conv1.weight&#39;]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="mindspore.export">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">export</code><span class="sig-paren">(</span><em class="sig-param">net</em>, <em class="sig-param">*inputs</em>, <em class="sig-param">file_name</em>, <em class="sig-param">file_format=&quot;AIR&quot;</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#export"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.export" title="Permalink to this definition">¶</a></dt>
<dd><p>Export the mindspore network into an offline model in the specified format.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ol class="arabic simple">
<li><p>When exporting AIR, ONNX format, the size of a single tensor can not exceed 2GB.</p></li>
<li><p>When file_name does not have a suffix, the system will automatically add one according to the file_format.</p></li>
</ol>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>net</strong> (<a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – MindSpore network.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – Inputs of the <cite>net</cite>, if the network has multiple inputs, incoming tuple(Tensor).</p></li>
<li><p><strong>file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – File name of the model to be exported.</p></li>
<li><p><strong>file_format</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>MindSpore currently supports ‘AIR’, ‘ONNX’ and ‘MINDIR’ format for exported model.</p>
<ul>
<li><p>AIR: Ascend Intermediate Representation. An intermediate representation format of Ascend model.</p></li>
<li><p>ONNX: Open Neural Network eXchange. An open format built to represent machine learning models.</p></li>
<li><p>MINDIR: MindSpore Native Intermediate Representation for Anf. An intermediate representation format
for MindSpore models.</p></li>
</ul>
</p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – <p>Configuration options dictionary.</p>
<ul>
<li><p>quant_mode (str): If the network is quantization aware training network, the quant_mode should
be set to “QUANT”, else the quant_mode should be set to “NONQUANT”.</p></li>
<li><p>mean (float): The mean of input data after preprocessing, used for quantizing the first layer of network.
Default: 127.5.</p></li>
<li><p>std_dev (float): The variance of input data after preprocessing,
used for quantizing the first layer of network. Default: 127.5.</p></li>
<li><p>enc_key (byte): Byte type key used for encryption. Tha valid length is 16, 24, or 32.</p></li>
<li><p>enc_mode (str): Specifies the encryption mode, take effect when enc_key is set.
Option: ‘AES-GCM’ | ‘AES-CBC’. Default: ‘AES-GCM’.</p></li>
<li><p>dataset (Dataset): Specifies the preprocess methods of network.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">export</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">export</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">),</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;lenet&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;MINDIR&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="mindspore.load">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">file_name</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load MindIR.</p>
<p>The returned object can be executed by a <cite>GraphCell</cite>, see class <code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.nn.GraphCell</span></code> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – MindIR file name.</p></li>
<li><p><strong>kwargs</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – <p>Configuration options dictionary.</p>
<ul>
<li><p>dec_key (bytes): Byte type key used for decryption. Tha valid length is 16, 24, or 32.</p></li>
<li><p>dec_mode (str): Specifies the decryption mode, take effect when dec_key is set.
Option: ‘AES-GCM’ | ‘AES-CBC’. Default: ‘AES-GCM’.</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Object, a compiled graph that can executed by <cite>GraphCell</cite>.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – MindIR file name is incorrect.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – Failed to parse MindIR file.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">export</span><span class="p">,</span> <span class="n">load</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s2">&quot;ones&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">export</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">&quot;net&quot;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s2">&quot;MINDIR&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">graph</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">&quot;net.mindir&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GraphCell</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[[[4. 6. 4.]</span>
<span class="go">   [6. 9. 6.]</span>
<span class="go">   [4. 6. 4.]]]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="mindspore.parse_print">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">parse_print</code><span class="sig-paren">(</span><em class="sig-param">print_file_name</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#parse_print"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.parse_print" title="Permalink to this definition">¶</a></dt>
<dd><p>Parse saved data generated by mindspore.ops.Print.  Print is used to print data to screen in graph mode.
It can also been turned off by setting the parameter <cite>print_file_path</cite> in <cite>context</cite>, and the data will be saved
in a file specified by print_file_path. parse_print is used to parse the saved file. For more information
please refer to <a class="reference internal" href="mindspore.context.html#mindspore.context.set_context" title="mindspore.context.set_context"><code class="xref py py-func docutils literal notranslate"><span class="pre">mindspore.context.set_context()</span></code></a> and <a class="reference internal" href="ops/mindspore.ops.Print.html#mindspore.ops.Print" title="mindspore.ops.Print"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.Print</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>print_file_name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The file name of saved print data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List, element of list is Tensor.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – The print file may be empty, please make sure enter the correct file name.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">context</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">print_file_path</span><span class="o">=</span><span class="s1">&#39;log.data&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">PrintInputTensor</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>            <span class="bp">self</span><span class="o">.</span><span class="n">print</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Print</span><span class="p">()</span>
</pre></div>
</div>
<p>…         def construct(self, input_pra):
…             self.print(‘print:’, input_pra)
…             return input_pra</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_pra</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">PrintInputTensor</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="p">(</span><span class="n">input_pra</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">parse_print</span><span class="p">(</span><span class="s1">&#39;./log.data&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="go">[&#39;print:&#39;, Tensor(shape=[2, 4], dtype=Float32, value=</span>
<span class="go">[[ 1.00000000e+00,  2.00000000e+00,  3.00000000e+00,  4.00000000e+00],</span>
<span class="go">[ 5.00000000e+00,  6.00000000e+00,  7.00000000e+00,  8.00000000e+00]])]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="mindspore.build_searched_strategy">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">build_searched_strategy</code><span class="sig-paren">(</span><em class="sig-param">strategy_filename</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#build_searched_strategy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.build_searched_strategy" title="Permalink to this definition">¶</a></dt>
<dd><p>Build strategy of every parameter in network. Used in the case of distributed inference.
For details of merge_sliced_parameter, please check:
<a href="#id1"><span class="problematic" id="id2">`</span></a>Enabling Graph-Accounting Convergence</p>
<blockquote>
<div><p>&lt;<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/save_load_model_hybrid_parallel.html">https://www.mindspore.cn/docs/programming_guide/en/r1.5/save_load_model_hybrid_parallel.html</a>&gt;`_.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>strategy_filename</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Name of strategy file.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict, whose key is parameter name and value is slice strategy of this parameter.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Strategy file is incorrect.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – strategy_filename is not str.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">strategy</span> <span class="o">=</span> <span class="n">build_searched_strategy</span><span class="p">(</span><span class="s2">&quot;./strategy_train.ckpt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="mindspore.merge_sliced_parameter">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">merge_sliced_parameter</code><span class="sig-paren">(</span><em class="sig-param">sliced_parameters</em>, <em class="sig-param">strategy=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#merge_sliced_parameter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.merge_sliced_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Merge parameter slices into one parameter. Used in the case of distributed inference.
For details of merge_sliced_parameter, please check:
<a href="#id3"><span class="problematic" id="id4">`</span></a>Enabling Graph-Accounting Convergence</p>
<blockquote>
<div><p>&lt;<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/save_load_model_hybrid_parallel.html">https://www.mindspore.cn/docs/programming_guide/en/r1.5/save_load_model_hybrid_parallel.html</a>&gt;`_.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sliced_parameters</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference internal" href="#mindspore.Parameter" title="mindspore.Parameter"><em>Parameter</em></a><em>]</em>) – Parameter slices in order of rank_id.</p></li>
<li><p><strong>strategy</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a><em>]</em>) – Parameter slice strategy, whose key is parameter name and
value is slice strategy of this parameter. If strategy is None, just merge
parameter slices in 0 axis order. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Parameter, the merged parameter which has the whole data.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Failed to merge.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – The sliced_parameters is incorrect or strategy is not dict.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#KeyError" title="(in Python v3.8)"><strong>KeyError</strong></a> – The parameter name is not in keys of strategy.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">merge_sliced_parameter</span><span class="p">,</span> <span class="n">Parameter</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sliced_parameters</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>                     <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.00023915</span><span class="p">,</span> <span class="mf">0.00013939</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00098059</span><span class="p">])),</span>
<span class="gp">... </span>                               <span class="s2">&quot;network.embedding_table&quot;</span><span class="p">),</span>
<span class="gp">... </span>                     <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.00015815</span><span class="p">,</span> <span class="mf">0.00015458</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00012125</span><span class="p">])),</span>
<span class="gp">... </span>                               <span class="s2">&quot;network.embedding_table&quot;</span><span class="p">),</span>
<span class="gp">... </span>                     <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.00042165</span><span class="p">,</span> <span class="mf">0.00029692</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00007941</span><span class="p">])),</span>
<span class="gp">... </span>                               <span class="s2">&quot;network.embedding_table&quot;</span><span class="p">),</span>
<span class="gp">... </span>                     <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.00084451</span><span class="p">,</span> <span class="mf">0.00089960</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00010431</span><span class="p">])),</span>
<span class="gp">... </span>                               <span class="s2">&quot;network.embedding_table&quot;</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">merged_parameter</span> <span class="o">=</span> <span class="n">merge_sliced_parameter</span><span class="p">(</span><span class="n">sliced_parameters</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">merged_parameter</span><span class="p">)</span>
<span class="go">Parameter (name=network.embedding_table, shape=(12,), dtype=Float64, requires_grad=True)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="mindspore.load_distributed_checkpoint">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">load_distributed_checkpoint</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">checkpoint_filenames</em>, <em class="sig-param">predict_strategy=None</em>, <em class="sig-param">train_strategy_filename=None</em>, <em class="sig-param">strict_load=False</em>, <em class="sig-param">dec_key=None</em>, <em class="sig-param">dec_mode=&quot;AES-GCM&quot;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#load_distributed_checkpoint"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.load_distributed_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Load checkpoint into net for distributed predication. Used in the case of distributed inference.
For details of distributed inference, please check:
<a href="#id5"><span class="problematic" id="id6">`</span></a>Enabling Graph-Accounting Convergence</p>
<blockquote>
<div><p>&lt;<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/distributed_inference.html">https://www.mindspore.cn/docs/programming_guide/en/r1.5/distributed_inference.html</a>&gt;`_.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Network for distributed predication.</p></li>
<li><p><strong>checkpoint_filenames</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em>) – The name of Checkpoint files in order of rank id.</p></li>
<li><p><strong>predict_strategy</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – Strategy of predication process, whose key is parameter name, and value is a list or
a tuple that the first four elements are [dev_matrix, tensor_map, param_split_shape, field]. If None,
it means that the predication process just uses single device. Default: None.</p></li>
<li><p><strong>train_strategy_filename</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Train strategy proto file name. Default: None.</p></li>
<li><p><strong>strict_load</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to strict load the parameter into net. If False, it will load parameter
into net when parameter name’s suffix in checkpoint file is the same as the
parameter in the network. When the types are inconsistent perform type conversion
on the parameters of the same type, such as float32 to float16. Default: False.</p></li>
<li><p><strong>dec_key</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#bytes" title="(in Python v3.8)"><em>bytes</em></a><em>]</em>) – Byte type key used for decryption. If the value is None, the decryption
is not required. Default: None.</p></li>
<li><p><strong>dec_mode</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – This parameter is valid only when dec_key is not set to None. Specifies the decryption
mode, currently supports ‘AES-GCM’ and ‘AES-CBC’. Default: ‘AES-GCM’.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – The type of inputs do not match the requirements.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – Failed to load checkpoint into net.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mindspore.async_ckpt_thread_status">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">async_ckpt_thread_status</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/serialization.html#async_ckpt_thread_status"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.async_ckpt_thread_status" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the status of asynchronous save checkpoint thread.</p>
<p>When performing asynchronous save checkpoint, you can get the thread state through this function
to ensure that write checkpoint file are completed.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>True, Asynchronous save checkpoint thread is running.
False, Asynchronous save checkpoint thread is not executing.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mindspore.get_level">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">get_level</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/log.html#get_level"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.get_level" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the logger level.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>str, the Log level includes 4(EXCEPTION), 3(ERROR), 2(WARNING), 1(INFO), 0(DEBUG).</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">os</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;GLOG_v&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;0&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">log</span> <span class="k">as</span> <span class="n">logger</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">level</span> <span class="o">=</span> <span class="n">logger</span><span class="o">.</span><span class="n">get_level</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">level</span><span class="p">)</span>
<span class="go">&#39;0&#39;</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="mindspore.get_log_config">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">get_log_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/log.html#get_log_config"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.get_log_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Get logger configurations.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dict, the dictionary of logger configurations.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">os</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;GLOG_v&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;1&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;GLOG_logtostderr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;0&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;GLOG_log_dir&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;/var/log&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;logger_maxBytes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;5242880&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;logger_backupCount&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;10&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;GLOG_stderrthreshold&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;2&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">log</span> <span class="k">as</span> <span class="n">logger</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config</span><span class="o">=</span> <span class="n">logger</span><span class="o">.</span><span class="n">get_log_config</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="go">{&#39;GLOG_v&#39;: &#39;1&#39;, &#39;GLOG_logtostderr&#39;: &#39;0&#39;, &#39;GLOG_log_dir&#39;: &#39;/var/log&#39;,</span>
<span class="go"> &#39;logger_maxBytes&#39;: &#39;5242880&#39;, &#39;logger_backupCount&#39;: &#39;10&#39;, &#39;GLOG_stderrthreshold&#39;: &#39;2&#39;}</span>
</pre></div>
</div>
</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="mindspore.common.initializer.html" class="btn btn-neutral float-right" title="mindspore.common.initializer" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="../index.html" class="btn btn-neutral float-left" title="MindSpore API" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>