<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.train &mdash; MindSpore master documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="mindspore.profiler" href="mindspore.profiler.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">MindSpore Python API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.compression.html">mindspore.compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.explainer.html">mindspore.explainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.profiler.html">mindspore.profiler</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindspore.train</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.train.summary">mindspore.train.summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.train.callback">mindspore.train.callback</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-mindspore.train.train_thor">mindspore.train.train_thor</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindSpore C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.3/api_cpp/class_list.html">Lite</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>mindspore.train</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api_python/mindspore.train.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mindspore-train">
<h1>mindspore.train<a class="headerlink" href="#mindspore-train" title="Permalink to this headline"></a></h1>
<section id="module-mindspore.train.summary">
<span id="mindspore-train-summary"></span><h2>mindspore.train.summary<a class="headerlink" href="#module-mindspore.train.summary" title="Permalink to this headline"></a></h2>
<p>SummaryRecord.</p>
<p>User can use SummaryRecord to dump the summary data, the summary is a series of operations
to collect data for analysis and visualization.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.summary.SummaryRecord">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.summary.</span></span><span class="sig-name descname"><span class="pre">SummaryRecord</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'events'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_suffix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'_MS'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">network</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_file_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raise_exception</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">export_options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/summary/summary_record.html#SummaryRecord"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.summary.SummaryRecord" title="Permalink to this definition"></a></dt>
<dd><p>SummaryRecord is used to record the summary data and lineage data.</p>
<p>The API will create a summary file and lineage files lazily in a given directory and writes data to them.
It writes the data to files by executing the ‘record’ method. In addition to recording the data bubbled up from
the network by defining the summary operators, SummaryRecord also supports to record extra data which
can be added by calling add_value.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ol class="arabic simple">
<li><p>Make sure to close the SummaryRecord at the end, otherwise the process will not exit.
Please see the Example section below to learn how to close properly in two ways.</p></li>
<li><p>Only one SummaryRecord instance is allowed at a time, otherwise it will cause data writing problems.</p></li>
<li><p>SummaryRecord only supports Linux systems.</p></li>
</ol>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_dir</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The log_dir is a directory location to save the summary.</p></li>
<li><p><strong>file_prefix</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The prefix of file. Default: “events”.</p></li>
<li><p><strong>file_suffix</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The suffix of file. Default: “_MS”.</p></li>
<li><p><strong>network</strong> (<a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Obtain a pipeline through network for saving graph summary. Default: None.</p></li>
<li><p><strong>max_file_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The maximum size of each file that can be written to disk (in bytes).
Unlimited by default. For example, to write not larger than 4GB, specify <cite>max_file_size=4 * 1024 ** 3</cite>.</p></li>
<li><p><strong>raise_exception</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Sets whether to throw an exception when a RuntimeError or OSError exception
occurs in recording data. Default: False, this means that error logs are printed and no exception is thrown.</p></li>
<li><p><strong>export_options</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a><em>]</em>) – <p>Perform custom operations on the export data.
Note that the size of export files is not limited by the max_file_size.
You can customize the export data with a dictionary. For example, you can set {‘tensor_format’: ‘npy’}
to export tensor as npy file. The data that supports control is shown below. Default: None, it means that
the data is not exported.</p>
<ul>
<li><p>tensor_format (Union[str, None]): Customize the export tensor format. Supports [“npy”, None].
Default: None, it means that the tensor is not exported.</p>
<ul>
<li><p>npy: export tensor as npy file.</p></li>
</ul>
</li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If the parameter type is incorrect.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.summary</span> <span class="kn">import</span> <span class="n">SummaryRecord</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
<span class="gp">... </span>    <span class="c1"># use in with statement to auto close</span>
<span class="gp">... </span>    <span class="k">with</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./summary_dir&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">summary_record</span><span class="p">:</span>
<span class="gp">... </span>        <span class="k">pass</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="c1"># use in try .. finally .. to ensure closing</span>
<span class="gp">... </span>    <span class="k">try</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">summary_record</span> <span class="o">=</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./summary_dir&quot;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">finally</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">summary_record</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.summary.SummaryRecord.add_value">
<span class="sig-name descname"><span class="pre">add_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">plugin</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/summary/summary_record.html#SummaryRecord.add_value"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.summary.SummaryRecord.add_value" title="Permalink to this definition"></a></dt>
<dd><p>Add value to be recorded later.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>plugin</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The value of the plugin.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The value of the name.</p></li>
<li><p><strong>value</strong> (<em>Union</em><em>[</em><a class="reference internal" href="mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><em>GraphProto</em><em>, </em><em>TrainLineage</em><em>, </em><em>EvaluationLineage</em><em>, </em><em>DatasetGraph</em><em>, </em><em>UserDefinedInfo</em><em>]</em>) – <p>The value to store.</p>
<ul>
<li><p>The data type of value should be ‘GraphProto’ (see mindspore/ccsrc/anf_ir.proto) object
when the plugin is ‘graph’.</p></li>
<li><p>The data type of value should be ‘Tensor’ object when the plugin is ‘scalar’, ‘image’, ‘tensor’
or ‘histogram’.</p></li>
<li><p>The data type of value should be a ‘TrainLineage’ object when the plugin is ‘train_lineage’,
see mindspore/ccsrc/lineage.proto.</p></li>
<li><p>The data type of value should be a ‘EvaluationLineage’ object when the plugin is ‘eval_lineage’,
see mindspore/ccsrc/lineage.proto.</p></li>
<li><p>The data type of value should be a ‘DatasetGraph’ object when the plugin is ‘dataset_graph’,
see mindspore/ccsrc/lineage.proto.</p></li>
<li><p>The data type of value should be a ‘UserDefinedInfo’ object when the plugin is ‘custom_lineage_data’,
see mindspore/ccsrc/lineage.proto.</p></li>
<li><p>The data type of value should be a ‘Explain’ object when the plugin is ‘explainer’,
see mindspore/ccsrc/summary.proto.</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the parameter value is invalid.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If the parameter type is error.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.summary</span> <span class="kn">import</span> <span class="n">SummaryRecord</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
<span class="gp">... </span>    <span class="k">with</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./summary_dir&quot;</span><span class="p">,</span> <span class="n">file_prefix</span><span class="o">=</span><span class="s2">&quot;xx_&quot;</span><span class="p">,</span> <span class="n">file_suffix</span><span class="o">=</span><span class="s2">&quot;_yy&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">summary_record</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">summary_record</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s1">&#39;scalar&#39;</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.summary.SummaryRecord.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/summary/summary_record.html#SummaryRecord.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.summary.SummaryRecord.close" title="Permalink to this definition"></a></dt>
<dd><p>Flush all events and close summary records. Please use the statement to autoclose.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.summary</span> <span class="kn">import</span> <span class="n">SummaryRecord</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
<span class="gp">... </span>    <span class="k">try</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">summary_record</span> <span class="o">=</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./summary_dir&quot;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">finally</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">summary_record</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.summary.SummaryRecord.flush">
<span class="sig-name descname"><span class="pre">flush</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/summary/summary_record.html#SummaryRecord.flush"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.summary.SummaryRecord.flush" title="Permalink to this definition"></a></dt>
<dd><p>Flush the event file to disk.</p>
<p>Call it to make sure that all pending events have been written to disk.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.summary</span> <span class="kn">import</span> <span class="n">SummaryRecord</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
<span class="gp">... </span>    <span class="k">with</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./summary_dir&quot;</span><span class="p">,</span> <span class="n">file_prefix</span><span class="o">=</span><span class="s2">&quot;xx_&quot;</span><span class="p">,</span> <span class="n">file_suffix</span><span class="o">=</span><span class="s2">&quot;_yy&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">summary_record</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">summary_record</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.summary.SummaryRecord.log_dir">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">log_dir</span></span><a class="headerlink" href="#mindspore.train.summary.SummaryRecord.log_dir" title="Permalink to this definition"></a></dt>
<dd><p>Get the full path of the log file.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>str, the full path of log file.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.summary</span> <span class="kn">import</span> <span class="n">SummaryRecord</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
<span class="gp">... </span>    <span class="k">with</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./summary_dir&quot;</span><span class="p">,</span> <span class="n">file_prefix</span><span class="o">=</span><span class="s2">&quot;xx_&quot;</span><span class="p">,</span> <span class="n">file_suffix</span><span class="o">=</span><span class="s2">&quot;_yy&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">summary_record</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">log_dir</span> <span class="o">=</span> <span class="n">summary_record</span><span class="o">.</span><span class="n">log_dir</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.summary.SummaryRecord.record">
<span class="sig-name descname"><span class="pre">record</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_network</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plugin_filter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/summary/summary_record.html#SummaryRecord.record"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.summary.SummaryRecord.record" title="Permalink to this definition"></a></dt>
<dd><p>Record the summary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>step</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Represents training step number.</p></li>
<li><p><strong>train_network</strong> (<a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – The network to call the callback.</p></li>
<li><p><strong>plugin_filter</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>]</em><em>]</em>) – The filter function,                 which is used to filter out plugins from being written by returning False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>bool, whether the record process is successful or not.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If the parameter type is error.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – If the disk space is insufficient.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.summary</span> <span class="kn">import</span> <span class="n">SummaryRecord</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
<span class="gp">... </span>    <span class="k">with</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./summary_dir&quot;</span><span class="p">,</span> <span class="n">file_prefix</span><span class="o">=</span><span class="s2">&quot;xx_&quot;</span><span class="p">,</span> <span class="n">file_suffix</span><span class="o">=</span><span class="s2">&quot;_yy&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">summary_record</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">summary_record</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="n">step</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.summary.SummaryRecord.set_mode">
<span class="sig-name descname"><span class="pre">set_mode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/summary/summary_record.html#SummaryRecord.set_mode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.summary.SummaryRecord.set_mode" title="Permalink to this definition"></a></dt>
<dd><p>Set the training phase. Different training phases affect data recording.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The mode to be set, which should be ‘train’ or ‘eval’. When the mode is ‘eval’,
summary_record will not record the data of summary operators.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – When the mode is not recognized.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.summary</span> <span class="kn">import</span> <span class="n">SummaryRecord</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
<span class="gp">... </span>    <span class="k">with</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;./summary_dir&quot;</span><span class="p">,</span> <span class="n">file_prefix</span><span class="o">=</span><span class="s2">&quot;xx_&quot;</span><span class="p">,</span> <span class="n">file_suffix</span><span class="o">=</span><span class="s2">&quot;_yy&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">summary_record</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">summary_record</span><span class="o">.</span><span class="n">set_mode</span><span class="p">(</span><span class="s1">&#39;eval&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="module-mindspore.train.callback">
<span id="mindspore-train-callback"></span><h2>mindspore.train.callback<a class="headerlink" href="#module-mindspore.train.callback" title="Permalink to this headline"></a></h2>
<p>Callback related classes and functions.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.callback.Callback">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.callback.</span></span><span class="sig-name descname"><span class="pre">Callback</span></span><a class="reference internal" href="../_modules/mindspore/train/callback/_callback.html#Callback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.Callback" title="Permalink to this definition"></a></dt>
<dd><p>Abstract base class used to build a callback class. Callbacks are context managers
which will be entered and exited when passing into the Model.
You can use this mechanism to initialize and release resources automatically.</p>
<p>Callback function will execute some operations in the current step or epoch.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">Callback</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Print_info</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;step_num: &quot;</span><span class="p">,</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">print_cb</span> <span class="o">=</span> <span class="n">Print_info</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">print_cb</span><span class="p">)</span>
<span class="go">step_num: 1</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.Callback.begin">
<span class="sig-name descname"><span class="pre">begin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_callback.html#Callback.begin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.Callback.begin" title="Permalink to this definition"></a></dt>
<dd><p>Called once before the network executing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Include some information of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.Callback.end">
<span class="sig-name descname"><span class="pre">end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_callback.html#Callback.end"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.Callback.end" title="Permalink to this definition"></a></dt>
<dd><p>Called once after network training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Include some information of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.Callback.epoch_begin">
<span class="sig-name descname"><span class="pre">epoch_begin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_callback.html#Callback.epoch_begin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.Callback.epoch_begin" title="Permalink to this definition"></a></dt>
<dd><p>Called before each epoch beginning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Include some information of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.Callback.epoch_end">
<span class="sig-name descname"><span class="pre">epoch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_callback.html#Callback.epoch_end"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.Callback.epoch_end" title="Permalink to this definition"></a></dt>
<dd><p>Called after each epoch finished.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Include some information of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.Callback.step_begin">
<span class="sig-name descname"><span class="pre">step_begin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_callback.html#Callback.step_begin"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.Callback.step_begin" title="Permalink to this definition"></a></dt>
<dd><p>Called before each step beginning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Include some information of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.Callback.step_end">
<span class="sig-name descname"><span class="pre">step_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_callback.html#Callback.step_end"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.Callback.step_end" title="Permalink to this definition"></a></dt>
<dd><p>Called after each step finished.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Include some information of the model.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.callback.</span></span><span class="sig-name descname"><span class="pre">CheckpointConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_checkpoint_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_checkpoint_seconds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_checkpoint_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_checkpoint_per_n_minutes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integrated_save</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">async_save</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">saved_network</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">append_info</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enc_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enc_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'AES-GCM'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_checkpoint.html#CheckpointConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig" title="Permalink to this definition"></a></dt>
<dd><p>The configuration of model checkpoint.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>During the training process, if dataset is transmitted through the data channel,
It is suggested to set ‘save_checkpoint_steps’ to an integer multiple of loop_size.
Otherwise, the time to save the checkpoint may be biased.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_checkpoint_steps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Steps to save checkpoint. Default: 1.</p></li>
<li><p><strong>save_checkpoint_seconds</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Seconds to save checkpoint.
Can’t be used with save_checkpoint_steps at the same time. Default: 0.</p></li>
<li><p><strong>keep_checkpoint_max</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Maximum number of checkpoint files can be saved. Default: 5.</p></li>
<li><p><strong>keep_checkpoint_per_n_minutes</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Save the checkpoint file every <cite>keep_checkpoint_per_n_minutes</cite> minutes.
Can’t be used with keep_checkpoint_max at the same time. Default: 0.</p></li>
<li><p><strong>integrated_save</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to perform integrated save function in automatic model parallel scene.
Integrated save function is only supported in automatic parallel scene, not supported
in manual parallel. Default: True.</p></li>
<li><p><strong>async_save</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether asynchronous execution saves the checkpoint to a file. Default: False.</p></li>
<li><p><strong>saved_network</strong> (<a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Network to be saved in checkpoint file. If the saved_network has no relation
with the network in training, the initial value of saved_network will be saved. Default: None.</p></li>
<li><p><strong>append_info</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – The information save to checkpoint file. Support “epoch_num”、”step_num”、and dict.
The key of dict must be str, the value of dict must be one of int float and bool. Default: None.</p></li>
<li><p><strong>enc_key</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#bytes" title="(in Python v3.8)"><em>bytes</em></a><em>]</em>) – Byte type key used for encryption. If the value is None, the encryption
is not required. Default: None.</p></li>
<li><p><strong>enc_mode</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – This parameter is valid only when enc_key is not set to None. Specifies the encryption
mode, currently supports ‘AES-GCM’ and ‘AES-CBC’. Default: ‘AES-GCM’.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If input parameter is not the correct type.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">CheckpointConfig</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">LeNet5</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_class</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">super</span><span class="p">(</span><span class="n">LeNet5</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">num_channel</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="n">num_class</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">x</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_path</span> <span class="o">=</span> <span class="s1">&#39;./MNIST_Data&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">saved_network</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ckpoint_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;LeNet5&#39;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="s1">&#39;./checkpoint&#39;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">ckpoint_cb</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.append_dict">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">append_dict</span></span><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.append_dict" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of append_dict.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.async_save">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">async_save</span></span><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.async_save" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of _async_save.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.enc_key">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">enc_key</span></span><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.enc_key" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of _enc_key</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.enc_mode">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">enc_mode</span></span><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.enc_mode" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of _enc_mode</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.get_checkpoint_policy">
<span class="sig-name descname"><span class="pre">get_checkpoint_policy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_checkpoint.html#CheckpointConfig.get_checkpoint_policy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.get_checkpoint_policy" title="Permalink to this definition"></a></dt>
<dd><p>Get the policy of checkpoint.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.integrated_save">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">integrated_save</span></span><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.integrated_save" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of _integrated_save.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.keep_checkpoint_max">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">keep_checkpoint_max</span></span><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.keep_checkpoint_max" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of _keep_checkpoint_max.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.keep_checkpoint_per_n_minutes">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">keep_checkpoint_per_n_minutes</span></span><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.keep_checkpoint_per_n_minutes" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of _keep_checkpoint_per_n_minutes.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.save_checkpoint_seconds">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">save_checkpoint_seconds</span></span><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.save_checkpoint_seconds" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of _save_checkpoint_seconds.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.save_checkpoint_steps">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">save_checkpoint_steps</span></span><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.save_checkpoint_steps" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of _save_checkpoint_steps.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.CheckpointConfig.saved_network">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">saved_network</span></span><a class="headerlink" href="#mindspore.train.callback.CheckpointConfig.saved_network" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of _saved_network</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.callback.LearningRateScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.callback.</span></span><span class="sig-name descname"><span class="pre">LearningRateScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">learning_rate_function</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_lr_scheduler_callback.html#LearningRateScheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.LearningRateScheduler" title="Permalink to this definition"></a></dt>
<dd><p>Change the learning_rate during training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>learning_rate_function</strong> (<em>Function</em>) – The function about how to change the learning rate during training.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">LearningRateScheduler</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">learning_rate_function</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">cur_step_num</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">if</span> <span class="n">cur_step_num</span><span class="o">%</span><span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span><span class="o">*</span><span class="mf">0.1</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">lr</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">(</span><span class="s2">&quot;custom_dataset_path&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">learning_rate_function</span><span class="p">)],</span>
<span class="gp">... </span>            <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.callback.LossMonitor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.callback.</span></span><span class="sig-name descname"><span class="pre">LossMonitor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">per_print_times</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_loss_monitor.html#LossMonitor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.LossMonitor" title="Permalink to this definition"></a></dt>
<dd><p>Monitor the loss in training.</p>
<p>If the loss is NAN or INF, it will terminate training.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If per_print_times is 0, do not print loss.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>per_print_times</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Print the loss each every seconds. Default: 1.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If per_print_times is not an integer or less than zero.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.callback.ModelCheckpoint">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.callback.</span></span><span class="sig-name descname"><span class="pre">ModelCheckpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'CKP'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">directory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_checkpoint.html#ModelCheckpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.ModelCheckpoint" title="Permalink to this definition"></a></dt>
<dd><p>The checkpoint callback class.</p>
<p>It is called to combine with train process and save the model and network parameters after training.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In the distributed training scenario, please specify different directories for each training process
to save the checkpoint file. Otherwise, the training may fail.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The prefix name of checkpoint files. Default: “CKP”.</p></li>
<li><p><strong>directory</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The path of the folder which will be saved in the checkpoint file.
By default, the file is saved in the current directory. Default: None.</p></li>
<li><p><strong>config</strong> (<a class="reference internal" href="#mindspore.train.callback.CheckpointConfig" title="mindspore.train.callback.CheckpointConfig"><em>CheckpointConfig</em></a>) – Checkpoint strategy configuration. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the prefix is invalid.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If the config is not CheckpointConfig type.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.ModelCheckpoint.end">
<span class="sig-name descname"><span class="pre">end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_checkpoint.html#ModelCheckpoint.end"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.ModelCheckpoint.end" title="Permalink to this definition"></a></dt>
<dd><p>Save the last checkpoint after training finished.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Context of the train running.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.train.callback.ModelCheckpoint.latest_ckpt_file_name">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">latest_ckpt_file_name</span></span><a class="headerlink" href="#mindspore.train.callback.ModelCheckpoint.latest_ckpt_file_name" title="Permalink to this definition"></a></dt>
<dd><p>Return the latest checkpoint path and file name.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.ModelCheckpoint.step_end">
<span class="sig-name descname"><span class="pre">step_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_checkpoint.html#ModelCheckpoint.step_end"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.ModelCheckpoint.step_end" title="Permalink to this definition"></a></dt>
<dd><p>Save the checkpoint at the end of step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_context</strong> (<a class="reference internal" href="#mindspore.train.callback.RunContext" title="mindspore.train.callback.RunContext"><em>RunContext</em></a>) – Context of the train running.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.callback.RunContext">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.callback.</span></span><span class="sig-name descname"><span class="pre">RunContext</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">original_args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_callback.html#RunContext"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.RunContext" title="Permalink to this definition"></a></dt>
<dd><p>Provide information about the model.</p>
<p>Provide information about original request to model function.
Callback objects can stop the loop by calling request_stop() of run_context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>original_args</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – Holding the related information of model.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.RunContext.get_stop_requested">
<span class="sig-name descname"><span class="pre">get_stop_requested</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_callback.html#RunContext.get_stop_requested"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.RunContext.get_stop_requested" title="Permalink to this definition"></a></dt>
<dd><p>Return whether a stop is requested or not.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>bool, if true, model.train() stops iterations.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.RunContext.original_args">
<span class="sig-name descname"><span class="pre">original_args</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_callback.html#RunContext.original_args"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.RunContext.original_args" title="Permalink to this definition"></a></dt>
<dd><p>Get the _original_args object.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dict, an object that holds the original arguments of model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.callback.RunContext.request_stop">
<span class="sig-name descname"><span class="pre">request_stop</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_callback.html#RunContext.request_stop"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.RunContext.request_stop" title="Permalink to this definition"></a></dt>
<dd><p>Set stop requirement during training.</p>
<p>Callbacks can use this function to request stop of iterations.
model.train() checks whether this is called or not.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.callback.SummaryCollector">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.callback.</span></span><span class="sig-name descname"><span class="pre">SummaryCollector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">summary_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collect_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collect_specified_data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_default_action</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_lineage_data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collect_tensor_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_file_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">export_options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_summary_collector.html#SummaryCollector"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.SummaryCollector" title="Permalink to this definition"></a></dt>
<dd><p>SummaryCollector can help you to collect some common information.</p>
<p>It can help you to collect loss, learning late, computational graph and so on.
SummaryCollector also enables the summary operator to collect data to summary files.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ol class="arabic simple">
<li><p>Multiple SummaryCollector instances in callback list are not allowed.</p></li>
<li><p>Not all information is collected at the training phase or at the eval phase.</p></li>
<li><p>SummaryCollector always record the data collected by the summary operator.</p></li>
<li><p>SummaryCollector only supports Linux systems.</p></li>
</ol>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>summary_dir</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – The collected data will be persisted to this directory.
If the directory does not exist, it will be created automatically.</p></li>
<li><p><strong>collect_freq</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Set the frequency of data collection, it should be greater then zero,
and the unit is <cite>step</cite>. If a frequency is set, we will collect data
when (current steps % freq) equals to 0, and the first step will be collected at any time.
It is important to note that if the data sink mode is used, the unit will become the <cite>epoch</cite>.
It is not recommended to collect data too frequently, which can affect performance. Default: 10.</p></li>
<li><p><strong>collect_specified_data</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a><em>]</em>) – <p>Perform custom operations on the collected data.
By default, if set to None, all data is collected as the default behavior.
You can customize the collected data with a dictionary.
For example, you can set {‘collect_metric’: False} to control not collecting metrics.
The data that supports control is shown below. Default: None.</p>
<ul>
<li><p>collect_metric (bool): Whether to collect training metrics, currently only the loss is collected.
The first output will be treated as the loss and it will be averaged.
Optional: True/False. Default: True.</p></li>
<li><p>collect_graph (bool): Whether to collect the computational graph. Currently, only
training computational graph is collected. Optional: True/False. Default: True.</p></li>
<li><p>collect_train_lineage (bool): Whether to collect lineage data for the training phase,
this field will be displayed on the lineage page of Mindinsight. Optional: True/False. Default: True.</p></li>
<li><p>collect_eval_lineage (bool): Whether to collect lineage data for the evaluation phase,
this field will be displayed on the lineage page of Mindinsight. Optional: True/False. Default: True.</p></li>
<li><p>collect_input_data (bool): Whether to collect dataset for each training.
Currently only image data is supported.
If there are multiple columns of data in the dataset, the first column should be image data.
Optional: True/False. Default: True.</p></li>
<li><p>collect_dataset_graph (bool): Whether to collect dataset graph for the training phase.
Optional: True/False. Default: True.</p></li>
<li><p>histogram_regular (Union[str, None]): Collect weight and bias for parameter distribution page
and displayed in MindInsight. This field allows regular strings to control which parameters to collect.
It is not recommended to collect too many parameters at once, as it can affect performance.
Note that if you collect too many parameters and run out of memory, the training will fail.
Default: None, it means only the first five parameters are collected.</p></li>
</ul>
</p></li>
<li><p><strong>keep_default_action</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – This field affects the collection behavior of the ‘collect_specified_data’ field.
True: it means that after specified data is set, non-specified data is collected as the default behavior.
False: it means that after specified data is set, only the specified data is collected,
and the others are not collected. Optional: True/False, Default: True.</p></li>
<li><p><strong>custom_lineage_data</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a><em>, </em><em>None</em><em>]</em>) – Allows you to customize the data and present it on the MingInsight
lineage page. In the custom data, the type of the key supports str, and the type of value supports str, int
and float. Default: None, it means there is no custom data.</p></li>
<li><p><strong>collect_tensor_freq</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – The same semantics as the <cite>collect_freq</cite>, but controls TensorSummary only.
Because TensorSummary data is too large to be compared with other summary data, this parameter is used to
reduce its collection. By default, The maximum number of steps for collecting TensorSummary data is 20,
but it will not exceed the number of steps for collecting other summary data.
For example, given <cite>collect_freq=10</cite>, when the total steps is 600, TensorSummary will be collected 20 steps,
while other summary data 61 steps,
but when the total steps is 20, both TensorSummary and other summary will be collected 3 steps.
Also note that when in parallel mode, the total steps will be split evenly, which will
affect the number of steps TensorSummary will be collected.
Default: None, which means to follow the behavior as described above.</p></li>
<li><p><strong>max_file_size</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – The maximum size in bytes of each file that can be written to the disk.
For example, to write not larger than 4GB, specify <cite>max_file_size=4*1024**3</cite>.
Default: None, which means no limit.</p></li>
<li><p><strong>export_options</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a><em>]</em>) – <p>Perform custom operations on the export data.
Note that the size of export files is not limited by the max_file_size.
You can customize the export data with a dictionary. For example, you can set {‘tensor_format’: ‘npy’}
to export tensor as npy file. The data that supports control is shown below.
Default: None, it means that the data is not exported.</p>
<ul>
<li><p>tensor_format (Union[str, None]): Customize the export tensor format. Supports [“npy”, None].
Default: None, it means that the tensor is not exported.</p>
<ul>
<li><p>npy: export tensor as npy file.</p></li>
</ul>
</li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the parameter value is not expected.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If the parameter type is not expected.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – If an error occurs during data collection.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">SummaryCollector</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.nn.metrics</span> <span class="kn">import</span> <span class="n">Accuracy</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
<span class="gp">... </span>    <span class="c1"># If the device_target is GPU, set the device_target to &quot;GPU&quot;</span>
<span class="gp">... </span>    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">mnist_dataset_dir</span> <span class="o">=</span> <span class="s1">&#39;/path/to/mnist_dataset_directory&#39;</span>
<span class="gp">... </span>    <span class="c1"># The detail of create_dataset method shown in model_zoo.official.cv.lenet.src.dataset.py</span>
<span class="gp">... </span>    <span class="n">ds_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">mnist_dataset_dir</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">... </span>    <span class="c1"># The detail of LeNet5 shown in model_zoo.official.cv.lenet.src.lenet.py</span>
<span class="gp">... </span>    <span class="n">network</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">net_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">net_opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">,</span> <span class="n">net_opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">Accuracy</span><span class="p">()},</span> <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O2&quot;</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="c1"># Simple usage:</span>
<span class="gp">... </span>    <span class="n">summary_collector</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector</span><span class="p">],</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="c1"># Do not collect metric and collect the first layer parameter, others are collected by default</span>
<span class="gp">... </span>    <span class="n">specified</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;collect_metric&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;histogram_regular&#39;</span><span class="p">:</span> <span class="s1">&#39;^conv1.*&#39;</span><span class="p">}</span>
<span class="gp">... </span>    <span class="n">summary_collector</span> <span class="o">=</span> <span class="n">SummaryCollector</span><span class="p">(</span><span class="n">summary_dir</span><span class="o">=</span><span class="s1">&#39;./summary_dir&#39;</span><span class="p">,</span> <span class="n">collect_specified_data</span><span class="o">=</span><span class="n">specified</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ds_train</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">summary_collector</span><span class="p">],</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.callback.TimeMonitor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.callback.</span></span><span class="sig-name descname"><span class="pre">TimeMonitor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/callback/_time_monitor.html#TimeMonitor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.callback.TimeMonitor" title="Permalink to this definition"></a></dt>
<dd><p>Monitor the time in training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – How many steps are the intervals between print information each time.
if the program get <cite>batch_num</cite> during training, <cite>data_size</cite> will be set to <cite>batch_num</cite>,
otherwise <cite>data_size</cite> will be used. Default: None.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If data_size is not positive int.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-mindspore.train.train_thor">
<span id="mindspore-train-train-thor"></span><h2>mindspore.train.train_thor<a class="headerlink" href="#module-mindspore.train.train_thor" title="Permalink to this headline"></a></h2>
<p>convert to second order related classes and functions.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.train_thor.ConvertModelUtils">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.train_thor.</span></span><span class="sig-name descname"><span class="pre">ConvertModelUtils</span></span><a class="reference internal" href="../_modules/mindspore/train/train_thor/convert_utils.html#ConvertModelUtils"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.train_thor.ConvertModelUtils" title="Permalink to this definition"></a></dt>
<dd><p>Convert model to thor model.</p>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.train_thor.ConvertModelUtils.convert_to_thor_model">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">convert_to_thor_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amp_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'O0'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_scale_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_batchnorm_fp32</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/train_thor/convert_utils.html#ConvertModelUtils.convert_to_thor_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.train_thor.ConvertModelUtils.convert_to_thor_model" title="Permalink to this definition"></a></dt>
<dd><p>This interface is used to convert model to thor model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>Object</em>) – High-Level API for Training.
<cite>Model</cite> groups layers into an object with training features.</p></li>
<li><p><strong>network</strong> (<a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – A training network.</p></li>
<li><p><strong>loss_fn</strong> (<a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Objective function. Default: None.</p></li>
<li><p><strong>optimizer</strong> (<a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Optimizer used to updating the weights. Default: None.</p></li>
<li><p><strong>metrics</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#set" title="(in Python v3.8)"><em>set</em></a><em>]</em>) – A Dictionary or a set of metrics to be evaluated by the model during
training. eg: {‘accuracy’, ‘recall’}. Default: None.</p></li>
<li><p><strong>amp_level</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>Level for mixed precision training. Supports [“O0”, “O2”, “O3”, “auto”]. Default: “O0”.</p>
<ul>
<li><p>O0: Do not change.</p></li>
<li><p>O2: Cast network to float16, keep batchnorm run in float32, using dynamic loss scale.</p></li>
<li><p>O3: Cast network to float16, with additional property ‘keep_batchnorm_fp32=False’.</p></li>
<li><p>auto: Set level to recommended level in different devices. O2 is recommended on GPU, O3 is
recommended on Ascend. The recommended level is based on the expert experience, cannot
always generalize. User should specify the level for special network.</p></li>
</ul>
</p></li>
<li><p><strong>loss_scale_manager</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference internal" href="mindspore.html#mindspore.LossScaleManager" title="mindspore.LossScaleManager"><em>LossScaleManager</em></a><em>]</em>) – If it is None, the loss would not be scaled.
Otherwise, scale the loss by LossScaleManager and optimizer can not be None. It is a key argument.
e.g. Use <cite>loss_scale_manager=None</cite> to set the value.</p></li>
<li><p><strong>keep_batchnorm_fp32</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Keep Batchnorm running in <cite>float32</cite>. If True, the level setting before
will be overwritten. Default: True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>High-Level API for Training.</dt><dd><p><cite>Model</cite> groups layers into an object with training features.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>model (Object)</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.nn.optim</span> <span class="kn">import</span> <span class="n">thor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.model</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train.loss_scale_manager</span> <span class="kn">import</span> <span class="n">FixedLossScaleManager</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_manager</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">drop_overflow_update</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">thor</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">damping</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
<span class="gp">... </span>           <span class="n">frequency</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_manager</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;acc&quot;</span><span class="p">},</span>
<span class="gp">... </span>              <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O2&quot;</span><span class="p">,</span> <span class="n">keep_batchnorm_fp32</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ConvertModelUtils</span><span class="p">()</span><span class="o">.</span><span class="n">convert_to_thor_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span>
<span class="gp">... </span>                                                  <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">},</span> <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O2&quot;</span><span class="p">,</span>
<span class="gp">... </span>                                                  <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_manager</span><span class="p">,</span>
<span class="gp">... </span>                                                  <span class="n">keep_batchnorm_fp32</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.train_thor.ConvertNetUtils">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.train_thor.</span></span><span class="sig-name descname"><span class="pre">ConvertNetUtils</span></span><a class="reference internal" href="../_modules/mindspore/train/train_thor/convert_utils.html#ConvertNetUtils"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.train_thor.ConvertNetUtils" title="Permalink to this definition"></a></dt>
<dd><p>Convert net to thor layer net</p>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.train_thor.ConvertNetUtils.convert_to_thor_net">
<span class="sig-name descname"><span class="pre">convert_to_thor_net</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">net</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mindspore/train/train_thor/convert_utils.html#ConvertNetUtils.convert_to_thor_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.train.train_thor.ConvertNetUtils.convert_to_thor_net" title="Permalink to this definition"></a></dt>
<dd><p>This interface is used to convert a network to thor layer network, in order to calculate and store the
second-order information matrix.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This interface is automatically called by the second-order optimizer thor.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>net</strong> (<a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Network to be trained by the second-order optimizer thor.</p>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ConvertNetUtils</span><span class="p">()</span><span class="o">.</span><span class="n">convert_to_thor_net</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindspore.profiler.html" class="btn btn-neutral float-left" title="mindspore.profiler" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>