

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindspore.Model &mdash; MindSpore master documentation</title>
  

  
   
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="mindspore.DatasetHelper" href="mindspore.DatasetHelper.html" />
    <link rel="prev" title="mindspore.get_seed" href="mindspore.get_seed.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">MindSpore Python API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../mindspore.html">mindspore</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#tensor">Tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#parameter">Parameter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#datatype">DataType</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#seed">Seed</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../mindspore.html#model">Model</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">mindspore.Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#dataset-helper">Dataset Helper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#loss-scale-manager">Loss Scale Manager</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#serialization">Serialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#jit">JIT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#log">Log</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#automatic-mixed-precision">Automatic Mixed Precision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#installation-verification">Installation Verification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#debugging">Debugging</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#memory-recycle">Memory Recycle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.compression.html">mindspore.compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.audio.html">mindspore.dataset.audio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.transformer.html">mindspore.nn.transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.parallel.html">mindspore.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.parallel.nn.html">mindspore.parallel.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.profiler.html">mindspore.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.boost.html">mindspore.boost (experimental)</a></li>
</ul>
<p class="caption"><span class="caption-text">MindSpore C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.6/api_cpp/mindspore.html">MindSpore Lite↗</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../mindspore.html">mindspore</a> &raquo;</li>
        
      <li>mindspore.Model</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/api_python/mindspore/mindspore.Model.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="mindspore-model">
<h1>mindspore.Model<a class="headerlink" href="#mindspore-model" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="mindspore.Model">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">Model</code><span class="sig-paren">(</span><em class="sig-param">network</em>, <em class="sig-param">loss_fn=None</em>, <em class="sig-param">optimizer=None</em>, <em class="sig-param">metrics=None</em>, <em class="sig-param">eval_network=None</em>, <em class="sig-param">eval_indexes=None</em>, <em class="sig-param">amp_level=&quot;O0&quot;</em>, <em class="sig-param">boost_level=&quot;O0&quot;</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/train/model.html#Model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Model" title="Permalink to this definition">¶</a></dt>
<dd><p>High-Level API for training or inference.</p>
<p><cite>Model</cite> groups layers into an object with training and inference features based on the arguments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<a class="reference internal" href="../nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – A training or testing network.</p></li>
<li><p><strong>loss_fn</strong> (<a class="reference internal" href="../nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Objective function. If <cite>loss_fn</cite> is None, the <cite>network</cite> should contain the calculation of loss
and parallel if needed. Default: None.</p></li>
<li><p><strong>optimizer</strong> (<a class="reference internal" href="../nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Optimizer for updating the weights. If <cite>optimizer</cite> is None, the <cite>network</cite> needs to
do backpropagation and update weights. Default value: None.</p></li>
<li><p><strong>metrics</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#set" title="(in Python v3.8)"><em>set</em></a><em>]</em>) – A Dictionary or a set of metrics for model evaluation.
eg: {‘accuracy’, ‘recall’}. Default: None.</p></li>
<li><p><strong>eval_network</strong> (<a class="reference internal" href="../nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><em>Cell</em></a>) – Network for evaluation. If not defined, <cite>network</cite> and <cite>loss_fn</cite> would be wrapped as
<cite>eval_network</cite> . Default: None.</p></li>
<li><p><strong>eval_indexes</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – It is used when eval_network is defined. If <cite>eval_indexes</cite> is None by default, all outputs
of the <cite>eval_network</cite> would be passed to metrics. If <cite>eval_indexes</cite> is set, it must contain
three elements: the positions of loss value, predicted value and label in outputs of the
<cite>eval_network</cite>. In this case, the loss value will be passed to the <cite>Loss</cite> metric, the
predicted value and label will be passed to other metrics.
:func: <cite>mindindex.nn.metric.set_indexes</cite> is recommended instead of <cite>eval_indexes</cite>.
Default: None.</p></li>
<li><p><strong>amp_level</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>Option for argument <cite>level</cite> in <a class="reference internal" href="mindspore.build_train_network.html#mindspore.build_train_network" title="mindspore.build_train_network"><code class="xref py py-func docutils literal notranslate"><span class="pre">mindspore.build_train_network()</span></code></a>, level for mixed
precision training. Supports [“O0”, “O2”, “O3”, “auto”]. Default: “O0”.</p>
<ul>
<li><p>O0: Do not change.</p></li>
<li><p>O2: Cast network to float16, keep batchnorm run in float32, using dynamic loss scale.</p></li>
<li><p>O3: Cast network to float16, the batchnorm is also cast to float16, loss scale will not be used.</p></li>
<li><p>auto: Set level to recommended level in different devices. Set level to O2 on GPU, set
level to O3 on Ascend. The recommended level is chosen by the export experience, not applicable to all
scenarios. User should specify the level for special network.</p></li>
</ul>
<p>O2 is recommended on GPU, O3 is recommended on Ascend.
The batchnorm strategy can be changed by <cite>keep_batchnorm_fp32</cite> settings in <cite>kwargs</cite>. <cite>keep_batchnorm_fp32</cite>
must be a bool. The loss scale strategy can be changed by <cite>loss_scale_manager</cite> setting in <cite>kwargs</cite>.
<cite>loss_scale_manager</cite> should be a subclass of <a class="reference internal" href="mindspore.LossScaleManager.html#mindspore.LossScaleManager" title="mindspore.LossScaleManager"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.LossScaleManager</span></code></a>.
The more detailed explanation of <cite>amp_level</cite> setting can be found at <cite>mindspore.build_train_network</cite>.</p>
</p></li>
<li><p><strong>boost_level</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>Option for argument <cite>level</cite> in <cite>mindspore.boost</cite>, level for boost mode
training. Supports [“O0”, “O1”, “O2”]. Default: “O0”.</p>
<ul>
<li><p>O0: Do not change.</p></li>
<li><p>O1: Enable the boost mode, the performance is improved by about 20%, and
the accuracy is the same as the original accuracy.</p></li>
<li><p>O2: Enable the boost mode, the performance is improved by about 30%, and
the accuracy is reduced by less than 3%.</p></li>
</ul>
<p>If you want to config boost mode by yourself, you can set boost_config_dict as <cite>boost.py</cite>.</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_class</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_channel</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">num_channel</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="o">*</span><span class="mi">5</span><span class="o">*</span><span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;ones&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;ones&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="n">num_class</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;ones&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">x</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># For details about how to build the dataset, please refer to the tutorial</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># document on the official website.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore.Model.build">
<code class="sig-name descname">build</code><span class="sig-paren">(</span><em class="sig-param">train_dataset=None</em>, <em class="sig-param">valid_dataset=None</em>, <em class="sig-param">sink_size=-1</em>, <em class="sig-param">epoch=1</em>, <em class="sig-param">jit_config=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/train/model.html#Model.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Model.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Build computational graphs and data graphs with the sink mode.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This is an experimental prototype that is subject to change or deletion.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The interface builds the computational graphs, when the interface is executed first, ‘Model.train’ only
performs the graphs execution. Pre-build process only supports <cite>GRAPH_MODE</cite> and <cite>Ascend</cite> target currently.
It only supports dataset sink mode.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> (<em>Dataset</em>) – A training dataset iterator. If <cite>train_dataset</cite> is defined, training graphs will be
built. Default: None.</p></li>
<li><p><strong>valid_dataset</strong> (<em>Dataset</em>) – An evaluating dataset iterator. If <cite>valid_dataset</cite> is defined, evaluation graphs
will be built, and <cite>metrics</cite> in <cite>Model</cite> can not be None. Default: None.</p></li>
<li><p><strong>sink_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Control the amount of data in each sink. Default: -1.</p></li>
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Control the training epochs. Default: 1.</p></li>
<li><p><strong>jit_config</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>]</em>) – <p>Control the jit config.
By default, if set to None, the graph will compile as the default behavior.
You can customize the compile config with a dictionary.
For example, you can set {‘jit_level’: ‘o0’} to control the jit level.
The data that supports control is shown below. Default: None.</p>
<ul>
<li><p>jit_level (string): Control the graph compile optimize level.
Optional: o0/o1. Default: o1. If set to o0, the graph compiling will pass
the combine like graph phase.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">FixedLossScaleManager</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># For details about how to build the dataset, please refer to the tutorial</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># document on the official website.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Model.eval">
<code class="sig-name descname">eval</code><span class="sig-paren">(</span><em class="sig-param">valid_dataset</em>, <em class="sig-param">callbacks=None</em>, <em class="sig-param">dataset_sink_mode=True</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/train/model.html#Model.eval"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Model.eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluation API.</p>
<p>Configure to pynative mode or CPU, the evaluating process will be performed with dataset non-sink mode.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If dataset_sink_mode is True, data will be sent to device. If the device is Ascend, features
of data will be transferred one by one. The limitation of data transmission per time is 256M.</p>
<p>If dataset_sink_mode is True, dataset will be bound to this model and cannot be used by other models.</p>
<p>The interface builds the computational graphs and then executes the computational graphs. However, when
the <cite>Model.build</cite> is executed first, it only performs the graphs execution.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>valid_dataset</strong> (<em>Dataset</em>) – Dataset to evaluate the model.</p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>(</em><a class="reference internal" href="../mindspore.train.html#mindspore.train.callback.Callback" title="mindspore.train.callback.Callback"><em>Callback</em></a><em>)</em><em>, </em><a class="reference internal" href="../mindspore.train.html#mindspore.train.callback.Callback" title="mindspore.train.callback.Callback"><em>Callback</em></a><em>]</em>) – List of callback objects or callback object,
which should be executed while evaluation.
Default: None.</p></li>
<li><p><strong>dataset_sink_mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Determines whether to pass the data through dataset channel.
Default: True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict, the key is the metric name defined by users and the value is the metrics value for
the model in the test mode.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># For details about how to build the dataset, please refer to the tutorial</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># document on the official website.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Model.eval_network">
<em class="property">property </em><code class="sig-name descname">eval_network</code><a class="headerlink" href="#mindspore.Model.eval_network" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the model’s eval network.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Object, the instance of evaluate network.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.Model.infer_predict_layout">
<code class="sig-name descname">infer_predict_layout</code><span class="sig-paren">(</span><em class="sig-param">*predict_data</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/train/model.html#Model.infer_predict_layout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Model.infer_predict_layout" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate parameter layout for the predict network in ‘AUTO_PARALLEL’ or ‘SEMI_AUTO_PARALLEL’ mode.</p>
<p>Data could be a single tensor or multiple tensors.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Batch data should be put together in one tensor.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>predict_data</strong> (<a class="reference internal" href="mindspore.Tensor.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – One tensor or multiple tensors of predict data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict, Parameter layout dictionary used for load distributed checkpoint.
Using as one of input parameters of load_distributed_checkpoint, always.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – If not in GRAPH_MODE.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># This example should be run with multiple devices. Refer to the tutorial &gt; Distributed Training on</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.cn.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.context</span> <span class="kn">import</span> <span class="n">ParallelMode</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">full_batch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parallel_mode</span><span class="o">=</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">SEMI_AUTO_PARALLEL</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">Net</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">predict_map</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">infer_predict_layout</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Model.infer_train_layout">
<code class="sig-name descname">infer_train_layout</code><span class="sig-paren">(</span><em class="sig-param">train_dataset</em>, <em class="sig-param">dataset_sink_mode=True</em>, <em class="sig-param">sink_size=-1</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/train/model.html#Model.infer_train_layout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Model.infer_train_layout" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate parameter layout for the train network in ‘AUTO_PARALLEL’ or ‘SEMI_AUTO_PARALLEL’ mode.
Only dataset sink mode is supported for now.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This is an experimental prototype that is subject to change and/or deletion.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This is a pre-compile function. The arguments should be the same as model.train() function.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> (<em>Dataset</em>) – A training dataset iterator. If there is no
loss_fn, a tuple with multiple data (data1, data2, data3, …) should be
returned and passed to the network. Otherwise, a tuple (data, label) should
be returned. The data and label would be passed to the network and loss
function respectively.</p></li>
<li><p><strong>dataset_sink_mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Determines whether to pass the data through dataset channel.
Configure pynative mode or CPU, the training process will be performed with
dataset not sink. Default: True.</p></li>
<li><p><strong>sink_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Control the amount of data in each sink.
If sink_size = -1, sink the complete dataset for each epoch.
If sink_size &gt; 0, sink sink_size data for each epoch.
If dataset_sink_mode is False, set sink_size as invalid.
Default: -1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dict, Parameter layout dictionary used for load distributed checkpoint</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># This example should be run with multiple devices. Refer to the tutorial &gt; Distributed Training on</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.cn.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">FixedLossScaleManager</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.context</span> <span class="kn">import</span> <span class="n">ParallelMode</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">parallel_mode</span><span class="o">=</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">SEMI_AUTO_PARALLEL</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># For details about how to build the dataset, please refer to the tutorial</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># document on the official website.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">layout_dict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">infer_train_layout</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Model.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">*predict_data</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/train/model.html#Model.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Model.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate output predictions for the input samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>predict_data</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="mindspore.Tensor.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference internal" href="mindspore.Tensor.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference internal" href="mindspore.Tensor.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>]</em><em>]</em>) – The predict data, can be a single tensor,
a list of tensor, or a tuple of tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor, array(s) of predictions.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">Net</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Model.predict_network">
<em class="property">property </em><code class="sig-name descname">predict_network</code><a class="headerlink" href="#mindspore.Model.predict_network" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the model’s predict network.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Object, the instance of predict network.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mindspore.Model.train">
<code class="sig-name descname">train</code><span class="sig-paren">(</span><em class="sig-param">epoch</em>, <em class="sig-param">train_dataset</em>, <em class="sig-param">callbacks=None</em>, <em class="sig-param">dataset_sink_mode=True</em>, <em class="sig-param">sink_size=-1</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/train/model.html#Model.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mindspore.Model.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Training API.</p>
<p>When setting pynative mode or CPU, the training process will be performed with dataset not sink.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If dataset_sink_mode is True, data will be sent to device. If the device is Ascend, features
of data will be transferred one by one. The limitation of data transmission per time is 256M.</p>
<p>When dataset_sink_mode is True, the <cite>step_end</cite> method of the instance of Callback will be called at the end
of epoch.</p>
<p>If dataset_sink_mode is True, dataset will be bound to this model and cannot be used by other models.</p>
<p>If sink_size &gt; 0, each epoch of the dataset can be traversed unlimited times until you get sink_size
elements of the dataset. The next epoch continues to traverse from the end position of the previous
traversal.</p>
<p>The interface builds the computational graphs and then executes the computational graphs. However, when
the <cite>Model.build</cite> is executed first, it only performs the graphs execution.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Total training epochs. Generally, train network will be trained on complete dataset per epoch.
If <cite>dataset_sink_mode</cite> is set to True and <cite>sink_size</cite> is greater than 0, each epoch will
train <cite>sink_size</cite> steps instead of total steps of dataset.</p></li>
<li><p><strong>train_dataset</strong> (<em>Dataset</em>) – A training dataset iterator. If <cite>loss_fn</cite> is defined, the data and label will be
passed to the <cite>network</cite> and the <cite>loss_fn</cite> respectively, so a tuple (data, label)
should be returned from dataset. If there is multiple data or labels, set <cite>loss_fn</cite>
to None and implement calculation of loss in <cite>network</cite>,
then a tuple (data1, data2, data3, …) with all data returned from dataset will be
passed to the <cite>network</cite>.</p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference internal" href="../mindspore.train.html#mindspore.train.callback.Callback" title="mindspore.train.callback.Callback"><em>Callback</em></a><em>]</em><em>, </em><a class="reference internal" href="../mindspore.train.html#mindspore.train.callback.Callback" title="mindspore.train.callback.Callback"><em>Callback</em></a><em>]</em>) – List of callback objects or callback object,
which should be executed while training.
Default: None.</p></li>
<li><p><strong>dataset_sink_mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Determines whether to pass the data through dataset channel.
Configure pynative mode or CPU, the training process will be performed with
dataset not sink. Default: True.</p></li>
<li><p><strong>sink_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Control the amount of data in each sink. <cite>sink_size</cite> is invalid if <cite>dataset_sink_mode</cite>
is False.
If sink_size = -1, sink the complete dataset for each epoch.
If sink_size &gt; 0, sink sink_size data for each epoch.
Default: -1.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">FixedLossScaleManager</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># For details about how to build the dataset, please refer to the tutorial</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># document on the official website.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_custom_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Model.train_network">
<em class="property">property </em><code class="sig-name descname">train_network</code><a class="headerlink" href="#mindspore.Model.train_network" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the model’s train network.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Object, the instance of train network.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="mindspore.DatasetHelper.html" class="btn btn-neutral float-right" title="mindspore.DatasetHelper" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="mindspore.get_seed.html" class="btn btn-neutral float-left" title="mindspore.get_seed" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>