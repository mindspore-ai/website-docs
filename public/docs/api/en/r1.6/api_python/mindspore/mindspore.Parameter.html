<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.Parameter &mdash; MindSpore master documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="mindspore.ParameterTuple" href="mindspore.ParameterTuple.html" />
    <link rel="prev" title="mindspore.SparseTensor" href="mindspore.SparseTensor.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">MindSpore Python API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../mindspore.html">mindspore</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#tensor">Tensor</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../mindspore.html#parameter">Parameter</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">mindspore.Parameter</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.ParameterTuple.html">mindspore.ParameterTuple</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#datatype">DataType</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#seed">Seed</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#model">Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#dataset-helper">Dataset Helper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#loss-scale-manager">Loss Scale Manager</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#serialization">Serialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#jit">JIT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#log">Log</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#automatic-mixed-precision">Automatic Mixed Precision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#installation-verification">Installation Verification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#debugging">Debugging</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#memory-recycle">Memory Recycle</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.compression.html">mindspore.compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.audio.html">mindspore.dataset.audio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.transformer.html">mindspore.nn.transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.parallel.html">mindspore.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.parallel.nn.html">mindspore.parallel.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.profiler.html">mindspore.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.boost.html">mindspore.boost (experimental)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindSpore C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.6/api_cpp/mindspore.html">MindSpore Lite↗</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../mindspore.html">mindspore</a> &raquo;</li>
      <li>mindspore.Parameter</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/api_python/mindspore/mindspore.Parameter.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mindspore-parameter">
<h1>mindspore.Parameter<a class="headerlink" href="#mindspore-parameter" title="Permalink to this headline"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.Parameter">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">Parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">default_input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layerwise_parallel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel_optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/parameter.html#Parameter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Parameter" title="Permalink to this definition"></a></dt>
<dd><p>An object holding weights of cells, after initialized <cite>Parameter</cite> is a subtype of <cite>Tensor</cite>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In auto_parallel mode of  “semi_auto_parallel” and “auto_parallel”, if init <cite>Parameter</cite> by
a <cite>Tensor</cite>, the type of Parameter will be <cite>Tensor</cite>. <cite>Tensor</cite>
will save the shape and type info of a tensor with no memory usage. The shape can be changed while
compiling for auto-parallel. Call <cite>init_data</cite> will return a Tensor Parameter with initialized data.
If there is an operator in the network that requires part of the inputs to be Parameter,
then the Parameters as this part of the inputs are not allowed to be cast.
It is recommended to use the default value of <cite>name</cite> when initialize a parameter as one attribute of a cell,
otherwise, the parameter name may be different from expected.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>default_input</strong> (<em>Union</em><em>[</em><a class="reference internal" href="mindspore.Tensor.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>]</em>) – Parameter data,
to initialize the parameter data.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – <p>Name of the parameter. Default: None.</p>
<p>1) If the parameter is not given a name, the default name is its variable name. For example, the name of
param_a below is name_a, and the name of param_b is the variable name param_b.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">param_a</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;name_a&quot;</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">param_b</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</pre></div>
</div>
<p>2) If parameter in list or tuple is not given a name, will give it a unique name. For example, the names of
parameters below are Parameter$1 and Parameter$2.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">param_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)),</span>
                   <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">))]</span>
</pre></div>
</div>
<p>3) If the parameter is given a name, and the same name exists between different parameters, an exception
will be thrown. For example, “its name ‘name_a’ already exists.” will be thrown.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">param_a</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;name_a&quot;</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">param_tuple</span> <span class="o">=</span> <span class="p">(</span><span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">5</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;name_a&quot;</span><span class="p">),</span>
                    <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">6</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
</pre></div>
</div>
<p>4) If a parameter appear multiple times in list or tuple, check the name of the object only once. For
example, the following example will not throw an exception.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">param_a</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;name_a&quot;</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">param_tuple</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_a</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_a</span><span class="p">)</span>
</pre></div>
</div>
</p></li>
<li><p><strong>requires_grad</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – True if the parameter requires gradient. Default: True.</p></li>
<li><p><strong>layerwise_parallel</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – When layerwise_parallel is true in data/hybrid parallel mode,
broadcast and gradients communication would not be applied to parameters. Default: False.</p></li>
<li><p><strong>parallel_optimizer</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – It is used to filter the weight shard operation in semi auto or auto parallel
mode. It works only when enable parallel optimizer in <cite>mindspore.context.set_auto_parallel_context()</cite>.
Default: True.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">matmul</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">MatMul</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="go">[[2.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="go">[[0.]]</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.cache_enable">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cache_enable</span></span><a class="headerlink" href="#mindspore.Parameter.cache_enable" title="Permalink to this definition"></a></dt>
<dd><p>Return whether the parameter is cache enable.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.cache_shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cache_shape</span></span><a class="headerlink" href="#mindspore.Parameter.cache_shape" title="Permalink to this definition"></a></dt>
<dd><p>Return the cache shape corresponding to the parameter if use cache.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Parameter.clone">
<span class="sig-name descname"><span class="pre">clone</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'same'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/parameter.html#Parameter.clone"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Parameter.clone" title="Permalink to this definition"></a></dt>
<dd><p>Clone the parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>init</strong> (<em>Union</em><em>[</em><a class="reference internal" href="mindspore.Tensor.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/numbers.html#numbers.Number" title="(in Python v3.8)"><em>numbers.Number</em></a><em>]</em>) – Initialize the shape and dtype of the parameter.
If <cite>init</cite> is a <cite>Tensor</cite> or <cite>numbers.Number</cite>, clone a new parameter with the same shape
and dtype, and the data of the new parameter will be set according to <cite>init</cite>. If <cite>init</cite>
is a <cite>str</cite>, the <cite>init</cite> should be the alias of the class inheriting from <cite>Initializer</cite>.
For example, if <cite>init</cite> is ‘same’, clone a new parameter with the same data, shape, and
dtype. Default: ‘same’.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Parameter, a new parameter.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.comm_fusion">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">comm_fusion</span></span><a class="headerlink" href="#mindspore.Parameter.comm_fusion" title="Permalink to this definition"></a></dt>
<dd><p>Get the fusion type (int) for communication operators corresponding to this parameter.</p>
<p>In <cite>AUTO_PARALLEL</cite> and <cite>SEMI_AUTO_PARALLEL</cite> mode, some communication operators used for parameters or
gradients aggregation are inserted automatically. The value of fusion must be greater than or equal to 0.
When the value of fusion is 0, operators will not be fused together.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.data">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">data</span></span><a class="headerlink" href="#mindspore.Parameter.data" title="Permalink to this definition"></a></dt>
<dd><p>Return the parameter object.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Parameter.init_data">
<span class="sig-name descname"><span class="pre">init_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">set_sliced</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/parameter.html#Parameter.init_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Parameter.init_data" title="Permalink to this definition"></a></dt>
<dd><p>Initialize the parameter’s data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layout</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>]</em>) – <p>The parameter’s layout info.
layout [dev_mat, tensor_map, slice_shape, filed_size, uniform_split, opt_shard_group]. Default: None.
It’s not None only in ‘SEMI_AUTO_PARALLEL’ or ‘AUTO_PARALLEL’ mode.</p>
<ul>
<li><p>dev_mat (list(int)): The parameter’s device matrix.</p></li>
<li><p>tensor_map (list(int)): The parameter’s tensor map.</p></li>
<li><p>slice_shape (list(int)): The parameter’s slice shape.</p></li>
<li><p>filed_size (int): The parameter’s filed size.</p></li>
<li><p>uniform_split (bool): Whether the parameter is split evenly.</p></li>
<li><p>opt_shard_group (str): The group of the parameter while running optimizer parallel.</p></li>
</ul>
</p></li>
<li><p><strong>set_sliced</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – True if the parameter is set sliced after initializing the data.
Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#RuntimeError" title="(in Python v3.8)"><strong>RuntimeError</strong></a> – If it is from Initializer, and parallel mode has changed after the Initializer created.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the length of the layout is less than 6.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If <cite>layout</cite> is not tuple.</p></li>
</ul>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Parameter, the <cite>Parameter</cite> after initializing data. If current <cite>Parameter</cite> was already initialized before,
returns the same initialized <cite>Parameter</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.inited_param">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">inited_param</span></span><a class="headerlink" href="#mindspore.Parameter.inited_param" title="Permalink to this definition"></a></dt>
<dd><p>Get the new parameter after call the init_data.</p>
<p>Default is a None, If <cite>self</cite> is a Parameter without data, after call the
<cite>init_data</cite> the initialized Parameter with data will be recorded here.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.layerwise_parallel">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">layerwise_parallel</span></span><a class="headerlink" href="#mindspore.Parameter.layerwise_parallel" title="Permalink to this definition"></a></dt>
<dd><p>Get the layerwise parallel status(bool) of the parameter.</p>
<p>When layerwise_parallel is true in <cite>DATA_PARALLEL</cite> and <cite>HYBRID_PARALLEL</cite> parallel mode, broadcast and gradients
communication would not be applied to parameters.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.name">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#mindspore.Parameter.name" title="Permalink to this definition"></a></dt>
<dd><p>Get the name of the parameter.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.parallel_optimizer">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">parallel_optimizer</span></span><a class="headerlink" href="#mindspore.Parameter.parallel_optimizer" title="Permalink to this definition"></a></dt>
<dd><p>Get the optimizer parallel status(bool) of the parameter.</p>
<p>It is used to filter the weight shard operation in <cite>AUTO_PARALLEL</cite> and <cite>SEMI_AUTO_PARALLEL</cite> mode. It works only
when enable parallel optimizer in <cite>mindspore.context.set_auto_parallel_context()</cite>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.parallel_optimizer_comm_recompute">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">parallel_optimizer_comm_recompute</span></span><a class="headerlink" href="#mindspore.Parameter.parallel_optimizer_comm_recompute" title="Permalink to this definition"></a></dt>
<dd><p>Get the communication recompute status(bool) of optimizer parallel for the parameter.</p>
<p>In <cite>AUTO_PARALLEL</cite> and <cite>SEMI_AUTO_PARALLEL</cite> mode, when applying parallel optimizer, some AllGather operators
used for parameters gathering are inserted automatically. It is used to control the recompute attr for those
AllGather operators.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Only <cite>Graph</cite> mode is supported.</p></li>
<li><p>It is recommended to use cell.recompute(parallel_optimizer_comm_recompute=True/False) to configure
the AllGather operators introducing by parallel optimizer rather than using this interface directly.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.requires_grad">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">requires_grad</span></span><a class="headerlink" href="#mindspore.Parameter.requires_grad" title="Permalink to this definition"></a></dt>
<dd><p>Return whether the parameter requires gradient.</p>
<p>The main function of requires_grad is to tell auto grad to start recording operations on a Tensor.
If a Tensor has requires_grad=False, then Tensor requires_grad will make auto grad start recording
operations on the tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Parameter.set_data">
<span class="sig-name descname"><span class="pre">set_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">slice_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/parameter.html#Parameter.set_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Parameter.set_data" title="Permalink to this definition"></a></dt>
<dd><p>Set Parameter’s data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>Union</em><em>[</em><a class="reference internal" href="mindspore.Tensor.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em>) – New data.</p></li>
<li><p><strong>slice_shape</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If slice the parameter is set to true, the shape is not checked for consistency.
Default: False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Parameter, the parameter after set data.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Parameter.set_param_fl">
<span class="sig-name descname"><span class="pre">set_param_fl</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">push_to_server</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pull_from_server</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_aggr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/parameter.html#Parameter.set_param_fl"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Parameter.set_param_fl" title="Permalink to this definition"></a></dt>
<dd><p>Set the way of parameter and server interaction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>push_to_server</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether the parameter should be pushed to server. Default: False.</p></li>
<li><p><strong>pull_from_server</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether the parameter should be pulled from server. Default: False.</p></li>
<li><p><strong>requires_aggr</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether the parameter should be aggregated in the server. Default: True.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.Parameter.set_param_ps">
<span class="sig-name descname"><span class="pre">set_param_ps</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">init_in_server</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/parameter.html#Parameter.set_param_ps"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.Parameter.set_param_ps" title="Permalink to this definition"></a></dt>
<dd><p>Set whether the trainable parameter is updated by parameter server and whether the
trainable parameter is initialized on server.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It only works when a running task is in the parameter server mode.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>init_in_server</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether trainable parameter updated by parameter server is
initialized on server. Default: False.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.sliced">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sliced</span></span><a class="headerlink" href="#mindspore.Parameter.sliced" title="Permalink to this definition"></a></dt>
<dd><p>Get slice status of the parameter.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mindspore.Parameter.unique">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">unique</span></span><a class="headerlink" href="#mindspore.Parameter.unique" title="Permalink to this definition"></a></dt>
<dd><p>Whether the parameter is already unique or not.</p>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindspore.SparseTensor.html" class="btn btn-neutral float-left" title="mindspore.SparseTensor" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mindspore.ParameterTuple.html" class="btn btn-neutral float-right" title="mindspore.ParameterTuple" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>