<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.nn.Conv2dThor &mdash; MindSpore master documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="mindspore.nn.DenseThor" href="mindspore.nn.DenseThor.html" />
    <link rel="prev" title="mindspore.nn.MaxPool2d" href="mindspore.nn.MaxPool2d.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">MindSpore Python API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.compression.html">mindspore.compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.explainer.html">mindspore.explainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../mindspore.nn.html">mindspore.nn</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#cell">Cell</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#containers">Containers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#convolution-layers">Convolution Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#recurrent-layers">Recurrent Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#sparse-layers">Sparse Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#non-linear-activations">Non-linear Activations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#utilities">Utilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#images-functions">Images Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#normalization-layers">Normalization Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#pooling-layers">Pooling layers</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../mindspore.nn.html#thor-layers">Thor Layers</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">mindspore.nn.Conv2dThor</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.DenseThor.html">mindspore.nn.DenseThor</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.EmbeddingThor.html">mindspore.nn.EmbeddingThor</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#quantized-functions">Quantized Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#loss-functions">Loss Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#optimizer-functions">Optimizer Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#wrapper-functions">Wrapper Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#math-functions">Math Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#metrics">Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#dynamic-learning-rate">Dynamic Learning Rate</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.profiler.html">mindspore.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.train.html">mindspore.train</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindSpore C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.3/api_cpp/class_list.html">Lite</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../mindspore.nn.html">mindspore.nn</a> &raquo;</li>
      <li>mindspore.nn.Conv2dThor</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/api_python/nn/mindspore.nn.Conv2dThor.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mindspore-nn-conv2dthor">
<h1>mindspore.nn.Conv2dThor<a class="headerlink" href="#mindspore-nn-conv2dthor" title="Permalink to this headline">ÔÉÅ</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.Conv2dThor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.</span></span><span class="sig-name descname"><span class="pre">Conv2dThor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'same'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">has_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'normal'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'zeros'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/layer/thor_layer.html#Conv2dThor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.Conv2dThor" title="Permalink to this definition">ÔÉÅ</a></dt>
<dd><p>2D convolution layer and saving the information needed for THOR.</p>
<p>Applies a 2D convolution over an input tensor which is typically of shape <span class="math notranslate nohighlight">\((N, C_{in}, H_{in}, W_{in})\)</span>,
where <span class="math notranslate nohighlight">\(N\)</span> is batch size, <span class="math notranslate nohighlight">\(C_{in}\)</span> is channel number, and <span class="math notranslate nohighlight">\(H_{in}, W_{in})\)</span> are height and width.
And saves the information A and G in the 2D convolution layer needed for THOR.
The detail can be seen in paper: <a class="reference external" href="https://www.aaai.org/AAAI21Papers/AAAI-6611.ChenM.pdf">https://www.aaai.org/AAAI21Papers/AAAI-6611.ChenM.pdf</a></p>
<p>For each batch of shape <span class="math notranslate nohighlight">\((C_{in}, H_{in}, W_{in})\)</span>, the formula is defined as:</p>
<div class="math notranslate nohighlight">
\[out_j = \sum_{i=0}^{C_{in} - 1} ccor(W_{ij}, X_i) + b_j,\]</div>
<p>where <span class="math notranslate nohighlight">\(ccor\)</span> is the cross-correlation operator, <span class="math notranslate nohighlight">\(C_{in}\)</span> is the input channel number, <span class="math notranslate nohighlight">\(j\)</span> ranges
from <span class="math notranslate nohighlight">\(0\)</span> to <span class="math notranslate nohighlight">\(C_{out} - 1\)</span>, <span class="math notranslate nohighlight">\(W_{ij}\)</span> corresponds to the <span class="math notranslate nohighlight">\(i\)</span>-th channel of the <span class="math notranslate nohighlight">\(j\)</span>-th
filter and <span class="math notranslate nohighlight">\(out_{j}\)</span> corresponds to the <span class="math notranslate nohighlight">\(j\)</span>-th channel of the output. <span class="math notranslate nohighlight">\(W_{ij}\)</span> is a slice
of kernel and it has shape <span class="math notranslate nohighlight">\((\text{ks_h}, \text{ks_w})\)</span>, where <span class="math notranslate nohighlight">\(\text{ks_h}\)</span> and
<span class="math notranslate nohighlight">\(\text{ks_w}\)</span> are the height and width of the convolution kernel. The full kernel has shape
<span class="math notranslate nohighlight">\((C_{out}, C_{in} // \text{group}, \text{ks_h}, \text{ks_w})\)</span>, where group is the group number
to split the input <cite>x</cite> in the channel dimension.</p>
<p>If the ‚Äòpad_mode‚Äô is set to be ‚Äúvalid‚Äù, the output height and width will be
<span class="math notranslate nohighlight">\(\left \lfloor{1 + \frac{H_{in} + 2 \times \text{padding} - \text{ks_h} -
(\text{ks_h} - 1) \times (\text{dilation} - 1) }{\text{stride}}} \right \rfloor\)</span> and
<span class="math notranslate nohighlight">\(\left \lfloor{1 + \frac{W_{in} + 2 \times \text{padding} - \text{ks_w} -
(\text{ks_w} - 1) \times (\text{dilation} - 1) }{\text{stride}}} \right \rfloor\)</span> respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) ‚Äì The number of the input channel <span class="math notranslate nohighlight">\(C_{in}\)</span>.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) ‚Äì The number of the output channel <span class="math notranslate nohighlight">\(C_{out}\)</span>.</p></li>
<li><p><strong>kernel_size</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) ‚Äì The data type is int or a tuple of 2 integers. Specifies the height
and width of the 2D convolution window. Single int means that the value is not only the height, but also
the width of the kernel. A tuple of 2 integers means the height and the width of the kernel respectively.</p></li>
<li><p><strong>stride</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) ‚Äì The distance of kernel moving, an int number represents the height and width
of movement, or a tuple of two int numbers that represent height and width of movement, respectively.
Default: 1.</p></li>
<li><p><strong>pad_mode</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) ‚Äì <p>Specifies padding mode. The optional values are
‚Äúsame‚Äù, ‚Äúvalid‚Äù, ‚Äúpad‚Äù. Default: ‚Äúsame‚Äù.</p>
<ul>
<li><p>same: Adopts the way of completion. The shape of the output will be the same as
the <cite>x</cite>. The total number of padding will be calculated in horizontal and vertical
directions and evenly distributed to top and bottom, left and right if possible. Otherwise, the
last extra padding will be done from the bottom and the right side. If this mode is set, <cite>padding</cite>
must be 0.</p></li>
<li><p>valid: Adopts the way of discarding. The possible largest height and width of output will be returned
without padding. Extra pixels will be discarded. If this mode is set, <cite>padding</cite> must be 0.</p></li>
<li><p>pad: Implicit paddings on both sides of the input <cite>x</cite>. The number of <cite>padding</cite> will be padded to the input
Tensor borders. <cite>padding</cite> must be greater than or equal to 0.</p></li>
</ul>
</p></li>
<li><p><strong>padding</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) ‚Äì Implicit paddings on both sides of the input <cite>x</cite>. If <cite>padding</cite> is an integer,
the paddings of top, bottom, left and right are the same, equal to padding. If <cite>padding</cite> is a tuple
with four integers, the paddings of top, bottom, left and right will be equal to padding[0],
padding[1], padding[2], and padding[3] accordingly. Default: 0.</p></li>
<li><p><strong>dilation</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) ‚Äì The data type is int or a tuple of 2 integers. Specifies the dilation rate
to use for dilated convolution. If set to be <span class="math notranslate nohighlight">\(k &gt; 1\)</span>, there will
be <span class="math notranslate nohighlight">\(k - 1\)</span> pixels skipped for each sampling location. Its value must
be greater or equal to 1 and bounded by the height and width of the  input <cite>x</cite>.
Default: 1.</p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) ‚Äì Splits filter into groups, <cite>in_ channels</cite> and <cite>out_channels</cite> must be
divisible by the number of groups. If the group is equal to <cite>in_channels</cite> and <cite>out_channels</cite>,
this 2D convolution layer also can be called 2D depthwise convolution layer. Default: 1.</p></li>
<li><p><strong>has_bias</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) ‚Äì Specifies whether the layer uses a bias vector. Default: False.</p></li>
<li><p><strong>weight_init</strong> (<em>Union</em><em>[</em><a class="reference internal" href="../mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference internal" href="../mindspore.common.initializer.html#mindspore.common.initializer.Initializer" title="mindspore.common.initializer.Initializer"><em>Initializer</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/numbers.html#numbers.Number" title="(in Python v3.8)"><em>numbers.Number</em></a><em>]</em>) ‚Äì Initializes the convolution kernel.
It can be a Tensor, a string, an Initializer or a number. When a string is specified,
values from ‚ÄòTruncatedNormal‚Äô, ‚ÄòNormal‚Äô, ‚ÄòUniform‚Äô, ‚ÄòHeUniform‚Äô and ‚ÄòXavierUniform‚Äô distributions as well
as constant ‚ÄòOne‚Äô and ‚ÄòZero‚Äô distributions are possible. Alias ‚Äòxavier_uniform‚Äô, ‚Äòhe_uniform‚Äô, ‚Äòones‚Äô
and ‚Äòzeros‚Äô are acceptable. Uppercase and lowercase are both acceptable. Refer to the values of
Initializer for more details. Default: ‚Äònormal‚Äô.</p></li>
<li><p><strong>bias_init</strong> (<em>Union</em><em>[</em><a class="reference internal" href="../mindspore.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference internal" href="../mindspore.common.initializer.html#mindspore.common.initializer.Initializer" title="mindspore.common.initializer.Initializer"><em>Initializer</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/numbers.html#numbers.Number" title="(in Python v3.8)"><em>numbers.Number</em></a><em>]</em>) ‚Äì Initializes the bias vector. Possible
Initializer and string are the same as ‚Äòweight_init‚Äô. Refer to the values of
Initializer for more details. Default: ‚Äòzeros‚Äô.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>x</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, C_{in}, H_{in}, W_{in})\)</span>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor of shape <span class="math notranslate nohighlight">\((N, C_{out}, H_{out}, W_{out})\)</span>.</p>
</dd>
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2dThor</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">640</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(1, 240, 1024, 640)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Conv2dThor.save_gradient">
<span class="sig-name descname"><span class="pre">save_gradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dout</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/layer/thor_layer.html#Conv2dThor.save_gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.Conv2dThor.save_gradient" title="Permalink to this definition">ÔÉÅ</a></dt>
<dd></dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindspore.nn.MaxPool2d.html" class="btn btn-neutral float-left" title="mindspore.nn.MaxPool2d" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mindspore.nn.DenseThor.html" class="btn btn-neutral float-right" title="mindspore.nn.DenseThor" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>