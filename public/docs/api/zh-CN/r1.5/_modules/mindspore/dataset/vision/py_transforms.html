<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.dataset.vision.py_transforms &mdash; MindSpore master documentation</title><link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">MindSpore Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.compression.html">mindspore.compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.audio.html">mindspore.dataset.audio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.parallel.html">mindspore.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.parallel.nn.html">mindspore.parallel.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.profiler.html">mindspore.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.boost.html">mindspore.boost (experimental)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MindSpore C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.5/api_cpp/mindspore.html">MindSpore Liteâ†—</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
      <li>mindspore.dataset.vision.py_transforms</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for mindspore.dataset.vision.py_transforms</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2019 Huawei Technologies Co., Ltd</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">The module vision.py_transforms is mainly implemented based on Python PIL, which</span>
<span class="sd">provides many kinds of image augmentation methods and conversion methods between</span>
<span class="sd">PIL image and numpy.ndarray. For users who prefer using Python PIL in computer vision</span>
<span class="sd">tasks, this module is a good choice to process images. Users can also self-define</span>
<span class="sd">their own augmentation methods with Python PIL.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numbers</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="kn">import</span> <span class="nn">mindspore.dataset.transforms.py_transforms</span> <span class="k">as</span> <span class="nn">py_transforms</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">py_transforms_util</span> <span class="k">as</span> <span class="n">util</span>
<span class="kn">from</span> <span class="nn">.c_transforms</span> <span class="kn">import</span> <span class="n">parse_padding</span>
<span class="kn">from</span> <span class="nn">.validators</span> <span class="kn">import</span> <span class="n">check_prob</span><span class="p">,</span> <span class="n">check_center_crop</span><span class="p">,</span> <span class="n">check_five_crop</span><span class="p">,</span> <span class="n">check_resize_interpolation</span><span class="p">,</span> <span class="n">check_random_resize_crop</span><span class="p">,</span> \
    <span class="n">check_normalize_py</span><span class="p">,</span> <span class="n">check_normalizepad_py</span><span class="p">,</span> <span class="n">check_random_crop</span><span class="p">,</span> <span class="n">check_random_color_adjust</span><span class="p">,</span> <span class="n">check_random_rotation</span><span class="p">,</span> \
    <span class="n">check_ten_crop</span><span class="p">,</span> <span class="n">check_num_channels</span><span class="p">,</span> <span class="n">check_pad</span><span class="p">,</span> <span class="n">check_rgb_to_hsv</span><span class="p">,</span> <span class="n">check_hsv_to_rgb</span><span class="p">,</span> \
    <span class="n">check_random_perspective</span><span class="p">,</span> <span class="n">check_random_erasing</span><span class="p">,</span> <span class="n">check_cutout</span><span class="p">,</span> <span class="n">check_linear_transform</span><span class="p">,</span> <span class="n">check_random_affine</span><span class="p">,</span> \
    <span class="n">check_mix_up</span><span class="p">,</span> <span class="n">check_positive_degrees</span><span class="p">,</span> <span class="n">check_uniform_augment_py</span><span class="p">,</span> <span class="n">check_auto_contrast</span><span class="p">,</span> <span class="n">check_rgb_to_bgr</span><span class="p">,</span> \
    <span class="n">check_adjust_gamma</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">Inter</span><span class="p">,</span> <span class="n">Border</span>
<span class="kn">from</span> <span class="nn">.py_transforms_util</span> <span class="kn">import</span> <span class="n">is_pil</span>

<span class="n">DE_PY_INTER_MODE</span> <span class="o">=</span> <span class="p">{</span><span class="n">Inter</span><span class="o">.</span><span class="n">NEAREST</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">NEAREST</span><span class="p">,</span>
                    <span class="n">Inter</span><span class="o">.</span><span class="n">ANTIALIAS</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">ANTIALIAS</span><span class="p">,</span>
                    <span class="n">Inter</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">,</span>
                    <span class="n">Inter</span><span class="o">.</span><span class="n">CUBIC</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">CUBIC</span><span class="p">}</span>

<span class="n">DE_PY_BORDER_TYPE</span> <span class="o">=</span> <span class="p">{</span><span class="n">Border</span><span class="o">.</span><span class="n">CONSTANT</span><span class="p">:</span> <span class="s1">&#39;constant&#39;</span><span class="p">,</span>
                     <span class="n">Border</span><span class="o">.</span><span class="n">EDGE</span><span class="p">:</span> <span class="s1">&#39;edge&#39;</span><span class="p">,</span>
                     <span class="n">Border</span><span class="o">.</span><span class="n">REFLECT</span><span class="p">:</span> <span class="s1">&#39;reflect&#39;</span><span class="p">,</span>
                     <span class="n">Border</span><span class="o">.</span><span class="n">SYMMETRIC</span><span class="p">:</span> <span class="s1">&#39;symmetric&#39;</span><span class="p">}</span>


<span class="k">def</span> <span class="nf">not_random</span><span class="p">(</span><span class="n">function</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Specify the function as &quot;not random&quot;, i.e., it produces deterministic result.</span>
<span class="sd">    A Python function can only be cached after it is specified as &quot;not random&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">function</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="n">function</span>


<div class="viewcode-block" id="ToTensor"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.ToTensor.html#mindspore.dataset.vision.py_transforms.ToTensor">[docs]</a><span class="k">class</span> <span class="nc">ToTensor</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert the input PIL Image or numpy.ndarray of shape (H, W, C) in the range [0, 255] to numpy.ndarray of</span>
<span class="sd">    shape (C, H, W) in the range [0.0, 1.0] with the desired dtype.</span>

<span class="sd">    Note:</span>
<span class="sd">        The values in the input image will be rescaled from [0, 255] to [0.0, 1.0].</span>
<span class="sd">        The dtype will be cast to `output_type`.</span>
<span class="sd">        The number of channels remains the same.</span>

<span class="sd">    Args:</span>
<span class="sd">        output_type (numpy.dtype, optional): The dtype of the numpy.ndarray output (default=np.float32).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input is not PIL Image or numpy.ndarray.</span>
<span class="sd">        TypeError: If the dimension of input is not 2 or 3.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; # create a list of transformations to be applied to the &quot;image&quot; column of each data row</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_type</span> <span class="o">=</span> <span class="n">output_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (Union[PIL Image, numpy.ndarray]): PIL Image or numpy.ndarray to be type converted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, converted numpy.ndarray with desired type.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_type</span><span class="p">)</span></div>


<div class="viewcode-block" id="ToType"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.ToType.html#mindspore.dataset.vision.py_transforms.ToType">[docs]</a><span class="k">class</span> <span class="nc">ToType</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert the input numpy.ndarray image to the desired dtype.</span>

<span class="sd">    Args:</span>
<span class="sd">        output_type (numpy.dtype): The dtype of the numpy.ndarray output, e.g. numpy.float32.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input is not numpy.ndarray.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; transforms_list =Compose([py_vision.Decode(),</span>
<span class="sd">        ...                           py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                           py_vision.ToTensor(),</span>
<span class="sd">        ...                           py_vision.ToType(np.float32)])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_type</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_type</span> <span class="o">=</span> <span class="n">output_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (numpy.ndarray): numpy.ndarray to be dtype converted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, converted numpy.ndarray with desired dtype.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">to_type</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_type</span><span class="p">)</span></div>


<div class="viewcode-block" id="HWC2CHW"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.HWC2CHW.html#mindspore.dataset.vision.py_transforms.HWC2CHW">[docs]</a><span class="k">class</span> <span class="nc">HWC2CHW</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transpose the input numpy.ndarray image of shape (H, W, C) to (C, H, W).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input is not numpy.ndarray.</span>
<span class="sd">        TypeError: If the dimension of input is not 3.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.HWC2CHW()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (numpy.ndarray): numpy.ndarray of shape (H, W, C) to be transposed.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, transposed numpy.ndarray of shape (C, H, W).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">hwc_to_chw</span><span class="p">(</span><span class="n">img</span><span class="p">)</span></div>


<div class="viewcode-block" id="ToPIL"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.ToPIL.html#mindspore.dataset.vision.py_transforms.ToPIL">[docs]</a><span class="k">class</span> <span class="nc">ToPIL</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert the input decoded numpy.ndarray image to PIL Image.</span>

<span class="sd">    Note:</span>
<span class="sd">        The conversion mode will be determined from type according to `PIL.Image.fromarray`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input is not numpy.ndarray or PIL Image.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; # data is already decoded, but not in PIL Image format</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.ToPIL(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (numpy.ndarray): Decoded numpy.ndarray image to be converted to PIL Image.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, converted PIL Image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">to_pil</span><span class="p">(</span><span class="n">img</span><span class="p">)</span></div>


<div class="viewcode-block" id="Decode"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Decode.html#mindspore.dataset.vision.py_transforms.Decode">[docs]</a><span class="k">class</span> <span class="nc">Decode</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Decode the input raw image to PIL Image format in RGB mode.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If the input is not raw data.</span>
<span class="sd">        ValueError: If the input image is already decoded.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (Bytes-like Object): Raw image data to be decoded.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, decoded PIL Image in RGB mode.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">img</span><span class="p">)</span></div>


<div class="viewcode-block" id="Normalize"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Normalize.html#mindspore.dataset.vision.py_transforms.Normalize">[docs]</a><span class="k">class</span> <span class="nc">Normalize</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Normalize the input numpy.ndarray image of shape (C, H, W) with the specified mean and standard deviation.</span>

<span class="sd">    .. math::</span>

<span class="sd">        output_{c} = \frac{input_{c} - mean_{c}}{std_{c}}</span>

<span class="sd">    Note:</span>
<span class="sd">        The values of the input image need to be in the range [0.0, 1.0]. If not so, call `ToTensor` first.</span>

<span class="sd">    Args:</span>
<span class="sd">        mean (Union[float, sequence]): list or tuple of mean values for each channel, arranged in channel order. The</span>
<span class="sd">            values must be in the range [0.0, 1.0].</span>
<span class="sd">            If a single float is provided, it will be filled to the same length as the channel.</span>
<span class="sd">        std (Union[float, sequence]): list or tuple of standard deviation values for each channel, arranged in channel</span>
<span class="sd">            order. The values must be in the range (0.0, 1.0].</span>
<span class="sd">            If a single float is provided, it will be filled to the same length as the channel.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input is not numpy.ndarray.</span>
<span class="sd">        TypeError: If the dimension of input is not 3.</span>
<span class="sd">        NotImplementedError: If the dtype of input is a subdtype of np.integer.</span>
<span class="sd">        ValueError: If the lengths of the mean and std are not equal.</span>
<span class="sd">        ValueError: If the length of the mean or std is neither equal to the channel length nor 1.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.Normalize((0.491, 0.482, 0.447), (0.247, 0.243, 0.262))])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_normalize_py</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (numpy.ndarray): numpy.ndarray to be normalized.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, normalized numpy.ndarray.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="p">)</span></div>


<div class="viewcode-block" id="NormalizePad"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.NormalizePad.html#mindspore.dataset.vision.py_transforms.NormalizePad">[docs]</a><span class="k">class</span> <span class="nc">NormalizePad</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Normalize the input numpy.ndarray image of shape (C, H, W) with the specified mean and standard deviation,</span>
<span class="sd">    then pad an extra channel filled with zeros.</span>

<span class="sd">    .. math::</span>
<span class="sd">        output_{c} = \begin{cases}</span>
<span class="sd">        \frac{input_{c} - mean_{c}}{std_{c}}, &amp; \text{if} \quad 0 \le c &lt; 3 \text{;}\\</span>
<span class="sd">        0, &amp; \text{if} \quad c = 3 \text{.}</span>
<span class="sd">        \end{cases}</span>

<span class="sd">    Note:</span>
<span class="sd">        The values of the input image need to be in the range [0.0, 1.0]. If not so, call `ToTensor` first.</span>

<span class="sd">    Args:</span>
<span class="sd">        mean (Union[float, sequence]): list or tuple of mean values for each channel, arranged in channel order. The</span>
<span class="sd">            values must be in the range [0.0, 1.0].</span>
<span class="sd">            If a single float is provided, it will be filled to the same length as the channel.</span>
<span class="sd">        std (Union[float, sequence]): list or tuple of standard deviation values for each channel, arranged in channel</span>
<span class="sd">            order. The values must be in the range (0.0, 1.0].</span>
<span class="sd">            If a single float is provided, it will be filled to the same length as the channel.</span>
<span class="sd">        dtype (str): The dtype of the numpy.ndarray output when `pad_channel` is set True. Only &quot;float32&quot; and &quot;float16&quot;</span>
<span class="sd">            are supported (default=&quot;float32&quot;).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input is not numpy.ndarray.</span>
<span class="sd">        TypeError: If the dimension of input is not 3.</span>
<span class="sd">        NotImplementedError: If the dtype of input is a subdtype of np.integer.</span>
<span class="sd">        ValueError: If the length of the mean and std are not equal.</span>
<span class="sd">        ValueError: If the length of the mean or std is neither equal to the channel length nor 1.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.NormalizePad((0.491, 0.482, 0.447), (0.247, 0.243, 0.262), &quot;float32&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_normalizepad_py</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (numpy.ndarray): numpy.ndarray to be normalized and padded.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, normalized and padded numpy.ndarray.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="p">,</span> <span class="n">pad_channel</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomCrop"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomCrop.html#mindspore.dataset.vision.py_transforms.RandomCrop">[docs]</a><span class="k">class</span> <span class="nc">RandomCrop</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Crop the input PIL Image at a random location with the specified size.</span>

<span class="sd">    Args:</span>
<span class="sd">        size (Union[int, sequence]): The output size of the cropped image.</span>
<span class="sd">            If size is an integer, a square of size (size, size) is returned.</span>
<span class="sd">            If size is a sequence of length 2, it should be in shape of (height, width).</span>
<span class="sd">        padding (Union[int, sequence], optional): Padding on each border of the image (default=None).</span>
<span class="sd">            If padding is not None, pad the image before cropping.</span>
<span class="sd">            If a single number is provided, pad all borders with this value.</span>
<span class="sd">            If a sequence of length 2 is provided, pad the left/top border</span>
<span class="sd">            with the first value and right/bottom border with the second value.</span>
<span class="sd">            If a sequence of length 4 is provided, pad the left, top, right and bottom borders respectively.</span>
<span class="sd">        pad_if_needed (bool, optional): Pad the image if either side is smaller than</span>
<span class="sd">            the given output size (default=False).</span>
<span class="sd">        fill_value (Union[int, tuple], optional): Pixel fill value to pad the borders when padding_mode is</span>
<span class="sd">            Border.CONSTANT (default=0). If a tuple of length 3 is provided, it is used to fill R, G, B</span>
<span class="sd">            channels respectively.</span>
<span class="sd">        padding_mode (Border, optional): The method of padding (default=Border.CONSTANT). It can be any of</span>
<span class="sd">            [Border.CONSTANT, Border.EDGE, Border.REFLECT, Border.SYMMETRIC].</span>

<span class="sd">            - Border.CONSTANT, means to pad with given constant values.</span>

<span class="sd">            - Border.EDGE, means to pad with the last value at the edge.</span>

<span class="sd">            - Border.REFLECT, means to pad with reflection of image omitting the last value at the edge.</span>

<span class="sd">            - Border.SYMMETRIC, means to pad with reflection of image repeating the last value at the edge.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomCrop(224),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_crop</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pad_if_needed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="n">Border</span><span class="o">.</span><span class="n">CONSTANT</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">padding</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="n">parse_padding</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_if_needed</span> <span class="o">=</span> <span class="n">pad_if_needed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span> <span class="o">=</span> <span class="n">fill_value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span> <span class="o">=</span> <span class="n">DE_PY_BORDER_TYPE</span><span class="p">[</span><span class="n">padding_mode</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be randomly cropped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, cropped image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_if_needed</span><span class="p">,</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomHorizontalFlip"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomHorizontalFlip.html#mindspore.dataset.vision.py_transforms.RandomHorizontalFlip">[docs]</a><span class="k">class</span> <span class="nc">RandomHorizontalFlip</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly flip the input image horizontally with a given probability.</span>

<span class="sd">    Args:</span>
<span class="sd">        prob (float, optional): Probability of the image to be horizontally flipped (default=0.5).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_prob</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be horizontally flipped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, randomly horizontally flipped image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_horizontal_flip</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomVerticalFlip"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomVerticalFlip.html#mindspore.dataset.vision.py_transforms.RandomVerticalFlip">[docs]</a><span class="k">class</span> <span class="nc">RandomVerticalFlip</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly flip the input image vertically with a given probability.</span>

<span class="sd">    Args:</span>
<span class="sd">        prob (float, optional): Probability of the image to be vertically flipped (default=0.5).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomVerticalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_prob</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be vertically flipped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, randomly vertically flipped image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_vertical_flip</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob</span><span class="p">)</span></div>


<div class="viewcode-block" id="Resize"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Resize.html#mindspore.dataset.vision.py_transforms.Resize">[docs]</a><span class="k">class</span> <span class="nc">Resize</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Resize the input PIL Image to the given size.</span>

<span class="sd">    Args:</span>
<span class="sd">        size (Union[int, sequence]): The output size of the image.</span>
<span class="sd">            If size is an integer, the smaller edge of the image will be resized to this</span>
<span class="sd">            value, keeping the image aspect ratio the same.</span>
<span class="sd">            If size is a sequence of length 2, it should be in shape of (height, width).</span>
<span class="sd">        interpolation (Inter, optional): Image interpolation mode (default=Inter.BILINEAR).</span>
<span class="sd">            It can be any of [Inter.NEAREST, Inter.ANTIALIAS, Inter.BILINEAR, Inter.BICUBIC].</span>

<span class="sd">            - Inter.NEAREST, nearest-neighbor interpolation.</span>

<span class="sd">            - Inter.ANTIALIAS, antialias interpolation.</span>

<span class="sd">            - Inter.BILINEAR, bilinear interpolation.</span>

<span class="sd">            - Inter.BICUBIC, bicubic interpolation.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.Resize(256),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_resize_interpolation</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">BILINEAR</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span> <span class="o">=</span> <span class="n">DE_PY_INTER_MODE</span><span class="p">[</span><span class="n">interpolation</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be resized.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, resized image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomResizedCrop"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomResizedCrop.html#mindspore.dataset.vision.py_transforms.RandomResizedCrop">[docs]</a><span class="k">class</span> <span class="nc">RandomResizedCrop</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly crop the image and resize it to a given size.</span>

<span class="sd">    Args:</span>
<span class="sd">        size (Union[int, sequence]): The size of the output image.</span>
<span class="sd">            If size is an integer, a square of size (size, size) is returned.</span>
<span class="sd">            If size is a sequence of length 2, it should be in shape of (height, width).</span>
<span class="sd">        scale (Union[list, tuple], optional): Respective size range of the original image to be cropped</span>
<span class="sd">            in shape of (min, max) (default=(0.08, 1.0)).</span>
<span class="sd">        ratio (Union[list, tuple], optional): Aspect ratio range to be cropped</span>
<span class="sd">            in shape of (min, max) (default=(3./4., 4./3.)).</span>
<span class="sd">        interpolation (Inter, optional): Image interpolation mode (default=Inter.BILINEAR).</span>
<span class="sd">            It can be any of [Inter.NEAREST, Inter.ANTIALIAS, Inter.BILINEAR, Inter.BICUBIC].</span>

<span class="sd">            - Inter.NEAREST, nearest-neighbor interpolation.</span>

<span class="sd">            - Inter.ANTIALIAS, antialias interpolation.</span>

<span class="sd">            - Inter.BILINEAR, bilinear interpolation.</span>

<span class="sd">            - Inter.BICUBIC, bicubic interpolation.</span>

<span class="sd">        max_attempts (int, optional): The maximum number of attempts to propose a valid</span>
<span class="sd">            crop area (default=10). If exceeded, fall back to use center crop instead.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomResizedCrop(224),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_resize_crop</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.08</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="mf">3.</span> <span class="o">/</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">4.</span> <span class="o">/</span> <span class="mf">3.</span><span class="p">),</span>
                 <span class="n">interpolation</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">BILINEAR</span><span class="p">,</span> <span class="n">max_attempts</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span> <span class="o">=</span> <span class="n">ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span> <span class="o">=</span> <span class="n">DE_PY_INTER_MODE</span><span class="p">[</span><span class="n">interpolation</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_attempts</span> <span class="o">=</span> <span class="n">max_attempts</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be randomly cropped and resized.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, randomly cropped and resized image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_resize_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_attempts</span><span class="p">)</span></div>


<div class="viewcode-block" id="CenterCrop"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.CenterCrop.html#mindspore.dataset.vision.py_transforms.CenterCrop">[docs]</a><span class="k">class</span> <span class="nc">CenterCrop</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Crop the central region of the input PIL Image with the given size.</span>

<span class="sd">    Args:</span>
<span class="sd">        size (Union[int, sequence]): The output size of the cropped image.</span>
<span class="sd">            If size is an integer, a square of size (size, size) is returned.</span>
<span class="sd">            If size is a sequence of length 2, it should be in shape of (height, width).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.CenterCrop(64),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_center_crop</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be center cropped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, cropped image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">center_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomColorAdjust"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomColorAdjust.html#mindspore.dataset.vision.py_transforms.RandomColorAdjust">[docs]</a><span class="k">class</span> <span class="nc">RandomColorAdjust</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly adjust the brightness, contrast, saturation, and hue of the input PIL Image.</span>

<span class="sd">    Args:</span>
<span class="sd">        brightness (Union[float, tuple], optional): Brightness adjustment factor,</span>
<span class="sd">            which must be non negative (default=(1, 1)).</span>
<span class="sd">            If brightness is a float, the factor is uniformly chosen in range of [max(0, 1-brightness), 1+brightness].</span>
<span class="sd">            If brightness is a sequence of length 2, it should be in shape of [min, max].</span>
<span class="sd">        contrast (Union[float, tuple], optional): Contrast adjustment factor,</span>
<span class="sd">            which must be non negative (default=(1, 1)).</span>
<span class="sd">            If contrast is a float, the factor is uniformly chosen in range of [max(0, 1-contrast), 1+contrast].</span>
<span class="sd">            If contrast is a sequence of length 2, it should be in shape of [min, max].</span>
<span class="sd">        saturation (Union[float, tuple], optional): Saturation adjustment factor,</span>
<span class="sd">            which must be non negative(default=(1, 1)).</span>
<span class="sd">            If saturation is a float, the factor is uniformly chosen in range of [max(0, 1-saturation), 1+saturation].</span>
<span class="sd">            If saturation is a sequence of length 2, it should be in shape of [min, max].</span>
<span class="sd">        hue (Union[float, tuple], optional): Hue adjustment factor (default=(0, 0)).</span>
<span class="sd">            If hue is a float, the range will be [-hue, hue], where 0 &lt;= hue &lt;= 0.5.</span>
<span class="sd">            If hue is a sequence of length 2, it should be in shape of [min, max], where -0.5 &lt;= min &lt;= max &lt;= 0.5.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomColorAdjust(0.4, 0.4, 0.4, 0.1),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_color_adjust</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">brightness</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">contrast</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">saturation</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">hue</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">brightness</span> <span class="o">=</span> <span class="n">brightness</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">contrast</span> <span class="o">=</span> <span class="n">contrast</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">saturation</span> <span class="o">=</span> <span class="n">saturation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hue</span> <span class="o">=</span> <span class="n">hue</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL image): Image to be randomly color adjusted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, randomly color adjusted image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_color_adjust</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">brightness</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">contrast</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">saturation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hue</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomRotation"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomRotation.html#mindspore.dataset.vision.py_transforms.RandomRotation">[docs]</a><span class="k">class</span> <span class="nc">RandomRotation</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rotate the input PIL Image by a random angle.</span>

<span class="sd">    Note:</span>
<span class="sd">        See https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.rotate.</span>

<span class="sd">    Args:</span>
<span class="sd">        degrees (Union[int, float, sequence]): Range of random rotation degrees.</span>
<span class="sd">            If `degrees` is a number, the range will be converted to (-degrees, degrees).</span>
<span class="sd">            If `degrees` is a sequence of length 2, it should be in shape of (min, max).</span>
<span class="sd">        resample (Inter, optional): An optional resampling filter (default=Inter.NEAREST).</span>
<span class="sd">            If the image is in mode of &quot;1&quot; or &quot;P&quot;, it is set to Inter.NEAREST by default.</span>
<span class="sd">            It can be any of [Inter.NEAREST, Inter.ANTIALIAS, Inter.BILINEAR, Inter.BICUBIC].</span>

<span class="sd">            - Inter.NEAREST, nearest-neighbor interpolation.</span>

<span class="sd">            - Inter.ANTIALIAS, antialias interpolation.</span>

<span class="sd">            - Inter.BILINEAR, bilinear interpolation.</span>

<span class="sd">            - Inter.BICUBIC, bicubic interpolation.</span>

<span class="sd">        expand (bool, optional): Optional expansion flag (default=False).</span>
<span class="sd">            If set to True, expand the output image to make it large enough to hold the entire rotated image.</span>
<span class="sd">            If set to False, keep the output image the same size as the input.</span>
<span class="sd">            Note that the expand flag assumes rotation around the center and no translation.</span>
<span class="sd">        center (tuple, optional): Optional center of rotation, which must be a tuple of length 2 (default=None).</span>
<span class="sd">            Origin is the top left corner. Default None means to set the center of the image.</span>
<span class="sd">        fill_value (int or tuple, optional): Pixel fill value for the area outside the rotated image (default=0).</span>
<span class="sd">            If fill_value is a tuple of length 3, it is used to fill R, G, B channels respectively.</span>
<span class="sd">            If fill_value is an integer, it is used to fill all RGB channels.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomRotation(30),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_rotation</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degrees</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">NEAREST</span><span class="p">,</span> <span class="n">expand</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">=</span> <span class="n">degrees</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resample</span> <span class="o">=</span> <span class="n">DE_PY_INTER_MODE</span><span class="p">[</span><span class="n">resample</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">expand</span> <span class="o">=</span> <span class="n">expand</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">center</span> <span class="o">=</span> <span class="n">center</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span> <span class="o">=</span> <span class="n">fill_value</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be randomly rotated.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, randomly rotated image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_rotation</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">resample</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">expand</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">center</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span><span class="p">)</span></div>


<div class="viewcode-block" id="FiveCrop"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.FiveCrop.html#mindspore.dataset.vision.py_transforms.FiveCrop">[docs]</a><span class="k">class</span> <span class="nc">FiveCrop</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Crop the given image into one central crop and four corners.</span>

<span class="sd">    Args:</span>
<span class="sd">        size (Union[int, sequence]): The output size of the cropped images.</span>
<span class="sd">            If size is an integer, a square of size (size, size) is returned.</span>
<span class="sd">            If size is a sequence of length 2, it should be in shape of (height, width).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.FiveCrop(size=200),</span>
<span class="sd">        ...                            # 4D stack of 5 images</span>
<span class="sd">        ...                            lambda *images: numpy.stack([py_vision.ToTensor()(image) for image in images])])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_five_crop</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be cropped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple, a tuple of five PIL Image in order of top_left, top_right, bottom_left, bottom_right, center.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">five_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">)</span></div>


<div class="viewcode-block" id="TenCrop"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.TenCrop.html#mindspore.dataset.vision.py_transforms.TenCrop">[docs]</a><span class="k">class</span> <span class="nc">TenCrop</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Crop the given image into one central crop and four corners plus the flipped version of these.</span>

<span class="sd">    Args:</span>
<span class="sd">        size (Union[int, sequence]): The output size of the cropped images.</span>
<span class="sd">            If size is an integer, a square of size (size, size) is returned.</span>
<span class="sd">            If size is a sequence of length 2, it should be in shape of (height, width).</span>
<span class="sd">        use_vertical_flip (bool, optional): Whether to flip the image vertically,</span>
<span class="sd">            otherwise horizontally (default=False).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.TenCrop(size=200),</span>
<span class="sd">        ...                            # 4D stack of 10 images</span>
<span class="sd">        ...                            lambda *images: numpy.stack([py_vision.ToTensor()(image) for image in images])])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_ten_crop</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">use_vertical_flip</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_vertical_flip</span> <span class="o">=</span> <span class="n">use_vertical_flip</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be cropped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple, a tuple of 10 PIL Image, in order of top_left, top_right, bottom_left, bottom_right, center</span>
<span class="sd">                of the original image and top_left, top_right, bottom_left, bottom_right, center of the flipped image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">ten_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_vertical_flip</span><span class="p">)</span></div>


<div class="viewcode-block" id="Grayscale"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Grayscale.html#mindspore.dataset.vision.py_transforms.Grayscale">[docs]</a><span class="k">class</span> <span class="nc">Grayscale</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert the input PIL Image to grayscale.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_output_channels (int): Number of channels of the output grayscale image, which can be 1 or 3 (default=1).</span>
<span class="sd">            If num_output_channels is 3, the returned image will have 3 identical RGB channels.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.Grayscale(3),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_num_channels</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_output_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_output_channels</span> <span class="o">=</span> <span class="n">num_output_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be converted to grayscale.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, converted grayscale image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">grayscale</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">num_output_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_output_channels</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomGrayscale"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomGrayscale.html#mindspore.dataset.vision.py_transforms.RandomGrayscale">[docs]</a><span class="k">class</span> <span class="nc">RandomGrayscale</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly convert the input image into grayscale with a given probability.</span>

<span class="sd">    Args:</span>
<span class="sd">        prob (float, optional): Probability of the image being converted to grayscale (default=0.1).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomGrayscale(0.3),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_prob</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be randomly converted to grayscale.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, randomly converted grayscale image, which has the same number of channels as the input image.</span>
<span class="sd">                If input image has 1 channel, the output grayscale image will have 1 channel.</span>
<span class="sd">                If input image has 3 channels, the output grayscale image will have 3 identical channels.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">img</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;L&#39;</span><span class="p">:</span>
            <span class="n">num_output_channels</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">num_output_channels</span> <span class="o">=</span> <span class="mi">3</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">&gt;</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">grayscale</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">num_output_channels</span><span class="o">=</span><span class="n">num_output_channels</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span></div>


<div class="viewcode-block" id="Pad"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Pad.html#mindspore.dataset.vision.py_transforms.Pad">[docs]</a><span class="k">class</span> <span class="nc">Pad</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Pad the input image on all sides with the given padding parameters.</span>

<span class="sd">    Args:</span>
<span class="sd">        padding (Union[int, sequence]): The number of pixels padded on the image borders.</span>
<span class="sd">            If a single number is provided, pad all borders with this value.</span>
<span class="sd">            If a sequence of length 2 is provided, pad the left and top with the</span>
<span class="sd">            first value and the right and bottom with the second value.</span>
<span class="sd">            If a sequence of length 4 is provided, pad the left, top, right and bottom respectively.</span>
<span class="sd">        fill_value (Union[int, tuple], optional): Pixel fill value to pad the borders,</span>
<span class="sd">            only valid when padding_mode is Border.CONSTANT (default=0).</span>
<span class="sd">            If fill_value is an integer, it is used for all RGB channels.</span>
<span class="sd">            If fill_value is a tuple of length 3, it is used to fill R, G, B channels respectively.</span>
<span class="sd">        padding_mode (Border, optional): The method of padding (default=Border.CONSTANT).</span>
<span class="sd">            It can be any of [Border.CONSTANT, Border.EDGE, Border.REFLECT, Border.SYMMETRIC].</span>

<span class="sd">            - Border.CONSTANT, pads with a constant value.</span>

<span class="sd">            - Border.EDGE, pads with the last value at the edge of the image.</span>

<span class="sd">            - Border.REFLECT, pads with reflection of the image omitting the last value on the edge.</span>

<span class="sd">            - Border.SYMMETRIC, pads with reflection of the image repeating the last value on the edge.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            # adds 10 pixels (default black) to each border of the image</span>
<span class="sd">        ...                            py_vision.Pad(padding=10),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_pad</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="n">Border</span><span class="o">.</span><span class="n">CONSTANT</span><span class="p">):</span>
        <span class="n">parse_padding</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span> <span class="o">=</span> <span class="n">fill_value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span> <span class="o">=</span> <span class="n">DE_PY_BORDER_TYPE</span><span class="p">[</span><span class="n">padding_mode</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be padded.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, padded image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomPerspective"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomPerspective.html#mindspore.dataset.vision.py_transforms.RandomPerspective">[docs]</a><span class="k">class</span> <span class="nc">RandomPerspective</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly apply perspective transformation to the input PIL Image with a given probability.</span>

<span class="sd">    Args:</span>
<span class="sd">        distortion_scale (float, optional): The scale of distortion, in range of [0, 1] (default=0.5).</span>
<span class="sd">        prob (float, optional): Probability of the image being applied perspective transformation (default=0.5).</span>
<span class="sd">        interpolation (Inter, optional): Image interpolation mode (default=Inter.BICUBIC).</span>
<span class="sd">            It can be any of [Inter.BILINEAR, Inter.NEAREST, Inter.BICUBIC].</span>

<span class="sd">            - Inter.BILINEAR, bilinear interpolation.</span>

<span class="sd">            - Inter.NEAREST, nearest-neighbor interpolation.</span>

<span class="sd">            - Inter.BICUBIC, bicubic interpolation.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomPerspective(prob=0.1),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_perspective</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">distortion_scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distortion_scale</span> <span class="o">=</span> <span class="n">distortion_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span> <span class="o">=</span> <span class="n">DE_PY_INTER_MODE</span><span class="p">[</span><span class="n">interpolation</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be applied randomly perspective transformation.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, image applied randomly perspective transformation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_pil</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input image should be a Pillow image.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">&gt;</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">():</span>
            <span class="n">start_points</span><span class="p">,</span> <span class="n">end_points</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">get_perspective_params</span><span class="p">(</span>
                <span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">distortion_scale</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">perspective</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">start_points</span><span class="p">,</span> <span class="n">end_points</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span></div>


<div class="viewcode-block" id="RandomErasing"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomErasing.html#mindspore.dataset.vision.py_transforms.RandomErasing">[docs]</a><span class="k">class</span> <span class="nc">RandomErasing</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly erase the pixels within a random selected rectangle region with a given probability.</span>

<span class="sd">    See Zhun Zhong et al. &#39;Random Erasing Data Augmentation&#39; 2017 on https://arxiv.org/pdf/1708.04896.pdf</span>

<span class="sd">    Args:</span>
<span class="sd">        prob (float, optional): Probability of the image being randomly erased (default=0.5).</span>
<span class="sd">        scale (sequence of floats, optional): Range of the relative erase area to the</span>
<span class="sd">            original image (default=(0.02, 0.33)).</span>
<span class="sd">        ratio (sequence, optional): Range of aspect ratio of the erased area (default=(0.3, 3.3)).</span>
<span class="sd">        value (Union[int, sequence, str]): Erasing value (default=0).</span>
<span class="sd">            If value is a single integer, it is used to erase all pixels.</span>
<span class="sd">            If value is a sequence of length 3, it is used to erase R, G, B channels respectively.</span>
<span class="sd">            If value is a string of &#39;random&#39;, each pixel will be erased with a random value obtained</span>
<span class="sd">            from a standard normal distribution.</span>
<span class="sd">        inplace (bool, optional): Whether to apply this transformation inplace (default=False).</span>
<span class="sd">        max_attempts (int, optional): The maximum number of attempts to propose a valid</span>
<span class="sd">            area to be erased (default=10). If exceeded, return the original image.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.RandomErasing(value=&#39;random&#39;)])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_erasing</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">),</span> <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.3</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_attempts</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span> <span class="o">=</span> <span class="n">ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span> <span class="o">=</span> <span class="n">inplace</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_attempts</span> <span class="o">=</span> <span class="n">max_attempts</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">np_img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            np_img (numpy.ndarray): image in shape of (C, H, W) to be randomly erased.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, erased image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">bounded</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">&gt;</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">():</span>
            <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">erase_h</span><span class="p">,</span> <span class="n">erase_w</span><span class="p">,</span> <span class="n">erase_value</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">get_erase_params</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span><span class="p">,</span>
                                                                        <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">bounded</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_attempts</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">erase</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">erase_h</span><span class="p">,</span> <span class="n">erase_w</span><span class="p">,</span> <span class="n">erase_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np_img</span></div>


<div class="viewcode-block" id="Cutout"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Cutout.html#mindspore.dataset.vision.py_transforms.Cutout">[docs]</a><span class="k">class</span> <span class="nc">Cutout</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly apply a given number of square patches of zeros to a location within the input</span>
<span class="sd">    numpy.ndarray image of shape (C, H, W).</span>

<span class="sd">    See Terrance DeVries and Graham W. Taylor &#39;Improved Regularization of Convolutional Neural Networks with Cutout&#39;</span>
<span class="sd">    2017 on https://arxiv.org/pdf/1708.04552.pdf</span>

<span class="sd">    Args:</span>
<span class="sd">        length (int): The side length of each square patch.</span>
<span class="sd">        num_patches (int, optional): Number of patches to be applied to the image (default=1).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.Cutout(80)])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_cutout</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">num_patches</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">length</span> <span class="o">=</span> <span class="n">length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_patches</span> <span class="o">=</span> <span class="n">num_patches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">np_img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            np_img (numpy.ndarray): Image in shape of (C, H, W) to be cut out.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, image cut out.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;img should be NumPy array. Got </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">np_img</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">np_img</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s1">&#39;img dimension should be 3. Got </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np_img</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">image_h</span><span class="p">,</span> <span class="n">image_w</span> <span class="o">=</span> <span class="n">np_img</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">length</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">length</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">image_h</span> <span class="o">*</span> <span class="n">image_w</span><span class="p">)</span>
        <span class="n">bounded</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_patches</span><span class="p">):</span>
            <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">erase_h</span><span class="p">,</span> <span class="n">erase_w</span><span class="p">,</span> <span class="n">erase_value</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">get_erase_params</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">scale</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">bounded</span><span class="p">,</span>
                                                                        <span class="mi">1</span><span class="p">)</span>
            <span class="n">np_img</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">erase</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">erase_h</span><span class="p">,</span> <span class="n">erase_w</span><span class="p">,</span> <span class="n">erase_value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np_img</span></div>


<div class="viewcode-block" id="LinearTransformation"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.LinearTransformation.html#mindspore.dataset.vision.py_transforms.LinearTransformation">[docs]</a><span class="k">class</span> <span class="nc">LinearTransformation</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transform the input numpy.ndarray image with a given square transformation matrix and a mean vector.</span>
<span class="sd">    It will first flatten the input image and subtract the mean vector from it, then compute the dot</span>
<span class="sd">    product with the transformation matrix, finally reshape it back to its original shape.</span>

<span class="sd">    Args:</span>
<span class="sd">        transformation_matrix (numpy.ndarray): A square transformation matrix in shape of (D, D), where</span>
<span class="sd">            :math:`D = C \times H \times W`.</span>
<span class="sd">        mean_vector (numpy.ndarray): A mean vector in shape of (D,), where :math:`D = C \times H \times W`.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; height, width = 32, 32</span>
<span class="sd">        &gt;&gt;&gt; dim = 3 * height * width</span>
<span class="sd">        &gt;&gt;&gt; transformation_matrix = np.ones([dim, dim])</span>
<span class="sd">        &gt;&gt;&gt; mean_vector = np.zeros(dim)</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.Resize((height,width)),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.LinearTransformation(transformation_matrix, mean_vector)])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_linear_transform</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transformation_matrix</span><span class="p">,</span> <span class="n">mean_vector</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformation_matrix</span> <span class="o">=</span> <span class="n">transformation_matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_vector</span> <span class="o">=</span> <span class="n">mean_vector</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">np_img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            np_img (numpy.ndarray): Image in shape of (C, H, W) to be linearly transformed.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, linearly transformed image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">linear_transform</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformation_matrix</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_vector</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomAffine"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomAffine.html#mindspore.dataset.vision.py_transforms.RandomAffine">[docs]</a><span class="k">class</span> <span class="nc">RandomAffine</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply random affine transformation to the input PIL Image.</span>

<span class="sd">    Args:</span>
<span class="sd">        degrees (Union[int, float, sequence]): Range of degrees to select from.</span>
<span class="sd">            If `degrees` is a number, the range will be (-degrees, degrees).</span>
<span class="sd">            If `degrees` is a sequence, it should be in shape of (min, max).</span>
<span class="sd">        translate (sequence, optional): Maximum absolute fraction sequence in shape of (tx, ty)</span>
<span class="sd">            for horizontal and vertical translations. The horizontal and vertical shifts are randomly</span>
<span class="sd">            selected in the range (-tx * width, tx * width) and (-ty * height, ty * height) respectively.</span>
<span class="sd">            (default=None, no translation will be applied).</span>
<span class="sd">        scale (sequence, optional): Scaling factor interval (default=None, keep original scale).</span>
<span class="sd">        shear (Union[int, float, sequence], optional): Range of shear factor to select from.</span>
<span class="sd">            If shear is an integer, a shear parallel to the X axis in the range (-shear, shear) will be applied.</span>
<span class="sd">            If shear is a sequence of length 2, a shear parallel to the X axis in the range (shear[0], shear[1])</span>
<span class="sd">            will be applied.</span>
<span class="sd">            If shear is a sequence of length 4, a shear parallel to the X axis in the range (shear[0], shear[1])</span>
<span class="sd">            and a shear parallel to the Y axis in the range (shear[2], shear[3]) will be applied.</span>
<span class="sd">            (default=None, no shear will be applied).</span>
<span class="sd">        resample (Inter, optional): An optional resampling filter (default=Inter.NEAREST).</span>
<span class="sd">            If the PIL Image is in mode of &quot;1&quot; or &quot;P&quot;, it is set to Inter.NEAREST by default.</span>
<span class="sd">            It can be any of [Inter.BILINEAR, Inter.NEAREST, Inter.BICUBIC].</span>

<span class="sd">            - Inter.BILINEAR, bilinear interpolation.</span>

<span class="sd">            - Inter.NEAREST, nearest-neighbor interpolation.</span>

<span class="sd">            - Inter.BICUBIC, bicubic interpolation.</span>

<span class="sd">        fill_value (Union[int, tuple], optional): Pixel fill value for the area outside the</span>
<span class="sd">            transformed image (default=0).</span>
<span class="sd">            If fill_value is an integer, it is used for all RGB channels.</span>
<span class="sd">            If fill_value is a tuple of length 3, it is used to fill R, G, B channels respectively.</span>
<span class="sd">            Only supported with Pillow version &gt; 5.0.0.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If `degrees` is negative.</span>
<span class="sd">        ValueError: If translation is not between 0 and 1.</span>
<span class="sd">        ValueError: If scale is not positive.</span>
<span class="sd">        ValueError: If shear is a non positive number.</span>
<span class="sd">        TypeError: If `degrees` is not a number or a sequence of length 2.</span>
<span class="sd">        TypeError: If translate is defined but not a sequence of length 2.</span>
<span class="sd">        TypeError: If scale is not a sequence of length 2.</span>
<span class="sd">        TypeError: If shear is not a sequence of length 2 or 4.</span>
<span class="sd">        TypeError: If fill_value is not an integer or a tuple of length 3.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_affine</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degrees</span><span class="p">,</span> <span class="n">translate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shear</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">NEAREST</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">shear</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shear</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">):</span>
                <span class="n">shear</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">shear</span><span class="p">,</span> <span class="n">shear</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shear</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="n">shear</span> <span class="o">=</span> <span class="p">[</span><span class="n">shear</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shear</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]</span>
                <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shear</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                    <span class="n">shear</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">shear</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">degrees</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">):</span>
            <span class="n">degrees</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">degrees</span><span class="p">,</span> <span class="n">degrees</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">=</span> <span class="n">degrees</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">translate</span> <span class="o">=</span> <span class="n">translate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_ranges</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shear</span> <span class="o">=</span> <span class="n">shear</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resample</span> <span class="o">=</span> <span class="n">DE_PY_INTER_MODE</span><span class="p">[</span><span class="n">resample</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span> <span class="o">=</span> <span class="n">fill_value</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be randomly affine transformed.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, randomly affine transformed image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_affine</span><span class="p">(</span><span class="n">img</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">translate</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">scale_ranges</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">shear</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">resample</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span><span class="p">)</span></div>


<div class="viewcode-block" id="MixUp"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.MixUp.html#mindspore.dataset.vision.py_transforms.MixUp">[docs]</a><span class="k">class</span> <span class="nc">MixUp</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly mix up a batch of images together with its labels. Each image will be multiplied by a random</span>
<span class="sd">    weight lambda generated from the beta distribution and then added to another image multiplied by 1 - lambda.</span>
<span class="sd">    The same transformation will be applied to their labels with the same value of lambda. Make sure that the</span>
<span class="sd">    labels are one hot encoded in advance.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch_size (int): The number of images in a batch.</span>
<span class="sd">        alpha (float): The alpha and beta parameter in the beta distribution.</span>
<span class="sd">        is_single (bool, optional): If True, it will randomly mix up [img(0), ..., img(n-1), img(n)] with</span>
<span class="sd">            [img1, ..., img(n), img0] in each batch. Otherwise, it will randomly mix up images with the</span>
<span class="sd">            output of mixing of previous batch of images (Default=True).</span>


<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; # Setup multi-batch mixup transformation</span>
<span class="sd">        &gt;&gt;&gt; transform = [py_vision.MixUp(batch_size=16, alpha=0.2, is_single=False)]</span>
<span class="sd">        &gt;&gt;&gt; # Apply the transform to the dataset through dataset.map()</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(input_columns=&quot;image&quot;,</span>
<span class="sd">        ...                                                 operations=transform)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_mix_up</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">is_single</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_first</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_single</span> <span class="o">=</span> <span class="n">is_single</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            image (numpy.ndarray): Images to be mixed up.</span>
<span class="sd">            label (numpy.ndarray): Labels to be mixed up.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, images after mixing up.</span>
<span class="sd">            numpy.ndarray, labels after mixing up.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_single</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">mix_up_single</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">mix_up_muti</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span></div>


<span class="k">class</span> <span class="nc">RgbToBgr</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert one or more numpy.ndarray images from RGB to BGR.</span>

<span class="sd">    Args:</span>
<span class="sd">        is_hwc (bool): Whether the image is in shape of (H, W, C) or (N, H, W, C), otherwise</span>
<span class="sd">            in shape of (C, H, W) or (N, C, H, W) (default=False).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.CenterCrop(20),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.RgbToBgr()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_rgb_to_bgr</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">is_hwc</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span> <span class="o">=</span> <span class="n">is_hwc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rgb_imgs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            rgb_imgs (numpy.ndarray): RGB images to be converted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, converted BGR images.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">rgb_to_bgrs</span><span class="p">(</span><span class="n">rgb_imgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span><span class="p">)</span>


<div class="viewcode-block" id="RgbToHsv"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RgbToHsv.html#mindspore.dataset.vision.py_transforms.RgbToHsv">[docs]</a><span class="k">class</span> <span class="nc">RgbToHsv</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert one or more numpy.ndarray images from RGB to HSV.</span>

<span class="sd">    Args:</span>
<span class="sd">        is_hwc (bool): Whether the image is in shape of (H, W, C) or (N, H, W, C), otherwise</span>
<span class="sd">            in shape of (C, H, W) or (N, C, H, W) (default=False).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.CenterCrop(20),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.RgbToHsv()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_rgb_to_hsv</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">is_hwc</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span> <span class="o">=</span> <span class="n">is_hwc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rgb_imgs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            rgb_imgs (numpy.ndarray): RGB images to be converted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, converted HSV images.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">rgb_to_hsvs</span><span class="p">(</span><span class="n">rgb_imgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span><span class="p">)</span></div>


<div class="viewcode-block" id="HsvToRgb"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.HsvToRgb.html#mindspore.dataset.vision.py_transforms.HsvToRgb">[docs]</a><span class="k">class</span> <span class="nc">HsvToRgb</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert one or more numpy.ndarray images from HSV to RGB.</span>

<span class="sd">    Args:</span>
<span class="sd">        is_hwc (bool): Whether the image is in shape of (H, W, C) or (N, H, W, C), otherwise</span>
<span class="sd">            in shape of (C, H, W) or (N, C, H, W) (default=False).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.CenterCrop(20),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.HsvToRgb()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_hsv_to_rgb</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">is_hwc</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span> <span class="o">=</span> <span class="n">is_hwc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hsv_imgs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            hsv_imgs (numpy.ndarray): HSV images to be converted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, converted RGB images.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">hsv_to_rgbs</span><span class="p">(</span><span class="n">hsv_imgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomColor"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomColor.html#mindspore.dataset.vision.py_transforms.RandomColor">[docs]</a><span class="k">class</span> <span class="nc">RandomColor</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Adjust the color balance of the input PIL Image by a random degree.</span>

<span class="sd">    Args:</span>
<span class="sd">        degrees (sequence): Range of color adjustment degree to be randomly chosen from,</span>
<span class="sd">            which should be in shape of (min, max) (default=(0.1,1.9)).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomColor((0.5, 2.0)),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_positive_degrees</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degrees</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">=</span> <span class="n">degrees</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be color adjusted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, color adjusted image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_color</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomSharpness"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomSharpness.html#mindspore.dataset.vision.py_transforms.RandomSharpness">[docs]</a><span class="k">class</span> <span class="nc">RandomSharpness</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Adjust the sharpness of the input PIL Image by a random degree.</span>

<span class="sd">    Args:</span>
<span class="sd">        degrees (sequence): Range of sharpness adjustment degree to be randomly chosen from, which</span>
<span class="sd">            should be in shape of (min, max) (default=(0.1,1.9)).</span>
<span class="sd">            Degree of 0.0 gives a blurred image, degree of 1.0 gives the original image,</span>
<span class="sd">            and degree of 2.0 increases the sharpness by a factor of 2.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomSharpness((0.5, 1.5)),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_positive_degrees</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degrees</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">=</span> <span class="n">degrees</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be sharpness adjusted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, sharpness adjusted image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_sharpness</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span><span class="p">)</span></div>


<span class="k">class</span> <span class="nc">AdjustGamma</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform gamma correction on the input PIL Image.</span>

<span class="sd">    Args:</span>
<span class="sd">        gamma (float): Gamma parameter in the correction equation, which must be non negative.</span>
<span class="sd">        gain (float, optional): The constant multiplier (default=1.0).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.AdjustGamma(gamma=10.0),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_adjust_gamma</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">=</span> <span class="n">gain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be gamma adjusted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, gamma adjusted image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">adjust_gamma</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gain</span><span class="p">)</span>


<div class="viewcode-block" id="AutoContrast"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.AutoContrast.html#mindspore.dataset.vision.py_transforms.AutoContrast">[docs]</a><span class="k">class</span> <span class="nc">AutoContrast</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Automatically maximize the contrast of the input PIL Image.</span>

<span class="sd">    Args:</span>
<span class="sd">        cutoff (float, optional): Percent of pixels to be cut off from the histogram,</span>
<span class="sd">            which must be in range of [0.0, 50.0) (default=0.0).</span>
<span class="sd">        ignore (Union[int, sequence], optional): Pixel values to be ignored (default=None).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.AutoContrast(),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_auto_contrast</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cutoff</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">ignore</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span> <span class="o">=</span> <span class="n">cutoff</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignore</span> <span class="o">=</span> <span class="n">ignore</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be automatically contrasted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, automatically contrasted image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">auto_contrast</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore</span><span class="p">)</span></div>


<div class="viewcode-block" id="Invert"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Invert.html#mindspore.dataset.vision.py_transforms.Invert">[docs]</a><span class="k">class</span> <span class="nc">Invert</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Invert the colors of the input PIL Image.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.Invert(),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be color inverted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, color inverted image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">invert_color</span><span class="p">(</span><span class="n">img</span><span class="p">)</span></div>


<div class="viewcode-block" id="Equalize"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Equalize.html#mindspore.dataset.vision.py_transforms.Equalize">[docs]</a><span class="k">class</span> <span class="nc">Equalize</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply histogram equalization on the input PIL Image.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.Equalize(),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be equalized.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, equalized image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">equalize</span><span class="p">(</span><span class="n">img</span><span class="p">)</span></div>


<div class="viewcode-block" id="UniformAugment"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.UniformAugment.html#mindspore.dataset.vision.py_transforms.UniformAugment">[docs]</a><span class="k">class</span> <span class="nc">UniformAugment</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Uniformly select a number of transformations from a sequence and apply them</span>
<span class="sd">    sequentially and randomly, which means that there is a chance that a chosen</span>
<span class="sd">    transformation will not be applied.</span>

<span class="sd">    All transformations in the sequence require the output type to be the same as</span>
<span class="sd">    the input. Thus, the latter one can deal with the output of the previous one.</span>

<span class="sd">    Args:</span>
<span class="sd">         transforms (sequence): Sequence of transformations to be chosen from.</span>
<span class="sd">         num_ops (int, optional): Number of transformations to be sequentially and randomly applied (default=2).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt; transforms = [py_vision.CenterCrop(64),</span>
<span class="sd">        ...               py_vision.RandomColor(),</span>
<span class="sd">        ...               py_vision.RandomSharpness(),</span>
<span class="sd">        ...               py_vision.RandomRotation(30)]</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.UniformAugment(transforms),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_uniform_augment_py</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">num_ops</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">transforms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_ops</span> <span class="o">=</span> <span class="n">num_ops</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL Image): Image to be transformed.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL Image, transformed image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">uniform_augment</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_ops</span><span class="p">)</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>