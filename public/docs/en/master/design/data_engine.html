<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>High Performance Data Processing Engine &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script src="../_static/js/training.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Glossary" href="glossary.html" />
    <link rel="prev" title="Graph-Kernel Fusion Acceleration Engine" href="graph_fusion_engine.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="programming_paradigm.html">Functional and Object-Oriented Fusion Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="all_scenarios.html">Full-scenarios Unified Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_design.html">Native Distributed Parallel Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">High Performance Data Processing Engine</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#background-introduction">Background Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#data-processing-engine-design">Data Processing Engine Design</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#design-goals-and-ideas">Design Goals and Ideas</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ultimate-processing-performance">Ultimate Processing Performance</a></li>
<li class="toctree-l3"><a class="reference internal" href="#flexible-customization-capabilities">Flexible Customization Capabilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="#device-cloud-unified-architecture">Device-cloud Unified Architecture</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/official_models.html">Official Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.experimental.html">mindspore.experimental</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/enveriment_preparation.html">Environment Preparation and Information Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/typical_api_comparision.html">Differences between PyTorch and MindSpore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/model_development/model_development.html">Constructing MindSpore Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/migrator_with_tools.html">Application Practice Guide for Network Migration Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/faq.html">FAQs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Syntax Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax_support.html">Static Graph Syntax Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/operators.html">Static Graph Syntax - Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/statements.html">Static Graph Syntax - Python Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/python_builtin_functions.html">Static Graph Syntax - Python Built-in Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/index_support.html">Tensor Index Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/env_var_list.html">Environment Variables</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>High Performance Data Processing Engine</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/design/data_engine.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="high-performance-data-processing-engine">
<h1>High Performance Data Processing Engine<a class="headerlink" href="#high-performance-data-processing-engine" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/mindspore/source_en/design/data_engine.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.svg" /></a></p>
<section id="background-introduction">
<h2>Background Introduction<a class="headerlink" href="#background-introduction" title="Permalink to this headline"></a></h2>
<p>The core of MindSpore training data processing engine is to efficiently and flexibly transform training samples (datasets) to a Tensor and provide that Tensor to the training network for training, with the following key features:</p>
<ul class="simple">
<li><p>Efficient data processing Pipeline, allowing data to flow within the Pipeline and achieving efficient processing capabilities.</p></li>
<li><p>Provide a variety of data loading capabilities such as common datasets, specific format datasets (MindRecord), custom datasets, to meet a variety of dataset loading needs of users.</p></li>
<li><p>Provide uniform sampling capabilities for multiple datasets, enabling flexible output of one copy of data.</p></li>
<li><p>Provide a large number of C++ layer data processing operations, Python layer data processing operations, and support custom data processing operations, making it easy for users to use upon unpacking.</p></li>
<li><p>Provide MindSpore dataset format (MindRecord), which facilitates users to convert their own datasets and then load them uniformly and efficiently through <code class="docutils literal notranslate"><span class="pre">MindDataset</span></code>.</p></li>
<li><p>Provide an automatic data augmentation mode, and perform automatic data augmentation on images based on specific strategies.</p></li>
<li><p>Provide single-node data caching capability to solve the problem of repeated loading and processing of data, reduce data processing overhead, and improve device-to-device training efficiency.</p></li>
</ul>
<p>MindSpore training data engine also provides efficient loading and sampling capabilities of datasets in fields, such as scientific computing - electromagnetic simulation, remote sensing large-format image processing, helping MindSpore achieve full-scene support.</p>
</section>
<section id="data-processing-engine-design">
<h2>Data Processing Engine Design<a class="headerlink" href="#data-processing-engine-design" title="Permalink to this headline"></a></h2>
<section id="design-goals-and-ideas">
<h3>Design Goals and Ideas<a class="headerlink" href="#design-goals-and-ideas" title="Permalink to this headline"></a></h3>
<p>The design of MindSpore considers the efficiency, flexibility and adaptability of data processing in different scenarios. The whole data processing subsystem is divided into the following modules:</p>
<p><img alt="image" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/design/images/data/architecture.png" /></p>
<ul class="simple">
<li><p>API: The data processing process is represented in MindSpore in the form of a graph, called a data graph. MindSpore provides Python API to define data graphs externally and implement graph optimization and graph execution internally.</p></li>
<li><p>Data Processing Pipeline: Data loading and pre-processing multi-step parallel pipeline, which consists of the following components.</p>
<ul>
<li><p>Adaptor: data graphs constructed in an upper-level language (e.g. Python) converted into a lower-level executable C++ data graph (Execution Tree).</p></li>
<li><p>Optimizer: Data graph optimizer to implement operations such as operator fusion and automatic parameter optimization.</p></li>
<li><p>Runtime: Running the execution engine of the optimized Execution tree.</p></li>
<li><p>Dataset Operations: A node in the Execution tree, corresponding to a specific step in the data processing pipeline, for example, the <code class="docutils literal notranslate"><span class="pre">ImageFolderDataset</span></code> and <code class="docutils literal notranslate"><span class="pre">MindDataset</span></code> operations for loading data from image folders, and the <code class="docutils literal notranslate"><span class="pre">map</span></code>, <code class="docutils literal notranslate"><span class="pre">shuffle</span></code>, <code class="docutils literal notranslate"><span class="pre">repeat</span></code>, <code class="docutils literal notranslate"><span class="pre">concat</span></code> and <code class="docutils literal notranslate"><span class="pre">split</span></code> operations for data processing.</p></li>
<li><p>Data Augmentation Operations: Also called Tensor operators, used to perform specific transformations on the Tensor, such as <code class="docutils literal notranslate"><span class="pre">Decode</span></code>, <code class="docutils literal notranslate"><span class="pre">Resize</span></code>, <code class="docutils literal notranslate"><span class="pre">Crop</span></code>, <code class="docutils literal notranslate"><span class="pre">Pad</span></code> operations, which are usually called by the <code class="docutils literal notranslate"><span class="pre">map</span></code> operation in Dataset Operations.</p></li>
</ul>
</li>
</ul>
<p>The results of the data augmentation are connected to the forward and backward computing system via a queue.</p>
<p>Based on the above design, the data processing engine implements the following Pipeline process:</p>
<p>In addition, due to the limited resources of device-side scenarios, MindSpore provides a set of more lightweight data processing Eager model, which can solve the problem that the data processing Pipeline of cloud-based scenarios is not applicable to the device-side. Users can directly perform data processing operations on a single image and then pass it into the model for inference.</p>
</section>
<section id="ultimate-processing-performance">
<h3>Ultimate Processing Performance<a class="headerlink" href="#ultimate-processing-performance" title="Permalink to this headline"></a></h3>
<ul>
<li><p>Multi-stage data processing pipeline</p>
<p>Unlike TensorFlow and PyTorch, MindSpore uses ，multi-stage parallel pipeline to build data processing Pipeline, which can plan the use of computational resources in a more fine-grained way. As shown above, each dataset operation contains an output Connector, which is an order-preserving buffer queue consisting of a set of blocking queues and counters. Each dataset operation takes cached data from the Connector of the upstream operation for processing, and then pushes this cache back to its own output Connector, and so on. The advantages of this mechanism include:</p>
<ul class="simple">
<li><p>The dataset loading, <code class="docutils literal notranslate"><span class="pre">map</span></code>, <code class="docutils literal notranslate"><span class="pre">batch</span></code> and other operations are driven by a task scheduling mechanism. Tasks for each operation are independent of each other, and the contexts are linked through Connectors.</p></li>
<li><p>Each operation can be implemented with fine-grained multi-threaded or multi-process parallel acceleration. Data framework provides the interfaces for users to adjust the number of threads of operation and control of multi-process processing, and users can flexibly control the processing speed of each node, and thus achieve optimal performance of the entire data processing Pipeline.</p></li>
<li><p>Support users to set the size of the Connector, which to a certain extent, can effectively control the memory utilization, and adapt to different network requirements for data processing performance.</p></li>
</ul>
<p>With this data processing mechanism, performing order-preserving on the output data is the key to ensure the training accuracy. Order preservation means that the data processing pipeline runs with the output data in the same order as it was before the data processing. MindSpore uses a round robin algorithm to ensure the orderliness of data during multi-threaded processing.</p>
<p>The above figure is a data processing Pipeline, where the order-preserving operation occurs in takeout operation of the downstream <code class="docutils literal notranslate"><span class="pre">map</span></code> operation (4 concurrent) to take out the data in the upstream queue by single-threaded round robin. The Connector has two internal counters. <code class="docutils literal notranslate"><span class="pre">expect_consumer_</span></code> records how many <code class="docutils literal notranslate"><span class="pre">consumer</span></code>s have taken data from <code class="docutils literal notranslate"><span class="pre">queues_</span></code> and <code class="docutils literal notranslate"><span class="pre">pop_from_</span></code> records which internal blocking queue is about to perform the next takeout operation. <code class="docutils literal notranslate"><span class="pre">expect_consumer_</span></code> performs modulo operation on <code class="docutils literal notranslate"><span class="pre">consumer</span></code>, and <code class="docutils literal notranslate"><span class="pre">pop_from_</span></code> performs modulo operation on <code class="docutils literal notranslate"><span class="pre">producer</span></code>. When <code class="docutils literal notranslate"><span class="pre">expect_consumer_</span></code> is 0 again, it means that all the <code class="docutils literal notranslate"><span class="pre">local_queues_</span></code> have finished processing the previous batch of tasks and can continue to allocate and process the next batch of tasks, thus realizing multiple concurrent order-preserving processing from upstream to downstream <code class="docutils literal notranslate"><span class="pre">map</span></code> operations.</p>
</li>
<li><p>Data processing and network computing pipeline</p>
<p>The data processing pipeline continuously processes the data and sends the processed data to the Device-side cache, and after the execution of one Step, the data of the next Step is read directly from the Device’s cache.</p>
<ul class="simple">
<li><p>datat processing: for processing the dataset into the input needed by the network and passing it to the sending queue to ensure efficient data processing.</p></li>
<li><p>sending Queue: maintaining data queues to ensure that data processing and network computing processes do not interfere with each other, acting as a bridge.</p></li>
<li><p>network computing: get the data from the sending queue for iterative training.</p></li>
</ul>
<p>Each of the above three has its own role, independent of each other, to construct the entire training process Pipeline. Therefore, as long as the data queue is not empty, model training will not block due to waiting for training data.</p>
</li>
<li><p>Cache technology</p>
<p>When the dataset size is too large to be loaded all into the in-memory cache, some of the data used for training needs to be read from disk and may encounter I/O bottlenecks, increasing the hit ratio of cache in each Epoch is especially critical. Traditional cache management uses LRU strategy, which does not consider the read characteristics of deep learning data, i.e., data is read repeatedly between different Epochs, while it is read randomly in the same Epoch. Each piece of data has the same probability of being read, so it does not matter which piece of data is cached. Instead it is more critical that the data that has been cached is not swapped out before it is used. For this feature, we use a simple and efficient caching algorithm, i.e., once data is cached, it is not swapped out of the cache.</p>
<p>During data graph optimization, MindSpore automatically generates caching operators based on the pipeline structure, caching both the original dataset and the results after data augmentation processing.</p>
</li>
</ul>
</section>
<section id="flexible-customization-capabilities">
<h3>Flexible Customization Capabilities<a class="headerlink" href="#flexible-customization-capabilities" title="Permalink to this headline"></a></h3>
<p>Users often have diverse needs for data processing, and processing logic that is not solidified in the framework needs to be supported by open customization capabilities. As a result, MindSpore provides flexible dataset loading methods, rich data processing operations, and mechanisms such as automatic data augmentation, dynamic Shape, and data processing Callback for developers to use in various scenarios.</p>
<ul>
<li><p>Flexible dataset loading methods</p>
<p>To address the challenge of having a wide variety of datasets with different formats and organization, MindSpore provides three different methods of loading datasets:</p>
<ul class="simple">
<li><p>For common datasets in each domain, they can be loaded directly by using MindSpore built-in API interface. MindSpore provides <code class="docutils literal notranslate"><span class="pre">CelebADataset</span></code>, <code class="docutils literal notranslate"><span class="pre">Cifar10Dataset</span></code>, <code class="docutils literal notranslate"><span class="pre">CocoDataset</span></code>, <code class="docutils literal notranslate"><span class="pre">ImageFolderDataset</span></code>, <code class="docutils literal notranslate"><span class="pre">MnistDataset</span></code>, <code class="docutils literal notranslate"><span class="pre">VOCDataset</span></code> and other common dataset loading interfaces to ensure performance while enabling users to use them out of the box.</p></li>
<li><p>For datasets that do not support direct loading at the moment, they can be converted to MindSpore data format, i.e. MindRecord, and then loaded through the <code class="docutils literal notranslate"><span class="pre">MindDataset</span></code> interface. MindRecord can normalize different dataset formats, with various advantages such as aggregated storage, efficient reading, fast coding and decoding, and flexible control of partition size.</p></li>
<li><p>Users can also write custom dataset reading classes in Python and then use the <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> interface for dataset loading. This method allows for quick integration of existing code, but requires additional attention to data loading performance as it is a Python IO Reader.</p></li>
</ul>
</li>
<li><p>Support more operations by Python layer customization and C++ layer plug-in</p>
<p>MindSpore has a rich set of built-in data processing operations, which can be divided into C++ layer and Python layer operations depending on the implementation. C++ layer operations tend to have better performance, while Python layer operations are easier to integrate with third-party libraries and are easier to implement. For the operation that the framework does not support, users can develop the C++ layer to implement the code, and the code is compiled in the form of a plug-in to register to MindSpore data processing Pipeline. The data processing logic is customized directly in the Python layer, and then called through the <code class="docutils literal notranslate"><span class="pre">map</span></code> operation.</p>
</li>
<li><p>Support automatic data augmentation strategies</p>
<p>MindSpore provides mechanisms for automatic image augmentation processing based on specific strategies, including probability-based automatic data augmentation and feedback-based automatic data augmentation, which can realize automatic selection and execution of operations to achieve improving training accuracy.</p>
<p>For the ImageNet dataset, the automatic data augmentation strategy finally searched by the AutoAugment method contains 25 substrategy combinations. Each substrategy contains 2 transformations, and one substrategy combination is randomly selected for each image in the actual training. A certain probability is used to decide whether to execute each transformation in the substrategy. The flow is shown in the figure below.</p>
<p>To support AutoAugment, an automatic data augmentation strategy, MindSpore provides the following interface.</p>
<ul>
<li><p>RandomChoice, or random selection, allows the user to define a list of data augmentation operations, and the data processing process will select one data augmentation operation from the list with equal probability for each image.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.dataset.transforms</span> <span class="kn">import</span> <span class="n">RandomChoice</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset.vision</span> <span class="kn">import</span> <span class="n">RandomCrop</span><span class="p">,</span> <span class="n">RandomHorizontalFlip</span><span class="p">,</span> <span class="n">RandomRotation</span>

<span class="n">transform_list</span> <span class="o">=</span> <span class="n">RandomChoice</span><span class="p">([</span><span class="n">RandomCrop</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span>
                               <span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
                               <span class="n">RandomRotation</span><span class="p">((</span><span class="mi">90</span><span class="p">,</span> <span class="mi">90</span><span class="p">))])</span>
</pre></div>
</div>
</li>
<li><p>RandomApply, a random probability execution, allows the user to define a list of data augmentation operations and the corresponding probabilities, and the data augmentation operations in the list will be executed for each image with the specified probability, either all or none.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.dataset.transforms</span> <span class="kn">import</span> <span class="n">RandomApply</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset.vision</span> <span class="kn">import</span> <span class="n">RandomCrop</span><span class="p">,</span> <span class="n">RandomHorizontalFlip</span><span class="p">,</span> <span class="n">RandomRotation</span>

<span class="n">transform_list</span> <span class="o">=</span> <span class="n">RandomApply</span><span class="p">([</span><span class="n">RandomCrop</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span>
                              <span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
                              <span class="n">RandomRotation</span><span class="p">((</span><span class="mi">90</span><span class="p">,</span> <span class="mi">90</span><span class="p">))],</span> <span class="mf">0.8</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>RandomSelectSubpolicy, a random subpolicy selection, allows users to define multiple lists of data augmentation operation subpolices and specify the probability of execution for each data augmentation operation in the subpolicy. During data processing, a subpolicy is first selected with equal probability for each image, and then whether each data augmentation operation is performed is decided in order according to the probability.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.dataset.vision</span> <span class="kn">import</span> <span class="n">RandomSelectSubpolicy</span><span class="p">,</span> <span class="n">RandomRotation</span><span class="p">,</span> <span class="n">RandomVerticalFlip</span><span class="p">,</span> \
    <span class="n">RandomHorizontalFlip</span>

<span class="n">transform_list</span> <span class="o">=</span> <span class="n">RandomSelectSubpolicy</span><span class="p">([[(</span><span class="n">RandomRotation</span><span class="p">((</span><span class="mi">45</span><span class="p">,</span> <span class="mi">45</span><span class="p">)),</span> <span class="mf">0.5</span><span class="p">),</span>
                                         <span class="p">(</span><span class="n">RandomVerticalFlip</span><span class="p">(),</span> <span class="mi">1</span><span class="p">)],</span>
                                        <span class="p">[(</span><span class="n">RandomRotation</span><span class="p">((</span><span class="mi">90</span><span class="p">,</span> <span class="mi">90</span><span class="p">)),</span> <span class="mi">1</span><span class="p">),</span>
                                         <span class="p">(</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span> <span class="mf">0.5</span><span class="p">)]])</span>
</pre></div>
</div>
</li>
</ul>
<p>Automatic data augmentation operations can improve the training accuracy of the ImageNet dataset by about 1%.</p>
</li>
<li><p>Support dynamic shape</p>
<p>MindSpore supports custom control of the Shape of the output training data through <code class="docutils literal notranslate"><span class="pre">per_batch_map</span></code>, which satisfies that the network needs to adjust the data Shape based on different scenarios.</p>
<ul class="simple">
<li><p>Users control the Shape of the generated data through user-defined functions (UDF), e.g. generate the data with the Shape (x, y, z, …) at the nth Step.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">per_batch_map</span></code> parameter of the <code class="docutils literal notranslate"><span class="pre">batch</span></code> operation is passed to this custom function to obtain the training data with different Shape.</p></li>
</ul>
</li>
<li><p>Callback mechanism makes data processing more flexible</p>
<p>The function of dynamically adjusting the data augmentation logic according to the training results is implemented through the Callback mechanism, which provides more flexible automatic data augmentation.</p>
<p>MindSpore supports users to implement their own data augmentation logic (User Defined Function, UDF) based on the DSCallback provided by data processing (including Epoch Start, Step Start, Step End, Epoch End) and add it to <code class="docutils literal notranslate"><span class="pre">map</span></code> operations to achieve more flexible data augmentation operations.</p>
</li>
</ul>
</section>
<section id="device-cloud-unified-architecture">
<h3>Device-cloud Unified Architecture<a class="headerlink" href="#device-cloud-unified-architecture" title="Permalink to this headline"></a></h3>
<ul>
<li><p>Unification of data and computational graphs</p>
<p>MindIR is MindSpore functional IR based on graph representation, whose most central purpose is to serve automatic differential transformations. Automatic differentiation uses a transformation method based on a functional programming framework, so IR adopts a semantics close to that of ANF functional style.</p>
<p>Typical scenarios for inference data graphs include size scaling, intermediate screenshots, normalization, and channel transformations.</p>
<p>We save the inference data graphs as subgraphs in the generated model file (MindIR), so that the data processing process in the model can be loaded through a unified interface during inference to automatically perform data processing and get the input needed by the model, which simplifies user operations and improves ease of use.</p>
</li>
<li><p>Lightweight data processing</p>
<p>Data processing Pipeline occupies more system resources, including CPU and memory, during operation. Taking the training process of ImageNet as an example, the CPU usage reaches 20% and the memory usage reaches 30 to 50G. The resources that can be used are more abundant when training on the cloud side, but in device-side scenarios, this demand is often unacceptable. The initialization process of the data processing Pipeline is usually time-consuming, and also does not satisfy the device-side need for fast start-up and multiple training and inference. Therefore, MindSpore provides a set of data processing models that are lighter and more applicable to device-side scenarios, solving the problem that the data processing Pipeline for cloud-based scenarios is not applicable to the device-side.</p>
<p>MindSpore supports independently use data processing single operation (Eager mode), supports various scenarios of inference, provides AI developers with greater flexibility based on Pipeline tuning architecture. At the same time, the Pipeline is lightened to achieve a light pipeline based on Pull Base, reducing resource consumption and improving processing speed.</p>
</li>
</ul>
<p>With the above two methods, MindSpore ensures that a unified data processing architecture supports many different application scenarios.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="graph_fusion_engine.html" class="btn btn-neutral float-left" title="Graph-Kernel Fusion Acceleration Engine" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="glossary.html" class="btn btn-neutral float-right" title="Glossary" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>