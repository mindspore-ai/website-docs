<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Model Analysis and Preparation &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script src="../_static/js/mermaid-9.3.0.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Network Constructing Comparison" href="model_development/model_development.html" />
    <link rel="prev" title="Environment Preparation" href="enveriment_preparation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/programming_paradigm.html">Functional and Object-Oriented Fusion Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/distributed_training_design.html">Distributed Parallel Native</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/all_scenarios.html">Full-scenarios Unified Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/official_models.html">Official Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.experimental.html">mindspore.experimental</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="enveriment_preparation.html">Environment Preparation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_development/model_development.html">Network Constructing Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Syntax Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax_support.html">Static Graph Syntax Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/operators.html">Static Graph Syntax - Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/statements.html">Static Graph Syntax - Python Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/python_builtin_functions.html">Static Graph Syntax - Python Built-in Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/index_support.html">Tensor Index Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/env_var_list.html">Environment Variables</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Model Analysis and Preparation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/migration_guide/analysis_and_preparation.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section class="tex2jax_ignore mathjax_ignore" id="model-analysis-and-preparation">
<h1>Model Analysis and Preparation<a class="headerlink" href="#model-analysis-and-preparation" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/mindspore/source_en/migration_guide/analysis_and_preparation.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.svg" /></a></p>
<section id="reproducing-algorithm-implementation">
<h2>Reproducing Algorithm Implementation<a class="headerlink" href="#reproducing-algorithm-implementation" title="Permalink to this headline"></a></h2>
<ol class="arabic simple">
<li><p>Obtain the PyTorch reference code.</p></li>
<li><p>Analyze the algorithm, network structure, and tricks in the original code, including the method of data augmentation, learning rate attenuation policy, optimizer parameters, and the initialization method of training parameters, etc.</p></li>
<li><p>Reproduce the accuracy of the reference implementation, obtain the performance data of the reference implementation, and identify some issues in advance.</p></li>
</ol>
<p>Please refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/master/migration_guide/reproducing_algorithm.html">Details of Reproducing Algorithm Implementation</a>.</p>
</section>
<section id="analyzing-api-compliance">
<h2>Analyzing API Compliance<a class="headerlink" href="#analyzing-api-compliance" title="Permalink to this headline"></a></h2>
<p>Before practicing migration, it is recommended to analyze the API compliance in MindSpore’s migration code to avoid affecting code implementation due to the lack of API support.</p>
<p>The API missing analysis here refers to APIs in the network execution diagram, including MindSpore <a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/mindspore.ops.primitive.html">operators</a> and advanced encapsulated APIs, and excluding the APIs used in data processing. You are advised to use third-party APIs, such as NumPy, OpenCV, Pandas, and PIL, to replace APIs used in data processing.</p>
<p>There are two methods to analyze API compliance:</p>
<ol class="arabic simple">
<li><p>Scanning API by MindSpore Dev Toolkit (recommended).</p></li>
<li><p>Querying the API Mapping Table.</p></li>
</ol>
<section id="scanning-api-by-toolkit">
<h3>Scanning API by Toolkit<a class="headerlink" href="#scanning-api-by-toolkit" title="Permalink to this headline"></a></h3>
<p><a class="reference external" href="https://www.mindspore.cn/devtoolkit/docs/en/master/index.html">MindSpore Dev Toolkit</a> is a development kit supporting PyCharm and Visual Studio Code plug-in developed by MindSpore, which can scan API based on file-level or project-level.</p>
<p>Refer to <a class="reference external" href="https://www.mindspore.cn/devtoolkit/docs/en/master/api_scanning.html">PyCharm API Scanning</a> for the tutorials of Dev Toolkit in PyCharm.</p>
<p><img alt="api_scan_pycharm" src="../_images/api_scan_pycharm.jpg" /></p>
<p>Refer to <a class="reference external" href="https://www.mindspore.cn/devtoolkit/docs/en/master/VSCode_api_scan.html">Visual Studio Code API Scanning</a> for the tutorials of Dev Toolkit in Visual Studio Code.</p>
<p><img alt="api_scan_pycharm" src="../_images/api_scan_vscode.jpg" /></p>
</section>
<section id="querying-the-api-mapping-table">
<h3>Querying the API Mapping Table<a class="headerlink" href="#querying-the-api-mapping-table" title="Permalink to this headline"></a></h3>
<p>Take the PyTorch code migration as an example. After obtaining the reference code implementation, you can filter keywords such as <code class="docutils literal notranslate"><span class="pre">torch</span></code>, <code class="docutils literal notranslate"><span class="pre">nn</span></code>, and <code class="docutils literal notranslate"><span class="pre">ops</span></code> to obtain the used APIs. If the method of another repository is invoked, you need to manually analyze the API. Then, check the <a class="reference external" href="https://www.mindspore.cn/docs/en/master/note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a>.
Alternatively, the <a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/mindspore.ops.primitive.html">API</a> searches for the corresponding API implementation.</p>
<p>For details about the mapping of other framework APIs, see the <a class="reference external" href="https://www.mindspore.cn/docs/en/master/api_python/mindspore.html">API naming and function description</a>. For APIs with the same function, the names of MindSpore may be different from those of other frameworks. The parameters and functions of APIs with the same name may also be different from those of other frameworks. For details, see the official description.</p>
</section>
<section id="processing-missing-api">
<h3>Processing Missing API<a class="headerlink" href="#processing-missing-api" title="Permalink to this headline"></a></h3>
<p>You can use the following methods to process the missing API:</p>
<ol class="arabic simple">
<li><p>Use equivalent replacement</p></li>
<li><p>Use existing APIs to package equivalent function logic</p></li>
<li><p>Customize operators</p></li>
<li><p>Seek help from the community</p></li>
</ol>
<p>Refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/master/migration_guide/missing_api_processing_policy.html">Missing API Processing Policy</a> for details.</p>
</section>
</section>
<section id="analyzing-function-compliance">
<h2>Analyzing Function Compliance<a class="headerlink" href="#analyzing-function-compliance" title="Permalink to this headline"></a></h2>
<p>During continuous delivery of MindSpore, some functions are restricted. If restricted functions are involved during network migration, before migration, functional compliance needs to be analyzed.
It can be analyzed from the following points:</p>
<ol class="arabic simple">
<li><p>Dynamic shape.</p></li>
<li><p>Sparse.</p></li>
</ol>
<section id="dynamic-shape">
<h3>Dynamic Shape<a class="headerlink" href="#dynamic-shape" title="Permalink to this headline"></a></h3>
<p>Currently MindSpore dynamic shape feature is under iterative development, and the dynamic shape functionality is not well supported. The following will give several scenarios where dynamic shape is introduced. During network migration, the presence of one of the following scenarios indicates the presence of dynamic shape in the network.</p>
<ul>
<li><p>Several scenarios that introduces dynamic shapes:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.mindspore.cn/docs/en/master/migration_guide/dynamic_shape.html#input-shape-not-fixed">Input Shape is not Fixed</a></p></li>
<li><p><a class="reference external" href="https://www.mindspore.cn/docs/en/master/migration_guide/dynamic_shape.html#apis-that-cause-shape-changes-during-network-execution">APIs that Cause Shape Changes During Network Execution</a></p></li>
<li><p><a class="reference external" href="https://www.mindspore.cn/docs/en/master/migration_guide/dynamic_shape.html#shape-changes-introduced-by-different-branches-of-control-flows">Shape Changes Introduced by Different Branches of Control Flows</a></p></li>
</ul>
</li>
<li><p>Several solutions for dynamic shapes:</p>
<ul>
<li><p>Input shape is not fixed:
Dynamic shape can be converted to static shape through the mask mechanism. Mask mechanism example code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_convert_ids_and_mask</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">,</span> <span class="n">seq_max_bucket_length</span><span class="p">):</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">)</span>
    <span class="n">input_mask</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_seq_length</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">seq_max_bucket_length</span><span class="p">:</span>
        <span class="n">input_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">input_mask</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span> <span class="o">==</span> <span class="n">seq_max_bucket_length</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_mask</span><span class="p">)</span> <span class="o">==</span> <span class="n">seq_max_bucket_length</span>

    <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_mask</span>
</pre></div>
</div>
</li>
<li><p>There is an API that triggers a shape change during network execution:
If this scenario is encountered to introduce a dynamic shape, the essence is that the dynamically changing values need to be modified to a fixed shape to solve the problem.
As in the case of the TopK operator, if K is changing during execution, a dynamic shape is introduced.
Solution: You can fix a maximum number of targets, first get the confidence level of all targets by static shape, then choose the K number of highest targets as the result output, and other targets are removed by mask mechanism. Sample code such as the multiclass_nms interface of <a class="reference external" href="https://gitee.com/mindspore/models/blob/master/official/cv/FasterRCNN/src/FasterRcnn/faster_rcnn.py">FasterRCNN</a>.</p></li>
<li><p>Different branches of the control flow introduce changes on the shape:
You can try to use equal, select operators to replace the if condition. Sample code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Code example for introducing control flow:</span>
<span class="k">if</span> <span class="n">ms</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">object_masks</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
   <span class="n">stage2_loss</span> <span class="o">=</span> <span class="n">stage2_loss</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
<span class="c1"># modified code example</span>
<span class="n">stage2_loss</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">object_masks</span><span class="p">),</span> <span class="mi">0</span><span class="p">),</span> <span class="n">stage2_loss</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">stage2_loss</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</section>
<section id="sparse">
<h3>Sparse<a class="headerlink" href="#sparse" title="Permalink to this headline"></a></h3>
<p>MindSpore now supports the two most commonly used sparse data formats, CSR and COO, but due to the limited support for sparse operators at the moment, most of the sparse features are still limited.
In this case, it is recommended to find whether the corresponding operator supports sparse computation first, and if not it needs to be converted to a normal operator. For details, see <a class="reference external" href="https://www.mindspore.cn/docs/en/master/migration_guide/sparsity.html">Sparse</a>.</p>
</section>
</section>
<section id="recommended-functions-and-features-for-migration-scenarios">
<h2>Recommended Functions and Features for Migration Scenarios<a class="headerlink" href="#recommended-functions-and-features-for-migration-scenarios" title="Permalink to this headline"></a></h2>
<p>The main problems in the MindSpore network migration process are: accuracy problems and performance problems. The following section describes the relatively mature functions and features provided by MindSpore to localize these two problems.</p>
<section id="accuracy-problem">
<h3>Accuracy Problem<a class="headerlink" href="#accuracy-problem" title="Permalink to this headline"></a></h3>
<p>Common localization methods for accuracy problems can be found in: <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/accuracy_problem_preliminary_location.html">Preliminary Localization Guide for Accuracy Problems</a> and <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/accuracy_optimization.html">Accuracy problem detailed localization and tuning guide</a>.
Here are a few of the main tools used for positioning accuracy issues:</p>
<ol class="arabic simple">
<li><p>Visualize the dataset.</p></li>
<li><p>TroubleShooter.</p></li>
<li><p>Dump.</p></li>
</ol>
<section id="visualizing-the-dataset">
<h4>Visualizing the Dataset<a class="headerlink" href="#visualizing-the-dataset" title="Permalink to this headline"></a></h4>
<p>MindRecord is an efficient data format developed by MindSpore that allows you to first check that your data is processed correctly when accuracy issues arise.
If the source data is TFRecord, it can be converted to MindRecord by <a class="reference external" href="https://gitee.com/mindspore/models/blob/master/official/nlp/Bert/src/tools/parallel_tfrecord_to_mindrecord.py">TFRecord to MindRecord</a> tool, and sent directly to the network for accuracy comparison.
Use <a class="reference external" href="https://gitee.com/mindspore/models/blob/master/official/nlp/Bert/src/tools/vis_tfrecord_or_mindrecord.py">visualize TFRecord or MindRecord datasets</a> tool to visualize the data for data checking.</p>
</section>
<section id="troubleshooter">
<h4>TroubleShooter<a class="headerlink" href="#troubleshooter" title="Permalink to this headline"></a></h4>
<p><a class="reference external" href="https://gitee.com/mindspore/toolkits/tree/master/troubleshooter">TroubleShooter</a> is a MindSpore web development debugging toolkit for providing convenient, easy-to-use debugging capabilities.
The current functions supported by TroubleShooter are: comparing whether two sets of Tensor values (npy files) are equal; comparing whether the network outputs of PyTorch and MindSpore are equal; comparing the ckpt/pth of MindSpore and PyTorch, etc.
See <a class="reference external" href="https://gitee.com/mindspore/toolkits/tree/master/troubleshooter#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF">TroubleShooter application scenarios</a> for details.</p>
</section>
<section id="dump">
<h4>Dump<a class="headerlink" href="#dump" title="Permalink to this headline"></a></h4>
<p>MindSpore provides Dump function, used to model training in the graph and operator input and output data saved to disk files, generally used for network migration complex problem location (eg: operator overflow, etc). It can be dumped out of the operator level data.</p>
<p>For getting Dump data, refer to: <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/debug/dump.html#synchronous-dump-step">Synchronous Dump Step</a> and <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/debug/dump.html#asynchronous-dump-step">Asynchronous Dump Step</a>.</p>
<p>For analyzig Dump data, refer to: <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/debug/dump.html#synchronous-dump-data-analysis-sample">Synchronous Dump Data Analysis Sample</a> and <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/debug/dump.html#asynchronous-dump-data-analysis-sample">Asynchronous Dump Data Analysis Sample</a></p>
<p>See <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/debug/dump.html">Dump</a> for details.</p>
</section>
</section>
<section id="performance-issues">
<h3>Performance Issues<a class="headerlink" href="#performance-issues" title="Permalink to this headline"></a></h3>
<p>Common methods for locating performance problems can be found in: <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/performance_tuning_guide.html">Performance Tuning Guide</a>.
Here are a few of the main tools available for locating performance issues:</p>
<ol class="arabic simple">
<li><p>Profiler.</p></li>
<li><p>MindSpore Insight.</p></li>
</ol>
<section id="profiler">
<h4>Profiler<a class="headerlink" href="#profiler" title="Permalink to this headline"></a></h4>
<p>Profiler can record information such as operator time consumption during the training and inference process into a file, and mainly provides the host execution of the framework, as well as the Profiler analysis function of operator execution to help users debug neural network performance more efficiently.
Currently MindSpore offers two ways to enable Profiler: <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling_ascend.html#method-1-modify-the-training-script">Modify the script to get performance data</a> and <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling_ascend.html#method-2-enable-environment-variables">Environment variables get access to performance data</a>.</p>
</section>
<section id="mindspore-insight">
<h4>MindSpore Insight<a class="headerlink" href="#mindspore-insight" title="Permalink to this headline"></a></h4>
<p>MindSpore Insight is a visual debugging and tuning tool to help users get better model accuracy and performance. After obtaining performance data through Profiler, you can use MindSpore Insight to visualize the data and then view the training process, optimize model performance, and debug accuracy issues.
An introduction to MindSpore Insight startup and other uses can be found at <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/mindinsight_commands.html#mindspore-insight-commands">MindSpore Insight related commands</a>.
After visualizing the data, the data can be analyzed by <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling_ascend.html#training-performance">parsing performance data</a> for data analysis.
More introduction can be found in <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/index.html">MindSpore Insight documentation</a>.</p>
</section>
</section>
<section id="dynamic-and-static-graphs">
<h3><a class="reference external" href="https://www.mindspore.cn/tutorials/en/master/beginner/accelerate_with_static_graph.html">Dynamic and Static Graphs</a><a class="headerlink" href="#dynamic-and-static-graphs" title="Permalink to this headline"></a></h3>
<p>Currently, there are two execution modes of a mainstream deep learning framework: a static graph mode (Graph) and a dynamic graph mode (PyNative).</p>
<ul class="simple">
<li><p>In static graph mode, when the program is built and executed, the graph structure of the neural network is generated first, and then the computation operations involved in the graph are performed. Therefore, in static graph mode, the compiler can achieve better execution performance by using technologies such as graph optimization, which facilitates large-scale deployment and cross-platform running.</p></li>
<li><p>In dynamic graph mode, the program is executed line by line according to the code writing sequence. In the forward execution process, the backward execution graph is dynamically generated according to the backward propagation principle. In this mode, the compiler delivers the operators in the neural network to the device one by one for computing, facilitating users to build and debug the neural network model.</p></li>
</ul>
</section>
<section id="calling-the-custom-class">
<h3><a class="reference external" href="https://www.mindspore.cn/tutorials/en/master/advanced/static_graph_expert_programming.html#using-jit-class">Calling the Custom Class</a><a class="headerlink" href="#calling-the-custom-class" title="Permalink to this headline"></a></h3>
<p>In static graph mode, you can use <code class="docutils literal notranslate"><span class="pre">jit_class</span></code> to modify a custom class. You can create and call an instance of the custom class, and obtain its attributes and methods.</p>
<p><code class="docutils literal notranslate"><span class="pre">jit_class</span></code> is applied to the static graph mode to expand the support scope of static graph compilation syntax. In dynamic graph mode, that is, PyNative mode, the use of <code class="docutils literal notranslate"><span class="pre">jit_class</span></code> does not affect the execution logic of PyNative mode.</p>
</section>
<section id="automatic-differential">
<h3><a class="reference external" href="https://www.mindspore.cn/tutorials/en/master/beginner/autograd.html">Automatic Differential</a><a class="headerlink" href="#automatic-differential" title="Permalink to this headline"></a></h3>
<p>Automatic differentiation can calculate a derivative value of a derivative function at a certain point, which is a generalization of backward propagation algorithms. The main problem solved by automatic differential is to decompose a complex mathematical operation into a series of simple basic operations. This function shields a large number of derivative details and processes from users, greatly reducing the threshold for using the framework.</p>
</section>
<section id="mixed-precision">
<h3><a class="reference external" href="https://www.mindspore.cn/tutorials/en/master/advanced/mixed_precision.html">Mixed Precision</a><a class="headerlink" href="#mixed-precision" title="Permalink to this headline"></a></h3>
<p>Generally, when a neural network model is trained, the default data type is FP32. In recent years, to accelerate training time, reduce memory occupied during network training, and store a trained model with same precision, more and more mixed-precision training methods are proposed in the industry. The mixed-precision training herein means that both single precision (FP32) and half precision (FP16) are used in a training process.</p>
</section>
<section id="auto-augmentation">
<h3><a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/dataset/augment.html">Auto Augmentation</a><a class="headerlink" href="#auto-augmentation" title="Permalink to this headline"></a></h3>
<p>MindSpore not only allows you to customize data augmentation, but also provides an automatic data augmentation mode to automatically perform data augmentation on images based on specific policies.</p>
</section>
<section id="gradient-accumulation">
<h3><a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/optimize/gradient_accumulation.html">Gradient Accumulation</a><a class="headerlink" href="#gradient-accumulation" title="Permalink to this headline"></a></h3>
<p>Gradient accumulation is a method of splitting data samples for training neural networks into several small batches by batch and then calculating the batches in sequence. The purpose is to solve the out of memory (OOM) problem that the neural network cannot be trained or the network model cannot be loaded due to insufficient memory.</p>
</section>
<section id="summary">
<h3><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/summary_record.html">Summary</a><a class="headerlink" href="#summary" title="Permalink to this headline"></a></h3>
<p>Scalars, images, computational graphs, training optimization processes, and model hyperparameters during training are recorded in files and can be viewed on the web page.</p>
</section>
<section id="debugger">
<h3><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/debugger.html">Debugger</a><a class="headerlink" href="#debugger" title="Permalink to this headline"></a></h3>
<p>The MindSpore debugger is a debugging tool provided for graph mode training. It can be used to view and analyze the intermediate results of graph nodes.</p>
</section>
<section id="golden-stick">
<h3><a class="reference external" href="https://www.mindspore.cn/golden_stick/docs/en/master/index.html">Golden Stick</a><a class="headerlink" href="#golden-stick" title="Permalink to this headline"></a></h3>
<p>MindSpore Golden Stick is a model compression algorithm set jointly designed and developed by Huawei Noah’s team and Huawei MindSpore team. It contains basic quantization and pruning methods.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="enveriment_preparation.html" class="btn btn-neutral float-left" title="Environment Preparation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="model_development/model_development.html" class="btn btn-neutral float-right" title="Network Constructing Comparison" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>