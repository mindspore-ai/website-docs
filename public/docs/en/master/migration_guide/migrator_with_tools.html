<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Application Practice Guide for Network Migration Tool &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/training.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="FAQs" href="faq.html" />
    <link rel="prev" title="Network Migration Debugging Example" href="sample_code.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/programming_paradigm.html">Functional and Object-Oriented Fusion Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/all_scenarios.html">Full-scenarios Unified Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/distributed_training_design.html">Native Distributed Parallel Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/official_models.html">Official Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/tensorflow_api_mapping.html">TensorFlow and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="enveriment_preparation.html">Environment Preparation and Information Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="typical_api_comparision.html">Differences Between MindSpore and PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_development/model_development.html">Constructing MindSpore Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Application Practice Guide for Network Migration Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Syntax Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax_support.html">Static Graph Syntax Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/operators.html">Static Graph Syntax —— Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/statements.html">Static Graph Syntax —— Python Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/python_builtin_functions.html">Static Graph Syntax —— Python Built-in Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/index_support.html">Tensor Index Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/env_var_list.html">Environment Variables</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Application Practice Guide for Network Migration Tool</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/migration_guide/migrator_with_tools.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="application-practice-guide-for-network-migration-tool">
<h1>Application Practice Guide for Network Migration Tool<a class="headerlink" href="#application-practice-guide-for-network-migration-tool" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/mindspore/source_en/migration_guide/migrator_with_tools.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>This guide describes how to apply various migration-related tools to improve the efficiency of the migration process when migrating neural networks from other machine learning frameworks to MindSpore, with a focus on describing how to tightly integrate the migration tools with the migration process.</p>
</section>
<section id="description-of-tools-related-to-network-migration-paths">
<h2>Description of Tools Related to Network Migration Paths<a class="headerlink" href="#description-of-tools-related-to-network-migration-paths" title="Permalink to this headline"></a></h2>
<section id="migration-path-tool-map">
<h3>Migration Path Tool Map<a class="headerlink" href="#migration-path-tool-map" title="Permalink to this headline"></a></h3>
<p><img alt="" src="../_images/map.png" /></p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Tools</p></th>
<th class="head"><p>Tool Description</p></th>
<th class="head"><p>Applications to network migration</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://www.mindspore.cn/devtoolkit/docs/en/master/index.html">MindSpore Dev Toolkit</a></p></td>
<td><p>MindSpore Dev Toolkit is a development kit supporting the cross-platform Python IDE plug-in developed by MindSpore, and provides functions such as Project creation, intelligent supplement, API search, and Document search.</p></td>
<td><p>With capabilities such as API search, it is possible to improve the efficiency of users network migration development.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://gitee.com/mindspore/toolkits/tree/master/troubleshooter">TroubleShooter</a></p></td>
<td><p>TroubleShooter is a MindSpore web development debugging toolkit designed to provide convenient, easy-to-use debugging capabilities.</p></td>
<td><p>Network debugging toolset (e.g., network weight migration, accuracy comparison, code tracing, error reporting analysis, execution tracking and other functions) to help users improve migration debugging efficiency.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling.html">Profiler</a></p></td>
<td><p>Profiler can record information such as operator time consumption during the training process into a file, which can be viewed and analyzed by the user through a visual interface, helping the user to debug neural network performance more efficiently.</p></td>
<td><p>After the network migration, if the execution performance is not good, you can use Profiler to analyze the performance. Profiler provides Profiler analysis of the host execution of the framework, as well as the execution of the operator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/debug/dump.html">Dump</a></p></td>
<td><p>The Dump function is provided to save the graphs from model training and the input and output data of the operators to a disk file.</p></td>
<td><p>Generally used for network migration complex problem localization (eg: operator overflow, etc.) and can dump out the operator-level data.</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="examples-of-network-migration-tool-applications">
<h2>Examples of Network Migration Tool Applications<a class="headerlink" href="#examples-of-network-migration-tool-applications" title="Permalink to this headline"></a></h2>
<p>This chapter uses a network (Vision Transformer) as an example of completing a network migration and describes how various tools are applied during the critical migration process.</p>
<p>Note: The complete sample code for migrating the network can be found at the following link</p>
<p><a class="reference external" href="https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_classification/vision_transformer">https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_classification/vision_transformer</a></p>
<section id="network-migration-development">
<h3>Network Migration Development<a class="headerlink" href="#network-migration-development" title="Permalink to this headline"></a></h3>
<p>The API scanning function of <a class="reference external" href="https://www.mindspore.cn/devtoolkit/docs/en/master/index.html">MindSpore Dev Toolkit</a> scans the mapping between APIs in PyTorch network and MindSpore APIs. The API scanning function scans the mapping between the APIs in PyTorch network and MindSpore APIs, and opens the “Description” URL for API differences, which gives a detailed analysis of the APIs and helps users to quickly build the network code for MindSpore.</p>
<p><img alt="" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/api_scan.jpg" /></p>
<p>For example, the <code class="docutils literal notranslate"><span class="pre">torch.cat</span></code> interface:</p>
<p>The following API differences can be seen in the “Description” URL (PyTorch and MindSpore API Mapping Table).</p>
<p><img alt="" src="../_images/api_diff.PNG" /></p>
<p>According to the rule, refer to the following PyTorch code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cls_token</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># [B, 197, 768]</span>
</pre></div>
</div>
<p>The MindSpore code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cls_token</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># [B, 197, 768]</span>
</pre></div>
</div>
</section>
<section id="initial-verification-of-network-structure">
<h3>Initial Verification of Network Structure<a class="headerlink" href="#initial-verification-of-network-structure" title="Permalink to this headline"></a></h3>
<p>After the initial network migration is constructed, we can first perform some basic comparisons of the network structure to verify that the migrated network structure is correct. You can use the following two ways to compare the network structure respectively:</p>
<p><strong>Step 1: Obtain PyTorch ViT network structure and weight parameters (pth)</strong></p>
<p>Call the <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/migrator/save_net_and_weight_params.md#">ts.migrator.save_net_and_weight_params</a> interface will save the network object to a file (the same as printing the contents of a model object with print, where model is an nn.Module object) and will save the weight parameters to a pth file as well as to a mapping file (to be used for weight comparison with MindSpore).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">net_pt_vit</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">has_logits</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">ts</span><span class="o">.</span><span class="n">migrator</span><span class="o">.</span><span class="n">save_net_and_weight_params</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt_net_info/&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The following file can be found under the configured path.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>-rw-r--r-- 1 root root      8709 Jul  5 20:36 torch_net_architecture.txt （Network structure information, the same as printing the contents of a model object with python print）
-rw-r--r-- 1 root root      7737 Jul  5 20:36 torch_net_map.json (parameter mapping file for weight comparison with MindSpore)
-rw-r--r-- 1 root root 343261393 Jul  5 20:36 torch_troubleshooter_create.pth (weight parameters)
</pre></div>
</div>
<p><strong>Step 2: Obtain MindSpore ViT network structure and weight parameters (ckpt)</strong></p>
<p>Call the <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/migrator/save_net_and_weight_params.md#">ts.migrator.save_net_and_weight_params</a> interface. You can save the network object to a file (the same as printing the contents of the model object with print, where model is a Cell object), and will save the weight parameters to a ckpt file.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">net_ms_vit</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">has_logits</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ts</span><span class="o">.</span><span class="n">migrator</span><span class="o">.</span><span class="n">save_net_and_weight_params</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/ms_net_info/&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The following file can be found under the configured path.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>-r-------- 1 root root 343217199 Jul  5 20:26 mindspore_troubleshooter_create.ckpt    (weight parameters)
-rw-r--r-- 1 root root     14013 Jul  5 20:26 mindspore_net_architecture.txt  （Network structure information, the same as printing the contents of a model object with python print）
</pre></div>
</div>
<p><img alt="" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/image2.png" /></p>
<p><strong>Step 3: Compare the network infrastructure through net_architecture.txt</strong></p>
<p>Tools such as Beyond Compare can be used to quickly compare the network structure (i.e., mindspore_net_architecture.txt vs. torch_net_architecture.txt), and the following can be used to preliminarily determine that the network structure hierarchies are basically aligned, and that there are a number of natural API as well as parameter differences, for example: Dense and Linear are in the normal range.</p>
<p><img alt="" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/image3.png" /></p>
<p><strong>Step 4: Further compare the network structure by comparing the weight parameters</strong></p>
<p>Using the files we saved in steps 1 and 2, the weight parameter structure comparison of pth and ckpt can be accomplished through TroubleShooter <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/migrator/compare_pth_and_ckpt.md#">ts.migrator.compare_pth_and_ckpt</a> interface, to further verify that the network structure is correct.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># weight_map_path is the parameter mapping file exported in step 1, compare_value=False means it only compares the quantity and shape information, not the parameter value.</span>
<span class="n">ts</span><span class="o">.</span><span class="n">migrator</span><span class="o">.</span><span class="n">compare_pth_and_ckpt</span><span class="p">(</span>
    <span class="n">weight_map_path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt_net_info/torch_net_map.json&quot;</span><span class="p">,</span>
    <span class="n">pt_file_path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt_net_info/torch_troubleshooter_create.pth&quot;</span><span class="p">,</span>
    <span class="n">ms_file_path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/ms_net_info/mindspore_troubleshooter_create.ckpt&quot;</span><span class="p">,</span>
    <span class="n">compare_value</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/image4.png" /></p>
</section>
<section id="network-forward-result-verification">
<h3>Network Forward Result Verification<a class="headerlink" href="#network-forward-result-verification" title="Permalink to this headline"></a></h3>
<p>After the migrated MindSpore network can be executed normally, the network forward result verification can be performed, which is done by comparing the PyTorch and MindSpore network forward results. Two different verification schemes are provided here, one is semi-automatic verification scheme and the other is fully-automatic verification scheme. We will introduce the two schemes applicable scenarios and usage methods respectively.</p>
<section id="three-basic-conditions-for-network-comparison">
<h4>Three Basic Conditions for Network Comparison<a class="headerlink" href="#three-basic-conditions-for-network-comparison" title="Permalink to this headline"></a></h4>
<blockquote>
<div><p>Note: This is only a brief description. For detailed steps see the example of the semi-automatic Verification scheme.</p>
</div></blockquote>
<p>There are three conditions that need to be met before PyTorch and MindSpore network comparison can be performed:</p>
<ol class="arabic">
<li><p>Randomness fixed and identical</p>
<p>You can use <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/widget/fix_random.md#">ts.migrator.fix_random</a> in PyTorch and MindSpore to fix randomness, for example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ts</span><span class="o">.</span><span class="n">widget</span><span class="o">.</span><span class="n">fix_random</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Consistent input data sample</p>
<p>Refer to the following two steps, which can be used to save and load the same data samples (included: both data and labels can be used in this method).</p>
<ul>
<li><p>Step 1: Use <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/save.md#">ts.save</a> to save a particular data sample of the PyTorch network as npy, and <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/save.md#">ts.save</a> will be automatically numbered as <code class="docutils literal notranslate"><span class="pre">0_images.npy</span></code></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ts</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt/npy/images.npy&quot;</span><span class="p">,</span> <span class="n">images</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Step 2: Then use <code class="docutils literal notranslate"><span class="pre">np.load</span></code> to load this data into PyTorch Tenosr and MindSpore Tensor, respectively</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">images</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/mindspore_model/vit/v1/pytorch_org/vision_transformer/0_images.npy&#39;</span><span class="p">))</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/mindspore_model/vit/v1/pytorch_org/vision_transformer/0_images.npy&#39;</span><span class="p">))</span>
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Consistent initialization weight parameters</p>
<p>Generally we will take the weights of the PyTorch network as a benchmark, convert them to MindSpore weights and load them to achieve a uniform initialization of the weight parameters. Refer to the following two steps:</p>
<ul>
<li><p>Step 1: Save PyTorch network weights and conversion mappings for loading in MindSpore.</p>
<p>Use the <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/migrator/save_net_and_weight_params.md#">ts.migrator.save_net_and_weight_params</a> interface to save PyTorch network weights and transformation mappings.
For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ts</span><span class="o">.</span><span class="n">migrator</span><span class="o">.</span><span class="n">save_net_and_weight_params</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt_net_info/&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Step 2: Convert and load weights in the MindSpore network.</p>
<p>Use <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/migrator/convert_weight_and_load.md#">ts.migrator.convert_weight_and_load</a> interface to convert PyTorch weights and load them into MindSpore network. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ts</span><span class="o">.</span><span class="n">migrator</span><span class="o">.</span><span class="n">convert_weight_and_load</span><span class="p">(</span><span class="n">weight_map_path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt_net_info/torch_net_map.json&quot;</span><span class="p">,</span>
<span class="n">pt_file_path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt_net_info/torch_troubleshooter_create.pth&quot;</span><span class="p">,</span><span class="n">net</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ol>
</section>
<section id="semi-automatic-verification-scheme">
<h4>Semi-automatic Verification Scheme<a class="headerlink" href="#semi-automatic-verification-scheme" title="Permalink to this headline"></a></h4>
<p>Based on meeting the three preconditions for comparison, the semi-automatic verification scheme completes the verification of forwrd results by manually specifying the data to be saved and performing batch comparison. The advantage of the semi-automatic scheme is the strong applicability of the scenario, and the disadvantage is that it requires more manual operations.</p>
<p><strong>Step 1: Execute PyTorch network and obtain forward results</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_pt_net</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="c1"># 1) Fix randomness, call ts.widget.fix_random interface to fix randomness in PyTorch</span>
    <span class="n">ts</span><span class="o">.</span><span class="n">widget</span><span class="o">.</span><span class="n">fix_random</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">has_logits</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># 2) Load samples of the same data (samples can be kept in a .npy format with numpy.save while the PyTorch network is executed.)</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/mindspore_model/vit/v1/pytorch_org/vision_transformer/0_images.npy&#39;</span><span class="p">))</span>
    <span class="c1"># 3) Save weights and conversion mapping for loading in MindSpore</span>
    <span class="n">ts</span><span class="o">.</span><span class="n">migrator</span><span class="o">.</span><span class="n">save_net_and_weight_params</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt_net_info/&quot;</span><span class="p">)</span>
    <span class="c1"># 4) Execute the network and save the forward results, and use the ts.save interface to save the network execution results</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
    <span class="n">ts</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt/npy/pred.npy&quot;</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 2: Execute the MindSpore network to obtain forward results</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_ms_net</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="c1"># 1) Fix randomness, same as step 1, call the same interface ts.widget.fix_random(16)</span>
    <span class="n">ts</span><span class="o">.</span><span class="n">widget</span><span class="o">.</span><span class="n">fix_random</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
    <span class="c1"># 2) Load the same data samples</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/mindspore_model/vit/v1/pytorch_org/vision_transformer/0_images.npy&#39;</span><span class="p">))</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">has_logits</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># 3) Load weights output by pt to ensure consistent initialization weight parameters</span>
    <span class="c1"># Call the ts.migrator.convert_weight_and_load interface to convert PyTorch weight parameters to MindSpore weight parameters and load them into the MindSpore network</span>
    <span class="n">ts</span><span class="o">.</span><span class="n">migrator</span><span class="o">.</span><span class="n">convert_weight_and_load</span><span class="p">(</span><span class="n">weight_map_path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt_net_info/torch_net_map.json&quot;</span><span class="p">,</span>
                                        <span class="n">pt_file_path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt_net_info/torch_troubleshooter_create.pth&quot;</span><span class="p">,</span>
                                        <span class="n">net</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
    <span class="c1"># 4) Execute the network and save the forward results</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
    <span class="n">ts</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/ms/npy/pred.npy&quot;</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 3: Make comparisons and view comparison results</strong></p>
<p>Use the <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/migrator/compare_npy_dir.md#">ts.migrator.compare_npy_dir</a> interface for forward result comparison.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 5) Compare the forward output results of PyTorch and MindSpore, and call the ts.migrator.compare_npy_dir interface to complete the comparison of the saved forward results</span>
<span class="n">ts</span><span class="o">.</span><span class="n">migrator</span><span class="o">.</span><span class="n">compare_npy_dir</span><span class="p">(</span><span class="s1">&#39;/mindspore_model/vit/v1/temp_data/pt/npy&#39;</span><span class="p">,</span>
                            <span class="s1">&#39;/mindspore_model/vit/v1/temp_data/ms/npy&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The following comparison results can be seen, the forward network results are all properly aligned by allclose and cosine similarity comparisons, which proves that the results are identical.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>The orig dir: /mnt/sdb2/mindspore_model/vit/v1/temp_data/pt/npy
The target dir: /mnt/sdb2/mindspore_model/vit/v1/temp_data/ms/npy
</pre></div>
</div>
<p><img alt="" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/image6.png" /></p>
</section>
<section id="fully-automatic-verification-scheme">
<h4>Fully-automatic Verification Scheme<a class="headerlink" href="#fully-automatic-verification-scheme" title="Permalink to this headline"></a></h4>
<p>Fully-automatic verification scheme is suitable for verification of inference network or network forward results and other migration scenarios. The difference from semi-automatic verification scheme is that the tool is used to automatically complete a variety of pre-comparison condition alignment, and the user only needs to pass in the network object. Compared to the semi-automatic scheme, it is more simple, basically can be realized with one-click comparison, but some complex scenarios the use of which may be limited. For example: the PyTorch network and the MindSpore network are not convenient to run on the same machine. For scenarios that cannot be supported by the fully-automatic verification scheme, please refer to the section on  semi-automatic verification scheme.</p>
<p><strong>Step 1: Import PyTorch model objects to complete network forward automatic comparison</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">auto_run_ms_net</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="c1"># 1) Import pytoch script path and import pytroch model for creating PyTorch model objects</span>
    <span class="kn">import</span> <span class="nn">sys</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;/mindspore_model/vit/v1/pytorch_org&quot;</span><span class="p">)</span>
    <span class="kn">from</span> <span class="nn">pytorch_org.vision_transformer.vit_model</span> <span class="kn">import</span> <span class="n">vit_base_patch16_224_in21k</span> <span class="k">as</span> <span class="n">create_pt_model</span>
    <span class="c1"># 2) Create MindSpore model object and PyTorch model object, respectively, for passing in the auto-comparison interface</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">has_logits</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">pt_model</span> <span class="o">=</span> <span class="n">create_pt_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">has_logits</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># 3) Create a forward automatic comparison object and perform the comparison</span>
    <span class="n">diff_finder</span> <span class="o">=</span> <span class="n">ts</span><span class="o">.</span><span class="n">migrator</span><span class="o">.</span><span class="n">NetDifferenceFinder</span><span class="p">(</span><span class="n">pt_net</span><span class="o">=</span><span class="n">pt_model</span><span class="p">,</span>
                                                  <span class="n">ms_net</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
    <span class="c1"># auto_inputs parameter to automatically generate data samples according to shape, compare will automatically align weights, fixed randomness.</span>
    <span class="n">diff_finder</span><span class="o">.</span><span class="n">compare</span><span class="p">(</span><span class="n">auto_inputs</span><span class="o">=</span><span class="p">(((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),))</span>
</pre></div>
</div>
<p><strong>Step 2: View comparison results</strong></p>
<p>After the interface is run, it prints some logs of the execution process, and finally prints the comparison results of the network forward output.</p>
<p><img alt="" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/image5.png" /></p>
<blockquote>
<div><p>Note: When the results are inconsistent, the API output of each layer in the network can be exported dichotomously or layer-by-layer via the <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/save.md#">ts.save</a> interface and batch comparison is performed via the <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/migrator/compare_npy_dir.md#">ts.migrator.compare_npy_dir</a> interface to localize to the API where the problem was introduced.</p>
</div></blockquote>
</section>
</section>
<section id="network-loss-result-verification">
<h3>Network Loss Result Verification<a class="headerlink" href="#network-loss-result-verification" title="Permalink to this headline"></a></h3>
<p>The verification scheme for loss, similar to the semi-automatic verification scheme for forward results, is based on satisfying the three preconditions for comparison by manually specifying the loss to be saved and saving them using the ts.save interface, and using <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/migrator/compare_npy_dir.md#">ts.migrator.compare_npy_dir</a> for batch comparison to complete the verification of the loss results. For the specific steps, refer to the semi-automatic verification scheme of the forward results.</p>
</section>
<section id="backward-result-verification-with-comparison-of-gradient,-weight-parameters">
<h3>Backward Result Verification (with Comparison of Gradient, Weight Parameters)<a class="headerlink" href="#backward-result-verification-with-comparison-of-gradient,-weight-parameters" title="Permalink to this headline"></a></h3>
<p>The idea of the comparison verification scheme of the gradient is also similar to that of the semi-automatic verification scheme of the forward result, but the invocation is slightly different. Refer to the following step for operation.</p>
<p><strong>Step 1: Save the output of each stage of PyTorch network training</strong></p>
<p>Similar to the semi-automatic verification scheme for forward results, we can use the <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/save.md#">ts.save</a> interface for saving key data at various stages of training, for example: forward outputs, losses, grads, and weight parameters. Refer to the example below, explaining each key data saving.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_one_step</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="c1"># 1) Fix randomness</span>
    <span class="n">ts</span><span class="o">.</span><span class="n">widget</span><span class="o">.</span><span class="n">fix_random</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
    <span class="c1"># 2) The process of creating a training network</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">has_logits</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">pg</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">pg</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">5E-5</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="c1"># 3) Unify data samples and labels</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/mindspore_model/vit/v1/&#39;</span>
                                  <span class="s1">&#39;pytorch_org/vision_transformer/1_None.npy&#39;</span><span class="p">))</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/mindspore_model/vit/v1/&#39;</span>
                                  <span class="s1">&#39;pytorch_org/vision_transformer/0_None.npy&#39;</span><span class="p">))</span>
    <span class="c1"># 4) Save weights and conversion mappings for loading in MindSpore</span>
    <span class="n">ts</span><span class="o">.</span><span class="n">migrator</span><span class="o">.</span><span class="n">save_net_and_weight_params</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt_net_info/&quot;</span><span class="p">)</span>
    <span class="c1"># 5) Implement the training process</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="c1"># 6) Preserve the gradient</span>
    <span class="c1"># The ts.widget.get_pt_grads interface encapsulates PyTorch method for saving grads, which can be called directly and saved using ts.save.</span>
    <span class="c1"># Because the gradient is a Tensor list, ts.save will save the gradient in multiple files and automatically number them. It is recommended to create a separate directory to save the gradient list</span>
    <span class="n">ts</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt/grads/grads.npy&quot;</span><span class="p">,</span> <span class="n">ts</span><span class="o">.</span><span class="n">widget</span><span class="o">.</span><span class="n">get_pt_grads</span><span class="p">(</span><span class="n">model</span><span class="p">))</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="c1"># 7) Save the weight parameter pth, set the weight_params_filename name, do not use the default value to avoid overwriting the initialized weights</span>
    <span class="n">ts</span><span class="o">.</span><span class="n">migrator</span><span class="o">.</span><span class="n">save_net_and_weight_params</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt_net_info/&quot;</span><span class="p">,</span>
                                           <span class="n">weight_params_filename</span><span class="o">=</span><span class="s1">&#39;result_pt.pth&#39;</span><span class="p">)</span>

</pre></div>
</div>
<p><strong>Step 2: Save the output of each stage of MindSpore network training</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_one_step_ms</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="c1"># 1) Fix randomness</span>
    <span class="n">ts</span><span class="o">.</span><span class="n">widget</span><span class="o">.</span><span class="n">fix_random</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
    <span class="c1"># 2) The process of creating a training network</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">has_logits</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">5E-5</span><span class="p">)</span>
    <span class="n">loss_function</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">forward_fn</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">logits</span>
    <span class="n">grad_fn</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">forward_fn</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># 3) Load weights output by pt to ensure consistent initialization weight parameters</span>
    <span class="c1"># Call the ts.migrator.convert_weight_and_load interface to convert PyTorch weight parameters to MindSpore weight parameters and load them into the MindSpore network</span>
    <span class="n">ts</span><span class="o">.</span><span class="n">migrator</span><span class="o">.</span><span class="n">convert_weight_and_load</span><span class="p">(</span><span class="n">weight_map_path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt_net_info/torch_net_map.json&quot;</span><span class="p">,</span>
                                        <span class="n">pt_file_path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt_net_info/torch_troubleshooter_create.pth&quot;</span><span class="p">,</span>
                                        <span class="n">net</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
    <span class="c1"># 4) Load the same data samples and labels as in PT</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/mindspore_model/vit/v1/pytorch_org/vision_transformer/1_None.npy&#39;</span><span class="p">))</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/mindspore_model/vit/v1/pytorch_org/vision_transformer/0_None.npy&#39;</span><span class="p">))</span>
    <span class="c1"># 5) Implement the training process</span>
    <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">pred</span><span class="p">),</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">grad_fn</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
    <span class="c1"># 6) Save the gradient</span>
    <span class="n">ts</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/ms/grads/grads.npy&quot;</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
    <span class="c1"># 7) Save the weight parameter pth</span>
    <span class="n">mindspore</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/ms/ms_result.ckpt&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 3: Compare the gradients</strong></p>
<p>Use the <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/migrator/compare_grads_dir.md#">ts.migrator.compare_grads_dir</a> interface for gradient comparison.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ts</span><span class="o">.</span><span class="n">migrator</span><span class="o">.</span><span class="n">compare_grads_dir</span><span class="p">(</span><span class="s1">&#39;/mindspore_model/vit/v1/temp_data/pt/grads&#39;</span><span class="p">,</span>
                              <span class="s1">&#39;/mindspore_model/vit/v1/temp_data/ms/grads&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>The orig dir: /mindspore_model/vit/v1/temp_data/pt/grads
The target dir: /mindspore_model/vit/v1/temp_data/ms/grads
</pre></div>
</div>
<p><img alt="" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/image8.png" /></p>
<p><strong>Step 4: Compare weighting parameters</strong></p>
<p>Use the <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/migrator/compare_pth_and_ckpt.md#">ts.migrator.compare_pth_and_ckpt</a> interface for weight parameter comparison.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ts</span><span class="o">.</span><span class="n">migrator</span><span class="o">.</span><span class="n">compare_pth_and_ckpt</span><span class="p">(</span><span class="n">weight_map_path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt_net_info/torch_net_map.json&quot;</span><span class="p">,</span>
                                 <span class="n">pt_file_path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt_net_info/result_pt.pth&quot;</span><span class="p">,</span>
                                 <span class="n">ms_file_path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/ms/ms_result.ckpt&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Obtain the comparison result to the weight parameter shape.</p>
<p><img alt="" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/image9.png" /></p>
<p>Obtain the comparison result to the weight parameter value.</p>
<p><img alt="" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/image10.png" /></p>
<blockquote>
<div><p>Note: If the comparison results are inconsistent, you can go backward to see if the gradients are consistent. If the gradients are consistent, you can check if the optimizer is used correctly, and you can refer to the section on Network Layer-by-Layer Difference Check for a layer-by-layer problem delimitation and exclusion.</p>
</div></blockquote>
</section>
<section id="others">
<h3>Others<a class="headerlink" href="#others" title="Permalink to this headline"></a></h3>
<section id="network-layer-by-layer-difference-check">
<h4>Network Layer-by-Layer Difference Check<a class="headerlink" href="#network-layer-by-layer-difference-check" title="Permalink to this headline"></a></h4>
<p>When we need to locate the cause of the problem when comparing the network forward results or loss inconsistencies, we can take a dichotomous or layer-by-layer approach to save the API output and perform a data comparison to identify the point where the differences are introduced. This comparison also needs to fulfill the three basic conditions of comparison.</p>
<p><strong>Step 1: Save the API output of PyTorch network part</strong></p>
<p>In the network, use <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/save.md#">ts.save</a> to save the output of the API for checking network differences introduction points.</p>
<blockquote>
<div><p>Note: <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/save.md#">ts.save</a> supports saving Tensor (including mindspore.Tensor and torch.tensor), and list/tuple/dict composed by Tensor. When it is list/tuple, the number will be added sequentially, while when it is dict, the key will be added in the filename. Please refer to <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/save.md#">troubleshooter.save</a> for details.</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Mlp</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    MLP as used in Vision Transformer, MLP-Mixer and related networks</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">act_layer</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="mf">0.</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">out_features</span> <span class="o">=</span> <span class="n">out_features</span> <span class="ow">or</span> <span class="n">in_features</span>
        <span class="n">hidden_features</span> <span class="o">=</span> <span class="n">hidden_features</span> <span class="ow">or</span> <span class="n">in_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">act_layer</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">drop</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Save self.fc1, that is output of nn.Linear</span>
        <span class="n">ts</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;/mindspore_model/vit/v1/temp_data/pt/npy/fc1.npy&#39;</span><span class="p">,</span>  <span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Save self.fc2, that is output of nn.Linear</span>
        <span class="n">ts</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;/mindspore_model/vit/v1/temp_data/pt/npy/fc2.npy&#39;</span><span class="p">,</span>  <span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<p><strong>Step 1: Save the API output of MindSpore network part</strong></p>
<p>In the network, use <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/save.md#">ts.save</a> to save the output of the API for checking network differences introduction points.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Mlp</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">act_layer</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="mf">0.</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">out_features</span> <span class="o">=</span> <span class="n">out_features</span> <span class="ow">or</span> <span class="n">in_features</span>
        <span class="n">hidden_features</span> <span class="o">=</span> <span class="n">hidden_features</span> <span class="ow">or</span> <span class="n">in_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">)</span>
        <span class="c1">#self.act = act_layer(approximate=False)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">(</span><span class="n">approximate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">drop</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Save self.fc1, that is output of nn.Dense</span>
        <span class="n">ts</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;/mindspore_model/vit/v1/temp_data/ms/npy/fc1.npy&#39;</span><span class="p">,</span>  <span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Save self.fc2, that is output of nn.Dense</span>
        <span class="n">ts</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;/mindspore_model/vit/v1/temp_data/ms/npy/fc2.npy&#39;</span><span class="p">,</span>  <span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<p><strong>Step 3: Compare API outputs to find differences</strong></p>
<p>Use the <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/migrator/compare_npy_dir.md#">ts.migrator.compare_npy_dir</a> interface to compare the data saved in each layer, and the results can be used to determine where differences have been introduced for problem localization.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ts</span><span class="o">.</span><span class="n">migrator</span><span class="o">.</span><span class="n">compare_npy_dir</span><span class="p">(</span><span class="s1">&#39;/mindspore_model/vit/v1/temp_data/pt/npy&#39;</span><span class="p">,</span>
                            <span class="s1">&#39;/mindspore_model/vit/v1/temp_data/ms/npy&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/image7.png" /></p>
</section>
<section id="network-weight-migration">
<h4>Network Weight Migration<a class="headerlink" href="#network-weight-migration" title="Permalink to this headline"></a></h4>
<p>In scenarios such as migrating inference networks or fine-tuning network training, it is often necessary to migrate weights from PyTroch to MindSpore. At this time, you can use TroubleShooter weight migration tool, first call <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/migrator/get_weight_map.md#">ts.migrator.get_weight_map</a> to obtain the weight mapping file, then call <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/api/migrator/convert_weight.md#">ts.migrator.convert_weight</a> to complete the weight auto-migration. The following is the basic sample. For the complex scenarios that require customization, refer to <a class="reference external" href="https://gitee.com/mindspore/toolkits/blob/master/troubleshooter/docs/migrator.md#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF1pth%E5%88%B0ckpt%E6%9D%83%E9%87%8D%E8%87%AA%E5%8A%A8%E8%BD%AC%E6%8D%A2">TroubleShooter pth to ckpt weights auto conversion</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">troubleshooter</span> <span class="k">as</span> <span class="nn">ts</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">has_logits</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="c1"># 1) Obtain the weight mapping file</span>
<span class="n">ts</span><span class="o">.</span><span class="n">migrator</span><span class="o">.</span><span class="n">get_weight_map</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">weight_map_save_path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt_net_info/torch_net_map.json&quot;</span><span class="p">)</span>

<span class="c1"># 2) Weight conversion</span>
<span class="n">ts</span><span class="o">.</span><span class="n">migrator</span><span class="o">.</span><span class="n">convert_weight</span><span class="p">(</span><span class="n">weight_map_path</span><span class="o">=</span><span class="s2">&quot;/mindspore_model/vit/v1/temp_data/pt_net_info/torch_net_map.json&quot;</span><span class="p">,</span>
                           <span class="n">pt_file_path</span><span class="o">=</span><span class="s2">&quot;/torch_model/vit/v1/torch_net.pth&quot;</span><span class="p">,</span>
                           <span class="n">ms_file_save_path</span><span class="o">=</span><span class="s1">&#39;/mindspore_model/vit/v1/ms_net.ckpt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="sample_code.html" class="btn btn-neutral float-left" title="Network Migration Debugging Example" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="faq.html" class="btn btn-neutral float-right" title="FAQs" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>