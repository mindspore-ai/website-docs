<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Network Migration Debugging Example &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script src="../_static/js/theme.js"></script>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/training.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Application Practice Guide for Network Migration Tool" href="migrator_with_tools.html" />
    <link rel="prev" title="Debugging and Tuning" href="debug_and_tune.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/programming_paradigm.html">Functional and Object-Oriented Fusion Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/all_scenarios.html">Full-scenarios Unified Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/distributed_training_design.html">Native Distributed Parallel Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/official_models.html">Official Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.experimental.html">mindspore.experimental</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="enveriment_preparation.html">Environment Preparation and Information Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="typical_api_comparision.html">Differences between PyTorch and MindSpore</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_development/model_development.html">Constructing MindSpore Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="migrator_with_tools.html">Application Practice Guide for Network Migration Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Syntax Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax_support.html">Static Graph Syntax Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/operators.html">Static Graph Syntax - Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/statements.html">Static Graph Syntax - Python Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/python_builtin_functions.html">Static Graph Syntax - Python Built-in Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/index_support.html">Tensor Index Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/env_var_list.html">Environment Variables</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Network Migration Debugging Example</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/migration_guide/sample_code.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="network-migration-debugging-example">
<h1>Network Migration Debugging Example<a class="headerlink" href="#network-migration-debugging-example" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/mindspore/source_en/migration_guide/sample_code.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png" /></a></p>
<p>The following uses the classic network ResNet-50 as an example to describe the network migration method in detail based on the code.</p>
<section id="model-analysis-and-preparation">
<h2>Model Analysis and Preparation<a class="headerlink" href="#model-analysis-and-preparation" title="Permalink to this headline"></a></h2>
<p>Assume that the MindSpore operating environment has been configured according to <a class="reference external" href="https://www.mindspore.cn/docs/en/master/migration_guide/enveriment_preparation.html">Environment Preparation and Information Acquisition</a>. Assume that ResNet-50 has not been implemented in the models repository.</p>
<p>First, analyze the algorithm and network structure.</p>
<p>The Residual Neural Network (ResNet) was proposed by Kaiming He et al. from Microsoft Research Institute. They used residual units to successfully train a 152-layer neural network, and thus became the winner of ILSVRC 2015. A conventional convolutional network or fully-connected network has more or less information losses, and further causes gradient disappearance or explosion. As a result, deep network training fails. The ResNet can solve these problems to some extent. By passing the input information to the output, the information integrity is protected. The network only needs to learn the differences between the input and output, simplifying the learning objective and difficulty. Its structure can accelerate training of a neural network and greatly improve the accuracy of the network model.</p>
<p><a class="reference external" href="https://arxiv.org/pdf/1512.03385.pdf">Paper</a>: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.”Deep Residual Learning for Image Recognition”</p>
<p>The <a class="reference external" href="https://gitee.com/mindspore/docs/tree/master/docs/mindspore/source_zh_cn/migration_guide/code/resnet_convert/resnet_pytorch">sample code of PyTorch ResNet-50 CIFAR-10</a> contains the PyTorch ResNet implementation, CIFAR-10 data processing, network training, and inference processes.</p>
<section id="checklist">
<h3>Checklist<a class="headerlink" href="#checklist" title="Permalink to this headline"></a></h3>
<p>When reading the paper and referring to the implementation, analyze and fill in the following checklist:</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Trick</p></th>
<th class="head"><p>Record</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Data augmentation</p></td>
<td><p>RandomCrop, RandomHorizontalFlip, Resize, Normalize</p></td>
</tr>
<tr class="row-odd"><td><p>Learning rate attenuation policy</p></td>
<td><p>Fixed learning rate = 0.001</p></td>
</tr>
<tr class="row-even"><td><p>Optimization parameters</p></td>
<td><p>Adam optimizer, weight_decay = 1e-5</p></td>
</tr>
<tr class="row-odd"><td><p>Training parameters</p></td>
<td><p>batch_size = 32, epochs = 90</p></td>
</tr>
<tr class="row-even"><td><p>Network structure optimization</p></td>
<td><p>Bottleneck</p></td>
</tr>
<tr class="row-odd"><td><p>Training process optimization</p></td>
<td><p>None</p></td>
</tr>
</tbody>
</table>
</section>
<section id="reproducing-reference-implementation">
<h3>Reproducing Reference Implementation<a class="headerlink" href="#reproducing-reference-implementation" title="Permalink to this headline"></a></h3>
<p>Download the PyTorch code and CIFAR-10 dataset to train the network.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Train Epoch: 89 [0/1563 (0%)]    Loss: 0.010917
Train Epoch: 89 [100/1563 (6%)]    Loss: 0.013386
Train Epoch: 89 [200/1563 (13%)]    Loss: 0.078772
Train Epoch: 89 [300/1563 (19%)]    Loss: 0.031228
Train Epoch: 89 [400/1563 (26%)]    Loss: 0.073462
Train Epoch: 89 [500/1563 (32%)]    Loss: 0.098645
Train Epoch: 89 [600/1563 (38%)]    Loss: 0.112967
Train Epoch: 89 [700/1563 (45%)]    Loss: 0.137923
Train Epoch: 89 [800/1563 (51%)]    Loss: 0.143274
Train Epoch: 89 [900/1563 (58%)]    Loss: 0.088426
Train Epoch: 89 [1000/1563 (64%)]    Loss: 0.071185
Train Epoch: 89 [1100/1563 (70%)]    Loss: 0.094342
Train Epoch: 89 [1200/1563 (77%)]    Loss: 0.126669
Train Epoch: 89 [1300/1563 (83%)]    Loss: 0.245604
Train Epoch: 89 [1400/1563 (90%)]    Loss: 0.050761
Train Epoch: 89 [1500/1563 (96%)]    Loss: 0.080932

Test set: Average loss: -9.7052, Accuracy: 91%

Finished Training
</pre></div>
</div>
<p>You can download training logs and saved parameter files from <a class="reference external" href="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/models/resnet_pytorch_res.zip">resnet_pytorch_res</a>.</p>
</section>
<section id="analyzing-api/feature-missing">
<h3>Analyzing API/Feature Missing<a class="headerlink" href="#analyzing-api/feature-missing" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>API analysis</p></li>
</ul>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>PyTorch API</p></th>
<th class="head"><p>MindSpore API</p></th>
<th class="head"><p>Different or Not</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.Conv2D</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Conv2d</span></code></p></td>
<td><p>Yes. <a class="reference external" href="https://www.mindspore.cn/docs/en/master/note/api_mapping/pytorch_diff/Conv2d.html">Difference</a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">nn.BatchNorm2D</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.BatchNom2d</span></code></p></td>
<td><p>Yes. <a class="reference external" href="https://www.mindspore.cn/docs/en/master/note/api_mapping/pytorch_diff/BatchNorm2d.html">Difference</a></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.ReLU</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.ReLU</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">nn.MaxPool2D</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.MaxPool2d</span></code></p></td>
<td><p>Yes. <a class="reference external" href="https://www.mindspore.cn/docs/en/master/note/api_mapping/pytorch_diff/MaxPool2d.html">Difference</a></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.AdaptiveAvgPool2D</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.AdaptiveAvgPool2D</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Dense</span></code></p></td>
<td><p>Yes. <a class="reference external" href="https://www.mindspore.cn/docs/en/master/note/api_mapping/pytorch_diff/Dense.html">Difference</a></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">torch.flatten</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Flatten</span></code></p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
<p>By checking <a class="reference external" href="https://www.mindspore.cn/docs/en/master/note/api_mapping/pytorch_api_mapping.html">PyTorch API Mapping</a>, we find that four APIs are different.</p>
<ul class="simple">
<li><p>Function analysis</p></li>
</ul>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>PyTorch Function</p></th>
<th class="head"><p>MindSpore Function</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.init.kaiming_normal_</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">initializer(init='HeNormal')</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">nn.init.constant_</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">initializer(init='Constant')</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.SequentialCell</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Cell</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.distibuted</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">set_auto_parallel_context</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">torch.optim.SGD</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.optim.SGD</span></code> or <code class="docutils literal notranslate"><span class="pre">nn.optim.Momentum</span></code></p></td>
</tr>
</tbody>
</table>
<p>(The interface design of MindSpore is different from that of PyTorch. Therefore, only the comparison of key functions is listed here.)</p>
<p>After API and function analysis, we find that there are no missing APIs and functions on MindSpore compared with PyTorch.</p>
</section>
</section>
<section id="mindspore-model-implementation">
<h2>MindSpore Model Implementation<a class="headerlink" href="#mindspore-model-implementation" title="Permalink to this headline"></a></h2>
<section id="datasets">
<h3>Datasets<a class="headerlink" href="#datasets" title="Permalink to this headline"></a></h3>
<p>The CIFAR-10 dataset of PyTorch is processed as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">trans</span>
<span class="kn">import</span> <span class="nn">torchvision</span>

<span class="n">train_transform</span> <span class="o">=</span> <span class="n">trans</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">trans</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
    <span class="n">trans</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">trans</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
    <span class="n">trans</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">trans</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.4914</span><span class="p">,</span> <span class="mf">0.4822</span><span class="p">,</span> <span class="mf">0.4465</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2023</span><span class="p">,</span> <span class="mf">0.1994</span><span class="p">,</span> <span class="mf">0.2010</span><span class="p">]),</span>
<span class="p">])</span>
<span class="n">test_transform</span> <span class="o">=</span> <span class="n">trans</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">trans</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
    <span class="n">trans</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">trans</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">trans</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.4914</span><span class="p">,</span> <span class="mf">0.4822</span><span class="p">,</span> <span class="mf">0.4465</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2023</span><span class="p">,</span> <span class="mf">0.1994</span><span class="p">,</span> <span class="mf">0.2010</span><span class="p">]),</span>
<span class="p">])</span>
<span class="n">train_set</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">train_transform</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_set</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">test_transform</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>If the CIFAR-10 dataset does not exist on the local host, you can add <code class="docutils literal notranslate"><span class="pre">download=True</span></code> when using <code class="docutils literal notranslate"><span class="pre">torchvision.datasets.CIFAR10</span></code> to automatically download the dataset.</p>
<p>The CIFAR-10 dataset directory is organized as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─dataset_path
    ├─cifar-10-batches-bin      # train dataset
        ├─ data_batch_1.bin
        ├─ data_batch_2.bin
        ├─ data_batch_3.bin
        ├─ data_batch_4.bin
        ├─ data_batch_5.bin
    └─cifar-10-verify-bin       # evaluate dataset
        ├─ test_batch.bin
</pre></div>
</div>
<p>This operation is implemented on MindSpore as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset</span> <span class="kn">import</span> <span class="n">vision</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset.transforms.transforms</span> <span class="kn">import</span> <span class="n">TypeCast</span>

<span class="k">def</span> <span class="nf">create_cifar_dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">do_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="n">rank_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">rank_id</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">do_train</span><span class="p">,</span>
                                <span class="n">num_shards</span><span class="o">=</span><span class="n">rank_size</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="n">rank_id</span><span class="p">)</span>

    <span class="c1"># define map operations</span>
    <span class="n">trans</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">do_train</span><span class="p">:</span>
        <span class="n">trans</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="n">vision</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span>
            <span class="n">vision</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="n">trans</span> <span class="o">+=</span> <span class="p">[</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Rescale</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.4914</span><span class="p">,</span> <span class="mf">0.4822</span><span class="p">,</span> <span class="mf">0.4465</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2023</span><span class="p">,</span> <span class="mf">0.1994</span><span class="p">,</span> <span class="mf">0.2010</span><span class="p">]),</span>
        <span class="n">vision</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
    <span class="p">]</span>

    <span class="n">type_cast_op</span> <span class="o">=</span> <span class="n">TypeCast</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="n">data_set</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">type_cast_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">)</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">trans</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">)</span>

    <span class="c1"># apply batch operations</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="n">do_train</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data_set</span>
</pre></div>
</div>
</section>
<section id="network-model-implementation">
<h3>Network Model Implementation<a class="headerlink" href="#network-model-implementation" title="Permalink to this headline"></a></h3>
<p>By referring to <a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/mindspore/source_zh_cn/migration_guide/code/resnet_convert/resnet_pytorch/resnet.py">PyTorch ResNet</a>, we have implemented <a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/mindspore/source_zh_cn/migration_guide/code/resnet_convert/resnet_ms/src/resnet.py">MindSpore ResNet</a>. The comparison tool shows that the implementation is different in the following aspects:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Conv2d PyTorch</span>
<span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
    <span class="n">in_planes</span><span class="p">,</span>
    <span class="n">out_planes</span><span class="p">,</span>
    <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
    <span class="n">padding</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
    <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span>
    <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1">##########################################</span>

<span class="c1"># Conv2d MindSpore</span>
<span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
    <span class="n">in_planes</span><span class="p">,</span>
    <span class="n">out_planes</span><span class="p">,</span>
    <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;pad&quot;</span><span class="p">,</span>
    <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
    <span class="n">padding</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
    <span class="n">group</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span>
    <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># PyTorch</span>
<span class="n">nn</span><span class="o">.</span><span class="n">Module</span>
<span class="c1">############################################</span>
<span class="c1"># MindSpore</span>
<span class="n">nn</span><span class="o">.</span><span class="n">Cell</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># PyTorch</span>
<span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1">############################################</span>
<span class="c1"># MindSpore</span>
<span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># PyTorch graph construction</span>
<span class="n">forward</span>
<span class="c1">############################################</span>
<span class="c1"># MindSpore graph construction</span>
<span class="n">construct</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># PyTorch MaxPool2d with padding</span>
<span class="n">maxpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1">############################################</span>
<span class="c1"># MindSpore MaxPool2d with padding</span>
<span class="n">maxpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span>
              <span class="n">nn</span><span class="o">.</span><span class="n">Pad</span><span class="p">(</span><span class="n">paddings</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;CONSTANT&quot;</span><span class="p">),</span>
              <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)])</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># PyTorch AdaptiveAvgPool2d</span>
<span class="n">avgpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="c1">############################################</span>
<span class="c1"># When PyTorch AdaptiveAvgPool2d output shape is set to 1, MindSpore ReduceMean functions the same with higher speed.</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">(</span><span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># PyTorch full connection</span>
<span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="c1">############################################</span>
<span class="c1"># MindSpore full connection</span>
<span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># PyTorch Sequential</span>
<span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span>
<span class="c1">############################################</span>
<span class="c1"># MindSpore SequentialCell</span>
<span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># PyTorch initialization</span>
<span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;fan_out&quot;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">)):</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># Zero-initialize the last BN in each residual branch,</span>
<span class="c1"># so that the residual branch starts with zeros, and each residual block behaves like an identity.</span>
<span class="c1"># This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677</span>
<span class="k">if</span> <span class="n">zero_init_residual</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">Bottleneck</span><span class="p">)</span> <span class="ow">and</span> <span class="n">m</span><span class="o">.</span><span class="n">bn3</span><span class="o">.</span><span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bn3</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># type: ignore[arg-type]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">BasicBlock</span><span class="p">)</span> <span class="ow">and</span> <span class="n">m</span><span class="o">.</span><span class="n">bn2</span><span class="o">.</span><span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bn2</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># type: ignore[arg-type]</span>

<span class="c1">############################################</span>

<span class="c1"># MindSpore initialization</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">cell</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span>
            <span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">HeNormal</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fan_out&#39;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
            <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">)):</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;ones&quot;</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;zeros&quot;</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">)):</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span>
            <span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">HeUniform</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)),</span>
            <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;zeros&quot;</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

<span class="c1"># Zero-initialize the last BN in each residual branch,</span>
<span class="c1"># so that the residual branch starts with zeros, and each residual block behaves like an identity.</span>
<span class="c1"># This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677</span>
<span class="k">if</span> <span class="n">zero_init_residual</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">cell</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">Bottleneck</span><span class="p">)</span> <span class="ow">and</span> <span class="n">cell</span><span class="o">.</span><span class="n">bn3</span><span class="o">.</span><span class="n">gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cell</span><span class="o">.</span><span class="n">bn3</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="s2">&quot;zeros&quot;</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">bn3</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">bn3</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">BasicBlock</span><span class="p">)</span> <span class="ow">and</span> <span class="n">cell</span><span class="o">.</span><span class="n">bn2</span><span class="o">.</span><span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cell</span><span class="o">.</span><span class="n">bn2</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="s2">&quot;zeros&quot;</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">bn2</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">bn2</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="loss-function">
<h3>Loss Function<a class="headerlink" href="#loss-function" title="Permalink to this headline"></a></h3>
<p>PyTorch:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</pre></div>
</div>
<p>MindSpore:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="learning-rate-and-optimizer">
<h3>Learning Rate and Optimizer<a class="headerlink" href="#learning-rate-and-optimizer" title="Permalink to this headline"></a></h3>
<p>PyTorch:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</pre></div>
</div>
<p>MindSpore:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">resnet</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="model-validation">
<h2>Model Validation<a class="headerlink" href="#model-validation" title="Permalink to this headline"></a></h2>
<p>The trained PyTorch parameters are obtained in <a class="reference internal" href="#reproducing-reference-implementation"><span class="std std-doc">Reproducing Reference Implementation</span></a>. How do I convert the parameter file into a checkpoint file that can be used by MindSpore?</p>
<p>The following steps are required:</p>
<ol class="arabic simple">
<li><p>Print the names and shapes of all parameters in the PyTorch parameter file and the names and shapes of all parameters in the MindSpore cell to which parameters need to be loaded.</p></li>
<li><p>Compare the parameter name and shape to construct the parameter mapping.</p></li>
<li><p>Create a parameter list based on the parameter mapping (PyTorch parameters -&gt; numpy -&gt; MindSpore parameters) and save the parameter list as a checkpoint.</p></li>
<li><p>Unit test: Load PyTorch parameters and MindSpore parameters, construct random input, and compare the output.</p></li>
</ol>
<section id="printing-parameters">
<h3>Printing Parameters<a class="headerlink" href="#printing-parameters" title="Permalink to this headline"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="c1"># Print the parameter names and shapes of all parameters in the PyTorch parameter file and return the parameter dictionary.</span>
<span class="k">def</span> <span class="nf">pytorch_params</span><span class="p">(</span><span class="n">pth_file</span><span class="p">):</span>
    <span class="n">par_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">pth_file</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
    <span class="n">pt_params</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">par_dict</span><span class="p">:</span>
        <span class="n">parameter</span> <span class="o">=</span> <span class="n">par_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">parameter</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">pt_params</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">parameter</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">pt_params</span>

<span class="c1"># Print the names and shapes of all parameters in the MindSpore cell and return the parameter dictionary.</span>
<span class="k">def</span> <span class="nf">mindspore_params</span><span class="p">(</span><span class="n">network</span><span class="p">):</span>
    <span class="n">ms_params</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">():</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">ms_params</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">return</span> <span class="n">ms_params</span>
</pre></div>
</div>
<p>Run the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">resnet_ms.src.resnet</span> <span class="kn">import</span> <span class="n">resnet50</span> <span class="k">as</span> <span class="n">ms_resnet50</span>
<span class="n">pth_path</span> <span class="o">=</span> <span class="s2">&quot;resnet.pth&quot;</span>
<span class="n">pt_param</span> <span class="o">=</span> <span class="n">pytorch_params</span><span class="p">(</span><span class="n">pth_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span>
<span class="n">ms_param</span> <span class="o">=</span> <span class="n">mindspore_params</span><span class="p">(</span><span class="n">ms_resnet50</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
<p>You can obtain the following result:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>conv1.weight (64, 3, 7, 7)
bn1.weight (64,)
bn1.bias (64,)
bn1.running_mean (64,)
bn1.running_var (64,)
bn1.num_batches_tracked ()
layer1.0.conv1.weight (64, 64, 1, 1)
......
===========================================
conv1.weight (64, 3, 7, 7)
bn1.moving_mean (64,)
bn1.moving_variance (64,)
bn1.gamma (64,)
bn1.beta (64,)
layer1.0.conv1.weight (64, 64, 1, 1)
......
</pre></div>
</div>
</section>
<section id="parameter-mapping-and-checkpoint-saving">
<h3>Parameter Mapping and Checkpoint Saving<a class="headerlink" href="#parameter-mapping-and-checkpoint-saving" title="Permalink to this headline"></a></h3>
<p>Except the BatchNorm parameter, the names and shapes of other parameters are correct. In this case, you can write a simple Python script for parameter mapping.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="k">def</span> <span class="nf">param_convert</span><span class="p">(</span><span class="n">ms_params</span><span class="p">,</span> <span class="n">pt_params</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">):</span>
    <span class="c1"># Parameter name mapping dictionary</span>
    <span class="n">bn_ms2pt</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="s2">&quot;weight&quot;</span><span class="p">,</span>
                <span class="s2">&quot;beta&quot;</span><span class="p">:</span> <span class="s2">&quot;bias&quot;</span><span class="p">,</span>
                <span class="s2">&quot;moving_mean&quot;</span><span class="p">:</span> <span class="s2">&quot;running_mean&quot;</span><span class="p">,</span>
                <span class="s2">&quot;moving_variance&quot;</span><span class="p">:</span> <span class="s2">&quot;running_var&quot;</span><span class="p">}</span>
    <span class="n">new_params_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">ms_param</span> <span class="ow">in</span> <span class="n">ms_params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="c1"># In the parameter list, only the parameters that contain bn and downsample.1 are the parameters of the BatchNorm operator.</span>
        <span class="k">if</span> <span class="s2">&quot;bn&quot;</span> <span class="ow">in</span> <span class="n">ms_param</span> <span class="ow">or</span> <span class="s2">&quot;downsample.1&quot;</span> <span class="ow">in</span> <span class="n">ms_param</span><span class="p">:</span>
            <span class="n">ms_param_item</span> <span class="o">=</span> <span class="n">ms_param</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
            <span class="n">pt_param_item</span> <span class="o">=</span> <span class="n">ms_param_item</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">bn_ms2pt</span><span class="p">[</span><span class="n">ms_param_item</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]]</span>
            <span class="n">pt_param</span> <span class="o">=</span> <span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pt_param_item</span><span class="p">)</span>
            <span class="c1"># If the corresponding parameter is found and the shape is the same, add the parameter to the parameter list.</span>
            <span class="k">if</span> <span class="n">pt_param</span> <span class="ow">in</span> <span class="n">pt_params</span> <span class="ow">and</span> <span class="n">pt_params</span><span class="p">[</span><span class="n">pt_param</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">ms_params</span><span class="p">[</span><span class="n">ms_param</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="n">ms_value</span> <span class="o">=</span> <span class="n">pt_params</span><span class="p">[</span><span class="n">pt_param</span><span class="p">]</span>
                <span class="n">new_params_list</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">ms_param</span><span class="p">,</span> <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">ms_value</span><span class="p">)})</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">ms_param</span><span class="p">,</span> <span class="s2">&quot;not match in pt_params&quot;</span><span class="p">)</span>
        <span class="c1"># Other parameters</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If the corresponding parameter is found and the shape is the same, add the parameter to the parameter list.</span>
            <span class="k">if</span> <span class="n">ms_param</span> <span class="ow">in</span> <span class="n">pt_params</span> <span class="ow">and</span> <span class="n">pt_params</span><span class="p">[</span><span class="n">ms_param</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">ms_params</span><span class="p">[</span><span class="n">ms_param</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="n">ms_value</span> <span class="o">=</span> <span class="n">pt_params</span><span class="p">[</span><span class="n">ms_param</span><span class="p">]</span>
                <span class="n">new_params_list</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">ms_param</span><span class="p">,</span> <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">ms_value</span><span class="p">)})</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">ms_param</span><span class="p">,</span> <span class="s2">&quot;not match in pt_params&quot;</span><span class="p">)</span>
    <span class="c1"># Save as MindSpore checkpoint.</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">new_params_list</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">)</span>

<span class="n">ckpt_path</span> <span class="o">=</span> <span class="s2">&quot;resnet50.ckpt&quot;</span>
<span class="n">param_convert</span><span class="p">(</span><span class="n">ms_params</span><span class="p">,</span> <span class="n">pt_params</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">)</span>
</pre></div>
</div>
<p>After the execution is complete, you can find the generated checkpoint file in <code class="docutils literal notranslate"><span class="pre">ckpt_path</span></code>.</p>
<p>If the parameter mapping is complex and it is difficult to find the mapping based on the parameter name, you can write a parameter mapping dictionary, for example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">param</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;bn1.bias&#39;</span><span class="p">:</span> <span class="s1">&#39;bn1.beta&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bn1.weight&#39;</span><span class="p">:</span> <span class="s1">&#39;bn1.gamma&#39;</span><span class="p">,</span>
    <span class="s1">&#39;IN.weight&#39;</span><span class="p">:</span> <span class="s1">&#39;IN.gamma&#39;</span><span class="p">,</span>
    <span class="s1">&#39;IN.bias&#39;</span><span class="p">:</span> <span class="s1">&#39;IN.beta&#39;</span><span class="p">,</span>
    <span class="s1">&#39;BN.bias&#39;</span><span class="p">:</span> <span class="s1">&#39;BN.beta&#39;</span><span class="p">,</span>
    <span class="s1">&#39;in.weight&#39;</span><span class="p">:</span> <span class="s1">&#39;in.gamma&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bn.weight&#39;</span><span class="p">:</span> <span class="s1">&#39;bn.gamma&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bn.bias&#39;</span><span class="p">:</span> <span class="s1">&#39;bn.beta&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bn2.weight&#39;</span><span class="p">:</span> <span class="s1">&#39;bn2.gamma&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bn2.bias&#39;</span><span class="p">:</span> <span class="s1">&#39;bn2.beta&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bn3.bias&#39;</span><span class="p">:</span> <span class="s1">&#39;bn3.beta&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bn3.weight&#39;</span><span class="p">:</span> <span class="s1">&#39;bn3.gamma&#39;</span><span class="p">,</span>
    <span class="s1">&#39;BN.running_mean&#39;</span><span class="p">:</span> <span class="s1">&#39;BN.moving_mean&#39;</span><span class="p">,</span>
    <span class="s1">&#39;BN.running_var&#39;</span><span class="p">:</span> <span class="s1">&#39;BN.moving_variance&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bn.running_mean&#39;</span><span class="p">:</span> <span class="s1">&#39;bn.moving_mean&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bn.running_var&#39;</span><span class="p">:</span> <span class="s1">&#39;bn.moving_variance&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bn1.running_mean&#39;</span><span class="p">:</span> <span class="s1">&#39;bn1.moving_mean&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bn1.running_var&#39;</span><span class="p">:</span> <span class="s1">&#39;bn1.moving_variance&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bn2.running_mean&#39;</span><span class="p">:</span> <span class="s1">&#39;bn2.moving_mean&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bn2.running_var&#39;</span><span class="p">:</span> <span class="s1">&#39;bn2.moving_variance&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bn3.running_mean&#39;</span><span class="p">:</span> <span class="s1">&#39;bn3.moving_mean&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bn3.running_var&#39;</span><span class="p">:</span> <span class="s1">&#39;bn3.moving_variance&#39;</span><span class="p">,</span>
    <span class="s1">&#39;downsample.1.running_mean&#39;</span><span class="p">:</span> <span class="s1">&#39;downsample.1.moving_mean&#39;</span><span class="p">,</span>
    <span class="s1">&#39;downsample.1.running_var&#39;</span><span class="p">:</span> <span class="s1">&#39;downsample.1.moving_variance&#39;</span><span class="p">,</span>
    <span class="s1">&#39;downsample.0.weight&#39;</span><span class="p">:</span> <span class="s1">&#39;downsample.1.weight&#39;</span><span class="p">,</span>
    <span class="s1">&#39;downsample.1.bias&#39;</span><span class="p">:</span> <span class="s1">&#39;downsample.1.beta&#39;</span><span class="p">,</span>
    <span class="s1">&#39;downsample.1.weight&#39;</span><span class="p">:</span> <span class="s1">&#39;downsample.1.gamma&#39;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Then, you can obtain the parameter file based on the <code class="docutils literal notranslate"><span class="pre">param_convert</span></code> process. For the case where the network model is TensorFlow, please refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/master/migration_guide/tensorflow2mindspore.html">File Method for Converting TensorFlow Models to MindSpore Models</a>.</p>
</section>
<section id="unit-test">
<h3>Unit Test<a class="headerlink" href="#unit-test" title="Permalink to this headline"></a></h3>
<p>After obtaining the corresponding parameter file, you need to perform a unit test on the entire model to ensure model consistency.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">resnet_ms.src.resnet</span> <span class="kn">import</span> <span class="n">resnet50</span> <span class="k">as</span> <span class="n">ms_resnet50</span>
<span class="kn">from</span> <span class="nn">resnet_pytorch.resnet</span> <span class="kn">import</span> <span class="n">resnet50</span> <span class="k">as</span> <span class="n">pt_resnet50</span>

<span class="k">def</span> <span class="nf">check_res</span><span class="p">(</span><span class="n">pth_path</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">):</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="c1"># When performing a unit test, you need to add a training or inference label to the cell.</span>
    <span class="n">ms_resnet</span> <span class="o">=</span> <span class="n">ms_resnet50</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">pt_resnet</span> <span class="o">=</span> <span class="n">pt_resnet50</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">pt_resnet</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">pth_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">))</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">,</span> <span class="n">ms_resnet</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;========= pt_resnet conv1.weight ==========&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">pt_resnet</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,))[:</span><span class="mi">10</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;========= ms_resnet conv1.weight ==========&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ms_resnet</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,))[:</span><span class="mi">10</span><span class="p">])</span>
    <span class="n">pt_res</span> <span class="o">=</span> <span class="n">pt_resnet</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">inp</span><span class="p">))</span>
    <span class="n">ms_res</span> <span class="o">=</span> <span class="n">ms_resnet</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">inp</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;========= pt_resnet res ==========&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">pt_res</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;========= ms_resnet res ==========&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ms_res</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;diff&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">pt_res</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="o">-</span> <span class="n">ms_res</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())))</span>

<span class="n">pth_path</span> <span class="o">=</span> <span class="s2">&quot;resnet.pth&quot;</span>
<span class="n">ckpt_path</span> <span class="o">=</span> <span class="s2">&quot;resnet50.ckpt&quot;</span>
<span class="n">check_res</span><span class="p">(</span><span class="n">pth_path</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">)</span>
</pre></div>
</div>
<p>During the unit test, you need to add training or inference labels to cells. PyTorch training uses <code class="docutils literal notranslate"><span class="pre">.train()</span></code> and inference uses <code class="docutils literal notranslate"><span class="pre">.eval()</span></code>, MindSpore training uses <code class="docutils literal notranslate"><span class="pre">.set_train()</span></code> and inference uses <code class="docutils literal notranslate"><span class="pre">.set_train(False)</span></code>.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>========= pt_resnet conv1.weight ==========
[ 1.091892e-40 -1.819391e-39  3.509566e-40 -8.281730e-40  1.207908e-39
 -3.576954e-41 -1.000796e-39  1.115791e-39 -1.077758e-39 -6.031427e-40]
========= ms_resnet conv1.weight ==========
[ 1.091892e-40 -1.819391e-39  3.509566e-40 -8.281730e-40  1.207908e-39
 -3.576954e-41 -1.000796e-39  1.115791e-39 -1.077758e-39 -6.031427e-40]
========= pt_resnet res ==========
tensor([[-15.1945,  -5.6529,   6.5738,   9.7807,  -2.4615,   3.0365,  -4.7216,
         -11.1005,   2.7121,  -9.3612],
        [-14.2412,  -5.9004,   5.6366,   9.7030,  -1.6322,   2.6926,  -3.7307,
         -10.7582,   1.4195,  -7.9930],
        [-13.4795,  -5.6582,   5.6432,   8.9152,  -1.5169,   2.6958,  -3.4469,
         -10.5300,   1.3318,  -8.1476],
        [-13.6448,  -5.4239,   5.8254,   9.3094,  -2.1969,   2.7042,  -4.1194,
         -10.4388,   1.9331,  -8.1746]], grad_fn=&lt;AddmmBackward0&gt;)
========= ms_resnet res ==========
[[-15.194535   -5.652934    6.5737996   9.780719   -2.4615316   3.0365033
   -4.7215843 -11.100524    2.7121294  -9.361177 ]
 [-14.24116    -5.9004383   5.6366115   9.702984   -1.6322318   2.69261
   -3.7307222 -10.758192    1.4194587  -7.992969 ]
 [-13.47945    -5.658216    5.6432185   8.915173   -1.5169426   2.6957715
   -3.446888  -10.529953    1.3317728  -8.147601 ]
 [-13.644804   -5.423854    5.825424    9.309403   -2.1969485   2.7042081
   -4.119426  -10.438771    1.9330862  -8.174606 ]]
diff 2.861023e-06
</pre></div>
</div>
<p>The final result is similar and basically meets the expectation. If the result difference is large, you need to compare the result layer by layer.</p>
</section>
</section>
<section id="inference-process">
<h2>Inference Process<a class="headerlink" href="#inference-process" title="Permalink to this headline"></a></h2>
<p>PyTorch inference:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">trans</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">resnet</span> <span class="kn">import</span> <span class="n">resnet50</span>

<span class="k">def</span> <span class="nf">test_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
            <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="c1"># sum up batch loss</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># get the index of the max log-probability</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">test_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Test set: Average loss: </span><span class="si">{:.4f}</span><span class="s1">, Accuracy: </span><span class="si">{:.0f}</span><span class="s1">%</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">test_loss</span><span class="p">,</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)))</span>

<span class="n">use_cuda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">test_transform</span> <span class="o">=</span> <span class="n">trans</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">trans</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
    <span class="n">trans</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">trans</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">trans</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.4914</span><span class="p">,</span> <span class="mf">0.4822</span><span class="p">,</span> <span class="mf">0.4465</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2023</span><span class="p">,</span> <span class="mf">0.1994</span><span class="p">,</span> <span class="mf">0.2010</span><span class="p">]),</span>
<span class="p">])</span>
<span class="n">test_set</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">test_transform</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># 2. define forward network</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="n">resnet50</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;./resnet.pth&quot;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">))</span>
<span class="n">test_epoch</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: -9.7075, Accuracy: 91%
</pre></div>
</div>
<p>MindSpore implements this process:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">src.dataset</span> <span class="kn">import</span> <span class="n">create_dataset</span>
<span class="kn">from</span> <span class="nn">src.model_utils.moxing_adapter</span> <span class="kn">import</span> <span class="n">moxing_wrapper</span>
<span class="kn">from</span> <span class="nn">src.model_utils.config</span> <span class="kn">import</span> <span class="n">config</span>
<span class="kn">from</span> <span class="nn">src.utils</span> <span class="kn">import</span> <span class="n">init_env</span>
<span class="kn">from</span> <span class="nn">src.resnet</span> <span class="kn">import</span> <span class="n">resnet50</span>


<span class="k">def</span> <span class="nf">test_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">test_loss</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss_func</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">target</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">dataset_size</span> <span class="o">=</span> <span class="n">data_loader</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>
    <span class="n">test_loss</span> <span class="o">/=</span> <span class="n">dataset_size</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Test set: Average loss: </span><span class="si">{:.4f}</span><span class="s1">, Accuracy: </span><span class="si">{:.0f}</span><span class="s1">%</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">test_loss</span><span class="p">,</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">dataset_size</span><span class="p">))</span>


<span class="nd">@moxing_wrapper</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">test_net</span><span class="p">():</span>
    <span class="n">init_env</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                  <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">image_height</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">image_width</span><span class="p">)))</span>
    <span class="n">resnet</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">class_num</span><span class="p">)</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">resnet</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
    <span class="n">test_epoch</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">eval_dataset</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">test_net</span><span class="p">()</span>
</pre></div>
</div>
<p>Run the following command:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>test.py<span class="w"> </span>--data_path<span class="w"> </span>data/cifar10/<span class="w"> </span>--checkpoint_path<span class="w"> </span>resnet.ckpt
</pre></div>
</div>
<p>You can obtain the following inference accuracy result:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>run standalone!
Test set: Average loss: 0.3240, Accuracy: 91%
</pre></div>
</div>
<p>The inference accuracy is the same.</p>
</section>
<section id="training-process">
<h2>Training Process<a class="headerlink" href="#training-process" title="Permalink to this headline"></a></h2>
<p>For details about the PyTorch training process, see <a class="reference external" href="https://gitee.com/mindspore/docs/tree/master/docs/mindspore/source_zh_cn/migration_guide/code/resnet_convert/resnet_pytorch">PyToch ResNet-50 CIFAR-10 Sample Code</a>. The log file and trained path are stored in <a class="reference external" href="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/models/resnet_pytorch_res.zip">resnet_pytorch_res</a>.</p>
<p>The corresponding MindSpore code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.profiler</span> <span class="kn">import</span> <span class="n">Profiler</span>
<span class="kn">from</span> <span class="nn">src.dataset</span> <span class="kn">import</span> <span class="n">create_dataset</span>
<span class="kn">from</span> <span class="nn">src.model_utils.moxing_adapter</span> <span class="kn">import</span> <span class="n">moxing_wrapper</span>
<span class="kn">from</span> <span class="nn">src.model_utils.config</span> <span class="kn">import</span> <span class="n">config</span>
<span class="kn">from</span> <span class="nn">src.utils</span> <span class="kn">import</span> <span class="n">init_env</span>
<span class="kn">from</span> <span class="nn">src.resnet</span> <span class="kn">import</span> <span class="n">resnet50</span>


<span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>
    <span class="c1"># Define forward function</span>
    <span class="k">def</span> <span class="nf">forward_fn</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">logits</span>

    <span class="c1"># Get gradient function</span>
    <span class="n">grad_fn</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">forward_fn</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Define function of one-step training</span>
    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">_</span><span class="p">),</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">grad_fn</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="n">dataset_size</span> <span class="o">=</span> <span class="n">data_loader</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">train_step</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train Epoch: </span><span class="si">{}</span><span class="s1"> [</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> (</span><span class="si">{:.0f}</span><span class="s1">%)]</span><span class="se">\t</span><span class="s1">Loss: </span><span class="si">{:.6f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataset_size</span><span class="p">,</span>
                <span class="mf">100.</span> <span class="o">*</span> <span class="n">batch_idx</span> <span class="o">/</span> <span class="n">dataset_size</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">test_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">test_loss</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss_func</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">target</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">dataset_size</span> <span class="o">=</span> <span class="n">data_loader</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>
    <span class="n">test_loss</span> <span class="o">/=</span> <span class="n">dataset_size</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Test set: Average loss: </span><span class="si">{:.4f}</span><span class="s1">, Accuracy: </span><span class="si">{:.0f}</span><span class="s1">%</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">test_loss</span><span class="p">,</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">dataset_size</span><span class="p">))</span>


<span class="nd">@moxing_wrapper</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">train_net</span><span class="p">():</span>
    <span class="n">init_env</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">enable_profiling</span><span class="p">:</span>
        <span class="n">profiler</span> <span class="o">=</span> <span class="n">Profiler</span><span class="p">()</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                   <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">image_height</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">image_width</span><span class="p">)),</span>
                                   <span class="n">rank_size</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">rank_id</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">rank_id</span><span class="p">)</span>
    <span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                  <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">image_height</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">image_width</span><span class="p">)))</span>
    <span class="n">config</span><span class="o">.</span><span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>
    <span class="n">resnet</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">class_num</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">resnet</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">config</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">)</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">epoch_size</span><span class="p">):</span>
        <span class="n">train_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">train_net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">)</span>
        <span class="n">test_epoch</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">eval_dataset</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Finished Training&#39;</span><span class="p">)</span>
    <span class="n">save_path</span> <span class="o">=</span> <span class="s1">&#39;./resnet.ckpt&#39;</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">train_net</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="performance-optimization">
<h2>Performance Optimization<a class="headerlink" href="#performance-optimization" title="Permalink to this headline"></a></h2>
<p>During the preceding training, it is found that the training is slow and performance optimization is required. Before performing specific optimization items, run the <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling.html">profiler tool</a> to obtain the performance data. The profiler tool can obtain only the training encapsulated by the model. Therefore, you need to reconstruct the training process first.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device_num</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">device_num</span>
<span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">use_profilor</span><span class="p">:</span>
    <span class="n">profiler</span> <span class="o">=</span> <span class="n">Profiler</span><span class="p">()</span>
    <span class="c1"># Note that the profiling data should not be too large. Otherwise, the processing will be slow. In this example, if use_profilor is set to True, the original dataset is divided into 40 copies.</span>
    <span class="n">device_num</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                               <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">image_height</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">image_width</span><span class="p">)),</span>
                               <span class="n">rank_size</span><span class="o">=</span><span class="n">device_num</span><span class="p">,</span> <span class="n">rank_id</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">rank_id</span><span class="p">)</span>
<span class="o">.....</span>
<span class="n">loss_scale</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">FixedLossScaleManager</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">drop_overflow_update</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">)</span>
<span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">use_profilor</span><span class="p">:</span>
    <span class="c1"># Note that the profiling data should not be too large. Otherwise, the processing will be slow.</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">LossMonitor</span><span class="p">(),</span> <span class="n">TimeMonitor</span><span class="p">()],</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">profiler</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">epoch_size</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">eval_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">LossMonitor</span><span class="p">(),</span> <span class="n">TimeMonitor</span><span class="p">()],</span>
                <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>Set <code class="docutils literal notranslate"><span class="pre">use_profilor=True</span></code>. The <code class="docutils literal notranslate"><span class="pre">data</span></code> directory is generated in the running directory. Rename the directory <code class="docutils literal notranslate"><span class="pre">profiler_v1</span></code> and run the <code class="docutils literal notranslate"><span class="pre">mindinsight</span> <span class="pre">start</span></code> command in the same directory.</p>
<p><img alt="resnet_profiler1" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/resnet_profiler1.png" /></p>
<p>The following figure shows the MindSpore Insight profiler page. (This analysis is performed in the Ascend environment, which is similar to that in the GPU. The CPU does not support profiler.) There are three parts on the page.</p>
<p>The first part is step trace, which is the most basic part for profiler. The data of a single device includes the step interval and forward and backward propagation. The forward and backward time is the actual running time of the model on the device, and the step interval time includes data processing, data printing, and time when parameters are saved on the CPU during the training process.
It can be seen that the step trace time and forward and backward execution time are almost even, and non-device operations such as data processing account for a large part.</p>
<p>The second part is the forward and backward network execution time, where you can view details.</p>
<p><img alt="resnet_profiler2" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/resnet_profiler2.png" /></p>
<p>The upper part shows the proportion of each AI CORE operator to the total time, and the lower part shows the details of each operator.</p>
<p><img alt="resnet_profiler3" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/resnet_profiler3.png" /></p>
<p>You can click an operator to obtain the execution time, scope, shape, and type of the operator.</p>
<p>In addition to the AI CORE operators, there may be AI CPU and HOST CPU operators on the network. These operators take more time than the AI CORE operators. You can click the tabs to view the time.</p>
<p><img alt="resnet_profiler4" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/resnet_profiler4.png" /></p>
<p>In addition to viewing the operator performance, you can also view the raw data for analysis.</p>
<p><img alt="resnet_profiler5" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/resnet_profiler5.png" /></p>
<p>Go to the <code class="docutils literal notranslate"><span class="pre">profiler_v1/profiler/</span></code> directory and click the <code class="docutils literal notranslate"><span class="pre">aicore_intermediate_0_type.csv</span></code> file to view the statistics of each operator. There are 30 AI Core operators in total. The total execution time is 37.526 ms.</p>
<p><img alt="resnet_profiler6" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/resnet_profiler6.png" /></p>
<p>In addition, <code class="docutils literal notranslate"><span class="pre">aicore_intermediate_0_detail.csv</span></code> contains detailed data of each operator, which is similar to the operator details displayed in MindSpore Insight. <code class="docutils literal notranslate"><span class="pre">ascend_timeline_display_0.json</span></code> is a timeline data file. For details, see <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling_ascend.html#timeline-analysis">timeline</a>.</p>
<p>The third part is the performance data during data processing. You can view the data queue status in this part.</p>
<p><img alt="resnet_profiler7" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/resnet_profiler7.png" /></p>
<p>And a queue status of each data processing operation:</p>
<p><img alt="resnet_profiler8" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/resnet_profiler8.png" /></p>
<p>Now, let’s analyze the process and solve the problem.</p>
<p>From the step trace, the step interval and forward and backward execution time are almost even. MindSpore provides an <a class="reference external" href="https://mindspore.cn/docs/zh-CN/master/design/overview.html">on-device execution method</a> to concurrently process data and execute the network on the device. You only need to set <code class="docutils literal notranslate"><span class="pre">dataset_sink_mode=True</span></code> in <code class="docutils literal notranslate"><span class="pre">model.train</span></code>. Note that this configuration is <code class="docutils literal notranslate"><span class="pre">True</span></code> by default. When this configuration is enabled, one epoch returns the result of only one network. You are advised to change the value to <code class="docutils literal notranslate"><span class="pre">False</span></code> during debugging.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">dataset_sink_mode=True</span></code> is set, the result of setting the profiler is as follows:</p>
<p><img alt="resnet_profiler9" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/resnet_profiler9.png" /></p>
<p>The execution time is reduced by half.</p>
<p>Let’s go on with the analysis and optimization. According to the execution time of forward and backward operators, <code class="docutils literal notranslate"><span class="pre">Cast</span></code> and <code class="docutils literal notranslate"><span class="pre">BatchNorm</span></code> account for almost 50%. Why are there so many <code class="docutils literal notranslate"><span class="pre">Cast</span></code>? According to <a class="reference external" href="https://www.mindspore.cn/docs/en/master/migration_guide/model_development/model_development.html">Constructing MindSpore Network</a>, Conv, Sort, and TopK in the Ascend environment can only be float16. Therefore, the <code class="docutils literal notranslate"><span class="pre">Cast</span></code> operator is added before and after Conv calculation. The most direct method is to change the network calculation to float16. Only <code class="docutils literal notranslate"><span class="pre">Cast</span></code> is added before the network input and loss computation. The consumption of the <code class="docutils literal notranslate"><span class="pre">Cast</span></code> operator can be ignored. This involves the mixed precision policy of MindSpore.</p>
<p>MindSpore has three methods to use mixed precision:</p>
<ol class="arabic simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">Cast</span></code> to convert the network input <code class="docutils literal notranslate"><span class="pre">cast</span></code> into <code class="docutils literal notranslate"><span class="pre">float16</span></code> and the loss input <code class="docutils literal notranslate"><span class="pre">cast</span></code> into <code class="docutils literal notranslate"><span class="pre">float32</span></code>.</p></li>
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">to_float</span></code> method of <code class="docutils literal notranslate"><span class="pre">Cell</span></code>. For details, see <a class="reference external" href="https://www.mindspore.cn/docs/en/master/migration_guide/model_development/model_and_cell.html">Network Entity and Loss Construction</a>.</p></li>
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">amp_level</span></code> interface of the <code class="docutils literal notranslate"><span class="pre">Model</span></code> to perform mixed precision. For details, see <a class="reference external" href="https://www.mindspore.cn/tutorials/en/master/advanced/mixed_precision.html#automatic-mix-precision">Automatic Mixed-Precision</a>.</p></li>
</ol>
<p>Use the third method to set <code class="docutils literal notranslate"><span class="pre">amp_level</span></code> in <code class="docutils literal notranslate"><span class="pre">Model</span></code> to <code class="docutils literal notranslate"><span class="pre">O3</span></code> and check the profiler result.</p>
<p><img alt="resnet_profiler10" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/resnet_profiler10.png" /></p>
<p>Each step takes only 23 ms.</p>
<p>Finally, let’s look at data processing.</p>
<p><img alt="resnet_profiler11" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/resnet_profiler11.png" /></p>
<p>After the sink mode is added, there are two queues in total. The host queue is a queue in the memory. The dataset object continuously places the input data required by the network in the host queue.
The other is a data queue on the device. The data in the host queue is cached to the data queue, and the network directly obtains the model input from the data queue.</p>
<p>The host queue is empty in many places, indicating that the dataset is quickly taken away by the data queue when data is continuously generated. The data queue is almost full. Therefore, data can keep up with network training, and data processing is not the bottleneck of network training.</p>
<p>If most of the data queues are empty, you need to optimize the data performance. For example:</p>
<p><img alt="resnet_profiler12" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/mindspore/source_zh_cn/migration_guide/images/resnet_profiler12.png" /></p>
<p>In the queue of each data processing operation, the last operator and the <code class="docutils literal notranslate"><span class="pre">batch</span></code> operator are empty for a long time. In this case, you can increase the degree of parallelism of the <code class="docutils literal notranslate"><span class="pre">batch</span></code> operator. For details, see <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/master/dataset/optimize.html">Data Processing Performance Tuning</a>.</p>
<p>The code required for ResNet migration can be obtained from <a class="reference external" href="https://gitee.com/mindspore/docs/tree/master/docs/mindspore/source_zh_cn/migration_guide/code">code</a>.</p>
<p>You can click the following video to learn.</p>
<div style="position: relative; padding: 30% 45%;">
<iframe style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;" src="https://player.bilibili.com/player.html?aid=216889508&bvid=BV1sa411P737&cid=802191204&page=1&high_quality=1&&danmaku=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="debug_and_tune.html" class="btn btn-neutral float-left" title="Debugging and Tuning" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="migrator_with_tools.html" class="btn btn-neutral float-right" title="Application Practice Guide for Network Migration Tool" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>