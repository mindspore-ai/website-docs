<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Differences with torch.nn.SyncBatchNorm &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      <link rel="stylesheet" href="../../../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script><script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/js/theme.js"></script><script src="../../../_static/underscore.js"></script><script src="../../../_static/doctools.js"></script><script src="../../../_static/js/mermaid-9.3.0.js"></script><script src="../../../_static/js/training.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script><script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script><script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/programming_paradigm.html">Functional and Object-Oriented Fusion Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/distributed_training_design.html">Distributed Parallel Native</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/all_scenarios.html">Full-scenarios Unified Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../official_models.html">Official Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.experimental.html">mindspore.experimental</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/enveriment_preparation.html">Environment Preparation and Information Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/model_development/model_development.html">Network Constructing Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/faq.html">FAQs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Syntax Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../static_graph_syntax_support.html">Static Graph Syntax Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../static_graph_syntax/operators.html">Static Graph Syntax - Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../static_graph_syntax/statements.html">Static Graph Syntax - Python Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../static_graph_syntax/python_builtin_functions.html">Static Graph Syntax - Python Built-in Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../index_support.html">Tensor Index Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../env_var_list.html">Environment Variables</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Differences with torch.nn.SyncBatchNorm</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/note/api_mapping/pytorch_diff/SyncBatchNorm.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="differences-with-torch-nn-syncbatchnorm">
<h1>Differences with torch.nn.SyncBatchNorm<a class="headerlink" href="#differences-with-torch-nn-syncbatchnorm" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/mindspore/source_en/note/api_mapping/pytorch_diff/SyncBatchNorm.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.svg" /></a></p>
<section id="torch-nn-syncbatchnorm">
<h2>torch.nn.SyncBatchNorm<a class="headerlink" href="#torch-nn-syncbatchnorm" title="Permalink to this headline"></a></h2>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>class torch.nn.SyncBatchNorm(
    num_features,
    eps=1e-05,
    momentum=0.1,
    affine=True,
    track_running_stats=True,
    process_group=None
)(input) -&gt; Tensor
</pre></div>
</div>
<p>For more information, see <a class="reference external" href="https://pytorch.org/docs/1.8.1/generated/torch.nn.SyncBatchNorm.html">torch.nn.SyncBatchNorm</a>.</p>
</section>
<section id="mindspore-nn-syncbatchnorm">
<h2>mindspore.nn.SyncBatchNorm<a class="headerlink" href="#mindspore-nn-syncbatchnorm" title="Permalink to this headline"></a></h2>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>class mindspore.nn.SyncBatchNorm(
    num_features,
    eps=1e-5,
    momentum=0.9,
    affine=True,
    gamma_init=&#39;ones&#39;,
    beta_init=&#39;zeros&#39;,
    moving_mean_init=&#39;zeros&#39;,
    moving_var_init=&#39;ones&#39;,
    use_batch_statistics=None,
    process_groups=None
)(x) -&gt; Tensor
</pre></div>
</div>
<p>For more information, see <a class="reference external" href="https://mindspore.cn/docs/en/master/api_python/nn/mindspore.nn.SyncBatchNorm.html">mindspore.nn.SyncBatchNorm</a>.</p>
</section>
<section id="differences">
<h2>Differences<a class="headerlink" href="#differences" title="Permalink to this headline"></a></h2>
<p>PyTorch: Perform cross-device synchronous batch normalization of input data.</p>
<p>MindSpore: MindSpore API is basically the same as PyTorch, and the MindSpore input only supports 2D and 4D. The default value of momentum in MindSpore is 0.9, and the conversion relationship with PyTorch momentum is 1-momentum, with the same default behavior as PyTorch. The training and the parameter update strategy during inference are different from PyTorch.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Categories</p></th>
<th class="head"><p>Subcategories</p></th>
<th class="head"><p>PyTorch</p></th>
<th class="head"><p>MindSpore</p></th>
<th class="head"><p>Differences</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Parameters</p></td>
<td><p>Parameter 1</p></td>
<td><p>num_features</p></td>
<td><p>num_features</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 2</p></td>
<td><p>eps</p></td>
<td><p>eps</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Parameter 3</p></td>
<td><p>momentum</p></td>
<td><p>momentum</p></td>
<td><p>Consistent functionality, but the default value is 0.1 in PyTorch and 0.9 in MindSpore. The conversion relationship with PyTorch momentum is 1-momentum with the same default behavior as PyTorch</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 4</p></td>
<td><p>affine</p></td>
<td><p>affine</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Parameter 5</p></td>
<td><p>track_running_stats</p></td>
<td><p>use_batch_statistics</p></td>
<td><p>Consistent function. Different values correspond to different default methods.</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 6</p></td>
<td><p>-</p></td>
<td><p>gamma_init</p></td>
<td><p>PyTorch does not have this parameter, and MindSpore can initialize the value of the parameter gamma</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Parameter 7</p></td>
<td><p>-</p></td>
<td><p>beta_init</p></td>
<td><p>PyTorch does not have this parameter, and MindSpore can initialize the value of the parameter beta</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 8</p></td>
<td><p>-</p></td>
<td><p>moving_mean_init</p></td>
<td><p>PyTorch does not have this parameter, and MindSpore can initialize the value of the parameter moving_mean</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Parameter 9</p></td>
<td><p>-</p></td>
<td><p>moving_var_init</p></td>
<td><p>PyTorch does not have this parameter, and MindSpore can initialize the value of the parameter moving_var</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 10</p></td>
<td><p>process_group</p></td>
<td><p>process_groups</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p>Input</p></td>
<td><p>Single input</p></td>
<td><p>input</p></td>
<td><p>x</p></td>
<td><p>Interface input. MindSpore only supports 2-D and 4-D input</p></td>
</tr>
</tbody>
</table>
<p>BatchNorm is a special regularization method in the CV field. It has different computation processes during training and inference and is usually controlled by operator attributes. BatchNorm of MindSpore and PyTorch uses two different parameter groups at this point.</p>
<ul class="simple">
<li><p>Difference 1</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">torch.nn.SyncBatchNorm</span></code> status under different parameters</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-left head"><p>training</p></th>
<th class="text-left head"><p>track_running_stats</p></th>
<th class="text-left head"><p>Status</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>True</p></td>
<td class="text-left"><p>True</p></td>
<td class="text-left"><p>Expected training status. <code class="docutils literal notranslate"><span class="pre">running_mean</span></code> and <code class="docutils literal notranslate"><span class="pre">running_var</span></code> trace the statistical features of the batch in the entire training process. Each group of input data is normalized based on the mean and var statistical features of the current batch, and then <code class="docutils literal notranslate"><span class="pre">running_mean</span></code> and <code class="docutils literal notranslate"><span class="pre">running_var</span></code> are updated.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>True</p></td>
<td class="text-left"><p>False</p></td>
<td class="text-left"><p>Each group of input data is normalized based on the statistics feature of the current batch, but the <code class="docutils literal notranslate"><span class="pre">running_mean</span></code> and <code class="docutils literal notranslate"><span class="pre">running_var</span></code> parameters do not exist.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>False</p></td>
<td class="text-left"><p>True</p></td>
<td class="text-left"><p>Expected inference status. The BN uses <code class="docutils literal notranslate"><span class="pre">running_mean</span></code> and <code class="docutils literal notranslate"><span class="pre">running_var</span></code> for normalization and does not update them.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>False</p></td>
<td class="text-left"><p>False</p></td>
<td class="text-left"><p>The effect is the same as that of the second status. The only difference is that this is the inference status and does not learn the weight and bias parameters. Generally, this status is not used.</p></td>
</tr>
</tbody>
</table>
<p><code class="docutils literal notranslate"><span class="pre">mindspore.nn.SyncBatchNorm</span></code> status under different parameters</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-left head"><p>use_batch_statistics</p></th>
<th class="text-left head"><p>Status</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>True</p></td>
<td class="text-left"><p>Expected training status. <code class="docutils literal notranslate"><span class="pre">moving_mean</span></code> and <code class="docutils literal notranslate"><span class="pre">moving_var</span></code> trace the statistical features of the batch in the entire training process. Each group of input data is normalized based on the mean and var statistical features of the current batch, and then <code class="docutils literal notranslate"><span class="pre">moving_mean</span></code> and <code class="docutils literal notranslate"><span class="pre">moving_var</span></code> are updated.</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Fasle</p></td>
<td class="text-left"><p>Expected inference status. The BN uses <code class="docutils literal notranslate"><span class="pre">moving_mean</span></code> and <code class="docutils literal notranslate"><span class="pre">moving_var</span></code> for normalization and does not update them.</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>None</p></td>
<td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">use_batch_statistics</span></code> is automatically set. For training, set <code class="docutils literal notranslate"><span class="pre">use_batch_statistics</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code>. For inference, <code class="docutils literal notranslate"><span class="pre">set</span> <span class="pre">use_batch_statistics</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></td>
</tr>
</tbody>
</table>
<p>Compared with <code class="docutils literal notranslate"><span class="pre">torch.nn.SyncBatchNorm</span></code>, <code class="docutils literal notranslate"><span class="pre">mindspore.nn.SyncBatchNorm</span></code> does not have two redundant states and retains only the most commonly used training and inference states.</p>
<ul class="simple">
<li><p>Difference 2</p></li>
</ul>
<p>In PyTorch, the network is in training mode by default, while in MindSpore, it is in inference mode by default (<code class="docutils literal notranslate"><span class="pre">is_training</span></code> is False). You need to use the <code class="docutils literal notranslate"><span class="pre">net.set_train()</span></code> method in MindSpore to switch the network to training mode. In this case, the parameters <code class="docutils literal notranslate"><span class="pre">mean</span></code> and <code class="docutils literal notranslate"><span class="pre">variance</span></code> are calculated during the training. Otherwise, in inference mode, the parameters are loaded from the checkpoint.</p>
<ul class="simple">
<li><p>Difference 3</p></li>
</ul>
<p>The meaning of the momentum parameter of the BatchNorm series operators in MindSpore is opposite to that in PyTorch. The relationship is as follows:</p>
<div class="math notranslate nohighlight">
\[momentum_{pytorch} = 1 - momentum_{mindspore}\]</div>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>