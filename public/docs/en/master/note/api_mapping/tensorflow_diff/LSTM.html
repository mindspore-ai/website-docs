

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Function Differences with tf.keras.layers.LSTM &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../../../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
        <script src="../../../_static/js/training.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/programming_paradigm.html">Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/auto_gradient.html">Functional Differential Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/all_scenarios.html">Full-scenarios Unification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption"><span class="caption-text">Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark.html">Benchmarks</a></li>
<li class="toctree-l1"><a class="reference external" href="https://gitee.com/mindspore/models/blob/master/README.md#table-of-contents">Network List↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../operator_list.html">API List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../syntax_list.html">Syntax Support</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/en/master/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensorflow_api_mapping.html">TensorFlow and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption"><span class="caption-text">Migration Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/enveriment_preparation.html">Environment Preparation and Information Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/model_development/model_development.html">Constructing MindSpore Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/faq.html">FAQs</a></li>
</ul>
<p class="caption"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Function Differences with tf.keras.layers.LSTM</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../_sources/note/api_mapping/tensorflow_diff/LSTM.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="function-differences-with-tf-keras-layers-lstm">
<h1>Function Differences with tf.keras.layers.LSTM<a class="headerlink" href="#function-differences-with-tf-keras-layers-lstm" title="Permalink to this headline">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/master/docs/mindspore/source_en/note/api_mapping/tensorflow_diff/LSTM.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png"></a></p>
<div class="section" id="tf-keras-layers-lstm">
<h2>tf.keras.layers.LSTM<a class="headerlink" href="#tf-keras-layers-lstm" title="Permalink to this headline">¶</a></h2>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>class tf.keras.layers.LSTM(
    units, activation=&#39;tanh&#39;, recurrent_activation=&#39;sigmoid&#39;,
    use_bias=True, kernel_initializer=&#39;glorot_uniform&#39;,
    recurrent_initializer=&#39;orthogonal&#39;,
    bias_initializer=&#39;zeros&#39;, unit_forget_bias=True,
    kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None,
    activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None,
    bias_constraint=None, dropout=0.0, recurrent_dropout=0.0,
    return_sequences=False, return_state=False, go_backwards=False, stateful=False,
    time_major=False, unroll=False)(inputs, mask, training, initial_state) -&gt; Tensor
</pre></div>
</div>
<p>For more information, see <a class="reference external" href="https://tensorflow.google.cn/versions/r2.6/api_docs/python/tf/keras/layers/LSTM">tf.keras.layers.LSTM</a>.</p>
</div>
<div class="section" id="mindspore-nn-lstm">
<h2>mindspore.nn.LSTM<a class="headerlink" href="#mindspore-nn-lstm" title="Permalink to this headline">¶</a></h2>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>class mindspore.nn.LSTM(
    input_size,
    hidden_size,
    num_layers=1,
    has_bias=True,
    batch_first=False,
    dropout=0,
    bidirectional=False)(x, hx, seq_length) -&gt; Tensor
</pre></div>
</div>
<p>For more information, see <a class="reference external" href="https://mindspore.cn/docs/en/master/api_python/nn/mindspore.nn.LSTM.html">mindspore.nn.LSTM</a>.</p>
</div>
<div class="section" id="differences">
<h2>Differences<a class="headerlink" href="#differences" title="Permalink to this headline">¶</a></h2>
<p>TensorFlow: When the parameters return_sequences and return_state are set, the output sequence and final state can be calculated based on the input sequence.</p>
<p>MindSpore: MindSpore can compute output sequences and final states based on input sequences and given initial states, and can implement multi-layer and bi-directional LSTM networks. However, it is not possible to specify some functions (such as activation function, regularization function, constraint function) in the computation process like TensorFlow, and the API of TensorFlow can only implement one-way one-layer LSTM networks, so it will lead to different shapes of the final state tensor between the two APIs.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Categories</th>
<th>Subcategories</th>
<th>TensorFlow</th>
<th>MindSpore</th>
<th>Differences</th>
</tr>
</thead>
<tbody>
<tr>
<td>Parameters</td>
<td>Parameter 1</td>
<td>units</td>
<td>hidden_size</td>
<td>Same function, different parameter names</td>
</tr>
<tr>
<td></td>
<td>Parameter 2</td>
<td>activation</td>
<td>-</td>
<td>Specify the activation function to be used. Default value: tanh. MindSpore does not have this parameter, but the same activation function is used by default during the calculation</td>
</tr>
<tr>
<td></td>
<td>Parameter 3</td>
<td>recurrent_activation</td>
<td>-</td>
<td>Specify the activation function used in the recursion step. Default value: sigmoid. MindSpore does not have this parameter, but the same activation function is used by default during the calculation</td>
</tr>
<tr>
<td></td>
<td>Parameter 4</td>
<td>use_bias</td>
<td>has_bias</td>
<td>Same function, different parameter names</td>
</tr>
<tr>
<td></td>
<td>Parameter 5</td>
<td>kernel_initializer</td>
<td>-</td>
<td>Initialize the kernel weight matrix for the linear transformation of the input. Default value: glorot_uniform. MindSpore does not have this parameter.</td>
</tr>
<tr>
<td></td>
<td>Parameter 6</td>
<td>recurrent_initializer</td>
<td>-</td>
<td>Initialize the weight matrix of recurrent_kernel for linear transformation of recursive states. Default value: orthogonal. MindSpore does not have this parameter</td>
</tr>
<tr>
<td></td>
<td>Parameter 7</td>
<td>bias_initializer</td>
<td>-</td>
<td>Initialize the bias vector. Default value: zeros. MindSpore does not have this parameter.</td>
</tr>
<tr>
<td></td>
<td>Parameter 8</td>
<td>unit_forget_bias</td>
<td>-</td>
<td>Select whether to add 1 to the offset of the forget gate at initialization. Default value: True. MindSpore does not have this parameter.</td>
</tr>
<tr>
<td></td>
<td>Parameter 9</td>
<td>kernel_regularizer</td>
<td>-</td>
<td>The regularization function applied to the kernel weight matrix. Default value: None. MindSpore does not have this parameter.</td>
</tr>
<tr>
<td></td>
<td>Parameter 10</td>
<td>recurrent_regularizer</td>
<td>-</td>
<td>The regularization function applied to the recurrent_kernel weight matrix. Default value: None. MindSpore does not have this parameter.</td>
</tr>
<tr>
<td></td>
<td>Parameter 11</td>
<td>bias_regularizer</td>
<td>-</td>
<td>The regularization function applied to the bias vector. Default value: None. MindSpore does not have this parameter.</td>
</tr>
<tr>
<td></td>
<td>Parameter 12</td>
<td>activity_regularizer</td>
<td>-</td>
<td>The regularization function applied to the output of the activated layer. Default value: None. MindSpore does not have this parameter</td>
</tr>
<tr>
<td></td>
<td>Parameter 13</td>
<td>kernel_constraint</td>
<td>-</td>
<td>Constraint function applied to the kernel weight matrix. Default value: None. MindSpore does not have this parameter</td>
</tr>
<tr>
<td></td>
<td>Parameter 14</td>
<td>recurrent_constraint</td>
<td>-</td>
<td>Constraint function applied to the recurrent_kernel weight matrix. Default value: None. MindSpore does not have this parameter</td>
</tr>
<tr>
<td></td>
<td>Parameter 15</td>
<td>bias_constraint</td>
<td>-</td>
<td>Constraint function applied to the weight vector. Default value: None. MindSpore does not have this parameter</td>
</tr>
<tr>
<td></td>
<td>Parameter 16</td>
<td>dropout</td>
<td>dropout</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>Parameter 17</td>
<td>recurrent_dropout</td>
<td>-</td>
<td>The dropout probability used in the recursive state. MindSpore uses dropout</td>
</tr>
<tr>
<td></td>
<td>Parameter 18</td>
<td>return_sequences</td>
<td>-</td>
<td>Whether to return the last output in the output sequence or the complete sequence. Default value: False. MindSpore does not have this parameter, but defaults to True.</td>
</tr>
<tr>
<td></td>
<td>Parameter 19</td>
<td>return_state</td>
<td>-</td>
<td>Whether to return the last state. Default value: False. MindSpore does not have this parameter, but defaults to True</td>
</tr>
<tr>
<td></td>
<td>Parameter 20</td>
<td>go_backwards</td>
<td>-</td>
<td>Whether to reverse the input sequence and return the reverse sequence. Default value: False. MindSpore does not have this parameter.</td>
</tr>
<tr>
<td></td>
<td>Parameter 21</td>
<td>stateful</td>
<td>-</td>
<td>Whether to use the last state of each sample at index i in the batch as the initial state of the samples at index i in the next batch. Default value: False. MindSpore does not have this parameter.</td>
</tr>
<tr>
<td></td>
<td>Parameter 22</td>
<td>time_major</td>
<td>-</td>
<td>Selects the shape format of the input and output tensor. If True, the input and output will be [timesteps, batch, feature], while in the case of False, it will be [batch, timesteps, feature]. Default value: False. MindSpore does not have this parameter, but by default both shapes are possible</td>
</tr>
<tr>
<td></td>
<td>Parameter 23</td>
<td>unroll</td>
<td>-</td>
<td>If True, the network will be expanded, otherwise a symbolic loop will be used. Default value: False. MindSpore does not have this parameter.</td>
</tr>
<tr>
<td></td>
<td>Parameter 24</td>
<td>inputs</td>
<td>x</td>
<td>Same function, different parameter names</td>
</tr>
<tr>
<td></td>
<td>Parameter 25</td>
<td>mask</td>
<td>-</td>
<td>A binary tensor of the shape [batch, timesteps] indicating whether the given time step should be masked or not (optional, default is None). A single True entry indicates that the corresponding time step should be utilized, while a False entry indicates that the corresponding time step should be ignored. MindSpore does not have this parameter</td>
</tr>
<tr>
<td></td>
<td>Parameter 26</td>
<td>training</td>
<td>-</td>
<td>Python bool indicating whether layer should be run in training mode or inference mode. This parameter is passed to the cell when the cell is called. This is only relevant when using dropout or recurrent_dropout (optional, default is None). MindSpore does not have this parameter</td>
</tr>
<tr>
<td></td>
<td>Parameter 27</td>
<td>initial_state</td>
<td>hx</td>
<td>The initial state tensor list to be passed to the cell for the first call (optional, default is None, which will result in the creation of a zero-padded initial state tensor). The role in MindSpore is to give the initial state tensor.</td>
</tr>
<tr>
<td></td>
<td>Parameter 28</td>
<td>-</td>
<td>input_size</td>
<td>Automatically determine the input size. TensorFlow does not have this parameter</td>
</tr>
<tr>
<td></td>
<td>Parameter 29</td>
<td>-</td>
<td>num_layers</td>
<td>Set the number of network layers. Default value: 1. TensorFlow does not have this parameter</td>
</tr>
<tr>
<td></td>
<td>Parameter 30</td>
<td>-</td>
<td>batch_first</td>
<td>The first dimension of the default input is batch_size, and TensorFlow does not have this parameter</td>
</tr>
<tr>
<td></td>
<td>Parameter 31</td>
<td>-</td>
<td>bidirectional</td>
<td>The function is to set the bi-directional LSTM, and TensorFlow does not have this parameter</td>
</tr>
<tr>
<td></td>
<td>Parameter 32</td>
<td>-</td>
<td>seq_length</td>
<td>Specify the sequence length of the input batch. TensorFlow does not have this parameter</td>
</tr>
</tbody>
</table>
<div class="section" id="code-example">
<h3>Code Example<a class="headerlink" href="#code-example" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>This API of TensorFlow generally defaults to a zero-padding tensor for the initial state tensor, so we can set MindSpore input state tensor to a zero tensor. In addition, TensorFlow API can only implement one layer of one-way LSTM network, and the shape of the output state is [batch_size, hidden_size], while the shape of MindSpore output state is [num_directions * num_layers, batch_size, hidden_size]. Therefore, we can take the default value of False for the parameter bidirectional of the MindSpore API, so that num_directions is 1. By taking the default value of 1 for the parameter num_layers as well, making the first dimension of MindSpore output state tensor shape 1, and then removing the first dimension with mindspore.ops.Squeeze, we can get the same result as TensorFlow API and achieve the same function.</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># TensorFlow</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="n">lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">whole_seq_output</span><span class="p">,</span> <span class="n">final_memory_state</span><span class="p">,</span> <span class="n">final_carry_state</span> <span class="o">=</span> <span class="n">lstm</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">whole_seq_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># (3, 5, 16)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">final_memory_state</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># (3, 16)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">final_carry_state</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># (3, 16)</span>

<span class="c1"># MindSpore</span>
<span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">h0</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span> <span class="o">*</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">c0</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span> <span class="o">*</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">hn</span><span class="p">,</span> <span class="n">cn</span><span class="p">)</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">h0</span><span class="p">,</span> <span class="n">c0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># (3, 5, 16)</span>
<span class="n">squeeze</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">hn_</span> <span class="o">=</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">hn</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">hn_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># (3, 16)</span>
<span class="n">cn_</span> <span class="o">=</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">cn</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cn_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># (3, 16)</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>