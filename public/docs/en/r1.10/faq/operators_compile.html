<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Operators Compile &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/training.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Migration from a Third-party Framework" href="usage_migrate_3rd.html" />
    <link rel="prev" title="Network Compilation" href="network_compilation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../design/auto_gradient.html">Functional Differential Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/thor.html">Second Order Optimizer</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.10/training_visual_design.html">Design of Visualization↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/benchmark.html">Benchmarks</a></li>
<li class="toctree-l1"><a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.10/README.md#table-of-contents">Network List↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/operator_list.html">API List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/syntax_list.html">Syntax Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.audio.html">mindspore.dataset.audio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.transformer.html">mindspore.nn.transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.function.html">mindspore.ops.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.10/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/tensorflow_api_mapping.html">TensorFlow and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/enveriment_preparation.html">Environment Preparation and Information Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/model_development/model_development.html">Constructing MindSpore Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/faq.html">FAQs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/typical_api_comparision.html">Differences Between MindSpore and PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/use_third_party_op.html">Using Third-party Operator Libraries Based on Customized Interfaces</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_configure.html">Distributed Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Operators Compile</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/faq/operators_compile.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="operators-compile">
<h1>Operators Compile<a class="headerlink" href="#operators-compile" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.10/docs/mindspore/source_en/faq/operators_compile.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/resource/_static/logo_source_en.png"></a></p>
<p><font size=3><strong>Q: When the <code class="docutils literal notranslate"><span class="pre">ops.concat</span></code> operator is used, the error message <code class="docutils literal notranslate"><span class="pre">Error:Input</span> <span class="pre">and</span> <span class="pre">(output</span> <span class="pre">+</span> <span class="pre">workspace)</span> <span class="pre">num</span> <span class="pre">should</span> <span class="pre">&lt;=192!</span></code> is displayed, which indicating that the data volume is large. What can I do?</strong></font></p>
<p>A: The <code class="docutils literal notranslate"><span class="pre">shape</span></code> of the <code class="docutils literal notranslate"><span class="pre">ops.concat</span></code> operator is too large. You are advised to set the output to <code class="docutils literal notranslate"><span class="pre">numpy</span></code> when creating an iterator for the <code class="docutils literal notranslate"><span class="pre">dataset</span></code> object. The setting is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gallaryloader</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>In the post-processing phase (in a non-network calculation process, that is, in a non-<code class="docutils literal notranslate"><span class="pre">construct</span></code> function), <code class="docutils literal notranslate"><span class="pre">numpy</span></code> can be directly used for computation. For example, <code class="docutils literal notranslate"><span class="pre">numpy.concatenate</span></code> is used to replace the <code class="docutils literal notranslate"><span class="pre">ops.concat</span></code> for computation.</p>
<br/>
<p><font size=3><strong>Q: In the <code class="docutils literal notranslate"><span class="pre">construct</span></code> function of the static graph mode, how do I remove all negative values contained in a <code class="docutils literal notranslate"><span class="pre">tensor</span></code>?</strong></font></p>
<p>A: You are advised to use the <code class="docutils literal notranslate"><span class="pre">ops.clip_by_value</span></code> interface to change all negative numbers to 0 for computation.</p>
<br/>
<p><font size=3><strong>Q: What is the function of the <code class="docutils literal notranslate"><span class="pre">TransData</span></code> operator? Can the performance be optimized?</strong></font></p>
<p>A: The <code class="docutils literal notranslate"><span class="pre">TransData</span></code> operator is used in the scenario where the data formats (such as NC1HWC0) used by interconnected operators on the network are inconsistent. In this case, the framework automatically inserts the <code class="docutils literal notranslate"><span class="pre">TransData</span></code> operator to convert the data formats into the same format and then performs computation. Huawei Ascend supports 5D format operations, and uses the <code class="docutils literal notranslate"><span class="pre">transdata</span></code> operator to convert data from 4D to 5D to improve performance.</p>
<br/>
<p><font size=3><strong>Q: An error occurs when the <code class="docutils literal notranslate"><span class="pre">Concat</span></code> operator concatenates tuples containing multiple tensors. An error occurs when the number of <code class="docutils literal notranslate"><span class="pre">tensor</span> <span class="pre">list</span></code> elements entered is greater than or equal to 192. What is a better solution (running in dynamic mode) for <code class="docutils literal notranslate"><span class="pre">Concat</span></code> to concatenate tuples containing multiple Tensors?</strong></font></p>
<p>A: The number of tensors to be concatenated at a time cannot exceed 192 according to the bottom-layer specifications of the Ascend operator. You can try to concatenate them twice.</p>
<br/>
<p><font size=3><strong>Q: When <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> is used to define convolution, the <code class="docutils literal notranslate"><span class="pre">group</span></code> parameter is used. Is it necessary to ensure that the value of <code class="docutils literal notranslate"><span class="pre">group</span></code> can be exactly divided by the input and output dimensions? How is the <code class="docutils literal notranslate"><span class="pre">group</span></code> parameter transferred?</strong></font></p>
<p>A: The <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code> operator has the following constraint: When the value of <code class="docutils literal notranslate"><span class="pre">group</span></code> is greater than 1, the value must be the same as the number of input and output channels. Do not use <code class="docutils literal notranslate"><span class="pre">ops.Conv2D</span></code>. Currently, this operator does not support a value of <code class="docutils literal notranslate"><span class="pre">group</span></code> that is greater than 1. Currently, only the <code class="docutils literal notranslate"><span class="pre">nn.Conv2d</span></code> API of MindSpore supports group convolution. However, the number of <code class="docutils literal notranslate"><span class="pre">group</span></code> must be the same as the number of input and output channels.</p>
<br/>
<p><font size=3><strong>Q: Does MindSpore support matrix transposition?</strong></font></p>
<p>A: Yes. For details, see <a class="reference external" href="https://www.mindspore.cn/docs/en/r1.10/api_python/ops/mindspore.ops.Transpose.html#mindspore.ops.Transpose">mindspore.ops.Transpose</a>.</p>
<br/>
<p><font size=3><strong>Q: Can MindSpore calculate the variance of any <code class="docutils literal notranslate"><span class="pre">tensor</span></code>?</strong></font></p>
<p>A: Currently, MindSpore does not have APIs or operators which can directly calculate the variance of a <code class="docutils literal notranslate"><span class="pre">tensor</span></code>.</p>
<br/>
<p><font size=3><strong>Q: Compared with PyTorch, the <code class="docutils literal notranslate"><span class="pre">nn.Embedding</span></code> layer lacks the <code class="docutils literal notranslate"><span class="pre">padding</span></code> operation. Can other operators implement this operation?</strong></font></p>
<p>A: In PyTorch, <code class="docutils literal notranslate"><span class="pre">padding_idx</span></code> is used to set the word vector in the <code class="docutils literal notranslate"><span class="pre">padding_idx</span></code> position in the embedding matrix to 0, and the word vector in the <code class="docutils literal notranslate"><span class="pre">padding_idx</span></code> position is not updated during backward propagation.
In MindSpore, you can manually initialize the weight corresponding to the <code class="docutils literal notranslate"><span class="pre">padding_idx</span></code> position of embedding to 0. In addition, the <code class="docutils literal notranslate"><span class="pre">loss</span></code> corresponding to <code class="docutils literal notranslate"><span class="pre">padding_idx</span></code> is filtered out through the <code class="docutils literal notranslate"><span class="pre">mask</span></code> operation during training.</p>
<br/>
<p><font size=3><strong>Q: When the <code class="docutils literal notranslate"><span class="pre">Tile</span></code> operator in operations executes <code class="docutils literal notranslate"><span class="pre">__infer__</span></code>, the <code class="docutils literal notranslate"><span class="pre">value</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>. Why is the value lost?</strong></font></p>
<p>A: The <code class="docutils literal notranslate"><span class="pre">multiples</span> <span class="pre">input</span></code> of the <code class="docutils literal notranslate"><span class="pre">Tile</span></code> operator must be a constant (The value cannot directly or indirectly come from the input of the graph). Otherwise, the <code class="docutils literal notranslate"><span class="pre">None</span></code> data will be obtained during graph composition because the graph input is transferred only during graph execution and the input data cannot be obtained during graph composition. For the detailed imformation, refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/r1.10/note/static_graph_syntax_support.html">Static Graph Syntax Support</a>.</p>
<br/>
<p><font size=3><strong>Q: When conv2d is set to (3,10), Tensor [2,2,10,10] and it runs on Ascend on ModelArts, the error message <code class="docutils literal notranslate"><span class="pre">FM_W+pad_left+pad_right-KW&gt;=strideW</span></code> is displayed. However, no error message is displayed when it runs on a CPU. What should I do?</strong></font></p>
<p>A: TBE (Tensor Boost Engine) operator is Huawei’s self-developed Ascend operator development tool, which is extended on the basis of the TVM framework to develop custom operators. The above problem is the limitation of this TBE operator, and the width of x must be greater than the width of the kernel. The CPU operator does not have this restriction, so no error is reported.</p>
<br/>
<p><font size=3><strong>Q: Has MindSpore implemented the anti-pooling operation similar to <code class="docutils literal notranslate"><span class="pre">nn.MaxUnpool2d</span></code>?</strong></font></p>
<p>A: Currently, MindSpore does not provide anti-pooling APIs but you can customize the operator to implement the operation. For details, refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r1.10/operation/op_custom.html">Customize Operators</a>.</p>
<br/>
<p><font size=3><strong>Q: What should I do if other operations can not be performed on Ascend environment when training a model？</strong></font></p>
<p>A: It may because the computer recourses if fulled when operators compilation. Try to use the environment variable <code class="docutils literal notranslate"><span class="pre">MS_BUILD_PROCESS_NUM</span></code> to reduce the parallel number of operator compilation. For specific configuration instructions, see <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r1.10/env/env_var_list.html">Environment Variables</a>.</p>
<br/>
<p><font size=3><strong>Q: The performance of some operators can not up to standard even though tuned by the operator tuning tool, what should I do？</strong></font></p>
<p>A: In this case,</p>
<ol class="arabic simple">
<li><p>Make sure if these operators are fusion operators, and then suing the environment variable <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">MS_DEV_DISABLE_PREBUILD=True</span></code> to close the operator fusion. The operator pre-compiling may change the value of operator’s attribute <code class="docutils literal notranslate"><span class="pre">fusion_type</span></code>, the attr will affect the fusion of operator. The performance of the fused operator is not necessarily better than that of small operator.</p></li>
<li><p>If these operators are not fusion operators, using the environment variable <code class="docutils literal notranslate"><span class="pre">MS_COMPILER_OP_LEVEL</span></code> to generate the operator debug info, and then ask the operator developer for help. For specific configuration instructions, see <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r1.10/env/env_var_list.html">Environment Variables</a>.</p></li>
</ol>
<br/>
<p><font size=3><strong>Q: What can I do if the error message <code class="docutils literal notranslate"><span class="pre">Pynative</span> <span class="pre">run</span> <span class="pre">op</span> <span class="pre">ExpandDims</span> <span class="pre">failed</span></code> is displayed when the ExpandDims operator is used? The code is as follows:</strong></font></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">GRAPH_MODE</span><span class="p">,</span><span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">)</span>
<span class="n">input_tensor</span><span class="o">=</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]]),</span><span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">expand_dims</span><span class="o">=</span><span class="n">ops</span><span class="o">.</span><span class="n">ExpandDims</span><span class="p">()</span>
<span class="n">output</span><span class="o">=</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>A: The problem is that the Graph mode is selected but the PyNative mode is used. As a result, an error is reported. MindSpore supports the following running modes which are optimized in terms of debugging or running:</p>
<ul class="simple">
<li><p>PyNative mode: dynamic graph mode. In this mode, operators in the neural network are delivered and executed one by one, facilitating the compilation and debugging of the neural network model.</p></li>
<li><p>Graph mode: static graph mode or graph mode. In this mode, the neural network model is compiled into an entire graph and then delivered for execution. This mode uses technologies such as graph optimization to improve the running performance and facilitates large-scale deployment and cross-platform running.</p></li>
</ul>
<br/>
<p><font size=3><strong>Q: Ascend backend error: <code class="docutils literal notranslate"><span class="pre">AI</span> <span class="pre">CORE</span></code> and <code class="docutils literal notranslate"><span class="pre">AI</span> <span class="pre">CPU</span></code> can not find a valid <code class="docutils literal notranslate"><span class="pre">kernel</span> <span class="pre">info</span></code> when the Kernel Select Failed, how to locate?</strong></font></p>
<p>A: The <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> backend operators can be divided into AI CORE operators and AI CPU operators. Some operators are supported by AI CORE, some operators are supported by AI CPU, and some operators are supported by AI CORE and AI CPU at the same time. According to the error message:</p>
<ol class="arabic simple">
<li><p>If the <code class="docutils literal notranslate"><span class="pre">AI</span> <span class="pre">CORE</span></code> operator’s candidates list is empty, it may be that all operator information failed to pass the verification in the <code class="docutils literal notranslate"><span class="pre">check</span> <span class="pre">support</span></code> stage. You can search the keyword <code class="docutils literal notranslate"><span class="pre">CheckSupport</span></code> in the log to find the reason for the failure. Modify the shape or data type according to the specific information, or ask the developer to further locate the problem.</p></li>
<li><p>If the <code class="docutils literal notranslate"><span class="pre">AI</span> <span class="pre">CPU</span></code> candidate operator information is not empty, or the candidate operator information of <code class="docutils literal notranslate"><span class="pre">AI</span> <span class="pre">CORE</span></code> and <code class="docutils literal notranslate"><span class="pre">AI</span> <span class="pre">CPU</span></code> are both not empty, it may be that the given input data type was not in the candidate list and was filtered out in the selection stage. Try to modify the input data type of the operator according to the candidate list.</p></li>
</ol>
<p>You can select a proper mode and writing method to complete the training by referring to the <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.10/advanced/compute_graph/mode.html">official website tutorial</a>.</p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="network_compilation.html" class="btn btn-neutral float-left" title="Network Compilation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="usage_migrate_3rd.html" class="btn btn-neutral float-right" title="Migration from a Third-party Framework" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>