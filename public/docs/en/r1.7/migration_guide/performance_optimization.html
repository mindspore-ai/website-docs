<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Performance Profiling &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/training.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Inference Execution" href="inference.html" />
    <link rel="prev" title="Network Debugging" href="neural_network_debug.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../design/technical_white_paper.html">Technical White Paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/gradient.html">MindSpore Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/graph_kernel_fusion.html">Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/second_order_optimizer.html">Second Order Optimizer</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.7/training_visual_design.html">Design of Visualization↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Note</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/benchmark.html">Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/network_list.html">Network List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/operator_list.html">Operator List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/syntax_list.html">Syntax Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/env_var_list.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping.html">API Mapping</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.audio.html">mindspore.dataset.audio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.transformer.html">mindspore.nn.transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.functional.html">mindspore.ops.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.parallel.html">mindspore.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.parallel.nn.html">mindspore.parallel.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.profiler.html">mindspore.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.boost.html">mindspore.boost (experimental)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/en/r1.7/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="preparation.html">Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="script_analysis.html">Network Script Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="script_development.html">Network Script Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="neural_network_debug.html">Network Debugging</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Performance Profiling</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#quick-start">Quick Start</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#case-1-long-step-interval">Case 1: Long Step Interval</a></li>
<li class="toctree-l3"><a class="reference internal" href="#case-2-long-forward-propagation-interval">Case 2: Long Forward Propagation Interval</a></li>
<li class="toctree-l3"><a class="reference internal" href="#case-3-optimize-the-step-tail">Case 3: Optimize The Step Tail</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#faq">FAQ</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#startup-failure">Startup Failure</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="inference.html">Inference Execution</a></li>
<li class="toctree-l1"><a class="reference internal" href="sample_code.html">Network Migration Debugging Example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/distributed_configure.html">Distributed Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Performance Profiling</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/migration_guide/performance_optimization.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="performance-profiling">
<h1>Performance Profiling<a class="headerlink" href="#performance-profiling" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.7/docs/mindspore/source_en/migration_guide/performance_optimization.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.7/resource/_static/logo_source_en.png"></a></p>
<p>Profiler provides performance tuning ability for MindSpore, and provides easy-to-use and rich debugging functions in operator performance, data processing performance, etc., helping users quickly locate and solve performance problems.</p>
<p>This chapter introduces the common methods and cases of performance tuning, as well as the solutions of some common problems.</p>
<section id="quick-start">
<h2>Quick Start<a class="headerlink" href="#quick-start" title="Permalink to this headline"></a></h2>
<p>Please refer to the tutorials for the function introduction and instructions of MindSpore Profiler.</p>
<p><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.7/performance_profiling_ascend.html">Performance Profiling（Ascend）</a></p>
<p><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.7/performance_profiling_gpu.html">Performance Profiling（GPU）</a></p>
<p><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.7/performance_profiling_of_cluster.html">Cluster Performance Profiling</a></p>
<p>This section will introduce the common use of MindSpore Profiler through three typical cases.</p>
<section id="case-1-long-step-interval">
<h3>Case 1: Long Step Interval<a class="headerlink" href="#case-1-long-step-interval" title="Permalink to this headline"></a></h3>
<p>We run ResNet50 training script in MindSpore <a class="reference external" href="https://gitee.com/mindspore/models/tree/r1.7">ModelZoo</a> with batch size set to 32, and we find that each step cost almost 90ms, with a poor performance.
As we observed on the MindInsight UI page, the step interval in the step trace is too long, which may indicate that data is the performance bottleneck.</p>
<p><img alt="long_step_interval" src="../_images/profiler_case1_long_step_interval.png" /></p>
<p><em>Figure 1: Long Step Interval in Step Trace</em></p>
<p>Looking at the iteration gap tab in the data preparation details page, we observed that the data queue has more data in the early stage, and the number of later data becomes 0, because the loading and augmentment of the dataset has begun in the early stage of the graph compilation stage, and multiple pieces of data are cached in the queue.</p>
<p>After the normal training begins in the later stage, the data in the queue is consumed faster than the speed of production, so the data queue gradually becomes empty, indicating that the data becomes a bottleneck at this time. The same is true for observing host queues.</p>
<p>With comprehensive analysis, during normal training, data processing is a performance bottleneck. Therefore, you need to go to the data processing tab in the data preparation details page to see the specific issue.</p>
<p><img alt="dataset_process_step_interval" src="../_images/profiler_case1_data_processing_step_interval.png" /></p>
<p><em>Figure 2: Data Preparation Details – Step Interval</em></p>
<p>By observing the <code class="docutils literal notranslate"><span class="pre">queue</span> <span class="pre">relationship</span> <span class="pre">between</span> <span class="pre">operators</span></code> in the Data Processing tab, we find that the queue usage of the <code class="docutils literal notranslate"><span class="pre">Queue_3</span></code> and later is low, that is, the speed <code class="docutils literal notranslate"><span class="pre">MapOp_3</span></code> of production data as a producer is slower, so we can determine that there is still room for optimization of the performance of <code class="docutils literal notranslate"><span class="pre">MapOp_3</span></code>, and try to optimize the performance of the operator.</p>
<p><img alt="data_processing" src="../_images/profiler_case1_dataset_processing.png" /></p>
<p><em>Figure 3: Data Preparation Details – Data Processing</em></p>
<p>We can refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r1.7/dataset/optimize.html">Optimizing the Data Processing</a> to adjust dataset operators to improve dataset performance.</p>
<p>We find that the num_parallel_workers parameter of map operator is 1(default value) by observing the code part of data processing in ResNet50, and code is shown below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">do_train</span><span class="p">:</span>
    <span class="n">trans</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">C</span><span class="o">.</span><span class="n">RandomCropDecodeResize</span><span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.08</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">1.333</span><span class="p">)),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
    <span class="p">]</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">trans</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">C</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
    <span class="p">]</span>

<span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">trans</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Therefore we try to increase the num_parallel_workers parameter to 12 and run training script again. Optimization code is shown below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">trans</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
<p>By observing the step trace on the MindInsight performance analysis page, you can see that the step interval is shortened from 72.8ms to 0.25ms, and each step time is shortened from 90ms to 18.07ms.</p>
<p><img alt="short_step_interval" src="../_images/profiler_case1_short_step_interval.png" /></p>
<p><em>Figure 4: Step Interval is Shorten</em></p>
</section>
<section id="case-2-long-forward-propagation-interval">
<h3>Case 2: Long Forward Propagation Interval<a class="headerlink" href="#case-2-long-forward-propagation-interval" title="Permalink to this headline"></a></h3>
<p>We run VGG16 inference script in MindSpore <a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.7/README.md#">ModelZoo</a> , and each step cost almost 113.79ms, with a poor performance.</p>
<p>As we observed on the MindInsight UI page, the forward propagation in the step trace is too long, which may indicate that operators performance can be optimized. In a single card training or inference process, the forward time consumption is usually considered whether there is a operator that can be optimized for the time consumption.</p>
<p><img alt="long_fp_bp" src="../_images/profiler_case2_long_fp_bp.png" /></p>
<p><em>Figure 5: Long FP interval in Step Trace</em></p>
<p>Open the details page of Operator Time Consumption Ranking, and we find that MatMul operator is time-consuming in the operator details page.</p>
<p><img alt="operator_details" src="../_images/profiler_case2_operator_details.png" /></p>
<p><em>Figure 6: Finding operators that can be optimized via the details page of Operator Time Consumption Ranking</em></p>
<p>For Operator Time Consumption optimization, usually float16 type with the less computating amount can be used to improve operator performance if there is no difference in accuracy between float16 and float32 type. We can refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r1.7/others/mixed_precision.html">Enabling Mixed Precision</a> to improve operators performance.</p>
<p>Optimization code is shown below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="o">...</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">vgg16</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">phase</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
<span class="n">network</span><span class="o">.</span><span class="n">add_flags_recursive</span><span class="p">(</span><span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>After the float16 format is set, the inference script is run. From the MindInsight performance analysis page to observe the step trace, we can see that the forward propagation interval is shorten from 82.45ms to 16.89ms and each step time consumption is shortened, which is shown as the following picture:</p>
<p><img alt="short_fp" src="../_images/profiler_case2_short_fp.png" /></p>
<p><em>Figure 7: FP interval is shorten from 82.45ms to 16.89ms</em></p>
</section>
<section id="case-3-optimize-the-step-tail">
<h3>Case 3: Optimize The Step Tail<a class="headerlink" href="#case-3-optimize-the-step-tail" title="Permalink to this headline"></a></h3>
<p>We run ResNet50 training script with 8 processes in MindSpore <a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.7/README.md#">ModelZoo</a> , set batch size to 32, and each step cost about 23.6ms. We still want to improve each step time consumption.</p>
<p>As we observed the step trace on the MindInsight UI page, step interval and FP/BP interval can not be improved more, so we try to optimize step tail.</p>
<p><img alt="long_step_tail" src="../_images/profiler_case3_long_step_tail.png" /></p>
<p><em>Figure 8: Step Trace with Long Step Tail</em></p>
<p>Step Tail duration contains AllReduce gradient synchronization, parameter update and other operations. Normally, AllReduce gradient synchronization waits until all the inverse operators are finished, i.e., all the gradients of all weights are computed before synchronizing the gradients of all machines at once. With AllReduce tangent, we can synchronize the gradients of some weights as soon as they are computed, so that the gradient synchronization and the gradient computation of the remaining operators can be performed in parallel, hiding this part of the AllReduce gradient synchronization time.</p>
<p>The tangent strategy is usually a manual attempt to find an optimal solution (supporting slicing greater than two segments). As an example, ResNet50 network has 160 weights, and [85, 160] indicates that the gradient synchronization is performed immediately after the gradient is calculated for the 0th to 85th weights, and the gradient synchronization is performed after the gradient is calculated for the 86th to 160th weights. Here there are two segments, therefore the gradient synchronization is required to perform twice.</p>
<p>Optimization code is shown below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">resnet50_imagenet2012_config.yaml</span> <span class="kn">import</span> <span class="n">config</span>
<span class="o">...</span>

<span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">net_name</span> <span class="o">==</span> <span class="s2">&quot;resnet50&quot;</span> <span class="ow">or</span> <span class="n">config</span><span class="o">.</span><span class="n">net_name</span> <span class="o">==</span> <span class="s2">&quot;se-resnet50&quot;</span><span class="p">:</span>
    <span class="c1"># AllReduce split</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">all_reduce_fusion_config</span><span class="o">=</span><span class="p">[</span><span class="mi">85</span><span class="p">,</span> <span class="mi">160</span><span class="p">])</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># Another split stratety</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">all_reduce_fusion_config</span><span class="o">=</span><span class="p">[</span><span class="mi">180</span><span class="p">,</span> <span class="mi">313</span><span class="p">])</span>
<span class="n">init</span><span class="p">()</span>
</pre></div>
</div>
<p>We run ResNet50 8P script again after AllReduce is sliced. The step trace is observed in the MindInsight performance analysis page, and the step tail is shorten from 6.15ms to 4.20ms. The figure is shown in the following:</p>
<p><img alt="short_step_tail" src="../_images/profiler_case3_short_step_tail.png" /></p>
<p><em>Figure 9: Step Tail is shorten from 6.15ms to 4.20ms</em></p>
</section>
</section>
<section id="faq">
<h2>FAQ<a class="headerlink" href="#faq" title="Permalink to this headline"></a></h2>
<section id="startup-failure">
<h3>Startup Failure<a class="headerlink" href="#startup-failure" title="Permalink to this headline"></a></h3>
<p>If you encounter the error of startup failure, you can check whether you encountered one of the following situations:</p>
<ul class="simple">
<li><p>There is no space left in the system, or the remaining space is too small to run profiling tool.</p></li>
<li><p>Mismatched versions of MindSpore and Ascend AI processor software package.</p></li>
</ul>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="neural_network_debug.html" class="btn btn-neutral float-left" title="Network Debugging" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="inference.html" class="btn btn-neutral float-right" title="Inference Execution" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>