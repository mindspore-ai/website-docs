

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Data Processing &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/training.js"></script>
        
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Implement Problem" href="implement_problem.html" />
    <link rel="prev" title="Installation" href="installation.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/auto_gradient.html">Functional Differential Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/all_scenarios.html">Full-scenarios Unification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/thor.html">Second Order Optimizer</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r2.0.0-alpha/training_visual_design.html">Design of Visualization↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/benchmark.html">Benchmarks</a></li>
<li class="toctree-l1"><a class="reference external" href="https://gitee.com/mindspore/models/blob/r2.0.0-alpha/README.md#table-of-contents">Network List↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/operator_list.html">API List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/syntax_list.html">Syntax Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.transformer.html">mindspore.nn.transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/en/r2.0.0-alpha/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/tensorflow_api_mapping.html">TensorFlow and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/enveriment_preparation.html">Environment Preparation and Information Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/model_development/model_development.html">Constructing MindSpore Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/faq.html">FAQs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/typical_api_comparision.html">Differences Between MindSpore and PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/use_third_party_op.html">Using Third-party Operator Libraries Based on Customized Interfaces</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_configure.html">Distributed Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Data Processing</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/faq/data_processing.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="data-processing">
<h1>Data Processing<a class="headerlink" href="#data-processing" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r2.0.0-alpha/docs/mindspore/source_en/faq/data_processing.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.0.0-alpha/resource/_static/logo_source_en.png"></a></p>
<p><font size=3><strong>Q: How do I offload data if I do not use high-level APIs?</strong></font></p>
<p>A: You can implement by referring to the <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r2.0.0-alpha/tests/st/data_transfer/test_tdt_data_transfer.py">test_tdt_data_transfer.py</a> example of the manual offloading mode without using the <code class="docutils literal notranslate"><span class="pre">model.train</span></code> API. Currently, the GPU-based and Ascend-based hardware is supported.</p>
<br/>
<p><font size=3><strong>Q: In the process of using <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> to process data, the memory consumption is high. How to optimize it?</strong></font></p>
<p>A: You can refer to the following steps to reduce the memory occupation, which may also reduce the efficiency of data processing.</p>
<ol class="arabic simple">
<li><p>Before defining the dataset <code class="docutils literal notranslate"><span class="pre">**Dataset</span></code> object, set the prefetch size of <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>  data processing, <code class="docutils literal notranslate"><span class="pre">ds.config.set_prefetch_size(2)</span></code>.</p></li>
<li><p>When defining the <code class="docutils literal notranslate"><span class="pre">**Dataset</span></code> object, set its parameter <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> as 1.</p></li>
<li><p>If you further use <code class="docutils literal notranslate"><span class="pre">.map(...)</span></code> operation on <code class="docutils literal notranslate"><span class="pre">**Dataset</span></code> object, you can set <code class="docutils literal notranslate"><span class="pre">.map(...)</span></code> operation’s parameter <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> as 1.</p></li>
<li><p>If you further use <code class="docutils literal notranslate"><span class="pre">.batch(...)</span></code> operation on <code class="docutils literal notranslate"><span class="pre">**Dataset</span></code> object, you can set <code class="docutils literal notranslate"><span class="pre">.batch(...)</span></code> operation’s parameter <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> as 1.</p></li>
<li><p>If you further use <code class="docutils literal notranslate"><span class="pre">.shuffle(...)</span></code> operation on <code class="docutils literal notranslate"><span class="pre">**Dataset</span></code> object, you can reduce the parameter <code class="docutils literal notranslate"><span class="pre">buffer_size</span></code>.</p></li>
</ol>
<br/>
<p><font size=3><strong>Q: In the process of using <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> to process data, the CPU occupation is high which shows that sy occupation is high and us occupation is low. How to optimize it?</strong></font></p>
<p>A: You can refer to the following steps to reduce CPU consumption (mainly due to resource competition between third-party library multithreading and data processing multithreading) and further improve performance.</p>
<ol class="arabic simple">
<li><p>If there is a <code class="docutils literal notranslate"><span class="pre">cv2</span></code> operation of opencv in the data processing, use <code class="docutils literal notranslate"><span class="pre">cv2.setNumThreads(2)</span></code> to set the number of <code class="docutils literal notranslate"><span class="pre">cv2</span></code> global threads.</p></li>
<li><p>If there is a <code class="docutils literal notranslate"><span class="pre">numpy</span></code> operation in the data processing, use <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">OPENBLAS_NUM_THREADS=1</span></code> to set the number of <code class="docutils literal notranslate"><span class="pre">OPENBLAS</span></code> threads.</p></li>
<li><p>If there is a <code class="docutils literal notranslate"><span class="pre">numba</span></code> operation in the data processing, use <code class="docutils literal notranslate"><span class="pre">numba.set_num_threads(1)</span></code> to set the number of threads for <code class="docutils literal notranslate"><span class="pre">numba</span></code>.</p></li>
</ol>
<br/>
<p><font size=3><strong>Q:  Why there is no difference between the parameter <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> in <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>, and <code class="docutils literal notranslate"><span class="pre">shuffle=True</span></code> and <code class="docutils literal notranslate"><span class="pre">shuffle=False</span></code>  when the task is run?</strong></font></p>
<p>A: If <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> is enabled, the input <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> must support random access (for example, the user-defined <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> has the <code class="docutils literal notranslate"><span class="pre">getitem</span></code> method). If data is returned in <code class="docutils literal notranslate"><span class="pre">yeild</span></code> mode in the user-defined <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>, random access is not supported. For details, see section <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.0.0-alpha/advanced/dataset.html">Loading Dataset Overview</a> in the tutorial.</p>
<br/>
<p><font size=3><strong>Q: How does <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> combine two <code class="docutils literal notranslate"><span class="pre">columns</span></code> into one <code class="docutils literal notranslate"><span class="pre">column</span></code>?</strong></font></p>
<p>A: You can perform the following operations to combine the two columns into one:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">combine</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">combine</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;data2&quot;</span><span class="p">],</span> <span class="n">output_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>Note: The <code class="docutils literal notranslate"><span class="pre">shapes</span></code>of the two <code class="docutils literal notranslate"><span class="pre">columns</span></code> are different. Therefore, you need to <code class="docutils literal notranslate"><span class="pre">flatten</span></code> them before combining.</p>
<br/>
<p><font size=3><strong>Q: Does <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> support <code class="docutils literal notranslate"><span class="pre">ds.PKSampler</span></code> sampling?</strong></font></p>
<p>A: The user-defined dataset<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> does not support <code class="docutils literal notranslate"><span class="pre">PKSampler</span></code> sampling logic. The main reason is that the customizing data operation is too flexible. The built-in <code class="docutils literal notranslate"><span class="pre">PKSampler</span></code> cannot be universal. Therefore, a message is displayed at the API layer, indicating that the operation is not supported. However, for <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>, you can easily define the required <code class="docutils literal notranslate"><span class="pre">Sampler</span></code> logic. That is, you can define specific <code class="docutils literal notranslate"><span class="pre">sampler</span></code> rules in the <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> function of the <code class="docutils literal notranslate"><span class="pre">ImageDataset</span></code> class and return the required data.</p>
<br/>
<p><font size=3><strong>Q: How does MindSpore load the existing pre-trained word vector?</strong></font></p>
<p>A: When defining EmbedingLookup or Embedding, you only need to transfer the pre-trained word vector and encapsulate the pre-trained word vector into a tensor as the initial value of EmbeddingLookup.</p>
<br/>
<p><font size=3><strong>Q: What is the difference between <code class="docutils literal notranslate"><span class="pre">c_transforms</span></code> and <code class="docutils literal notranslate"><span class="pre">py_transforms</span></code>? Which one is recommended?</strong></font></p>
<p>A: <code class="docutils literal notranslate"><span class="pre">c_transforms</span></code> is recommended. Its performance is better because it is executed only at the C layer.</p>
<p>Principle: The underlying layer of <code class="docutils literal notranslate"><span class="pre">c_transform</span></code> uses <code class="docutils literal notranslate"><span class="pre">opencv/jpeg-turbo</span></code> of the C version for data processing, and <code class="docutils literal notranslate"><span class="pre">py_transform</span></code> uses <code class="docutils literal notranslate"><span class="pre">Pillow</span></code> of the Python version for data processing.</p>
<p>Data augmentation APIs are unified in MindSpore 1.8. Transformations of <code class="docutils literal notranslate"><span class="pre">c_transforms</span></code> and <code class="docutils literal notranslate"><span class="pre">py_transforms</span></code> will be selected automatically due to input tensor type instead of importing them manually. <code class="docutils literal notranslate"><span class="pre">c_transforms</span></code> is set to default option since its performance is better. More details please refer to <a class="reference external" href="https://mindspore.cn/docs/en/r2.0.0-alpha/api_python/mindspore.dataset.transforms.html#module-mindspore.dataset.vision">Latest API doc and import note</a>.</p>
<br/>
<p><font size=3><strong>Q: A piece of data contains multiple images which have different widths and heights. I need to perform the <code class="docutils literal notranslate"><span class="pre">map</span></code> operation on the data in mindrecord format. However, the data I read from <code class="docutils literal notranslate"><span class="pre">record</span></code> is in <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> format. My <code class="docutils literal notranslate"><span class="pre">operations</span></code>  of data processing are for the image format. How can I preprocess the generated data in mindrecord format?</strong></font></p>
<p>A: You are advised to perform the following operations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#1 The defined schema is as follows: Among them, data1, data2, data3, ... These fields store your image, and only the binary of the image is stored here.</span>

<span class="n">cv_schema_json</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;int32&quot;</span><span class="p">},</span> <span class="s2">&quot;data1&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;bytes&quot;</span><span class="p">},</span> <span class="s2">&quot;data2&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;bytes&quot;</span><span class="p">},</span> <span class="s2">&quot;data3&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;bytes&quot;</span><span class="p">}}</span>

<span class="c1">#2 The organized data can be as follows, and then this data_list can be written by FileWriter.write_raw_data(...).</span>

<span class="n">data_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;1.jpg&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
<span class="n">image_bytes</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span>

<span class="n">data</span><span class="p">[</span><span class="s1">&#39;data1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_bytes</span>

<span class="n">f2</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;2.jpg&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
<span class="n">image_bytes2</span> <span class="o">=</span> <span class="n">f2</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">f2</span><span class="o">.</span><span class="n">close</span>

<span class="n">data</span><span class="p">[</span><span class="s1">&#39;data2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_bytes2</span>

<span class="n">f3</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;3.jpg&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
<span class="n">image_bytes3</span> <span class="o">=</span> <span class="n">f3</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">f3</span><span class="o">.</span><span class="n">close</span>

<span class="n">data</span><span class="p">[</span><span class="s1">&#39;data3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_bytes3</span>

<span class="n">data_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1">#3 Use MindDataset to load, then use the decode operation we provide to decode, and then perform subsequent processing.</span>

<span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">MindDataset</span><span class="p">(</span><span class="s2">&quot;mindrecord_file_name&quot;</span><span class="p">)</span>
<span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data1&quot;</span><span class="p">],</span> <span class="n">operations</span><span class="o">=</span><span class="n">vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data2&quot;</span><span class="p">],</span> <span class="n">operations</span><span class="o">=</span><span class="n">vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data3&quot;</span><span class="p">],</span> <span class="n">operations</span><span class="o">=</span><span class="n">vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">resize_op</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">)</span>
<span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">resize_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data1&quot;</span><span class="p">],</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data_set</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: When a customizing image dataset is converted to the mindrecord format, the data is in the <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> format and <code class="docutils literal notranslate"><span class="pre">shape</span></code> is [4,100,132,3], indicating four three-channel frames, and each value ranges from 0 to 255. However, when I view the data that is converted into the mindrecord format, I find that the <code class="docutils literal notranslate"><span class="pre">shape</span></code> is <code class="docutils literal notranslate"><span class="pre">[19800]</span></code> and the dimensions of the original data are all expanded as<code class="docutils literal notranslate"><span class="pre">[158400]</span></code>. Why?</strong></font></p>
<p>A: The value of <code class="docutils literal notranslate"><span class="pre">dtype</span></code> in <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> might be set to <code class="docutils literal notranslate"><span class="pre">int8</span></code>. The difference between <code class="docutils literal notranslate"><span class="pre">[158400]</span></code> and <code class="docutils literal notranslate"><span class="pre">[19800]</span></code> is eight times. You are advised to set <code class="docutils literal notranslate"><span class="pre">dtype</span></code> of <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> to <code class="docutils literal notranslate"><span class="pre">float64</span></code>.</p>
<br/>
<p><font size=3><strong>Q: I want to save the generated image, but the image cannot be found in the corresponding directory after the code is executed. Similarly, a dataset is generated in JupyterLab for training. During training, data can be read in the corresponding path, but the image or dataset cannot be found in the path. Why?</strong></font></p>
<p>A: The images or datasets generated by JumperLab are stored in Docker. The data downloaded by <code class="docutils literal notranslate"><span class="pre">moxing</span></code> can be viewed only in Docker during the training process. After the training is complete, the data is released with Docker. You can try to transfer the data that needs to be <code class="docutils literal notranslate"><span class="pre">download</span></code> to <code class="docutils literal notranslate"><span class="pre">obs</span></code> through <code class="docutils literal notranslate"><span class="pre">moxing</span></code> in the training task, and then download the data to the local host through <code class="docutils literal notranslate"><span class="pre">obs</span></code>.</p>
<br/>
<p><font size=3><strong>Q: How do I understand the <code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">model.train</span></code> of MindSpore?</strong></font></p>
<p>A: When <code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, data processing and network computing are performed in pipeline mode. That is, when data processing is performed step by step, after a <code class="docutils literal notranslate"><span class="pre">batch</span></code> of data is processed, the data is placed in a queue which is used to cache the processed data. Then, network computing obtains data from the queue for training. In this case, data processing and network computing are performed in <code class="docutils literal notranslate"><span class="pre">pipeline</span></code> mode. The entire training duration is the longest data processing/network computing duration.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code> is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, data processing and network computing are performed in serial mode. That is, after a <code class="docutils literal notranslate"><span class="pre">batch</span></code> of data is processed, it is transferred to the network for computation. After the computation is complete, the next <code class="docutils literal notranslate"><span class="pre">batch</span></code> of data is processed and transferred to the network for computation. This process repeats until the training is complete. The total time consumed for the training is the time consumed for data processing plus the time consumed for network computing.</p>
<br/>
<p><font size=3><strong>Q: Can MindSpore train image data of different sizes by batch?</strong></font></p>
<p>A: You can refer to the usage of YOLOv3 which contains the resizing of different images. For details about the script, see <a class="reference external" href="https://gitee.com/mindspore/models/blob/r2.0.0-alpha/official/cv/YOLOv3/src/yolo_dataset.py">yolo_dataset</a>.</p>
<br/>
<p><font size=3><strong>Q: Must data be converted into MindRecords when MindSpore is used for segmentation training?</strong></font></p>
<p>A: <a class="reference external" href="https://gitee.com/mindspore/models/blob/r2.0.0-alpha/research/cv/FCN8s/src/data/build_seg_data.py">build_seg_data.py</a> is the script of MindRecords generated by the dataset. You can directly use or adapt it to your dataset. Alternatively, you can use <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> to customize the dataset loading if you want to implement the dataset reading by yourself.</p>
<p><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.0.0-alpha/advanced/dataset.html">GenratorDataset example</a></p>
<p><a class="reference external" href="https://www.mindspore.cn/docs/en/r2.0.0-alpha/api_python/dataset/mindspore.dataset.GeneratorDataset.html#mindspore.dataset.GeneratorDataset">GeneratorDataset API description</a></p>
<br/>
<p><font size=3><strong>Q: When MindSpore performs multi-device training on the Ascend hardware platform, how does the user-defined dataset transfer data to different chip?</strong></font></p>
<p>A: When <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> is used, the <code class="docutils literal notranslate"><span class="pre">num_shards=num_shards</span></code> can be used. <code class="docutils literal notranslate"><span class="pre">shard_id=device_id</span></code> parameters can be used to control which shard of data is read by different devices. <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> and <code class="docutils literal notranslate"><span class="pre">__len__</span></code> are processed as full datasets.</p>
<p>An example is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Device 0:</span>
<span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="c1"># Device 1:</span>
<span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="c1"># Device 2:</span>
<span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="o">...</span>
<span class="c1"># Device 7:</span>
<span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: How do I build a multi-label MindRecord dataset for images?</strong></font></p>
<p>A: The data schema can be defined as follows:<code class="docutils literal notranslate"><span class="pre">cv_schema_json</span> <span class="pre">=</span> <span class="pre">{&quot;label&quot;:</span> <span class="pre">{&quot;type&quot;:</span> <span class="pre">&quot;int32&quot;,</span> <span class="pre">&quot;shape&quot;:</span> <span class="pre">[-1]},</span> <span class="pre">&quot;data&quot;:</span> <span class="pre">{&quot;type&quot;:</span> <span class="pre">&quot;bytes&quot;}}</span></code></p>
<p>Note: A label is an array of the numpy type, where label values 1, 1, 0, 1, 0, 1 are stored. These label values correspond to the same data, that is, the binary value of the same image.
For details, see <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.0.0-alpha/advanced/dataset/record.html#converting-dataset-to-mindrecord">Converting Dataset to MindRecord</a>.</p>
<br/>
<p><font size=3><strong>Q: What can I do if an error message <code class="docutils literal notranslate"><span class="pre">wrong</span> <span class="pre">shape</span> <span class="pre">of</span> <span class="pre">image</span></code> is displayed when I use a model trained by MindSpore to perform prediction on a <code class="docutils literal notranslate"><span class="pre">28</span> <span class="pre">x</span> <span class="pre">28</span></code> digital image made by myself with white text on a black background?</strong></font></p>
<p>A: The MNIST gray scale image dataset is used for MindSpore training. Therefore, when the model is used, the data must be set to a <code class="docutils literal notranslate"><span class="pre">28</span> <span class="pre">x</span> <span class="pre">28</span></code> gray scale image, that is, a single channel.</p>
<br/>
<p><font size=3><strong>Q: Can you introduce the data processing framework in MindSpore?</strong></font></p>
<p>A: MindSpore Dataset module makes it easy for users to define data preprocessing pipelines and transform samples efficiently with multiprocessing or multithreading. MindSpore Dataset also provides variable APIs for users to load and process datasets, more introduction please refer to <a class="reference external" href="https://mindspore.cn/docs/en/r2.0.0-alpha/api_python/mindspore.dataset.html#introduction-to-data-processing-pipeline">MindSpore Dataset</a>. If you want to further study the performance optimization of dataset pipeline, please read <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r2.0.0-alpha/dataset/optimize.html">Optimizing Data Processing</a>.</p>
<br/>
<p><font size=3><strong>Q: When an error message  that “TDT Push data into device Failed” is displayed during network training, how to locate the problem?</strong></font></p>
<p>A: Firstly, above error refers to failed sending data to the device through the training data transfer channel (TDT). Here are several possible reasons for this error. Therefore, the corresponding checking suggestions are given in the log. In detail:</p>
<ol class="arabic">
<li><p>Commonly, we will find the first error (the first ERROR level error) or error TraceBack thrown in the log, and try to find information that helps locate the cause of the error.</p></li>
<li><p><strong>When error raised in the graph compiling stage, as training has not started</strong> (for example, the loss has not been printed in the log), please check the error log if there are errors reported by the network related operators or the environment configuration resulted Errors (such as hccl.json is incorrect, resulted abnormal initialization of multi-card communication)</p></li>
<li><p><strong>When error raised during the training process</strong>, usually this is caused by the mismatch between the amount of data (batch number) has been sent and the amount of data (step number) required for network training. You can print and check the number of batches of an epoch with <code class="docutils literal notranslate"><span class="pre">get_dataset_size</span></code> interface，several possible reason are as follows:</p>
<ul>
<li><p>With checking the print times of loss to figure out that when data amount(trained steps) is just an integer multiple of the batches number in an epoch, there may be a processing existence problem in the data processing part involving Epoch processing, such as the following case:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_tuple_iteator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Here, if you want to return an iterator, num_epochs should be 1, but it is recommended to return dataset directly</span>
<span class="k">return</span> <span class="n">dataset</span>
</pre></div>
</div>
</li>
<li><p>The data processing performance is slow, and cannot keep up with the speed of network training. For this case, you can use the profiler tool and MindInsight to see if there is an obvious iteration gap, or manually iterating the dataset, and print the average single batch time if it is longer than the combined forward and backward time of the network. There is a high probability that the performance of the data processing part needs to be optimized if yes.</p></li>
<li><p>During the training process, the occurrence of abnormal data may resulted in exception, causing sending data failed. In this case, there will be other <code class="docutils literal notranslate"><span class="pre">ERROR</span></code> logs that shows which part of the data processing process is abnormal and checking advice. If it is not obvious, you can also try to find the abnormal data by iterating each data batch in the dataset (such as turning off shuffle, and using dichotomy).</p></li>
</ul>
</li>
<li><p><strong>When after training</strong> the log is printed (this is probably caused by forced release of resources), this error can be ignored.</p></li>
<li><p>If the specific cause cannot be located, please create issue or raise question to ask the module developers for help.</p></li>
</ol>
<br/>
<p><font size=3><strong>Q: Can the py_transforms and c_transforms operations be used together? If yes, how should I use them?</strong></font></p>
<p>A: To ensure high performance, you are not advised to use the py_transforms and c_transforms operations together. For details, see <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.0.0-alpha/advanced/dataset.html">Image Data Processing and Enhancement</a>. However, if the main consideration is to streamline the process, the performance can be compromised more or less. If you cannot use all the c_transforms operations, that is, corresponding certain c_transforms operations are not available, the py_transforms operations can be used instead. In this case, the two operations are used together.
Note that the c_transforms operation usually outputs numpy array, and the py_transforms operation outputs PIL Image. For details, check the operation description. The common method to use them together is as follows:</p>
<ul class="simple">
<li><p>c_transforms operation + ToPIL operation + py_transforms operation + ToTensor operation</p></li>
<li><p>py_transforms operation + ToTensor operation + c_transforms operation</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># example that using c_transforms and py_transforms operations together</span>
<span class="c1"># in following case: c_vision refers to c_transforms, py_vision refer to py_transforms</span>
<span class="kn">import</span> <span class="nn">mindspore.vision.c_transforms</span> <span class="k">as</span> <span class="nn">c_vision</span>
<span class="kn">import</span> <span class="nn">mindspore.vision.py_transforms</span> <span class="k">as</span> <span class="nn">py_vision</span>

<span class="n">decode_op</span> <span class="o">=</span> <span class="n">c_vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">()</span>

<span class="c1"># If input type is not PIL, then add ToPIL operation.</span>
<span class="n">transforms</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">py_vision</span><span class="o">.</span><span class="n">ToPIL</span><span class="p">(),</span>
    <span class="n">py_vision</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">375</span><span class="p">),</span>
    <span class="n">py_vision</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">]</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span><span class="n">transforms</span><span class="p">)</span>
<span class="n">data1</span> <span class="o">=</span> <span class="n">data1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">decode_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>
<span class="n">data1</span> <span class="o">=</span> <span class="n">data1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>From MindSpore 1.8, the code above can be simpler since we unify the APIs of data augmentation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.vision</span> <span class="k">as</span> <span class="nn">vision</span>

<span class="n">transforms</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span>         <span class="c1"># default to use c_transforms</span>
    <span class="n">vision</span><span class="o">.</span><span class="n">ToPIL</span><span class="p">(),</span>          <span class="c1"># switch to PIL backend</span>
    <span class="n">vision</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">375</span><span class="p">),</span>  <span class="c1"># use py_transforms</span>
<span class="p">]</span>

<span class="n">data1</span> <span class="o">=</span> <span class="n">data1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">transforms</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: Why is the error message “The data pipeline is not a tree (i.e., one node has 2 consumers)” displayed?</strong></font></p>
<p>A: The preceding error is usually caused by incorrect script writing. In normal cases, operations in the data processing pipeline are connected in sequence, for example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pipeline definition</span>
<span class="c1"># dataset1 -&gt; map -&gt; shuffle -&gt; batch</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">XXDataset</span><span class="p">()</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>However, in the following exception scenario, <code class="docutils literal notranslate"><span class="pre">dataset1</span></code> has two consumption nodes <code class="docutils literal notranslate"><span class="pre">dataset2</span></code> and <code class="docutils literal notranslate"><span class="pre">dataset3</span></code>. As a result, the direction of data flow from <code class="docutils literal notranslate"><span class="pre">dataset1</span></code> is undefined, thus the pipeline definition is invalid.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pipeline definition:</span>
<span class="c1"># dataset1 -&gt; dataset2 -&gt; map</span>
<span class="c1">#          |</span>
<span class="c1">#          --&gt; dataset3 -&gt; map</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">XXDataset</span><span class="p">()</span>
<span class="n">dataset2</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">***</span><span class="p">)</span>
<span class="n">dataset3</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">***</span><span class="p">)</span>
</pre></div>
</div>
<p>The correct format is as follows. dataset3 is obtained by performing data enhancement on dataset2 rather than dataset1.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset2</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">***</span><span class="p">)</span>
<span class="n">dataset3</span> <span class="o">=</span> <span class="n">dataset2</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">***</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: What is the API corresponding to DataLoader in MindSpore?</strong></font></p>
<p>A: If the DataLoader is considered as an API for receiving user-defined datasets, the GeneratorDataset in the MindSpore data processing API is similar to that in the DataLoader and can receive user-defined datasets. For details about how to use the GeneratorDataset, see the <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.0.0-alpha/advanced/dataset.html">Loading Dataset Overview</a>, and for details about the differences, see the <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.0.0-alpha/note/api_mapping/pytorch_api_mapping.html">API Mapping</a>.</p>
<br/>
<p><font size=3><strong>Q: How do I debug a user-defined dataset when an error occurs?</strong></font></p>
<p>A: Generally, a user-defined dataset is imported to GeneratorDataset. If the user-defined dataset is incorrectly pointed to, you can use some methods for debugging (for example, adding printing information and printing the shape and dtype of the return value). The intermediate processing result of a user-defined dataset is numpy array. You are not advised to use it together with the MindSpore network computing operator. In addition, for the user-defined dataset, such as MyDataset shown below, after initialization, you can directly perform the following inritations (to simplify debugging and analyze problems in the original dataset, you do not need to import GeneratorDataset). The debugging complies with common Python syntax rules.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Dataset</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">()</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">Dataset</span><span class="p">:</span>
   <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;item:&quot;</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: Can the data processing operation and network computing operator be used together?</strong></font></p>
<p>A: Generally, if the data processing operation and network computing operator are used together, the performance deteriorates. If the corresponding data processing operation is unavailable and the user-defined py_transforms operation is inappropriate, you can try to use the data processing operation and network computing operator together. Note that because the inputs required are different, the input of the data processing operation is Numpy array or PIL Image, but the input of the network computing operator must be MindSpore.Tensor.
To use these two together, ensure that the output format of the previous one is the same as the input format of the next. Data processing operations refer to APIs in mindspore.dataset module on the official website, for example, mindspore.dataset.vision.CenterCrop. Network computing operators include operators in the mindspore.nn and mindspore.ops modules.</p>
<br/>
<p><font size=3><strong>Q: Why is a .db file generated in MindRecord? What is the error reported when I load a dataset without a .db file?</strong></font></p>
<p>A: The .db file is the index file corresponding to the MindRecord file. If the .db file is missing, an error is reported when the total data volume of the dataset is obtained. The error message <code class="docutils literal notranslate"><span class="pre">MindRecordOp</span> <span class="pre">Count</span> <span class="pre">total</span> <span class="pre">rows</span> <span class="pre">failed</span></code> is displayed.</p>
<br/>
<p><font size=3><strong>Q: How to read image and perform Decode operation in user-defined Dataset?</strong></font></p>
<p>A: The user-defined Dataset is passed into GeneratorDataset, and after reading the image inside the interface (such as <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> function), it can directly return bytes type data, numpy array type array or numpy array that has been decoded, as shown below:</p>
<ul>
<li><p>Return bytes type data directly after reading the image</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ImageDataset</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_path</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data_path</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="c1"># use file open and read method</span>
        <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span>
        <span class="n">img_bytes</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="c1"># return bytes directly</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">img_bytes</span><span class="p">,</span> <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># data_path is a list of image file name</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">ImageDataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">),</span> <span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
<span class="n">decode_op</span> <span class="o">=</span> <span class="n">py_vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">()</span>
<span class="n">to_tensor</span> <span class="o">=</span> <span class="n">py_vision</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(</span><span class="n">output_type</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="p">[</span><span class="n">decode_op</span><span class="p">,</span> <span class="n">to_tensor</span><span class="p">],</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
</pre></div>
</div>
</li>
<li><p>Return numpy array after reading the image</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># In the above case, the __getitem__ function can be modified as follows, and the Decode operation is the same as the above use case</span>
<span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
    <span class="c1"># use np.fromfile to read image</span>
    <span class="n">img_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromfile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>

    <span class="c1"># return Numpy array directly</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">img_np</span><span class="p">,</span> <span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Perform Decode operation directly after reading the image</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># According to the above case, the __getitem__ function can be modified as follows to directly return the data after Decode. After that, there is no need to add Decode operation through the map operation.</span>
<span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
    <span class="c1"># use Image.Open to open file, and convert to RGC</span>
    <span class="n">img_rgb</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">Open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">index</span><span class="p">])</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">img_rgb</span><span class="p">,</span> <span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
<br/>
<p><font size=3><strong>Q: In the process of using <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> to process data, an error <code class="docutils literal notranslate"><span class="pre">RuntimeError:</span> <span class="pre">can't</span> <span class="pre">start</span> <span class="pre">new</span> <span class="pre">thread</span></code> is reported. How to solve it?</strong></font></p>
<p>A: The main reason is that the parameter <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> is configured too large while using <code class="docutils literal notranslate"><span class="pre">**Dataset</span></code>, <code class="docutils literal notranslate"><span class="pre">.map(...)</span></code> and <code class="docutils literal notranslate"><span class="pre">.batch(...)</span></code> and the number of user processes reaches the maximum. You can increase the range of the maximum number of user processes through <code class="docutils literal notranslate"><span class="pre">ulimit</span> <span class="pre">-u</span> <span class="pre">MAX_PROCESSES</span></code>, or reduce <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>.</p>
<br/>
<p><font size=3><strong>Q: In the process of using <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> to load data, an error <code class="docutils literal notranslate"><span class="pre">RuntimeError:</span> <span class="pre">Failed</span> <span class="pre">to</span> <span class="pre">copy</span> <span class="pre">data</span> <span class="pre">into</span> <span class="pre">tensor.</span></code> is reported. How to solve it?</strong></font></p>
<p>A: When the <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> is used to load Numpy array returned by Pyfunc, MindSpore performs conversion from the Numpy array to the MindSpore Tensor. If the memory pointed to by the Numpy array has been freed, a memory copy error may occur. An example is as shown below:</p>
<ul>
<li><p>Perform an in place conversion among Numpy array, MindSpore Tensor and Numpy array in <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> function. Tensor <code class="docutils literal notranslate"><span class="pre">tensor</span></code> and Numpy array <code class="docutils literal notranslate"><span class="pre">ndarray_1</span></code> share the same memory and Tensor <code class="docutils literal notranslate"><span class="pre">tensor</span></code> will go out of scope when the function exits, and the memory which is pointed to by Numpy array will be freed.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">class</span> <span class="nc">RandomAccessDataset</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="n">ndarray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">544</span><span class="p">,</span> <span class="mi">1056</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">ndarray</span><span class="p">)</span>
        <span class="n">ndarray_1</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">ndarray_1</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">8</span>

<span class="n">data1</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">RandomAccessDataset</span><span class="p">(),</span> <span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>

</pre></div>
</div>
</li>
<li><p>Ignore the cyclic conversion in the example above. When <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> function exits, Tensor <code class="docutils literal notranslate"><span class="pre">tensor</span></code> is freed, and the behavior of Numpy array <code class="docutils literal notranslate"><span class="pre">ndarray_1</span></code> that shares the same memory with <code class="docutils literal notranslate"><span class="pre">tensor</span></code> will become unpredictable. To avoid the issue, we can use the <code class="docutils literal notranslate"><span class="pre">deepcopy</span></code> function to apply for independent memory for the returned Numpy array <code class="docutils literal notranslate"><span class="pre">ndarray_2</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">class</span> <span class="nc">RandomAccessDataset</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="n">ndarray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">544</span><span class="p">,</span> <span class="mi">1056</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">ndarray</span><span class="p">)</span>
        <span class="n">ndarray_1</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
        <span class="n">ndarray_2</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">ndarray_1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ndarray_2</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">8</span>

<span class="n">data1</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">RandomAccessDataset</span><span class="p">(),</span> <span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>

</pre></div>
</div>
</li>
</ul>
<br/>
</section>


           </div>
           
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="installation.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="implement_problem.html" class="btn btn-neutral float-right" title="Implement Problem" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
</body>
</html>