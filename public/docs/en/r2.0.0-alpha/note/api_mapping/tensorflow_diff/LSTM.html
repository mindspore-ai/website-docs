

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Function Differences with tf.keras.layers.LSTM &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/js/training.js"></script>
        
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/auto_gradient.html">Functional Differential Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/all_scenarios.html">Full-scenarios Unification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/thor.html">Second Order Optimizer</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r2.0.0-alpha/training_visual_design.html">Design of Visualization↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark.html">Benchmarks</a></li>
<li class="toctree-l1"><a class="reference external" href="https://gitee.com/mindspore/models/blob/r2.0.0-alpha/README.md#table-of-contents">Network List↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../operator_list.html">API List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../syntax_list.html">Syntax Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.nn.transformer.html">mindspore.nn.transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/en/r2.0.0-alpha/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensorflow_api_mapping.html">TensorFlow and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/enveriment_preparation.html">Environment Preparation and Information Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/model_development/model_development.html">Constructing MindSpore Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/faq.html">FAQs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/typical_api_comparision.html">Differences Between MindSpore and PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/use_third_party_op.html">Using Third-party Operator Libraries Based on Customized Interfaces</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/distributed_configure.html">Distributed Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Function Differences with tf.keras.layers.LSTM</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/note/api_mapping/tensorflow_diff/LSTM.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="function-differences-with-tf-keras-layers-lstm">
<h1>Function Differences with tf.keras.layers.LSTM<a class="headerlink" href="#function-differences-with-tf-keras-layers-lstm" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r2.0.0-alpha/docs/mindspore/source_en/note/api_mapping/tensorflow_diff/LSTM.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.0.0-alpha/resource/_static/logo_source_en.png"></a></p>
<section id="tf-keras-layers-lstm">
<h2>tf.keras.layers.LSTM<a class="headerlink" href="#tf-keras-layers-lstm" title="Permalink to this headline"></a></h2>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>class tf.keras.layers.LSTM(
    units, activation=&#39;tanh&#39;, recurrent_activation=&#39;sigmoid&#39;,
    use_bias=True, kernel_initializer=&#39;glorot_uniform&#39;,
    recurrent_initializer=&#39;orthogonal&#39;,
    bias_initializer=&#39;zeros&#39;, unit_forget_bias=True,
    kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None,
    activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None,
    bias_constraint=None, dropout=0.0, recurrent_dropout=0.0,
    return_sequences=False, return_state=False, go_backwards=False, stateful=False,
    time_major=False, unroll=False, **kwargs
)(inputs, mask, training, initial_state) -&gt; Tensor
</pre></div>
</div>
<p>For more information, see <a class="reference external" href="https://tensorflow.google.cn/versions/r2.6/api_docs/python/tf/keras/layers/LSTM">tf.keras.layers.LSTM</a>.</p>
</section>
<section id="mindspore-nn-lstm">
<h2>mindspore.nn.LSTM<a class="headerlink" href="#mindspore-nn-lstm" title="Permalink to this headline"></a></h2>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>class mindspore.nn.LSTM(
    input_size,
    hidden_size,
    num_layers=1,
    has_bias=True,
    batch_first=False,
    dropout=0,
    bidirectional=False)(x, hx, seq_length) -&gt; Tensor
</pre></div>
</div>
<p>For more information, see <a class="reference external" href="https://mindspore.cn/docs/en/r2.0.0-alpha/api_python/nn/mindspore.nn.LSTM.html">mindspore.nn.LSTM</a>.</p>
</section>
<section id="differences">
<h2>Differences<a class="headerlink" href="#differences" title="Permalink to this headline"></a></h2>
<p>TensorFlow: When the parameters return_sequences and return_state are set, the output sequence and final state can be calculated based on the input sequence.</p>
<p>MindSpore: MindSpore can compute output sequences and final states based on input sequences and given initial states, and can implement multi-layer and bi-directional LSTM networks. However, it is not possible to specify some functions (such as activation function, regularization function, constraint function, etc.) in the computation process like TensorFlow, and the API of TensorFlow can only implement one-way one-layer LSTM networks, so it will lead to different shapes of the final state tensor between the two APIs.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Categories</p></th>
<th class="head"><p>Subcategories</p></th>
<th class="head"><p>TensorFlow</p></th>
<th class="head"><p>MindSpore</p></th>
<th class="head"><p>Differences</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Parameters</p></td>
<td><p>Parameter 1</p></td>
<td><p>units</p></td>
<td><p>hidden_size</p></td>
<td><p>Same function, different parameter names</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 2</p></td>
<td><p>activation</p></td>
<td><p>-</p></td>
<td><p>Specify the activation function to be used. Default value: tanh. MindSpore does not have this parameter, but the same activation function is used by default during the calculation</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Parameter 3</p></td>
<td><p>recurrent_activation</p></td>
<td><p>-</p></td>
<td><p>Specify the activation function used in the recursion step. Default value: sigmoid. MindSpore does not have this parameter, but the same activation function is used by default during the calculation</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 4</p></td>
<td><p>use_bias</p></td>
<td><p>has_bias</p></td>
<td><p>Same function, different parameter names</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Parameter 5</p></td>
<td><p>kernel_initializer</p></td>
<td><p>-</p></td>
<td><p>Initialize the kernel weight matrix for the linear transformation of the input. Default value: glorot_uniform. MindSpore does not have this parameter.</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 6</p></td>
<td><p>recurrent_initializer</p></td>
<td><p>-</p></td>
<td><p>Initialize the weight matrix of recurrent_kernel for linear transformation of recursive states. Default value: orthogonal. MindSpore does not have this parameter</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Parameter 7</p></td>
<td><p>bias_initializer</p></td>
<td><p>-</p></td>
<td><p>Initialize the bias vector. Default value: zeros. MindSpore does not have this parameter.</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 8</p></td>
<td><p>unit_forget_bias</p></td>
<td><p>-</p></td>
<td><p>Select whether to add 1 to the offset of the forget gate at initialization. Default value: True. MindSpore does not have this parameter.</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Parameter 9</p></td>
<td><p>kernel_regularizer</p></td>
<td><p>-</p></td>
<td><p>The regularization function applied to the kernel weight matrix. Default value: None. MindSpore does not have this parameter.</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 10</p></td>
<td><p>recurrent_regularizer</p></td>
<td><p>-</p></td>
<td><p>The regularization function applied to the recurrent_kernel weight matrix. Default value: None. MindSpore does not have this parameter.</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Parameter 11</p></td>
<td><p>bias_regularizer</p></td>
<td><p>-</p></td>
<td><p>The regularization function applied to the bias vector. Default value: None. MindSpore does not have this parameter.</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 12</p></td>
<td><p>activity_regularizer</p></td>
<td><p>-</p></td>
<td><p>The regularization function applied to the output of the activated layer. Default value: None. MindSpore does not have this parameter</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Parameter 13</p></td>
<td><p>kernel_constraint</p></td>
<td><p>-</p></td>
<td><p>Constraint function applied to the kernel weight matrix. Default value: None. MindSpore does not have this parameter</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 14</p></td>
<td><p>recurrent_constraint</p></td>
<td><p>-</p></td>
<td><p>Constraint function applied to the recurrent_kernel weight matrix. Default value: None. MindSpore does not have this parameter</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Parameter 15</p></td>
<td><p>bias_constraint</p></td>
<td><p>-</p></td>
<td><p>Constraint function applied to the weight vector. Default value: None. MindSpore does not have this parameter</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 16</p></td>
<td><p>dropout</p></td>
<td><p>dropout</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Parameter 17</p></td>
<td><p>recurrent_dropout</p></td>
<td><p>-</p></td>
<td><p>The dropout probability used in the recursive state. MindSpore uses dropout</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 18</p></td>
<td><p>return_sequences</p></td>
<td><p>-</p></td>
<td><p>Whether to return the last output in the output sequence or the complete sequence. Default value: False. MindSpore does not have this parameter, but defaults to True.</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Parameter 19</p></td>
<td><p>return_state</p></td>
<td><p>-</p></td>
<td><p>Whether to return the last state. Default value: False. MindSpore does not have this parameter, but defaults to True</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 20</p></td>
<td><p>go_backwards</p></td>
<td><p>-</p></td>
<td><p>Whether to reverse the input sequence and return the reverse sequence. Default value: False. MindSpore does not have this parameter.</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Parameter 21</p></td>
<td><p>stateful</p></td>
<td><p>-</p></td>
<td><p>Whether to use the last state of each sample at index i in the batch as the initial state of the samples at index i in the next batch. Default value: False. MindSpore does not have this parameter.</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 22</p></td>
<td><p>time_major</p></td>
<td><p>-</p></td>
<td><p>Selects the shape format of the input and output tensor. If True, the input and output will be [timesteps, batch, feature], while in the case of False, it will be [batch, timesteps, feature]. Default value: False. MindSpore does not have this parameter, but by default both shapes are possible</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Parameter 23</p></td>
<td><p>unroll</p></td>
<td><p>-</p></td>
<td><p>If True, the network will be expanded, otherwise a symbolic loop will be used. Default value: False. MindSpore does not have this parameter.</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 24</p></td>
<td><p>**kwargs</p></td>
<td><p>-</p></td>
<td><p>Not involved</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Parameter 25</p></td>
<td><p>-</p></td>
<td><p>input_size</p></td>
<td><p>Automatically determine the input size. TensorFlow does not have this parameter</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 26</p></td>
<td><p>-</p></td>
<td><p>num_layers</p></td>
<td><p>Set the number of network layers. Default value: 1. TensorFlow does not have this parameter</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Parameter 27</p></td>
<td><p>-</p></td>
<td><p>batch_first</p></td>
<td><p>The first dimension of the default input is batch_size. TensorFlow does not have this parameter</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Parameter 28</p></td>
<td><p>-</p></td>
<td><p>bidirectional</p></td>
<td><p>The function is to set the bidirectional LSTM. TensorFlow does not have this parameter</p></td>
</tr>
<tr class="row-even"><td><p>Inputs</p></td>
<td><p>Input 1</p></td>
<td><p>inputs</p></td>
<td><p>x</p></td>
<td><p>Same function, different parameter names</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Input 2</p></td>
<td><p>mask</p></td>
<td><p>-</p></td>
<td><p>A binary tensor of the shape [batch, timesteps] indicating whether the given time step should be masked or not (optional, default is None). A single True entry indicates that the corresponding time step should be utilized, while a False entry indicates that the corresponding time step should be ignored. MindSpore does not have this parameter</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Input 3</p></td>
<td><p>training</p></td>
<td><p>-</p></td>
<td><p>Python boolean, indicating whether layer should run in training mode or inference mode. This parameter is passed to the cell when the cell is called. This is only relevant when using dropout or recurrent_dropout (optional, default is None). MindSpore does not have this parameter</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Input 4</p></td>
<td><p>initial_state</p></td>
<td><p>hx</p></td>
<td><p>The initial state tensor list to be passed to the cell for the first call (optional, default is None, which will result in the creation of a zero-populated initial state tensor). The role in MindSpore is to give the initial state tensor</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Input 5</p></td>
<td><p>-</p></td>
<td><p>seq_length</p></td>
<td><p>Specify the sequence length of the input batch. TensorFlow does not have this parameter</p></td>
</tr>
</tbody>
</table>
<section id="code-example">
<h3>Code Example<a class="headerlink" href="#code-example" title="Permalink to this headline"></a></h3>
<blockquote>
<div><p>This API of TensorFlow generally defaults to a zero-padding tensor for the initial state tensor, so we can set MindSpore input state tensor to a zero tensor. In addition, TensorFlow API can only implement one layer of one-way LSTM network, and the shape of the output state is [batch_size, hidden_size], while the shape of MindSpore output state is [num_directions * num_layers, batch_size, hidden_size]. Therefore, we can take the default value of False for the parameter bidirectional of the MindSpore API, so that num_directions is 1. By taking the default value of 1 for the parameter num_layers as well, making the first dimension of MindSpore output state tensor shape 1, and then removing the first dimension with mindspore.ops.Squeeze, we can get the same result as TensorFlow API and achieve the same function.</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># TensorFlow</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="n">lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">whole_seq_output</span><span class="p">,</span> <span class="n">final_memory_state</span><span class="p">,</span> <span class="n">final_carry_state</span> <span class="o">=</span> <span class="n">lstm</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">whole_seq_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># (3, 5, 16)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">final_memory_state</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># (3, 16)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">final_carry_state</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># (3, 16)</span>

<span class="c1"># MindSpore</span>
<span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">h0</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span> <span class="o">*</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">c0</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span> <span class="o">*</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">hn</span><span class="p">,</span> <span class="n">cn</span><span class="p">)</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">h0</span><span class="p">,</span> <span class="n">c0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># (3, 5, 16)</span>
<span class="n">squeeze</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">hn_</span> <span class="o">=</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">hn</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">hn_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># (3, 16)</span>
<span class="n">cn_</span> <span class="o">=</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">cn</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cn_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># (3, 16)</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
</body>
</html>