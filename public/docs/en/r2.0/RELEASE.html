

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Release Notes &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script src="_static/js/training.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Feature Advice" href="faq/feature_advice.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/programming_paradigm.html">Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/auto_gradient.html">Functional Differential Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/all_scenarios.html">Full-scenarios Unification</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/glossary.html">Glossary</a></li>
</ul>
<p class="caption"><span class="caption-text">Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="note/benchmark.html">Benchmarks</a></li>
<li class="toctree-l1"><a class="reference external" href="https://gitee.com/mindspore/models/blob/r2.0/README.md#table-of-contents">Network List↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="note/operator_list.html">API List</a></li>
<li class="toctree-l1"><a class="reference internal" href="note/syntax_list.html">Syntax Support</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/en/r2.0/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
<li class="toctree-l1"><a class="reference internal" href="note/api_mapping/tensorflow_api_mapping.html">TensorFlow and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption"><span class="caption-text">Migration Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="migration_guide/overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="migration_guide/enveriment_preparation.html">Environment Preparation and Information Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="migration_guide/analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="migration_guide/model_development/model_development.html">Constructing MindSpore Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="migration_guide/debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="migration_guide/sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="migration_guide/faq.html">FAQs</a></li>
</ul>
<p class="caption"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Release Notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#mindspore-2-0-0-rc1-release-notes">MindSpore 2.0.0-rc1 Release Notes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#major-features-and-improvements">Major Features and Improvements</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#frontend">FrontEnd</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dataset">DataSet</a></li>
<li class="toctree-l4"><a class="reference internal" href="#autoparallel">AutoParallel</a></li>
<li class="toctree-l4"><a class="reference internal" href="#runtime">Runtime</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ascend">Ascend</a></li>
<li class="toctree-l4"><a class="reference internal" href="#profiler">Profiler</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dump">Dump</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#api-change">API Change</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#operator">operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="#deleted-apis">Deleted APIs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#backwards-incompatible-change">Backwards Incompatible Change</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#bug-fixes">Bug fixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#others">Others</a></li>
<li class="toctree-l3"><a class="reference internal" href="#contributors">Contributors</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Release Notes</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/RELEASE.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="release-notes">
<h1>Release Notes<a class="headerlink" href="#release-notes" title="Permalink to this headline">¶</a></h1>
<div class="section" id="mindspore-2-0-0-rc1-release-notes">
<h2>MindSpore 2.0.0-rc1 Release Notes<a class="headerlink" href="#mindspore-2-0-0-rc1-release-notes" title="Permalink to this headline">¶</a></h2>
<div class="section" id="major-features-and-improvements">
<h3>Major Features and Improvements<a class="headerlink" href="#major-features-and-improvements" title="Permalink to this headline">¶</a></h3>
<div class="section" id="frontend">
<h4>FrontEnd<a class="headerlink" href="#frontend" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>[BETA] Statement with “return”, “return None” and with no return of function are supported in <code class="docutils literal notranslate"><span class="pre">GRAPH_MODE</span></code>.</p></li>
<li><p>[BETA] Object with <code class="docutils literal notranslate"><span class="pre">list</span></code> type are supported in <code class="docutils literal notranslate"><span class="pre">GRAPH_MODE</span></code>.</p></li>
<li><p>[BETA] Statement with “raise” are supported in variable condition situation in <code class="docutils literal notranslate"><span class="pre">GRAPH_MODE</span></code>.</p></li>
<li><p>[STABLE] Functional call supports data sinking mode.</p></li>
<li><p>[BETA] The Transformer layer in nn module is added to provide easy-to-use Transformer APIs. Batch_size does not need to be defined. Dynamic seq_length is supported.</p></li>
</ul>
</div>
<div class="section" id="dataset">
<h4>DataSet<a class="headerlink" href="#dataset" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>[STABLE] In the Ascend environment，the timeout waiting time in data sink mode is adjusted to 1900s by default. This solves the problem that the GetNext operator may time out due to environment resource competition and large computing workload in data sinking mode.</p></li>
<li><p>[STABLE] MindRecord supports to query the schemas and number samples. MindRecord provides multi-process writing mode, allowing users to generate MindRecord data files in parallel.</p></li>
<li><p>[STABLE] The Dataset pipeline can process any Python object. For details, see <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.0/advanced/dataset/python_objects.html">Supporting Python Objects in Dataset Pipeline</a>.</p></li>
</ul>
</div>
<div class="section" id="autoparallel">
<h4>AutoParallel<a class="headerlink" href="#autoparallel" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>[STABLE] The strategies of whole parameters can be saved when saving strategy.</p></li>
<li><p>[STABLE] The Conv3D/MaxPool3D/AvgPool3D distributed operator is supported.</p></li>
<li><p>[STABLE] Support operator-level parallelism and optimizer-level parallelism under the PyNative with shard: parallel training and the Model API are decoupled to provide basic parallel expression capabilities.</p></li>
<li><p>[STABLE] Support operator-level parallelism, and optimizer-level parallelism under the Graph mode: parallel training and the Model API are decoupled to provide basic parallel expression capabilities.</p></li>
<li><p>[BETA] Supports customized distributed graph segmentation, improving the flexibility of distributed training.</p></li>
</ul>
</div>
<div class="section" id="runtime">
<h4>Runtime<a class="headerlink" href="#runtime" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>[STABLE] Control flow supports subgraph sink.</p></li>
<li><p>[STABLE] Support CUDA 11.6.</p></li>
<li><p>[STABLE] Support for operator selection and execution of List/Tuple/Scalar type kernel to match native Python expression.</p></li>
<li><p>[STABLE] Kernel that is not supported by hardware can automatically select CPU kernel.</p></li>
<li><p>[STABLE] Support heterogeneous execution within subgraph.</p></li>
</ul>
</div>
<div class="section" id="ascend">
<h4>Ascend<a class="headerlink" href="#ascend" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>[STABLE] Support overflow detection scheme and HCCL runtime overflow check.</p></li>
<li><p>[STABLE] Support dump of communication operators.</p></li>
</ul>
</div>
<div class="section" id="profiler">
<h4>Profiler<a class="headerlink" href="#profiler" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>[STABLE] Rich Profiler collection item configuration, users can collect performance data in more detail.</p></li>
</ul>
</div>
<div class="section" id="dump">
<h4>Dump<a class="headerlink" href="#dump" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>[BETA] Single card in PyNatvie mode supports operator overflow detection.</p></li>
<li><p>[BETA] Graph mode supports hccl operator dump.</p></li>
</ul>
</div>
</div>
<div class="section" id="api-change">
<h3>API Change<a class="headerlink" href="#api-change" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>[STABLE] Add computing APIs, such as MaxUnpool, ReplicationPad, and GaussianNLLLoss.
For details, visit <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.0/api_python/mindspore.html">https://www.mindspore.cn/docs/en/r2.0/api_python/mindspore.html</a>.</p></li>
<li><p>[STABLE] Extend inventory API functions, such as AvgPool, pad, norm, and interplate.</p></li>
</ul>
<div class="section" id="operator">
<h4>operator<a class="headerlink" href="#operator" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.AdaptiveAvgPool3D</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.AffineGrid</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Angle</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.BartlettWindow</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Bernoulli</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.BesselI0</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.BesselI1</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.BesselJ0</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.BesselJ1</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.BesselK0</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.BesselK0e</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.BesselK1</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.BesselK1e</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.BesselY0</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.BesselY1</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Bincount</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.BlackmanWindow</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.ChannelShuffle</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Cholesky</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Col2Im</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Complex</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.ComplexAbs</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Cross</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.CTCLossV2</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Cummin</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Diag</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Digamma</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Eig</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Expand</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Fmax</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Gcd</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Geqrf</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.GLU</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.GridSampler2D</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.GridSampler3D</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.HammingWindow</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Heaviside</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Hypot</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Igamma</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.IndexFill</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.InplaceIndexAdd</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.InplaceUpdateV2</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Lcm</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.LeftShift</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.LogicalXor</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Logit</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.LogSpace</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.LuUnpack</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.MatrixDiagPartV3</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.MatrixDiagV3</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.MatrixSetDiagV3</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.MaxPool3DWithArgmax</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.MaxUnpool2D</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.MaxUnpool3D</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.MultiMarginLoss</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.MultinomialWithReplacement</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Mvlgamma</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.NanToNum</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.NextAfter</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Orgqr</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Polygamma</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Qr</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.ResizeBilinearV2</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.RightShift</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.ScatterNdDiv</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.ScatterNdMul</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.SearchSorted</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Sinc</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Trace</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Tril</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.TrilIndices</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.TriuIndices</span></code>.</p></li>
<li><p>[BETA] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.UniqueConsecutive</span></code>.</p></li>
<li><p>[STABLE] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Cummax</span></code>.</p></li>
<li><p>[STABLE] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.FillV2</span></code>.</p></li>
<li><p>[STABLE] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.IsClose</span></code>.</p></li>
<li><p>[STABLE] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.MatrixSolve</span></code>.</p></li>
<li><p>[STABLE] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Median</span></code>.</p></li>
<li><p>[STABLE] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.MultilabelMarginLoss</span></code>.</p></li>
<li><p>[STABLE] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.NonZero</span></code>.</p></li>
<li><p>[STABLE] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Pdist</span></code>.</p></li>
<li><p>[STABLE] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Polar</span></code>.</p></li>
<li><p>[STABLE] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.RandomGamma</span></code>.</p></li>
<li><p>[STABLE] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.RandomPoisson</span></code>.</p></li>
<li><p>[STABLE] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.RandomShuffle</span></code>.</p></li>
<li><p>[STABLE] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Renorm</span></code>.</p></li>
<li><p>[STABLE] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.ScatterNdMax</span></code>.</p></li>
<li><p>[STABLE] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.ScatterNdMin</span></code>.</p></li>
<li><p>[STABLE] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Svd</span></code>.</p></li>
<li><p>[STABLE] Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.TripletMarginLoss</span></code>.</p></li>
</ul>
</div>
<div class="section" id="deleted-apis">
<h4>Deleted APIs<a class="headerlink" href="#deleted-apis" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">mindspore.compression</span></code> feature was deprecated at MindSpore 1.8 and is removed in this version.
The following <code class="docutils literal notranslate"><span class="pre">mindspore.nn.quant</span></code> interfaces are also removed simultaneously: <code class="docutils literal notranslate"><span class="pre">mindspore.nn.FakeQuantWithMinMaxObserver</span></code>, <code class="docutils literal notranslate"><span class="pre">mindspore.nn.Conv2dBnFoldQuantOneConv</span></code>, <code class="docutils literal notranslate"><span class="pre">mindspore.nn.Conv2dBnFoldQuant</span></code>, <code class="docutils literal notranslate"><span class="pre">mindspore.nn.Conv2dBnWithoutFoldQuant</span></code>, <code class="docutils literal notranslate"><span class="pre">mindspore.nn.Conv2dQuant</span></code>, <code class="docutils literal notranslate"><span class="pre">mindspore.nn.DenseQuant</span></code>, <code class="docutils literal notranslate"><span class="pre">mindspore.nn.ActQuant</span></code>, <code class="docutils literal notranslate"><span class="pre">mindspore.nn.TensorAddQuant</span></code>, <code class="docutils literal notranslate"><span class="pre">mindspore.nn.ActQuant</span></code>, <code class="docutils literal notranslate"><span class="pre">mindspore.nn.MulQuant</span></code>. Please use <a class="reference external" href="https://gitee.com/mindspore/golden-stick">MindSpore Golden Stick</a> instead to implement QuantAwareTraining in MindSpore.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">mindspore.dataset.close_pool</span></code>, <code class="docutils literal notranslate"><span class="pre">mindspore.dataset.to_device</span></code>, and <code class="docutils literal notranslate"><span class="pre">mindspore.dataset.set_dynamic_columns</span></code> interfaces are discarded in earlier version and being removed in this version.</p></li>
</ul>
</div>
<div class="section" id="backwards-incompatible-change">
<h4>Backwards Incompatible Change<a class="headerlink" href="#backwards-incompatible-change" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p>Interface: mindspore.set_context(mode=PYNATIVE_MODE)</p>
<p>Change: The default value is changed from GRAPH_MODE to PYNATIVE_MODE.</p>
<p>Description: If the running mode is not set and the diagram mode needs to be set, use the following method:
mindspore.set_context(mode=GRAPH_MODE).</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
mindspore.set_context(mode=GRAPH_MODE)
</pre>
</td>
<td><pre>
mindspore.set_context(mode=PYNATIVE_MODE)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.train.Model.train</p>
<p>Change: The default value of dataset_sink_mode is changed from True to False.</p>
<p>Description: If dataset_sink_mode is not set and the data sinking mode needs to be set, use the following method:
Model.train(dataset_sink_mode=True).</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
Model.train(dataset_sink_mode=True)
</pre>
</td>
<td><pre>
Model.train(dataset_sink_mode=False)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.export</p>
<p>Change: The file_format parameter is changed from AIR to no default value.</p>
<p>Description: If file_format is not set in the original mode, you need to set file_format additionally. In this case, use the following method:
mindspore.export(net, *inputs, file_name, file_format=”AIR”, **kwargs).</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
mindspore.export(net, *inputs, file_name,
                 file_format="AIR", **kwargs)
</pre>
</td>
<td><pre>
mindspore.export(net, *inputs, file_name,
                 file_format, **kwargs)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.norm</p>
<p>Change: The ord parameter function is extended to support multiple forms.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.norm(input_x, axis, p=2, keep_dims=False, epsilon=1e-12)
>>> # Example:
>>> input = Tensor(np.array([[[1.0, 2.0], [3.0, 4.0]],
...                          [[5.0, 6.0], [7.0, 8.0]]]).astype(np.float32))
>>> output = ops.norm(input, [0, 1], p=2)
</pre></td>
<td><pre>
ops.norm(A, ord=None, dim=None, keepdim=False, *, dtype=None)
>>> # Example:
>>> input = Tensor(np.array([[[1.0, 2.0], [3.0, 4.0]],
...                          [[5.0, 6.0], [7.0, 8.0]]]).astype(np.float32))
>>> output = ops.norm(input, ord=2, dim=(0, 1))
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.Tensor.norm</p>
<p>Change: The ord parameter function is extended to support multiple forms.</p>
<p>Description: For details, see the example of ops.norm.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
Tensor.norm(axis, p=2, keep_dims=False, epsilon=1e-12)
</pre>
</td>
<td><pre>
Tensor.norm(ord=None, dim=None, keepdim=False, *, dtype=None)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.dropout</p>
<p>Change: The seed0 and seed1 parameters are deleted and seed=None parameter is added. Instead of returning Tensors and masks, only Tensors are returned. The input parameter training=True is added.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.dropout(x, p=0.5, seed0=0, seed1=0)
>>> # Example:
>>> input = Tensor(((20, 16), (50, 50)),
...                mindspore.float32)
>>> output, mask = dropout(x, p=0.5)
</pre>
</td>
<td><pre>
ops.dropout(input, p=0.5, training=True, seed=None)
>>> # Example:
>>> input = Tensor(((20, 16), (50, 50)),
...                mindspore.float32)
>>> output = ops.dropout(input, p=0.5，training=True)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.dropout2d</p>
<p>Change: Return value is changed from Tensor and mask to Tensor only. The input parameter training=True is added.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.dropout2d(x, p=0.5)
>>> # Example:
>>> input = Tensor(np.ones([2, 1, 2, 3]),
...                mindspore.float32)
>>> output, mask = dropout2d(input, 0.5)
</pre>
</td>
<td><pre>
ops.dropout2d(input, p=0.5, training=True)
>>> # Example:
>>> input = Tensor(np.ones([2, 1, 2, 3]),
...                mindspore.float32)
>>> output = ops.dropout2d(input, 0.5, training=True)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.dropout3d</p>
<p>Change: Return value is changed from Tensor and mask to Tensor only. The input parameter training=True is added.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.dropout3d(x, p=0.5)
>>> # Example:
>>> input = Tensor(np.ones([2, 1, 2, 3]),
...                mindspore.float32)
>>> output, mask = dropout3d(input, 0.5)
</pre>
</td>
<td><pre>
ops.dropout3d(input, p=0.5, training=True)
>>> # Example:
>>> input = Tensor(np.ones([2, 1, 2, 3]),
...                mindspore.float32)
>>> output = ops.dropout3d(input, 0.5, training=True)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.std</p>
<p>Change: The interface is reconstructed, and the interface usage mode is more consistent with user habits.</p>
<p>Description: If parameter <code class="docutils literal notranslate"><span class="pre">unbiased</span></code> has been set, use the following alternative: <code class="docutils literal notranslate"><span class="pre">unbiased=False</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">ddof=0</span></code>, <code class="docutils literal notranslate"><span class="pre">unbiased=True</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">ddof=1</span></code>.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.std(input_x, axis=(), unbiased=True, keep_dims=False)
</pre>
</td>
<td><pre>
ops.std(input, axis=None, ddof=0, keepdims=False)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.load_param_into_net</p>
<p>Change: Parameters that are not loaded in the ckpt are added as return values.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
net_param = load_param_into_net()
</pre>
</td>
<td><pre>
net_param, ckpt_param = load_param_into_net()
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.nn.BCELoss</p>
<p>Change: The default value of <code class="docutils literal notranslate"><span class="pre">reduction</span></code> is changed from ‘none’ to ‘mean’.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
BCELoss(weight=None, reduction='none')
>>> # Example:
>>> weight = Tensor(np.array([[1.0, 2.0, 3.0],
...                           [4.0, 3.3, 2.2]]),
...                 mindspore.float32)
>>> loss = nn.BCELoss(weight=weight, reduction='mean')
>>> logits = Tensor(np.array([[0.1, 0.2, 0.3],
...                           [0.5, 0.7, 0.9]]),
...                 mindspore.float32)
>>> labels = Tensor(np.array([[0, 1, 0], [0, 0, 1]]),
...                 mindspore.float32)
>>> output = loss(logits, labels)
>>> print(output)
>>> 1.8952923
</pre>
</td>
<td><pre>
BCELoss(weight=None, reduction='mean')
>>> # Example:
>>> weight = Tensor(np.array([[1.0, 2.0, 3.0],
...                           [4.0, 3.3, 2.2]]),
...                 mindspore.float32)
>>> loss = nn.BCELoss(weight=weight)
>>> logits = Tensor(np.array([[0.1, 0.2, 0.3],
...                           [0.5, 0.7, 0.9]]),
...                 mindspore.float32)
>>> labels = Tensor(np.array([[0, 1, 0], [0, 0, 1]]),
...                 mindspore.float32)
>>> output = loss(logits, labels)
>>> print(output)
>>> 1.8952923
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.split</p>
<p>Change: The interface is reconstructed. The interface usage mode is more suitable for users. The sequence of the second and third parameters is adjusted, and the split_size_or_sections function is modified and extended.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.split(input_x, axis=0, output_num=1)
>>> # Example:
>>> input = Tensor(np.array([[1, 1, 1, 1], [2, 2, 2, 2]]),
...                mindspore.int32)
>>> output = ops.split(input, axis=1, output_num=4)
</pre>
</td>
<td><pre>
ops.split(tensor, split_size_or_sections, axis=0)
>>> # Example:
>>> input = Tensor(np.array([[1, 1, 1, 1], [2, 2, 2, 2]]),
...                mindspore.int32)
>>> output = ops.split(input, split_size_or_sections=1, axis=1)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.Tensor.split</p>
<p>Change: The interface is reconstructed. The interface usage mode is more suitable for users. The positions of the two parameters is adjusted, and the split_size_or_sections function is modified and extended.</p>
<p>Description: For details, see the example of ops.split.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
Tensor.split(axis=0, output_num=1)
</pre>
</td>
<td><pre>
Tensor.split(split_size_or_sections, axis=0)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.pad</p>
<p>Change: Modify the parameter name paddings to padding, and the mode and value functions are added.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.pad(input_x, paddings)
>>> # Example:
>>> input_x = Tensor(np.array([[-0.1, 0.3, 3.6],
...                            [0.4, 0.5, -3.2]]),
...                  mindspore.float32)
>>> paddings = ((1, 2), (2, 1))
>>> output = ops.pad(input_x, paddings)
</pre>
</td>
<td><pre>
ops.pad(input_x, padding, mode='constant', value=None)
>>> # Example:
>>> input_x = Tensor(np.array([[-0.1, 0.3, 3.6],
...                            [0.4, 0.5, -3.2]]),
...                  mindspore.float32)
>>> paddings = (2, 1, 1, 2)
>>> output = ops.pad(input_x, paddings)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.meshgrid</p>
<p>Change: The input parameter is changed from <code class="docutils literal notranslate"><span class="pre">inputs</span></code> to <code class="docutils literal notranslate"><span class="pre">*input</span></code>.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.meshgrid(inputs, indexing='xy')
>>> # Example:
>>> x = Tensor(np.array([1, 2, 3, 4]).astype(np.int32))
>>> y = Tensor(np.array([5, 6, 7]).astype(np.int32))
>>> z = Tensor(np.array([8, 9, 0, 1, 2]).astype(np.int32))
output = ops.meshgrid((x, y, z), indexing='xy')
</pre>
</td>
<td><pre>
ops.meshgrid(*inputs, indexing='xy')
>>> # Example:
>>> x = Tensor(np.array([1, 2, 3, 4]).astype(np.int32))
>>> y = Tensor(np.array([5, 6, 7]).astype(np.int32))
>>> z = Tensor(np.array([8, 9, 0, 1, 2]).astype(np.int32))
output = ops.meshgrid(x, y, z, indexing='xy')
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.max</p>
<p>Change: Return value exchange sequence. The value is changed from “index, value” to “value, index”.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.max(x, axis=0, keep_dims=False)
>>> # Example:
>>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),
...                mindspore.float32)
>>> index, output = ops.max(input)
>>> print(index, output)
>>> 3 0.7
</pre>
</td>
<td><pre>
ops.max(input, axis=None, keepdims=False, *, initial=None, where=True, return_indices=False)
>>> # Example:
>>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),
...                mindspore.float32)
>>> output, index = ops.max(input, axis=0)
>>> print(output, index)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.min</p>
<p>Change: Return value exchange sequence. The value is changed from “index, value” to “value, index”.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.min(x, axis=0, keep_dims=False)
>>> # Example:
>>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),
...                mindspore.float32)
>>> index, output = ops.min(input)
>>> 0 0.0
</pre>
</td>
<td><pre>
ops.min(input, axis=None, keepdims=False, *, initial=None, where=True, return_indices=False)
>>> # Example:
>>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),
...                mindspore.float32)
>>> output, index = ops.min(input, keepdims=True)
>>> 0.0 0
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.random_gamma</p>
<p>Change: The seed2 parameter is deleted and seed=0 is changed to None. The framework behavior is unified and complies with the actual application scenarios and habits of users.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.random_gamma(shape, alpha, seed=0, seed2=0)
</pre>
</td>
<td><pre>
ops.random_gamma(shape, alpha, seed=None)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.standard_laplace</p>
<p>Change: The seed2 parameter is deleted and seed=0 is changed to None. The framework behavior is unified and complies with the actual application scenarios and habits of users.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.standard_laplace(shape, seed=0, seed2=0)
</pre>
</td>
<td><pre>
ops.standard_laplace(shape, seed=None)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.standard_normal</p>
<p>Change: The seed2 parameter is deleted and seed=0 is changed to None. The framework behavior is unified and complies with the actual application scenarios and habits of users.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.standard_normal(shape, seed=0, seed2=0)
</pre>
</td>
<td><pre>
ops.standard_normal(shape, seed=None)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.bernoulli</p>
<p>Change: The default value of seed is changed from -1 to None. Meets the actual application scenario.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.bernoulli(x, p=0.5, seed=-1)
</pre>
</td>
<td><pre>
ops.bernoulli(input, p=0.5, seed=None)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.data_sink</p>
<p>Change: Deleted the steps parameter. Parameter name jit is changed to jit_config, and new input_signature parameter is added. The usability is improved to meet the requirements of actual application scenarios.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
mindspore.data_sink(fn, dataset, steps,
                    sink_size=1, jit=False)
</pre>
</td>
<td><pre>
mindspore.data_sink(fn, dataset, sink_size=1,
                    jit_config=None, input_signature=None)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.conv2d</p>
<p>Change: Extend Interface Function. Add the bias parameter and modify the parameter name and parameter sequence.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
conv2d(inputs, weight, pad_mode="valid",
       padding=0, stride=1, dilation=1, group=1)
</pre>
</td>
<td><pre>
conv2d(input, weight, bias=None, stride=1,
       pad_mode="valid", padding=0, dilation=1, groups=1)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.dataset.vision.Pad</p>
<p>Change: Adjust the input parameter padding of Pad, RandomCrop, and RandomCropWithBbox. When the input length of Padding is 2, the first value is used to fill the left/upper boundary, the second value is used to fill the right/lower boundary, and the first value is used to fill the left/right boundary. Fill the upper/lower boundary with the second value.</p>
<p>Description: The padding parameter whose size is 2 is not compatible with the effect of the earlier version. The padding parameter needs to be explicitly represented (left, right, top, and bottom).</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
mindspore.dataset.vision.Pad(padding=(1,2))
Indicates that the left/upper part of the image is filled with 1 pixel,
and the right/down part is filled with 2 pixels.
</pre>
</td>
<td><pre>
mindspore.dataset.vision.Pad(padding=(1,2,1,2))
Indicates that the left/upper part of the image is filled with 1 pixel,
and the right/down part is filled with 2 pixels.
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.dataset.Dataset.map</p>
<p>Change: Delete the column_order parameter. In most cases, output_columns and column_order have the same value. Therefore, column_order does not need to be transferred. To adjust the sequence of data columns, use mindspore.dataset.Dataset.project.</p>
<p>Description:</p>
<ol class="simple">
<li><p>If the column sequence does not need to be changed, delete the column_order parameter.</p></li>
<li><p>If you need to specify the data column sequence, delete the column_order parameter and add a project method to the end of the parameter for column transformation (as in the following example).</p></li>
</ol>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
>>> dataset = dataset.map(operations=[transforms],
...                       input_columns=["column_a"],
...                       output_columns=["column_b", "column_c"],
...                       column_order=["column_c", "column_b"])
</pre>
</td>
<td><pre>
>>> dataset = dataset.map(operations=[transforms],
...                       input_columns=["column_a"],
...                       output_columns=["column_b", "column_c"])
>>> dataset = dataset.project(["column_c", column_b"])")
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.dataset.Dataset.batch</p>
<p>Change: Delete the column_order parameter. In most cases, output_columns and column_order have the same value. Therefore, column_order does not need to be transferred. To adjust the sequence of data columns, use mindspore.dataset.Dataset.project.</p>
<p>Description:</p>
<ol class="simple">
<li><p>If the column sequence does not need to be changed, delete the column_order parameter.</p></li>
<li><p>If you need to specify the data column sequence, delete the column_order parameter and add a project method to the end of the parameter for column transformation (as in the following example).</p></li>
</ol>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
>>> dataset = dataset.batch(batch_size=4,
...                         input_columns=["column_a"],
...                         output_columns=["column_b", "column_c"],
...                         column_order=["column_c", "column_b"])
</pre>
</td>
<td><pre>
>>> dataset = dataset.batch(batch_size=4, input_columns=["column_a"]
...                         output_columns=["column_b", "column_c"])
>>> dataset = dataset.project(["column_c", column_b"])")
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.dataset.Dataset.batch</p>
<p>Change: Split the batch method into two methods: batch and padded_batch. The pad_info parameter is moved from the batch method to the padded_batch method.</p>
<p>Description: To use the pad_info parameter, use the padded_batch method instead.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
>>> dataset = dataset.batch(batch_size=4,
...                         drop_remainder=True, pad_info=...)
</pre>
</td>
<td><pre>
>>> dataset = dataset.padded_batch(batch_size=4,
...                                drop_remainder=True, pad_info=...)
</pre>
</td>
</tr>
</table>
</li>
</ul>
</div>
</div>
<div class="section" id="bug-fixes">
<h3>Bug fixes<a class="headerlink" href="#bug-fixes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>[I66PE6] fix AssignSub primitive abnormal input leads to coredump.</p></li>
<li><p>[I6F5E6] fix data_sink function timeout on Ascend.</p></li>
</ul>
</div>
<div class="section" id="others">
<h3>Others<a class="headerlink" href="#others" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Windows support is still being optimized,this version does not support now.It will be available for download in version 2.0.</p></li>
</ul>
</div>
<div class="section" id="contributors">
<h3>Contributors<a class="headerlink" href="#contributors" title="Permalink to this headline">¶</a></h3>
<p>Thanks goes to these wonderful people:</p>
<p>alashkari,anzhengqi,archer2049,B.L.LAN,baihuawei,bichaoyang,BJ-WANG,Bokai Li,Brian-K,caifubi,caiyimeng,cathwong,changzherui,ChenDonYY,chenfei_mindspore,chengang,chengbin,chenhaozhe,chenjianping,chenkang,chenweifeng,chuht,chujinjin,davidanugraha,DavidFFFan,DeshiChen,douzhixing,emmmmtang,Erpim,Ethan,fangwenyi,fangzehua,fangzhou0329,fary86,fengyixing,gaoshuanglong,Gaoxiong,gaoyong10,gengdongjie,gongdaguo1,Greatpan,GuoZhibin,guozhijian,hangq,hanhuifeng,haozhang,hedongdong,Henry Shi,heterogeneous_to_backoff_2_0,huangbingjian,huanghui,huangxinjing,hujiahui8,hujingsong,huoxinyou,jachua,jiahongQian,jianghui58,jiangzhenguang,jiaorui,jiaoy1224,jijiarong,jjfeing,JoeyLin,json,JuiceZ,jxl,kairui_kou,KevinYi,kisnwang,KXiong,laiyongqiang,lanzhineng,liangchenghui,liangzelang,LiangZhibo,lianliguang,lichen,ligan,lijunbin,limingqi107,ling,linqingke,liubuyu,liuchao,liuchuting,liujunzhu,liuluobin,liutongtong9,liuyang811,lixiao,liyan2022,liyejun,liyuxia,looop5,luochao60,luojianing,luoyang,luoyuan,lyqlola,maning202007,maoyaomin,Margaret_wangrui,mayadong,MaZhiming,melody,mengyuanli,michaelzhu_70ab,Mohammad Motallebi,moran,NaCN,nomindcarry,OwenSec,panfengfeng,panshaowu,panzhihui,pkuliuliu,qinzheng,qiuzhongya,qujianwei,r1chardf1d0,Renyuan Zhang,RobinGrosman,shaojunsong,shenwei41,Soaringfish,tangdezhi_123,tanghuikang,tan-wei-cheng,TinaMengtingZhang,TronZhang,TuDouNi,VectorSL,wang_ziqi,wanghenchang,wangnan39,wangpingan,wangshaocong,wangshengnan123,wangtongyu6,weichaoran,wind-zyx,wqx,wtcheng,wujueying,wYann,XianglongZeng,xiaohanzhang,xiaotianci,xiaoyao,XinDu,xulei,xumengjuan1,xupan,xwkgch,yanghaoran,yangluhang,yangruoqi713,yangshuo,yangsijia,yangzhenzhang,yanzhenxiang2020,Yanzhi_YI,yao_yf,yefeng,yeyunpeng2020,Yi_zhang95,yide12,YijieChen,YingLai Lin,YingtongHu,youshu,yuchaojie,yuedongli,YuJianfeng,zangqx,ZengZitao,zhangbuxue,zhangdanyang,zhangdong,zhangfanghe,zhangqi,zhangqinghua,zhangyanhui,zhangyinxia,zhangyongxian,zhangzhaoju,zhanzhan,zhengzuohe,ZhidanLiu,zhixinaa,zhoufeng,zhouyaqiang0,zhuguodong,zhupuxu,zhuyuxiao,zichun_ye,zjun,zlq2020,zong_shuai,ZPaC,zuochuanyong,zyli2020,陈宇,范吉斌,冯一航,胡彬,宦晓玲,黄勇,雷元哲,李良灿,李林杰,刘崇鸣,刘力力,刘勇琪,吕浩宇,吕昱峰（Nate.River）,没有窗户的小巷,沈竞兴,十六夜,王程浩,王禹程,王振邦,徐安越,徐永飞,杨旭华,于振华,俞涵,张清华,张澍坤,张栩浩,张学同,赵英灼,周超,周洪叶,朱家兴</p>
<p>Contributions of any kind are welcome!</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="faq/feature_advice.html" class="btn btn-neutral float-left" title="Feature Advice" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>