<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Release Notes &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/training.css" type="text/css" /><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/js/training.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Feature Advice" href="faq/feature_advice.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/programming_paradigm.html">Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/auto_gradient.html">Functional Differential Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/all_scenarios.html">Full-scenarios Unification</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="note/official_models.html">Official Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_python/mindspore.scipy.html">mindspore.scipy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
<li class="toctree-l1"><a class="reference internal" href="note/api_mapping/tensorflow_api_mapping.html">TensorFlow and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="migration_guide/overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="migration_guide/enveriment_preparation.html">Environment Preparation and Information Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="migration_guide/analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="migration_guide/model_development/model_development.html">Constructing MindSpore Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="migration_guide/debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="migration_guide/sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="migration_guide/faq.html">FAQs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Syntax Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="note/static_graph_syntax_support.html">Static Graph Syntax Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="note/index_support.html">Tensor Index Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Release Notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#mindspore-2-0-0-release-notes">MindSpore 2.0.0 Release Notes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#major-features-and-improvements">Major Features and Improvements</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pynative">PyNative</a></li>
<li class="toctree-l4"><a class="reference internal" href="#autoparallel">AutoParallel</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#api-change">API Change</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#operator">operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="#backwards-incompatible-change">Backwards Incompatible Change</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#bug-fixes">Bug fixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#contributors">Contributors</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Release Notes</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/RELEASE.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="release-notes">
<h1>Release Notes<a class="headerlink" href="#release-notes" title="Permalink to this headline"></a></h1>
<section id="mindspore-2-0-0-release-notes">
<h2>MindSpore 2.0.0 Release Notes<a class="headerlink" href="#mindspore-2-0-0-release-notes" title="Permalink to this headline"></a></h2>
<section id="major-features-and-improvements">
<h3>Major Features and Improvements<a class="headerlink" href="#major-features-and-improvements" title="Permalink to this headline"></a></h3>
<section id="pynative">
<h4>PyNative<a class="headerlink" href="#pynative" title="Permalink to this headline"></a></h4>
<ul class="simple">
<li><p>[STABLE] Dynamic shape is fully supported on framework. For detailed operator support, refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.0/note/dynamic_shape_nn.html">Dynamic Shape Support Status of nn Interface</a>, <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.0/note/dynamic_shape_func.html">Dynamic Shape Support Status of functional Interface</a>, and <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.0/note/dynamic_shape_primitive.html">Dynamic Shape Support Status of primitive Interface</a>.</p></li>
</ul>
</section>
<section id="autoparallel">
<h4>AutoParallel<a class="headerlink" href="#autoparallel" title="Permalink to this headline"></a></h4>
<ul class="simple">
<li><p>[STABLE] Build new MindFormers independent repositpry, providing distributed parallel suite, replacing mindspore.nn.transformer module.</p></li>
<li><p>[DEMO] Distributed parallel operator Gather supports the BatchDim attribute.</p></li>
<li><p>[DEMO] Streamline parallel supports specifying any dimension of the input data as the Batch dimension.</p></li>
</ul>
</section>
</section>
<section id="api-change">
<h3>API Change<a class="headerlink" href="#api-change" title="Permalink to this headline"></a></h3>
<section id="operator">
<h4>operator<a class="headerlink" href="#operator" title="Permalink to this headline"></a></h4>
<ul class="simple">
<li><p>Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.AdaptiveAvgPool2D</span></code> .</p></li>
<li><p>Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.BatchToSpaceNDV2</span></code> .</p></li>
<li><p>Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.CeLU</span></code> .</p></li>
<li><p>Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.ExtractVolumePatches</span></code> .</p></li>
<li><p>Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.FFTWithSize</span></code> .</p></li>
<li><p>Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.FillDiagonal</span></code> .</p></li>
<li><p>Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.FractionalMaxPool3DWithFixedKsize</span></code> .</p></li>
<li><p>Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Im2Col</span></code> .</p></li>
<li><p>Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.MaskedScatter</span></code> .</p></li>
<li><p>Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.MatrixBandPart</span></code> .</p></li>
<li><p>Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.MatrixInverse</span></code> .</p></li>
<li><p>Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.MaxPoolWithArgmaxV2</span></code> .</p></li>
<li><p>Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Ormqr</span></code> .</p></li>
<li><p>Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.RandpermV2</span></code> .</p></li>
<li><p>Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.ResizeBicubic</span></code> .</p></li>
<li><p>Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Triu</span></code> .</p></li>
<li><p>Add operator primitive for <code class="docutils literal notranslate"><span class="pre">mindspore.ops.Zeta</span></code> .</p></li>
</ul>
</section>
<section id="backwards-incompatible-change">
<h4>Backwards Incompatible Change<a class="headerlink" href="#backwards-incompatible-change" title="Permalink to this headline"></a></h4>
<ul>
<li><p>Interface: mindspore.ops.MultitypeFuncGraph</p>
<p>Change: The interface parameter doc_url is used as a test feature in MindSpore 2.0.0.rc1 version. After the optimization of MindSpore 2.0.0 version, users do not need to configure this parameter, so this parameter is deleted in MindSpore 2.0.0 version.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0 </td>
</tr>
<tr>
<td><pre>
mindspore.ops.MultitypeFuncGraph（name, read_value=False, doc_url=""）
</pre>
</td>
<td><pre>
mindspore.ops.MultitypeFuncGraph（name, read_value=False）
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.set_context(auto_tune_mode=”GA,RL”)</p>
<p>Change: The AutoTune tool has been deprecated, delete auto_tune_mode option, new tuning tools will be planned in the future.</p>
</li>
<li><p>Interface: mindspore.set_context(mode=PYNATIVE_MODE)</p>
<p>Change: The default value is changed from GRAPH_MODE to PYNATIVE_MODE.</p>
<p>Description: If the running mode is not set and the diagram mode needs to be set, use the following method:
mindspore.set_context(mode=GRAPH_MODE).</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
mindspore.set_context(mode=GRAPH_MODE)
</pre>
</td>
<td><pre>
mindspore.set_context(mode=PYNATIVE_MODE)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.train.Model.train</p>
<p>Change: The default value of dataset_sink_mode is changed from True to False.</p>
<p>Description: If dataset_sink_mode is not set and the data sinking mode needs to be set, use the following method:
Model.train(dataset_sink_mode=True).</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
Model.train(dataset_sink_mode=True)
</pre>
</td>
<td><pre>
Model.train(dataset_sink_mode=False)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.export</p>
<p>Change: The file_format parameter is changed from AIR to no default value.</p>
<p>Description: If file_format is not set in the original mode, you need to set file_format additionally. In this case, use the following method:
mindspore.export(net, *inputs, file_name, file_format=”AIR”, **kwargs).</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
mindspore.export(net, *inputs, file_name,
                 file_format="AIR", **kwargs)
</pre>
</td>
<td><pre>
mindspore.export(net, *inputs, file_name,
                 file_format, **kwargs)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.norm</p>
<p>Change: The ord parameter function is extended to support multiple forms.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.norm(input_x, axis, p=2, keep_dims=False, epsilon=1e-12)
>>> # Example:
>>> input = Tensor(np.array([[[1.0, 2.0], [3.0, 4.0]],
...                          [[5.0, 6.0], [7.0, 8.0]]]).astype(np.float32))
>>> output = ops.norm(input, [0, 1], p=2)
</pre></td>
<td><pre>
ops.norm(A, ord=None, dim=None, keepdim=False, *, dtype=None)
>>> # Example:
>>> input = Tensor(np.array([[[1.0, 2.0], [3.0, 4.0]],
...                          [[5.0, 6.0], [7.0, 8.0]]]).astype(np.float32))
>>> output = ops.norm(input, ord=2, dim=(0, 1))
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.Tensor.norm</p>
<p>Change: The ord parameter function is extended to support multiple forms.</p>
<p>Description: For details, see the example of ops.norm.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
Tensor.norm(axis, p=2, keep_dims=False, epsilon=1e-12)
</pre>
</td>
<td><pre>
Tensor.norm(ord=None, dim=None, keepdim=False, *, dtype=None)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.dropout</p>
<p>Change: The seed0 and seed1 parameters are deleted and seed=None parameter is added. Instead of returning Tensors and masks, only Tensors are returned. The input parameter training=True is added.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.dropout(x, p=0.5, seed0=0, seed1=0)
>>> # Example:
>>> input = Tensor(((20, 16), (50, 50)),
...                mindspore.float32)
>>> output, mask = dropout(x, p=0.5)
</pre>
</td>
<td><pre>
ops.dropout(input, p=0.5, training=True, seed=None)
>>> # Example:
>>> input = Tensor(((20, 16), (50, 50)),
...                mindspore.float32)
>>> output = ops.dropout(input, p=0.5，training=True)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.dropout2d</p>
<p>Change: Return value is changed from Tensor and mask to Tensor only. The input parameter training=True is added.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.dropout2d(x, p=0.5)
>>> # Example:
>>> input = Tensor(np.ones([2, 1, 2, 3]),
...                mindspore.float32)
>>> output, mask = dropout2d(input, 0.5)
</pre>
</td>
<td><pre>
ops.dropout2d(input, p=0.5, training=True)
>>> # Example:
>>> input = Tensor(np.ones([2, 1, 2, 3]),
...                mindspore.float32)
>>> output = ops.dropout2d(input, 0.5, training=True)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.dropout3d</p>
<p>Change: Return value is changed from Tensor and mask to Tensor only. The input parameter training=True is added.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.dropout3d(x, p=0.5)
>>> # Example:
>>> input = Tensor(np.ones([2, 1, 2, 3]),
...                mindspore.float32)
>>> output, mask = dropout3d(input, 0.5)
</pre>
</td>
<td><pre>
ops.dropout3d(input, p=0.5, training=True)
>>> # Example:
>>> input = Tensor(np.ones([2, 1, 2, 3]),
...                mindspore.float32)
>>> output = ops.dropout3d(input, 0.5, training=True)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.std</p>
<p>Change: The interface is reconstructed, and the interface usage mode is more consistent with user habits.</p>
<p>Description: If parameter <code class="docutils literal notranslate"><span class="pre">unbiased</span></code> has been set, use the following alternative: <code class="docutils literal notranslate"><span class="pre">unbiased=False</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">ddof=0</span></code>, <code class="docutils literal notranslate"><span class="pre">unbiased=True</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">ddof=1</span></code>.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.std(input_x, axis=(), unbiased=True, keep_dims=False)
</pre>
</td>
<td><pre>
ops.std(input, axis=None, ddof=0, keepdims=False)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.load_param_into_net</p>
<p>Change: Parameters that are not loaded in the ckpt are added as return values.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
net_param = load_param_into_net()
</pre>
</td>
<td><pre>
net_param, ckpt_param = load_param_into_net()
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.nn.BCELoss</p>
<p>Change: The default value of <code class="docutils literal notranslate"><span class="pre">reduction</span></code> is changed from ‘none’ to ‘mean’.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
BCELoss(weight=None, reduction='none')
>>> # Example:
>>> weight = Tensor(np.array([[1.0, 2.0, 3.0],
...                           [4.0, 3.3, 2.2]]),
...                 mindspore.float32)
>>> loss = nn.BCELoss(weight=weight, reduction='mean')
>>> logits = Tensor(np.array([[0.1, 0.2, 0.3],
...                           [0.5, 0.7, 0.9]]),
...                 mindspore.float32)
>>> labels = Tensor(np.array([[0, 1, 0], [0, 0, 1]]),
...                 mindspore.float32)
>>> output = loss(logits, labels)
>>> print(output)
>>> 1.8952923
</pre>
</td>
<td><pre>
BCELoss(weight=None, reduction='mean')
>>> # Example:
>>> weight = Tensor(np.array([[1.0, 2.0, 3.0],
...                           [4.0, 3.3, 2.2]]),
...                 mindspore.float32)
>>> loss = nn.BCELoss(weight=weight)
>>> logits = Tensor(np.array([[0.1, 0.2, 0.3],
...                           [0.5, 0.7, 0.9]]),
...                 mindspore.float32)
>>> labels = Tensor(np.array([[0, 1, 0], [0, 0, 1]]),
...                 mindspore.float32)
>>> output = loss(logits, labels)
>>> print(output)
>>> 1.8952923
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.split</p>
<p>Change: The interface is reconstructed. The interface usage mode is more suitable for users. The sequence of the second and third parameters is adjusted, and the split_size_or_sections function is modified and extended.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.split(input_x, axis=0, output_num=1)
>>> # Example:
>>> input = Tensor(np.array([[1, 1, 1, 1], [2, 2, 2, 2]]),
...                mindspore.int32)
>>> output = ops.split(input, axis=1, output_num=4)
</pre>
</td>
<td><pre>
ops.split(tensor, split_size_or_sections, axis=0)
>>> # Example:
>>> input = Tensor(np.array([[1, 1, 1, 1], [2, 2, 2, 2]]),
...                mindspore.int32)
>>> output = ops.split(input, split_size_or_sections=1, axis=1)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.Tensor.split</p>
<p>Change: The interface is reconstructed. The interface usage mode is more suitable for users. The positions of the two parameters is adjusted, and the split_size_or_sections function is modified and extended.</p>
<p>Description: For details, see the example of ops.split.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
Tensor.split(axis=0, output_num=1)
</pre>
</td>
<td><pre>
Tensor.split(split_size_or_sections, axis=0)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.pad</p>
<p>Change: Modify the parameter name paddings to padding, and the mode and value functions are added.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.pad(input_x, paddings)
>>> # Example:
>>> input_x = Tensor(np.array([[-0.1, 0.3, 3.6],
...                            [0.4, 0.5, -3.2]]),
...                  mindspore.float32)
>>> paddings = ((1, 2), (2, 1))
>>> output = ops.pad(input_x, paddings)
</pre>
</td>
<td><pre>
ops.pad(input_x, padding, mode='constant', value=None)
>>> # Example:
>>> input_x = Tensor(np.array([[-0.1, 0.3, 3.6],
...                            [0.4, 0.5, -3.2]]),
...                  mindspore.float32)
>>> paddings = (2, 1, 1, 2)
>>> output = ops.pad(input_x, paddings)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.meshgrid</p>
<p>Change: The input parameter is changed from <code class="docutils literal notranslate"><span class="pre">inputs</span></code> to <code class="docutils literal notranslate"><span class="pre">*input</span></code>.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.meshgrid(inputs, indexing='xy')
>>> # Example:
>>> x = Tensor(np.array([1, 2, 3, 4]).astype(np.int32))
>>> y = Tensor(np.array([5, 6, 7]).astype(np.int32))
>>> z = Tensor(np.array([8, 9, 0, 1, 2]).astype(np.int32))
output = ops.meshgrid((x, y, z), indexing='xy')
</pre>
</td>
<td><pre>
ops.meshgrid(*inputs, indexing='xy')
>>> # Example:
>>> x = Tensor(np.array([1, 2, 3, 4]).astype(np.int32))
>>> y = Tensor(np.array([5, 6, 7]).astype(np.int32))
>>> z = Tensor(np.array([8, 9, 0, 1, 2]).astype(np.int32))
output = ops.meshgrid(x, y, z, indexing='xy')
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.max</p>
<p>Change: Return value exchange sequence. The value is changed from “index, value” to “value, index”.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.max(x, axis=0, keep_dims=False)
>>> # Example:
>>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),
...                mindspore.float32)
>>> index, output = ops.max(input)
>>> print(index, output)
>>> 3 0.7
</pre>
</td>
<td><pre>
ops.max(input, axis=None, keepdims=False, *, initial=None, where=True, return_indices=False)
>>> # Example:
>>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),
...                mindspore.float32)
>>> output, index = ops.max(input, axis=0)
>>> print(output, index)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.min</p>
<p>Change: Return value exchange sequence. The value is changed from “index, value” to “value, index”.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.min(x, axis=0, keep_dims=False)
>>> # Example:
>>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),
...                mindspore.float32)
>>> index, output = ops.min(input)
>>> 0 0.0
</pre>
</td>
<td><pre>
ops.min(input, axis=None, keepdims=False, *, initial=None, where=True, return_indices=False)
>>> # Example:
>>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),
...                mindspore.float32)
>>> output, index = ops.min(input, keepdims=True)
>>> 0.0 0
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.random_gamma</p>
<p>Change: The seed2 parameter is deleted and seed=0 is changed to None. The framework behavior is unified and complies with the actual application scenarios and habits of users.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.random_gamma(shape, alpha, seed=0, seed2=0)
</pre>
</td>
<td><pre>
ops.random_gamma(shape, alpha, seed=None)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.standard_laplace</p>
<p>Change: The seed2 parameter is deleted and seed=0 is changed to None. The framework behavior is unified and complies with the actual application scenarios and habits of users.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.standard_laplace(shape, seed=0, seed2=0)
</pre>
</td>
<td><pre>
ops.standard_laplace(shape, seed=None)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.standard_normal</p>
<p>Change: The seed2 parameter is deleted and seed=0 is changed to None. The framework behavior is unified and complies with the actual application scenarios and habits of users.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.standard_normal(shape, seed=0, seed2=0)
</pre>
</td>
<td><pre>
ops.standard_normal(shape, seed=None)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.bernoulli</p>
<p>Change: The default value of seed is changed from -1 to None. Meets the actual application scenario.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
ops.bernoulli(x, p=0.5, seed=-1)
</pre>
</td>
<td><pre>
ops.bernoulli(input, p=0.5, seed=None)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.data_sink</p>
<p>Change: Deleted the steps parameter. Parameter name jit is changed to jit_config, and new input_signature parameter is added. The usability is improved to meet the requirements of actual application scenarios.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
mindspore.data_sink(fn, dataset, steps,
                    sink_size=1, jit=False)
</pre>
</td>
<td><pre>
mindspore.data_sink(fn, dataset, sink_size=1,
                    jit_config=None, input_signature=None)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.ops.conv2d</p>
<p>Change: Extend Interface Function. Add the bias parameter and modify the parameter name and parameter sequence.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
conv2d(inputs, weight, pad_mode="valid",
       padding=0, stride=1, dilation=1, group=1)
</pre>
</td>
<td><pre>
conv2d(input, weight, bias=None, stride=1,
       pad_mode="valid", padding=0, dilation=1, groups=1)
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.dataset.vision.Pad</p>
<p>Change: Adjust the input parameter padding of Pad, RandomCrop, and RandomCropWithBbox. When the input length of Padding is 2, the first value is used to fill the left/upper boundary, the second value is used to fill the right/lower boundary, and the first value is used to fill the left/right boundary. Fill the upper/lower boundary with the second value.</p>
<p>Description: The padding parameter whose size is 2 is not compatible with the effect of the earlier version. The padding parameter needs to be explicitly represented (left, right, top, and bottom).</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
mindspore.dataset.vision.Pad(padding=(1,2))
Indicates that the left/upper part of the image is filled with 1 pixel,
and the right/down part is filled with 2 pixels.
</pre>
</td>
<td><pre>
mindspore.dataset.vision.Pad(padding=(1,2,1,2))
Indicates that the left/upper part of the image is filled with 1 pixel,
and the right/down part is filled with 2 pixels.
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.dataset.Dataset.map</p>
<p>Change: Delete the column_order parameter. In most cases, output_columns and column_order have the same value. Therefore, column_order does not need to be transferred. To adjust the sequence of data columns, use mindspore.dataset.Dataset.project.</p>
<p>Description:</p>
<ol class="arabic simple">
<li><p>If the column sequence does not need to be changed, delete the column_order parameter.</p></li>
<li><p>If you need to specify the data column sequence, delete the column_order parameter and add a project method to the end of the parameter for column transformation (as in the following example).</p></li>
</ol>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
>>> dataset = dataset.map(operations=[transforms],
...                       input_columns=["column_a"],
...                       output_columns=["column_b", "column_c"],
...                       column_order=["column_c", "column_b"])
</pre>
</td>
<td><pre>
>>> dataset = dataset.map(operations=[transforms],
...                       input_columns=["column_a"],
...                       output_columns=["column_b", "column_c"])
>>> dataset = dataset.project(["column_c", column_b"])")
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.dataset.Dataset.batch</p>
<p>Change: Delete the column_order parameter. In most cases, output_columns and column_order have the same value. Therefore, column_order does not need to be transferred. To adjust the sequence of data columns, use mindspore.dataset.Dataset.project.</p>
<p>Description:</p>
<ol class="arabic simple">
<li><p>If the column sequence does not need to be changed, delete the column_order parameter.</p></li>
<li><p>If you need to specify the data column sequence, delete the column_order parameter and add a project method to the end of the parameter for column transformation (as in the following example).</p></li>
</ol>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
>>> dataset = dataset.batch(batch_size=4,
...                         input_columns=["column_a"],
...                         output_columns=["column_b", "column_c"],
...                         column_order=["column_c", "column_b"])
</pre>
</td>
<td><pre>
>>> dataset = dataset.batch(batch_size=4, input_columns=["column_a"]
...                         output_columns=["column_b", "column_c"])
>>> dataset = dataset.project(["column_c", column_b"])")
</pre>
</td>
</tr>
</table>
</li>
<li><p>Interface: mindspore.dataset.Dataset.batch</p>
<p>Change: Split the batch method into two methods: batch and padded_batch. The pad_info parameter is moved from the batch method to the padded_batch method.</p>
<p>Description: To use the pad_info parameter, use the padded_batch method instead.</p>
<table>
<tr>
<td style="text-align:center"> Original Interface </td> <td style="text-align:center"> Interface v2.0.0-rc1 </td>
</tr>
<tr>
<td><pre>
>>> dataset = dataset.batch(batch_size=4,
...                         drop_remainder=True, pad_info=...)
</pre>
</td>
<td><pre>
>>> dataset = dataset.padded_batch(batch_size=4,
...                                drop_remainder=True, pad_info=...)
</pre>
</td>
</tr>
</table>
</li>
</ul>
</section>
</section>
<section id="bug-fixes">
<h3>Bug fixes<a class="headerlink" href="#bug-fixes" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>[I62I3J] fix inference failure of BGCF network on Ascend 310</p></li>
<li><p>[I7C2W3] fix error issuse of null pointer when enabling multiple loss in parallel pipeline scenarios</p></li>
</ul>
</section>
<section id="contributors">
<h3>Contributors<a class="headerlink" href="#contributors" title="Permalink to this headline"></a></h3>
<p>Thanks goes to these wonderful people:</p>
<p>alashkari,anzhengqi,archer2049,B.L.LAN,baihuawei,bichaoyang,BJ-WANG,Bokai Li,Brian-K,caifubi,caiyimeng,cathwong,changzherui,ChenDonYY,chenfei_mindspore,chengang,chengbin,chenhaozhe,chenjianping,chenkang,chenweifeng,chuht,chujinjin,davidanugraha,DavidFFFan,DeshiChen,douzhixing,emmmmtang,Erpim,Ethan,fangwenyi,fangzehua,fangzhou0329,fary86,fengyixing,gaoshuanglong,Gaoxiong,gaoyong10,gengdongjie,gongdaguo1,Greatpan,GuoZhibin,guozhijian,hangq,hanhuifeng,haozhang,hedongdong,Henry Shi,heterogeneous_to_backoff_2_0,huangbingjian,huanghui,huangxinjing,hujiahui8,hujingsong,huoxinyou,jachua,jiahongQian,jianghui58,jiangzhenguang,jiaorui,jiaoy1224,jijiarong,jjfeing,JoeyLin,json,JuiceZ,jxl,kairui_kou,KevinYi,kisnwang,KXiong,laiyongqiang,lanzhineng,liangchenghui,liangzelang,LiangZhibo,lianliguang,lichen,ligan,lijunbin,limingqi107,ling,linqingke,liubuyu,liuchao,liuchuting,liujunzhu,liuluobin,liutongtong9,liuyang811,lixiao,liyan2022,liyejun,liyuxia,looop5,luochao60,luojianing,luoyang,luoyuan,lyqlola,maning202007,maoyaomin,Margaret_wangrui,mayadong,MaZhiming,melody,mengyuanli,michaelzhu_70ab,Mohammad Motallebi,moran,NaCN,nomindcarry,OwenSec,panfengfeng,panshaowu,panzhihui,pkuliuliu,qinzheng,qiuzhongya,qujianwei,r1chardf1d0,Renyuan Zhang,RobinGrosman,shaojunsong,shenwei41,Soaringfish,tangdezhi_123,tanghuikang,tan-wei-cheng,TinaMengtingZhang,TronZhang,TuDouNi,VectorSL,wang_ziqi,wanghenchang,wangnan39,wangpingan,wangshaocong,wangshengnan123,wangtongyu6,weichaoran,wind-zyx,wqx,wtcheng,wujueying,wYann,XianglongZeng,xiaohanzhang,xiaotianci,xiaoyao,XinDu,xulei,xumengjuan1,xupan,xwkgch,yanghaoran,yangluhang,yangruoqi713,yangshuo,yangsijia,yangzhenzhang,yanzhenxiang2020,Yanzhi_YI,yao_yf,yefeng,yeyunpeng2020,Yi_zhang95,yide12,YijieChen,YingLai Lin,YingtongHu,youshu,yuchaojie,yuedongli,YuJianfeng,zangqx,ZengZitao,zhangbuxue,zhangdanyang,zhangdong,zhangfanghe,zhangqi,zhangqinghua,zhangyanhui,zhangyinxia,zhangyongxian,zhangzhaoju,zhanzhan,zhengzuohe,ZhidanLiu,zhixinaa,zhoufeng,zhouyaqiang0,zhuguodong,zhupuxu,zhuyuxiao,zichun_ye,zjun,zlq2020,zong_shuai,ZPaC,zuochuanyong,zyli2020,陈宇,范吉斌,冯一航,胡彬,宦晓玲,黄勇,雷元哲,李良灿,李林杰,刘崇鸣,刘力力,刘勇琪,吕浩宇,吕昱峰（Nate.River）,没有窗户的小巷,沈竞兴,十六夜,王程浩,王禹程,王振邦,徐安越,徐永飞,杨旭华,于振华,俞涵,张清华,张澍坤,张栩浩,张学同,赵英灼,周超,周洪叶,朱家兴</p>
<p>Contributions of any kind are welcome!</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="faq/feature_advice.html" class="btn btn-neutral float-left" title="Feature Advice" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>