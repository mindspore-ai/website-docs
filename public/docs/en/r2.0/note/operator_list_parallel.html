

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>MindSpore Distributed API List &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/js/training.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Syntax Support" href="syntax_list.html" />
    <link rel="prev" title="MindSpore Implicit Type Conversion API List" href="operator_list_implicit.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/programming_paradigm.html">Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/auto_gradient.html">Functional Differential Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/all_scenarios.html">Full-scenarios Unification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption"><span class="caption-text">Specification</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">Benchmarks</a></li>
<li class="toctree-l1"><a class="reference external" href="https://gitee.com/mindspore/models/blob/r2.0/README.md#table-of-contents">Network List↗</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="operator_list.html">API List</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="operator_list_implicit.html">MindSpore Implicit Type Conversion API List</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">MindSpore Distributed API List</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="syntax_list.html">Syntax Support</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/en/r2.0/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_mapping/tensorflow_api_mapping.html">TensorFlow and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption"><span class="caption-text">Migration Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/enveriment_preparation.html">Environment Preparation and Information Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/model_development/model_development.html">Constructing MindSpore Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/faq.html">FAQs</a></li>
</ul>
<p class="caption"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="operator_list.html">API List</a> &raquo;</li>
        
      <li>MindSpore Distributed API List</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/note/operator_list_parallel.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="mindspore-distributed-api-list">
<h1>MindSpore Distributed API List<a class="headerlink" href="#mindspore-distributed-api-list" title="Permalink to this headline">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r2.0/docs/mindspore/source_en/note/operator_list_parallel.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.0/resource/_static/logo_source_en.png"></a></p>
<table border="1" class="docutils">
<thead>
<tr>
<th style="text-align: left;">API name</th>
<th style="text-align: left;">constraints</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Abs.html">mindspore.ops.Abs</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ACos.html">mindspore.ops.ACos</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Acosh.html">mindspore.ops.Acosh</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Add.html">mindspore.ops.Add</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.AddN.html">mindspore.ops.AddN</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ApproximateEqual.html">mindspore.ops.ApproximateEqual</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ArgMaxWithValue.html">mindspore.ops.ArgMaxWithValue</a></td>
<td style="text-align: left;">When the input_x is splited on the axis dimension, the distributed result may be inconsistent with that on the single machine.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ArgMinWithValue.html">mindspore.ops.ArgMinWithValue</a></td>
<td style="text-align: left;">When the input_x is splited on the axis dimension, the distributed result may be inconsistent with that on the single machine.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Asin.html">mindspore.ops.Asin</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Asinh.html">mindspore.ops.Asinh</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Assign.html">mindspore.ops.Assign</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.AssignAdd.html">mindspore.ops.AssignAdd</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.AssignSub.html">mindspore.ops.AssignSub</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Atan.html">mindspore.ops.Atan</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Atan2.html">mindspore.ops.Atan2</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Atanh.html">mindspore.ops.Atanh</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.AvgPool.html">mindspore.ops.AvgPool</a></td>
<td style="text-align: left;">1. The data format only supports 'NCHW'; <br />2. The shapes of output H/W dimension must be divisible by the split strategies of input H/W dimension;<br />3. If H/W is split: <br />    1) If the kernel_size &lt;= stride, the input slice size must be divisible by stride;<br />    2) It does not support kernel_size &gt; stride;<br />4. In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.AvgPool3D.html">mindspore.ops.AvgPool3D</a></td>
<td style="text-align: left;">1. The data format only supports 'NCDHW';<br />2. If data exchange between adjacent nodes is involved,  only Ascend is supported;<br />3. The W dimensions can not be split;<br />4. The output shape of D/H dimension must be divisible by the strategy of input D/H dimensions;<br />5. In valid mode: If D/H dimension is split:<br />    1) When the kernel_size &lt;= stride, the input‘s slice shape of D/H dimension must be divisible by stride;<br />    2) It does not support that kernel_size &gt; stride;<br />6. In the same/pad mode: If D/H dimension is split:<br />    1) If kernel_size &gt;= stride, (Total input length including pad - kernel_size) must be divisible by stride. Otherwise, the pad must be 0 and the slice shape of D/H dimension must be divisible by stride;<br />    2) (Output length* stride - input length) must be divisible by strategy:<br />    3) The length of data sent and received between adjacent cards must be greater than or equal to 0 and less than or equal to the slice size;<br />7. In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.BatchMatMul.html">mindspore.ops.BatchMatMul</a></td>
<td style="text-align: left;"><code>transpore_a=True</code> is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.BatchNorm.html">mindspore.ops.BatchNorm</a></td>
<td style="text-align: left;">It does not support GPU.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.BesselI0e.html">mindspore.ops.BesselI0e</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.BesselI1e.html">mindspore.ops.BesselI1e</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.BiasAdd.html">mindspore.ops.BiasAdd</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.BitwiseAnd.html">mindspore.ops.BitwiseAnd</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.BitwiseOr.html">mindspore.ops.BitwiseOr</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.BitwiseXor.html">mindspore.ops.BitwiseXor</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.BoundingBoxEncode.html">mindspore.ops.BoundingBoxEncode</a></td>
<td style="text-align: left;">1. The first dimension of input (anchor_box) and input (groundtruth_box) can be split; <br /> 2. The sharding strategies of input (anchor_box) and input (groundtruth_box) must be the same.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.BroadcastTo.html">mindspore.ops.BroadcastTo</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Cast.html">mindspore.ops.Cast</a></td>
<td style="text-align: left;">The shard strategy is ignored in the Auto Parallel and Semi Auto Parallel mode.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Cdist.html">mindspore.ops.Cdist</a></td>
<td style="text-align: left;">1. The strategy for 'B' dimension must be the same; <br /> 2.<code>M</code> dimension can't be split.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Ceil.html">mindspore.ops.Ceil</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Concat.html">mindspore.ops.Concat</a></td>
<td style="text-align: left;">The input_x can't be split into the dimension of axis, otherwise it's inconsistent with the single machine in the mathematical logic.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Conv2D.html">mindspore.ops.Conv2D</a></td>
<td style="text-align: left;">1. The data format only supports 'NCHW';<br />2. If data exchange between adjacent nodes is involved, only Ascend is supported;<br />3. When the value of group is not 1, can not split C-in or C-out;<br />4. The last two dimensions of weight can not be split;<br />5. The output shape of H/W dimension must be divisible by the strategy of input H/W dimensions;<br />6. In valid mode: If H/W dimension is split:<br />    1) When the kernel_size &lt;= stride (kernel_size is dilation <em>(kernel_size - 1) + 1, the same below), the input‘s slice shape of H/W dimension must be divisible by stride;<br />    2) It does not support that kernel_size &gt; stride;<br />7. In the same/pad mode: If H/W dimension is split:<br />    1)  If kernel_size &gt;= stride, (Total input length including pad - kernel_size) must be divisible by stride. Otherwise, the pad must be 0 and the slice shape of H/W dimension must be divisible by stride;<br />    2) (Output length</em> stride - input length) must be divisible by strategy:<br />    3) The length of data sent and received between adjacent cards must be greater than or equal to 0 and less than or equal to the slice size;</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Conv3D.html">mindspore.ops.Conv3D</a></td>
<td style="text-align: left;">1. The data format only supports 'NCDHW';<br />2. If data exchange between adjacent nodes is involved, only Ascend is supported;<br />3. When the value of group is not 1, can not split C-in or C-out;<br />4. The W dimension and the last three dimensions of weight can not be split;<br />5. The output shape of D/H dimension must be divisible by the strategy of input D/H dimensions;<br />6. In valid mode: If D/H dimension is split:<br />    1) When the kernel_size &lt;= stride (kernel_size is dilation <em>(kernel_size - 1) + 1, the same below), the input‘s slice shape of D/H dimension must be divisible by stride;<br />    2) It does not support that kernel_size &gt; stride;<br />7. In the same/pad mode: If D/H dimension is split:<br />    1) If kernel_size &gt;= stride, (Total input length including pad - kernel_size) must be divisible by stride. Otherwise, the pad must be 0 and the slice shape of D/H dimension must be divisible by stride;<br />    2) (Output length</em> stride - input length) must be divisible by strategy:<br />    3) The length of data sent and received between adjacent cards must be greater than or equal to 0 and less than or equal to the slice size;<br />8. In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Cos.html">mindspore.ops.Cos</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Cosh.html">mindspore.ops.Cosh</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.CropAndResize.html">mindspore.ops.CropAndResize</a></td>
<td style="text-align: left;">1. Sharding of the H/W dimension of input (x) and the second dimension of input (boxes) is not supported. <br /> 2. The shard strategy for the first dimension of inputs (boxes) and (box_index) must be the same.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.CumProd.html">mindspore.ops.CumProd</a></td>
<td style="text-align: left;">The <code>axis</code> dimension for <code>input</code> can't be split.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.CumSum.html">mindspore.ops.CumSum</a></td>
<td style="text-align: left;">The same as CumProd.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Div.html">mindspore.ops.Div</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.DivNoNan.html">mindspore.ops.DivNoNan</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Dropout.html">mindspore.ops.Dropout</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Elu.html">mindspore.ops.Elu</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.EmbeddingLookup.html">mindspore.ops.EmbeddingLookup</a></td>
<td style="text-align: left;">The same as Gather.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Equal.html">mindspore.ops.Equal</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Erf.html">mindspore.ops.Erf</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Erfc.html">mindspore.ops.Erfc</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Erfinv.html">mindspore.ops.Erfinv</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Exp.html">mindspore.ops.Exp</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ExpandDims.html">mindspore.ops.ExpandDims</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Expm1.html">mindspore.ops.Expm1</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Floor.html">mindspore.ops.Floor</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.FloorDiv.html">mindspore.ops.FloorDiv</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.FloorMod.html">mindspore.ops.FloorMod</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Gamma.html">mindspore.ops.Gamma</a></td>
<td style="text-align: left;">1. Set the strategy for <code>shape</code>. e.g shape=(8, 16), the corresponding policy can be (2, 4); <br /> 2. The strategy for <code>alpha</code> and <code>beta</code> must be all-1; <br /> 3. When the setting for <code>shard</code> is not all-1 strategy, the result is inconsistent with standalone.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Gather.html">mindspore.ops.Gather</a></td>
<td style="text-align: left;">1. Uniform split:<br />1) Only support 1-dim and 2-dim parameters and the last dimension of the input_params should be 32-byte aligned;<br />2) Scalar input_indices is not supported;<br />3) Repeated calculation is not supported when the parameters are split in the dimension of the axis;<br />4) Splitting input_indices and input_params at the same time is not supported;<br />5) When axis = 0 and the parameter is split in the dimension of axis, the output strategy can be configured. The legal output shard strategy is (indices_strategy, param_strategy[1:]) or ((indices_strategy[0]*param_strategy[0], indices_strategy[1:]), param_strategy[1:])<br />2. Non-uniform split:<br />1) Only support axis = 0;<br />2) The non-uniform split only represents the non-uniformity of the 0th dimension of input_params, and the last dimension of the params slice should be aligned by 32 bytes;<br />3) The number of slices in the 0th dimension of input_params should be equal to that of the last dimension of input_indices;<br />4) Each dimension of input_params can be split, but input_indices can only split the last dimension, and does not support repeated calculations;<br />5) Input_indices shall meet the following requirements: the Tensor value of the next slice shall be greater than that of the previous slice.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.GatherD.html">mindspore.ops.GatherD</a></td>
<td style="text-align: left;">The dimension corresponding to dim cannot be segmented; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.GatherNd.html">mindspore.ops.GatherNd</a></td>
<td style="text-align: left;">The first input can't be split, and the last dimension of the second input can't be split; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.GeLU.html">mindspore.ops.GeLU</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Greater.html">mindspore.ops.Greater</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.GreaterEqual.html">mindspore.ops.GreaterEqual</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.HShrink.html">mindspore.ops.HShrink</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.HSigmoid.html">mindspore.ops.HSigmoid</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.InplaceAdd.html">mindspore.ops.InplaceAdd</a></td>
<td style="text-align: left;">The first dimension of <code>x</code> and <code>input_v</code> can't be split.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.InplaceSub.html">mindspore.ops.InplaceSub</a></td>
<td style="text-align: left;">The same as InplaceAdd.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.InplaceUpdate.html">mindspore.ops.InplaceUpdate</a></td>
<td style="text-align: left;">The same as InplaceAdd.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Inv.html">mindspore.ops.Inv</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.IOU.html">mindspore.ops.IOU</a></td>
<td style="text-align: left;">The first dimension of the <code>anchor_boxes</code> and <code>gt_boxes</code> can be spilt.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.IsFinite.html">mindspore.ops.IsFinite</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.KLDivLoss.html">mindspore.ops.KLDivLoss</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.L2Loss.html">mindspore.ops.L2Loss</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.L2Normalize.html">mindspore.ops.L2Normalize</a></td>
<td style="text-align: left;">The input_x can't be split into the dimension of axis, otherwise it's inconsistent with the single machine in the mathematical logic.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Lerp.html">mindspore.ops.Lerp</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Less.html">mindspore.ops.Less</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.LessEqual.html">mindspore.ops.LessEqual</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.LinSpace.html">mindspore.ops.LinSpace</a></td>
<td style="text-align: left;">You don't need to configure strategy for <code>start</code> and <code>end</code>. You just need to pass in a strategy of length 1 whose value divisible into <code>num</code>.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.LogicalAnd.html">mindspore.ops.LogicalAnd</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.LogicalNot.html">mindspore.ops.LogicalNot</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.LogicalOr.html">mindspore.ops.LogicalOr</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Log.html">mindspore.ops.Log</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Log1p.html">mindspore.ops.Log1p</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.LogSoftmax.html">mindspore.ops.LogSoftmax</a></td>
<td style="text-align: left;">The logits can't be split into the dimension of axis, otherwise it's inconsistent with the single machine in the mathematical logic.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.MaskedFill.html">mindspore.ops.MaskedFill</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.MatMul.html">mindspore.ops.MatMul</a></td>
<td style="text-align: left;">1. <code>transpose_a=True</code> is not supported; <br />2. When <code>transpose_b=True</code> is set, the input's split strategy must be in the form of ((A, B), (C, B));<br />3. When <code>transpose_b=False</code> is set, the input's split strategy must be in the form of ((A, B), (B, C));<br />4. It is supported to set the output's split strategy, the legal output's split strategy is ((A, C),) or ((A * B, C),)</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Maximum.html">mindspore.ops.Maximum</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.MaxPool.html">mindspore.ops.MaxPool</a></td>
<td style="text-align: left;">1. The data format only supports 'NCHW'; <br />2. The shapes of output H/W dimension must be divisible by the split strategies of input H/W dimension;<br />3. If H/W is split: <br />    1) If the kernel_size &lt;= stride, the input slice size must be divisible by stride;<br />    2) It does not support kernel_size &gt; stride;<br />4. In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.MaxPool3D.html">mindspore.ops.MaxPool3D</a></td>
<td style="text-align: left;">The same as AvgPool3D.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Minimum.html">mindspore.ops.Minimum</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Mish.html">mindspore.ops.Mish</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Mod.html">mindspore.ops.Mod</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Mul.html">mindspore.ops.Mul</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.MulNoNan.html">mindspore.ops.MulNoNan</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Neg.html">mindspore.ops.Neg</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.NotEqual.html">mindspore.ops.NotEqual</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.OneHot.html">mindspore.ops.OneHot</a></td>
<td style="text-align: left;">Only support 1-dim indices. Must configure strategy for the output and the first and second inputs.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.OnesLike.html">mindspore.ops.OnesLike</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Pow.html">mindspore.ops.Pow</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.PReLU.html">mindspore.ops.PReLU</a></td>
<td style="text-align: left;">When the shape of weight is not [1], the shard strategy in channel dimension of input_x should be consistent with weight.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.RandomChoiceWithMask.html">mindspore.ops.RandomChoiceWithMask</a></td>
<td style="text-align: left;">Only the all-1 strategy is supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.RealDiv.html">mindspore.ops.RealDiv</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Reciprocal.html">mindspore.ops.Reciprocal</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ReduceMax.html">mindspore.ops.ReduceMax</a></td>
<td style="text-align: left;">When the input_x is splited on the axis dimension, the distributed result may be inconsistent with that on the single machine.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ReduceMin.html">mindspore.ops.ReduceMin</a></td>
<td style="text-align: left;">When the input_x is splited on the axis dimension, the distributed result may be inconsistent with that on the single machine.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ReduceSum.html">mindspore.ops.ReduceSum</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ReduceMean.html">mindspore.ops.ReduceMean</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ReLU.html">mindspore.ops.ReLU</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ReLU6.html">mindspore.ops.ReLU6</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Reshape.html">mindspore.ops.Reshape</a></td>
<td style="text-align: left;">Configuring shard strategy is not supported. In auto parallel mode, if multiple operators are followed by the reshape operator, different shard strategys are not allowed to be configured for these operators.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ResizeBilinear.html">mindspore.ops.ResizeBilinear</a></td>
<td style="text-align: left;">Under GPU platform, can not split H or W dimension; Under Ascend platform, can not split H dimension, and the output shape of W dimension can be divided by the strategy.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Rint.html">mindspore.ops.Rint</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ResizeNearestNeighbor.html">mindspore.ops.ResizeNearestNeighbor</a></td>
<td style="text-align: left;">When <code>align_corners=True</code> is set, only the first dimension and the second dimension can be split.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ROIAlign.html">mindspore.ops.ROIAlign</a></td>
<td style="text-align: left;">Sharding the H/W dimension of the input(features) and the second dimension of input(rois) is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Round.html">mindspore.ops.Round</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Rsqrt.html">mindspore.ops.Rsqrt</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ScatterAdd.html">mindspore.ops.ScatterAdd</a></td>
<td style="text-align: left;">The second input cannot be split, and the top n dimensions of the third input (n is the dimension of the second input) cannot be split; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ScatterDiv.html">mindspore.ops.ScatterDiv</a></td>
<td style="text-align: left;">The second input cannot be split, and the top n dimensions of the third input (n is the dimension of the second input) cannot be split; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ScatterMax.html">mindspore.ops.ScatterMax</a></td>
<td style="text-align: left;">The first dimension of the first input cannot be split, the second input cannot be split, and the top n dimensions of the third input (n is the dimension of the second input) cannot be split; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ScatterMin.html">mindspore.ops.ScatterMin</a></td>
<td style="text-align: left;">The first dimension of the first input cannot be split, the second input cannot be split, and the top n dimensions of the third input (n is the dimension of the second input) cannot be split; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ScatterMul.html">mindspore.ops.ScatterMul</a></td>
<td style="text-align: left;">The second input cannot be split, and the top n dimensions of the third input (n is the dimension of the second input) cannot be split; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ScatterNdAdd.html">mindspore.ops.ScatterNdAdd</a></td>
<td style="text-align: left;">The second input cannot be split, the top n-1 dimension of the third input (n is the dimension of the second input) cannot be split, and the remaining k dimensions (excluding the top n-1 dimension) of the third input are consistent with the last k partitions of the first input; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ScatterNdSub.html">mindspore.ops.ScatterNdSub</a></td>
<td style="text-align: left;">The second input cannot be split, the top n-1 dimension of the third input (n is the dimension of the second input) cannot be split, and the remaining k dimensions (excluding the top n-1 dimension) of the third input are consistent with the last k partitions of the first input; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ScatterNdUpdate.html">mindspore.ops.ScatterNdUpdate</a></td>
<td style="text-align: left;">The top m dimension of the first input cannot be cut (m is the value of the last dimension of the second input indexes [- 1]). The second input cannot be split. The top n-1 dimension of the third input (n is the dimension of the second input) cannot be split. The partitions of the remaining k dimensions (excluding the top n-1 dimension) of the third input is consistent with the last k partitions of the first input; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ScatterSub.html">mindspore.ops.ScatterSub</a></td>
<td style="text-align: left;">The second input cannot be split, and the top n dimensions of the third input (n is the dimension of the second input) cannot be split; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ScatterUpdate.html">mindspore.ops.ScatterUpdate</a></td>
<td style="text-align: left;">The first dimension of first input can not be split, the second input can not  be split, and the first n dimensions (n is the dimension size of the second input) of the third input can not be split; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.TensorScatterAdd.html">mindspore.ops.TensorScatterAdd</a></td>
<td style="text-align: left;">The second input cannot be split, the top n-1 dimension of the third input (n is the dimension of the second input) cannot be split, and the remaining k dimensions (excluding the top n-1 dimension) of the third input are consistent with the last k partitions of the first input; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.TensorScatterDiv.html">mindspore.ops.TensorScatterDiv</a></td>
<td style="text-align: left;">The second input cannot be split, the top n-1 dimension of the third input (n is the dimension of the second input) cannot be split, and the remaining k dimensions (excluding the top n-1 dimension) of the third input are consistent with the last k partitions of the first input; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.TensorScatterMax.html">mindspore.ops.TensorScatterMax</a></td>
<td style="text-align: left;">The top m dimension of the first input cannot be cut (m is the value of the last dimension of the second input indexes [- 1]). The second input cannot be split. The top n-1 dimension of the third input (n is the dimension of the second input) cannot be split. The partitions of the remaining k dimensions (excluding the top n-1 dimension) of the third input is consistent with the last k partitions of the first input; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.TensorScatterMin.html">mindspore.ops.TensorScatterMax</a></td>
<td style="text-align: left;">The top m dimension of the first input cannot be cut (m is the value of the last dimension of the second input indexes [- 1]). The second input cannot be split. The top n-1 dimension of the third input (n is the dimension of the second input) cannot be split. The partitions of the remaining k dimensions (excluding the top n-1 dimension) of the third input is consistent with the last k partitions of the first input; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.TensorScatterMul.html">mindspore.ops.TensorScatterMul</a></td>
<td style="text-align: left;">The second input cannot be split, the top n-1 dimension of the third input (n is the dimension of the second input) cannot be split, and the remaining k dimensions (excluding the top n-1 dimension) of the third input are consistent with the last k partitions of the first input; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.TensorScatterSub.html">mindspore.ops.TensorScatterAdd</a></td>
<td style="text-align: left;">The second input cannot be split, the top n-1 dimension of the third input (n is the dimension of the second input) cannot be split, and the remaining k dimensions (excluding the top n-1 dimension) of the third input are consistent with the last k partitions of the first input; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.TensorScatterUpdate.html">mindspore.ops.TensorScatterUpdate</a></td>
<td style="text-align: left;">The top m dimension of the first input cannot be cut (m is the value of the last dimension of the second input indexes [- 1]). The second input cannot be split. The top n-1 dimension of the third input (n is the dimension of the second input) cannot be split. The partitions of the remaining k dimensions (excluding the top n-1 dimension) of the third input is consistent with the last k partitions of the first input; In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Select.html">mindspore.ops.Select</a></td>
<td style="text-align: left;">In auto_parallel mode, the dual recursive algorithm is not supported.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.SeLU.html">mindspore.ops.SeLU</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Sigmoid.html">mindspore.ops.Sigmoid</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.SigmoidCrossEntropyWithLogits.html">mindspore.ops.SigmoidCrossEntropyWithLogits</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Sign.html">mindspore.ops.Sign</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Sin.html">mindspore.ops.Sin</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Sinh.html">mindspore.ops.Sinh</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Softmax.html">mindspore.ops.Softmax</a></td>
<td style="text-align: left;">The logits can't be split into the dimension of axis, otherwise it's inconsistent with the single machine in the mathematical logic.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.SoftmaxCrossEntropyWithLogits.html">mindspore.ops.SoftmaxCrossEntropyWithLogits</a></td>
<td style="text-align: left;">The last dimension of logits and labels can't be splited; Only supports using output[0].</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Softplus.html">mindspore.ops.Softplus</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Softsign.html">mindspore.ops.Softsign</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.SoftShrink.html">mindspore.ops.SoftShrink</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.SparseGatherV2.html">mindspore.ops.SparseGatherV2</a></td>
<td style="text-align: left;">The same as Gather.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Split.html">mindspore.ops.Split</a></td>
<td style="text-align: left;">The input_x can't be split into the dimension of axis, otherwise it's inconsistent with the single machine in the mathematical logic.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Sqrt.html">mindspore.ops.Sqrt</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Square.html">mindspore.ops.Square</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.SquaredDifference.html">mindspore.ops.SquaredDifference</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Squeeze.html">mindspore.ops.Squeeze</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Stack.html">mindspore.ops.Stack</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.StridedSlice.html">mindspore.ops.StridedSlice</a></td>
<td style="text-align: left;">Only support mask with all 0 values; The dimension needs to be split should be all extracted; Split is supported when the strides of dimension is 1.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Slice.html">mindspore.ops.Slice</a></td>
<td style="text-align: left;">The dimension needs to be split should be all extracted.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Sub.html">mindspore.ops.Sub</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Tan.html">mindspore.ops.Tan</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Tanh.html">mindspore.ops.Tanh</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Tile.html">mindspore.ops.Tile</a></td>
<td style="text-align: left;">Only support configuring shard strategy for multiples.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.TopK.html">mindspore.ops.TopK</a></td>
<td style="text-align: left;">The input_x can't be split into the last dimension, otherwise it's inconsistent with the single machine in the mathematical logic.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Transpose.html">mindspore.ops.Transpose</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.TruncateDiv.html">mindspore.ops.TruncateDiv</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.TruncateMod.html">mindspore.ops.TruncateMod</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Unique.html">mindspore.ops.Unique</a></td>
<td style="text-align: left;">Only support the repeat calculate shard strategy (1,).</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.UnsortedSegmentSum.html">mindspore.ops.UnsortedSegmentSum</a></td>
<td style="text-align: left;">The shard of input_x and segment_ids must be the same as the dimension of segment_ids.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.UnsortedSegmentMin.html">mindspore.ops.UnsortedSegmentMin</a></td>
<td style="text-align: left;">The shard of input_x and segment_ids must be the same as the dimension of segment_ids. Note that if the segment id i is missing, then the output[i] will be filled with the maximum of the input type. The user needs to mask the maximum value to avoid value overflow. The communication operation such as AllReudce will raise an Run Task Error due to overflow.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.UnsortedSegmentMax.html">mindspore.ops.UnsortedSegmentMax</a></td>
<td style="text-align: left;">The shard of input_x and segment_ids must be the same as the dimension of segment_ids. Note that if the segment id i is missing, then the output[i] will be filled with the minimum of the input type. The user needs to mask the minimum value to avoid value overflow. The communication operation such as AllReudce will raise an Run Task Error due to overflow.</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Xdivy.html">mindspore.ops.Xdivy</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.Xlogy.html">mindspore.ops.Xlogy</a></td>
<td style="text-align: left;">None</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.mindspore.cn/docs/en/r2.0/api_python/ops/mindspore.ops.ZerosLike.html">mindspore.ops.ZerosLike</a></td>
<td style="text-align: left;">None</td>
</tr>
</tbody>
</table>
<blockquote>
<div><p>Repeated calculation means that the device is not fully used. For example, the cluster has 8 devices to run distributed training, the splitting strategy only cuts the input into 4 copies. In this case, double counting will occur.</p>
</div></blockquote>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="syntax_list.html" class="btn btn-neutral float-right" title="Syntax Support" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="operator_list_implicit.html" class="btn btn-neutral float-left" title="MindSpore Implicit Type Conversion API List" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>