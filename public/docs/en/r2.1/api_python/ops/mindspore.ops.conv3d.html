<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.ops.conv3d &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script><script src="../../_static/jquery.js"></script>
        <script src="../../_static/js/theme.js"></script><script src="../../_static/underscore.js"></script><script src="../../_static/doctools.js"></script><script src="../../_static/js/training.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script><script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script><script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="mindspore.ops.deformable_conv2d" href="mindspore.ops.deformable_conv2d.html" />
    <link rel="prev" title="mindspore.ops.conv2d" href="mindspore.ops.conv2d.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/programming_paradigm.html">Functional and Object-Oriented Fusion Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/all_scenarios.html">Full-scenarios Unified Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/distributed_training_design.html">Native Distributed Parallel Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/official_models.html">Official Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../mindspore.ops.html">mindspore.ops</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../mindspore.ops.html#neural-network-layer-functions">Neural Network Layer Functions</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../mindspore.ops.html#neural-network">Neural Network</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.adaptive_avg_pool1d.html">mindspore.ops.adaptive_avg_pool1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.adaptive_avg_pool2d.html">mindspore.ops.adaptive_avg_pool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.adaptive_avg_pool3d.html">mindspore.ops.adaptive_avg_pool3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.adaptive_max_pool1d.html">mindspore.ops.adaptive_max_pool1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.adaptive_max_pool2d.html">mindspore.ops.adaptive_max_pool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.avg_pool1d.html">mindspore.ops.avg_pool1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.avg_pool2d.html">mindspore.ops.avg_pool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.avg_pool3d.html">mindspore.ops.avg_pool3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.batch_norm.html">mindspore.ops.batch_norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.bias_add.html">mindspore.ops.bias_add</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.bidense.html">mindspore.ops.bidense</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.ctc_greedy_decoder.html">mindspore.ops.ctc_greedy_decoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.conv1d.html">mindspore.ops.conv1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.conv2d.html">mindspore.ops.conv2d</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">mindspore.ops.conv3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.deformable_conv2d.html">mindspore.ops.deformable_conv2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.dense.html">mindspore.ops.dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.dropout.html">mindspore.ops.dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.dropout1d.html">mindspore.ops.dropout1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.dropout2d.html">mindspore.ops.dropout2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.dropout3d.html">mindspore.ops.dropout3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.flatten.html">mindspore.ops.flatten</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.fold.html">mindspore.ops.fold</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.fractional_max_pool3d.html">mindspore.ops.fractional_max_pool3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.lp_pool1d.html">mindspore.ops.lp_pool1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.lp_pool2d.html">mindspore.ops.lp_pool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.lrn.html">mindspore.ops.lrn</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.max_pool2d.html">mindspore.ops.max_pool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.max_pool3d.html">mindspore.ops.max_pool3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.max_unpool1d.html">mindspore.ops.max_unpool1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.max_unpool2d.html">mindspore.ops.max_unpool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.max_unpool3d.html">mindspore.ops.max_unpool3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.unfold.html">mindspore.ops.unfold</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../mindspore.ops.html#loss-functions">Loss Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mindspore.ops.html#activation-functions">Activation Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mindspore.ops.html#distance-functions">Distance Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mindspore.ops.html#sampling-functions">Sampling Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mindspore.ops.html#image-functions">Image Functions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.html#mathematical-functions">Mathematical Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.html#tensor-operation-functions">Tensor Operation Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.html#parameter-operation-functions">Parameter Operation Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.html#differential-functions">Differential Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.html#debugging-functions">Debugging Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.html#sparse-functions">Sparse Functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.scipy.html">mindspore.scipy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/tensorflow_api_mapping.html">TensorFlow and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/enveriment_preparation.html">Environment Preparation and Information Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/typical_api_comparision.html">Differences Between MindSpore and PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/model_development/model_development.html">Constructing MindSpore Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/migrator_with_tools.html">Application Practice Guide for Network Migration Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/faq.html">FAQs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Syntax Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax_support.html">Static Graph Syntax Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax/operators.html">Static Graph Syntax —— Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax/statements.html">Static Graph Syntax —— Python Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax/python_builtin_functions.html">Static Graph Syntax —— Python Built-in Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/index_support.html">Tensor Index Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/env_var_list.html">Environment Variables</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../mindspore.ops.html">mindspore.ops</a> &raquo;</li>
      <li>mindspore.ops.conv3d</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/api_python/ops/mindspore.ops.conv3d.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="mindspore-ops-conv3d">
<h1>mindspore.ops.conv3d<a class="headerlink" href="#mindspore-ops-conv3d" title="Permalink to this headline"></a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="mindspore.ops.conv3d">
<span class="sig-prename descclassname"><span class="pre">mindspore.ops.</span></span><span class="sig-name descname"><span class="pre">conv3d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'valid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/ops/function/nn_func.html#conv3d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.ops.conv3d" title="Permalink to this definition"></a></dt>
<dd><p>Applies a 3D convolution over an input tensor. The input tensor is typically of shape
<span class="math notranslate nohighlight">\((N, C_{in}, D_{in}, H_{in}, W_{in})\)</span> and output shape
<span class="math notranslate nohighlight">\((N, C_{out}, D_{out}, H_{out}, W_{out})\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is batch size, <span class="math notranslate nohighlight">\(C\)</span> is channel number,
<span class="math notranslate nohighlight">\(D\)</span> is depth, <span class="math notranslate nohighlight">\(H, W\)</span> is feature height and width respectively.
the output value of a layer is calculated as:</p>
<div class="math notranslate nohighlight">
\[\operatorname{out}\left(N_{i}, C_{\text {out}_j}\right)=\operatorname{bias}\left(C_{\text {out}_j}\right)+
\sum_{k=0}^{C_{in}-1} ccor(\text {weight}\left(C_{\text {out}_j}, k\right),
\operatorname{input}\left(N_{i}, k\right))\]</div>
<p>where <span class="math notranslate nohighlight">\(k\)</span> is kernel,
<span class="math notranslate nohighlight">\(ccor\)</span> is the <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a> ,
<span class="math notranslate nohighlight">\(C_{in}\)</span> is the channel number of the input, <span class="math notranslate nohighlight">\(out_{j}\)</span> corresponds to the jth channel of
the output and <span class="math notranslate nohighlight">\(j\)</span> is in the range of <span class="math notranslate nohighlight">\([0, C_{out}-1]\)</span>. <span class="math notranslate nohighlight">\(\text{weight}(C_{\text{out}_j}, k)\)</span>
is a convolution kernel slice with shape
<span class="math notranslate nohighlight">\((\text{kernel_size[0]}, \text{kernel_size[1]}, \text{kernel_size[2]})\)</span>,
where <span class="math notranslate nohighlight">\(\text{kernel_size[0]}\)</span>, <span class="math notranslate nohighlight">\(\text{kernel_size[1]}\)</span> and <span class="math notranslate nohighlight">\(\text{kernel_size[2]}\)</span> are
the depth, height and width of the convolution kernel respectively. <span class="math notranslate nohighlight">\(\text{bias}\)</span> is the bias parameter
and <span class="math notranslate nohighlight">\(\text{X}\)</span> is the input tensor.
The shape of full convolution kernel is
<span class="math notranslate nohighlight">\((C_{out}, C_{in} / \text{groups}, \text{kernel_size[0]}, \text{kernel_size[1]}, \text{kernel_size[2]})\)</span>,
where <cite>groups</cite> is the number of groups to split <cite>input</cite> in the channel dimension.</p>
<p>For more details, please refer to the paper <a class="reference external" href="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf">Gradient Based Learning Applied to Document
Recognition</a> .</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ol class="arabic simple">
<li><p>On Ascend platform, <cite>groups = 1</cite> must be satisfied.</p></li>
<li><p>On Ascend dilation on depth only supports the case of 1.</p></li>
</ol>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference internal" href="../mindspore/mindspore.Tensor.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – Tensor of shape <span class="math notranslate nohighlight">\((N, C_{in}, D_{in}, H_{in}, W_{in})\)</span>.</p></li>
<li><p><strong>weight</strong> (<a class="reference internal" href="../mindspore/mindspore.Tensor.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – Set size of kernel is <span class="math notranslate nohighlight">\((\text{kernel_size[0]}, \text{kernel_size[1]},
\text{kernel_size[2]})\)</span>, then the shape is <span class="math notranslate nohighlight">\((C_{out}, C_{in}, \text{kernel_size[0]},
\text{kernel_size[1]}, \text{kernel_size[1]})\)</span>.</p></li>
<li><p><strong>bias</strong> (<a class="reference internal" href="../mindspore/mindspore.Tensor.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a>) – Bias Tensor with shape <span class="math notranslate nohighlight">\((C_{out})\)</span>. When bias is None, zeros will be used. Default:
<code class="docutils literal notranslate"><span class="pre">None</span></code> .</p></li>
<li><p><strong>stride</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – The distance of kernel moving,
it can be an int number that represents
the depth, height and width of movement or a tuple of three int numbers that
represent depth, height and width movement respectively. Default: <code class="docutils literal notranslate"><span class="pre">1</span></code> .</p></li>
<li><p><strong>pad_mode</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – <p>Specifies padding mode. The optional values are
<code class="docutils literal notranslate"><span class="pre">&quot;same&quot;</span></code> , <code class="docutils literal notranslate"><span class="pre">&quot;valid&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;pad&quot;</span></code> . Default: <code class="docutils literal notranslate"><span class="pre">&quot;valid&quot;</span></code> .</p>
<ul>
<li><p>same: Adopts the way of completion. The depth, height and width of the output will be equal to
the input <cite>x</cite> divided by stride. The padding will be evenly calculated in head and tail, top and bottom,
left and right directions possiblily.
Otherwise, the last extra padding will be calculated from the tail, bottom and the right side.
If this mode is set, <cite>pad</cite> must be 0.</p></li>
<li><p>valid: Adopts the way of discarding. The possible largest depth, height and width of output
will be returned without padding. Extra pixels will be discarded. If this mode is set, <cite>pad</cite>
must be 0.</p></li>
<li><p>pad: Implicit paddings on both sides of the input in depth, height and width. The number of <cite>pad</cite> will
be padded to the input Tensor borders. <cite>pad</cite> must be greater than or equal to 0.</p></li>
</ul>
</p></li>
<li><p><strong>padding</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – The pad value to be filled. If <cite>pad</cite> is an integer,
the paddings of head, tail, top, bottom, left and right are the same, equal to pad.
If <cite>pad</cite> is a tuple/list of 3 integers, the padding of head, tail, top, bottom,
left and right equal to pad[0], pad[0], pad[1], pad[1], pad[2] and pad[2] correspondingly. Default: <code class="docutils literal notranslate"><span class="pre">0</span></code> .</p></li>
<li><p><strong>dilation</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – The data type is int or a tuple of 3 integers
<span class="math notranslate nohighlight">\((dilation_d, dilation_h, dilation_w)\)</span>. Currently, dilation on depth only supports the case of 1
on Ascend backend. Specifies the dilation rate to use for dilated convolution. If set <span class="math notranslate nohighlight">\(k &gt; 1\)</span>,
there will be <span class="math notranslate nohighlight">\(k - 1\)</span> pixels skipped for each sampling location.
The value ranges for the depth, height, and width dimensions are [1, D], [1, H], and [1, W],
respectively. Default: <code class="docutils literal notranslate"><span class="pre">1</span></code> .</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The number of groups into which the filter is divided. <cite>in_channels</cite>
and <cite>out_channels</cite> must be divisible by <cite>group</cite>. Default: <code class="docutils literal notranslate"><span class="pre">1</span></code> .</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>Tensor, the value that applied 3D convolution. The shape is <span class="math notranslate nohighlight">\((N, C_{out}, D_{out}, H_{out}, W_{out})\)</span>.</p>
<p><cite>pad_mode</cite> is ‘same’:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll} \\
    D_{out} ＝ \left \lceil{\frac{D_{in}}{\text{stride[0]}}} \right \rceil \\
    H_{out} ＝ \left \lceil{\frac{H_{in}}{\text{stride[1]}}} \right \rceil \\
    W_{out} ＝ \left \lceil{\frac{W_{in}}{\text{stride[2]}}} \right \rceil \\
\end{array}\end{split}\]</div>
<p><cite>pad_mode</cite> is ‘valid’:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll} \\
    D_{out} ＝ \left \lfloor{\frac{D_{in} - \text{dilation[0]} \times (\text{kernel_size[0]} - 1) }
    {\text{stride[0]}} + 1} \right \rfloor \\
    H_{out} ＝ \left \lfloor{\frac{H_{in} - \text{dilation[1]} \times (\text{kernel_size[1]} - 1) }
    {\text{stride[1]}} + 1} \right \rfloor \\
    W_{out} ＝ \left \lfloor{\frac{W_{in} - \text{dilation[2]} \times (\text{kernel_size[2]} - 1) }
    {\text{stride[2]}} + 1} \right \rfloor \\
\end{array}\end{split}\]</div>
<p><cite>pad_mode</cite> is ‘pad’:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll} \\
    D_{out} ＝ \left \lfloor{\frac{D_{in} + padding[0] + padding[1] - (\text{dilation[0]} - 1) \times
    \text{kernel_size[0]} - 1 }{\text{stride[0]}} + 1} \right \rfloor \\
    H_{out} ＝ \left \lfloor{\frac{H_{in} + padding[2] + padding[3] - (\text{dilation[1]} - 1) \times
    \text{kernel_size[1]} - 1 }{\text{stride[1]}} + 1} \right \rfloor \\
    W_{out} ＝ \left \lfloor{\frac{W_{in} + padding[4] + padding[5] - (\text{dilation[2]} - 1) \times
    \text{kernel_size[2]} - 1 }{\text{stride[2]}} + 1} \right \rfloor \\
\end{array}\end{split}\]</div>
</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If <cite>out_channel</cite> or <cite>groups</cite> is not an int.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If <cite>stride</cite>, <cite>padding</cite> or <cite>dilation</cite> is neither an int nor a tuple.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If <cite>bias</cite> is not a Tensor.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If the shape of <cite>bias</cite> is not <span class="math notranslate nohighlight">\(C_{out}\)</span>.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>stride</cite> or <cite>dilation</cite> is less than 1.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>pad_mode</cite> is not one of ‘same’, ‘valid’ or ‘pad’.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>padding</cite> is a tuple or list whose length is not equal to 3.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>pad_mode</cite> is not equal to ‘pad’ and <cite>pad</cite> is greater than 0.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">ops</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">weight</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">conv3d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(16, 32, 10, 32, 32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">conv3d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(16, 32, 7, 30, 30)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">conv3d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;pad&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(16, 32, 11, 32, 32)</span>
</pre></div>
</div>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindspore.ops.conv2d.html" class="btn btn-neutral float-left" title="mindspore.ops.conv2d" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mindspore.ops.deformable_conv2d.html" class="btn btn-neutral float-right" title="mindspore.ops.deformable_conv2d" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>