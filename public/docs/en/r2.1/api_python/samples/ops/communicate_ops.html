<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Distributed Set Communication Primitives &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      <link rel="stylesheet" href="../../../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script><script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/js/theme.js"></script><script src="../../../_static/underscore.js"></script><script src="../../../_static/doctools.js"></script><script src="../../../_static/js/training.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/programming_paradigm.html">Functional and Object-Oriented Fusion Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/all_scenarios.html">Full-scenarios Unified Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/distributed_training_design.html">Native Distributed Parallel Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../note/official_models.html">Official Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.scipy.html">mindspore.scipy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../note/api_mapping/tensorflow_api_mapping.html">TensorFlow and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/enveriment_preparation.html">Environment Preparation and Information Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/typical_api_comparision.html">Differences Between MindSpore and PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/model_development/model_development.html">Constructing MindSpore Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/migrator_with_tools.html">Application Practice Guide for Network Migration Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/faq.html">FAQs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Syntax Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../note/static_graph_syntax_support.html">Static Graph Syntax Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../note/static_graph_syntax/operators.html">Static Graph Syntax —— Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../note/static_graph_syntax/statements.html">Static Graph Syntax —— Python Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../note/static_graph_syntax/python_builtin_functions.html">Static Graph Syntax —— Python Built-in Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../note/index_support.html">Tensor Index Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../note/env_var_list.html">Environment Variables</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Distributed Set Communication Primitives</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/api_python/samples/ops/communicate_ops.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="distributed-set-communication-primitives">
<h1>Distributed Set Communication Primitives<a class="headerlink" href="#distributed-set-communication-primitives" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/mindspore/blob/r2.1/docs/api/api_python_en/samples/ops/communicate_ops.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.1/resource/_static/logo_source_en.svg"></a></p>
<p>Distributed training involves communication operations such as <code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>, <code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code>, <code class="docutils literal notranslate"><span class="pre">AllGather</span></code> and <code class="docutils literal notranslate"><span class="pre">Broadcast</span></code> for data transfer, and we will explain their meaning and sample code in the following sections.</p>
<p>Examples of different communication operations by using 4 GPUs are given in each of the following sections. The output in the example comes from the results of the <code class="docutils literal notranslate"><span class="pre">rank0</span></code> program on card 0. The user needs to save each section code below as a separate communication.py. Because it involves a multi-card program, the user needs to go through the <code class="docutils literal notranslate"><span class="pre">mpirun</span></code> command to start communication.py. The <code class="docutils literal notranslate"><span class="pre">mpirun</span></code> commands requires the installation of OpenMPI as well as NCCL, and please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r2.1/parallel/train_gpu.html">here</a> for the corresponding installation.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mpirun<span class="w"> </span>-output-filename<span class="w"> </span>log<span class="w"> </span>-merge-stderr-to-stdout<span class="w"> </span>-np<span class="w"> </span><span class="m">4</span><span class="w"> </span>python<span class="w"> </span>communication.py
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">-np</span></code> in the above code means that 4 process tasks will be started, occupying cards 0, 1, 2 and 3 respectively, and the output logs will be saved under the <code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code> directory. The user can view the output of the program here. <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">communication.py</span></code> indicates starting the script.</p>
<section id="allreduce">
<h2>AllReduce<a class="headerlink" href="#allreduce" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="../../../_images/allreduce.png" /></p>
<p>The <code class="docutils literal notranslate"><span class="pre">AllReduce</span></code> operation sums the input Tensor of the <code class="docutils literal notranslate"><span class="pre">AllReduce</span></code> operator in each card. Finally, the output of the <code class="docutils literal notranslate"><span class="pre">AllReduce</span></code> operator in each card is the same value. For example, as shown in the figure above, the input to the AllReduce operator for each card is <code class="docutils literal notranslate"><span class="pre">0,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">3</span></code>. After <code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>, the output of each card is the sum of all card inputs as 6(0+1+2+3).</p>
<p>The sample code is as follows: we initialize the value of the <code class="docutils literal notranslate"><span class="pre">AllReduce</span></code> operator input in each process based on the rank number (the communication number to which each card belongs), e.g. for card 0, we request an input of size 1x1 with a value of 0. Then call the <code class="docutils literal notranslate"><span class="pre">AllReduce</span></code> operator to communicate among the cards with communication domain <code class="docutils literal notranslate"><span class="pre">0-1-2-3</span></code> (communication range of all cards i.e. nccl_world_group) and print the output results.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">init</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_reduce_sum</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">AllReduce</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s2">&quot;nccl_world_group&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">value</span> <span class="o">=</span> <span class="n">get_rank</span><span class="p">()</span>
<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">value</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The card 0 runs as follows, and the output log path is <code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[6.]]
</pre></div>
</div>
</section>
<section id="allgather">
<h2>AllGather<a class="headerlink" href="#allgather" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="../../../_images/allgather.png" /></p>
<p>The <code class="docutils literal notranslate"><span class="pre">AllGather</span></code> operation will stitch the 0th dimension of the input Tensor on each card, and the final output of each card is the same value. For example, as shown above, the input of each card is a Tensor of size 1x1. After the <code class="docutils literal notranslate"><span class="pre">AllGather</span></code> operation, the output shape of the <code class="docutils literal notranslate"><span class="pre">AllGather</span></code> operator of each card is [4,1]. The element values with index [0,0] are from the input [[0.0]] of card 0 <code class="docutils literal notranslate"><span class="pre">AllGather</span></code>, and the element values with index [1,0] are from the input [[1.0]] of card 1 <code class="docutils literal notranslate"><span class="pre">AllGather</span></code>.</p>
<p>The sample code is as follows: we initialize the value of the <code class="docutils literal notranslate"><span class="pre">AllGather</span></code> operator input in each process based on the rank number (the communication number to which each card belongs), e.g. for card 0, we request an input of size 1x1 with a value of 0. Then call the <code class="docutils literal notranslate"><span class="pre">AllGather</span></code> operator to communicate among the cards with communication domain <code class="docutils literal notranslate"><span class="pre">0-1-2-3</span></code> (communication range of all cards i.e. nccl_world_group) and print the output results.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_gather</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">AllGather</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">value</span> <span class="o">=</span> <span class="n">get_rank</span><span class="p">()</span>
<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">value</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The result of the run is as follows, with the output log path <code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[0.],
 [1.],
 [2.],
 [3.]]
</pre></div>
</div>
</section>
<section id="reducescatter">
<h2>ReduceScatter<a class="headerlink" href="#reducescatter" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="../../../_images/reducescatter.png" /></p>
<p>The <code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code> operation will first sum the input of each card and then slice the data by number of cards in the 0th dimension and distribute the data to the corresponding card. For example, as shown above, the input of each card is a 4x1 Tensor. <code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code> first sums the input to get Tensor of [0, 4, 8, 12], and then distributes it to get Tensor of size 1x1 per card. For example, the output result corresponding to card 0 is [[0.0]], and the output result corresponding to card 1 is [[4.0]].</p>
<p>The sample code is as follows: we initialize the value of the <code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code> operator input in each process based on the rank number (the communication number to which each card belongs), e.g. for card 0, we request an input of size 4x1 with a value of 0. Then call the <code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code> operator to communicate among the cards with communication domain <code class="docutils literal notranslate"><span class="pre">0-1-2-3</span></code> (communication range of all cards i.e. nccl_world_group) and print the output results.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduce_scatter</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceScatter</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduce_scatter</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The running result is as follows, with the output log path <code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[0.]]
</pre></div>
</div>
</section>
<section id="broadcast">
<h2>Broadcast<a class="headerlink" href="#broadcast" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="../../../_images/broadcast.png" /></p>
<p>The sample code is as follows: we set the root node of the <code class="docutils literal notranslate"><span class="pre">Broadcast</span></code> operator to card 0, indicating that data will be broadcast from card 0 to other cards. We request an input of size 1x1 with a value of 0. Then call the <code class="docutils literal notranslate"><span class="pre">Broadcast</span></code> operator to communicate among the cards with communication domain <code class="docutils literal notranslate"><span class="pre">0-1-2-3</span></code> (communication range of all cards i.e. nccl_world_group). Finally, the output value of each card is from card 0.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">broadcast</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Broadcast</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">broadcast</span><span class="p">((</span><span class="n">x</span><span class="p">,))</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The result of the run is as follows, with the output log path <code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[0]]
</pre></div>
</div>
</section>
<section id="neighborexchange">
<h2>NeighborExchange<a class="headerlink" href="#neighborexchange" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="../../../_images/NeighborExchange.png" /></p>
<p>The <code class="docutils literal notranslate"><span class="pre">NeighborExchange</span></code> operation will provide a set of data to be sent to each of the other specific cards while receiving data from the specific card. For example, in the above figure, rank 0 sends a Tensor with shape [16,16] to rank 1 and receives a Tensor with shape [32,32] from rank 1. rank 1 sends a Tensor with shape [32,32] to rank 0 and receives a Tensor with shape [16,16] from rank 0. Finally, the rank 0 outputs the received Tensor with shape [32,32], and rank 1 outputs the received Tensor with [16,16].</p>
<p>The example code as follows: we use the <code class="docutils literal notranslate"><span class="pre">NeighborExchange</span></code> operator for data exchange between card 0 and card 1, sending data from card 0 to card 1, and receiving data from card 1. Card 1 sends data to card 0 and receives data from card 0. Finally each card outputs the received data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">Net0</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net0</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchange</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NeighborExchange</span><span class="p">(</span><span class="n">send_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">recv_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">recv_shapes</span><span class="o">=</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],),</span> <span class="n">send_shapes</span><span class="o">=</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],),</span> <span class="n">recv_type</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchange</span><span class="p">((</span><span class="n">x</span><span class="p">,))</span>
        <span class="k">return</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">Net1</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net1</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchange</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NeighborExchange</span><span class="p">(</span><span class="n">send_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">recv_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">recv_shapes</span><span class="o">=</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],),</span> <span class="n">send_shapes</span><span class="o">=</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],),</span> <span class="n">recv_type</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchange</span><span class="p">((</span><span class="n">x</span><span class="p">,))</span>
        <span class="k">return</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="n">rank_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;RANK_ID&quot;</span><span class="p">))</span>
<span class="k">if</span> <span class="p">(</span><span class="n">rank_id</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
    <span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net0</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net1</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>Use a shell script to start the 2-card script. The <code class="docutils literal notranslate"><span class="pre">rank_table_file</span></code> file below can be generated by hccl_tools.py under <a class="reference external" href="https://gitee.com/mindspore/models">models</a>, which corresponds to the directory file <code class="docutils literal notranslate"><span class="pre">models/utils/</span> <span class="pre">hccl_tools</span></code>. The sample shell script is as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_HCCL_CONFIG_PATH</span><span class="o">=</span>rank_table_file
<span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_NUM</span><span class="o">=</span><span class="m">2</span>
<span class="nv">BASE_PATH</span><span class="o">=</span><span class="k">$(</span><span class="nb">cd</span><span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>dirname<span class="w"> </span><span class="nv">$0</span><span class="k">)</span><span class="s2">&quot;</span><span class="p">;</span><span class="w"> </span><span class="nb">pwd</span><span class="k">)</span>
<span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i&lt;<span class="nv">$DEVICE_NUM</span><span class="p">;</span><span class="w"> </span>i++<span class="o">))</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>mkdir<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>cp<span class="w"> </span>-r<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/neighborexchange.py<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>/
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">RANK_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;start training for device </span><span class="nv">$i</span><span class="s2">&quot;</span>
<span class="w">    </span>python<span class="w"> </span>neighborexchange.py<span class="w"> </span>&gt;<span class="w"> </span>log.txt<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
<span class="k">done</span>
</pre></div>
</div>
<p>The results of rank0 are:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[2. 2.]
 [2. 2.]]
</pre></div>
</div>
<p>The results of rank1 are:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[1. 1. 1.]
 [1. 1. 1.]
 [1. 1. 1.]]
</pre></div>
</div>
</section>
<section id="neighborexchangev2">
<h2>NeighborExchangeV2<a class="headerlink" href="#neighborexchangev2" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="../../../_images/neighborexchangev2.png" /></p>
<p>The <code class="docutils literal notranslate"><span class="pre">NeighborExchangeV2</span></code> operation sends part of the data in the Tensor to the surrounding 8 cards according to the attribute settings, and receives data from the surrounding 8 cards and stitches them into a new Tensor, which is often used in scenarios where a large Tensor is sliced on multiple cards for distributed convolutional operations. Attributes send_rank_ids and recv_rank_ids are 8 numbers, respectively, indicating sending/receiving rank_id in 8 directions, and filling -1 means no send/no receive. As shown above, figure 2 indicates the order corresponding to the 8 directions. The attributes send_lens and recv_lens are four numbers that represent the send/receive lengths in the four directions [top, bottom, left, right], respectively. For example, in Figure 1 above, a 16-card example is shown, taking rank 10 as an example, setting send_rank_ids=[6,7,11,15,14,13,9,5], the data of rank 10 is sliced and sent to rank 5, 6, 7, 11, 15, 14, 13, 9 respectively, for example, red in Figure is sent to rank 5, red, yellow and blue to rank 6, blue to rank 7, etc. Setting recv_rank_ids=[6,7,11,15,14,13,9,5], at the same time rank10 receives some data from each of these cards stitched into the corresponding direction to form a new Tensor output, as shown in the figure with rank10 and the light green part.</p>
<p>The sample code is as follows: we use the <code class="docutils literal notranslate"><span class="pre">NeighborExchangeV2</span></code> operator for data exchange between card 0 and card 1, sending the data below card 0 to card 1 and receiving the data from card 1 stitched below. Card 1 sends the upper part of the data to card 0 and receives the data from card 0 stitched on top. Finally each card outputs the received data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">Net0</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net0</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchangev2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NeighborExchangeV2</span><span class="p">(</span><span class="n">send_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">send_lens</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">recv_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">recv_lens</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data_format</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchangev2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="k">class</span> <span class="nc">Net1</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net1</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchangev2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NeighborExchangeV2</span><span class="p">(</span><span class="n">send_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">send_lens</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">recv_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">recv_lens</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data_format</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchangev2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="n">rank_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;RANK_ID&quot;</span><span class="p">))</span>
<span class="k">if</span> <span class="p">(</span><span class="n">rank_id</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
    <span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net0</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net1</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>Use a shell script to start the 2-card script. The <code class="docutils literal notranslate"><span class="pre">rank_table_file</span></code> file below can be generated by hccl_tools.py under <a class="reference external" href="https://gitee.com/mindspore/models">models</a>, which corresponds to the directory file <code class="docutils literal notranslate"><span class="pre">models/utils/</span> <span class="pre">hccl_tools</span></code>. The sample shell script is as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_HCCL_CONFIG_PATH</span><span class="o">=</span>rank_table_file
<span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_NUM</span><span class="o">=</span><span class="m">2</span>
<span class="nv">BASE_PATH</span><span class="o">=</span><span class="k">$(</span><span class="nb">cd</span><span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>dirname<span class="w"> </span><span class="nv">$0</span><span class="k">)</span><span class="s2">&quot;</span><span class="p">;</span><span class="w"> </span><span class="nb">pwd</span><span class="k">)</span>
<span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i&lt;<span class="nv">$DEVICE_NUM</span><span class="p">;</span><span class="w"> </span>i++<span class="o">))</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>mkdir<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>cp<span class="w"> </span>-r<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/neighborexchangev2.py<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>/
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">RANK_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;start training for device </span><span class="nv">$i</span><span class="s2">&quot;</span>
<span class="w">    </span>python<span class="w"> </span>neighborexchangev2.py<span class="w"> </span>&gt;<span class="w"> </span>log.txt<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
<span class="k">done</span>
</pre></div>
</div>
<p>The results of rank0 are:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[1. 1.]
   [1. 1.]
   [2. 2.]]]]
</pre></div>
</div>
<p>The results of rank1 are:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[1. 1.]
   [2. 2.]
   [2. 2.]]]]
</pre></div>
</div>
</section>
<section id="alltoall">
<h2>AlltoAll<a class="headerlink" href="#alltoall" title="Permalink to this headline"></a></h2>
<p><img alt="image" src="../../../_images/alltoall.png" /></p>
<p>The <code class="docutils literal notranslate"><span class="pre">AlltoAll</span></code> operation will slice the input data into a specific number of chunks in a specific dimension and send them to other ranks in order, while receiving input from other ranks and stitching the data together in a specific dimension in order. For example, in the above figure, the Tensor is sliced into 5 pieces in dimension 0, while receiving data from other ranks and stitching them in dimension 1, and finally outputting the stitched data.</p>
<p>The sample code is as follows: we use <code class="docutils literal notranslate"><span class="pre">AlltoAll</span></code> operator to exchange the data of 8 cards, slice each card in the negative second dimension, and send the slice data to other cards in order, and receive the data from other cards and stitch them in the negative first dimension. Finally, each card outputs the stitched data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_to_all</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">AlltoAll</span><span class="p">(</span><span class="n">split_count</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">split_dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="n">concat_dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_to_all</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">rank_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;RANK_ID&quot;</span><span class="p">))</span>
<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">rank_id</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>To start the 8-card script by using a shell script, the <code class="docutils literal notranslate"><span class="pre">rank_table_file</span></code> file below can be generated by hccl_tools.py under <a class="reference external" href="https://gitee.com/mindspore/models">models</a>, which corresponds to the directory file <code class="docutils literal notranslate"><span class="pre">models/utils/</span> <span class="pre">hccl_tools</span></code>. The sample shell script is as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_HCCL_CONFIG_PATH</span><span class="o">=</span>rank_table_file
<span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_NUM</span><span class="o">=</span><span class="m">8</span>
<span class="nv">BASE_PATH</span><span class="o">=</span><span class="k">$(</span><span class="nb">cd</span><span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>dirname<span class="w"> </span><span class="nv">$0</span><span class="k">)</span><span class="s2">&quot;</span><span class="p">;</span><span class="w"> </span><span class="nb">pwd</span><span class="k">)</span>
<span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i&lt;<span class="nv">$DEVICE_NUM</span><span class="p">;</span><span class="w"> </span>i++<span class="o">))</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>mkdir<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>cp<span class="w"> </span>-r<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/alltoall.py<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>/
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">RANK_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;start training for device </span><span class="nv">$i</span><span class="s2">&quot;</span>
<span class="w">    </span>python<span class="w"> </span>alltoall.py<span class="w"> </span>&gt;<span class="w"> </span>log.txt<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
<span class="k">done</span>
</pre></div>
</div>
<p>The results of rank0 to rank7 are:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[0. 1. 2. 3. 4. 5. 6. 7.]]]]
</pre></div>
</div>
</section>
<section id="notes">
<h2>Notes<a class="headerlink" href="#notes" title="Permalink to this headline"></a></h2>
<p>On the Ascend chip, the three operators, NeighborExchange, NeighborExchangeV2, and AlltoAll, need to be fully-connected for network allocation.</p>
<p>The fully connected network allocation supports communication between any cards with no limit to the number of cards. The fully-connected network allocation method is available in the <a class="reference external" href="https://support.huawei.com/enterprise/en/ascend-computing/a300t-9000-pid-250702906?category=developer-documents">HCCN Tool Interface Reference</a> for configuration. For fully-connected network allocation, all cards need to have the same VLan ID, IP in the same network segment, static routing table and ARP configured to other cards. <strong>VLan ID needs to be configured on the switch</strong>, and the reference sample of the single 8-card configuration IP changes is as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Configure IP to the same network segment</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0

<span class="c1"># Strategy routing</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>table<span class="w"> </span><span class="m">100</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>table<span class="w"> </span><span class="m">101</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>table<span class="w"> </span><span class="m">102</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>table<span class="w"> </span><span class="m">103</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>table<span class="w"> </span><span class="m">104</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>table<span class="w"> </span><span class="m">105</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>table<span class="w"> </span><span class="m">106</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>table<span class="w"> </span><span class="m">107</span>

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>table<span class="w"> </span><span class="m">100</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>dev<span class="w"> </span>eth1<span class="w"> </span>table<span class="w"> </span><span class="m">101</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>dev<span class="w"> </span>eth2<span class="w"> </span>table<span class="w"> </span><span class="m">102</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>dev<span class="w"> </span>eth3<span class="w"> </span>table<span class="w"> </span><span class="m">103</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>dev<span class="w"> </span>eth4<span class="w"> </span>table<span class="w"> </span><span class="m">104</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>dev<span class="w"> </span>eth5<span class="w"> </span>table<span class="w"> </span><span class="m">105</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>dev<span class="w"> </span>eth6<span class="w"> </span>table<span class="w"> </span><span class="m">106</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>dev<span class="w"> </span>eth7<span class="w"> </span>table<span class="w"> </span><span class="m">107</span>

<span class="c1"># Static ARPs</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:16
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:15
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:14

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth1<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:17
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth1<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:15
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth1<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:14

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth2<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:17
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth2<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:16
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth2<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:14

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth3<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:17
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth3<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:16
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth3<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:15

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth4<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0e
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth4<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0d
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth4<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0c

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth5<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0f
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth5<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0d
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth5<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0c

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth6<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0f
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth6<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0e
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth6<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0c

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth7<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0f
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth7<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0e
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth7<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0d
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>