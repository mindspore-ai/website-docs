<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.dataset.audio.transforms &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script><script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/js/theme.js"></script><script src="../../../../_static/underscore.js"></script><script src="../../../../_static/doctools.js"></script><script src="../../../../_static/js/mermaid-9.3.0.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/tensor_view.html">TENSOR VIEWS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/programming_paradigm.html">Functional and Object-Oriented Fusion Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/distributed_training_design.html">Distributed Parallel Native</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/all_scenarios.html">Full-scenarios Unified Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/official_models.html">Official Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.hal.html">mindspore.hal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.multiprocessing.html">mindspore.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.experimental.html">mindspore.experimental</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/enveriment_preparation.html">Environment Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/model_development/model_development.html">Network Constructing Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/faq.html">FAQs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Syntax Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/static_graph_syntax_support.html">Static Graph Syntax Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/static_graph_syntax/operators.html">Static Graph Syntax - Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/static_graph_syntax/statements.html">Static Graph Syntax - Python Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/static_graph_syntax/python_builtin_functions.html">Static Graph Syntax - Python Built-in Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/index_support.html">Tensor Index Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/env_var_list.html">Environment Variables</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
      <li>mindspore.dataset.audio.transforms</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for mindspore.dataset.audio.transforms</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2021-2022 Huawei Technologies Co., Ltd</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">The module audio.transforms is inherited from _c_dataengine and is</span>
<span class="sd">implemented based on C++. It&#39;s a high performance module to process</span>
<span class="sd">audio. Users can apply suitable augmentations on audio data to improve</span>
<span class="sd">their training models.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">mindspore._c_dataengine</span> <span class="k">as</span> <span class="nn">cde</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">BorderType</span><span class="p">,</span> <span class="n">DensityFunction</span><span class="p">,</span> <span class="n">FadeShape</span><span class="p">,</span> <span class="n">GainType</span><span class="p">,</span> <span class="n">Interpolation</span><span class="p">,</span> <span class="n">MelType</span><span class="p">,</span> <span class="n">Modulation</span><span class="p">,</span> <span class="n">NormMode</span><span class="p">,</span> \
    <span class="n">NormType</span><span class="p">,</span> <span class="n">ResampleMethod</span><span class="p">,</span> <span class="n">ScaleType</span><span class="p">,</span> <span class="n">WindowType</span>
<span class="kn">from</span> <span class="nn">.validators</span> <span class="kn">import</span> <span class="n">check_allpass_biquad</span><span class="p">,</span> <span class="n">check_amplitude_to_db</span><span class="p">,</span> <span class="n">check_band_biquad</span><span class="p">,</span> <span class="n">check_bandpass_biquad</span><span class="p">,</span> \
    <span class="n">check_bandreject_biquad</span><span class="p">,</span> <span class="n">check_bass_biquad</span><span class="p">,</span> <span class="n">check_biquad</span><span class="p">,</span> <span class="n">check_complex_norm</span><span class="p">,</span> <span class="n">check_compute_deltas</span><span class="p">,</span> \
    <span class="n">check_contrast</span><span class="p">,</span> <span class="n">check_db_to_amplitude</span><span class="p">,</span> <span class="n">check_dc_shift</span><span class="p">,</span> <span class="n">check_deemph_biquad</span><span class="p">,</span> <span class="n">check_detect_pitch_frequency</span><span class="p">,</span> \
    <span class="n">check_dither</span><span class="p">,</span> <span class="n">check_equalizer_biquad</span><span class="p">,</span> <span class="n">check_fade</span><span class="p">,</span> <span class="n">check_flanger</span><span class="p">,</span> <span class="n">check_gain</span><span class="p">,</span> <span class="n">check_griffin_lim</span><span class="p">,</span> \
    <span class="n">check_highpass_biquad</span><span class="p">,</span> <span class="n">check_inverse_mel_scale</span><span class="p">,</span> <span class="n">check_inverse_spectrogram</span><span class="p">,</span> <span class="n">check_lfcc</span><span class="p">,</span> <span class="n">check_lfilter</span><span class="p">,</span> \
    <span class="n">check_lowpass_biquad</span><span class="p">,</span> <span class="n">check_magphase</span><span class="p">,</span> <span class="n">check_mask_along_axis</span><span class="p">,</span> <span class="n">check_mask_along_axis_iid</span><span class="p">,</span> <span class="n">check_masking</span><span class="p">,</span> \
    <span class="n">check_mel_scale</span><span class="p">,</span> <span class="n">check_mel_spectrogram</span><span class="p">,</span> <span class="n">check_mfcc</span><span class="p">,</span> <span class="n">check_mu_law_coding</span><span class="p">,</span> <span class="n">check_overdrive</span><span class="p">,</span> <span class="n">check_phase_vocoder</span><span class="p">,</span> \
    <span class="n">check_phaser</span><span class="p">,</span> <span class="n">check_pitch_shift</span><span class="p">,</span> <span class="n">check_resample</span><span class="p">,</span> <span class="n">check_riaa_biquad</span><span class="p">,</span> <span class="n">check_sliding_window_cmn</span><span class="p">,</span> \
    <span class="n">check_spectral_centroid</span><span class="p">,</span> <span class="n">check_spectrogram</span><span class="p">,</span> <span class="n">check_time_stretch</span><span class="p">,</span> <span class="n">check_treble_biquad</span><span class="p">,</span> <span class="n">check_vad</span><span class="p">,</span> <span class="n">check_vol</span>
<span class="kn">from</span> <span class="nn">..transforms.py_transforms_util</span> <span class="kn">import</span> <span class="n">Implementation</span>
<span class="kn">from</span> <span class="nn">..transforms.transforms</span> <span class="kn">import</span> <span class="n">TensorOperation</span>


<span class="k">class</span> <span class="nc">AudioTensorOperation</span><span class="p">(</span><span class="n">TensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class of Audio Tensor Ops.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">implementation</span> <span class="o">=</span> <span class="n">Implementation</span><span class="o">.</span><span class="n">C</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">input_tensor_list</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">input_tensor_list</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,)):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Input should be NumPy audio, got </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">tensor</span><span class="p">)))</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="o">*</span><span class="n">input_tensor_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;AudioTensorOperation has to implement parse() method.&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="AllpassBiquad"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.AllpassBiquad.html#mindspore.dataset.audio.AllpassBiquad">[docs]</a><span class="k">class</span> <span class="nc">AllpassBiquad</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Design two-pole all-pass filter with central frequency and bandwidth for audio waveform.</span>

<span class="sd">    An all-pass filter changes the audio&#39;s frequency to phase relationship without changing</span>
<span class="sd">    its frequency to amplitude relationship. The system function is:</span>

<span class="sd">    .. math::</span>
<span class="sd">        H(s) = \frac{s^2 - \frac{s}{Q} + 1}{s^2 + \frac{s}{Q} + 1}</span>

<span class="sd">    Similar to `SoX &lt;https://sourceforge.net/projects/sox/&gt;`_ implementation.</span>

<span class="sd">    Note:</span>
<span class="sd">        The shape of the audio waveform to be processed needs to be &lt;..., time&gt;.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int): Sampling rate (in Hz), which can&#39;t be zero.</span>
<span class="sd">        central_freq (float): Central frequency (in Hz).</span>
<span class="sd">        Q (float, optional): `Quality factor &lt;https://en.wikipedia.org/wiki/Q_factor&gt;`_ ,</span>
<span class="sd">            in range of (0, 1]. Default: ``0.707``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is 0.</span>
<span class="sd">        TypeError: If `central_freq` is not of type float.</span>
<span class="sd">        TypeError: If `Q` is not of type float.</span>
<span class="sd">        ValueError: If `Q` is not in range of (0, 1].</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode.</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.AllpassBiquad(44100, 200.0)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.AllpassBiquad(44100, 200.0)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_allpass_biquad</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">central_freq</span><span class="p">,</span> <span class="n">Q</span><span class="o">=</span><span class="mf">0.707</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">central_freq</span> <span class="o">=</span> <span class="n">central_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span> <span class="o">=</span> <span class="n">Q</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">AllpassBiquadOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">central_freq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span><span class="p">)</span></div>


<span class="n">DE_C_SCALE_TYPE</span> <span class="o">=</span> <span class="p">{</span><span class="n">ScaleType</span><span class="o">.</span><span class="n">POWER</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">ScaleType</span><span class="o">.</span><span class="n">DE_SCALE_TYPE_POWER</span><span class="p">,</span>
                   <span class="n">ScaleType</span><span class="o">.</span><span class="n">MAGNITUDE</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">ScaleType</span><span class="o">.</span><span class="n">DE_SCALE_TYPE_MAGNITUDE</span><span class="p">}</span>


<div class="viewcode-block" id="AmplitudeToDB"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.AmplitudeToDB.html#mindspore.dataset.audio.AmplitudeToDB">[docs]</a><span class="k">class</span> <span class="nc">AmplitudeToDB</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Turn the input audio waveform from the amplitude/power scale to decibel scale.</span>

<span class="sd">    Note:</span>
<span class="sd">        The shape of the audio waveform to be processed needs to be &lt;..., freq, time&gt;.</span>

<span class="sd">    Args:</span>
<span class="sd">        stype (ScaleType, optional): Scale of the input waveform, which can be</span>
<span class="sd">            ``ScaleType.POWER`` or ``ScaleType.MAGNITUDE``. Default: ``ScaleType.POWER``.</span>
<span class="sd">        ref_value (float, optional): Multiplier reference value for generating</span>
<span class="sd">            `db_multiplier` . Default: ``1.0``. The formula is</span>

<span class="sd">            :math:`\text{db_multiplier} = \log10(\max(\text{ref_value}, amin))` .</span>

<span class="sd">        amin (float, optional): Lower bound to clamp the input waveform, which must</span>
<span class="sd">            be greater than zero. Default: ``1e-10``.</span>
<span class="sd">        top_db (float, optional): Minimum cut-off decibels, which must be non-negative. Default: ``80.0``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `stype` is not of type :class:`mindspore.dataset.audio.ScaleType` .</span>
<span class="sd">        TypeError: If `ref_value` is not of type float.</span>
<span class="sd">        ValueError: If `ref_value` is not a positive number.</span>
<span class="sd">        TypeError: If `amin` is not of type float.</span>
<span class="sd">        ValueError: If `amin` is not a positive number.</span>
<span class="sd">        TypeError: If `top_db` is not of type float.</span>
<span class="sd">        ValueError: If `top_db` is not a positive number.</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., freq, time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 400 // 2 + 1, 30])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.AmplitudeToDB(stype=audio.ScaleType.POWER)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (201, 30) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([400 // 2 + 1, 30])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.AmplitudeToDB(stype=audio.ScaleType.POWER)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (201, 30) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_amplitude_to_db</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stype</span><span class="o">=</span><span class="n">ScaleType</span><span class="o">.</span><span class="n">POWER</span><span class="p">,</span> <span class="n">ref_value</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">amin</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">top_db</span><span class="o">=</span><span class="mf">80.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stype</span> <span class="o">=</span> <span class="n">stype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ref_value</span> <span class="o">=</span> <span class="n">ref_value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">amin</span> <span class="o">=</span> <span class="n">amin</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">top_db</span> <span class="o">=</span> <span class="n">top_db</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">AmplitudeToDBOperation</span><span class="p">(</span><span class="n">DE_C_SCALE_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stype</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">amin</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">top_db</span><span class="p">)</span></div>


<div class="viewcode-block" id="Angle"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.Angle.html#mindspore.dataset.audio.Angle">[docs]</a><span class="k">class</span> <span class="nc">Angle</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the angle of complex number sequence.</span>

<span class="sd">    Note:</span>
<span class="sd">        The shape of the audio waveform to be processed needs to be &lt;..., complex=2&gt;.</span>
<span class="sd">        The first dimension represents the real part while the second represents the imaginary.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., complex=2&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16, 2])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.Angle()]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16, 2])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.Angle()(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">AngleOperation</span><span class="p">()</span></div>


<div class="viewcode-block" id="BandBiquad"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.BandBiquad.html#mindspore.dataset.audio.BandBiquad">[docs]</a><span class="k">class</span> <span class="nc">BandBiquad</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Design two-pole band-pass filter for audio waveform.</span>

<span class="sd">    The frequency response drops logarithmically around the center frequency. The</span>
<span class="sd">    bandwidth gives the slope of the drop. The frequencies at band edge will be</span>
<span class="sd">    half of their original amplitudes.</span>

<span class="sd">    Similar to `SoX &lt;https://sourceforge.net/projects/sox/&gt;`_ implementation.</span>

<span class="sd">    Note:</span>
<span class="sd">        The shape of the audio waveform to be processed needs to be &lt;..., time&gt;.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int): Sampling rate (in Hz), which can&#39;t be zero.</span>
<span class="sd">        central_freq (float): Central frequency (in Hz).</span>
<span class="sd">        Q (float, optional): `Quality factor &lt;https://en.wikipedia.org/wiki/Q_factor&gt;`_ ,</span>
<span class="sd">            in range of (0, 1]. Default: ``0.707``.</span>
<span class="sd">        noise (bool, optional) : If ``True``, uses the alternate mode for un-pitched audio (e.g. percussion).</span>
<span class="sd">            If ``False``, uses mode oriented to pitched audio, i.e. voice, singing, or instrumental music.</span>
<span class="sd">            Default: ``False``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is 0.</span>
<span class="sd">        TypeError: If `central_freq` is not of type float.</span>
<span class="sd">        TypeError: If `Q` is not of type float.</span>
<span class="sd">        ValueError: If `Q` is not in range of (0, 1].</span>
<span class="sd">        TypeError: If `noise` is not of type bool.</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.BandBiquad(44100, 200.0)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.BandBiquad(44100, 200.0)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_band_biquad</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">central_freq</span><span class="p">,</span> <span class="n">Q</span><span class="o">=</span><span class="mf">0.707</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">central_freq</span> <span class="o">=</span> <span class="n">central_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span> <span class="o">=</span> <span class="n">Q</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise</span> <span class="o">=</span> <span class="n">noise</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">BandBiquadOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">central_freq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">)</span></div>


<div class="viewcode-block" id="BandpassBiquad"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.BandpassBiquad.html#mindspore.dataset.audio.BandpassBiquad">[docs]</a><span class="k">class</span> <span class="nc">BandpassBiquad</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Design two-pole Butterworth band-pass filter for audio waveform.</span>

<span class="sd">    The frequency response of the Butterworth filter is maximally flat (i.e. has no ripples)</span>
<span class="sd">    in the passband and rolls off towards zero in the stopband.</span>

<span class="sd">    The system function of Butterworth band-pass filter is:</span>

<span class="sd">    .. math::</span>
<span class="sd">        H(s) = \begin{cases}</span>
<span class="sd">            \frac{s}{s^2 + \frac{s}{Q} + 1}, &amp;\text{if const_skirt_gain=True}; \cr</span>
<span class="sd">            \frac{\frac{s}{Q}}{s^2 + \frac{s}{Q} + 1}, &amp;\text{if const_skirt_gain=False}.</span>
<span class="sd">        \end{cases}</span>

<span class="sd">    Similar to `SoX &lt;https://sourceforge.net/projects/sox/&gt;`_ implementation.</span>

<span class="sd">    Note:</span>
<span class="sd">        The shape of the audio waveform to be processed needs to be &lt;..., time&gt;.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int): Sampling rate (in Hz), which can&#39;t be zero.</span>
<span class="sd">        central_freq (float): Central frequency (in Hz).</span>
<span class="sd">        Q (float, optional): `Quality factor &lt;https://en.wikipedia.org/wiki/Q_factor&gt;`_ ,</span>
<span class="sd">            in range of (0, 1]. Default: ``0.707``.</span>
<span class="sd">        const_skirt_gain (bool, optional) : If ``True``, uses a constant skirt gain (peak gain = Q);</span>
<span class="sd">            If ``False``, uses a constant 0dB peak gain. Default: ``False``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is 0.</span>
<span class="sd">        TypeError: If `central_freq` is not of type float.</span>
<span class="sd">        TypeError: If `Q` is not of type float.</span>
<span class="sd">        ValueError: If `Q` is not in range of (0, 1].</span>
<span class="sd">        TypeError: If `const_skirt_gain` is not of type bool.</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.BandpassBiquad(44100, 200.0)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.BandpassBiquad(44100, 200.0)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_bandpass_biquad</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">central_freq</span><span class="p">,</span> <span class="n">Q</span><span class="o">=</span><span class="mf">0.707</span><span class="p">,</span> <span class="n">const_skirt_gain</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">central_freq</span> <span class="o">=</span> <span class="n">central_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span> <span class="o">=</span> <span class="n">Q</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">const_skirt_gain</span> <span class="o">=</span> <span class="n">const_skirt_gain</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">BandpassBiquadOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">central_freq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span><span class="p">,</span>
                                           <span class="bp">self</span><span class="o">.</span><span class="n">const_skirt_gain</span><span class="p">)</span></div>


<div class="viewcode-block" id="BandrejectBiquad"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.BandrejectBiquad.html#mindspore.dataset.audio.BandrejectBiquad">[docs]</a><span class="k">class</span> <span class="nc">BandrejectBiquad</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Design two-pole Butterworth band-reject filter for audio waveform.</span>

<span class="sd">    The frequency response of the Butterworth filter is maximally flat (i.e. has no ripples)</span>
<span class="sd">    in the passband and rolls off towards zero in the stopband.</span>

<span class="sd">    The system function of Butterworth band-reject filter is:</span>

<span class="sd">    .. math::</span>
<span class="sd">        H(s) = \frac{s^2 + 1}{s^2 + \frac{s}{Q} + 1}</span>

<span class="sd">    Similar to `SoX &lt;https://sourceforge.net/projects/sox/&gt;`_ implementation.</span>

<span class="sd">    Note:</span>
<span class="sd">        The shape of the audio waveform to be processed needs to be &lt;..., time&gt;.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int): Sampling rate (in Hz), which can&#39;t be zero.</span>
<span class="sd">        central_freq (float): Central frequency (in Hz).</span>
<span class="sd">        Q (float, optional): `Quality factor &lt;https://en.wikipedia.org/wiki/Q_factor&gt;`_ ,</span>
<span class="sd">            in range of (0, 1]. Default: ``0.707``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is 0.</span>
<span class="sd">        TypeError: If `central_freq` is not of type float.</span>
<span class="sd">        TypeError: If `Q` is not of type float.</span>
<span class="sd">        ValueError: If `Q` is not in range of (0, 1].</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.BandrejectBiquad(44100, 200.0)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.BandrejectBiquad(44100, 200.0)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_bandreject_biquad</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">central_freq</span><span class="p">,</span> <span class="n">Q</span><span class="o">=</span><span class="mf">0.707</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">central_freq</span> <span class="o">=</span> <span class="n">central_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span> <span class="o">=</span> <span class="n">Q</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">BandrejectBiquadOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">central_freq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span><span class="p">)</span></div>


<div class="viewcode-block" id="BassBiquad"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.BassBiquad.html#mindspore.dataset.audio.BassBiquad">[docs]</a><span class="k">class</span> <span class="nc">BassBiquad</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Design a bass tone-control effect, also known as two-pole low-shelf filter for audio waveform.</span>

<span class="sd">    A low-shelf filter passes all frequencies, but increase or reduces frequencies below the shelf</span>
<span class="sd">    frequency by specified amount. The system function is:</span>

<span class="sd">    .. math::</span>
<span class="sd">        H(s) = A\frac{s^2 + \frac{\sqrt{A}}{Q}s + A}{As^2 + \frac{\sqrt{A}}{Q}s + 1}</span>

<span class="sd">    Similar to `SoX &lt;https://sourceforge.net/projects/sox/&gt;`_ implementation.</span>

<span class="sd">    Note:</span>
<span class="sd">        The shape of the audio waveform to be processed needs to be &lt;..., time&gt;.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int): Sampling rate (in Hz), which can&#39;t be zero.</span>
<span class="sd">        gain (float): Desired gain at the boost (or attenuation) in dB.</span>
<span class="sd">        central_freq (float, optional): Central frequency (in Hz). Default: ``100.0``.</span>
<span class="sd">        Q (float, optional): `Quality factor &lt;https://en.wikipedia.org/wiki/Q_factor&gt;`_ ,</span>
<span class="sd">            in range of (0, 1]. Default: ``0.707``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is 0.</span>
<span class="sd">        TypeError: If `gain` is not of type float.</span>
<span class="sd">        TypeError: If `central_freq` is not of type float.</span>
<span class="sd">        TypeError: If `Q` is not of type float.</span>
<span class="sd">        ValueError: If `Q` is not in range of (0, 1].</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.BassBiquad(44100, 100.0)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.BassBiquad(44100, 200.0)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_bass_biquad</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">gain</span><span class="p">,</span> <span class="n">central_freq</span><span class="o">=</span><span class="mf">100.0</span><span class="p">,</span> <span class="n">Q</span><span class="o">=</span><span class="mf">0.707</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">=</span> <span class="n">gain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">central_freq</span> <span class="o">=</span> <span class="n">central_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span> <span class="o">=</span> <span class="n">Q</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">BassBiquadOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gain</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">central_freq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span><span class="p">)</span></div>


<div class="viewcode-block" id="Biquad"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.Biquad.html#mindspore.dataset.audio.Biquad">[docs]</a><span class="k">class</span> <span class="nc">Biquad</span><span class="p">(</span><span class="n">TensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform a biquad filter of input audio.</span>
<span class="sd">    Mathematical fomulas refer to: `Digital_biquad_filter &lt;https://en.wikipedia.org/wiki/Digital_biquad_filter&gt;`_ .</span>

<span class="sd">    Args:</span>
<span class="sd">        b0 (float): Numerator coefficient of current input, x[n].</span>
<span class="sd">        b1 (float): Numerator coefficient of input one time step ago x[n-1].</span>
<span class="sd">        b2 (float): Numerator coefficient of input two time steps ago x[n-2].</span>
<span class="sd">        a0 (float): Denominator coefficient of current output y[n], the value can&#39;t be 0, typically 1.</span>
<span class="sd">        a1 (float): Denominator coefficient of current output y[n-1].</span>
<span class="sd">        a2 (float): Denominator coefficient of current output y[n-2].</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `b0` is not of type float.</span>
<span class="sd">        TypeError: If `b1` is not of type float.</span>
<span class="sd">        TypeError: If `b2` is not of type float.</span>
<span class="sd">        TypeError: If `a0` is not of type float.</span>
<span class="sd">        TypeError: If `a1` is not of type float.</span>
<span class="sd">        TypeError: If `a2` is not of type float.</span>
<span class="sd">        ValueError: If `a0` is 0.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.Biquad(0.01, 0.02, 0.13, 1, 0.12, 0.3)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.Biquad(0.01, 0.02, 0.13, 1, 0.12, 0.3)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_biquad</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b0</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">a0</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">a2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b0</span> <span class="o">=</span> <span class="n">b0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b1</span> <span class="o">=</span> <span class="n">b1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b2</span> <span class="o">=</span> <span class="n">b2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a0</span> <span class="o">=</span> <span class="n">a0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a1</span> <span class="o">=</span> <span class="n">a1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a2</span> <span class="o">=</span> <span class="n">a2</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">BiquadOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">a0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">a1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">a2</span><span class="p">)</span></div>


<div class="viewcode-block" id="ComplexNorm"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.ComplexNorm.html#mindspore.dataset.audio.ComplexNorm">[docs]</a><span class="k">class</span> <span class="nc">ComplexNorm</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the norm of complex number sequence.</span>

<span class="sd">    Note:</span>
<span class="sd">        The shape of the audio waveform to be processed needs to be &lt;..., complex=2&gt;.</span>
<span class="sd">        The first dimension represents the real part while the second represents the imaginary.</span>

<span class="sd">    Args:</span>
<span class="sd">        power (float, optional): Power of the norm, which must be non-negative. Default: ``1.0``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `power` is not of type float.</span>
<span class="sd">        ValueError: If `power` is a negative number.</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., complex=2&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16, 2])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.ComplexNorm()]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16, 2])  # 1 samples</span>
<span class="sd">        &gt;&gt;&gt; output = audio.ComplexNorm()(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_complex_norm</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">power</span> <span class="o">=</span> <span class="n">power</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">ComplexNormOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">power</span><span class="p">)</span></div>


<span class="n">DE_C_BORDER_TYPE</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">BorderType</span><span class="o">.</span><span class="n">CONSTANT</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">BorderType</span><span class="o">.</span><span class="n">DE_BORDER_CONSTANT</span><span class="p">,</span>
    <span class="n">BorderType</span><span class="o">.</span><span class="n">EDGE</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">BorderType</span><span class="o">.</span><span class="n">DE_BORDER_EDGE</span><span class="p">,</span>
    <span class="n">BorderType</span><span class="o">.</span><span class="n">REFLECT</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">BorderType</span><span class="o">.</span><span class="n">DE_BORDER_REFLECT</span><span class="p">,</span>
    <span class="n">BorderType</span><span class="o">.</span><span class="n">SYMMETRIC</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">BorderType</span><span class="o">.</span><span class="n">DE_BORDER_SYMMETRIC</span><span class="p">,</span>
<span class="p">}</span>


<div class="viewcode-block" id="ComputeDeltas"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.ComputeDeltas.html#mindspore.dataset.audio.ComputeDeltas">[docs]</a><span class="k">class</span> <span class="nc">ComputeDeltas</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute delta coefficients, also known as differential coefficients, of a spectrogram.</span>

<span class="sd">    Delta coefficients help to understand the dynamics of the power spectrum. It can be</span>
<span class="sd">    computed using the following formula.</span>

<span class="sd">    .. math::</span>
<span class="sd">        d_{t}=\frac{{\textstyle\sum_{n=1}^{N}}n(c_{t+n}-c_{t-n})}{2{\textstyle\sum_{n=1}^{N}}n^{2}}</span>

<span class="sd">    where :math:`d_{t}` is the deltas at time :math:`t` , :math:`c_{t}` is the spectrogram coefficients</span>
<span class="sd">    at time :math:`t` , :math:`N` is :math:`(\text{win_length} - 1) // 2` .</span>

<span class="sd">    Args:</span>
<span class="sd">        win_length (int, optional): The window length used for computing delta, must be no less than 3. Default: ``5``.</span>
<span class="sd">        pad_mode (BorderType, optional): Mode parameter passed to padding, can be ``BorderType.CONSTANT``,</span>
<span class="sd">            ``BorderType.EDGE``, ``BorderType.REFLECT`` or ``BorderType.SYMMETRIC``. Default: ``BorderType.EDGE``.</span>

<span class="sd">            - ``BorderType.CONSTANT``, pad with a constant value.</span>
<span class="sd">            - ``BorderType.EDGE``, pad with the last value on the edge.</span>
<span class="sd">            - ``BorderType.REFLECT``, reflect the value on the edge while omitting the last one.</span>
<span class="sd">              For example, pad [1, 2, 3, 4] with 2 elements on both sides will result in [3, 2, 1, 2, 3, 4, 3, 2].</span>
<span class="sd">            - ``BorderType.SYMMETRIC``, reflect the value on the edge while repeating the last one.</span>
<span class="sd">              For example, pad [1, 2, 3, 4] with 2 elements on both sides will result in [2, 1, 1, 2, 3, 4, 4, 3].</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `win_length` is not of type int.</span>
<span class="sd">        ValueError: If `win_length` is less than 3.</span>
<span class="sd">        TypeError: If `pad_mode` is not of type :class:`mindspore.dataset.audio.BorderType` .</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., freq, time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 400 // 2 + 1, 30])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.ComputeDeltas(win_length=7, pad_mode=audio.BorderType.EDGE)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (201, 30) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([400 // 2 + 1, 30])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.ComputeDeltas(win_length=7, pad_mode=audio.BorderType.EDGE)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (201, 30) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_compute_deltas</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">win_length</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="n">BorderType</span><span class="o">.</span><span class="n">EDGE</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">win_len</span> <span class="o">=</span> <span class="n">win_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_mode</span> <span class="o">=</span> <span class="n">pad_mode</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">ComputeDeltasOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">win_len</span><span class="p">,</span> <span class="n">DE_C_BORDER_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_mode</span><span class="p">))</span></div>


<div class="viewcode-block" id="Contrast"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.Contrast.html#mindspore.dataset.audio.Contrast">[docs]</a><span class="k">class</span> <span class="nc">Contrast</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply contrast effect for audio waveform.</span>

<span class="sd">    Comparable with compression, this effect modifies an audio signal to make it sound louder.</span>

<span class="sd">    Similar to `SoX &lt;https://sourceforge.net/projects/sox/&gt;`_ implementation.</span>

<span class="sd">    Note:</span>
<span class="sd">        The shape of the audio waveform to be processed needs to be &lt;..., time&gt;.</span>

<span class="sd">    Args:</span>
<span class="sd">        enhancement_amount (float, optional): Controls the amount of the enhancement,</span>
<span class="sd">            in range of [0, 100]. Default: ``75.0``. Note that `enhancement_amount` equal</span>
<span class="sd">            to 0 still gives a significant contrast enhancement.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `enhancement_amount` is not of type float.</span>
<span class="sd">        ValueError: If `enhancement_amount` is not in range [0, 100].</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.Contrast()]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.Contrast()(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_contrast</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enhancement_amount</span><span class="o">=</span><span class="mf">75.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enhancement_amount</span> <span class="o">=</span> <span class="n">enhancement_amount</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">ContrastOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enhancement_amount</span><span class="p">)</span></div>


<div class="viewcode-block" id="DBToAmplitude"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.DBToAmplitude.html#mindspore.dataset.audio.DBToAmplitude">[docs]</a><span class="k">class</span> <span class="nc">DBToAmplitude</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Turn a waveform from the decibel scale to the power/amplitude scale.</span>

<span class="sd">    Args:</span>
<span class="sd">        ref (float): Reference which the output will be scaled by.</span>
<span class="sd">        power (float): If power equals 1, will compute DB to power. If 0.5, will compute DB to amplitude.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `ref` is not of type float.</span>
<span class="sd">        TypeError: If `power` is not of type float.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.DBToAmplitude(0.5, 0.5)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.DBToAmplitude(0.5, 0.5)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_db_to_amplitude</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ref</span><span class="p">,</span> <span class="n">power</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ref</span> <span class="o">=</span> <span class="n">ref</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">power</span> <span class="o">=</span> <span class="n">power</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">DBToAmplitudeOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ref</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">power</span><span class="p">)</span></div>


<div class="viewcode-block" id="DCShift"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.DCShift.html#mindspore.dataset.audio.DCShift">[docs]</a><span class="k">class</span> <span class="nc">DCShift</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply a DC shift to the audio. This can be useful to remove DC offset from audio.</span>

<span class="sd">    Args:</span>
<span class="sd">        shift (float): The amount to shift the audio, the value must be in the range [-2.0, 2.0].</span>
<span class="sd">        limiter_gain (float, optional): Used only on peaks to prevent clipping,</span>
<span class="sd">            the value should be much less than 1, such as ``0.05`` or ``0.02``. Default: ``None``,</span>
<span class="sd">            will be set to `shift` .</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `shift` is not of type float.</span>
<span class="sd">        ValueError: If `shift` is not in range [-2.0, 2.0].</span>
<span class="sd">        TypeError: If `limiter_gain` is not of type float.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.DCShift(0.5, 0.02)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.DCShift(0.5, 0.02)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_dc_shift</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shift</span><span class="p">,</span> <span class="n">limiter_gain</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shift</span> <span class="o">=</span> <span class="n">shift</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">limiter_gain</span> <span class="o">=</span> <span class="n">limiter_gain</span> <span class="k">if</span> <span class="n">limiter_gain</span> <span class="k">else</span> <span class="n">shift</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">DCShiftOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shift</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">limiter_gain</span><span class="p">)</span></div>


<div class="viewcode-block" id="DeemphBiquad"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.DeemphBiquad.html#mindspore.dataset.audio.DeemphBiquad">[docs]</a><span class="k">class</span> <span class="nc">DeemphBiquad</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply Compact Disc (IEC 60908) de-emphasis (a treble attenuation shelving filter) to the audio waveform.</span>

<span class="sd">    Similar to `SoX &lt;https://sourceforge.net/projects/sox/&gt;`_ implementation.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int): Sampling rate of the waveform, must be 44100 or 48000 (Hz).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is not 44100 or 48000.</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 8])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.DeemphBiquad(44100)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (8,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([8])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.DeemphBiquad(44100)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (8,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_deemph_biquad</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">DeemphBiquadOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">)</span></div>


<div class="viewcode-block" id="DetectPitchFrequency"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.DetectPitchFrequency.html#mindspore.dataset.audio.DetectPitchFrequency">[docs]</a><span class="k">class</span> <span class="nc">DetectPitchFrequency</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Detect pitch frequency.</span>

<span class="sd">    It is implemented using normalized cross-correlation function and median smoothing.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int): Sampling rate of the waveform, e.g. ``44100`` (Hz), the value can&#39;t be zero.</span>
<span class="sd">        frame_time (float, optional): Duration of a frame, the value must be greater than zero. Default: ``0.01``.</span>
<span class="sd">        win_length (int, optional): The window length for median smoothing (in number of frames), the value must be</span>
<span class="sd">            greater than zero. Default: ``30``.</span>
<span class="sd">        freq_low (int, optional): Lowest frequency that can be detected (Hz), the value must be greater than zero.</span>
<span class="sd">            Default: ``85``.</span>
<span class="sd">        freq_high (int, optional): Highest frequency that can be detected (Hz), the value must be greater than zero.</span>
<span class="sd">            Default: ``3400``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is 0.</span>
<span class="sd">        TypeError: If `frame_time` is not of type float.</span>
<span class="sd">        ValueError: If `frame_time` is not positive.</span>
<span class="sd">        TypeError: If `win_length` is not of type int.</span>
<span class="sd">        ValueError: If `win_length` is not positive.</span>
<span class="sd">        TypeError: If `freq_low` is not of type int.</span>
<span class="sd">        ValueError: If `freq_low` is not positive.</span>
<span class="sd">        TypeError: If `freq_high` is not of type int.</span>
<span class="sd">        ValueError: If `freq_high` is not positive.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.DetectPitchFrequency(30, 0.1, 3, 5, 25)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (5,) float32</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.DetectPitchFrequency(30, 0.1, 3, 5, 25)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (5,) float32</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_detect_pitch_frequency</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">frame_time</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">win_length</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">freq_low</span><span class="o">=</span><span class="mi">85</span><span class="p">,</span> <span class="n">freq_high</span><span class="o">=</span><span class="mi">3400</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frame_time</span> <span class="o">=</span> <span class="n">frame_time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span> <span class="o">=</span> <span class="n">win_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">freq_low</span> <span class="o">=</span> <span class="n">freq_low</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">freq_high</span> <span class="o">=</span> <span class="n">freq_high</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">DetectPitchFrequencyOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">frame_time</span><span class="p">,</span>
                                                 <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">freq_low</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">freq_high</span><span class="p">)</span></div>


<span class="n">DE_C_DENSITY_FUNCTION</span> <span class="o">=</span> <span class="p">{</span><span class="n">DensityFunction</span><span class="o">.</span><span class="n">TPDF</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">DensityFunction</span><span class="o">.</span><span class="n">DE_DENSITY_FUNCTION_TPDF</span><span class="p">,</span>
                         <span class="n">DensityFunction</span><span class="o">.</span><span class="n">RPDF</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">DensityFunction</span><span class="o">.</span><span class="n">DE_DENSITY_FUNCTION_RPDF</span><span class="p">,</span>
                         <span class="n">DensityFunction</span><span class="o">.</span><span class="n">GPDF</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">DensityFunction</span><span class="o">.</span><span class="n">DE_DENSITY_FUNCTION_GPDF</span><span class="p">}</span>


<div class="viewcode-block" id="Dither"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.Dither.html#mindspore.dataset.audio.Dither">[docs]</a><span class="k">class</span> <span class="nc">Dither</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Dither increases the perceived dynamic range of audio stored at a</span>
<span class="sd">    particular bit-depth by eliminating nonlinear truncation distortion.</span>

<span class="sd">    Args:</span>
<span class="sd">        density_function (DensityFunction, optional): The density function of a continuous</span>
<span class="sd">            random variable, can be ``DensityFunction.TPDF`` (Triangular Probability Density Function),</span>
<span class="sd">            ``DensityFunction.RPDF`` (Rectangular Probability Density Function) or</span>
<span class="sd">            ``DensityFunction.GPDF`` (Gaussian Probability Density Function).</span>
<span class="sd">            Default: ``DensityFunction.TPDF``.</span>
<span class="sd">        noise_shaping (bool, optional): A filtering process that shapes the spectral</span>
<span class="sd">            energy of quantisation error. Default: ``False``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `density_function` is not of type :class:`mindspore.dataset.audio.DensityFunction` .</span>
<span class="sd">        TypeError: If `noise_shaping` is not of type bool.</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.Dither()]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.Dither()(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_dither</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">density_function</span><span class="o">=</span><span class="n">DensityFunction</span><span class="o">.</span><span class="n">TPDF</span><span class="p">,</span> <span class="n">noise_shaping</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">density_function</span> <span class="o">=</span> <span class="n">density_function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_shaping</span> <span class="o">=</span> <span class="n">noise_shaping</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">DitherOperation</span><span class="p">(</span><span class="n">DE_C_DENSITY_FUNCTION</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">density_function</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_shaping</span><span class="p">)</span></div>


<div class="viewcode-block" id="EqualizerBiquad"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.EqualizerBiquad.html#mindspore.dataset.audio.EqualizerBiquad">[docs]</a><span class="k">class</span> <span class="nc">EqualizerBiquad</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Design biquad equalizer filter and perform filtering.</span>

<span class="sd">    Similar to `SoX &lt;https://sourceforge.net/projects/sox/&gt;`_ implementation.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int): Sampling rate of the waveform, e.g. ``44100`` (Hz), the value can&#39;t be 0.</span>
<span class="sd">        center_freq (float): Central frequency (in Hz).</span>
<span class="sd">        gain (float): Desired gain at the boost (or attenuation) in dB.</span>
<span class="sd">        Q (float, optional): https://en.wikipedia.org/wiki/Q_factor, range: (0, 1]. Default: ``0.707``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is 0.</span>
<span class="sd">        TypeError: If `center_freq` is not of type float.</span>
<span class="sd">        TypeError: If `gain` is not of type float.</span>
<span class="sd">        TypeError: If `Q` is not of type float.</span>
<span class="sd">        ValueError: If `Q` is not in range of (0, 1].</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.EqualizerBiquad(44100, 1500, 5.5, 0.7)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.EqualizerBiquad(44100, 1500, 5.5, 0.7)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_equalizer_biquad</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">center_freq</span><span class="p">,</span> <span class="n">gain</span><span class="p">,</span> <span class="n">Q</span><span class="o">=</span><span class="mf">0.707</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">center_freq</span> <span class="o">=</span> <span class="n">center_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">=</span> <span class="n">gain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span> <span class="o">=</span> <span class="n">Q</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">EqualizerBiquadOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">center_freq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gain</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span><span class="p">)</span></div>


<span class="n">DE_C_FADE_SHAPE</span> <span class="o">=</span> <span class="p">{</span><span class="n">FadeShape</span><span class="o">.</span><span class="n">QUARTER_SINE</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">FadeShape</span><span class="o">.</span><span class="n">DE_FADE_SHAPE_QUARTER_SINE</span><span class="p">,</span>
                   <span class="n">FadeShape</span><span class="o">.</span><span class="n">HALF_SINE</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">FadeShape</span><span class="o">.</span><span class="n">DE_FADE_SHAPE_HALF_SINE</span><span class="p">,</span>
                   <span class="n">FadeShape</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">FadeShape</span><span class="o">.</span><span class="n">DE_FADE_SHAPE_LINEAR</span><span class="p">,</span>
                   <span class="n">FadeShape</span><span class="o">.</span><span class="n">LOGARITHMIC</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">FadeShape</span><span class="o">.</span><span class="n">DE_FADE_SHAPE_LOGARITHMIC</span><span class="p">,</span>
                   <span class="n">FadeShape</span><span class="o">.</span><span class="n">EXPONENTIAL</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">FadeShape</span><span class="o">.</span><span class="n">DE_FADE_SHAPE_EXPONENTIAL</span><span class="p">}</span>


<div class="viewcode-block" id="Fade"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.Fade.html#mindspore.dataset.audio.Fade">[docs]</a><span class="k">class</span> <span class="nc">Fade</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Add a fade in and/or fade out to an waveform.</span>

<span class="sd">    Args:</span>
<span class="sd">        fade_in_len (int, optional): Length of fade-in (time frames), which must be non-negative. Default: ``0``.</span>
<span class="sd">        fade_out_len (int, optional): Length of fade-out (time frames), which must be non-negative. Default: ``0``.</span>
<span class="sd">        fade_shape (FadeShape, optional): Shape of fade, five different types can be chosen as defined in FadeShape.</span>
<span class="sd">            Default: ``FadeShape.LINEAR``.</span>

<span class="sd">            - ``FadeShape.QUARTER_SINE``, means it tend to 0 in an quarter sin function.</span>

<span class="sd">            - ``FadeShape.HALF_SINE``, means it tend to 0 in an half sin function.</span>

<span class="sd">            - ``FadeShape.LINEAR``, means it linear to 0.</span>

<span class="sd">            - ``FadeShape.LOGARITHMIC``, means it tend to 0 in an logrithmic function.</span>

<span class="sd">            - ``FadeShape.EXPONENTIAL``, means it tend to 0 in an exponential function.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: If fade_in_len exceeds waveform length.</span>
<span class="sd">        RuntimeError: If fade_out_len exceeds waveform length.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.Fade(fade_in_len=3, fade_out_len=2, fade_shape=audio.FadeShape.LINEAR)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.Fade(fade_in_len=3, fade_out_len=2, fade_shape=audio.FadeShape.LINEAR)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_fade</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fade_in_len</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">fade_out_len</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">fade_shape</span><span class="o">=</span><span class="n">FadeShape</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fade_in_len</span> <span class="o">=</span> <span class="n">fade_in_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fade_out_len</span> <span class="o">=</span> <span class="n">fade_out_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fade_shape</span> <span class="o">=</span> <span class="n">fade_shape</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">FadeOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fade_in_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fade_out_len</span><span class="p">,</span> <span class="n">DE_C_FADE_SHAPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fade_shape</span><span class="p">))</span></div>


<div class="viewcode-block" id="Filtfilt"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.Filtfilt.html#mindspore.dataset.audio.Filtfilt">[docs]</a><span class="k">class</span> <span class="nc">Filtfilt</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply an IIR filter forward and backward to a waveform.</span>

<span class="sd">    Args:</span>
<span class="sd">        a_coeffs (Sequence[float]): Denominator coefficients of difference equation of dimension.</span>
<span class="sd">            Lower delays coefficients are first, e.g. [a0, a1, a2, ...].</span>
<span class="sd">            Must be same size as b_coeffs (pad with 0&#39;s as necessary).</span>
<span class="sd">        b_coeffs (Sequence[float]): Numerator coefficients of difference equation of dimension.</span>
<span class="sd">            Lower delays coefficients are first, e.g. [b0, b1, b2, ...].</span>
<span class="sd">            Must be same size as a_coeffs (pad with 0&#39;s as necessary).</span>
<span class="sd">        clamp (bool, optional): If ``True``, clamp the output signal to be in the range [-1, 1].</span>
<span class="sd">            Default: ``True``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `a_coeffs` is not of type Sequence[float].</span>
<span class="sd">        TypeError: If `b_coeffs` is not of type Sequence[float].</span>
<span class="sd">        ValueError: If `a_coeffs` and `b_coeffs` are of different sizes.</span>
<span class="sd">        TypeError: If `clamp` is not of type bool.</span>
<span class="sd">        RuntimeError: If shape of the input audio is not &lt;..., time&gt;.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.Filtfilt(a_coeffs=[0.1, 0.2, 0.3], b_coeffs=[0.1, 0.2, 0.3])]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.Filtfilt(a_coeffs=[0.1, 0.2, 0.3], b_coeffs=[0.1, 0.2, 0.3])(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_lfilter</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a_coeffs</span><span class="p">,</span> <span class="n">b_coeffs</span><span class="p">,</span> <span class="n">clamp</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a_coeffs</span> <span class="o">=</span> <span class="n">a_coeffs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b_coeffs</span> <span class="o">=</span> <span class="n">b_coeffs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clamp</span> <span class="o">=</span> <span class="n">clamp</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">FiltfiltOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a_coeffs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_coeffs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clamp</span><span class="p">)</span></div>


<span class="n">DE_C_MODULATION</span> <span class="o">=</span> <span class="p">{</span><span class="n">Modulation</span><span class="o">.</span><span class="n">SINUSOIDAL</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">Modulation</span><span class="o">.</span><span class="n">DE_MODULATION_SINUSOIDAL</span><span class="p">,</span>
                   <span class="n">Modulation</span><span class="o">.</span><span class="n">TRIANGULAR</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">Modulation</span><span class="o">.</span><span class="n">DE_MODULATION_TRIANGULAR</span><span class="p">}</span>

<span class="n">DE_C_INTERPOLATION</span> <span class="o">=</span> <span class="p">{</span><span class="n">Interpolation</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">Interpolation</span><span class="o">.</span><span class="n">DE_INTERPOLATION_LINEAR</span><span class="p">,</span>
                      <span class="n">Interpolation</span><span class="o">.</span><span class="n">QUADRATIC</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">Interpolation</span><span class="o">.</span><span class="n">DE_INTERPOLATION_QUADRATIC</span><span class="p">}</span>


<div class="viewcode-block" id="Flanger"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.Flanger.html#mindspore.dataset.audio.Flanger">[docs]</a><span class="k">class</span> <span class="nc">Flanger</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply a flanger effect to the audio.</span>

<span class="sd">    Similar to `SoX &lt;https://sourceforge.net/projects/sox/&gt;`_ implementation.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int): Sampling rate of the waveform, e.g. 44100 (Hz).</span>
<span class="sd">        delay (float, optional): Desired delay in milliseconds, in range of [0, 30]. Default: ``0.0``.</span>
<span class="sd">        depth (float, optional): Desired delay depth in milliseconds, in range of [0, 10]. Default: ``2.0``.</span>
<span class="sd">        regen (float, optional): Desired regen (feedback gain) in dB, in range of [-95, 95]. Default: ``0.0``.</span>
<span class="sd">        width (float, optional): Desired width (delay gain) in dB, in range of [0, 100]. Default: ``71.0``.</span>
<span class="sd">        speed (float, optional): Modulation speed in Hz, in range of [0.1, 10]. Default: ``0.5``.</span>
<span class="sd">        phase (float, optional): Percentage phase-shift for multi-channel, in range of [0, 100]. Default: ``25.0``.</span>
<span class="sd">        modulation (Modulation, optional): Modulation method, can be ``Modulation.SINUSOIDAL`` or</span>
<span class="sd">            ``Modulation.TRIANGULAR``. Default: ``Modulation.SINUSOIDAL``.</span>
<span class="sd">        interpolation (Interpolation, optional): Interpolation method, can be ``Interpolation.LINEAR`` or</span>
<span class="sd">            ``Interpolation.QUADRATIC``. Default: ``Interpolation.LINEAR``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is zero.</span>
<span class="sd">        TypeError: If `delay` is not of type float.</span>
<span class="sd">        ValueError: If `delay` is not in range of [0, 30].</span>
<span class="sd">        TypeError: If `depth` is not of type float.</span>
<span class="sd">        ValueError: If `depth` is not in range of [0, 10].</span>
<span class="sd">        TypeError: If `regen` is not of type float.</span>
<span class="sd">        ValueError: If `regen` is not in range of [-95, 95].</span>
<span class="sd">        TypeError: If `width` is not of type float.</span>
<span class="sd">        ValueError: If `width` is not in range of [0, 100].</span>
<span class="sd">        TypeError: If `speed` is not of type float.</span>
<span class="sd">        ValueError: If `speed` is not in range of [0.1, 10].</span>
<span class="sd">        TypeError: If `phase` is not of type float.</span>
<span class="sd">        ValueError: If `phase` is not in range of [0, 100].</span>
<span class="sd">        TypeError: If `modulation` is not of type :class:`mindspore.dataset.audio.Modulation` .</span>
<span class="sd">        TypeError: If `interpolation` is not of type :class:`mindspore.dataset.audio.Interpolation` .</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., channel, time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 4, 16])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.Flanger(44100)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (4, 16) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([4, 16])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.Flanger(44100)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (4, 16) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_flanger</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">regen</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">71.0</span><span class="p">,</span> <span class="n">speed</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">phase</span><span class="o">=</span><span class="mf">25.0</span><span class="p">,</span>
                 <span class="n">modulation</span><span class="o">=</span><span class="n">Modulation</span><span class="o">.</span><span class="n">SINUSOIDAL</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">Interpolation</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delay</span> <span class="o">=</span> <span class="n">delay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">depth</span> <span class="o">=</span> <span class="n">depth</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regen</span> <span class="o">=</span> <span class="n">regen</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">width</span> <span class="o">=</span> <span class="n">width</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">speed</span> <span class="o">=</span> <span class="n">speed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">phase</span> <span class="o">=</span> <span class="n">phase</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">modulation</span> <span class="o">=</span> <span class="n">modulation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span> <span class="o">=</span> <span class="n">interpolation</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">FlangerOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">delay</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">regen</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">speed</span><span class="p">,</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">phase</span><span class="p">,</span> <span class="n">DE_C_MODULATION</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">modulation</span><span class="p">),</span>
                                    <span class="n">DE_C_INTERPOLATION</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span><span class="p">))</span></div>


<div class="viewcode-block" id="FrequencyMasking"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.FrequencyMasking.html#mindspore.dataset.audio.FrequencyMasking">[docs]</a><span class="k">class</span> <span class="nc">FrequencyMasking</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply masking to a spectrogram in the frequency domain.</span>

<span class="sd">    Note:</span>
<span class="sd">        The shape of the audio waveform to be processed needs to be &lt;..., freq, time&gt;.</span>

<span class="sd">    Args:</span>
<span class="sd">        iid_masks (bool, optional): Whether to apply different masks to each example/channel. Default: ``False``.</span>
<span class="sd">        freq_mask_param (int, optional): When `iid_masks` is ``True``, length of the mask will be uniformly sampled</span>
<span class="sd">            from [0, freq_mask_param]; When `iid_masks` is ``False``, directly use it as length of the mask.</span>
<span class="sd">            The value should be in range of [0, freq_length], where `freq_length` is the length of audio waveform</span>
<span class="sd">            in frequency domain. Default: ``0``.</span>
<span class="sd">        mask_start (int, optional): Starting point to apply mask, only works when `iid_masks` is ``True``.</span>
<span class="sd">            The value should be in range of [0, freq_length - freq_mask_param], where `freq_length` is</span>
<span class="sd">            the length of audio waveform in frequency domain. Default: ``0``.</span>
<span class="sd">        mask_value (float, optional): Value to assign to the masked columns. Default: ``0.0``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `iid_masks` is not of type bool.</span>
<span class="sd">        TypeError: If `freq_mask_param` is not of type int.</span>
<span class="sd">        ValueError: If `freq_mask_param` is greater than the length of audio waveform in frequency domain.</span>
<span class="sd">        TypeError: If `mask_start` is not of type int.</span>
<span class="sd">        ValueError: If `mask_start` is a negative number.</span>
<span class="sd">        TypeError: If `mask_value` is not of type float.</span>
<span class="sd">        ValueError: If `mask_value` is a negative number.</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., freq, time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16, 2])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.FrequencyMasking(iid_masks=True, freq_mask_param=1)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16, 2) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16, 2])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.FrequencyMasking(iid_masks=True, freq_mask_param=1)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16, 2) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>

<span class="sd">    .. image:: frequency_masking_original.png</span>

<span class="sd">    .. image:: frequency_masking.png</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_masking</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iid_masks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">freq_mask_param</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mask_start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mask_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iid_masks</span> <span class="o">=</span> <span class="n">iid_masks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frequency_mask_param</span> <span class="o">=</span> <span class="n">freq_mask_param</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_start</span> <span class="o">=</span> <span class="n">mask_start</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_value</span> <span class="o">=</span> <span class="n">mask_value</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">FrequencyMaskingOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iid_masks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">frequency_mask_param</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_start</span><span class="p">,</span>
                                             <span class="bp">self</span><span class="o">.</span><span class="n">mask_value</span><span class="p">)</span></div>


<div class="viewcode-block" id="Gain"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.Gain.html#mindspore.dataset.audio.Gain">[docs]</a><span class="k">class</span> <span class="nc">Gain</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply amplification or attenuation to the whole waveform.</span>

<span class="sd">    Args:</span>
<span class="sd">        gain_db (float): Gain adjustment in decibels (dB). Default: ``1.0``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `gain_db` is not of type float.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 8])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.Gain(1.2)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (8,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([8])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.Gain(1.2)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (8,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_gain</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gain_db</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gain_db</span> <span class="o">=</span> <span class="n">gain_db</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">GainOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gain_db</span><span class="p">)</span></div>


<div class="viewcode-block" id="GriffinLim"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.GriffinLim.html#mindspore.dataset.audio.GriffinLim">[docs]</a><span class="k">class</span> <span class="nc">GriffinLim</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute waveform from a linear scale magnitude spectrogram using the Griffin-Lim transformation.</span>

<span class="sd">    About Griffin-Lim please refer to `A fast Griffin-Lim algorithm &lt;https://doi.org/10.1109/WASPAA.2013.6701851&gt;`_</span>
<span class="sd">    and `Signal estimation from modified short-time Fourier transform &lt;https://doi.org/10.1109/ICASSP.1983.1172092&gt;`_ .</span>

<span class="sd">    Args:</span>
<span class="sd">        n_fft (int, optional): Size of FFT. Default: ``400``.</span>
<span class="sd">        n_iter (int, optional): Number of iteration for phase recovery. Default: ``32``.</span>
<span class="sd">        win_length (int, optional): Window size for GriffinLim. Default: ``None``, will be set to `n_fft` .</span>
<span class="sd">        hop_length (int, optional): Length of hop between STFT windows.</span>
<span class="sd">            Default: ``None``, will be set to `win_length // 2` .</span>
<span class="sd">        window_type (WindowType, optional): Window type for GriffinLim, which can be ``WindowType.BARTLETT``,</span>
<span class="sd">            ``WindowType.BLACKMAN``, ``WindowType.HAMMING``, ``WindowType.HANN`` or ``WindowType.KAISER``.</span>
<span class="sd">            Default: ``WindowType.HANN``. Currently kaiser window is not supported on macOS.</span>
<span class="sd">        power (float, optional): Exponent for the magnitude spectrogram. Default: ``2.0``.</span>
<span class="sd">        momentum (float, optional): The momentum for fast Griffin-Lim. Default: ``0.99``.</span>
<span class="sd">        length (int, optional): Length of the expected output waveform. Default: ``None``,</span>
<span class="sd">            will be set to the value of last dimension of the stft matrix.</span>
<span class="sd">        rand_init (bool, optional): Flag for random phase initialization or all-zero phase initialization.</span>
<span class="sd">            Default: ``True``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `n_fft` is not of type int.</span>
<span class="sd">        ValueError: If `n_fft` is not positive.</span>
<span class="sd">        TypeError: If `n_iter` is not of type int.</span>
<span class="sd">        ValueError: If `n_iter` is not positive.</span>
<span class="sd">        TypeError: If `win_length` is not of type int.</span>
<span class="sd">        ValueError: If `win_length` is a negative number.</span>
<span class="sd">        TypeError: If `hop_length` is not of type int.</span>
<span class="sd">        ValueError: If `hop_length` is a negative number.</span>
<span class="sd">        TypeError: If `window_type` is not of type :class:`mindspore.dataset.audio.WindowType` .</span>
<span class="sd">        TypeError: If `power` is not of type float.</span>
<span class="sd">        ValueError: If `power` is not positive.</span>
<span class="sd">        TypeError: If `momentum` is not of type float.</span>
<span class="sd">        ValueError: If `momentum` is a negative number.</span>
<span class="sd">        TypeError: If `length` is not of type int.</span>
<span class="sd">        ValueError: If `length` is a negative number.</span>
<span class="sd">        TypeError: If `rand_init` is not of type bool.</span>
<span class="sd">        RuntimeError: If `n_fft` is not less than `length` .</span>
<span class="sd">        RuntimeError: If `win_length` is not less than `n_fft` .</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 201, 6])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.GriffinLim(n_fft=400)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (1000,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([201, 6])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.GriffinLim(n_fft=400)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (1000,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_griffin_lim</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_fft</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">win_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">window_type</span><span class="o">=</span><span class="n">WindowType</span><span class="o">.</span><span class="n">HANN</span><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
                 <span class="n">momentum</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rand_init</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_fft</span> <span class="o">=</span> <span class="n">n_fft</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">n_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span> <span class="o">=</span> <span class="n">win_length</span> <span class="k">if</span> <span class="n">win_length</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_fft</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span> <span class="o">=</span> <span class="n">hop_length</span> <span class="k">if</span> <span class="n">hop_length</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window_type</span> <span class="o">=</span> <span class="n">window_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">power</span> <span class="o">=</span> <span class="n">power</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">length</span> <span class="o">=</span> <span class="n">length</span> <span class="k">if</span> <span class="n">length</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rand_init</span> <span class="o">=</span> <span class="n">rand_init</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">GriffinLimOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_fft</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span><span class="p">,</span>
                                       <span class="n">DE_C_WINDOW_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">window_type</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">power</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">length</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">rand_init</span><span class="p">)</span></div>


<div class="viewcode-block" id="HighpassBiquad"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.HighpassBiquad.html#mindspore.dataset.audio.HighpassBiquad">[docs]</a><span class="k">class</span> <span class="nc">HighpassBiquad</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Design biquad highpass filter and perform filtering.</span>

<span class="sd">    Similar to `SoX &lt;https://sourceforge.net/projects/sox/&gt;`_ implementation.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int): Sampling rate of the waveform, e.g. 44100 (Hz), the value can&#39;t be 0.</span>
<span class="sd">        cutoff_freq (float): Filter cutoff frequency (in Hz).</span>
<span class="sd">        Q (float, optional): Quality factor, https://en.wikipedia.org/wiki/Q_factor, range: (0, 1]. Default: ``0.707``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is 0.</span>
<span class="sd">        TypeError: If `cutoff_freq` is not of type float.</span>
<span class="sd">        TypeError: If `Q` is not of type float.</span>
<span class="sd">        ValueError: If `Q` is not in range of (0, 1].</span>
<span class="sd">        RuntimeError: If the shape of input audio waveform does not match &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.HighpassBiquad(44100, 1500, 0.7)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.HighpassBiquad(44100, 1500, 0.7)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_highpass_biquad</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">cutoff_freq</span><span class="p">,</span> <span class="n">Q</span><span class="o">=</span><span class="mf">0.707</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cutoff_freq</span> <span class="o">=</span> <span class="n">cutoff_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span> <span class="o">=</span> <span class="n">Q</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">HighpassBiquadOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff_freq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span><span class="p">)</span></div>


<div class="viewcode-block" id="InverseMelScale"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.InverseMelScale.html#mindspore.dataset.audio.InverseMelScale">[docs]</a><span class="k">class</span> <span class="nc">InverseMelScale</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Solve for a normal STFT from a mel frequency STFT, using a conversion matrix.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_stft (int): Number of bins in STFT.</span>
<span class="sd">        n_mels (int, optional): Number of mel filterbanks. Default: ``128``.</span>
<span class="sd">        sample_rate (int, optional): Sample rate of audio signal. Default: ``16000``.</span>
<span class="sd">        f_min (float, optional): Minimum frequency. Default: ``0.0``.</span>
<span class="sd">        f_max (float, optional): Maximum frequency. Default: ``None``, will be set to `sample_rate // 2` .</span>
<span class="sd">        max_iter (int, optional): Maximum number of optimization iterations. Default: ``100000``.</span>
<span class="sd">        tolerance_loss (float, optional): Value of loss to stop optimization at. Default: ``1e-5``.</span>
<span class="sd">        tolerance_change (float, optional): Difference in losses to stop optimization at. Default: ``1e-8``.</span>
<span class="sd">        sgdargs (dict, optional): Arguments for the SGD optimizer. Default: ``None``, will be set to</span>
<span class="sd">            {&#39;sgd_lr&#39;: 0.1, &#39;sgd_momentum&#39;: 0.9}.</span>
<span class="sd">        norm (NormType, optional): Normalization method, can be ``NormType.SLANEY`` or ``NormType.NONE``.</span>
<span class="sd">            Default: ``NormType.NONE``, no narmalization.</span>
<span class="sd">        mel_type (MelType, optional): Mel scale to use, can be ``MelType.SLANEY`` or ``MelType.HTK``.</span>
<span class="sd">            Default: ``MelType.HTK``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `n_stft` is not of type int.</span>
<span class="sd">        ValueError: If `n_stft` is not positive.</span>
<span class="sd">        TypeError: If `n_mels` is not of type int.</span>
<span class="sd">        ValueError: If `n_mels` is not positive.</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is not positive.</span>
<span class="sd">        TypeError: If `f_min` is not of type float.</span>
<span class="sd">        ValueError: If `f_min` is greater than or equal to `f_max` .</span>
<span class="sd">        TypeError: If `f_max` is not of type float.</span>
<span class="sd">        ValueError: If `f_max` is a negative number.</span>
<span class="sd">        TypeError: If `max_iter` is not of type int.</span>
<span class="sd">        ValueError: If `max_iter` is a negative number.</span>
<span class="sd">        TypeError: If `tolerance_loss` is not of type float.</span>
<span class="sd">        ValueError: If `tolerance_loss` is a negative number.</span>
<span class="sd">        TypeError: If `tolerance_change` is not of type float.</span>
<span class="sd">        ValueError: If `tolerance_change` is a negative number.</span>
<span class="sd">        TypeError: If `sgdargs` is not of type dict.</span>
<span class="sd">        TypeError: If `norm` is not of type  :class:`mindspore.dataset.audio.NormType` .</span>
<span class="sd">        TypeError: If `mel_type` is not of type  :class:`mindspore.dataset.audio.MelType` .</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.randn(5, 8, 3, 2)  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.InverseMelScale(20, 3, 16000, 0, 8000, 10)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (8, 20, 2) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([8, 3, 2])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.InverseMelScale(20, 3, 16000, 0, 8000, 10)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (8, 20, 2) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_inverse_mel_scale</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_stft</span><span class="p">,</span> <span class="n">n_mels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span> <span class="n">f_min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">f_max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span>
                 <span class="n">tolerance_loss</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">tolerance_change</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span> <span class="n">sgdargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">NormType</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span> <span class="n">mel_type</span><span class="o">=</span><span class="n">MelType</span><span class="o">.</span><span class="n">HTK</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_stft</span> <span class="o">=</span> <span class="n">n_stft</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_mels</span> <span class="o">=</span> <span class="n">n_mels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_min</span> <span class="o">=</span> <span class="n">f_min</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_max</span> <span class="o">=</span> <span class="n">f_max</span> <span class="k">if</span> <span class="n">f_max</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">sample_rate</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tolerance_loss</span> <span class="o">=</span> <span class="n">tolerance_loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tolerance_change</span> <span class="o">=</span> <span class="n">tolerance_change</span>
        <span class="k">if</span> <span class="n">sgdargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sgdargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;sgd_lr&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> <span class="s1">&#39;sgd_momentum&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sgdargs</span> <span class="o">=</span> <span class="n">sgdargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mel_type</span> <span class="o">=</span> <span class="n">mel_type</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">InverseMelScaleOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_stft</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_mels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_min</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_max</span><span class="p">,</span>
                                            <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tolerance_loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tolerance_change</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sgdargs</span><span class="p">,</span>
                                            <span class="n">DE_C_NORM_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">),</span> <span class="n">DE_C_MEL_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mel_type</span><span class="p">))</span></div>


<div class="viewcode-block" id="InverseSpectrogram"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.InverseSpectrogram.html#mindspore.dataset.audio.InverseSpectrogram">[docs]</a><span class="k">class</span> <span class="nc">InverseSpectrogram</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create an inverse spectrogram to recover an audio signal from a spectrogram.</span>

<span class="sd">    Args:</span>
<span class="sd">        length (int, optional): The output length of the waveform, must be non negative. Default: ``None``,</span>
<span class="sd">            means to output the whole waveform.</span>
<span class="sd">        n_fft (int, optional): Size of FFT, creates `n_fft // 2 + 1` bins, which should be greater than 0.</span>
<span class="sd">            Default: ``400``.</span>
<span class="sd">        win_length (int, optional): Window size, which should be greater than 0.</span>
<span class="sd">            Default: ``None``, will be set to `n_fft` .</span>
<span class="sd">        hop_length (int, optional): Length of hop between STFT windows, which should be greater than 0.</span>
<span class="sd">            Default: ``None``, will be set to `win_length // 2` .</span>
<span class="sd">        pad (int, optional): Two sided padding of signal, cannot be less than 0. Default: ``0``.</span>
<span class="sd">        window (WindowType, optional): A function to create a window tensor that is applied/multiplied to each</span>
<span class="sd">            frame/window. Default: ``WindowType.HANN``.</span>
<span class="sd">        normalized (bool, optional): Whether the spectrogram was normalized by magnitude after stft. Default: ``False``.</span>
<span class="sd">        center (bool, optional): Whether the signal in spectrogram was padded on both sides. Default: ``True``.</span>
<span class="sd">        pad_mode (BorderType, optional): Controls the padding method used when `center` is ``True``,</span>
<span class="sd">            can be ``BorderType.REFLECT``, ``BorderType.CONSTANT``, ``BorderType.EDGE`` or ``BorderType.SYMMETRIC``.</span>
<span class="sd">            Default: ``BorderType.REFLECT``.</span>
<span class="sd">        onesided (bool, optional): Controls whether spectrogram was used to return half of results to avoid</span>
<span class="sd">            redundancy. Default: ``True``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `length` is not of type int.</span>
<span class="sd">        ValueError: If `length` is a negative number.</span>
<span class="sd">        TypeError: If `n_fft` is not of type int.</span>
<span class="sd">        ValueError: If `n_fft` is not positive.</span>
<span class="sd">        TypeError: If `win_length` is not of type int.</span>
<span class="sd">        ValueError: If `win_length` is not positive.</span>
<span class="sd">        TypeError: If `hop_length` is not of type int.</span>
<span class="sd">        ValueError: If `hop_length` is not positive.</span>
<span class="sd">        TypeError: If `pad` is not of type int.</span>
<span class="sd">        ValueError: If `pad` is a negative number.</span>
<span class="sd">        TypeError: If `window` is not of type :class:`mindspore.dataset.audio.WindowType` .</span>
<span class="sd">        TypeError: If `normalized` is not of type bool.</span>
<span class="sd">        TypeError: If `center` is not of type bool.</span>
<span class="sd">        TypeError: If `pad_mode` is not of type :class:`mindspore.dataset.audio.BorderType` .</span>
<span class="sd">        TypeError: If `onesided` is not of type bool.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 400 // 2 + 1, 30, 2])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.InverseSpectrogram(1, 400, 400, 200)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (1,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([400 // 2 + 1, 30, 2])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.InverseSpectrogram(1, 400, 400, 200)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (1,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_inverse_spectrogram</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_fft</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">win_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">window</span><span class="o">=</span><span class="n">WindowType</span><span class="o">.</span><span class="n">HANN</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">pad_mode</span><span class="o">=</span><span class="n">BorderType</span><span class="o">.</span><span class="n">REFLECT</span><span class="p">,</span> <span class="n">onesided</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">length</span> <span class="o">=</span> <span class="n">length</span> <span class="k">if</span> <span class="n">length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_fft</span> <span class="o">=</span> <span class="n">n_fft</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span> <span class="o">=</span> <span class="n">win_length</span> <span class="k">if</span> <span class="n">win_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">n_fft</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span> <span class="o">=</span> <span class="n">hop_length</span> <span class="k">if</span> <span class="n">hop_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad</span> <span class="o">=</span> <span class="n">pad</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window</span> <span class="o">=</span> <span class="n">window</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized</span> <span class="o">=</span> <span class="n">normalized</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">center</span> <span class="o">=</span> <span class="n">center</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_mode</span> <span class="o">=</span> <span class="n">pad_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">onesided</span> <span class="o">=</span> <span class="n">onesided</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">InverseSpectrogramOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_fft</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad</span><span class="p">,</span>
                                               <span class="n">DE_C_WINDOW_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">center</span><span class="p">,</span>
                                               <span class="n">DE_C_BORDER_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_mode</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">onesided</span><span class="p">)</span></div>


<span class="n">DE_C_NORM_MODE</span> <span class="o">=</span> <span class="p">{</span><span class="n">NormMode</span><span class="o">.</span><span class="n">ORTHO</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">NormMode</span><span class="o">.</span><span class="n">DE_NORM_MODE_ORTHO</span><span class="p">,</span>
                  <span class="n">NormMode</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">NormMode</span><span class="o">.</span><span class="n">DE_NORM_MODE_NONE</span><span class="p">}</span>


<div class="viewcode-block" id="LFCC"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.LFCC.html#mindspore.dataset.audio.LFCC">[docs]</a><span class="k">class</span> <span class="nc">LFCC</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create LFCC for a raw audio signal.</span>

<span class="sd">    Note:</span>
<span class="sd">        The shape of the audio waveform to be processed needs to be &lt;..., time&gt;.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int, optional): Sample rate of audio signal. Default: ``16000``.</span>
<span class="sd">        n_filter (int, optional) : Number of linear filters to apply. Default: ``128``.</span>
<span class="sd">        n_lfcc (int, optional) : Number of lfc coefficients to retain. Default: ``40``.</span>
<span class="sd">        f_min (float, optional): Minimum frequency. Default: ``0.0``.</span>
<span class="sd">        f_max (float, optional): Maximum frequency. Default: ``None``, will be set to `sample_rate // 2` .</span>
<span class="sd">        dct_type (int, optional) : Type of DCT to use. The value can only be ``2``. Default: ``2``.</span>
<span class="sd">        norm (NormMode, optional) : Norm to use. Default: ``NormMode.ORTHO``.</span>
<span class="sd">        log_lf (bool, optional) : Whether to use log-lf spectrograms instead of db-scaled. Default: ``False``.</span>
<span class="sd">        speckwargs (dict, optional) : Arguments for :class:`mindspore.dataset.audio.Spectrogram`.</span>
<span class="sd">            Default: ``None``, the default setting is a dict including</span>

<span class="sd">            - &#39;n_fft&#39;: 400</span>
<span class="sd">            - &#39;win_length&#39;: n_fft</span>
<span class="sd">            - &#39;hop_length&#39;: win_length // 2</span>
<span class="sd">            - &#39;pad&#39;: 0</span>
<span class="sd">            - &#39;window&#39;: WindowType.HANN</span>
<span class="sd">            - &#39;power&#39;: 2.0</span>
<span class="sd">            - &#39;normalized&#39;: False</span>
<span class="sd">            - &#39;center&#39;: True</span>
<span class="sd">            - &#39;pad_mode&#39;: BorderType.REFLECT</span>
<span class="sd">            - &#39;onesided&#39;: True</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        TypeError: If `n_filter` is not of type int.</span>
<span class="sd">        TypeError: If `n_lfcc` is not of type int.</span>
<span class="sd">        TypeError: If `norm` is not of type :class:`mindspore.dataset.audio.NormMode` .</span>
<span class="sd">        TypeError: If `log_lf` is not of type bool.</span>
<span class="sd">        TypeError: If `speckwargs` is not of type dict.</span>
<span class="sd">        ValueError: If `sample_rate` is 0.</span>
<span class="sd">        ValueError: If `n_lfcc` is less than 0.</span>
<span class="sd">        ValueError: If `f_min` is greater than `f_max` .</span>
<span class="sd">        ValueError: If `f_min` is greater than `sample_rate // 2` when `f_max` is set to None.</span>
<span class="sd">        ValueError: If `dct_type` is not ``2``.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 10, 300])</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.LFCC()]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (10, 40, 2) float32</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([10, 300])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.LFCC()(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (10, 40, 2) float32</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_lfcc</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span> <span class="n">n_filter</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">n_lfcc</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">f_min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">f_max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dct_type</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                 <span class="n">norm</span><span class="o">=</span><span class="n">NormMode</span><span class="o">.</span><span class="n">ORTHO</span><span class="p">,</span> <span class="n">log_lf</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">speckwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_filter</span> <span class="o">=</span> <span class="n">n_filter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_lfcc</span> <span class="o">=</span> <span class="n">n_lfcc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_min</span> <span class="o">=</span> <span class="n">f_min</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_max</span> <span class="o">=</span> <span class="n">f_max</span> <span class="k">if</span> <span class="n">f_max</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">sample_rate</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dct_type</span> <span class="o">=</span> <span class="n">dct_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_lf</span> <span class="o">=</span> <span class="n">log_lf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">speckwargs</span> <span class="o">=</span> <span class="n">speckwargs</span>
        <span class="k">if</span> <span class="n">speckwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">speckwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">speckwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;n_fft&quot;</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">speckwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;win_length&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">speckwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;n_fft&quot;</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">speckwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;hop_length&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">speckwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;win_length&quot;</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">speckwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;pad&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">speckwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;window&quot;</span><span class="p">,</span> <span class="n">WindowType</span><span class="o">.</span><span class="n">HANN</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">speckwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;power&quot;</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">speckwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;normalized&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">speckwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">speckwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;pad_mode&quot;</span><span class="p">,</span> <span class="n">BorderType</span><span class="o">.</span><span class="n">REFLECT</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">speckwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;onesided&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">speckwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;window&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">speckwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pad_mode&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">LFCCOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_filter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_lfcc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_min</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_max</span><span class="p">,</span>
                                 <span class="bp">self</span><span class="o">.</span><span class="n">dct_type</span><span class="p">,</span> <span class="n">DE_C_NORM_MODE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_lf</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">speckwargs</span><span class="p">,</span>
                                 <span class="n">DE_C_WINDOW_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">),</span> <span class="n">DE_C_BORDER_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_mode</span><span class="p">))</span></div>


<div class="viewcode-block" id="LFilter"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.LFilter.html#mindspore.dataset.audio.LFilter">[docs]</a><span class="k">class</span> <span class="nc">LFilter</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform an IIR filter by evaluating different equation.</span>

<span class="sd">    Args:</span>
<span class="sd">        a_coeffs (Sequence[float]): Denominator coefficients of difference equation of dimension.</span>
<span class="sd">            Lower delays coefficients are first, e.g. [a0, a1, a2, ...].</span>
<span class="sd">            Must be same size as b_coeffs (pad with 0&#39;s as necessary).</span>
<span class="sd">        b_coeffs (Sequence[float]): Numerator coefficients of difference equation of dimension.</span>
<span class="sd">            Lower delays coefficients are first, e.g. [b0, b1, b2, ...].</span>
<span class="sd">            Must be same size as a_coeffs (pad with 0&#39;s as necessary).</span>
<span class="sd">        clamp (bool, optional): If True, clamp the output signal to be in the range [-1, 1]. Default: ``True``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `a_coeffs` is not of type Sequence[float].</span>
<span class="sd">        TypeError: If `b_coeffs` is not of type Sequence[float].</span>
<span class="sd">        ValueError: If `a_coeffs` and `b_coeffs` are of different sizes.</span>
<span class="sd">        TypeError: If `clamp` is not of type bool.</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.LFilter(a_coeffs=[0.1, 0.2, 0.3], b_coeffs=[0.3, 0.2, 0.1])]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.LFilter(a_coeffs=[0.1, 0.2, 0.3], b_coeffs=[0.3, 0.2, 0.1])(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_lfilter</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a_coeffs</span><span class="p">,</span> <span class="n">b_coeffs</span><span class="p">,</span> <span class="n">clamp</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a_coeffs</span> <span class="o">=</span> <span class="n">a_coeffs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b_coeffs</span> <span class="o">=</span> <span class="n">b_coeffs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clamp</span> <span class="o">=</span> <span class="n">clamp</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">LFilterOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a_coeffs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_coeffs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clamp</span><span class="p">)</span></div>


<div class="viewcode-block" id="LowpassBiquad"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.LowpassBiquad.html#mindspore.dataset.audio.LowpassBiquad">[docs]</a><span class="k">class</span> <span class="nc">LowpassBiquad</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Design two-pole low-pass filter for audio waveform.</span>

<span class="sd">    A low-pass filter passes frequencies lower than a selected cutoff frequency</span>
<span class="sd">    but attenuates frequencies higher than it. The system function is:</span>

<span class="sd">    .. math::</span>
<span class="sd">        H(s) = \frac{1}{s^2 + \frac{s}{Q} + 1}</span>

<span class="sd">    Similar to `SoX &lt;https://sourceforge.net/projects/sox/&gt;`_ implementation.</span>

<span class="sd">    Note:</span>
<span class="sd">        The shape of the audio waveform to be processed needs to be &lt;..., time&gt;.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int): Sampling rate (in Hz), which can&#39;t be zero.</span>
<span class="sd">        cutoff_freq (float): Filter cutoff frequency (in Hz).</span>
<span class="sd">        Q (float, optional): `Quality factor &lt;https://en.wikipedia.org/wiki/Q_factor&gt;`_ ,</span>
<span class="sd">            in range of (0, 1]. Default: ``0.707``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is 0.</span>
<span class="sd">        TypeError: If `cutoff_freq` is not of type float.</span>
<span class="sd">        TypeError: If `Q` is not of type float.</span>
<span class="sd">        ValueError: If `Q` is not in range of (0, 1].</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 10])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.LowpassBiquad(4000, 1500, 0.7)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (10,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([10])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.LowpassBiquad(4000, 1500, 0.7)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (10,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_lowpass_biquad</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">cutoff_freq</span><span class="p">,</span> <span class="n">Q</span><span class="o">=</span><span class="mf">0.707</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cutoff_freq</span> <span class="o">=</span> <span class="n">cutoff_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span> <span class="o">=</span> <span class="n">Q</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">LowpassBiquadOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff_freq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span><span class="p">)</span></div>


<div class="viewcode-block" id="Magphase"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.Magphase.html#mindspore.dataset.audio.Magphase">[docs]</a><span class="k">class</span> <span class="nc">Magphase</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Separate a complex-valued spectrogram with shape :math:`(..., 2)` into its magnitude and phase.</span>

<span class="sd">    Args:</span>
<span class="sd">        power (float): Power of the norm, which must be non-negative. Default: ``1.0``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: If the shape of input audio waveform does not match (..., 2).</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16, 2])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.Magphase()]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;],</span>
<span class="sd">        ...                                                 output_columns=[&quot;spect&quot;, &quot;phase&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;spect&quot;].shape, item[&quot;spect&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16, 2])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.Magphase()(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output[0].shape, output[0].dtype)</span>
<span class="sd">        (16,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_magphase</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">power</span> <span class="o">=</span> <span class="n">power</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">MagphaseOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">power</span><span class="p">)</span></div>


<div class="viewcode-block" id="MaskAlongAxis"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.MaskAlongAxis.html#mindspore.dataset.audio.MaskAlongAxis">[docs]</a><span class="k">class</span> <span class="nc">MaskAlongAxis</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply a mask along `axis` . Mask will be applied from indices `[mask_start, mask_start + mask_width)` .</span>

<span class="sd">    Args:</span>
<span class="sd">        mask_start (int): Starting position of the mask, which must be non negative.</span>
<span class="sd">        mask_width (int): The width of the mask, which must be larger than 0.</span>
<span class="sd">        mask_value (float): Value to assign to the masked columns.</span>
<span class="sd">        axis (int): Axis to apply mask on (1 for frequency and 2 for time).</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If `mask_start` is invalid (&lt; 0).</span>
<span class="sd">        ValueError: If `mask_width` is invalid (&lt; 1).</span>
<span class="sd">        ValueError: If `axis` is not type of int or not within [1, 2].</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 20, 20])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.MaskAlongAxis(0, 10, 0.5, 1)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (20, 20) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([20, 20])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.MaskAlongAxis(0, 10, 0.5, 1)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (20, 20) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_mask_along_axis</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask_start</span><span class="p">,</span> <span class="n">mask_width</span><span class="p">,</span> <span class="n">mask_value</span><span class="p">,</span> <span class="n">axis</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_start</span> <span class="o">=</span> <span class="n">mask_start</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_width</span> <span class="o">=</span> <span class="n">mask_width</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_value</span> <span class="o">=</span> <span class="n">mask_value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">MaskAlongAxisOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask_start</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_width</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">axis</span><span class="p">)</span></div>


<div class="viewcode-block" id="MaskAlongAxisIID"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.MaskAlongAxisIID.html#mindspore.dataset.audio.MaskAlongAxisIID">[docs]</a><span class="k">class</span> <span class="nc">MaskAlongAxisIID</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply a mask along `axis` . Mask will be applied from indices `[mask_start, mask_start + mask_width)` , where</span>
<span class="sd">    `mask_width` is sampled from `uniform[0, mask_param]` , and `mask_start` from</span>
<span class="sd">    `uniform[0, max_length - mask_width]` , `max_length` is the number of columns of the specified axis</span>
<span class="sd">    of the spectrogram.</span>

<span class="sd">    Args:</span>
<span class="sd">        mask_param (int): Number of columns to be masked, will be uniformly sampled from</span>
<span class="sd">            [0, mask_param], must be non negative.</span>
<span class="sd">        mask_value (float): Value to assign to the masked columns.</span>
<span class="sd">        axis (int): Axis to apply mask on (1 for frequency and 2 for time).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `mask_param` is not of type int.</span>
<span class="sd">        ValueError: If `mask_param` is a negative value.</span>
<span class="sd">        TypeError: If `mask_value` is not of type float.</span>
<span class="sd">        TypeError: If `axis` is not of type int.</span>
<span class="sd">        ValueError: If `axis` is not in range of [1, 2].</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., freq, time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform= np.random.random([5, 20, 20])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.MaskAlongAxisIID(5, 0.5, 2)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (20, 20) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([20, 20])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.MaskAlongAxisIID(5, 0.5, 2)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (20, 20) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_mask_along_axis_iid</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask_param</span><span class="p">,</span> <span class="n">mask_value</span><span class="p">,</span> <span class="n">axis</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_param</span> <span class="o">=</span> <span class="n">mask_param</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_value</span> <span class="o">=</span> <span class="n">mask_value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">MaskAlongAxisIIDOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask_param</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">axis</span><span class="p">)</span></div>


<span class="n">DE_C_MEL_TYPE</span> <span class="o">=</span> <span class="p">{</span><span class="n">MelType</span><span class="o">.</span><span class="n">SLANEY</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">MelType</span><span class="o">.</span><span class="n">DE_MEL_TYPE_SLANEY</span><span class="p">,</span>
                 <span class="n">MelType</span><span class="o">.</span><span class="n">HTK</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">MelType</span><span class="o">.</span><span class="n">DE_MEL_TYPE_HTK</span><span class="p">}</span>

<span class="n">DE_C_NORM_TYPE</span> <span class="o">=</span> <span class="p">{</span><span class="n">NormType</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">NormType</span><span class="o">.</span><span class="n">DE_NORM_TYPE_NONE</span><span class="p">,</span>
                  <span class="n">NormType</span><span class="o">.</span><span class="n">SLANEY</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">NormType</span><span class="o">.</span><span class="n">DE_NORM_TYPE_SLANEY</span><span class="p">}</span>


<div class="viewcode-block" id="MelScale"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.MelScale.html#mindspore.dataset.audio.MelScale">[docs]</a><span class="k">class</span> <span class="nc">MelScale</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert normal STFT to STFT at the Mel scale.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_mels (int, optional): Number of mel filterbanks. Default: ``128``.</span>
<span class="sd">        sample_rate (int, optional): Sample rate of audio signal. Default: ``16000``.</span>
<span class="sd">        f_min (float, optional): Minimum frequency. Default: ``0.0``.</span>
<span class="sd">        f_max (float, optional): Maximum frequency. Default: ``None``, will be set to `sample_rate // 2` .</span>
<span class="sd">        n_stft (int, optional): Number of bins in STFT. Default: ``201``.</span>
<span class="sd">        norm (NormType, optional): Type of norm, value should be ``NormType.SLANEY`` or ``NormType.NONE``.</span>
<span class="sd">            If `norm` is ``NormType.SLANEY``, divide the triangular mel weight by the width of the mel band.</span>
<span class="sd">            Default: ``NormType.NONE``, no narmalization.</span>
<span class="sd">        mel_type (MelType, optional): Type to use, value should be ``MelType.SLANEY`` or ``MelType.HTK``.</span>
<span class="sd">            Default: ``MelType.HTK``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `n_mels` is not of type int.</span>
<span class="sd">        ValueError: If `n_mels` is not positive.</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is not positive.</span>
<span class="sd">        TypeError: If `f_min` is not of type float.</span>
<span class="sd">        ValueError: If `f_min` is greater than or equal to `f_max` .</span>
<span class="sd">        TypeError: If `f_max` is not of type float.</span>
<span class="sd">        ValueError: If `f_max` is a negative number.</span>
<span class="sd">        TypeError: If `n_stft` is not of type int.</span>
<span class="sd">        ValueError: If `n_stft` is not positive.</span>
<span class="sd">        TypeError: If `norm` is not of type  :class:`mindspore.dataset.audio.NormType` .</span>
<span class="sd">        TypeError: If `mel_type` is not of type  :class:`mindspore.dataset.audio.MelType` .</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 201, 3])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.MelScale(200, 1500, 0.7)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (200, 3) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([201, 3])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.MelScale(200, 1500, 0.7)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (200, 3) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_mel_scale</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_mels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span> <span class="n">f_min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">f_max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_stft</span><span class="o">=</span><span class="mi">201</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">NormType</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span>
                 <span class="n">mel_type</span><span class="o">=</span><span class="n">MelType</span><span class="o">.</span><span class="n">HTK</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_mels</span> <span class="o">=</span> <span class="n">n_mels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_min</span> <span class="o">=</span> <span class="n">f_min</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_max</span> <span class="o">=</span> <span class="n">f_max</span> <span class="k">if</span> <span class="n">f_max</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">sample_rate</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_stft</span> <span class="o">=</span> <span class="n">n_stft</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mel_type</span> <span class="o">=</span> <span class="n">mel_type</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">MelScaleOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_mels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_min</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_stft</span><span class="p">,</span>
                                     <span class="n">DE_C_NORM_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">),</span> <span class="n">DE_C_MEL_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mel_type</span><span class="p">))</span></div>


<div class="viewcode-block" id="MelSpectrogram"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.MelSpectrogram.html#mindspore.dataset.audio.MelSpectrogram">[docs]</a><span class="k">class</span> <span class="nc">MelSpectrogram</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create MelSpectrogram for a raw audio signal.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int, optional): Sampling rate of audio signal (in Hz), which can&#39;t be less than 0.</span>
<span class="sd">            Default: ``16000``.</span>
<span class="sd">        n_fft (int, optional): Size of FFT, creates `n_fft // 2 + 1` bins, which should be greater than 0 and less than</span>
<span class="sd">            twice of the last dimension size of the input. Default: ``400``.</span>
<span class="sd">        win_length (int, optional): Window size, which should be greater than 0 and no more than `n_fft` . Default:</span>
<span class="sd">            None, will be set to `n_fft` .</span>
<span class="sd">        hop_length (int, optional): Length of hop between STFT windows, which should be greater than 0.</span>
<span class="sd">            Default: ``None``, will be set to `win_length // 2` .</span>
<span class="sd">        f_min (float, optional): Minimum frequency, which can&#39;t be greater than `f_max` . Default: ``0.0``.</span>
<span class="sd">        f_max (float, optional): Maximum frequency, which can&#39;t be less than 0. Default: ``None``, will be set</span>
<span class="sd">            to `sample_rate // 2` .</span>
<span class="sd">        pad (int, optional): Two sided padding of signal, which can&#39;t be less than 0. Default: ``0``.</span>
<span class="sd">        n_mels (int, optional): Number of mel filterbanks, which can&#39;t be less than 0. Default: ``128``.</span>
<span class="sd">        window (WindowType, optional): A function to create a window tensor that is applied/multiplied to each</span>
<span class="sd">            frame/window. Default: ``WindowType.HANN``.</span>
<span class="sd">        power (float, optional): Exponent for the magnitude spectrogram, which must be</span>
<span class="sd">            greater than 0, e.g., ``1`` for energy, ``2`` for power, etc. Default: ``2.0``.</span>
<span class="sd">        normalized (bool, optional): Whether to normalize by magnitude after stft. Default: ``False``.</span>
<span class="sd">        center (bool, optional): Whether to pad waveform on both sides. Default: ``True``.</span>
<span class="sd">        pad_mode (BorderType, optional): Controls the padding method used when `center` is ``True``,</span>
<span class="sd">            can be ``BorderType.REFLECT``, ``BorderType.CONSTANT``, ``BorderType.EDGE`` or ``BorderType.SYMMETRIC``.</span>
<span class="sd">            Default: ``BorderType.REFLECT``.</span>
<span class="sd">        onesided (bool, optional): Controls whether to return half of results to avoid redundancy. Default: ``True``.</span>
<span class="sd">        norm (NormType, optional): If &#39;slaney&#39;, divide the triangular mel weights by the width of the mel band</span>
<span class="sd">            (area normalization). Default: ``NormType.NONE``, no narmalization.</span>
<span class="sd">        mel_scale (MelType, optional): Mel scale to use, can be ``MelType.SLANEY`` or ``MelType.HTK``.</span>
<span class="sd">            Default: ``MelType.HTK``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        TypeError: If `n_fft` is not of type int.</span>
<span class="sd">        TypeError: If `n_mels` is not of type int.</span>
<span class="sd">        TypeError: If `f_min` is not of type float.</span>
<span class="sd">        TypeError: If `f_max` is not of type float.</span>
<span class="sd">        TypeError: If `window` is not of type :class:`mindspore.dataset.audio.WindowType` .</span>
<span class="sd">        TypeError: If `norm` is not of type :class:`mindspore.dataset.audio.NormType` .</span>
<span class="sd">        TypeError: If `mel_scale` is not of type :class:`mindspore.dataset.audio.MelType` .</span>
<span class="sd">        TypeError: If `power` is not of type float.</span>
<span class="sd">        TypeError: If `normalized` is not of type bool.</span>
<span class="sd">        TypeError: If `center` is not of type bool.</span>
<span class="sd">        TypeError: If `pad_mode` is not of type :class:`mindspore.dataset.audio.BorderType` .</span>
<span class="sd">        TypeError: If `onesided` is not of type bool.</span>
<span class="sd">        TypeError: If `pad` is not of type int.</span>
<span class="sd">        TypeError: If `win_length` is not of type int.</span>
<span class="sd">        TypeError: If `hop_length` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is a negative number.</span>
<span class="sd">        ValueError: If `n_fft` is not positive.</span>
<span class="sd">        ValueError: If `n_mels` is a negative number.</span>
<span class="sd">        ValueError: If `f_min` is greater than `f_max` .</span>
<span class="sd">        ValueError: If `f_max` is a negative number.</span>
<span class="sd">        ValueError: If `f_min` is not less than `sample_rate // 2` when `f_max` is set to None.</span>
<span class="sd">        ValueError: If `power` is not positive.</span>
<span class="sd">        ValueError: If `pad` is a negative number.</span>
<span class="sd">        ValueError: If `win_length` is not positive.</span>
<span class="sd">        ValueError: If `hop_length` is not positive.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 32])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.MelSpectrogram(sample_rate=16000, n_fft=16, win_length=16, hop_length=8, f_min=0.0,</span>
<span class="sd">        ...                                    f_max=5000.0, pad=0, n_mels=2, window=audio.WindowType.HANN, power=2.0,</span>
<span class="sd">        ...                                    normalized=False, center=True, pad_mode=audio.BorderType.REFLECT,</span>
<span class="sd">        ...                                    onesided=True, norm=audio.NormType.SLANEY, mel_scale=audio.MelType.HTK)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (2, 5) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([32])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.MelSpectrogram(sample_rate=16000, n_fft=16, win_length=16, hop_length=8, f_min=0.0,</span>
<span class="sd">        ...                               f_max=5000.0, pad=0, n_mels=2, window=audio.WindowType.HANN, power=2.0,</span>
<span class="sd">        ...                               normalized=False, center=True, pad_mode=audio.BorderType.REFLECT,</span>
<span class="sd">        ...                               onesided=True, norm=audio.NormType.SLANEY,</span>
<span class="sd">        ...                               mel_scale=audio.MelType.HTK)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (2, 5) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_mel_spectrogram</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span> <span class="n">n_fft</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">win_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">f_min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">f_max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">n_mels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="n">WindowType</span><span class="o">.</span><span class="n">HANN</span><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">pad_mode</span><span class="o">=</span><span class="n">BorderType</span><span class="o">.</span><span class="n">REFLECT</span><span class="p">,</span> <span class="n">onesided</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">NormType</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span> <span class="n">mel_scale</span><span class="o">=</span><span class="n">MelType</span><span class="o">.</span><span class="n">HTK</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_fft</span> <span class="o">=</span> <span class="n">n_fft</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span> <span class="o">=</span> <span class="n">win_length</span> <span class="k">if</span> <span class="n">win_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">n_fft</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span> <span class="o">=</span> <span class="n">hop_length</span> <span class="k">if</span> <span class="n">hop_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_min</span> <span class="o">=</span> <span class="n">f_min</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_max</span> <span class="o">=</span> <span class="n">f_max</span> <span class="k">if</span> <span class="n">f_max</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">sample_rate</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad</span> <span class="o">=</span> <span class="n">pad</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_mels</span> <span class="o">=</span> <span class="n">n_mels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window</span> <span class="o">=</span> <span class="n">window</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">power</span> <span class="o">=</span> <span class="n">power</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized</span> <span class="o">=</span> <span class="n">normalized</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">center</span> <span class="o">=</span> <span class="n">center</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_mode</span> <span class="o">=</span> <span class="n">pad_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">onesided</span> <span class="o">=</span> <span class="n">onesided</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mel_scale</span> <span class="o">=</span> <span class="n">mel_scale</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">MelSpectrogramOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_fft</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_min</span><span class="p">,</span>
                                           <span class="bp">self</span><span class="o">.</span><span class="n">f_max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_mels</span><span class="p">,</span> <span class="n">DE_C_WINDOW_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">),</span>
                                           <span class="bp">self</span><span class="o">.</span><span class="n">power</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">center</span><span class="p">,</span>
                                           <span class="n">DE_C_BORDER_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_mode</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">onesided</span><span class="p">,</span>
                                           <span class="n">DE_C_NORM_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">),</span> <span class="n">DE_C_MEL_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mel_scale</span><span class="p">))</span></div>


<div class="viewcode-block" id="MFCC"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.MFCC.html#mindspore.dataset.audio.MFCC">[docs]</a><span class="k">class</span> <span class="nc">MFCC</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create MFCC for a raw audio signal.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int, optional): Sampling rate of audio signal (in Hz), can&#39;t be less than 0. Default: ``16000``.</span>
<span class="sd">        n_mfcc (int, optional): Number of mfc coefficients to retain, can&#39;t be less than 0. Default: ``40``.</span>
<span class="sd">        dct_type (int, optional): Type of DCT (discrete cosine transform) to use, can only be ``2``. Default: ``2``.</span>
<span class="sd">        norm (NormMode, optional): Norm to use. Default: ``NormMode.ORTHO``.</span>
<span class="sd">        log_mels (bool, optional): Whether to use log-mel spectrograms instead of db-scaled. Default: ``False``.</span>
<span class="sd">        melkwargs (dict, optional): Arguments for :class:`mindspore.dataset.audio.MelSpectrogram`.</span>
<span class="sd">            Default: ``None``, the default setting is a dict including</span>

<span class="sd">            - &#39;n_fft&#39;: 400</span>
<span class="sd">            - &#39;win_length&#39;: n_fft</span>
<span class="sd">            - &#39;hop_length&#39;: win_length // 2</span>
<span class="sd">            - &#39;f_min&#39;: 0.0</span>
<span class="sd">            - &#39;f_max&#39;: sample_rate // 2</span>
<span class="sd">            - &#39;pad&#39;: 0</span>
<span class="sd">            - &#39;window&#39;: WindowType.HANN</span>
<span class="sd">            - &#39;power&#39;: 2.0</span>
<span class="sd">            - &#39;normalized&#39;: False</span>
<span class="sd">            - &#39;center&#39;: True</span>
<span class="sd">            - &#39;pad_mode&#39;: BorderType.REFLECT</span>
<span class="sd">            - &#39;onesided&#39;: True</span>
<span class="sd">            - &#39;norm&#39;: NormType.NONE</span>
<span class="sd">            - &#39;mel_scale&#39;: MelType.HTK</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        TypeError: If `log_mels` is not of type bool.</span>
<span class="sd">        TypeError: If `norm` is not of type :class:`mindspore.dataset.audio.NormMode` .</span>
<span class="sd">        TypeError: If `n_mfcc` is not of type int.</span>
<span class="sd">        TypeError: If `melkwargs` is not of type dict.</span>
<span class="sd">        ValueError: If `sample_rate` is a negative number.</span>
<span class="sd">        ValueError: If `n_mfcc` is a negative number.</span>
<span class="sd">        ValueError: If `dct_type` is not ``2``.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 500])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.MFCC(4000, 128, 2)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (128, 3) float32</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([500])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.MFCC(4000, 128, 2)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (128, 3) float32</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_mfcc</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span> <span class="n">n_mfcc</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">dct_type</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">NormMode</span><span class="o">.</span><span class="n">ORTHO</span><span class="p">,</span> <span class="n">log_mels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">melkwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_mfcc</span> <span class="o">=</span> <span class="n">n_mfcc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dct_type</span> <span class="o">=</span> <span class="n">dct_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_mels</span> <span class="o">=</span> <span class="n">log_mels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span> <span class="o">=</span> <span class="n">melkwargs</span>
        <span class="k">if</span> <span class="n">melkwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;n_fft&quot;</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;win_length&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;n_fft&quot;</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;hop_length&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;win_length&quot;</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;f_min&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;f_max&quot;</span><span class="p">,</span> <span class="n">sample_rate</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;pad&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;n_mels&quot;</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;window&quot;</span><span class="p">,</span> <span class="n">WindowType</span><span class="o">.</span><span class="n">HANN</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;power&quot;</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;normalized&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;pad_mode&quot;</span><span class="p">,</span> <span class="n">BorderType</span><span class="o">.</span><span class="n">REFLECT</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;onesided&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;norm&quot;</span><span class="p">,</span> <span class="n">NormType</span><span class="o">.</span><span class="n">NONE</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;mel_scale&quot;</span><span class="p">,</span> <span class="n">MelType</span><span class="o">.</span><span class="n">HTK</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;window&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pad_mode&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_mel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;norm&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mel_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;mel_scale&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">MFCCOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_mfcc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dct_type</span><span class="p">,</span> <span class="n">DE_C_NORM_MODE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">),</span>
                                 <span class="bp">self</span><span class="o">.</span><span class="n">log_mels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">melkwargs</span><span class="p">,</span> <span class="n">DE_C_WINDOW_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">),</span>
                                 <span class="n">DE_C_BORDER_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_mode</span><span class="p">),</span> <span class="n">DE_C_NORM_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm_mel</span><span class="p">),</span>
                                 <span class="n">DE_C_MEL_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mel_scale</span><span class="p">))</span></div>


<div class="viewcode-block" id="MuLawDecoding"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.MuLawDecoding.html#mindspore.dataset.audio.MuLawDecoding">[docs]</a><span class="k">class</span> <span class="nc">MuLawDecoding</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Decode mu-law encoded signal, refer to `mu-law algorithm &lt;https://en.wikipedia.org/wiki/M-law_algorithm&gt;`_ .</span>

<span class="sd">    Args:</span>
<span class="sd">        quantization_channels (int, optional): Number of channels, which must be positive. Default: ``256``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `quantization_channels` is not of type int.</span>
<span class="sd">        ValueError: If `quantization_channels` is not a positive number.</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 3, 4])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.MuLawDecoding()]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (3, 4) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([3, 4])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.MuLawDecoding()(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (3, 4) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_mu_law_coding</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">quantization_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantization_channels</span> <span class="o">=</span> <span class="n">quantization_channels</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">MuLawDecodingOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantization_channels</span><span class="p">)</span></div>


<div class="viewcode-block" id="MuLawEncoding"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.MuLawEncoding.html#mindspore.dataset.audio.MuLawEncoding">[docs]</a><span class="k">class</span> <span class="nc">MuLawEncoding</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Encode signal based on mu-law companding.</span>

<span class="sd">    Args:</span>
<span class="sd">        quantization_channels (int, optional): Number of channels, which must be positive. Default: ``256``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `quantization_channels` is not of type int.</span>
<span class="sd">        ValueError: If `quantization_channels` is not a positive number.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 3, 4])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.MuLawEncoding()]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (3, 4) int32</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([3, 4])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.MuLawEncoding()(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (3, 4) int32</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_mu_law_coding</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">quantization_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantization_channels</span> <span class="o">=</span> <span class="n">quantization_channels</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">MuLawEncodingOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantization_channels</span><span class="p">)</span></div>


<div class="viewcode-block" id="Overdrive"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.Overdrive.html#mindspore.dataset.audio.Overdrive">[docs]</a><span class="k">class</span> <span class="nc">Overdrive</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply an overdrive effect to the audio waveform.</span>

<span class="sd">    Similar to `SoX &lt;https://sourceforge.net/projects/sox/&gt;`_ implementation.</span>

<span class="sd">    Args:</span>
<span class="sd">        gain (float, optional): Desired gain at the boost (or attenuation) in dB, in range of [0, 100].</span>
<span class="sd">            Default: ``20.0``.</span>
<span class="sd">        color (float, optional): Controls the amount of even harmonic content in the over-driven output,</span>
<span class="sd">            in range of [0, 100]. Default: ``20.0``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `gain` is not of type float.</span>
<span class="sd">        ValueError: If `gain` is not in range of [0, 100].</span>
<span class="sd">        TypeError: If `color` is not of type float.</span>
<span class="sd">        ValueError: If `color` is not in range of [0, 100].</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 10])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.Overdrive()]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (10,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([10])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.Overdrive()(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (10,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_overdrive</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mf">20.0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="mf">20.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">=</span> <span class="n">gain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">color</span> <span class="o">=</span> <span class="n">color</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">OverdriveOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gain</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">color</span><span class="p">)</span></div>


<div class="viewcode-block" id="Phaser"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.Phaser.html#mindspore.dataset.audio.Phaser">[docs]</a><span class="k">class</span> <span class="nc">Phaser</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply a phasing effect to the audio.</span>

<span class="sd">    Similar to `SoX &lt;https://sourceforge.net/projects/sox/&gt;`_ implementation.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int): Sampling rate of the waveform, e.g. 44100 (Hz).</span>
<span class="sd">        gain_in (float, optional): Desired input gain at the boost (or attenuation) in dB,</span>
<span class="sd">            in range of [0.0, 1.0]. Default: ``0.4``.</span>
<span class="sd">        gain_out (float, optional): Desired output gain at the boost (or attenuation) in dB,</span>
<span class="sd">            in range of [0.0, 1e9]. Default: ``0.74``.</span>
<span class="sd">        delay_ms (float, optional): Desired delay in milliseconds, in range of [0.0, 5.0]. Default: ``3.0``.</span>
<span class="sd">        decay (float, optional): Desired decay relative to gain-in, in range of [0.0, 0.99]. Default: ``0.4``.</span>
<span class="sd">        mod_speed (float, optional): Modulation speed in Hz, in range of [0.1, 2.0]. Default: ``0.5``.</span>
<span class="sd">        sinusoidal (bool, optional): If ``True``, use sinusoidal modulation (preferable for multiple instruments).</span>
<span class="sd">            If ``False``, use triangular modulation (gives single instruments a sharper phasing effect).</span>
<span class="sd">            Default: ``True``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        TypeError: If `gain_in` is not of type float.</span>
<span class="sd">        ValueError: If `gain_in` is not in range of [0.0, 1.0].</span>
<span class="sd">        TypeError: If `gain_out` is not of type float.</span>
<span class="sd">        ValueError: If `gain_out` is not in range of [0.0, 1e9].</span>
<span class="sd">        TypeError: If `delay_ms` is not of type float.</span>
<span class="sd">        ValueError: If `delay_ms` is not in range of [0.0, 5.0].</span>
<span class="sd">        TypeError: If `decay` is not of type float.</span>
<span class="sd">        ValueError: If `decay` is not in range of [0.0, 0.99].</span>
<span class="sd">        TypeError: If `mod_speed` is not of type float.</span>
<span class="sd">        ValueError: If `mod_speed` is not in range of [0.1, 2.0].</span>
<span class="sd">        TypeError: If `sinusoidal` is not of type bool.</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 12])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.Phaser(44100)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (12,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([12])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.Phaser(44100)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (12,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_phaser</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">gain_in</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">gain_out</span><span class="o">=</span><span class="mf">0.74</span><span class="p">,</span> <span class="n">delay_ms</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">mod_speed</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                 <span class="n">sinusoidal</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decay</span> <span class="o">=</span> <span class="n">decay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delay_ms</span> <span class="o">=</span> <span class="n">delay_ms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gain_in</span> <span class="o">=</span> <span class="n">gain_in</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gain_out</span> <span class="o">=</span> <span class="n">gain_out</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mod_speed</span> <span class="o">=</span> <span class="n">mod_speed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sinusoidal</span> <span class="o">=</span> <span class="n">sinusoidal</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">PhaserOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gain_in</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gain_out</span><span class="p">,</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">delay_ms</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">decay</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mod_speed</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sinusoidal</span><span class="p">)</span></div>


<div class="viewcode-block" id="PhaseVocoder"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.PhaseVocoder.html#mindspore.dataset.audio.PhaseVocoder">[docs]</a><span class="k">class</span> <span class="nc">PhaseVocoder</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given a STFT spectrogram, speed up in time without modifying pitch by a factor of rate.</span>

<span class="sd">    Args:</span>
<span class="sd">        rate (float): Speed-up factor.</span>
<span class="sd">        phase_advance (numpy.ndarray): Expected phase advance in each bin, in shape of (freq, 1).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `rate` is not of type float.</span>
<span class="sd">        ValueError: If `rate` is not a positive number.</span>
<span class="sd">        TypeError: If `phase_advance` is not of type :class:`numpy.ndarray` .</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., freq, num_frame, complex=2&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 44, 10, 2])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.PhaseVocoder(rate=2, phase_advance=np.random.random([44, 1]))]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (44, 5, 2) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([44, 10, 2])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.PhaseVocoder(rate=2, phase_advance=np.random.random([44, 1]))(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (44, 5, 2) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_phase_vocoder</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">phase_advance</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rate</span> <span class="o">=</span> <span class="n">rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">phase_advance</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">phase_advance</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">PhaseVocoderOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">phase_advance</span><span class="p">)</span></div>


<div class="viewcode-block" id="PitchShift"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.PitchShift.html#mindspore.dataset.audio.PitchShift">[docs]</a><span class="k">class</span> <span class="nc">PitchShift</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Shift the pitch of a waveform by `n_steps` steps.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int): Sampling rate of waveform (in Hz).</span>
<span class="sd">        n_steps (int): The steps to shift waveform.</span>
<span class="sd">        bins_per_octave (int, optional): The number of steps per octave. Default: ``12``.</span>
<span class="sd">        n_fft (int, optional): Size of FFT, creates `n_fft // 2 + 1` bins. Default: ``512``.</span>
<span class="sd">        win_length (int, optional): Window size. Default: ``None``, will be set to `n_fft` .</span>
<span class="sd">        hop_length (int, optional): Length of hop between STFT windows. Default: ``None``,</span>
<span class="sd">            will be set to `win_length // 4` .</span>
<span class="sd">        window (WindowType, optional): Window tensor that is applied/multiplied to each frame/window.</span>
<span class="sd">            Default: ``WindowType.HANN``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        TypeError: If `n_steps` is not of type int.</span>
<span class="sd">        TypeError: If `bins_per_octave` is not of type int.</span>
<span class="sd">        TypeError: If `n_fft` is not of type int.</span>
<span class="sd">        TypeError: If `win_length` is not of type int.</span>
<span class="sd">        TypeError: If `hop_length` is not of type int.</span>
<span class="sd">        TypeError: If `window` is not of type :class:`mindspore.dataset.audio.WindowType` .</span>
<span class="sd">        ValueError: If `sample_rate` is a negative number.</span>
<span class="sd">        ValueError: If `bins_per_octave` is 0.</span>
<span class="sd">        ValueError: If `n_fft` is a negative number.</span>
<span class="sd">        ValueError: If `win_length` is not positive.</span>
<span class="sd">        ValueError: If `hop_length` is not positive.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 8, 30])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.PitchShift(sample_rate=16000, n_steps=4)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (8, 30) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([8, 30])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.PitchShift(sample_rate=16000, n_steps=4)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (8, 30) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_pitch_shift</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">bins_per_octave</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">n_fft</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">win_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">hop_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="n">WindowType</span><span class="o">.</span><span class="n">HANN</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">=</span> <span class="n">n_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bins_per_octave</span> <span class="o">=</span> <span class="n">bins_per_octave</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_fft</span> <span class="o">=</span> <span class="n">n_fft</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span> <span class="o">=</span> <span class="n">win_length</span> <span class="k">if</span> <span class="n">win_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">n_fft</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span> <span class="o">=</span> <span class="n">hop_length</span> <span class="k">if</span> <span class="n">hop_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span> <span class="o">//</span> <span class="mi">4</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window</span> <span class="o">=</span> <span class="n">window</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">PitchShiftOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bins_per_octave</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_fft</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span><span class="p">,</span> <span class="n">DE_C_WINDOW_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">))</span></div>


<span class="n">DE_C_RESAMPLE_METHOD</span> <span class="o">=</span> <span class="p">{</span><span class="n">ResampleMethod</span><span class="o">.</span><span class="n">SINC_INTERPOLATION</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">ResampleMethod</span><span class="o">.</span><span class="n">DE_RESAMPLE_SINC_INTERPOLATION</span><span class="p">,</span>
                        <span class="n">ResampleMethod</span><span class="o">.</span><span class="n">KAISER_WINDOW</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">ResampleMethod</span><span class="o">.</span><span class="n">DE_RESAMPLE_KAISER_WINDOW</span><span class="p">}</span>


<div class="viewcode-block" id="Resample"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.Resample.html#mindspore.dataset.audio.Resample">[docs]</a><span class="k">class</span> <span class="nc">Resample</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Resample a signal from one frequency to another. A resample method can be given.</span>

<span class="sd">    Args:</span>
<span class="sd">        orig_freq (float, optional): The original frequency of the signal, must be positive. Default: ``16000``.</span>
<span class="sd">        new_freq (float, optional): The desired frequency, must be positive. Default: ``16000``.</span>
<span class="sd">        resample_method (ResampleMethod, optional): The resample method to use, can be</span>
<span class="sd">            ``ResampleMethod.SINC_INTERPOLATION`` or ``ResampleMethod.KAISER_WINDOW``.</span>
<span class="sd">            Default: ``ResampleMethod.SINC_INTERPOLATION``.</span>
<span class="sd">        lowpass_filter_width (int, optional): Controls the sharpness of the filter, more means sharper but less</span>
<span class="sd">            efficient, must be positive. Default: ``6``.</span>
<span class="sd">        rolloff (float, optional): The roll-off frequency of the filter, as a fraction of the Nyquist. Lower values</span>
<span class="sd">            reduce anti-aliasing, but also reduce some of the highest frequencies, in range of (0, 1].</span>
<span class="sd">            Default: ``0.99``.</span>
<span class="sd">        beta (float, optional): The shape parameter used for kaiser window. Default: ``None``,</span>
<span class="sd">            will use ``14.769656459379492``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `orig_freq` is not of type float.</span>
<span class="sd">        ValueError: If `orig_freq` is not a positive number.</span>
<span class="sd">        TypeError: If `new_freq` is not of type float.</span>
<span class="sd">        ValueError: If `new_freq` is not a positive number.</span>
<span class="sd">        TypeError: If `resample_method` is not of type :class:`mindspore.dataset.audio.ResampleMethod` .</span>
<span class="sd">        TypeError: If `lowpass_filter_width` is not of type int.</span>
<span class="sd">        ValueError: If `lowpass_filter_width` is not a positive number.</span>
<span class="sd">        TypeError: If `rolloff` is not of type float.</span>
<span class="sd">        ValueError: If `rolloff` is not in range of (0, 1].</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16, 30])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.Resample(orig_freq=48000, new_freq=16000,</span>
<span class="sd">        ...                              resample_method=audio.ResampleMethod.SINC_INTERPOLATION,</span>
<span class="sd">        ...                              lowpass_filter_width=6, rolloff=0.99, beta=None)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16, 10) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16, 30])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.Resample(orig_freq=48000, new_freq=16000,</span>
<span class="sd">        ...                         resample_method=audio.ResampleMethod.SINC_INTERPOLATION,</span>
<span class="sd">        ...                         lowpass_filter_width=6, rolloff=0.99, beta=None)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16, 10) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_resample</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">orig_freq</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span> <span class="n">new_freq</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span> <span class="n">resample_method</span><span class="o">=</span><span class="n">ResampleMethod</span><span class="o">.</span><span class="n">SINC_INTERPOLATION</span><span class="p">,</span>
                 <span class="n">lowpass_filter_width</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">rolloff</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">orig_freq</span> <span class="o">=</span> <span class="n">orig_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">new_freq</span> <span class="o">=</span> <span class="n">new_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resample_method</span> <span class="o">=</span> <span class="n">resample_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lowpass_filter_width</span> <span class="o">=</span> <span class="n">lowpass_filter_width</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rolloff</span> <span class="o">=</span> <span class="n">rolloff</span>
        <span class="n">kaiser_beta</span> <span class="o">=</span> <span class="mf">14.769656459379492</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span> <span class="k">if</span> <span class="n">beta</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">kaiser_beta</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">ResampleOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">orig_freq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_freq</span><span class="p">,</span> <span class="n">DE_C_RESAMPLE_METHOD</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">resample_method</span><span class="p">),</span>
                                     <span class="bp">self</span><span class="o">.</span><span class="n">lowpass_filter_width</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rolloff</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span></div>


<div class="viewcode-block" id="RiaaBiquad"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.RiaaBiquad.html#mindspore.dataset.audio.RiaaBiquad">[docs]</a><span class="k">class</span> <span class="nc">RiaaBiquad</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply RIAA vinyl playback equalization.</span>

<span class="sd">    Similar to `SoX &lt;https://sourceforge.net/projects/sox/&gt;`_ implementation.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int): sampling rate of the waveform, e.g. 44100 (Hz),</span>
<span class="sd">            can only be one of 44100, 48000, 88200, 96000.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is not any of [44100, 48000, 88200, 96000].</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 24])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.RiaaBiquad(44100)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (24,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([24])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.RiaaBiquad(44100)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (24,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_riaa_biquad</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">RiaaBiquadOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">)</span></div>


<div class="viewcode-block" id="SlidingWindowCmn"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.SlidingWindowCmn.html#mindspore.dataset.audio.SlidingWindowCmn">[docs]</a><span class="k">class</span> <span class="nc">SlidingWindowCmn</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply sliding-window cepstral mean (and optionally variance) normalization per utterance.</span>

<span class="sd">    Args:</span>
<span class="sd">        cmn_window (int, optional): Window in frames for running average CMN computation. Default: ``600``.</span>
<span class="sd">        min_cmn_window (int, optional): Minimum CMN window used at start of decoding (adds latency only at start).</span>
<span class="sd">            Only applicable if center is ``False``, ignored if center is ``True``. Default: ``100``.</span>
<span class="sd">        center (bool, optional): If ``True``, use a window centered on the current frame. If ``False``, window is</span>
<span class="sd">            to the left. Default: ``False``.</span>
<span class="sd">        norm_vars (bool, optional): If ``True``, normalize variance to one. Default: ``False``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `cmn_window` is not of type int.</span>
<span class="sd">        ValueError: If `cmn_window` is a negative number.</span>
<span class="sd">        TypeError: If `min_cmn_window` is not of type int.</span>
<span class="sd">        ValueError: If `min_cmn_window` is a negative number.</span>
<span class="sd">        TypeError: If `center` is not of type bool.</span>
<span class="sd">        TypeError: If `norm_vars` is not of type bool.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16, 3])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.SlidingWindowCmn()]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16, 3) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16, 3])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.SlidingWindowCmn()(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16, 3) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_sliding_window_cmn</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cmn_window</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span> <span class="n">min_cmn_window</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">norm_vars</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cmn_window</span> <span class="o">=</span> <span class="n">cmn_window</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_cmn_window</span> <span class="o">=</span> <span class="n">min_cmn_window</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">center</span> <span class="o">=</span> <span class="n">center</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_vars</span> <span class="o">=</span> <span class="n">norm_vars</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">SlidingWindowCmnOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cmn_window</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_cmn_window</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">center</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_vars</span><span class="p">)</span></div>


<span class="n">DE_C_WINDOW_TYPE</span> <span class="o">=</span> <span class="p">{</span><span class="n">WindowType</span><span class="o">.</span><span class="n">BARTLETT</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">WindowType</span><span class="o">.</span><span class="n">DE_WINDOW_TYPE_BARTLETT</span><span class="p">,</span>
                    <span class="n">WindowType</span><span class="o">.</span><span class="n">BLACKMAN</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">WindowType</span><span class="o">.</span><span class="n">DE_WINDOW_TYPE_BLACKMAN</span><span class="p">,</span>
                    <span class="n">WindowType</span><span class="o">.</span><span class="n">HAMMING</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">WindowType</span><span class="o">.</span><span class="n">DE_WINDOW_TYPE_HAMMING</span><span class="p">,</span>
                    <span class="n">WindowType</span><span class="o">.</span><span class="n">HANN</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">WindowType</span><span class="o">.</span><span class="n">DE_WINDOW_TYPE_HANN</span><span class="p">,</span>
                    <span class="n">WindowType</span><span class="o">.</span><span class="n">KAISER</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">WindowType</span><span class="o">.</span><span class="n">DE_WINDOW_TYPE_KAISER</span><span class="p">}</span>


<div class="viewcode-block" id="SpectralCentroid"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.SpectralCentroid.html#mindspore.dataset.audio.SpectralCentroid">[docs]</a><span class="k">class</span> <span class="nc">SpectralCentroid</span><span class="p">(</span><span class="n">TensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the spectral centroid for each channel along the time axis.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int): Sampling rate of audio signal, e.g. ``44100`` (Hz).</span>
<span class="sd">        n_fft (int, optional): Size of FFT, creates `n_fft // 2 + 1` bins. Default: ``400``.</span>
<span class="sd">        win_length (int, optional): Window size. Default: ``None``, will use `n_fft` .</span>
<span class="sd">        hop_length (int, optional): Length of hop between STFT windows. Default: ``None``, will use `win_length // 2` .</span>
<span class="sd">        pad (int, optional): Two sided padding of signal. Default: ``0``.</span>
<span class="sd">        window (WindowType, optional): Window function that is applied/multiplied to each frame/window,</span>
<span class="sd">            can be ``WindowType.BARTLETT``, ``WindowType.BLACKMAN``, ``WindowType.HAMMING``, ``WindowType.HANN``</span>
<span class="sd">            or ``WindowType.KAISER``. Default: ``WindowType.HANN``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is a negative number.</span>
<span class="sd">        TypeError: If `n_fft` is not of type int.</span>
<span class="sd">        ValueError: If `n_fft` is not a positive number.</span>
<span class="sd">        TypeError: If `win_length` is not of type int.</span>
<span class="sd">        ValueError: If `win_length` is not a positive number.</span>
<span class="sd">        ValueError: If `win_length` is greater than `n_fft` .</span>
<span class="sd">        TypeError: If `hop_length` is not of type int.</span>
<span class="sd">        ValueError: If `hop_length` is not a positive number.</span>
<span class="sd">        TypeError: If `pad` is not of type int.</span>
<span class="sd">        ValueError: If `pad` is a negative number.</span>
<span class="sd">        TypeError: If `window` is not of type :class:`mindspore.dataset.audio.WindowType` .</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 10, 20])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.SpectralCentroid(44100)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (10, 1, 1) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([10, 20])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.SpectralCentroid(44100)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (10, 1, 1) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_spectral_centroid</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">n_fft</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">win_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="n">WindowType</span><span class="o">.</span><span class="n">HANN</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad</span> <span class="o">=</span> <span class="n">pad</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window</span> <span class="o">=</span> <span class="n">window</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_fft</span> <span class="o">=</span> <span class="n">n_fft</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span> <span class="o">=</span> <span class="n">win_length</span> <span class="k">if</span> <span class="n">win_length</span> <span class="k">else</span> <span class="n">n_fft</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span> <span class="o">=</span> <span class="n">hop_length</span> <span class="k">if</span> <span class="n">hop_length</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span> <span class="o">//</span> <span class="mi">2</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">SpectralCentroidOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_fft</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span><span class="p">,</span>
                                             <span class="bp">self</span><span class="o">.</span><span class="n">pad</span><span class="p">,</span> <span class="n">DE_C_WINDOW_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">))</span></div>


<div class="viewcode-block" id="Spectrogram"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.Spectrogram.html#mindspore.dataset.audio.Spectrogram">[docs]</a><span class="k">class</span> <span class="nc">Spectrogram</span><span class="p">(</span><span class="n">TensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a spectrogram from an audio signal.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_fft (int, optional): Size of FFT, creates `n_fft // 2 + 1` bins. Default: ``400``.</span>
<span class="sd">        win_length (int, optional): Window size. Default: ``None``, will use `n_fft` .</span>
<span class="sd">        hop_length (int, optional): Length of hop between STFT windows. Default: ``None``, will use `win_length // 2` .</span>
<span class="sd">        pad (int, optional): Two sided padding of signal. Default: ``0``.</span>
<span class="sd">        window (WindowType, optional): Window function that is applied/multiplied to each frame/window,</span>
<span class="sd">            can be ``WindowType.BARTLETT``, ``WindowType.BLACKMAN``, ``WindowType.HAMMING``, ``WindowType.HANN``</span>
<span class="sd">            or ``WindowType.KAISER``. Currently, Kaiser window is not supported on macOS. Default: ``WindowType.HANN``.</span>
<span class="sd">        power (float, optional): Exponent for the magnitude spectrogram, must be non negative,</span>
<span class="sd">            e.g., ``1`` for energy, ``2`` for power, etc. Default: ``2.0``.</span>
<span class="sd">        normalized (bool, optional): Whether to normalize by magnitude after stft. Default: ``False``.</span>
<span class="sd">        center (bool, optional): Whether to pad waveform on both sides. Default: ``True``.</span>
<span class="sd">        pad_mode (BorderType, optional): Controls the padding method used when `center` is ``True``,</span>
<span class="sd">            can be ``BorderType.REFLECT``, ``BorderType.CONSTANT``, ``BorderType.EDGE`` or ``BorderType.SYMMETRIC``.</span>
<span class="sd">            Default: ``BorderType.REFLECT``.</span>
<span class="sd">        onesided (bool, optional): Controls whether to return half of results to avoid redundancy. Default: ``True``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `n_fft` is not of type int.</span>
<span class="sd">        ValueError: If `n_fft` is not a positive number.</span>
<span class="sd">        TypeError: If `win_length` is not of type int.</span>
<span class="sd">        ValueError: If `win_length` is not a positive number.</span>
<span class="sd">        ValueError: If `win_length` is greater than `n_fft` .</span>
<span class="sd">        TypeError: If `hop_length` is not of type int.</span>
<span class="sd">        ValueError: If `hop_length` is not a positive number.</span>
<span class="sd">        TypeError: If `pad` is not of type int.</span>
<span class="sd">        ValueError: If `pad` is a negative number.</span>
<span class="sd">        TypeError: If `window` is not of type :class:`mindspore.dataset.audio.WindowType` .</span>
<span class="sd">        TypeError: If `power` is not of type float.</span>
<span class="sd">        ValueError: If `power` is a negative number.</span>
<span class="sd">        TypeError: If `normalized` is not of type bool.</span>
<span class="sd">        TypeError: If `center` is not of type bool.</span>
<span class="sd">        TypeError: If `pad_mode` is not of type :class:`mindspore.dataset.audio.BorderType` .</span>
<span class="sd">        TypeError: If `onesided` is not of type bool.</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 10, 20])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.Spectrogram()]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (10, 201, 1) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([10, 20])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.Spectrogram()(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (10, 201, 1) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_spectrogram</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_fft</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">win_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="n">WindowType</span><span class="o">.</span><span class="n">HANN</span><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
                 <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="n">BorderType</span><span class="o">.</span><span class="n">REFLECT</span><span class="p">,</span> <span class="n">onesided</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_fft</span> <span class="o">=</span> <span class="n">n_fft</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span> <span class="o">=</span> <span class="n">win_length</span> <span class="k">if</span> <span class="n">win_length</span> <span class="k">else</span> <span class="n">n_fft</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span> <span class="o">=</span> <span class="n">hop_length</span> <span class="k">if</span> <span class="n">hop_length</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad</span> <span class="o">=</span> <span class="n">pad</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window</span> <span class="o">=</span> <span class="n">window</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">power</span> <span class="o">=</span> <span class="n">power</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized</span> <span class="o">=</span> <span class="n">normalized</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">center</span> <span class="o">=</span> <span class="n">center</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_mode</span> <span class="o">=</span> <span class="n">pad_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">onesided</span> <span class="o">=</span> <span class="n">onesided</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">SpectrogramOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_fft</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad</span><span class="p">,</span>
                                        <span class="n">DE_C_WINDOW_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">power</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized</span><span class="p">,</span>
                                        <span class="bp">self</span><span class="o">.</span><span class="n">center</span><span class="p">,</span> <span class="n">DE_C_BORDER_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_mode</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">onesided</span><span class="p">)</span></div>


<div class="viewcode-block" id="TimeMasking"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.TimeMasking.html#mindspore.dataset.audio.TimeMasking">[docs]</a><span class="k">class</span> <span class="nc">TimeMasking</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply masking to a spectrogram in the time domain.</span>

<span class="sd">    Note:</span>
<span class="sd">        The shape of the audio waveform to be processed needs to be &lt;..., freq, time&gt;.</span>

<span class="sd">    Args:</span>
<span class="sd">        iid_masks (bool, optional): Whether to apply different masks to each example/channel. Default: ``False``.</span>
<span class="sd">        time_mask_param (int, optional): When `iid_masks` is ``True``, length of the mask will be uniformly sampled</span>
<span class="sd">            from [0, time_mask_param]; When `iid_masks` is ``False``, directly use it as length of the mask.</span>
<span class="sd">            The value should be in range of [0, time_length], where `time_length` is the length of audio waveform</span>
<span class="sd">            in time domain. Default: ``0``.</span>
<span class="sd">        mask_start (int, optional): Starting point to apply mask, only works when `iid_masks` is ``True``.</span>
<span class="sd">            The value should be in range of [0, time_length - time_mask_param], where `time_length` is</span>
<span class="sd">            the length of audio waveform in time domain. Default: ``0``.</span>
<span class="sd">        mask_value (float, optional): Value to assign to the masked columns. Default: ``0.0``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `iid_masks` is not of type bool.</span>
<span class="sd">        TypeError: If `time_mask_param` is not of type int.</span>
<span class="sd">        ValueError: If `time_mask_param` is greater than the length of audio waveform in time domain.</span>
<span class="sd">        TypeError: If `mask_start` is not of type int.</span>
<span class="sd">        ValueError: If `mask_start` a negative number.</span>
<span class="sd">        TypeError: If `mask_value` is not of type float.</span>
<span class="sd">        ValueError: If `mask_value` is a negative number.</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., freq, time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16, 2])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.TimeMasking(time_mask_param=1)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (16, 2) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16, 2])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.TimeMasking(time_mask_param=1)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (16, 2) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>

<span class="sd">    .. image:: time_masking_original.png</span>

<span class="sd">    .. image:: time_masking.png</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_masking</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iid_masks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">time_mask_param</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mask_start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mask_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iid_masks</span> <span class="o">=</span> <span class="n">iid_masks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_mask_param</span> <span class="o">=</span> <span class="n">time_mask_param</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_start</span> <span class="o">=</span> <span class="n">mask_start</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_value</span> <span class="o">=</span> <span class="n">mask_value</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">TimeMaskingOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iid_masks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_mask_param</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_start</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_value</span><span class="p">)</span></div>


<div class="viewcode-block" id="TimeStretch"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.TimeStretch.html#mindspore.dataset.audio.TimeStretch">[docs]</a><span class="k">class</span> <span class="nc">TimeStretch</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Stretch Short Time Fourier Transform (STFT) in time without modifying pitch for a given rate.</span>

<span class="sd">    Note:</span>
<span class="sd">        The shape of the audio waveform to be processed needs to be &lt;..., freq, time, complex=2&gt;.</span>
<span class="sd">        The first dimension represents the real part while the second represents the imaginary.</span>

<span class="sd">    Args:</span>
<span class="sd">        hop_length (int, optional): Length of hop between STFT windows, i.e. the number of samples</span>
<span class="sd">            between consecutive frames. Default: ``None``, will use `n_freq - 1` .</span>
<span class="sd">        n_freq (int, optional): Number of filter banks from STFT. Default: ``201``.</span>
<span class="sd">        fixed_rate (float, optional): Rate to speed up or slow down by. Default: ``None``, will keep</span>
<span class="sd">            the original rate.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `hop_length` is not of type int.</span>
<span class="sd">        ValueError: If `hop_length` is not a positive number.</span>
<span class="sd">        TypeError: If `n_freq` is not of type int.</span>
<span class="sd">        ValueError: If `n_freq` is not a positive number.</span>
<span class="sd">        TypeError: If `fixed_rate` is not of type float.</span>
<span class="sd">        ValueError: If `fixed_rate` is not a positive number.</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., freq, num_frame, complex=2&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 16, 8, 2])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.TimeStretch()]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (1, 16, 8, 2) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([16, 8, 2])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.TimeStretch()(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (1, 16, 8, 2) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>

<span class="sd">    .. image:: time_stretch_rate1.5.png</span>

<span class="sd">    .. image:: time_stretch_original.png</span>

<span class="sd">    .. image:: time_stretch_rate0.8.png</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_time_stretch</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_freq</span><span class="o">=</span><span class="mi">201</span><span class="p">,</span> <span class="n">fixed_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_freq</span> <span class="o">=</span> <span class="n">n_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fixed_rate</span> <span class="o">=</span> <span class="n">fixed_rate</span>

        <span class="n">n_fft</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_freq</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span> <span class="o">=</span> <span class="n">hop_length</span> <span class="k">if</span> <span class="n">hop_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">n_fft</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fixed_rate</span> <span class="o">=</span> <span class="n">fixed_rate</span> <span class="k">if</span> <span class="n">fixed_rate</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">TimeStretchOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_freq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fixed_rate</span><span class="p">)</span></div>


<div class="viewcode-block" id="TrebleBiquad"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.TrebleBiquad.html#mindspore.dataset.audio.TrebleBiquad">[docs]</a><span class="k">class</span> <span class="nc">TrebleBiquad</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Design a treble tone-control effect.</span>

<span class="sd">    Similar to `SoX &lt;https://sourceforge.net/projects/sox/&gt;`_ implementation.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int): Sampling rate (in Hz), which can&#39;t be zero.</span>
<span class="sd">        gain (float): Desired gain at the boost (or attenuation) in dB.</span>
<span class="sd">        central_freq (float, optional): Central frequency (in Hz). Default: ``3000``.</span>
<span class="sd">        Q (float, optional): `Quality factor &lt;https://en.wikipedia.org/wiki/Q_factor&gt;`_ ,</span>
<span class="sd">            in range of (0, 1]. Default: ``0.707``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is 0.</span>
<span class="sd">        TypeError: If `gain` is not of type float.</span>
<span class="sd">        TypeError: If `central_freq` is not of type float.</span>
<span class="sd">        TypeError: If `Q` is not of type float.</span>
<span class="sd">        ValueError: If `Q` is not in range of (0, 1].</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 20])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.TrebleBiquad(44100, 200.0)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (20,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([20])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.TrebleBiquad(44100, 200.0)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (20,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_treble_biquad</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">gain</span><span class="p">,</span> <span class="n">central_freq</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">Q</span><span class="o">=</span><span class="mf">0.707</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">=</span> <span class="n">gain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">central_freq</span> <span class="o">=</span> <span class="n">central_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span> <span class="o">=</span> <span class="n">Q</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">TrebleBiquadOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gain</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">central_freq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">quality_factor</span><span class="p">)</span></div>


<div class="viewcode-block" id="Vad"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.Vad.html#mindspore.dataset.audio.Vad">[docs]</a><span class="k">class</span> <span class="nc">Vad</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Voice activity detector.</span>

<span class="sd">    Attempt to trim silence and quiet background sounds from the ends of recordings of speech.</span>

<span class="sd">    Similar to `SoX &lt;https://sourceforge.net/projects/sox/&gt;`_ implementation.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int): Sampling rate of audio signal.</span>
<span class="sd">        trigger_level (float, optional): The measurement level used to trigger activity detection. Default: ``7.0``.</span>
<span class="sd">        trigger_time (float, optional): The time constant (in seconds) used to help ignore short bursts of</span>
<span class="sd">            sounds. Default: ``0.25``.</span>
<span class="sd">        search_time (float, optional): The amount of audio (in seconds) to search for quieter/shorter bursts of audio</span>
<span class="sd">            to include prior to the detected trigger point. Default: ``1.0``.</span>
<span class="sd">        allowed_gap (float, optional): The allowed gap (in seconds) between quieter/shorter bursts of audio to include</span>
<span class="sd">            prior to the detected trigger point. Default: ``0.25``.</span>
<span class="sd">        pre_trigger_time (float, optional): The amount of audio (in seconds) to preserve before the trigger point and</span>
<span class="sd">            any found quieter/shorter bursts. Default: ``0.0``.</span>
<span class="sd">        boot_time (float, optional): The time for the initial noise estimate. Default: ``0.35``.</span>
<span class="sd">        noise_up_time (float, optional): Time constant used by the adaptive noise estimator for when the noise level is</span>
<span class="sd">            increasing. Default: ``0.1``.</span>
<span class="sd">        noise_down_time (float, optional): Time constant used by the adaptive noise estimator for when the noise level</span>
<span class="sd">            is decreasing. Default: ``0.01``.</span>
<span class="sd">        noise_reduction_amount (float, optional): Amount of noise reduction to use in the detection algorithm.</span>
<span class="sd">            Default: 1.35.</span>
<span class="sd">        measure_freq (float, optional): Frequency of the algorithm&#39;s processing/measurements. Default: ``20.0``.</span>
<span class="sd">        measure_duration (float, optional): The duration of measurement. Default: ``None``,</span>
<span class="sd">            will use twice the measurement period.</span>
<span class="sd">        measure_smooth_time (float, optional): Time constant used to smooth spectral measurements. Default: ``0.4``.</span>
<span class="sd">        hp_filter_freq (float, optional): The &#39;Brick-wall&#39; frequency of high-pass filter applied at the input to the</span>
<span class="sd">            detector algorithm. Default: ``50.0``.</span>
<span class="sd">        lp_filter_freq (float, optional): The &#39;Brick-wall&#39; frequency of low-pass filter applied at the input to the</span>
<span class="sd">            detector algorithm. Default: ``6000.0``.</span>
<span class="sd">        hp_lifter_freq (float, optional): The &#39;Brick-wall&#39; frequency of high-pass lifter used in the</span>
<span class="sd">            detector algorithm. Default: ``150.0``.</span>
<span class="sd">        lp_lifter_freq (float, optional): The &#39;Brick-wall&#39; frequency of low-pass lifter used in the</span>
<span class="sd">            detector algorithm. Default: ``2000.0``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `sample_rate` is not of type int.</span>
<span class="sd">        ValueError: If `sample_rate` is not a positive number.</span>
<span class="sd">        TypeError: If `trigger_level` is not of type float.</span>
<span class="sd">        TypeError: If `trigger_time` is not of type float.</span>
<span class="sd">        ValueError: If `trigger_time` is a negative number.</span>
<span class="sd">        TypeError: If `search_time` is not of type float.</span>
<span class="sd">        ValueError: If `search_time` is a negative number.</span>
<span class="sd">        TypeError: If `allowed_gap` is not of type float.</span>
<span class="sd">        ValueError: If `allowed_gap` is a negative number.</span>
<span class="sd">        TypeError: If `pre_trigger_time` is not of type float.</span>
<span class="sd">        ValueError: If `pre_trigger_time` is a negative number.</span>
<span class="sd">        TypeError: If `boot_time` is not of type float.</span>
<span class="sd">        ValueError: If `boot_time` is a negative number.</span>
<span class="sd">        TypeError: If `noise_up_time` is not of type float.</span>
<span class="sd">        ValueError: If `noise_up_time` is a negative number.</span>
<span class="sd">        TypeError: If `noise_down_time` is not of type float.</span>
<span class="sd">        ValueError: If `noise_down_time` is a negative number.</span>
<span class="sd">        ValueError: If `noise_up_time` is less than `noise_down_time` .</span>
<span class="sd">        TypeError: If `noise_reduction_amount` is not of type float.</span>
<span class="sd">        ValueError: If `noise_reduction_amount` is a negative number.</span>
<span class="sd">        TypeError: If `measure_freq` is not of type float.</span>
<span class="sd">        ValueError: If `measure_freq` is not a positive number.</span>
<span class="sd">        TypeError: If `measure_duration` is not of type float.</span>
<span class="sd">        ValueError: If `measure_duration` is a negative number.</span>
<span class="sd">        TypeError: If `measure_smooth_time` is not of type float.</span>
<span class="sd">        ValueError: If `measure_smooth_time` is a negative number.</span>
<span class="sd">        TypeError: If `hp_filter_freq` is not of type float.</span>
<span class="sd">        ValueError: If `hp_filter_freq` is not a positive number.</span>
<span class="sd">        TypeError: If `lp_filter_freq` is not of type float.</span>
<span class="sd">        ValueError: If `lp_filter_freq` is not a positive number.</span>
<span class="sd">        TypeError: If `hp_lifter_freq` is not of type float.</span>
<span class="sd">        ValueError: If `hp_lifter_freq` is not a positive number.</span>
<span class="sd">        TypeError: If `lp_lifter_freq` is not of type float.</span>
<span class="sd">        ValueError: If `lp_lifter_freq` is not a positive number.</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 1000])  # 5 samples</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.Vad(sample_rate=600)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (660,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([1000])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.Vad(sample_rate=600)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (660,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_vad</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">trigger_level</span><span class="o">=</span><span class="mf">7.0</span><span class="p">,</span> <span class="n">trigger_time</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">search_time</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">allowed_gap</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
                 <span class="n">pre_trigger_time</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">boot_time</span><span class="o">=</span><span class="mf">0.35</span><span class="p">,</span> <span class="n">noise_up_time</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">noise_down_time</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
                 <span class="n">noise_reduction_amount</span><span class="o">=</span><span class="mf">1.35</span><span class="p">,</span> <span class="n">measure_freq</span><span class="o">=</span><span class="mf">20.0</span><span class="p">,</span> <span class="n">measure_duration</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">measure_smooth_time</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span>
                 <span class="n">hp_filter_freq</span><span class="o">=</span><span class="mf">50.0</span><span class="p">,</span> <span class="n">lp_filter_freq</span><span class="o">=</span><span class="mf">6000.0</span><span class="p">,</span> <span class="n">hp_lifter_freq</span><span class="o">=</span><span class="mf">150.0</span><span class="p">,</span> <span class="n">lp_lifter_freq</span><span class="o">=</span><span class="mf">2000.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trigger_level</span> <span class="o">=</span> <span class="n">trigger_level</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trigger_time</span> <span class="o">=</span> <span class="n">trigger_time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">search_time</span> <span class="o">=</span> <span class="n">search_time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allowed_gap</span> <span class="o">=</span> <span class="n">allowed_gap</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_trigger_time</span> <span class="o">=</span> <span class="n">pre_trigger_time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">boot_time</span> <span class="o">=</span> <span class="n">boot_time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_up_time</span> <span class="o">=</span> <span class="n">noise_up_time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_down_time</span> <span class="o">=</span> <span class="n">noise_down_time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_reduction_amount</span> <span class="o">=</span> <span class="n">noise_reduction_amount</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">measure_freq</span> <span class="o">=</span> <span class="n">measure_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">measure_duration</span> <span class="o">=</span> <span class="n">measure_duration</span> <span class="k">if</span> <span class="n">measure_duration</span> <span class="k">else</span> <span class="mf">2.0</span> <span class="o">/</span> <span class="n">measure_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">measure_smooth_time</span> <span class="o">=</span> <span class="n">measure_smooth_time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hp_filter_freq</span> <span class="o">=</span> <span class="n">hp_filter_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lp_filter_freq</span> <span class="o">=</span> <span class="n">lp_filter_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hp_lifter_freq</span> <span class="o">=</span> <span class="n">hp_lifter_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lp_lifter_freq</span> <span class="o">=</span> <span class="n">lp_lifter_freq</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">VadOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trigger_level</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trigger_time</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">search_time</span><span class="p">,</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">allowed_gap</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_trigger_time</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">boot_time</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_up_time</span><span class="p">,</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">noise_down_time</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_reduction_amount</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">measure_freq</span><span class="p">,</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">measure_duration</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">measure_smooth_time</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hp_filter_freq</span><span class="p">,</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">lp_filter_freq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hp_lifter_freq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lp_lifter_freq</span><span class="p">)</span></div>


<span class="n">DE_C_GAIN_TYPE</span> <span class="o">=</span> <span class="p">{</span><span class="n">GainType</span><span class="o">.</span><span class="n">AMPLITUDE</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">GainType</span><span class="o">.</span><span class="n">DE_GAIN_TYPE_AMPLITUDE</span><span class="p">,</span>
                  <span class="n">GainType</span><span class="o">.</span><span class="n">POWER</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">GainType</span><span class="o">.</span><span class="n">DE_GAIN_TYPE_POWER</span><span class="p">,</span>
                  <span class="n">GainType</span><span class="o">.</span><span class="n">DB</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">GainType</span><span class="o">.</span><span class="n">DE_GAIN_TYPE_DB</span><span class="p">}</span>


<div class="viewcode-block" id="Vol"><a class="viewcode-back" href="../../../../api_python/dataset_audio/mindspore.dataset.audio.Vol.html#mindspore.dataset.audio.Vol">[docs]</a><span class="k">class</span> <span class="nc">Vol</span><span class="p">(</span><span class="n">AudioTensorOperation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Adjust volume of waveform.</span>

<span class="sd">    Args:</span>
<span class="sd">        gain (float): Gain at the boost (or attenuation).</span>
<span class="sd">            If `gain_type` is ``GainType.AMPLITUDE``, it is a non negative amplitude ratio.</span>
<span class="sd">            If `gain_type` is ``GainType.POWER``, it is a power (voltage squared).</span>
<span class="sd">            If `gain_type` is ``GainType.DB``, it is in decibels.</span>
<span class="sd">        gain_type (GainType, optional): Type of gain, can be ``GainType.AMPLITUDE``, ``GainType.POWER``</span>
<span class="sd">            or ``GainType.DB``. Default: ``GainType.AMPLITUDE``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `gain` is not of type float.</span>
<span class="sd">        TypeError: If `gain_type` is not of type :class:`mindspore.dataset.audio.GainType` .</span>
<span class="sd">        ValueError: If `gain` is a negative number when `gain_type` is ``GainType.AMPLITUDE``.</span>
<span class="sd">        ValueError: If `gain` is not a positive number when `gain_type` is ``GainType.POWER``.</span>
<span class="sd">        RuntimeError: If input tensor is not in shape of &lt;..., time&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.audio as audio</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in dataset pipeline mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([5, 30])  # 5 sample</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = ds.NumpySlicesDataset(data=waveform, column_names=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; transforms = [audio.Vol(gain=10, gain_type=audio.GainType.DB)]</span>
<span class="sd">        &gt;&gt;&gt; numpy_slices_dataset = numpy_slices_dataset.map(operations=transforms, input_columns=[&quot;audio&quot;])</span>
<span class="sd">        &gt;&gt;&gt; for item in numpy_slices_dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     print(item[&quot;audio&quot;].shape, item[&quot;audio&quot;].dtype)</span>
<span class="sd">        ...     break</span>
<span class="sd">        (30,) float64</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Use the transform in eager mode</span>
<span class="sd">        &gt;&gt;&gt; waveform = np.random.random([30])  # 1 sample</span>
<span class="sd">        &gt;&gt;&gt; output = audio.Vol(gain=10, gain_type=audio.GainType.DB)(waveform)</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape, output.dtype)</span>
<span class="sd">        (30,) float64</span>

<span class="sd">    Tutorial Examples:</span>
<span class="sd">        - `Illustration of audio transforms</span>
<span class="sd">          &lt;https://www.mindspore.cn/docs/en/r2.3.0rc1/api_python/samples/dataset/audio_gallery.html&gt;`_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_vol</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gain</span><span class="p">,</span> <span class="n">gain_type</span><span class="o">=</span><span class="n">GainType</span><span class="o">.</span><span class="n">AMPLITUDE</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">=</span> <span class="n">gain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gain_type</span> <span class="o">=</span> <span class="n">gain_type</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">VolOperation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gain</span><span class="p">,</span> <span class="n">DE_C_GAIN_TYPE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gain_type</span><span class="p">))</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>