<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.nn.Conv3d &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script><script src="../../_static/jquery.js"></script>
        <script src="../../_static/js/theme.js"></script><script src="../../_static/underscore.js"></script><script src="../../_static/doctools.js"></script><script src="../../_static/js/mermaid-9.3.0.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script><script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script><script async="async" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/mathjax/MathJax-3.2.2/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="mindspore.nn.Conv3dTranspose" href="mindspore.nn.Conv3dTranspose.html" />
    <link rel="prev" title="mindspore.nn.Conv2dTranspose" href="mindspore.nn.Conv2dTranspose.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/tensor_view.html">TENSOR VIEWS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/programming_paradigm.html">Functional and Object-Oriented Fusion Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/distributed_training_design.html">Distributed Parallel Native</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/all_scenarios.html">Full-scenarios Unified Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/official_models.html">Official Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../mindspore.html">mindspore</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../mindspore.nn.html">mindspore.nn</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#basic-block">Basic Block</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#container">Container</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#wrapper-layer">Wrapper Layer</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../mindspore.nn.html#convolutional-layer">Convolutional Layer</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.Conv1d.html">mindspore.nn.Conv1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.Conv1dTranspose.html">mindspore.nn.Conv1dTranspose</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.Conv2d.html">mindspore.nn.Conv2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.Conv2dTranspose.html">mindspore.nn.Conv2dTranspose</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">mindspore.nn.Conv3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.Conv3dTranspose.html">mindspore.nn.Conv3dTranspose</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.Unfold.html">mindspore.nn.Unfold</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#recurrent-layer">Recurrent Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#transformer-layer">Transformer Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#embedding-layer">Embedding Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#nonlinear-activation-layer">Nonlinear Activation Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#linear-layer">Linear Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#dropout-layer">Dropout Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#normalization-layer">Normalization Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#pooling-layer">Pooling Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#padding-layer">Padding Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#loss-function">Loss Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#optimizer">Optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#dynamic-learning-rate">Dynamic Learning Rate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#image-processing-layer">Image Processing Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#tools">Tools</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.hal.html">mindspore.hal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.multiprocessing.html">mindspore.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.experimental.html">mindspore.experimental</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/enveriment_preparation.html">Environment Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/model_development/model_development.html">Network Constructing Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/faq.html">FAQs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Syntax Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax_support.html">Static Graph Syntax Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax/operators.html">Static Graph Syntax - Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax/statements.html">Static Graph Syntax - Python Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax/python_builtin_functions.html">Static Graph Syntax - Python Built-in Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/index_support.html">Tensor Index Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/env_var_list.html">Environment Variables</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../mindspore.nn.html">mindspore.nn</a> &raquo;</li>
      <li>mindspore.nn.Conv3d</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/api_python/nn/mindspore.nn.Conv3d.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="mindspore-nn-conv3d">
<h1>mindspore.nn.Conv3d<a class="headerlink" href="#mindspore-nn-conv3d" title="Permalink to this headline"></a></h1>
<a class="reference external image-reference" href="https://gitee.com/mindspore/mindspore/blob/r2.3.q1/mindspore/python/mindspore/nn/layer/conv.py"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3.q1/resource/_static/logo_source_en.svg" /></a>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.Conv3d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.</span></span><span class="sig-name descname"><span class="pre">Conv3d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'same'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">has_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCDHW'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">mstype.float32</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/layer/conv.html#Conv3d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mindspore.nn.Conv3d" title="Permalink to this definition"></a></dt>
<dd><p>3D convolution layer.</p>
<p>Applies a 3D convolution over an input tensor which is typically of shape
<span class="math notranslate nohighlight">\((N, C_{in}, D_{in}, H_{in}, W_{in})\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is batch size, <span class="math notranslate nohighlight">\(C\)</span> is channel number,
<span class="math notranslate nohighlight">\(D, H, W\)</span> are the depth, height and width of the feature map, respectively.</p>
<p>The output is calculated based on formula:</p>
<div class="math notranslate nohighlight">
\[\text{out}(N_i, C_{\text{out}_j}) = \text{bias}(C_{\text{out}_j}) +
\sum_{k = 0}^{C_{in} - 1} \text{ccor}({\text{weight}(C_{\text{out}_j}, k), \text{X}(N_i, k)})\]</div>
<p>where <span class="math notranslate nohighlight">\(bias\)</span> is the output channel bias, <span class="math notranslate nohighlight">\(ccor\)</span> is
the <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a>,
<span class="math notranslate nohighlight">\(weight\)</span> is the convolution kernel value and <span class="math notranslate nohighlight">\(X\)</span> represents the input feature map.</p>
<p>Here are the indices’ meanings:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(i\)</span> corresponds to the batch number, the range is <span class="math notranslate nohighlight">\([0, N-1]\)</span>,
where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of the input.</p></li>
<li><p><span class="math notranslate nohighlight">\(j\)</span> corresponds to the output channel, the range is <span class="math notranslate nohighlight">\([0, C_{out}-1]\)</span>,
where <span class="math notranslate nohighlight">\(C_{out}\)</span> is the number of
output channels, which is also equal to the number of kernels.</p></li>
<li><p><span class="math notranslate nohighlight">\(k\)</span> corresponds to the input channel, the range is <span class="math notranslate nohighlight">\([0, C_{in}-1]\)</span>,
where <span class="math notranslate nohighlight">\(C_{in}\)</span> is the number of
input channels, which is also equal to the number of channels in the convolutional kernels.</p></li>
</ul>
<p>Therefore, in the above formula, <span class="math notranslate nohighlight">\({bias}(C_{out_j})\)</span> represents the bias of the <span class="math notranslate nohighlight">\(j\)</span>-th
output channel, <span class="math notranslate nohighlight">\({weight}(C_{out_j}, k)\)</span> represents the slice of the <span class="math notranslate nohighlight">\(j\)</span>-th convolutional
kernel in the <span class="math notranslate nohighlight">\(k\)</span>-th channel, and <span class="math notranslate nohighlight">\({X}(N_i, k)\)</span> represents the slice of the <span class="math notranslate nohighlight">\(k\)</span>-th input
channel in the <span class="math notranslate nohighlight">\(i\)</span>-th batch of the input feature map.</p>
<p>The shape of the convolutional kernel is given by
<span class="math notranslate nohighlight">\((\text{kernel_size[0]}, \text{kernel_size[1]}, \text{kernel_size[2]})\)</span>
where <span class="math notranslate nohighlight">\(\text{kernel_size[0]}\)</span> , <span class="math notranslate nohighlight">\(\text{kernel_size[1]}\)</span> and <span class="math notranslate nohighlight">\(\text{kernel_size[2]}\)</span> are the depth,
height and width of the kernel, respectively.
If we consider the input and output channels as well as the <cite>group</cite> parameter, the complete kernel shape
will be <span class="math notranslate nohighlight">\((C_{out}, C_{in} / \text{group}, \text{kernel_size[0]},
\text{kernel_size[1]}, \text{kernel_size[2]})\)</span>,
where <cite>group</cite> is the number of groups dividing <cite>x</cite>’s input channel when applying group convolution.</p>
<p>For more details about convolution layer, please refer to <a class="reference external" href="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf">Gradient Based Learning Applied to Document Recognition</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>On Ascend platform, only group convolution in depthwise convolution scenarios is supported.
That is, when <cite>group&gt;1</cite>, condition <cite>in_channels</cite> = <cite>out_channels</cite> = <cite>group</cite> must be satisfied.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The channel number of the input tensor of the Conv3d layer.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The channel number of the output tensor of the Conv3d layer.</p></li>
<li><p><strong>kernel_size</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – Specifies the depth, height and width of the 3D convolution kernel.
It can be a single int or a tuple of 3 integers. A single int means the value is for depth, height
and the width. A tuple of 3 ints means the first value is
for depth and the rest is for the height and width.</p></li>
<li><p><strong>stride</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – The movement stride of the 3D convolution kernel.
The data type is an integer or a tuple of three integers. An integer represents the movement step size
in depth, height and width directions. A tuple of three integers represents the movement step size
in the depth, height and width directions respectively. Default: <code class="docutils literal notranslate"><span class="pre">1</span></code> .</p></li>
<li><p><strong>pad_mode</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – <p>Specifies the padding mode with a padding value of 0. It can be set to:
<code class="docutils literal notranslate"><span class="pre">&quot;same&quot;</span></code> , <code class="docutils literal notranslate"><span class="pre">&quot;valid&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;pad&quot;</span></code> . Default: <code class="docutils literal notranslate"><span class="pre">&quot;same&quot;</span></code> .</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;same&quot;</span></code>: Pad the input around its depth/height/width dimension so that the shape of input and output
are the same when <cite>stride</cite> is set to <code class="docutils literal notranslate"><span class="pre">1</span></code>.
The amount of padding to is calculated by the operator internally.  If the amount is even,
it isuniformly distributed around the input, if it is odd, the excess amount goes
to the front/right/bottom side.
If this mode is set, <cite>padding</cite> must be 0.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;valid&quot;</span></code>: No padding is applied to the input, and the output returns the maximum
possible depth, height and width. Extra pixels that could not complete a full stride will
be discarded. If this mode is set, <cite>padding</cite> must be 0.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;pad&quot;</span></code>: Pad the input with a specified amount. In this mode, the amount of padding
in the depth, height and width dimension is determined by the <cite>padding</cite> parameter.
If this mode is set, <cite>padding</cite> must be greater than or equal to 0.</p></li>
</ul>
</p></li>
<li><p><strong>padding</strong> (<em>Union</em><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>)</em><em>, </em><em>optional</em>) – The number of padding on the depth,
height and width directions of the input.
The data type is an integer or a tuple of six integers. If <cite>padding</cite> is an integer,
then the head, tail, top, bottom, left, and right padding are all equal to <cite>padding</cite>.
If <cite>padding</cite> is a tuple of six integers, then the head, tail, top, bottom, left, and right padding
is equal to <cite>padding[0]</cite>, <cite>padding[1]</cite>, <cite>padding[2]</cite>, <cite>padding[3]</cite>, <cite>padding[4]</cite> and <cite>padding[5]</cite>
respectively. The value should be greater than or equal to 0. Default: <code class="docutils literal notranslate"><span class="pre">0</span></code> .</p></li>
<li><p><strong>dilation</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – Specifies the dilation rate to use for dilated convolution.
It can be a single int or a tuple of 3 integers. A single int means the dilation size is the same
in the depth, height and width directions. A tuple of 3 ints represents the dilation size in
the depth, height and width directions, respectively.
Assuming <span class="math notranslate nohighlight">\(dilation=(d0, d1, d2)\)</span>, the convolutional kernel samples the input with a
spacing of <span class="math notranslate nohighlight">\(d0-1\)</span> elements in the depth direction, <span class="math notranslate nohighlight">\(d1-1\)</span> elements in the height direction,
<span class="math notranslate nohighlight">\(d2-1\)</span> elements in the width direction respectively.
The values in the depth, height and width dimensions are in
the ranges [1, D], [1, H] and [1, W], respectively.
Default: <code class="docutils literal notranslate"><span class="pre">1</span></code> .</p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Splits filter into groups, <cite>in_channels</cite> and <cite>out_channels</cite> must be
divisible by <cite>group</cite>. Default: <code class="docutils literal notranslate"><span class="pre">1</span></code> .</p></li>
<li><p><strong>has_bias</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether the Conv3d layer has a bias parameter. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code> .</p></li>
<li><p><strong>weight_init</strong> (<em>Union</em><em>[</em><a class="reference internal" href="../mindspore/mindspore.Tensor.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference internal" href="../mindspore.common.initializer.html#mindspore.common.initializer.Initializer" title="mindspore.common.initializer.Initializer"><em>Initializer</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/numbers.html#numbers.Number" title="(in Python v3.8)"><em>numbers.Number</em></a><em>]</em><em>, </em><em>optional</em>) – Initialization method of weight parameter.
It can be a Tensor, a string, an Initializer or a numbers.Number. When a string is specified,
values from <code class="docutils literal notranslate"><span class="pre">'TruncatedNormal'</span></code> , <code class="docutils literal notranslate"><span class="pre">'Normal'</span></code> , <code class="docutils literal notranslate"><span class="pre">'Uniform'</span></code> , <code class="docutils literal notranslate"><span class="pre">'HeUniform'</span></code> and <code class="docutils literal notranslate"><span class="pre">'XavierUniform'</span></code>
distributions as well as constant <code class="docutils literal notranslate"><span class="pre">'One'</span></code> and <code class="docutils literal notranslate"><span class="pre">'Zero'</span></code> distributions are possible. Alias
<code class="docutils literal notranslate"><span class="pre">'xavier_uniform'</span></code> , <code class="docutils literal notranslate"><span class="pre">'he_uniform'</span></code> , <code class="docutils literal notranslate"><span class="pre">'ones'</span></code> and <code class="docutils literal notranslate"><span class="pre">'zeros'</span></code> are acceptable. Uppercase and
lowercase are both acceptable. Refer to the values of
<a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3.q1/api_python/mindspore.common.initializer.html">Initializer</a>,
for more details. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code> , weight will be initialized using <code class="docutils literal notranslate"><span class="pre">'HeUniform'</span></code>.</p></li>
<li><p><strong>bias_init</strong> (<em>Union</em><em>[</em><a class="reference internal" href="../mindspore/mindspore.Tensor.html#mindspore.Tensor" title="mindspore.Tensor"><em>Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><a class="reference internal" href="../mindspore.common.initializer.html#mindspore.common.initializer.Initializer" title="mindspore.common.initializer.Initializer"><em>Initializer</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/numbers.html#numbers.Number" title="(in Python v3.8)"><em>numbers.Number</em></a><em>]</em><em>, </em><em>optional</em>) – <p>Initialization method of bias parameter.
Available initialization methods are the same as ‘weight_init’. Refer to the values of
<a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3.q1/api_python/mindspore.common.initializer.html">Initializer</a>,
for more details. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code> , bias will be initialized using <code class="docutils literal notranslate"><span class="pre">'Uniform'</span></code> .</p>
</p></li>
<li><p><strong>data_format</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – The optional value for data format. Currently only support <code class="docutils literal notranslate"><span class="pre">'NCDHW'</span></code> .</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="../mindspore.html#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) – Dtype of Parameters. Default: <code class="docutils literal notranslate"><span class="pre">mstype.float32</span></code> .</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>x</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, C_{in}, D_{in}, H_{in}, W_{in})\)</span>.
Currently input data type only support float16 and float32.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor of shape is <span class="math notranslate nohighlight">\((N, C_{out}, D_{out}, H_{out}, W_{out})\)</span>.</p>
<p>pad_mode is <code class="docutils literal notranslate"><span class="pre">'same'</span></code> :</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll} \\
    D_{out} = \left \lceil{\frac{D_{in}}{\text{stride[0]}}} \right \rceil \\
    H_{out} = \left \lceil{\frac{H_{in}}{\text{stride[1]}}} \right \rceil \\
    W_{out} = \left \lceil{\frac{W_{in}}{\text{stride[2]}}} \right \rceil \\
\end{array}\end{split}\]</div>
<p>pad_mode is <code class="docutils literal notranslate"><span class="pre">'valid'</span></code> :</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll} \\
    D_{out} = \left \lfloor{\frac{D_{in} - \text{dilation[0]} \times (\text{kernel_size[0]} - 1) }
    {\text{stride[0]}} + 1} \right \rfloor \\
    H_{out} = \left \lfloor{\frac{H_{in} - \text{dilation[1]} \times (\text{kernel_size[1]} - 1) }
    {\text{stride[1]}} + 1} \right \rfloor \\
    W_{out} = \left \lfloor{\frac{W_{in} - \text{dilation[2]} \times (\text{kernel_size[2]} - 1) }
    {\text{stride[2]}} + 1} \right \rfloor \\
\end{array}\end{split}\]</div>
<p>pad_mode is <code class="docutils literal notranslate"><span class="pre">'pad'</span></code> :</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll} \\
    D_{out} = \left \lfloor{\frac{D_{in} + padding[0] + padding[1] - (\text{dilation[0]} - 1) \times
    \text{kernel_size[0]} - 1 }{\text{stride[0]}} + 1} \right \rfloor \\
    H_{out} = \left \lfloor{\frac{H_{in} + padding[2] + padding[3] - (\text{dilation[1]} - 1) \times
    \text{kernel_size[1]} - 1 }{\text{stride[1]}} + 1} \right \rfloor \\
    W_{out} = \left \lfloor{\frac{W_{in} + padding[4] + padding[5] - (\text{dilation[2]} - 1) \times
    \text{kernel_size[2]} - 1 }{\text{stride[2]}} + 1} \right \rfloor \\
\end{array}\end{split}\]</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If <cite>in_channels</cite>, <cite>out_channels</cite> or <cite>group</cite> is not an int.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(in Python v3.8)"><strong>TypeError</strong></a> – If <cite>kernel_size</cite>, <cite>stride</cite>, <cite>padding</cite> or <cite>dilation</cite> is neither an int nor a tuple.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>out_channels</cite>, <cite>kernel_size</cite>, <cite>stride</cite> or <cite>dilation</cite> is less than 1.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>padding</cite> is less than 0.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>pad_mode</cite> is not one of ‘same’, ‘valid’, ‘pad’.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>padding</cite> is a tuple whose length is not equal to 6.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>pad_mode</cite> is not equal to ‘pad’ and <cite>padding</cite> is not equal to (0, 0, 0, 0, 0, 0).</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If <cite>data_format</cite> is not ‘NCDHW’.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">conv3d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">conv3d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(16, 32, 10, 32, 32)</span>
</pre></div>
</div>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindspore.nn.Conv2dTranspose.html" class="btn btn-neutral float-left" title="mindspore.nn.Conv2dTranspose" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mindspore.nn.Conv3dTranspose.html" class="btn btn-neutral float-right" title="mindspore.nn.Conv3dTranspose" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>