<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.dataset.engine.datasets &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script><script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/js/theme.js"></script><script src="../../../../_static/underscore.js"></script><script src="../../../../_static/doctools.js"></script><script src="../../../../_static/js/mermaid-9.3.0.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/programming_paradigm.html">Functional and Object-Oriented Fusion Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/distributed_training_design.html">Distributed Parallel Native</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/all_scenarios.html">Full-scenarios Unified Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/official_models.html">Official Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.ops.extend.html">mindspore.ops.extend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.hal.html">mindspore.hal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.multiprocessing.html">mindspore.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.experimental.html">mindspore.experimental</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/enveriment_preparation.html">Environment Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/model_development/model_development.html">Network Constructing Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/faq.html">FAQs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Syntax Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/static_graph_syntax_support.html">Static Graph Syntax Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/static_graph_syntax/operators.html">Static Graph Syntax - Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/static_graph_syntax/statements.html">Static Graph Syntax - Python Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/static_graph_syntax/python_builtin_functions.html">Static Graph Syntax - Python Built-in Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/index_support.html">Tensor Index Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/env_var_list.html">Environment Variables</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
      <li>mindspore.dataset.engine.datasets</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for mindspore.dataset.engine.datasets</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2022-2023 Huawei Technologies Co., Ltd</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">1. This file is an abstraction of the dataset loading class. It contains</span>
<span class="sd">some basic dataset operations(skip, filter, map, batch, ...).</span>
<span class="sd">2. Specific dataset loading classes can be found in datasets_vision.py, datasets_text.py,</span>
<span class="sd">datasets_audio.py, datasets_standard_format.py and dataets_user_defined.py files.</span>
<span class="sd">    datasets_vision.py: contains vision dataset loading classes.</span>
<span class="sd">    datasets_text.py: contains text dataset loading classes.</span>
<span class="sd">    datasets_audio.py: contains audio dataset loading classes.</span>
<span class="sd">    datasets_standard_format.py: contains standard format loading classes which</span>
<span class="sd">                                 any other kinds of datasets can be converted to.</span>
<span class="sd">    dataets_user_defined.py: contains basic classes that help users to define</span>
<span class="sd">                             flexible ways to load dataset.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">atexit</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">queue</span>
<span class="kn">import</span> <span class="nn">signal</span>
<span class="kn">import</span> <span class="nn">stat</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">gc</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">uuid</span>
<span class="kn">import</span> <span class="nn">multiprocessing</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">from</span> <span class="nn">importlib</span> <span class="kn">import</span> <span class="n">import_module</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">threading</span>

<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">weakref</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="kn">import</span> <span class="nn">psutil</span>

<span class="kn">import</span> <span class="nn">mindspore._c_dataengine</span> <span class="k">as</span> <span class="nn">cde</span>
<span class="kn">from</span> <span class="nn">mindspore._c_expression</span> <span class="kn">import</span> <span class="n">typing</span>

<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">log</span> <span class="k">as</span> <span class="n">logger</span>
<span class="kn">from</span> <span class="nn">mindspore.parallel._ps_context</span> <span class="kn">import</span> <span class="n">_is_role_pserver</span><span class="p">,</span> <span class="n">_is_role_sched</span><span class="p">,</span> <span class="n">_get_ps_context</span><span class="p">,</span>\
                                           <span class="n">_enable_distributed_mindrt</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset.engine.offload</span> <span class="kn">import</span> <span class="n">GetOffloadModel</span>

<span class="kn">import</span> <span class="nn">mindspore.dataset.transforms.c_transforms</span> <span class="k">as</span> <span class="nn">c_transforms</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.transforms.py_transforms</span> <span class="k">as</span> <span class="nn">py_transforms</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset.text.utils</span> <span class="kn">import</span> <span class="n">SentencePieceModel</span><span class="p">,</span> <span class="n">DE_C_INTER_SENTENCEPIECE_MODE</span>
<span class="kn">from</span> <span class="nn">mindspore.parallel._utils</span> <span class="kn">import</span> <span class="n">_get_device_num</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset.debug</span> <span class="kn">import</span> <span class="n">DebugHook</span>

<span class="kn">from</span> <span class="nn">mindspore.dataset.engine</span> <span class="kn">import</span> <span class="n">samplers</span>
<span class="kn">from</span> <span class="nn">.iterators</span> <span class="kn">import</span> <span class="n">DictIterator</span><span class="p">,</span> <span class="n">TupleIterator</span><span class="p">,</span> <span class="n">DummyIterator</span><span class="p">,</span> <span class="n">check_iterator_cleanup</span><span class="p">,</span> <span class="n">_set_iterator_cleanup</span><span class="p">,</span> \
    <span class="n">ITERATORS_LIST</span><span class="p">,</span> <span class="n">_unset_iterator_cleanup</span>
<span class="kn">from</span> <span class="nn">.queue</span> <span class="kn">import</span> <span class="n">_SharedQueue</span><span class="p">,</span> <span class="n">_Queue</span>
<span class="kn">from</span> <span class="nn">.validators</span> <span class="kn">import</span> <span class="n">check_batch</span><span class="p">,</span> <span class="n">check_shuffle</span><span class="p">,</span> <span class="n">check_map</span><span class="p">,</span> <span class="n">check_filter</span><span class="p">,</span> <span class="n">check_repeat</span><span class="p">,</span> <span class="n">check_skip</span><span class="p">,</span> <span class="n">check_zip</span><span class="p">,</span> \
    <span class="n">check_rename</span><span class="p">,</span> <span class="n">check_device_send</span><span class="p">,</span> <span class="n">check_take</span><span class="p">,</span> <span class="n">check_output_shape</span><span class="p">,</span> <span class="n">check_project</span><span class="p">,</span> \
    <span class="n">check_sync_wait</span><span class="p">,</span> <span class="n">check_zip_dataset</span><span class="p">,</span> <span class="n">check_add_column</span><span class="p">,</span> <span class="n">check_concat</span><span class="p">,</span> <span class="n">check_split</span><span class="p">,</span> <span class="n">check_bucket_batch_by_length</span><span class="p">,</span> \
    <span class="n">check_save</span><span class="p">,</span> <span class="n">check_tuple_iterator</span><span class="p">,</span> <span class="n">check_dict_iterator</span><span class="p">,</span> <span class="n">check_schema</span><span class="p">,</span> <span class="n">check_to_device_send</span><span class="p">,</span> <span class="n">check_padded_batch</span>
<span class="kn">from</span> <span class="nn">..core.config</span> <span class="kn">import</span> <span class="n">get_callback_timeout</span><span class="p">,</span> <span class="n">_init_device_info</span><span class="p">,</span> <span class="n">get_enable_shared_mem</span><span class="p">,</span> <span class="n">get_num_parallel_workers</span><span class="p">,</span> \
    <span class="n">get_enable_watchdog</span><span class="p">,</span> <span class="n">get_seed</span><span class="p">,</span> <span class="n">set_seed</span><span class="p">,</span> <span class="n">get_debug_mode</span><span class="p">,</span> <span class="n">get_multiprocessing_timeout_interval</span><span class="p">,</span> <span class="n">_get_debug_hook_list</span>
<span class="kn">from</span> <span class="nn">..core.datatypes</span> <span class="kn">import</span> <span class="n">mstype_to_detype</span>
<span class="kn">from</span> <span class="nn">..core.validator_helpers</span> <span class="kn">import</span> <span class="n">replace_none</span>
<span class="kn">from</span> <span class="nn">..core.py_util_helpers</span> <span class="kn">import</span> <span class="n">ExceptionHandler</span>
<span class="kn">from</span> <span class="nn">..transforms.py_transforms_util</span> <span class="kn">import</span> <span class="n">FuncWrapper</span><span class="p">,</span> <span class="n">Implementation</span>
<span class="kn">from</span> <span class="nn">..vision.transforms</span> <span class="kn">import</span> <span class="n">ToNumpy</span>
<span class="kn">from</span> <span class="nn">...mindrecord.config</span> <span class="kn">import</span> <span class="n">_get_enc_key</span><span class="p">,</span> <span class="n">_get_enc_mode</span><span class="p">,</span> <span class="n">_get_hash_mode</span><span class="p">,</span> <span class="n">encrypt</span><span class="p">,</span> <span class="n">append_hash_to_file</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">import_module</span><span class="p">(</span><span class="s2">&quot;mindspore.context&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">ModuleNotFoundError</span><span class="p">:</span>
    <span class="n">context</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">if</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;darwin&quot;</span> <span class="ow">and</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">get_start_method</span><span class="p">()</span> <span class="o">!=</span> <span class="s2">&quot;fork&quot;</span><span class="p">:</span>
    <span class="n">multiprocessing</span><span class="o">.</span><span class="n">set_start_method</span><span class="p">(</span><span class="s2">&quot;fork&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

<span class="n">OffloadToManualOffloadMode</span> <span class="o">=</span> <span class="p">{</span>
    <span class="kc">None</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">ManualOffloadMode</span><span class="o">.</span><span class="n">UNSPECIFIED</span><span class="p">,</span>
    <span class="kc">False</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">ManualOffloadMode</span><span class="o">.</span><span class="n">DISABLED</span><span class="p">,</span>
    <span class="kc">True</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">ManualOffloadMode</span><span class="o">.</span><span class="n">ENABLED</span>
<span class="p">}</span>

<span class="n">_train_dataset</span> <span class="o">=</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">_set_training_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set the dataset to be used when training recovery has occurred.</span>

<span class="sd">    Args:</span>
<span class="sd">        dataset: the training dataset or iterator</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">global</span> <span class="n">_train_dataset</span>
    <span class="n">_train_dataset</span> <span class="o">=</span> <span class="n">dataset</span>


<span class="k">def</span> <span class="nf">_get_training_dataset</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the dataset to be used when training recovery has occurred.</span>

<span class="sd">    Returns:</span>
<span class="sd">        training dataset/iterator</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_train_dataset</span>


<span class="k">def</span> <span class="nf">_reset_training_dataset</span><span class="p">(</span><span class="n">global_step</span><span class="p">,</span> <span class="n">dataset_size</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reset the training dataset to the given global step.</span>

<span class="sd">    Args:</span>
<span class="sd">        global_step (int): Number of global steps that have completed training.</span>
<span class="sd">            Dataset will provide data from its next step after reset.</span>
<span class="sd">        dataset_size (int): Number of steps per epoch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">_get_training_dataset</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">_reset</span><span class="p">(</span><span class="n">global_step</span><span class="p">,</span> <span class="n">dataset_size</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Training dataset is not set.&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="Shuffle"><a class="viewcode-back" href="../../../../api_python/dataset/mindspore.dataset.Shuffle.html#mindspore.dataset.Shuffle">[docs]</a><span class="k">class</span> <span class="nc">Shuffle</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Specify the shuffle mode.</span>

<span class="sd">    - ``Shuffle.GLOBAL`` : Shuffle both the files and samples.</span>
<span class="sd">    - ``Shuffle.FILES`` : Shuffle files only.</span>
<span class="sd">    - ``Shuffle.INFILE`` : Shuffle data within each file.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">GLOBAL</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;global&quot;</span>
    <span class="n">FILES</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;files&quot;</span>
    <span class="n">INFILE</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;infile&quot;</span></div>


<span class="n">ShuffleToShuffleMode</span> <span class="o">=</span> <span class="p">{</span><span class="n">Shuffle</span><span class="o">.</span><span class="n">FILES</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">ShuffleMode</span><span class="o">.</span><span class="n">FILES</span><span class="p">,</span>
                        <span class="n">Shuffle</span><span class="o">.</span><span class="n">GLOBAL</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">ShuffleMode</span><span class="o">.</span><span class="n">GLOBAL</span><span class="p">,</span>
                        <span class="n">Shuffle</span><span class="o">.</span><span class="n">INFILE</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">ShuffleMode</span><span class="o">.</span><span class="n">INFILE</span><span class="p">}</span>


<span class="k">def</span> <span class="nf">shuffle_to_shuffle_mode</span><span class="p">(</span><span class="n">shuffle</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Shuffle Enum to Shuffle Mode</span>

<span class="sd">    Args:</span>
<span class="sd">        shuffle (Shuffle): shuffle flag to shuffle mode in C layer</span>

<span class="sd">    Returns:</span>
<span class="sd">        ShuffleMode, shuffle mode</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shuffle_mode</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">ShuffleMode</span><span class="o">.</span><span class="n">GLOBAL</span>  <span class="c1"># Global shuffle</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shuffle</span><span class="p">,</span> <span class="n">Shuffle</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">shuffle</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">shuffle</span><span class="p">:</span>
            <span class="n">shuffle_mode</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">ShuffleMode</span><span class="o">.</span><span class="n">GLOBAL</span>  <span class="c1"># Global shuffle</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">shuffle_mode</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">ShuffleMode</span><span class="o">.</span><span class="n">FALSE</span>  <span class="c1"># No shuffle</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">shuffle_mode</span> <span class="o">=</span> <span class="n">ShuffleToShuffleMode</span><span class="p">[</span><span class="n">shuffle</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">shuffle_mode</span>


<span class="k">def</span> <span class="nf">shuffle_to_bool</span><span class="p">(</span><span class="n">shuffle</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Shuffle Enum to bool</span>

<span class="sd">    Args:</span>
<span class="sd">        shuffle (Shuffle): shuffle flag to bool</span>

<span class="sd">    Returns:</span>
<span class="sd">        bool, True / False</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">shuffle</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shuffle</span><span class="p">,</span> <span class="p">(</span><span class="nb">bool</span><span class="p">,</span> <span class="n">Shuffle</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;shuffle must be of boolean or enum of &#39;Shuffle&#39; values like &#39;Shuffle.GLOBAL&#39; or &quot;</span>
                        <span class="s2">&quot;&#39;Shuffle.FILES&#39; or &#39;Shuffle.INFILE&#39;.&quot;</span><span class="p">)</span>

    <span class="n">shuffle_bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shuffle</span><span class="p">,</span> <span class="n">Shuffle</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">shuffle</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">shuffle_bool</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="n">shuffle</span><span class="p">:</span>
            <span class="n">shuffle_bool</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">shuffle_bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">shuffle_bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="n">shuffle_bool</span>


<span class="nd">@check_zip</span>
<span class="k">def</span> <span class="nf">zip</span><span class="p">(</span><span class="n">datasets</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Zip the datasets in the input tuple of datasets.</span>

<span class="sd">    Args:</span>
<span class="sd">        datasets (tuple[Dataset]): A tuple of datasets to be zipped together.</span>
<span class="sd">            The number of datasets must be more than 1.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dataset, a new dataset with the above operation applied.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If the number of datasets is 1.</span>
<span class="sd">        TypeError: If datasets is not a tuple.</span>

<span class="sd">    Examples:</span>
<span class="sd">            &gt;&gt;&gt; # Create a dataset which is the combination of dataset_1 and dataset_2</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; dataset_1 = ds.GeneratorDataset([1], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; dataset_2 = ds.GeneratorDataset([2], &quot;column2&quot;)</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.zip((dataset_1, dataset_2))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Can&#39;t zip empty or just one dataset!&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Invalid dataset, expected Dataset object, but got </span><span class="si">%s</span><span class="s2">!&quot;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">ZipDataset</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_get_operator_process</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Inner implemented method, mainly for passing sub-process id in C layer</span>

<span class="sd">    Returns:</span>
<span class="sd">         dict, mapping dict of operation id and corresponding process id.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">global</span> <span class="n">_OP_PROCESS</span>
    <span class="n">process_info</span> <span class="o">=</span> <span class="n">_OP_PROCESS</span>
    <span class="n">op_process</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">keys</span> <span class="o">=</span> <span class="n">process_info</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
    <span class="n">fetched_all</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">op_process</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">process_info</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">item_full</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">process_info</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span> <span class="o">==</span> <span class="n">process_info</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">except</span> <span class="ne">KeyError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">err</span>
        <span class="n">fetched_all</span> <span class="o">=</span> <span class="n">fetched_all</span> <span class="ow">and</span> <span class="n">item_full</span>
    <span class="k">return</span> <span class="n">op_process</span><span class="p">,</span> <span class="n">fetched_all</span>


<span class="k">def</span> <span class="nf">_set_dataset_permissions</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">num_files</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    set saved dataset files&#39; permissions to 600</span>
<span class="sd">    the rule of dataset filenames should be the same as those in C++.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_digits</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">num_files</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">num_files</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">file_name</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">paths</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;</span><span class="si">{}{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">rjust</span><span class="p">(</span><span class="n">num_digits</span><span class="p">,</span> <span class="s1">&#39;0&#39;</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_files</span><span class="p">)]</span>

    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">chmod</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">stat</span><span class="o">.</span><span class="n">S_IRUSR</span> <span class="o">|</span> <span class="n">stat</span><span class="o">.</span><span class="n">S_IWUSR</span><span class="p">)</span>
            <span class="n">index_file</span> <span class="o">=</span> <span class="n">item</span> <span class="o">+</span> <span class="s2">&quot;.db&quot;</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">index_file</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">chmod</span><span class="p">(</span><span class="n">index_file</span><span class="p">,</span> <span class="n">stat</span><span class="o">.</span><span class="n">S_IRUSR</span> <span class="o">|</span> <span class="n">stat</span><span class="o">.</span><span class="n">S_IWUSR</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Dataset</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract class to represent a dataset in DataEngine&#39;s data pipeline.</span>

<span class="sd">    This class is the base class of SourceDataset and Dataset, and represents</span>
<span class="sd">    a node in the data flow graph.</span>
<span class="sd">                                     Dataset</span>
<span class="sd">           -----------------------------------------------------------</span>
<span class="sd">           |                  |                   |                  |</span>
<span class="sd">    VisionBaseDataset    TextBaseDataset    AudioBaseDataset         |</span>
<span class="sd">           -                  -                   -                  |</span>
<span class="sd">           |                  |                   |                  |</span>
<span class="sd">           ----------------------------------------                  |</span>
<span class="sd">                      UnionBaseDataset                               |</span>
<span class="sd">                                                                     |</span>
<span class="sd">                                                               SourceDataset</span>
<span class="sd">                                                                     -</span>
<span class="sd">                                                                     |</span>
<span class="sd">                                                              MappableDataset</span>

<span class="sd">    DatasetOperation: MapDataset(UnionBaseDataset)</span>
<span class="sd">                      BatchDataset(UnionBaseDataset)</span>
<span class="sd">                      PaddedBatchDataset(UnionBaseDataset)</span>
<span class="sd">                      BucketBatchByLengthDataset(UnionBaseDataset)</span>
<span class="sd">                      ShuffleDataset(UnionBaseDataset)</span>
<span class="sd">                      FilterDataset(UnionBaseDataset)</span>
<span class="sd">                      RepeatDataset(UnionBaseDataset)</span>
<span class="sd">                      SkipDataset(UnionBaseDataset)</span>
<span class="sd">                      TakeDataset(UnionBaseDataset)</span>
<span class="sd">                      ZipDataset(UnionBaseDataset)</span>
<span class="sd">                      ConcatDataset(UnionBaseDataset)</span>
<span class="sd">                      RenameDataset(UnionBaseDataset)</span>
<span class="sd">                      ProjectDataset(UnionBaseDataset)</span>
<span class="sd">                      SyncWaitDataset(UnionBaseDataset)</span>

<span class="sd">    Impl Dataset - vision:       ImageFolderDataset(MappableDataset, VisionBaseDataset)</span>
<span class="sd">                                 USPSDataset(SourceDataset, VisionBaseDataset)</span>
<span class="sd">    Impl Dataset - text:         TextFileDataset(SourceDataset, TextBaseDataset)</span>
<span class="sd">                                 YahooAnswersDataset(SourceDataset, TextBaseDataset)</span>
<span class="sd">    Impl Dataset - audio:        LJSpeechDataset(MappableDataset, AudioBaseDataset)</span>
<span class="sd">                                 TedliumDataset(MappableDataset, AudioBaseDataset)</span>
<span class="sd">    Impl Dataset - standard:     MindDataset(MappableDataset, UnionBaseDataset)</span>
<span class="sd">                                 TFRecordDataset(SourceDataset, UnionBaseDataset)</span>
<span class="sd">    Impl Dataset - user defined: GeneratorDataset(MappableDataset, UnionBaseDataset)</span>
<span class="sd">                                 NumpySlicesDataset(GeneratorDataset)</span>

<span class="sd">    Args:</span>
<span class="sd">        num_parallel_workers (int, optional): Number of workers to process the dataset in parallel.</span>
<span class="sd">            Default: ``None``.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Note: children and parent are internal variables, not recommended for external using.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">children</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">children</span><span class="p">,</span> <span class="p">[])</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">children</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">children</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
            <span class="n">child</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weakref</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span> <span class="o">=</span> <span class="n">num_parallel_workers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span> <span class="o">=</span> <span class="n">cache</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_device_iter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_indexs</span> <span class="o">=</span> <span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">saved_output_types</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">saved_output_shapes</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimated_output_shapes</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">runtime_context</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_col_names</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_size</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_classes</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_repeat_count</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_class_indexing</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sync</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_global_step</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_get_operator_id</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Internal method to iterate the tree and obtain op_id of each operation.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, the root dataset of the tree.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">op_name</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">generator_process</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">op_name</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">dataset</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">op_id</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">def</span> <span class="nf">process_name</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span> <span class="n">operator_id</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">datasets</span><span class="p">:</span>
                <span class="k">return</span> <span class="mi">0</span>
            <span class="n">temp</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
                    <span class="n">temp</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
                    <span class="n">op_name</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">)]</span> <span class="o">=</span> <span class="n">operator_id</span>

                    <span class="kn">from</span> <span class="nn">mindspore.dataset.engine.datasets_user_defined</span> <span class="kn">import</span> <span class="n">GeneratorDataset</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">GeneratorDataset</span><span class="p">)</span> <span class="ow">and</span> <span class="n">d</span><span class="o">.</span><span class="n">sample_fn</span> <span class="ow">and</span> <span class="n">d</span><span class="o">.</span><span class="n">sample_fn</span><span class="o">.</span><span class="n">pids</span><span class="p">:</span>
                        <span class="n">generator_process</span><span class="p">[</span><span class="n">operator_id</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">num_parallel_workers</span><span class="p">,</span> <span class="nb">set</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">sample_fn</span><span class="o">.</span><span class="n">pids</span><span class="p">)]</span>

            <span class="n">operator_id</span> <span class="o">=</span> <span class="n">operator_id</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="k">return</span> <span class="n">process_name</span><span class="p">(</span><span class="n">temp</span><span class="p">,</span> <span class="n">operator_id</span><span class="p">)</span>

        <span class="n">process_name</span><span class="p">([</span><span class="n">dataset</span><span class="p">],</span> <span class="n">op_id</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">generator_process</span><span class="p">:</span>
            <span class="k">global</span> <span class="n">_OP_PROCESS</span>
            <span class="n">_OP_PROCESS</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">generator_process</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">op_name</span>

    <span class="k">def</span> <span class="nf">create_ir_tree</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">getter_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Internal method to build an IR tree.</span>

<span class="sd">        Args:</span>
<span class="sd">            getter_mode (bool, optional): Whether to build IR tree in pull mode. Default: ``False``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[DatasetNode, Dataset], the root node of the IR tree and the root dataset of the IR tree.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">global</span> <span class="n">_OP_NAME</span>
        <span class="n">_OP_NAME</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">_get_operator_id</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
        <span class="n">ir_tree</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">parse_tree</span><span class="p">(</span><span class="n">getter_mode</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="o">=</span> <span class="n">parent</span>
        <span class="n">_init_device_info</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">ir_tree</span><span class="p">,</span> <span class="n">dataset</span>

    <span class="k">def</span> <span class="nf">parse_tree</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">getter_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Internal method to parse the API tree into an IR tree.</span>

<span class="sd">        Args:</span>
<span class="sd">            getter_mode (bool, optional): Whether to build IR tree in pull mode. Default: ``False``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            DatasetNode, the root node of the IR tree.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The data pipeline is not a tree (i.e., one node has 2 consumers)&quot;</span><span class="p">)</span>
        <span class="n">ir_children</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">parse_tree</span><span class="p">(</span><span class="n">getter_mode</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">]</span>
        <span class="c1"># Bootstrap can only be performed on a copy of the original dataset node.</span>
        <span class="c1"># Bootstrap on original dataset node will make all iterators share the same process pool</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_parse</span><span class="p">(</span><span class="n">getter_mode</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iterator_bootstrap</span><span class="p">()</span>
        <span class="n">ir_node</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">ir_children</span><span class="p">)</span>
        <span class="n">ir_node</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_parse</span><span class="p">(</span><span class="n">ir_node</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ir_node</span>

    <span class="k">def</span> <span class="nf">__safe_deepcopy__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memodict</span><span class="p">,</span> <span class="n">exclude</span><span class="o">=</span><span class="p">()):</span>
        <span class="k">if</span> <span class="nb">id</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="ow">in</span> <span class="n">memodict</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">memodict</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="bp">self</span><span class="p">)]</span>
        <span class="bp">cls</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span>
        <span class="n">new_op</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="fm">__new__</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span>
        <span class="n">memodict</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="bp">self</span><span class="p">)]</span> <span class="o">=</span> <span class="n">new_op</span>
        <span class="k">for</span> <span class="n">arg</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">exclude</span><span class="p">:</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="n">new_op</span><span class="p">,</span> <span class="n">arg</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="nb">setattr</span><span class="p">(</span><span class="n">new_op</span><span class="p">,</span> <span class="n">arg</span><span class="p">,</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">memodict</span><span class="p">))</span>
                <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                    <span class="nb">setattr</span><span class="p">(</span><span class="n">new_op</span><span class="p">,</span> <span class="n">arg</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_op</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_noop_mode</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">_is_role_sched</span><span class="p">():</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">iterator_bootstrap</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="fm">__add__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datasets</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span>

<div class="viewcode-block" id="Dataset.to_json"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/others/mindspore.dataset.Dataset.to_json.html#mindspore.dataset.Dataset.to_json">[docs]</a>    <span class="k">def</span> <span class="nf">to_json</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Serialize a pipeline into JSON string and dump into file if filename is provided.</span>

<span class="sd">        Args:</span>
<span class="sd">            filename (str): filename of JSON file to be saved as. Default: ``&quot;&quot;``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str, JSON string of the pipeline.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; mnist_dataset_dir = &quot;/path/to/mnist_dataset_directory&quot;</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.MnistDataset(dataset_dir=mnist_dataset_dir)</span>
<span class="sd">            &gt;&gt;&gt; dataset_json = dataset.to_json(&quot;/path/to/mnist_dataset_pipeline.json&quot;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ir_tree</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_ir_tree</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">ir_tree</span><span class="o">.</span><span class="n">to_json</span><span class="p">(</span><span class="n">filename</span><span class="p">))</span></div>

    <span class="c1"># The decorator has been deleted.</span>
<div class="viewcode-block" id="Dataset.bucket_batch_by_length"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/batch/mindspore.dataset.Dataset.bucket_batch_by_length.html#mindspore.dataset.Dataset.bucket_batch_by_length">[docs]</a>    <span class="k">def</span> <span class="nf">bucket_batch_by_length</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column_names</span><span class="p">,</span> <span class="n">bucket_boundaries</span><span class="p">,</span> <span class="n">bucket_batch_sizes</span><span class="p">,</span> <span class="n">element_length_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                               <span class="n">pad_info</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pad_to_bucket_boundary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Bucket elements according to their lengths. Each bucket will be padded and batched when</span>
<span class="sd">        they are full.</span>

<span class="sd">        A length function is called on each row in the dataset. The row is then</span>
<span class="sd">        bucketed based on its length and bucket boundaries. When a bucket reaches its</span>
<span class="sd">        corresponding size specified in bucket_batch_sizes, the entire bucket will be</span>
<span class="sd">        padded according to pad_info, and then form a batch.</span>

<span class="sd">        Refer to the following figure for the execution process:</span>

<span class="sd">        .. image:: bucket_batch_by_length_en.png</span>

<span class="sd">        Args:</span>
<span class="sd">            column_names (list[str]): Columns passed to element_length_function.</span>
<span class="sd">            bucket_boundaries (list[int]): A list consisting of the upper boundaries</span>
<span class="sd">                of the buckets. Must be strictly increasing. If there are n boundaries,</span>
<span class="sd">                n+1 buckets are created: One bucket for [0, bucket_boundaries[0]), one</span>
<span class="sd">                bucket for [bucket_boundaries[i], bucket_boundaries[i+1]) for each</span>
<span class="sd">                0&lt;i&lt;n-1, and the last bucket for [bucket_boundaries[n-1], inf).</span>
<span class="sd">            bucket_batch_sizes (list[int]): A list consisting of the batch sizes for</span>
<span class="sd">                each bucket. Must contain len(bucket_boundaries)+1 elements.</span>
<span class="sd">            element_length_function (Callable, optional): A function that takes in</span>
<span class="sd">                M arguments where M = len(column_names) and returns an integer. If no value</span>
<span class="sd">                provided, parameter M the len(column_names) must be 1, and the size of the first</span>
<span class="sd">                dimension of that column will be taken as the length. Default: ``None``.</span>
<span class="sd">            pad_info (dict, optional): The information about how to batch each column. The key</span>
<span class="sd">                corresponds to the column name, and the value must be a tuple of 2 elements.</span>
<span class="sd">                The first element corresponds to the shape to pad to, and the second</span>
<span class="sd">                element corresponds to the value to pad with. If a column is not</span>
<span class="sd">                specified, then that column will be padded to the longest in the current</span>
<span class="sd">                batch, and 0 will be used as the padding value. Any None dimensions will</span>
<span class="sd">                be padded to the longest in the current batch, unless if</span>
<span class="sd">                `pad_to_bucket_boundary` is ``True``. If no padding is wanted, set `pad_info`</span>
<span class="sd">                to ``None``. Default: ``None``.</span>
<span class="sd">            pad_to_bucket_boundary (bool, optional): If ``True``, will pad each None</span>
<span class="sd">                dimension in `pad_info` to the bucket_boundary minus 1. If there are any</span>
<span class="sd">                elements that fall into the last bucket, an error will occur.</span>
<span class="sd">                Default: ``False``.</span>
<span class="sd">            drop_remainder (bool, optional): If ``True``, will drop the last batch for each</span>
<span class="sd">                bucket if it is not a full batch. Default: ``False``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, a new dataset with the above operation applied.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; # Create a dataset where certain counts rows are combined into a batch</span>
<span class="sd">            &gt;&gt;&gt; # and drops the last incomplete batch if there is one.</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; def generate_2_columns(n):</span>
<span class="sd">            ...     for i in range(n):</span>
<span class="sd">            ...         yield (np.array([i]), np.array([j for j in range(i + 1)]))</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; column_names = [&quot;col1&quot;, &quot;col2&quot;]</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset(generate_2_columns(8), column_names)</span>
<span class="sd">            &gt;&gt;&gt; bucket_boundaries = [5, 10]</span>
<span class="sd">            &gt;&gt;&gt; bucket_batch_sizes = [2, 1, 1]</span>
<span class="sd">            &gt;&gt;&gt; element_length_function = (lambda col1, col2: max(len(col1), len(col2)))</span>
<span class="sd">            &gt;&gt;&gt; # Will pad col2 to shape [bucket_boundaries[i]] where i is the</span>
<span class="sd">            &gt;&gt;&gt; # index of the bucket that is currently being batched.</span>
<span class="sd">            &gt;&gt;&gt; pad_info = {&quot;col2&quot;: ([None], -1)}</span>
<span class="sd">            &gt;&gt;&gt; pad_to_bucket_boundary = True</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.bucket_batch_by_length(column_names, bucket_boundaries,</span>
<span class="sd">            ...                                          bucket_batch_sizes,</span>
<span class="sd">            ...                                          element_length_function, pad_info,</span>
<span class="sd">            ...                                          pad_to_bucket_boundary)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">BucketBatchByLengthDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column_names</span><span class="p">,</span> <span class="n">bucket_boundaries</span><span class="p">,</span> <span class="n">bucket_batch_sizes</span><span class="p">,</span>
                                          <span class="n">element_length_function</span><span class="p">,</span> <span class="n">pad_info</span><span class="p">,</span> <span class="n">pad_to_bucket_boundary</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.batch"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/batch/mindspore.dataset.Dataset.batch.html#mindspore.dataset.Dataset.batch">[docs]</a>    <span class="nd">@check_batch</span>
    <span class="k">def</span> <span class="nf">batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Combine batch_size number of consecutive rows into batch which apply per_batch_map to the samples first.</span>

<span class="sd">        For any column, all the elements within that column must have the same shape.</span>

<span class="sd">        Refer to the following figure for the execution process:</span>

<span class="sd">        .. image:: batch_en.png</span>

<span class="sd">        Note:</span>
<span class="sd">            The order of using repeat and batch reflects the number of batches and per_batch_map.</span>
<span class="sd">            It is recommended that the repeat operation applied after the batch operation finished.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_size (Union[int, Callable]): The number of rows each batch is created with. An</span>
<span class="sd">                int or callable object which takes exactly 1 parameter, BatchInfo.</span>
<span class="sd">            drop_remainder (bool, optional): Determines whether or not to drop the last block</span>
<span class="sd">                whose data row number is less than batch size. Default: ``False`` . If ``True`` ,</span>
<span class="sd">                and if there are less than `batch_size` rows available to make the last batch,</span>
<span class="sd">                then those rows will be dropped and not propagated to the child node.</span>
<span class="sd">            num_parallel_workers (int, optional): Number of workers(threads) to process the dataset in parallel.</span>
<span class="sd">                Default: ``None`` .</span>
<span class="sd">            **kwargs:</span>

<span class="sd">                - per_batch_map (Callable[[List[numpy.ndarray], ..., List[numpy.ndarray], BatchInfo], \</span>
<span class="sd">                  (List[numpy.ndarray], ..., List[numpy.ndarray])], optional): Per batch map callable.</span>
<span class="sd">                  Default: ``None``.</span>
<span class="sd">                  A callable which takes (List[numpy.ndarray], ..., List[numpy.ndarray], BatchInfo) as input parameters.</span>
<span class="sd">                  Each list[numpy.ndarray] represents a batch of numpy.ndarray on a given column. The number of lists</span>
<span class="sd">                  should match with the number of entries in input_columns. The last parameter of the callable should</span>
<span class="sd">                  always be a BatchInfo object. Per_batch_map should return</span>
<span class="sd">                  (list[numpy.ndarray], list[numpy.ndarray], ...). The length of each list in output should be the same</span>
<span class="sd">                  as the input. output_columns is required if the number of output lists is different from input.</span>

<span class="sd">                - input_columns (Union[str, list[str]], optional): List of names of the input columns. The size of</span>
<span class="sd">                  the list should match with signature of `per_batch_map` callable. Default: ``None`` .</span>

<span class="sd">                - output_columns (Union[str, list[str]], optional): List of names assigned to the columns</span>
<span class="sd">                  outputted by the last operation. This parameter is mandatory if len(input_columns) !=</span>
<span class="sd">                  len(output_columns). The size of this list must match the number of output</span>
<span class="sd">                  columns of the last operation. Default: ``None`` , output columns will have the same</span>
<span class="sd">                  name as the input columns, i.e., the columns will be replaced.</span>

<span class="sd">                - python_multiprocessing (bool, optional): Parallelize Python function `per_batch_map` with</span>
<span class="sd">                  multi-processing or multi-threading mode, ``True`` means multi-processing,</span>
<span class="sd">                  ``False`` means multi-threading If `per_batch_map` is a I/O bound task, use</span>
<span class="sd">                  multi-threading mode. If `per_batch_map` is a CPU bound task, it is recommended to use</span>
<span class="sd">                  multi-processing mode. Default: ``False`` , use python multi-threading mode.</span>

<span class="sd">                - max_rowsize(Union[int, list[int]], optional): Maximum size of row in MB that is used for shared memory</span>
<span class="sd">                  allocation to copy data between processes, the total occupied shared memory will increase as</span>
<span class="sd">                  ``num_parallel_workers`` and :func:`mindspore.dataset.config.set_prefetch_size` increase. This is only</span>
<span class="sd">                  used if python_multiprocessing is set to True. If it is an int value, it represents</span>
<span class="sd">                  ``input_columns`` and ``output_columns`` use this value as the unit to create shared memory.</span>
<span class="sd">                  If it is a list, the first element represents the ``input_columns`` use this value as the unit to</span>
<span class="sd">                  create shared memory, and the second element represents ``output_columns`` use this value as the unit</span>
<span class="sd">                  to create shared memory. Default: 16.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, a new dataset with the above operation applied.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; # 1) Create a dataset where every 5 rows are combined into a batch</span>
<span class="sd">            &gt;&gt;&gt; # and drops the last incomplete batch if there is one.</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; from PIL import Image</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; cifar10_dataset_dir = &quot;/path/to/cifar10_dataset_directory&quot;</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.Cifar10Dataset(dataset_dir=cifar10_dataset_dir, num_samples=10)</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.batch(5, True)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # 2) resize image according to its batch number, if it&#39;s 5-th batch, resize to (5^2, 5^2) = (25, 25)</span>
<span class="sd">            &gt;&gt;&gt; def np_resize(col, BatchInfo):</span>
<span class="sd">            ...     output = col.copy()</span>
<span class="sd">            ...     s = (BatchInfo.get_batch_num() + 1) ** 2</span>
<span class="sd">            ...     index = 0</span>
<span class="sd">            ...     for c in col:</span>
<span class="sd">            ...         img = Image.fromarray(c.astype(&#39;uint8&#39;)).convert(&#39;RGB&#39;)</span>
<span class="sd">            ...         img = img.resize((s, s))</span>
<span class="sd">            ...         output[index] = np.array(img)</span>
<span class="sd">            ...         index += 1</span>
<span class="sd">            ...     return (output,)</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.batch(batch_size=8, input_columns=[&quot;image&quot;], per_batch_map=np_resize)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # 3) Create a dataset where its batch size is dynamic</span>
<span class="sd">            &gt;&gt;&gt; # Define a callable batch size function and let batch size increase 1 each time.</span>
<span class="sd">            &gt;&gt;&gt; def add_one(BatchInfo):</span>
<span class="sd">            ...     return BatchInfo.get_batch_num() + 1</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.batch(batch_size=add_one, drop_remainder=True)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">BatchDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.padded_batch"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/batch/mindspore.dataset.Dataset.padded_batch.html#mindspore.dataset.Dataset.padded_batch">[docs]</a>    <span class="nd">@check_padded_batch</span>
    <span class="k">def</span> <span class="nf">padded_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pad_info</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Combine batch_size number of consecutive rows into batch which apply pad_info to the samples first.</span>

<span class="sd">        Refer to the following figure for the execution process:</span>

<span class="sd">        .. image:: padded_batch_en.png</span>

<span class="sd">        Note:</span>
<span class="sd">            The order of using repeat and padded_batch reflects the number of batches.</span>
<span class="sd">            It is recommended that the repeat operation applied after the padded_batch operation finished.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_size (Union[int, Callable]): The number of rows each batch is created with. An</span>
<span class="sd">                int or callable object which takes exactly 1 parameter, BatchInfo.</span>
<span class="sd">            drop_remainder (bool, optional): Determines whether or not to drop the last block</span>
<span class="sd">                whose data row number is less than batch size. Default: ``False``. If ``True``, and if there</span>
<span class="sd">                are less than batch_size rows available to make the last batch, then those rows will</span>
<span class="sd">                be dropped and not propagated to the child node.</span>
<span class="sd">            num_parallel_workers (int, optional): Number of workers(threads) to process the dataset in parallel.</span>
<span class="sd">                Default: ``None``.</span>
<span class="sd">            pad_info (dict, optional): The pad information about how to batch each column. The key</span>
<span class="sd">                corresponds to the column name, and the value must be a tuple of 2 elements.</span>
<span class="sd">                The first element corresponds to the shape to pad to, and the second</span>
<span class="sd">                element corresponds to the value to pad with. If a column is not</span>
<span class="sd">                specified, then that column will be padded to the longest in the current</span>
<span class="sd">                batch, and 0 will be used as the padding value. If ``pad_info={&quot;col1&quot;: ([224, 224], 0)}``,</span>
<span class="sd">                expand the data column named ``col1`` to shape (224, 224), and fill in the missing values with 0.</span>
<span class="sd">                If ``pad_info={}``, all samples in the batch will be filled to the shape with the largest sample</span>
<span class="sd">                in the current batch. If ``pad_info={&quot;col1&quot;: (None, 100)}``, all samples in the batch will be filled</span>
<span class="sd">                to the shape with the largest sample in the current batch, and fill in the missing values with 100.</span>
<span class="sd">                If no padding is wanted, set `pad_info` to ``None``. Default: ``None``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, a new dataset with the above operation applied.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; # 1) Pad every sample to the largest sample&#39;s shape and batch the samples</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.NumpySlicesDataset([[1], [1, 2], [1, 2, 3], [1, 2, 3, 4]], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.padded_batch(2, True, pad_info={})</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # 2) Create a dataset where every 3 rows are combined into a batch</span>
<span class="sd">            &gt;&gt;&gt; # and drops the last incomplete batch if there is one.</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.NumpySlicesDataset([i for i in range(10)], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.padded_batch(3, True)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # 3) Create a dataset where its batch size is dynamic</span>
<span class="sd">            &gt;&gt;&gt; # Define a callable batch size function and let batch size increase 1 each time.</span>
<span class="sd">            &gt;&gt;&gt; def add_one(BatchInfo):</span>
<span class="sd">            ...     return BatchInfo.get_batch_num() + 1</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.padded_batch(batch_size=add_one, drop_remainder=True)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">PaddedBatchDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="p">,</span> <span class="n">pad_info</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.sync_wait"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/others/mindspore.dataset.Dataset.sync_wait.html#mindspore.dataset.Dataset.sync_wait">[docs]</a>    <span class="nd">@check_sync_wait</span>
    <span class="k">def</span> <span class="nf">sync_wait</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">condition_name</span><span class="p">,</span> <span class="n">num_batch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a blocking condition to the input Dataset and a synchronize action will be applied.</span>

<span class="sd">        Args:</span>
<span class="sd">            condition_name (str): The condition name that is used to toggle sending next row.</span>
<span class="sd">            num_batch (int): the number of batches without blocking at the start of each epoch.</span>
<span class="sd">                Default: ``1``.</span>
<span class="sd">            callback (function): The callback function that will be invoked when sync_update is called.</span>
<span class="sd">                Default: ``None``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, a new dataset with the above operation applied.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: If condition name already exists.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; def gen():</span>
<span class="sd">            ...     for i in range(100):</span>
<span class="sd">            ...         yield (np.array(i),)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; class Augment:</span>
<span class="sd">            ...     def __init__(self, loss):</span>
<span class="sd">            ...         self.loss = loss</span>
<span class="sd">            ...</span>
<span class="sd">            ...     def preprocess(self, input_):</span>
<span class="sd">            ...         return input_</span>
<span class="sd">            ...</span>
<span class="sd">            ...     def update(self, data):</span>
<span class="sd">            ...         self.loss = data[&quot;loss&quot;]</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; batch_size = 4</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset(gen, column_names=[&quot;input&quot;])</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; aug = Augment(0)</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.sync_wait(condition_name=&quot;policy&quot;, callback=aug.update)</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.map(operations=[aug.preprocess], input_columns=[&quot;input&quot;])</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.batch(batch_size)</span>
<span class="sd">            &gt;&gt;&gt; count = 0</span>
<span class="sd">            &gt;&gt;&gt; for data in dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">            ...     assert data[&quot;input&quot;][0] == count</span>
<span class="sd">            ...     count += batch_size</span>
<span class="sd">            ...     data = {&quot;loss&quot;: count}</span>
<span class="sd">            ...     dataset.sync_update(condition_name=&quot;policy&quot;, data=data)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">SyncWaitDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">condition_name</span><span class="p">,</span> <span class="n">num_batch</span><span class="p">,</span> <span class="n">callback</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.shuffle"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/operation/mindspore.dataset.Dataset.shuffle.html#mindspore.dataset.Dataset.shuffle">[docs]</a>    <span class="nd">@check_shuffle</span>
    <span class="k">def</span> <span class="nf">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_size</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Shuffle the dataset by creating a cache with the size of `buffer_size` .</span>

<span class="sd">        1. Make a shuffle buffer that contains the first `buffer_size` rows.</span>
<span class="sd">        2. Randomly select an element from the shuffle buffer to be the next row</span>
<span class="sd">           propagated to the child node.</span>
<span class="sd">        3. Get the next row (if any) from the parent node and put it in the shuffle buffer.</span>
<span class="sd">        4. Repeat steps 2 and 3 until there are no more rows left in the shuffle buffer.</span>

<span class="sd">        A random seed can be provided to be used on the first epoch via `dataset.config.set_seed` . In every subsequent</span>
<span class="sd">        epoch, the seed is changed to a new one, randomly generated value.</span>

<span class="sd">        Args:</span>
<span class="sd">            buffer_size (int): The size of the buffer (must be larger than 1) for</span>
<span class="sd">                shuffling. Setting `buffer_size` equal to the number of rows in the entire</span>
<span class="sd">                dataset will result in a global shuffle.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, a new dataset with the above operation applied.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: If exist sync operations before shuffle.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([i for i in range(10)], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Optionally set the seed for fixed randomness</span>
<span class="sd">            &gt;&gt;&gt; ds.config.set_seed(58)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Create a shuffled dataset using a shuffle buffer of size 4</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.shuffle(4)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">ShuffleDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_size</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.flat_map"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/operation/mindspore.dataset.Dataset.flat_map.html#mindspore.dataset.Dataset.flat_map">[docs]</a>    <span class="k">def</span> <span class="nf">flat_map</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Map `func` to each row in dataset and flatten the result.</span>

<span class="sd">        Args:</span>
<span class="sd">            func (function): A function that must take one `numpy.ndarray` as an argument and</span>
<span class="sd">                return a `Dataset` .</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, a new dataset with the above operation applied.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; # 1) flat_map on one column dataset</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.NumpySlicesDataset([[0, 1], [2, 3]], shuffle=False)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; def repeat(array):</span>
<span class="sd">            ...     # create a NumpySlicesDataset with the array</span>
<span class="sd">            ...     data = ds.NumpySlicesDataset(array, shuffle=False)</span>
<span class="sd">            ...     # repeat the dataset twice</span>
<span class="sd">            ...     data = data.repeat(2)</span>
<span class="sd">            ...     return data</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.flat_map(repeat)</span>
<span class="sd">            &gt;&gt;&gt; # [0, 1, 0, 1, 2, 3, 2, 3]</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # 2) flat_map on multi column dataset</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.NumpySlicesDataset(([[0, 1], [2, 3]], [[0, -1], [-2, -3]]), shuffle=False)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; def plus_and_minus(col1, col2):</span>
<span class="sd">            ...     # apply different methods on columns</span>
<span class="sd">            ...     data = ds.NumpySlicesDataset((col1 + 1, col2 - 1), shuffle=False)</span>
<span class="sd">            ...     return data</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.flat_map(plus_and_minus)</span>
<span class="sd">            &gt;&gt;&gt; # ([1, 2, 3, 4], [-1, -2, -3, -4])</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `func` is not a function.</span>
<span class="sd">            TypeError: If `func` doesn&#39;t return a Dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="s1">&#39;__call__&#39;</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">critical</span><span class="p">(</span><span class="s2">&quot;func must be a function.&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;func must be a function.&quot;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">row_data</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_tuple_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">dataset</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">row_data</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">dataset</span> <span class="o">+=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">row_data</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">critical</span><span class="p">(</span><span class="s2">&quot;flat_map must return a Dataset object.&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;flat_map must return a Dataset object.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dataset</span></div>

<div class="viewcode-block" id="Dataset.map"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/operation/mindspore.dataset.Dataset.map.html#mindspore.dataset.Dataset.map">[docs]</a>    <span class="nd">@check_map</span>
    <span class="k">def</span> <span class="nf">map</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">operations</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">column_order</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">num_parallel_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply each operation in operations to this dataset.</span>

<span class="sd">        Each operation will be passed one or more columns from the dataset as input, and one or</span>
<span class="sd">        more columns will be outputted. The first operation will be passed the columns specified</span>
<span class="sd">        in input_columns as input. If there is more than one operation in operations, the outputted</span>
<span class="sd">        columns of the previous operation are used as the input columns for the next operation.</span>

<span class="sd">        The columns outputted by the very last operation will be assigned names specified by</span>
<span class="sd">        `output_columns` , and if not specified, the column name of output column is same as that of `input_columns` .</span>

<span class="sd">        - If you use transformations (</span>
<span class="sd">          `vision transform &lt;https://mindspore.cn/docs/en/r2.3/api_python/mindspore.\</span>
<span class="sd">          dataset.transforms.html#module-mindspore.dataset.vision&gt;`_ ,</span>
<span class="sd">          `nlp transform &lt;https://mindspore.cn/docs/en/r2.3/api_python/mindspore.\</span>
<span class="sd">          dataset.transforms.html#module-mindspore.dataset.text&gt;`_ ,</span>
<span class="sd">          `audio transform &lt;https://mindspore.cn/docs/en/r2.3/api_python/mindspore.\</span>
<span class="sd">          dataset.transforms.html#module-mindspore.dataset.audio&gt;`_ )</span>
<span class="sd">          provided by mindspore dataset, please use the following parameters:</span>

<span class="sd">          .. image:: map_parameter_en.png</span>

<span class="sd">        - If you use user-defined transform as PyFunc (Python Func), please use the following parameters:</span>

<span class="sd">          .. image:: map_parameter_pyfunc_en.png</span>

<span class="sd">        Args:</span>
<span class="sd">            operations (Union[list[TensorOperation], list[functions]]): List of operations to be</span>
<span class="sd">                applied on the dataset. Operations are applied in the order they appear in this list.</span>
<span class="sd">            input_columns (Union[str, list[str]], optional): List of the names of the columns that will be passed to</span>
<span class="sd">                the first operation as input. The size of this list must match the number of</span>
<span class="sd">                input columns expected by the first operation. Default: ``None``, the first</span>
<span class="sd">                operation will be passed however many columns that are required, starting from</span>
<span class="sd">                the first column.</span>
<span class="sd">            output_columns (Union[str, list[str]], optional): List of names assigned to the columns outputted by</span>
<span class="sd">                the last operation. This parameter is mandatory if len(input_columns) !=</span>
<span class="sd">                len(output_columns). The size of this list must match the number of output</span>
<span class="sd">                columns of the last operation. Default: ``None``, output columns will have the same</span>
<span class="sd">                name as the input columns, i.e., the columns will be replaced.</span>
<span class="sd">            num_parallel_workers (int, optional): Number of threads used to process the dataset in</span>
<span class="sd">                parallel. Default: ``None``, the value from the configuration will be used.</span>
<span class="sd">            **kwargs:</span>

<span class="sd">                - python_multiprocessing (bool, optional): Parallelize Python operations with multiple worker processes.</span>
<span class="sd">                  This option could be beneficial if the Python operation is computational heavy. Default: ``False``.</span>

<span class="sd">                - max_rowsize (Union[int, list[int]], optional): Maximum size of row in MB that is used for shared</span>
<span class="sd">                  memory allocation to copy data between processes, the total occupied shared memory will increase as</span>
<span class="sd">                  ``num_parallel_workers`` and :func:`mindspore.dataset.config.set_prefetch_size` increase. This is only</span>
<span class="sd">                  used if python_multiprocessing is set to True. If it is an int value, it represents</span>
<span class="sd">                  ``input_columns`` and ``output_columns`` use this value as the unit to create shared memory.</span>
<span class="sd">                  If it is a list, the first element represents the ``input_columns`` use this value as the unit to</span>
<span class="sd">                  create shared memory, and the second element represents ``output_columns`` use this value as the unit</span>
<span class="sd">                  to create shared memory. Default: 16.</span>

<span class="sd">                - cache (DatasetCache, optional): Use tensor caching service to speed up dataset processing.</span>
<span class="sd">                  Default: ``None``, which means no cache is used.</span>

<span class="sd">                - callbacks (DSCallback, list[DSCallback], optional): List of Dataset callbacks to be called.</span>
<span class="sd">                  Default: ``None``.</span>

<span class="sd">                - offload (bool, optional): Flag to indicate whether offload is used. Default: ``None``.</span>

<span class="sd">        Note:</span>
<span class="sd">            - Input `operations` accepts TensorOperations defined in mindspore.dataset part, plus user-defined</span>
<span class="sd">              Python functions (PyFuncs).</span>
<span class="sd">            - Do not add network computing operators from mindspore.nn and mindspore.ops or others into this</span>
<span class="sd">              `operations` .</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, a new dataset with the above operation applied.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset.vision as vision</span>
<span class="sd">            &gt;&gt;&gt; # dataset is an instance of Dataset which has 2 columns, &quot;image&quot; and &quot;label&quot;.</span>
<span class="sd">            &gt;&gt;&gt; # image is of type bytes type which can be decoded to RGB</span>
<span class="sd">            &gt;&gt;&gt; # label is of type int32</span>
<span class="sd">            &gt;&gt;&gt; cifar10_dataset_dir = &quot;/path/to/cifar10_dataset_directory&quot;</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.Cifar10Dataset(dataset_dir=cifar10_dataset_dir)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Define two operations, where each operation accepts 1 input column and outputs 1 column.</span>
<span class="sd">            &gt;&gt;&gt; decode_op = vision.Decode(to_pil=False)</span>
<span class="sd">            &gt;&gt;&gt; random_jitter_op = vision.RandomColorAdjust(brightness=(0.8, 0.8), contrast=(1, 1),</span>
<span class="sd">            ...                                             saturation=(1, 1), hue=(0, 0))</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # 1) Simple map example.</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Apply decode_op on column &quot;image&quot;.</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.map(operations=[decode_op], input_columns=[&quot;image&quot;])</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Decode and rename column &quot;image&quot; to &quot;decoded_image&quot;.</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.map(operations=[decode_op], input_columns=[&quot;image&quot;], output_columns=[&quot;decoded_image&quot;])</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # A simple example for user defined python function transform.</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.NumpySlicesDataset(data=[[0, 1, 2]], column_names=[&quot;data&quot;])</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.map(operations=[(lambda x: x - 1)], input_columns=[&quot;data&quot;])</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # 2) Map example with more than one operation.</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Create a dataset where the images are decoded, then randomly color jittered.</span>
<span class="sd">            &gt;&gt;&gt; # decode_op takes column &quot;image&quot; as input and outputs one column. The column</span>
<span class="sd">            &gt;&gt;&gt; # outputted by decode_op is passed as input to random_jitter_op.</span>
<span class="sd">            &gt;&gt;&gt; # random_jitter_op will output one column. Column &quot;image&quot; will be replaced by</span>
<span class="sd">            &gt;&gt;&gt; # the column outputted by random_jitter_op (the very last operation). All other</span>
<span class="sd">            &gt;&gt;&gt; # columns are unchanged.</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.map(operations=[decode_op, random_jitter_op], input_columns=[&quot;image&quot;])</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Rename the column outputted by random_jitter_op to &quot;image_mapped&quot;.</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.map(operations=[decode_op, random_jitter_op], input_columns=[&quot;image&quot;],</span>
<span class="sd">            ...                       output_columns=[&quot;image_mapped&quot;])</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Map with multiple operations using pyfunc and rename column&#39;s name</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.NumpySlicesDataset(data=[[0, 1, 2]], column_names=[&quot;data&quot;])</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.map(operations=[(lambda x: x * x), (lambda x: x - 1)], input_columns=[&quot;data&quot;],</span>
<span class="sd">            ...                                   output_columns=[&quot;data_mapped&quot;])</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # 3) Example where number of input columns is not equal to number of output columns.</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # operations[0] is a lambda that takes 2 columns as input and outputs 3 columns.</span>
<span class="sd">            &gt;&gt;&gt; # operations[1] is a lambda that takes 3 columns as input and outputs 1 column.</span>
<span class="sd">            &gt;&gt;&gt; # operations[2] is a lambda that takes 1 column as input and outputs 4 columns.</span>
<span class="sd">            &gt;&gt;&gt; #</span>
<span class="sd">            &gt;&gt;&gt; # Note: The number of output columns of operation[i] must equal the number of</span>
<span class="sd">            &gt;&gt;&gt; # input columns of operation[i+1]. Otherwise, this map call will also result</span>
<span class="sd">            &gt;&gt;&gt; # in an error.</span>
<span class="sd">            &gt;&gt;&gt; operations = [(lambda x, y: (x, x + y, x + y + 1)),</span>
<span class="sd">            ...               (lambda x, y, z: x * y * z),</span>
<span class="sd">            ...               (lambda x: (x % 2, x % 3, x % 5, x % 7))]</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.NumpySlicesDataset(data=([[0, 1, 2]], [[3, 4, 5]]), column_names=[&quot;x&quot;, &quot;y&quot;])</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.map(operations, input_columns=[&quot;x&quot;, &quot;y&quot;],</span>
<span class="sd">            ...                       output_columns=[&quot;mod2&quot;, &quot;mod3&quot;, &quot;mod5&quot;, &quot;mod7&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;operator_mixed&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;operator_mixed&#39;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">num_parallel_workers</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Input &#39;operations&#39; of &#39;map&#39; includes network computing operators like in mindspore.nn, mindspore.ops, &quot;</span>
                <span class="s2">&quot;mindspore.numpy module and etc, which do not support multi-thread compiling, recommend to replace it &quot;</span>
                <span class="s2">&quot;with python implemented operator like numpy etc. Here decrease &#39;num_parallel_workers&#39; into 1.&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">MapDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">operations</span><span class="p">,</span> <span class="n">input_columns</span><span class="p">,</span> <span class="n">output_columns</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.filter"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/operation/mindspore.dataset.Dataset.filter.html#mindspore.dataset.Dataset.filter">[docs]</a>    <span class="nd">@check_filter</span>
    <span class="k">def</span> <span class="nf">filter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predicate</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Filter dataset by prediction.</span>

<span class="sd">        Args:</span>
<span class="sd">            predicate (callable): Python callable which returns a boolean value. If False then filter the element.</span>
<span class="sd">            input_columns (Union[str, list[str]], optional): List of names of the input columns. If not provided</span>
<span class="sd">                or provided with ``None``, the predicate will be applied on all columns in the dataset.</span>
<span class="sd">                Default: ``None``.</span>
<span class="sd">            num_parallel_workers (int, optional): Number of workers to process the dataset</span>
<span class="sd">                in parallel. Default: ``None``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, a new dataset with the above operation applied.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; # generator data(0 ~ 19)</span>
<span class="sd">            &gt;&gt;&gt; # filter the data that greater than or equal to 11</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([i for i in range(20)], &quot;data&quot;)</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.filter(predicate=lambda data: data &lt; 11, input_columns = [&quot;data&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">FilterDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predicate</span><span class="p">,</span> <span class="n">input_columns</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.repeat"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/operation/mindspore.dataset.Dataset.repeat.html#mindspore.dataset.Dataset.repeat">[docs]</a>    <span class="nd">@check_repeat</span>
    <span class="k">def</span> <span class="nf">repeat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">count</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Repeat this dataset `count` times. Repeat infinitely if the `count` is ``None`` or ``-1``.</span>

<span class="sd">        Note:</span>
<span class="sd">            The order of using repeat and batch reflects the number of batches. It is recommended that</span>
<span class="sd">            the repeat operation is used after the batch operation.</span>

<span class="sd">        Args:</span>
<span class="sd">            count (int): Number of times the dataset is going to be repeated. Default: ``None``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, a new dataset with the above operation applied.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Create a dataset with 10 elements</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([i for i in range(10)], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ori_size = dataset.get_dataset_size()</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Repeat the dataset 50 times.</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.repeat(50)</span>
<span class="sd">            &gt;&gt;&gt; repeated_size = dataset.get_dataset_size()</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;ori_size&quot;, ori_size, &quot;, repeated_size&quot;, repeated_size)</span>
<span class="sd">            ori_size 10 , repeated_size 500</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Since the original dataset size is less than batch_size, thus no data is returned</span>
<span class="sd">            &gt;&gt;&gt; dataset1 = ds.GeneratorDataset([i for i in range(10)], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; dataset1 = dataset1.batch(batch_size=20, drop_remainder=True)</span>
<span class="sd">            &gt;&gt;&gt; dataset1 = dataset1.repeat(6)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Repeat the original dataset to 60 elements, thus 3 batches are returned</span>
<span class="sd">            &gt;&gt;&gt; dataset2 = ds.GeneratorDataset([i for i in range(10)], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; dataset2 = dataset2.repeat(6)</span>
<span class="sd">            &gt;&gt;&gt; dataset2 = dataset2.batch(batch_size=20, drop_remainder=True)</span>
<span class="sd">            &gt;&gt;&gt; print(&quot;dataset1 size&quot;, dataset1.get_dataset_size(), &quot;, dataset2 size&quot;, dataset2.get_dataset_size())</span>
<span class="sd">            dataset1 size 0 , dataset2 size 3</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">RepeatDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">count</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.skip"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/operation/mindspore.dataset.Dataset.skip.html#mindspore.dataset.Dataset.skip">[docs]</a>    <span class="nd">@check_skip</span>
    <span class="k">def</span> <span class="nf">skip</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">count</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Skip the first N elements of this dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            count (int): Number of elements in the dataset to be skipped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, a new dataset with the above operation applied.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([i for i in range(10)], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; # Skip first 3 elements of dataset and retain 7 elements.</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.skip(3)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">SkipDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">count</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.take"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/operation/mindspore.dataset.Dataset.take.html#mindspore.dataset.Dataset.take">[docs]</a>    <span class="nd">@check_take</span>
    <span class="k">def</span> <span class="nf">take</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">count</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Take the first specified number of samples from the dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            count (int, optional): The desired number of samples to take. If the value exceeds</span>
<span class="sd">                the total number of samples in the dataset, all data will be returned.</span>
<span class="sd">                Default: ``-1`` , will return all data.</span>

<span class="sd">        Note:</span>
<span class="sd">            When there are operations that will change the number of samples of the dataset in</span>
<span class="sd">            the data pipeline, the location of the `take` operation can change its effect.</span>
<span class="sd">            For example, `batch` operation will combine the successive samples of the specified</span>
<span class="sd">            `batch_size` into 1 sample, so `.batch(batch_size).take(1)` will be equivalent to</span>
<span class="sd">            `.take(batch_size).batch(batch_size)`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, a new dataset with the above operation applied.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; mnist_dataset_dir = &quot;/path/to/mnist_dataset_directory&quot;</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.MnistDataset(dataset_dir=mnist_dataset_dir)</span>
<span class="sd">            &gt;&gt;&gt; # Take 50 samples from MNIST dataset.</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.take(50)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">TakeDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">count</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_get_absolute_split_sizes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sizes</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Internal method called by split to calculate absolute split sizes and to</span>
<span class="sd">        do some error checking after calculating absolute split sizes.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int, absolute split sizes of the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Call get_dataset_size here and check input here because</span>
        <span class="c1"># don&#39;t want to call this once in check_split and another time in</span>
        <span class="c1"># here again</span>
        <span class="n">dataset_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">dataset_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">dataset_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;dataset_size is unknown, unable to split.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sizes</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;sizes must be a list.&quot;</span><span class="p">)</span>

        <span class="n">all_int</span> <span class="o">=</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">all_int</span><span class="p">:</span>
            <span class="n">sizes_sum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">sizes_sum</span> <span class="o">!=</span> <span class="n">dataset_size</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Sum of split sizes </span><span class="si">{}</span><span class="s2"> is not equal to dataset size </span><span class="si">{}</span><span class="s2">.&quot;</span>
                                   <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sizes_sum</span><span class="p">,</span> <span class="n">dataset_size</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">sizes</span>

        <span class="n">absolute_sizes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">:</span>
            <span class="n">absolute_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">item</span> <span class="o">*</span> <span class="n">dataset_size</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">absolute_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Split percentage </span><span class="si">{}</span><span class="s2"> is too small.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">item</span><span class="p">))</span>
            <span class="n">absolute_sizes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">absolute_size</span><span class="p">)</span>

        <span class="n">absolute_sizes_sum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">absolute_sizes</span><span class="p">)</span>

        <span class="c1"># if we still need more rows, give them to the first split.</span>
        <span class="c1"># if we have too many rows, remove the extras from the first split that has</span>
        <span class="c1"># enough rows.</span>
        <span class="n">size_difference</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dataset_size</span> <span class="o">-</span> <span class="n">absolute_sizes_sum</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">size_difference</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">absolute_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">size_difference</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">absolute_sizes</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">absolute_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">size_difference</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">absolute_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">size_difference</span>
                    <span class="k">break</span>

        <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">absolute_sizes</span><span class="p">)</span> <span class="o">!=</span> <span class="n">dataset_size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Sum of calculated split sizes </span><span class="si">{}</span><span class="s2"> is not equal to dataset size </span><span class="si">{}</span><span class="s2">.&quot;</span>
                               <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">absolute_sizes_sum</span><span class="p">,</span> <span class="n">dataset_size</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">absolute_sizes</span>

<div class="viewcode-block" id="Dataset.split"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/operation/mindspore.dataset.Dataset.split.html#mindspore.dataset.Dataset.split">[docs]</a>    <span class="nd">@check_split</span>
    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sizes</span><span class="p">,</span> <span class="n">randomize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Split the dataset into smaller, non-overlapping datasets.</span>

<span class="sd">        Args:</span>
<span class="sd">            sizes (Union[list[int], list[float]]): If a list of integers [s1, s2, …, sn] is</span>
<span class="sd">                provided, the dataset will be split into n datasets of size s1, size s2, …, size sn</span>
<span class="sd">                respectively. If the sum of all input sizes does not equal the original dataset size, an</span>
<span class="sd">                error will throw.</span>
<span class="sd">                If a list of floats [f1, f2, …, fn] is provided, all floats must be between 0 and 1</span>
<span class="sd">                and must sum to 1, otherwise an error will throw. The dataset will be split into n</span>
<span class="sd">                Datasets of size round(f1*K), round(f2*K), …, round(fn*K) where K is the size of the</span>
<span class="sd">                original dataset.</span>
<span class="sd">                If after rounding:</span>

<span class="sd">                - Any size equals 0, an error will occur.</span>
<span class="sd">                - The sum of split sizes &lt; K, the difference of K - sigma(round(fi * k)) will be added to the first</span>
<span class="sd">                  split.</span>
<span class="sd">                - The sum of split sizes &gt; K, the difference of sigma(round(fi * K)) - K will be removed from the first</span>
<span class="sd">                  large enough split such that it will have at least 1 row after removing the difference.</span>

<span class="sd">            randomize (bool, optional): Determines whether or not to split the data randomly. Default: ``True``.</span>
<span class="sd">                If True, the data will be randomly split. Otherwise, each split will be created with</span>
<span class="sd">                consecutive rows from the dataset.</span>

<span class="sd">        Note:</span>
<span class="sd">            1. Dataset cannot be sharded if split is going to be called.</span>
<span class="sd">            2. It is strongly recommended to not shuffle the dataset, but use randomize=True instead.</span>
<span class="sd">               Shuffling the dataset may not be deterministic, which means the data in each split</span>
<span class="sd">               will be different in each epoch.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[Dataset], a tuple of new datasets split from the original one.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: If get_dataset_size returns None or is not supported for this dataset.</span>
<span class="sd">            RuntimeError: If `sizes` is list of integers and sum of all elements in sizes does not</span>
<span class="sd">                equal the dataset size.</span>
<span class="sd">            RuntimeError: If `sizes` is list of float and there is a split with size 0 after calculations.</span>
<span class="sd">            RuntimeError: If the dataset is sharded prior to calling split.</span>
<span class="sd">            ValueError: If `sizes` is list of float and not all floats are between 0 and 1, or if the</span>
<span class="sd">                floats don&#39;t sum to 1.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; # Split the data into train part and test part.</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([i for i in range(10)], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; train_dataset, test_dataset = dataset.split([0.9, 0.1])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_shuffled</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Dataset is shuffled before split.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_sharded</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Dataset should not be sharded before split.&quot;</span><span class="p">)</span>

        <span class="n">absolute_sizes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_absolute_split_sizes</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
        <span class="n">splits</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">rows_to_skip</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">absolute_sizes</span><span class="p">:</span>
            <span class="n">ds</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">randomize</span><span class="p">:</span>
                <span class="c1"># want to shuffle the same way every epoch before split</span>
                <span class="c1"># in alter_tree, shuffle buffer is minimum 10000, so use 10000 here</span>
                <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
                <span class="n">ds</span><span class="o">.</span><span class="n">reshuffle_each_epoch</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="k">if</span> <span class="n">rows_to_skip</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="n">rows_to_skip</span><span class="p">)</span>

            <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
            <span class="n">splits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>

            <span class="n">rows_to_skip</span> <span class="o">+=</span> <span class="n">size</span>

        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">splits</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.zip"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/operation/mindspore.dataset.Dataset.zip.html#mindspore.dataset.Dataset.zip">[docs]</a>    <span class="nd">@check_zip_dataset</span>
    <span class="k">def</span> <span class="nf">zip</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datasets</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Zip the datasets in the sense of input tuple of datasets. Columns in the input datasets must have different</span>
<span class="sd">        name.</span>

<span class="sd">        Args:</span>
<span class="sd">            datasets (Union[Dataset, tuple[Dataset]]): A tuple of datasets or a single class Dataset</span>
<span class="sd">                to be zipped together with this dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, a new dataset with the above operation applied.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: The parameter is not dataset object or tuple of dataset objects.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; # Create a dataset which is the combination of dataset_1 and dataset_2</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; dataset_1 = ds.GeneratorDataset([1, 2, 3], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; dataset_2 = ds.GeneratorDataset([1, 2, 3], &quot;column2&quot;)</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset_1.zip(dataset_2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">datasets</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">datasets</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">):</span>
            <span class="n">datasets</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datasets</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Invalid datasets, expected Dataset object or tuple of Dataset, but got </span><span class="si">%s</span><span class="s2">!&quot;</span> <span class="o">%</span> <span class="n">datasets</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ZipDataset</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.concat"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/operation/mindspore.dataset.Dataset.concat.html#mindspore.dataset.Dataset.concat">[docs]</a>    <span class="nd">@check_concat</span>
    <span class="k">def</span> <span class="nf">concat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datasets</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Concatenate the dataset objects in the input list.</span>
<span class="sd">        Performing &quot;+&quot; operation on dataset objects can achieve the same effect.</span>

<span class="sd">        For a dataset concatenated by many other dataset objects, it returns the data in the order of</span>
<span class="sd">        datasets passed in. If you want to change the data order(such as random selection from each dataset</span>
<span class="sd">        instead of in sequence), apply `use_sampler` method on the concatenated dataset object.</span>
<span class="sd">        Currently `use_sampler` supports `dataset.DistributedSampler` for sharding selection from each dataset</span>
<span class="sd">        or `dataset.RandomSampler` for random selection from each dataset, see examples below.</span>

<span class="sd">        Note:</span>
<span class="sd">            The column name, and rank and type of the column data must be the same in the input datasets.</span>

<span class="sd">        Args:</span>
<span class="sd">            datasets (Union[list, Dataset]): A list of datasets or a single class Dataset</span>
<span class="sd">                to be concatenated together with this dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, a new dataset with the above operation applied.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; dataset_1 = ds.GeneratorDataset([1, 2, 3], &quot;column1&quot;, shuffle=False)</span>
<span class="sd">            &gt;&gt;&gt; dataset_2 = ds.GeneratorDataset([4, 5, 6], &quot;column1&quot;, shuffle=False)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Create a dataset by concatenating dataset_1 and dataset_2 with &quot;+&quot; operator</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset_1 + dataset_2</span>
<span class="sd">            &gt;&gt;&gt; # Create a dataset by concatenating dataset_1 and dataset_2 with concat operation</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset_1.concat(dataset_2)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Check the data order of dataset</span>
<span class="sd">            &gt;&gt;&gt; dataset_1 = ds.GeneratorDataset([1, 2, 3], &quot;column1&quot;, shuffle=False)</span>
<span class="sd">            &gt;&gt;&gt; dataset_2 = ds.GeneratorDataset([4, 5, 6], &quot;column1&quot;, shuffle=False)</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset_1 + dataset_2</span>
<span class="sd">            &gt;&gt;&gt; result = list(dataset)</span>
<span class="sd">            &gt;&gt;&gt; # [[Tensor(shape=[], dtype=Int64, value= 1)], [Tensor(shape=[], dtype=Int64, value= 2)],</span>
<span class="sd">            &gt;&gt;&gt; #  [Tensor(shape=[], dtype=Int64, value= 3)], [Tensor(shape=[], dtype=Int64, value= 4)],</span>
<span class="sd">            &gt;&gt;&gt; #  [Tensor(shape=[], dtype=Int64, value= 5)], [Tensor(shape=[], dtype=Int64, value= 6)]]</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Change the data order of concatenated dataset with sharding selection</span>
<span class="sd">            &gt;&gt;&gt; dataset_1 = ds.GeneratorDataset([1, 2, 3], &quot;column1&quot;, shuffle=False)</span>
<span class="sd">            &gt;&gt;&gt; dataset_2 = ds.GeneratorDataset([4, 5, 6], &quot;column1&quot;, shuffle=False)</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset_1.concat(dataset_2)</span>
<span class="sd">            &gt;&gt;&gt; dataset.use_sampler(ds.DistributedSampler(num_shards=2, shard_id=1, shuffle=False))</span>
<span class="sd">            &gt;&gt;&gt; result = list(dataset)</span>
<span class="sd">            &gt;&gt;&gt; # [[Tensor(shape=[], dtype=Int64, value= 2)], [Tensor(shape=[], dtype=Int64, value= 4)],</span>
<span class="sd">            &gt;&gt;&gt; #  [Tensor(shape=[], dtype=Int64, value= 6)]]</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Change the data order of concatenated dataset with random selection</span>
<span class="sd">            &gt;&gt;&gt; dataset_1 = ds.GeneratorDataset([1, 2, 3], &quot;column1&quot;, shuffle=False)</span>
<span class="sd">            &gt;&gt;&gt; dataset_2 = ds.GeneratorDataset([4, 5, 6], &quot;column1&quot;, shuffle=False)</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset_1.concat(dataset_2)</span>
<span class="sd">            &gt;&gt;&gt; dataset.use_sampler(ds.RandomSampler())</span>
<span class="sd">            &gt;&gt;&gt; result = list(dataset)</span>
<span class="sd">            &gt;&gt;&gt; # [[Tensor(shape=[], dtype=Int64, value= 1)], [Tensor(shape=[], dtype=Int64, value= 4)],</span>
<span class="sd">            &gt;&gt;&gt; #  [Tensor(shape=[], dtype=Int64, value= 2)], [Tensor(shape=[], dtype=Int64, value= 5)],</span>
<span class="sd">            &gt;&gt;&gt; #  [Tensor(shape=[], dtype=Int64, value= 6)], [Tensor(shape=[], dtype=Int64, value= 3)]]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">):</span>
            <span class="n">datasets</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">datasets</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">datasets</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">datasets</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">]</span> <span class="o">+</span> <span class="n">datasets</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Invalid datasets, expected Dataset object or list of Dataset, but got </span><span class="si">%s</span><span class="s2">!&quot;</span> <span class="o">%</span> <span class="n">datasets</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ConcatDataset</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.rename"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/operation/mindspore.dataset.Dataset.rename.html#mindspore.dataset.Dataset.rename">[docs]</a>    <span class="nd">@check_rename</span>
    <span class="k">def</span> <span class="nf">rename</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_columns</span><span class="p">,</span> <span class="n">output_columns</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Rename the columns in input datasets.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_columns (Union[str, list[str]]): List of names of the input columns.</span>
<span class="sd">            output_columns (Union[str, list[str]]): List of names of the output columns.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, a new dataset with the above operation applied.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; input_columns = [&quot;input_col1&quot;, &quot;input_col2&quot;, &quot;input_col3&quot;]</span>
<span class="sd">            &gt;&gt;&gt; output_columns = [&quot;output_col1&quot;, &quot;output_col2&quot;, &quot;output_col3&quot;]</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Create a dataset with 3 columns</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([(1, 2, 3), (3, 4, 5), (5, 6, 7)], column_names=input_columns)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Rename &quot;input_col1&quot; to &quot;output_col1&quot;, &quot;input_col2&quot; to &quot;output_col2&quot;, &quot;input_col3&quot; to &quot;output_col3&quot;</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.rename(input_columns=input_columns, output_columns=output_columns)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">RenameDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_columns</span><span class="p">,</span> <span class="n">output_columns</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.project"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/operation/mindspore.dataset.Dataset.project.html#mindspore.dataset.Dataset.project">[docs]</a>    <span class="nd">@check_project</span>
    <span class="k">def</span> <span class="nf">project</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The specified columns will be selected from the dataset and passed into</span>
<span class="sd">        the pipeline with the order specified. The other columns are discarded.</span>

<span class="sd">        Args:</span>
<span class="sd">            columns(Union[str, list[str]]): List of names of the columns to project.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, a new dataset with the above operation applied.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; # Create a dataset with 3 columns</span>
<span class="sd">            &gt;&gt;&gt; input_columns = [&quot;column1&quot;, &quot;column2&quot;, &quot;column3&quot;]</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([(1, 2, 3), (3, 4, 5), (5, 6, 7)], column_names=input_columns)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; columns_to_project = [&quot;column3&quot;, &quot;column1&quot;, &quot;column2&quot;]</span>
<span class="sd">            &gt;&gt;&gt; # in that order, regardless of the original order of columns.</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.project(columns=columns_to_project)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">ProjectDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.apply"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/operation/mindspore.dataset.Dataset.apply.html#mindspore.dataset.Dataset.apply">[docs]</a>    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">apply_func</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply a function in this dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            apply_func (function): A function that must take one `Dataset` as an argument and</span>
<span class="sd">                                   return a preprocessed `Dataset` .</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, a new dataset with the above operation applied.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([i for i in range(10)], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Declare an apply_func function which returns a Dataset object</span>
<span class="sd">            &gt;&gt;&gt; def apply_func(data):</span>
<span class="sd">            ...     data = data.batch(2)</span>
<span class="sd">            ...     return data</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Use apply to call apply_func</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.apply(apply_func)</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If apply_func is not a function.</span>
<span class="sd">            TypeError: If apply_func doesn&#39;t return a Dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">apply_func</span><span class="p">,</span> <span class="s1">&#39;__call__&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;apply_func must be a function.&quot;</span><span class="p">)</span>

        <span class="n">dataset</span> <span class="o">=</span> <span class="n">apply_func</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;apply_func must return a dataset.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dataset</span></div>

    <span class="nd">@check_device_send</span>
    <span class="k">def</span> <span class="nf">device_que</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">send_epoch_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">create_data_info_queue</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">queue_name</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return a transferred Dataset that transfers data through a device.</span>

<span class="sd">        Args:</span>
<span class="sd">            send_epoch_end (bool, optional): Whether to send end of sequence to device or not.</span>
<span class="sd">                Default: ``True``.</span>
<span class="sd">            create_data_info_queue (bool, optional): Whether to create queue which stores</span>
<span class="sd">                types and shapes of data or not. Default: ``False``.</span>
<span class="sd">            queue_name (str, optional): Name of queue which connects dataset processing and model</span>
<span class="sd">                computing. Default: ``&quot;&quot;``.</span>

<span class="sd">        Note:</span>
<span class="sd">            If device is Ascend, features of data will be transferred one by one. The limitation</span>
<span class="sd">            of data transmission per time is 256M.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dataset, a new dataset with the above operation applied.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; import time</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; data = ds.TFRecordDataset(&#39;/path/to/TF_FILES&#39;, &#39;/path/to/TF_SCHEMA_FILE&#39;, shuffle=ds.Shuffle.FILES)</span>
<span class="sd">            &gt;&gt;&gt; data = data.device_que()</span>
<span class="sd">            &gt;&gt;&gt; data.send()</span>
<span class="sd">            &gt;&gt;&gt; time.sleep(0.1)</span>
<span class="sd">            &gt;&gt;&gt; data.stop_send()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">TransferDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">send_epoch_end</span><span class="p">,</span> <span class="n">create_data_info_queue</span><span class="p">,</span> <span class="n">queue_name</span><span class="p">)</span>

<div class="viewcode-block" id="Dataset.save"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/operation/mindspore.dataset.Dataset.save.html#mindspore.dataset.Dataset.save">[docs]</a>    <span class="nd">@check_save</span>
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_name</span><span class="p">,</span> <span class="n">num_files</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">file_type</span><span class="o">=</span><span class="s1">&#39;mindrecord&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save the dynamic data processed by the dataset pipeline in common dataset format.</span>
<span class="sd">        Supported dataset formats: ``&#39;mindrecord&#39;`` only. And you can use</span>
<span class="sd">        :class:`mindspore.dataset.MindDataset` API to read the saved file(s).</span>

<span class="sd">        Implicit type casting exists when saving data as ``&#39;mindrecord&#39;`` . The transform table shows how to do</span>
<span class="sd">        type casting.</span>

<span class="sd">        .. list-table:: Implicit Type Casting when Saving as `mindrecord`</span>
<span class="sd">           :widths: 25 25 50</span>
<span class="sd">           :header-rows: 1</span>

<span class="sd">           * - Type in `dataset`</span>
<span class="sd">             - Type in `mindrecord`</span>
<span class="sd">             - Details</span>
<span class="sd">           * - bool</span>
<span class="sd">             - int32</span>
<span class="sd">             - transform to int32</span>
<span class="sd">           * - int8</span>
<span class="sd">             - int32</span>
<span class="sd">             -</span>
<span class="sd">           * - uint8</span>
<span class="sd">             - int32</span>
<span class="sd">             -</span>
<span class="sd">           * - int16</span>
<span class="sd">             - int32</span>
<span class="sd">             -</span>
<span class="sd">           * - uint16</span>
<span class="sd">             - int32</span>
<span class="sd">             -</span>
<span class="sd">           * - int32</span>
<span class="sd">             - int32</span>
<span class="sd">             -</span>
<span class="sd">           * - uint32</span>
<span class="sd">             - int64</span>
<span class="sd">             -</span>
<span class="sd">           * - int64</span>
<span class="sd">             - int64</span>
<span class="sd">             -</span>
<span class="sd">           * - uint64</span>
<span class="sd">             - int64</span>
<span class="sd">             - Maybe reverse</span>
<span class="sd">           * - float16</span>
<span class="sd">             - float32</span>
<span class="sd">             -</span>
<span class="sd">           * - float32</span>
<span class="sd">             - float32</span>
<span class="sd">             -</span>
<span class="sd">           * - float64</span>
<span class="sd">             - float64</span>
<span class="sd">             -</span>
<span class="sd">           * - string</span>
<span class="sd">             - string</span>
<span class="sd">             - Multi-dimensional string not supported</span>
<span class="sd">           * - bytes</span>
<span class="sd">             - bytes</span>
<span class="sd">             - Multi-dimensional bytes not supported</span>

<span class="sd">        Note:</span>
<span class="sd">            1. To save the samples in order, set dataset&#39;s `shuffle` to ``False`` and `num_files` to ``1``.</span>
<span class="sd">            2. Before calling the function, do not use batch operation, repeat operation or data augmentation operations</span>
<span class="sd">               with random attribute in map operation.</span>
<span class="sd">            3. When array dimension is variable, one-dimensional arrays or</span>
<span class="sd">               multi-dimensional arrays with variable dimension 0 are supported.</span>
<span class="sd">            4. MindRecord does not support multi-dimensional string or multi-dimensional bytes.</span>

<span class="sd">        Args:</span>
<span class="sd">            file_name (str): Path to dataset file.</span>
<span class="sd">            num_files (int, optional): Number of dataset files. Default: ``1`` .</span>
<span class="sd">            file_type (str, optional): Dataset format. Default: ``&#39;mindrecord&#39;`` .</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; def generator_1d():</span>
<span class="sd">            ...     for i in range(10):</span>
<span class="sd">            ...         yield (np.array([i]),)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # apply dataset operations</span>
<span class="sd">            &gt;&gt;&gt; d1 = ds.GeneratorDataset(generator_1d, [&quot;data&quot;], shuffle=False)</span>
<span class="sd">            &gt;&gt;&gt; d1.save(&#39;/path/to/save_file&#39;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">_get_enc_key</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">_get_hash_mode</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_files</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;When encode mode or hash check is enabled, &quot;</span> <span class="o">+</span>
                               <span class="s2">&quot;the automatic sharding function is unavailable.&quot;</span><span class="p">)</span>

        <span class="n">ir_tree</span><span class="p">,</span> <span class="n">api_tree</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_ir_tree</span><span class="p">()</span>

        <span class="n">runtime_context</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">PythonRuntimeContext</span><span class="p">()</span>
        <span class="n">runtime_context</span><span class="o">.</span><span class="n">Init</span><span class="p">()</span>
        <span class="n">consumer</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">PythonSaveToDisk</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">num_files</span><span class="p">,</span> <span class="n">file_type</span><span class="p">)</span>
        <span class="n">consumer</span><span class="o">.</span><span class="n">Init</span><span class="p">(</span><span class="n">ir_tree</span><span class="p">)</span>
        <span class="n">runtime_context</span><span class="o">.</span><span class="n">AssignConsumer</span><span class="p">(</span><span class="n">consumer</span><span class="p">)</span>

        <span class="n">consumer</span><span class="o">.</span><span class="n">Save</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">_get_hash_mode</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">append_hash_to_file</span><span class="p">(</span><span class="n">file_name</span><span class="p">)</span>
            <span class="n">append_hash_to_file</span><span class="p">(</span><span class="n">file_name</span> <span class="o">+</span> <span class="s2">&quot;.db&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">_get_enc_key</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">encrypt</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">_get_enc_key</span><span class="p">(),</span> <span class="n">_get_enc_mode</span><span class="p">())</span>
            <span class="n">encrypt</span><span class="p">(</span><span class="n">file_name</span> <span class="o">+</span> <span class="s2">&quot;.db&quot;</span><span class="p">,</span> <span class="n">_get_enc_key</span><span class="p">(),</span> <span class="n">_get_enc_mode</span><span class="p">())</span>

        <span class="n">_set_dataset_permissions</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">num_files</span><span class="p">)</span>
        <span class="k">del</span> <span class="n">api_tree</span></div>

<div class="viewcode-block" id="Dataset.create_tuple_iterator"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/iterator/mindspore.dataset.Dataset.create_tuple_iterator.html#mindspore.dataset.Dataset.create_tuple_iterator">[docs]</a>    <span class="nd">@check_tuple_iterator</span>
    <span class="k">def</span> <span class="nf">create_tuple_iterator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">do_copy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create an iterator over the dataset. The datatype retrieved back will be a list of `numpy.ndarray` .</span>

<span class="sd">        To specify which columns to list and the order needed, use columns_list. If columns_list</span>
<span class="sd">        is not provided, the order of the columns will remain unchanged.</span>

<span class="sd">        Args:</span>
<span class="sd">            columns (list[str], optional): List of columns to be used to specify the order of columns.</span>
<span class="sd">                Default: ``None``, means all columns.</span>
<span class="sd">            num_epochs (int, optional): Maximum number of epochs that iterator can be iterated.</span>
<span class="sd">                Default: ``-1``, iterator can be iterated infinite number of epochs.</span>
<span class="sd">            output_numpy (bool, optional): Whether or not to output NumPy datatype.</span>
<span class="sd">                If `output_numpy` is ``False``, iterator will output MSTensor. Default: ``False``.</span>
<span class="sd">            do_copy (bool, optional): When output data type is :class:`mindspore.Tensor`,</span>
<span class="sd">                use this param to select the conversion method, only take False for better performance.</span>
<span class="sd">                Default: ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Iterator, a dataset iterator that returns data of type Tuple.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([i for i in range(10)], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; iterator = dataset.create_tuple_iterator()</span>
<span class="sd">            &gt;&gt;&gt; for item in iterator:</span>
<span class="sd">            ...     # item is a list</span>
<span class="sd">            ...     print(type(item))</span>
<span class="sd">            ...     break</span>
<span class="sd">            &lt;class &#39;list&#39;&gt;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">output_numpy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">output_numpy</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">_noop_mode</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">DummyIterator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;tuple&#39;</span><span class="p">,</span> <span class="n">output_numpy</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">TupleIterator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">output_numpy</span><span class="p">,</span> <span class="n">do_copy</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.create_dict_iterator"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/iterator/mindspore.dataset.Dataset.create_dict_iterator.html#mindspore.dataset.Dataset.create_dict_iterator">[docs]</a>    <span class="nd">@check_dict_iterator</span>
    <span class="k">def</span> <span class="nf">create_dict_iterator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">do_copy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create an iterator over the dataset. The data retrieved will be a dictionary datatype.</span>

<span class="sd">        Args:</span>
<span class="sd">            num_epochs (int, optional): Maximum number of epochs that iterator can be iterated.</span>
<span class="sd">                Default: ``-1`` , iterator can be iterated infinite number of epochs.</span>
<span class="sd">            output_numpy (bool, optional): Whether or not to output NumPy datatype,</span>
<span class="sd">                if `output_numpy` is ``False``, iterator will output MSTensor. Default: ``False`` .</span>
<span class="sd">            do_copy (bool, optional): When output data type is :class:`mindspore.Tensor`,</span>
<span class="sd">                use this param to select the conversion method, only take False for better performance.</span>
<span class="sd">                Default: ``True`` .</span>

<span class="sd">        Returns:</span>
<span class="sd">            Iterator, a dataset iterator that returns data of type Dict.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([i for i in range(10)], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; iterator = dataset.create_dict_iterator()</span>
<span class="sd">            &gt;&gt;&gt; for item in iterator:</span>
<span class="sd">            ...     # item is a dict</span>
<span class="sd">            ...     print(type(item))</span>
<span class="sd">            ...     break</span>
<span class="sd">            &lt;class &#39;dict&#39;&gt;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">output_numpy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">output_numpy</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">_noop_mode</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">DummyIterator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;dict&#39;</span><span class="p">,</span> <span class="n">output_numpy</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">DictIterator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">output_numpy</span><span class="p">,</span> <span class="n">do_copy</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create an iterator over the dataset.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_tuple_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">input_indexs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the column index, which represents the corresponding relationship between the data column order</span>
<span class="sd">        and the network when using the sink mode.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int, tuple of the input index information.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([i for i in range(10)], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; # set input_indexs</span>
<span class="sd">            &gt;&gt;&gt; dataset.input_indexs = 10</span>
<span class="sd">            &gt;&gt;&gt; print(dataset.input_indexs)</span>
<span class="sd">            10</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_indexs</span> <span class="o">!=</span> <span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_indexs</span>

        <span class="c1"># find input_indexes of children</span>
        <span class="n">children_input_index</span> <span class="o">=</span> <span class="p">[</span><span class="n">child</span><span class="o">.</span><span class="n">input_indexs</span> <span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">]</span>

        <span class="c1"># in case of more than one child, return the first input_indexes</span>
        <span class="k">for</span> <span class="n">cix</span> <span class="ow">in</span> <span class="n">children_input_index</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">cix</span> <span class="o">!=</span> <span class="p">():</span>
                <span class="k">return</span> <span class="n">cix</span>

        <span class="c1"># if all children&#39;s input_indexes are () or the node is a leaf</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_indexs</span>

    <span class="nd">@input_indexs</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">input_indexs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_indexs</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">def</span> <span class="nf">copy_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">def</span> <span class="nf">_init_tree_getters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">getter_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get pipeline information.</span>

<span class="sd">        Args:</span>
<span class="sd">            getter_mode (bool, optional): Whether to build IR tree in pull mode. Default: ``True``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ir_tree</span><span class="p">,</span> <span class="n">api_tree</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_ir_tree</span><span class="p">(</span><span class="n">getter_mode</span><span class="p">)</span>

        <span class="n">runtime_context</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">PythonRuntimeContext</span><span class="p">()</span>
        <span class="n">runtime_context</span><span class="o">.</span><span class="n">Init</span><span class="p">()</span>
        <span class="n">getter</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">TreeGetters</span><span class="p">()</span>
        <span class="n">getter</span><span class="o">.</span><span class="n">Init</span><span class="p">(</span><span class="n">ir_tree</span><span class="p">)</span>
        <span class="n">runtime_context</span><span class="o">.</span><span class="n">AssignConsumer</span><span class="p">(</span><span class="n">getter</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">getter</span><span class="p">,</span> <span class="n">runtime_context</span><span class="p">,</span> <span class="n">api_tree</span>

    <span class="k">def</span> <span class="nf">__init_size_getter</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get pipeline information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ir_tree</span><span class="p">,</span> <span class="n">api_tree</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_ir_tree</span><span class="p">()</span>

        <span class="n">runtime_context</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">PythonRuntimeContext</span><span class="p">()</span>
        <span class="n">runtime_context</span><span class="o">.</span><span class="n">Init</span><span class="p">()</span>
        <span class="n">getter</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">DatasetSizeGetters</span><span class="p">()</span>
        <span class="n">getter</span><span class="o">.</span><span class="n">Init</span><span class="p">(</span><span class="n">ir_tree</span><span class="p">)</span>
        <span class="n">runtime_context</span><span class="o">.</span><span class="n">AssignConsumer</span><span class="p">(</span><span class="n">getter</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">getter</span><span class="p">,</span> <span class="n">runtime_context</span><span class="p">,</span> <span class="n">api_tree</span>

<div class="viewcode-block" id="Dataset.get_col_names"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/attribute/mindspore.dataset.Dataset.get_col_names.html#mindspore.dataset.Dataset.get_col_names">[docs]</a>    <span class="k">def</span> <span class="nf">get_col_names</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the names of the columns in dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            list, list of column names in the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([i for i in range(10)], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; col_names = dataset.get_col_names()</span>
<span class="sd">            &gt;&gt;&gt; print(col_names)</span>
<span class="sd">            [&#39;column1&#39;]</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_col_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">runtime_getter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_tree_getters</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_col_names</span> <span class="o">=</span> <span class="n">runtime_getter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">GetColumnNames</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_col_names</span></div>

<div class="viewcode-block" id="Dataset.output_shapes"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/attribute/mindspore.dataset.Dataset.output_shapes.html#mindspore.dataset.Dataset.output_shapes">[docs]</a>    <span class="nd">@check_output_shape</span>
    <span class="k">def</span> <span class="nf">output_shapes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">estimate</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the shapes of output data.</span>

<span class="sd">        Args:</span>
<span class="sd">            estimate (bool): If `estimate` is ``False`` , will return the shapes of first data row.</span>
<span class="sd">                Otherwise, will iterate the whole dataset and return the estimated shapes of data row,</span>
<span class="sd">                where dynamic shape is marked as None (used in dynamic data shapes scenario).</span>
<span class="sd">                Default: ``False`` .</span>

<span class="sd">        Returns:</span>
<span class="sd">            list, list of shapes of each column.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; def generator1():</span>
<span class="sd">            ...     for i in range(1, 100):</span>
<span class="sd">            ...         yield np.ones((16, 83, 83)), np.array([i])</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset(generator1, [&quot;data1&quot;, &quot;data2&quot;])</span>
<span class="sd">            &gt;&gt;&gt; output_shapes = dataset.output_shapes()</span>
<span class="sd">            &gt;&gt;&gt; print(output_shapes)</span>
<span class="sd">            [[16, 83, 83], [1]]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># cache single shape</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">estimate</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">saved_output_shapes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">saved_output_shapes</span>
        <span class="c1"># cache estimate shape</span>
        <span class="k">if</span> <span class="n">estimate</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimated_output_shapes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimated_output_shapes</span>

        <span class="c1"># We have a hang problem when two-level pipeline with multiprocessing, we need to extend the life cycle</span>
        <span class="c1"># of runtime_context. We found this hang problem only occur on output_types and output_shapes.</span>
        <span class="n">runtime_getter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_tree_getters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">runtime_context</span> <span class="o">=</span> <span class="n">runtime_getter</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">api_tree</span> <span class="o">=</span> <span class="n">runtime_getter</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">output_shapes</span> <span class="o">=</span> <span class="n">runtime_getter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">GetOutputShapes</span><span class="p">(</span><span class="n">estimate</span><span class="p">)</span>
        <span class="k">del</span> <span class="n">api_tree</span>
        <span class="c1"># Need to terminate the runtime context to avoid the occasional hang problem for</span>
        <span class="c1"># Python (with multiprocessing enabled) in sink mode.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">runtime_context</span><span class="o">.</span><span class="n">Terminate</span><span class="p">()</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">runtime_context</span>

        <span class="k">if</span> <span class="n">estimate</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">estimated_output_shapes</span> <span class="o">=</span> <span class="n">output_shapes</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">saved_output_shapes</span> <span class="o">=</span> <span class="n">output_shapes</span>
        <span class="k">return</span> <span class="n">output_shapes</span></div>

<div class="viewcode-block" id="Dataset.output_types"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/attribute/mindspore.dataset.Dataset.output_types.html#mindspore.dataset.Dataset.output_types">[docs]</a>    <span class="k">def</span> <span class="nf">output_types</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the types of output data.</span>

<span class="sd">        Returns:</span>
<span class="sd">            list, list of data types.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; def generator1():</span>
<span class="sd">            ...     for i in range(1, 100):</span>
<span class="sd">            ...         yield np.ones((16, 83, 83)).astype(np.float32), np.array([i]).astype(np.int32)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset(generator1, [&quot;data1&quot;, &quot;data2&quot;])</span>
<span class="sd">            &gt;&gt;&gt; output_types = dataset.output_types()</span>
<span class="sd">            &gt;&gt;&gt; print(output_types)</span>
<span class="sd">            [dtype(&#39;float32&#39;), dtype(&#39;int32&#39;)]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">saved_output_types</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">runtime_getter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_tree_getters</span><span class="p">()</span>
            <span class="c1"># We have a hang problem when two-level pipeline with multiprocessing, we need to extend the life cycle</span>
            <span class="c1"># of runtime_context. We found this hang problem only occur on output_types and output_shapes.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">runtime_context</span> <span class="o">=</span> <span class="n">runtime_getter</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">api_tree</span> <span class="o">=</span> <span class="n">runtime_getter</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">saved_output_types</span> <span class="o">=</span> <span class="n">runtime_getter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">GetOutputTypes</span><span class="p">()</span>
            <span class="k">del</span> <span class="n">api_tree</span>
            <span class="c1"># Need to terminate the runtime context to avoid the occasional hang problem for</span>
            <span class="c1"># Python (with multiprocessing enabled) in sink mode.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">runtime_context</span><span class="o">.</span><span class="n">Terminate</span><span class="p">()</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">runtime_context</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">saved_output_types</span></div>

<div class="viewcode-block" id="Dataset.get_dataset_size"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/attribute/mindspore.dataset.Dataset.get_dataset_size.html#mindspore.dataset.Dataset.get_dataset_size">[docs]</a>    <span class="k">def</span> <span class="nf">get_dataset_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the number of batches in an epoch.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int, number of batches.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # A generator return 66 samples</span>
<span class="sd">            &gt;&gt;&gt; def generator1():</span>
<span class="sd">            ...     for i in range(66):</span>
<span class="sd">            ...         yield np.ones((16, 83, 83)), np.array([i])</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset(generator1, [&quot;data1&quot;, &quot;data2&quot;])</span>
<span class="sd">            &gt;&gt;&gt; dataset_size = dataset.get_dataset_size()</span>
<span class="sd">            &gt;&gt;&gt; print(dataset_size)</span>
<span class="sd">            66</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">runtime_getter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__init_size_getter</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dataset_size</span> <span class="o">=</span> <span class="n">runtime_getter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">GetDatasetSize</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Got 0 sample from dataset pipeline, check if drop all data or load dataset fail.&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_size</span></div>

<div class="viewcode-block" id="Dataset.num_classes"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/attribute/mindspore.dataset.Dataset.num_classes.html#mindspore.dataset.Dataset.num_classes">[docs]</a>    <span class="k">def</span> <span class="nf">num_classes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the number of classes in a dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int, number of classes.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; # Read image files</span>
<span class="sd">            &gt;&gt;&gt; image_folder_dataset_dir = &quot;/path/to/image_folder_dataset_directory&quot;</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.ImageFolderDataset(dataset_dir=image_folder_dataset_dir)</span>
<span class="sd">            &gt;&gt;&gt; # Check how many classes exist in image folder</span>
<span class="sd">            &gt;&gt;&gt; num_classes = dataset.num_classes()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_classes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">runtime_getter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_tree_getters</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_num_classes</span> <span class="o">=</span> <span class="n">runtime_getter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">GetNumClasses</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_classes</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_classes</span></div>

    <span class="k">def</span> <span class="nf">get_sync_notifiers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_sync_notifiers</span><span class="p">()</span>
        <span class="k">return</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">disable_sync</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">disable_sync</span><span class="p">()</span>
        <span class="k">return</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">is_sync</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">is_sync</span><span class="p">()</span>
        <span class="k">return</span> <span class="kc">False</span>

<div class="viewcode-block" id="Dataset.sync_update"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/others/mindspore.dataset.Dataset.sync_update.html#mindspore.dataset.Dataset.sync_update">[docs]</a>    <span class="k">def</span> <span class="nf">sync_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">condition_name</span><span class="p">,</span> <span class="n">num_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Release a blocking condition and trigger callback with given data.</span>

<span class="sd">        Args:</span>
<span class="sd">            condition_name (str): The condition name that is used to toggle sending next row.</span>
<span class="sd">            num_batch (Union[int, None]): The number of batches (rows) that are released.</span>
<span class="sd">                When `num_batch` is ``None``, it will default to the number specified by the</span>
<span class="sd">                `sync_wait` operation. Default: ``None``.</span>
<span class="sd">            data (Any): The data passed to the callback, user defined. Default: ``None``.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; def gen():</span>
<span class="sd">            ...     for i in range(100):</span>
<span class="sd">            ...         yield (np.array(i),)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; class Augment:</span>
<span class="sd">            ...     def __init__(self, loss):</span>
<span class="sd">            ...         self.loss = loss</span>
<span class="sd">            ...</span>
<span class="sd">            ...     def preprocess(self, input_):</span>
<span class="sd">            ...         return input_</span>
<span class="sd">            ...</span>
<span class="sd">            ...     def update(self, data):</span>
<span class="sd">            ...         self.loss = data[&quot;loss&quot;]</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; batch_size = 10</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset(gen, column_names=[&quot;input&quot;])</span>
<span class="sd">            &gt;&gt;&gt; aug = Augment(0)</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.sync_wait(condition_name=&#39;&#39;, num_batch=1)</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.map(input_columns=[&quot;input&quot;], operations=[aug.preprocess])</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.batch(batch_size)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; count = 0</span>
<span class="sd">            &gt;&gt;&gt; for data in dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">            ...     count += 1</span>
<span class="sd">            ...     data = {&quot;loss&quot;: count}</span>
<span class="sd">            ...     dataset.sync_update(condition_name=&quot;&quot;, data=data)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_batch</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_batch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> \
                <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">num_batch</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_batch</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">):</span>
            <span class="c1"># throwing exception, disable all sync_wait in pipeline</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">disable_sync</span><span class="p">()</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Sync_update batch size can only be positive integer, got : </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_batch</span><span class="p">))</span>
        <span class="n">notifiers_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_sync_notifiers</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">condition_name</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Argument condition_name with value </span><span class="si">{}</span><span class="s2"> is not of type str, but got </span><span class="si">{}</span><span class="s2">.&quot;</span>
                            <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">condition_name</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">condition_name</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">condition_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">notifiers_dict</span><span class="p">:</span>
            <span class="c1"># throwing exception, disable all sync_wait in pipeline</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">disable_sync</span><span class="p">()</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Condition name not found.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">num_batch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">num_batch</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_batch_size</span><span class="p">()</span>
        <span class="n">notifiers_dict</span><span class="p">[</span><span class="n">condition_name</span><span class="p">](</span><span class="n">num_batch</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span></div>

<div class="viewcode-block" id="Dataset.get_batch_size"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/attribute/mindspore.dataset.Dataset.get_batch_size.html#mindspore.dataset.Dataset.get_batch_size">[docs]</a>    <span class="k">def</span> <span class="nf">get_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the size of batch.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int, the batch size of data.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([i for i in range(10)], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.batch(2)</span>
<span class="sd">            &gt;&gt;&gt; batch_size = dataset.get_batch_size()</span>
<span class="sd">            &gt;&gt;&gt; print(batch_size)</span>
<span class="sd">            2</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">runtime_getter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_tree_getters</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">runtime_getter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">GetBatchSize</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span></div>

<div class="viewcode-block" id="Dataset.get_repeat_count"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/attribute/mindspore.dataset.Dataset.get_repeat_count.html#mindspore.dataset.Dataset.get_repeat_count">[docs]</a>    <span class="k">def</span> <span class="nf">get_repeat_count</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the replication times in RepeatDataset. Default: ``1`` .</span>

<span class="sd">        Returns:</span>
<span class="sd">            int, the count of repeat.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([i for i in range(10)], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.repeat(5)</span>
<span class="sd">            &gt;&gt;&gt; repeat_count = dataset.get_repeat_count()</span>
<span class="sd">            &gt;&gt;&gt; print(repeat_count)</span>
<span class="sd">            5</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repeat_count</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">runtime_getter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_tree_getters</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_repeat_count</span> <span class="o">=</span> <span class="n">runtime_getter</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">GetRepeatCount</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repeat_count</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_repeat_count</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repeat_count</span></div>

<div class="viewcode-block" id="Dataset.get_class_indexing"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/attribute/mindspore.dataset.Dataset.get_class_indexing.html#mindspore.dataset.Dataset.get_class_indexing">[docs]</a>    <span class="k">def</span> <span class="nf">get_class_indexing</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the mapping dictionary from category names to category indexes.</span>

<span class="sd">        This dictionary can be used to look up which category name corresponds to a particular category index.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dict[str, int], the mappings from category names to category indexes.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; # Read image files</span>
<span class="sd">            &gt;&gt;&gt; image_folder_dataset_dir = &quot;/path/to/image_folder_dataset_directory&quot;</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.ImageFolderDataset(dataset_dir=image_folder_dataset_dir)</span>
<span class="sd">            &gt;&gt;&gt; # Check how many classes exist in image folder</span>
<span class="sd">            &gt;&gt;&gt; class_indexing = dataset.get_class_indexing()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_class_indexing</span><span class="p">()</span>
        <span class="k">return</span> <span class="p">{}</span></div>

<div class="viewcode-block" id="Dataset.reset"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/operation/mindspore.dataset.Dataset.reset.html#mindspore.dataset.Dataset.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reset the dataset for next epoch.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; mind_dataset_dir = [&quot;/path/to/mind_dataset_file&quot;]</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.MindDataset(dataset_files=mind_dataset_dir)</span>
<span class="sd">            &gt;&gt;&gt; for _ in range(5):</span>
<span class="sd">            ...     num_iter = 0</span>
<span class="sd">            ...     for data in dataset.create_tuple_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">            ...         num_iter += 1</span>
<span class="sd">            ...     dataset.reset()</span>
<span class="sd">        &quot;&quot;&quot;</span></div>

    <span class="k">def</span> <span class="nf">is_shuffled</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns True if the dataset or its children is shuffled.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">input_dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">input_dataset</span><span class="o">.</span><span class="n">is_shuffled</span><span class="p">():</span>
                <span class="k">return</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">is_sharded</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns True if the dataset or its children is sharded.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">input_dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">input_dataset</span><span class="o">.</span><span class="n">is_sharded</span><span class="p">():</span>
                <span class="k">return</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Dataset has to implement parse method.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the length of dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int, the length of dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_update_data_shard</span><span class="p">(</span><span class="n">num_shards</span><span class="p">,</span> <span class="n">shard_id</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update the shard number and shard id if necessary.</span>
<span class="sd">        This is normally used in distributed training mode like Parameter Server training.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># If this is in distributed execution mode,</span>
        <span class="c1"># the shard number and shard id might need to be updated according to the process&#39;s rank or role.</span>
        <span class="n">worker_num</span> <span class="o">=</span> <span class="n">_get_ps_context</span><span class="p">(</span><span class="s2">&quot;worker_num&quot;</span><span class="p">)</span>
        <span class="n">server_num</span> <span class="o">=</span> <span class="n">_get_ps_context</span><span class="p">(</span><span class="s2">&quot;server_num&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">_is_role_pserver</span><span class="p">()</span> <span class="ow">and</span> <span class="n">_enable_distributed_mindrt</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="n">worker_num</span> <span class="o">!=</span> <span class="n">server_num</span><span class="p">):</span>
            <span class="n">num_shards</span> <span class="o">=</span> <span class="n">worker_num</span>
            <span class="n">shard_id</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">num_shards</span><span class="p">,</span> <span class="n">shard_id</span>

    <span class="k">def</span> <span class="nf">pre_parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">getter_mode</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">getter_mode</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;python_multiprocessing&quot;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">python_multiprocessing</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;num_parallel_workers&quot;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">post_parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ir_node</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">:</span>
            <span class="n">ir_node</span> <span class="o">=</span> <span class="n">ir_node</span><span class="o">.</span><span class="n">set_cache_client</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="o">.</span><span class="n">cache_client</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span><span class="p">:</span>
            <span class="n">ir_node</span> <span class="o">=</span> <span class="n">ir_node</span><span class="o">.</span><span class="n">set_num_workers</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ir_node</span>

    <span class="k">def</span> <span class="nf">set_init_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_step</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_global_step</span> <span class="o">=</span> <span class="n">init_step</span>

    <span class="k">def</span> <span class="nf">get_init_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_step</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_step</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_init_step</span><span class="p">()</span>
        <span class="c1"># When there are multiple children, we cannot tell from which child to get the initial step,</span>
        <span class="c1"># so we initialize from the beginning</span>
        <span class="k">return</span> <span class="mi">0</span>


<span class="k">class</span> <span class="nc">VisionBaseDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract class to represent a vision source dataset which produces content to the data pipeline.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">children</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="n">cache</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Dataset has to implement parse method.&quot;</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">TextBaseDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract class to represent a text source dataset which produces content to the data pipeline.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">children</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="n">cache</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Dataset has to implement parse method.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">build_vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">freq_range</span><span class="p">,</span> <span class="n">top_k</span><span class="p">,</span> <span class="n">special_tokens</span><span class="p">,</span> <span class="n">special_first</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to create a Vocab from source dataset.</span>
<span class="sd">        Desired source dataset is a text type dataset.</span>

<span class="sd">        Build a vocab from a dataset. This would collect all the unique words in a dataset and return a vocab</span>
<span class="sd">        which contains top_k most frequent words (if top_k is specified).</span>

<span class="sd">        Note:</span>
<span class="sd">            mindspore.dataset.Dataset.build_vocab is deprecated from version 2.0</span>
<span class="sd">            and will be removed in a future version. Use mindspore.dataset.text.Vocab.from_dataset instead.</span>

<span class="sd">        Args:</span>
<span class="sd">            columns(Union[str, list[str]]): Column names to get words from.</span>
<span class="sd">            freq_range(tuple[int]): A tuple of integers (min_frequency, max_frequency). Words within the frequency</span>
<span class="sd">                range will be stored.</span>
<span class="sd">                Naturally 0 &lt;= min_frequency &lt;= max_frequency &lt;= total_words. min_frequency/max_frequency</span>
<span class="sd">                can be set to default, which corresponds to 0/total_words separately.</span>
<span class="sd">            top_k(int): Number of words to be built into vocab. top_k most frequent words are</span>
<span class="sd">                taken. The top_k is taken after freq_range. If not enough top_k, all words will be taken</span>
<span class="sd">            special_tokens(list[str]): A list of strings, each one is a special token.</span>
<span class="sd">            special_first(bool): Whether special_tokens will be prepended/appended to vocab, If special_tokens</span>
<span class="sd">                is specified and special_first is set to default, special_tokens will be prepended.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Vocab, vocab built from the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;mindspore.dataset.Dataset.build_vocab is deprecated from version 2.0 &quot;</span>
                      <span class="s2">&quot;and will be removed in a future version. &quot;</span>
                      <span class="s2">&quot;Use mindspore.dataset.text.Vocab.from_dataset instead.&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">build_sentencepiece_vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">character_coverage</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to create a SentencePieceVocab from source dataset.</span>
<span class="sd">        Desired source dataset is a text type dataset.</span>

<span class="sd">        Note:</span>
<span class="sd">            mindspore.dataset.Dataset.build_sentencepiece_vocab is deprecated from version 2.0</span>
<span class="sd">            and will be removed in a future version. Use mindspore.dataset.text.SentencePieceVocab.from_dataset instead.</span>

<span class="sd">        Args:</span>
<span class="sd">            columns(list[str]): Column names to get words from.</span>
<span class="sd">            vocab_size(int): Vocabulary size.</span>
<span class="sd">            character_coverage(float): Percentage of characters covered by the model, must be between</span>
<span class="sd">                0.98 and 1.0 Good defaults are: 0.9995 for languages with rich character sets like</span>
<span class="sd">                Japanese or Chinese character sets, and 1.0 for other languages with small character sets</span>
<span class="sd">                like English or Latin.</span>
<span class="sd">            model_type(SentencePieceModel): Model type. Choose from unigram (default), bpe, char, or word.</span>
<span class="sd">                The input sentence must be pretokenized when using word type.</span>
<span class="sd">            params(dict): Any extra optional parameters of sentencepiece library according to your raw data</span>

<span class="sd">        Returns:</span>
<span class="sd">            SentencePieceVocab, vocab built from the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;mindspore.dataset.Dataset.build_sentencepiece_vocab is deprecated from version 2.0 &quot;</span>
                      <span class="s2">&quot;and will be removed in a future version. &quot;</span>
                      <span class="s2">&quot;Use mindspore.dataset.text.SentencePieceVocab.from_dataset instead.&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_build_vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">freq_range</span><span class="p">,</span> <span class="n">top_k</span><span class="p">,</span> <span class="n">special_tokens</span><span class="p">,</span> <span class="n">special_first</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to create a Vocab from source dataset.</span>
<span class="sd">        Desired source dataset is a text type dataset.</span>

<span class="sd">        Build a vocab from a dataset. This would collect all the unique words in a dataset and return a vocab</span>
<span class="sd">        which contains top_k most frequent words (if top_k is specified).</span>

<span class="sd">        Args:</span>
<span class="sd">            columns(Union[str, list[str]]): Column names to get words from.</span>
<span class="sd">            freq_range(tuple[int]): A tuple of integers (min_frequency, max_frequency). Words within the frequency</span>
<span class="sd">                range will be stored.</span>
<span class="sd">                Naturally 0 &lt;= min_frequency &lt;= max_frequency &lt;= total_words. min_frequency/max_frequency</span>
<span class="sd">                can be set to default, which corresponds to 0/total_words separately.</span>
<span class="sd">            top_k(int): Number of words to be built into vocab. top_k most frequent words are</span>
<span class="sd">                taken. The top_k is taken after freq_range. If not enough top_k, all words will be taken</span>
<span class="sd">            special_tokens(list[str]): A list of strings, each one is a special token.</span>
<span class="sd">            special_first(bool): Whether special_tokens will be prepended/appended to vocab, If special_tokens</span>
<span class="sd">                is specified and special_first is set to default, special_tokens will be prepended.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Vocab, vocab built from the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">Vocab</span><span class="p">()</span>
        <span class="n">columns</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="p">[])</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">columns</span><span class="p">]</span>

        <span class="n">freq_range</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">freq_range</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">9223372036854775807</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">freq_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">freq_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">freq_range</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">freq_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">freq_range</span> <span class="o">=</span> <span class="p">(</span><span class="n">freq_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">9223372036854775807</span><span class="p">)</span>
        <span class="n">special_tokens</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">special_tokens</span><span class="p">,</span> <span class="p">[])</span>
        <span class="n">top_k</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">top_k</span><span class="p">,</span> <span class="mi">9223372036854775807</span><span class="p">)</span>

        <span class="n">ir_tree</span><span class="p">,</span> <span class="n">api_tree</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_ir_tree</span><span class="p">()</span>

        <span class="c1"># vocab node</span>
        <span class="n">vocab_node</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">BuildVocabNode</span><span class="p">(</span><span class="n">ir_tree</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">freq_range</span><span class="p">,</span> <span class="n">top_k</span><span class="p">,</span> <span class="n">special_tokens</span><span class="p">,</span> <span class="n">special_first</span><span class="p">)</span>

        <span class="n">runtime_context</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">PythonRuntimeContext</span><span class="p">()</span>
        <span class="n">runtime_context</span><span class="o">.</span><span class="n">Init</span><span class="p">()</span>

        <span class="c1"># build vocab</span>
        <span class="n">consumer</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">PythonBuildVocabConsumer</span><span class="p">()</span>
        <span class="n">consumer</span><span class="o">.</span><span class="n">Init</span><span class="p">(</span><span class="n">vocab_node</span><span class="p">)</span>
        <span class="n">runtime_context</span><span class="o">.</span><span class="n">AssignConsumer</span><span class="p">(</span><span class="n">consumer</span><span class="p">)</span>

        <span class="n">consumer</span><span class="o">.</span><span class="n">Start</span><span class="p">()</span>
        <span class="k">del</span> <span class="n">api_tree</span>

        <span class="k">return</span> <span class="n">vocab</span>

    <span class="k">def</span> <span class="nf">_build_sentencepiece_vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">character_coverage</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to create a SentencePieceVocab from source dataset.</span>
<span class="sd">        Desired source dataset is a text type dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            columns(list[str]): Column names to get words from.</span>
<span class="sd">            vocab_size(int): Vocabulary size.</span>
<span class="sd">            character_coverage(float): Percentage of characters covered by the model, must be between</span>
<span class="sd">                0.98 and 1.0 Good defaults are: 0.9995 for languages with rich character sets like</span>
<span class="sd">                Japanese or Chinese character sets, and 1.0 for other languages with small character sets</span>
<span class="sd">                like English or Latin.</span>
<span class="sd">            model_type(SentencePieceModel): Model type. Choose from unigram (default), bpe, char, or word.</span>
<span class="sd">                The input sentence must be pretokenized when using word type.</span>
<span class="sd">            params(dict): Any extra optional parameters of sentencepiece library according to your raw data</span>

<span class="sd">        Returns:</span>
<span class="sd">            SentencePieceVocab, vocab built from the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model_type</span><span class="p">,</span> <span class="n">SentencePieceModel</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Argument model_type with value </span><span class="si">{0}</span><span class="s2"> is not of type SentencePieceModel, but got </span><span class="si">{1}</span><span class="s2">.&quot;</span> \
                            <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model_type</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">model_type</span><span class="p">)))</span>
        <span class="n">model_type</span> <span class="o">=</span> <span class="n">DE_C_INTER_SENTENCEPIECE_MODE</span><span class="p">[</span><span class="n">model_type</span><span class="p">]</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">SentencePieceVocab</span><span class="p">()</span>

        <span class="n">ir_tree</span><span class="p">,</span> <span class="n">api_tree</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_ir_tree</span><span class="p">()</span>

        <span class="c1"># vocab node</span>
        <span class="n">vocab_node</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">BuildSentenceVocabNode</span><span class="p">(</span><span class="n">ir_tree</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">character_coverage</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span>
                                                <span class="n">params</span><span class="p">)</span>

        <span class="n">runtime_context</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">PythonRuntimeContext</span><span class="p">()</span>
        <span class="n">runtime_context</span><span class="o">.</span><span class="n">Init</span><span class="p">()</span>

        <span class="c1"># build vocab</span>
        <span class="n">consumer</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">PythonBuildVocabConsumer</span><span class="p">()</span>
        <span class="n">consumer</span><span class="o">.</span><span class="n">Init</span><span class="p">(</span><span class="n">vocab_node</span><span class="p">)</span>
        <span class="n">runtime_context</span><span class="o">.</span><span class="n">AssignConsumer</span><span class="p">(</span><span class="n">consumer</span><span class="p">)</span>

        <span class="n">consumer</span><span class="o">.</span><span class="n">Start</span><span class="p">()</span>
        <span class="k">del</span> <span class="n">api_tree</span>

        <span class="k">return</span> <span class="n">vocab</span>


<span class="k">class</span> <span class="nc">AudioBaseDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract class to represent a audio source dataset which produces content to the data pipeline.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">children</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="n">cache</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Dataset has to implement parse method.&quot;</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">UnionBaseDataset</span><span class="p">(</span><span class="n">VisionBaseDataset</span><span class="p">,</span> <span class="n">TextBaseDataset</span><span class="p">,</span> <span class="n">AudioBaseDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract class to represent a union source dataset which produces content to the data pipeline.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">children</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="n">cache</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Dataset has to implement parse method.&quot;</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">SourceDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract class to represent a source dataset which produces content to the data pipeline.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">cache</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="n">cache</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_shards</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">num_shards</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shard_id</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">shard_id</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">shuffle</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shuffle</span><span class="p">,</span> <span class="p">(</span><span class="nb">bool</span><span class="p">,</span> <span class="n">Shuffle</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;shuffle must be of boolean or enum of &#39;Shuffle&#39; values like &#39;Shuffle.GLOBAL&#39; or &quot;</span>
                            <span class="s2">&quot;&#39;Shuffle.FILES&#39; or &#39;Shuffle.INFILE&#39;.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">shuffle_flag</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Global shuffle</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shuffle</span><span class="p">,</span> <span class="n">Shuffle</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">shuffle</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">shuffle</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">shuffle_flag</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Global shuffle</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">shuffle_flag</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># No shuffle</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">shuffle</span> <span class="o">==</span> <span class="n">Shuffle</span><span class="o">.</span><span class="n">GLOBAL</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">shuffle_flag</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Global shuffle</span>
            <span class="k">elif</span> <span class="n">shuffle</span> <span class="o">==</span> <span class="n">Shuffle</span><span class="o">.</span><span class="n">FILES</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">shuffle_flag</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Files shuffle</span>
            <span class="k">elif</span> <span class="n">shuffle</span> <span class="o">==</span> <span class="n">Shuffle</span><span class="o">.</span><span class="n">INFILE</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">shuffle_flag</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># Infile shuffle</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Dataset has to implement parse method.&quot;</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_find_files</span><span class="p">(</span><span class="n">patterns</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Utility function to search for files with the given glob patterns.</span>

<span class="sd">        Args:</span>
<span class="sd">            patterns (Union[str, list[str]]): String or list of patterns to be searched.</span>

<span class="sd">        Returns:</span>
<span class="sd">            list, list of files.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">patterns</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">patterns</span> <span class="o">=</span> <span class="p">[</span><span class="n">patterns</span><span class="p">]</span>

        <span class="n">file_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">unmatched_patterns</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">pattern</span> <span class="ow">in</span> <span class="n">patterns</span><span class="p">:</span>
            <span class="n">matches</span> <span class="o">=</span> <span class="p">[</span><span class="n">match</span> <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">recursive</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">match</span><span class="p">)]</span>

            <span class="k">if</span> <span class="n">matches</span><span class="p">:</span>
                <span class="n">file_list</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">matches</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">unmatched_patterns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">unmatched_patterns</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The following patterns did not match any files: </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">unmatched_patterns</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">file_list</span><span class="p">:</span>  <span class="c1"># not empty</span>
            <span class="k">return</span> <span class="n">file_list</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The list of path names matching the patterns is empty.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">is_shuffled</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle_flag</span> <span class="o">&gt;</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">is_sharded</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_shards</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_shards</span> <span class="o">&gt;</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="kc">False</span>


<span class="k">class</span> <span class="nc">MappableDataset</span><span class="p">(</span><span class="n">SourceDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract class to represent a source dataset which supports use of samplers.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Dataset has to implement parse method.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">shard_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">num_shards</span><span class="p">,</span> <span class="n">shard_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_data_shard</span><span class="p">(</span><span class="n">num_shards</span><span class="p">,</span> <span class="n">shard_id</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
                         <span class="n">num_shards</span><span class="o">=</span><span class="n">num_shards</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="n">shard_id</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="n">cache</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shuffle_flag</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">shuffle</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span> <span class="o">=</span> <span class="n">samplers</span><span class="o">.</span><span class="n">select_sampler</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">sampler</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">,</span> <span class="n">num_shards</span><span class="p">,</span> <span class="n">shard_id</span><span class="p">)</span>

<div class="viewcode-block" id="MappableDataset.add_sampler"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/sampler/mindspore.dataset.MappableDataset.add_sampler.html#mindspore.dataset.MappableDataset.add_sampler">[docs]</a>    <span class="k">def</span> <span class="nf">add_sampler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_sampler</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a child sampler for the current dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            new_sampler (Sampler): The child sampler to be added.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([i for i in range(10)], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; new_sampler = ds.DistributedSampler(10, 2)</span>
<span class="sd">            &gt;&gt;&gt; dataset.add_sampler(new_sampler)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Note: By adding a sampler, the sampled IDs will flow to the new_sampler</span>
        <span class="c1"># after first passing through the current samplers attached to this dataset.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_size</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">new_sampler</span><span class="o">.</span><span class="n">add_child</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span> <span class="o">=</span> <span class="n">new_sampler</span></div>

<div class="viewcode-block" id="MappableDataset.use_sampler"><a class="viewcode-back" href="../../../../api_python/dataset/dataset_method/sampler/mindspore.dataset.MappableDataset.use_sampler.html#mindspore.dataset.MappableDataset.use_sampler">[docs]</a>    <span class="k">def</span> <span class="nf">use_sampler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_sampler</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Replace the last child sampler of the current dataset, remaining the parent sampler unchanged.</span>

<span class="sd">        Args:</span>
<span class="sd">            new_sampler (Sampler): The new sampler to replace with.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([i for i in range(10)], &quot;column1&quot;)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # use a DistributedSampler instead</span>
<span class="sd">            &gt;&gt;&gt; new_sampler = ds.DistributedSampler(10, 2)</span>
<span class="sd">            &gt;&gt;&gt; dataset.use_sampler(new_sampler)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">new_sampler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Input sampler can not be None.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_sampler</span><span class="p">,</span> <span class="p">(</span><span class="n">samplers</span><span class="o">.</span><span class="n">BuiltinSampler</span><span class="p">,</span> <span class="n">samplers</span><span class="o">.</span><span class="n">Sampler</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Input sampler is not an instance of a sampler.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_size</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">child_sampler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_sampler</span><span class="p">(</span><span class="n">new_sampler</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">is_shuffled</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">is_shuffled</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">is_sharded</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">is_sharded</span><span class="p">()</span>

    <span class="nd">@check_split</span>
    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sizes</span><span class="p">,</span> <span class="n">randomize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Split the dataset into smaller, non-overlapping datasets.</span>

<span class="sd">        Args:</span>
<span class="sd">            sizes (Union[list[int], list[float]]): If a list of integers [s1, s2, …, sn] is</span>
<span class="sd">                provided, the dataset will be split into n datasets of size s1, size s2, …, size sn</span>
<span class="sd">                respectively. If the sum of all sizes does not equal the original dataset size, an</span>
<span class="sd">                error will occur.</span>
<span class="sd">                If a list of floats [f1, f2, …, fn] is provided, all floats must be between 0 and 1</span>
<span class="sd">                and must sum to 1, otherwise an error will occur. The dataset will be split into n</span>
<span class="sd">                Datasets of size round(f1*K), round(f2*K), …, round(fn*K) where K is the size of the</span>
<span class="sd">                original dataset.</span>
<span class="sd">                If after rounding:</span>

<span class="sd">                - Any size equals 0, an error will occur.</span>
<span class="sd">                - The sum of split sizes &lt; K, the difference will be added to the first split.</span>
<span class="sd">                - The sum of split sizes &gt; K, the difference will be removed from the first large</span>
<span class="sd">                  enough split such that it will have at least 1 row after removing the difference.</span>

<span class="sd">            randomize (bool, optional): Determines whether or not to split the data randomly. Default: ``True``.</span>
<span class="sd">                If ``True``, the data will be randomly split. Otherwise, each split will be created with</span>
<span class="sd">                consecutive rows from the dataset.</span>

<span class="sd">        Note:</span>
<span class="sd">            1. There is an optimized split function, which will be called automatically when the dataset</span>
<span class="sd">               that calls this function is a MappableDataset.</span>
<span class="sd">            2. Dataset should not be sharded if split is going to be called. Instead, create a</span>
<span class="sd">               :class:`mindspore.dataset.DistributedSampler` and specify a split to shard after splitting.</span>
<span class="sd">               If the dataset is sharded after a split, it is strongly recommended setting the same</span>
<span class="sd">               seed in each instance of execution, otherwise each shard may not be part of the same</span>
<span class="sd">               split (see Examples).</span>
<span class="sd">            3. It is strongly recommended to not shuffle the dataset, but set `randomize` to ``True`` instead.</span>
<span class="sd">               Shuffling the dataset may not be deterministic, which means the data in each split</span>
<span class="sd">               will be different in each epoch. Furthermore, if sharding occurs after split, each</span>
<span class="sd">               shard may not be part of the same split.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[Dataset], a tuple of new datasets split from the original one.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: If get_dataset_size returns None or is not supported for this dataset.</span>
<span class="sd">            RuntimeError: If `sizes` is list of integers and sum of all elements in sizes does not</span>
<span class="sd">                equal the dataset size.</span>
<span class="sd">            RuntimeError: If `sizes` is list of float and there is a split with size 0 after calculations.</span>
<span class="sd">            RuntimeError: If the dataset is sharded prior to calling split.</span>
<span class="sd">            ValueError: If `sizes` is list of float and not all floats are between 0 and 1, or if the</span>
<span class="sd">                floats don&#39;t sum to 1.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; # Since many datasets have shuffle on by default, set shuffle to False if split will be called!</span>
<span class="sd">            &gt;&gt;&gt; image_folder_dataset_dir = &quot;/path/to/image_folder_dataset_directory&quot;</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.ImageFolderDataset(image_folder_dataset_dir, shuffle=False)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Set the seed, and tell split to use this seed when randomizing.</span>
<span class="sd">            &gt;&gt;&gt; # This is needed because sharding will be done later</span>
<span class="sd">            &gt;&gt;&gt; ds.config.set_seed(58)</span>
<span class="sd">            &gt;&gt;&gt; train_dataset, test_dataset = dataset.split([0.9, 0.1])</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # To shard the train dataset, use a DistributedSampler</span>
<span class="sd">            &gt;&gt;&gt; train_sampler = ds.DistributedSampler(10, 2)</span>
<span class="sd">            &gt;&gt;&gt; train_dataset.use_sampler(train_sampler)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_shuffled</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Dataset is shuffled before split.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_sharded</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Dataset should not be sharded before split.&quot;</span><span class="p">)</span>

        <span class="n">absolute_sizes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_absolute_split_sizes</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
        <span class="n">splits</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">current_split_start_index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">absolute_sizes</span><span class="p">:</span>
            <span class="n">ds</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="n">ds</span><span class="o">.</span><span class="n">dataset_size</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">randomize</span><span class="p">:</span>
                <span class="c1"># want to shuffle the same way every epoch before split, we are assuming</span>
                <span class="c1"># that the user will call set_seed</span>
                <span class="n">random_sampler</span> <span class="o">=</span> <span class="n">samplers</span><span class="o">.</span><span class="n">RandomSampler</span><span class="p">()</span>
                <span class="n">random_sampler</span><span class="o">.</span><span class="n">reshuffle_each_epoch</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">ds</span><span class="o">.</span><span class="n">add_sampler</span><span class="p">(</span><span class="n">random_sampler</span><span class="p">)</span>

            <span class="n">subset_sampler</span> <span class="o">=</span> <span class="n">samplers</span><span class="o">.</span><span class="n">SequentialSampler</span><span class="p">(</span><span class="n">current_split_start_index</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
            <span class="n">ds</span><span class="o">.</span><span class="n">add_sampler</span><span class="p">(</span><span class="n">subset_sampler</span><span class="p">)</span>

            <span class="c1"># add sequential sampler, so that if user calls use_sampler, we will</span>
            <span class="c1"># get rid of the sequential sampler instead of something we need</span>
            <span class="n">ds</span><span class="o">.</span><span class="n">add_sampler</span><span class="p">(</span><span class="n">samplers</span><span class="o">.</span><span class="n">SequentialSampler</span><span class="p">())</span>

            <span class="n">splits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>

            <span class="n">current_split_start_index</span> <span class="o">+=</span> <span class="n">size</span>

        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">splits</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">BucketBatchByLengthDataset</span><span class="p">(</span><span class="n">UnionBaseDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The result of applying BucketBatchByLength operation to the input dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dataset</span><span class="p">,</span> <span class="n">column_names</span><span class="p">,</span> <span class="n">bucket_boundaries</span><span class="p">,</span> <span class="n">bucket_batch_sizes</span><span class="p">,</span> <span class="n">element_length_function</span><span class="p">,</span>
                 <span class="n">pad_info</span><span class="p">,</span> <span class="n">pad_to_bucket_boundary</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">input_dataset</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span> <span class="o">=</span> <span class="n">to_list</span><span class="p">(</span><span class="n">column_names</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bucket_boundaries</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">bucket_boundaries</span><span class="p">,</span> <span class="p">[])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bucket_batch_sizes</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">bucket_batch_sizes</span><span class="p">,</span> <span class="p">[])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">element_length_function</span> <span class="o">=</span> <span class="n">element_length_function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_info</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">pad_info</span><span class="p">,</span> <span class="p">{})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_to_bucket_boundary</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">pad_to_bucket_boundary</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop_remainder</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">drop_remainder</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">BucketBatchByLengthNode</span><span class="p">(</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">column_names</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bucket_boundaries</span><span class="p">,</span>
                                           <span class="bp">self</span><span class="o">.</span><span class="n">bucket_batch_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">element_length_function</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_info</span><span class="p">,</span>
                                           <span class="bp">self</span><span class="o">.</span><span class="n">pad_to_bucket_boundary</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_remainder</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_check_shm_usage</span><span class="p">(</span><span class="n">num_worker</span><span class="p">,</span> <span class="n">queue_size</span><span class="p">,</span> <span class="n">in_rowsize</span><span class="p">,</span> <span class="n">out_rowsize</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check sufficient shared memory is available for shared memory queues</span>
<span class="sd">    when training in parallel mode.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">threshold_ratio</span> <span class="o">=</span> <span class="mf">0.8</span>
    <span class="k">if</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;windows&quot;</span><span class="p">,</span> <span class="s2">&quot;darwin&quot;</span><span class="p">}:</span>
        <span class="n">device_num</span> <span class="o">=</span> <span class="n">_get_device_num</span><span class="p">()</span>
        <span class="c1"># In the cluster, _get_device_num indicates the number of the entire cluster. The maximum number of cards</span>
        <span class="c1"># on the ascend server is 8.</span>
        <span class="k">if</span> <span class="n">device_num</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">device_num</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">device_num</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
        <span class="n">shm_estimate_usage</span> <span class="o">=</span> <span class="n">device_num</span> <span class="o">*</span> <span class="n">num_worker</span> <span class="o">*</span> \
                             <span class="p">(</span><span class="n">queue_size</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">in_rowsize</span> <span class="o">+</span> <span class="n">out_rowsize</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">shm_available</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">disk_usage</span><span class="p">(</span><span class="s1">&#39;/dev/shm&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">free</span>
            <span class="k">if</span> <span class="n">shm_estimate_usage</span> <span class="o">&gt;=</span> <span class="n">threshold_ratio</span> <span class="o">*</span> <span class="n">shm_available</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Insufficient shared memory available. Required: </span><span class="si">{}</span><span class="s2">, Available: </span><span class="si">{}</span><span class="s2">. &quot;</span>
                    <span class="s2">&quot;The required memory can&#39;t exceed 80</span><span class="si">% o</span><span class="s2">f the available shared memory, &quot;</span>
                    <span class="s2">&quot;it&#39;s recommended to reduce memory usage by following methods:</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;1. reduce value of parameter max_rowsize or num_parallel_workers.</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;2. reduce prefetch size by set_prefetch_size().</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;3. disable shared memory by set_enable_shared_mem().&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">shm_estimate_usage</span><span class="p">,</span> <span class="n">shm_available</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">FileNotFoundError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Expected /dev/shm to exist.&quot;</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">BatchDataset</span><span class="p">(</span><span class="n">UnionBaseDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The result of applying Batch operation to the input dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_dataset (Dataset): Input Dataset to be batched.</span>
<span class="sd">        batch_size (Union[int, function]): The number of rows each batch is created with. An</span>
<span class="sd">            int or callable which takes exactly 1 parameter, BatchInfo.</span>
<span class="sd">        drop_remainder (bool, optional): Determines whether or not to drop the last</span>
<span class="sd">            possibly incomplete batch. Default: ``False``. If True, and if there are less</span>
<span class="sd">            than batch_size rows available to make the last batch, then those rows will</span>
<span class="sd">            be dropped and not propagated to the child node.</span>
<span class="sd">        num_parallel_workers (int, optional): Number of workers to process the dataset in parallel. Default: ``None``.</span>
<span class="sd">        per_batch_map (callable, optional): Per batch map callable. A callable which takes</span>
<span class="sd">            (list[Tensor], list[Tensor], ..., BatchInfo) as input parameters. Each list[Tensor] represents a batch of</span>
<span class="sd">            Tensors on a given column. The number of lists should match with number of entries in input_columns. The</span>
<span class="sd">            last parameter of the callable must always be a BatchInfo object.</span>
<span class="sd">        input_columns (Union[str, list[str]], optional): List of names of the input columns. The size of the list must</span>
<span class="sd">            match with signature of per_batch_map callable.</span>
<span class="sd">        output_columns (Union[str, list[str]], optional): List of names assigned to the columns outputted by</span>
<span class="sd">            the last operation. This parameter is mandatory if len(input_columns) !=</span>
<span class="sd">            len(output_columns). The size of this list must match the number of output</span>
<span class="sd">            columns of the last operation. Default: ``None``, output columns will have the same</span>
<span class="sd">            name as the input columns, i.e., the columns will be replaced.</span>
<span class="sd">        max_rowsize(Union[int, list[int]], optional): Maximum size of row in MB that is used for shared memory</span>
<span class="sd">            allocation to copy data between processes, the total occupied shared memory will increase as</span>
<span class="sd">            ``num_parallel_workers`` and :func:`mindspore.dataset.config.set_prefetch_size` increase. This is only</span>
<span class="sd">            used if python_multiprocessing is set to True. If it is an int value, it represents</span>
<span class="sd">            ``input_columns`` and ``output_columns`` use this value as the unit to create shared memory.</span>
<span class="sd">            If it is a list, the first element represents the ``input_columns`` use this value as the unit to</span>
<span class="sd">            create shared memory, and the second element represents ``output_columns`` use this value as the unit</span>
<span class="sd">            to create shared memory. Default: 16.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">per_batch_map</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">input_columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">python_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_rowsize</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">input_dataset</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">BatchDataset</span><span class="o">.</span><span class="n">_is_ancestor_of_repeat</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Repeat is located before batch, data from two epochs can be batched together.&quot;</span><span class="p">)</span>

        <span class="n">BatchDataset</span><span class="o">.</span><span class="n">_update_batch_size_for_syncwait</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

        <span class="c1"># if batch_size is callable, set batch_size to 1 and batch_size_func to that callable function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size_func</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="k">else</span> <span class="n">batch_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">drop_remainder</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">drop_remainder</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">per_batch_map</span> <span class="o">=</span> <span class="n">per_batch_map</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_columns</span> <span class="o">=</span> <span class="n">to_list</span><span class="p">(</span><span class="n">input_columns</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_columns</span> <span class="o">=</span> <span class="n">to_list</span><span class="p">(</span><span class="n">output_columns</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">python_multiprocessing</span> <span class="o">=</span> <span class="n">python_multiprocessing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">process_pool</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">max_rowsize</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">max_rowsize</span> <span class="o">=</span> <span class="p">[</span><span class="n">max_rowsize</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">max_rowsize</span> <span class="o">=</span> <span class="p">[</span><span class="n">max_rowsize</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_rowsize</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;process_pool&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_pool</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">process_pool</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_pool</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">BatchNode</span><span class="p">(</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_remainder</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_columns</span><span class="p">,</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">output_columns</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size_func</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">per_batch_map</span><span class="p">,</span> <span class="p">{},</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">process_pool</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_is_ancestor_of_repeat</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Utility function to find the case where repeat is used before batch.</span>

<span class="sd">        Args:</span>
<span class="sd">             dataset (Dataset): Dataset to be checked.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool, whether repeat is used before batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">RepeatDataset</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="n">flag</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">input_dataset</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
            <span class="n">flag</span> <span class="o">=</span> <span class="n">flag</span> <span class="o">|</span> <span class="n">BatchDataset</span><span class="o">.</span><span class="n">_is_ancestor_of_repeat</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">flag</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_update_batch_size_for_syncwait</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Utility function to notify batch size to sync_wait.</span>

<span class="sd">        Args:</span>
<span class="sd">             dataset (Dataset): Dataset to be checked.</span>
<span class="sd">             batch_size (int): batch size to notify.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">SyncWaitDataset</span><span class="p">):</span>
            <span class="n">dataset</span><span class="o">.</span><span class="n">update_sync_batch_size</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">input_dataset</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
            <span class="n">BatchDataset</span><span class="o">.</span><span class="n">_update_batch_size_for_syncwait</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__deepcopy__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memodict</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__safe_deepcopy__</span><span class="p">(</span><span class="n">memodict</span><span class="p">,</span> <span class="n">exclude</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;per_batch_map&quot;</span><span class="p">,</span> <span class="s2">&quot;batch_size_func&quot;</span><span class="p">,</span> <span class="s2">&quot;__transfer_dataset__&quot;</span><span class="p">))</span>

    <span class="c1"># Iterator bootstrap will be called on iterator construction.</span>
    <span class="c1"># A deep copy of Dataset object is created prior of iterator_bootstrap.</span>
    <span class="c1"># This method will create per iterator process pool and bind pyfunc execution to the pool.</span>
    <span class="k">def</span> <span class="nf">iterator_bootstrap</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Per iterator bootstrap callback.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">python_multiprocessing</span> <span class="ow">and</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;windows&#39;</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Python multiprocessing is not supported on Windows platform.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">python_multiprocessing</span> <span class="ow">and</span> <span class="n">get_debug_mode</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Python multiprocessing is not supported in debug mode.&quot;</span>
                           <span class="s2">&quot; Ignoring Python multiprocessing for batch operation.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">python_multiprocessing</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">python_multiprocessing</span> <span class="ow">and</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s1">&#39;windows&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">per_batch_map</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;per_batch_map is None so python_multiprocessing is ignored for batch.&quot;</span><span class="p">)</span>
                <span class="k">return</span>

            <span class="c1"># If user didn&#39;t specify num_parallel_workers, set it to default</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span> <span class="o">=</span> <span class="n">get_num_parallel_workers</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">process_pool</span> <span class="o">=</span> <span class="n">_PythonMultiprocessing</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">per_batch_map</span><span class="p">],</span>
                                                       <span class="bp">self</span><span class="o">.</span><span class="n">max_rowsize</span><span class="p">)</span>
            <span class="c1"># Wrap per_batch_map into _PythonCallable</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">per_batch_map</span> <span class="o">=</span> <span class="n">_PythonCallable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">per_batch_map</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_pool</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">per_batch_map</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">per_batch_map</span> <span class="o">=</span> <span class="n">FuncWrapper</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">per_batch_map</span><span class="p">)</span>


<div class="viewcode-block" id="BatchInfo"><a class="viewcode-back" href="../../../../api_python/dataset/mindspore.dataset.BatchInfo.html#mindspore.dataset.BatchInfo">[docs]</a><span class="k">class</span> <span class="nc">BatchInfo</span><span class="p">(</span><span class="n">cde</span><span class="o">.</span><span class="n">CBatchInfo</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This class helps to get dataset information dynamically when the input of `batch_size` or `per_batch_map`</span>
<span class="sd">    in `batch` operation is a callable object.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BatchInfo.get_batch_num"><a class="viewcode-back" href="../../../../api_python/dataset/mindspore.dataset.BatchInfo.html#mindspore.dataset.BatchInfo.get_batch_num">[docs]</a>    <span class="k">def</span> <span class="nf">get_batch_num</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the batch number being processed in current epoch, start from 0.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; # Create a dataset where its batch size is dynamic</span>
<span class="sd">            &gt;&gt;&gt; # Define a callable batch size function and let batch size increase 1 each time.</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; from mindspore.dataset import BatchInfo</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([i for i in range(3)], &quot;column1&quot;, shuffle=False)</span>
<span class="sd">            &gt;&gt;&gt; def add_one(BatchInfo):</span>
<span class="sd">            ...     return BatchInfo.get_batch_num() + 1</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.batch(batch_size=add_one)</span>
<span class="sd">            &gt;&gt;&gt; print(list(dataset))</span>
<span class="sd">            [[Tensor(shape=[1], dtype=Int64, value= [0])], [Tensor(shape=[2], dtype=Int64, value= [1, 2])]]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span></div>

<div class="viewcode-block" id="BatchInfo.get_epoch_num"><a class="viewcode-back" href="../../../../api_python/dataset/mindspore.dataset.BatchInfo.html#mindspore.dataset.BatchInfo.get_epoch_num">[docs]</a>    <span class="k">def</span> <span class="nf">get_epoch_num</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the epoch number, start from 0.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; # Create a dataset where its batch size is dynamic</span>
<span class="sd">            &gt;&gt;&gt; # Define a callable batch size function and let batch size increase 1 each epoch.</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; from mindspore.dataset import BatchInfo</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.GeneratorDataset([i for i in range(4)], &quot;column1&quot;, shuffle=False)</span>
<span class="sd">            &gt;&gt;&gt; def add_one_by_epoch(BatchInfo):</span>
<span class="sd">            ...     return BatchInfo.get_epoch_num() + 1</span>
<span class="sd">            &gt;&gt;&gt; dataset = dataset.batch(batch_size=add_one_by_epoch)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; result = []</span>
<span class="sd">            &gt;&gt;&gt; epoch = 2</span>
<span class="sd">            &gt;&gt;&gt; iterator = dataset.create_tuple_iterator(num_epochs=epoch)</span>
<span class="sd">            &gt;&gt;&gt; for i in range(epoch):</span>
<span class="sd">            ...    result.extend(list(iterator))</span>
<span class="sd">            &gt;&gt;&gt; # result:</span>
<span class="sd">            &gt;&gt;&gt; # [[Tensor(shape=[1], dtype=Int64, value= [0])], [Tensor(shape=[1], dtype=Int64, value= [1])],</span>
<span class="sd">            &gt;&gt;&gt; #  [Tensor(shape=[1], dtype=Int64, value= [2])], [Tensor(shape=[1], dtype=Int64, value= [3])],</span>
<span class="sd">            &gt;&gt;&gt; #  [Tensor(shape=[2], dtype=Int64, value= [0, 1])], [Tensor(shape=[2], dtype=Int64, value= [2, 3])]]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span></div></div>


<span class="k">class</span> <span class="nc">BlockReleasePair</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The blocking condition class used by SyncWaitDataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        init_release_rows (int): Number of lines to allow through the pipeline.</span>
<span class="sd">        callback (function): The callback function that will be called when release is called. Default: ``None``.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_release_rows</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">init_release_rows</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">init_release_rows</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;release_rows need to be greater than 0.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">row_count</span> <span class="o">=</span> <span class="o">-</span><span class="n">init_release_rows</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Condition</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback</span> <span class="o">=</span> <span class="n">callback</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_rows</span> <span class="o">=</span> <span class="n">init_release_rows</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">disable</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">__deepcopy__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memodict</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">row_count</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">default_rows</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="o">.</span><span class="n">notify_all</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">update_batched_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="c1"># sanity check</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">batch_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;batch_size need to be greater than 0.&quot;</span><span class="p">)</span>

        <span class="c1"># should only use before the pipeline creates</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">row_count</span> <span class="o">*=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_rows</span> <span class="o">*=</span> <span class="n">batch_size</span>

    <span class="k">def</span> <span class="nf">block_func</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function for handing blocking condition.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool, True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">:</span>
            <span class="c1"># if disable is true, the always evaluate to true</span>
            <span class="n">not_time_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="o">.</span><span class="n">wait_for</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_count</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">disable</span><span class="p">),</span>
                                            <span class="n">timeout</span><span class="o">=</span><span class="n">get_callback_timeout</span><span class="p">())</span>
            <span class="c1"># time_out will be False if time out occurs</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">not_time_out</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Timeout happened in sync_wait, maybe dataset.sync_update(condition=...) &quot;</span>
                               <span class="s2">&quot;is not added after dataset.create_dict_iterator(...), now disabling lock.&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">disable</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">row_count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">release_func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pass_rows</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">pass_rows</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">pass_rows</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_rows</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">row_count</span> <span class="o">-=</span> <span class="n">pass_rows</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">callback</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="o">.</span><span class="n">notify_all</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">disable_lock</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">disable</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="o">.</span><span class="n">notify_all</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">PaddedBatchDataset</span><span class="p">(</span><span class="n">UnionBaseDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The result of applying Batch operation to the input dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_dataset (Dataset): Input Dataset to be batched.</span>
<span class="sd">        batch_size (Union[int, function]): The number of rows each batch is created with. An</span>
<span class="sd">            int or callable which takes exactly 1 parameter, BatchInfo.</span>
<span class="sd">        drop_remainder (bool, optional): Determines whether or not to drop the last</span>
<span class="sd">            possibly incomplete batch. Default: ``False``. If True, and if there are less</span>
<span class="sd">            than batch_size rows available to make the last batch, then those rows will</span>
<span class="sd">            be dropped and not propagated to the child node.</span>
<span class="sd">        num_parallel_workers (int, optional): Number of workers to process the dataset in parallel. Default: ``None``.</span>
<span class="sd">        pad_info (dict, optional): Whether to perform padding on selected columns. pad_info={&quot;col1&quot;:([224,224],0)}</span>
<span class="sd">            will pad column with name &quot;col1&quot; to a tensor of size [224,224] and fill the missing with 0.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pad_info</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">input_dataset</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">PaddedBatchDataset</span><span class="o">.</span><span class="n">_is_ancestor_of_repeat</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Repeat is located before padded_batch, data from two epochs can be batched together.&quot;</span><span class="p">)</span>

        <span class="n">PaddedBatchDataset</span><span class="o">.</span><span class="n">_update_batch_size_for_syncwait</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

        <span class="c1"># if batch_size is callable, set batch_size to 1 and batch_size_func to that callable function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size_func</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="k">else</span> <span class="n">batch_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">drop_remainder</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">drop_remainder</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pad</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">pad_info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_info</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">pad_info</span><span class="p">,</span> <span class="nb">dict</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">BatchNode</span><span class="p">(</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_remainder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad</span><span class="p">,</span> <span class="p">[],</span>
                             <span class="p">[],</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size_func</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_info</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_is_ancestor_of_repeat</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Utility function to find the case where repeat is used before batch.</span>

<span class="sd">        Args:</span>
<span class="sd">             dataset (Dataset): Dataset to be checked.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool, whether repeat is used before batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">RepeatDataset</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="n">flag</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">input_dataset</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
            <span class="n">flag</span> <span class="o">=</span> <span class="n">flag</span> <span class="o">|</span> <span class="n">PaddedBatchDataset</span><span class="o">.</span><span class="n">_is_ancestor_of_repeat</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">flag</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_update_batch_size_for_syncwait</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Utility function to notify batch size to sync_wait.</span>

<span class="sd">        Args:</span>
<span class="sd">             dataset (Dataset): Dataset to be checked.</span>
<span class="sd">             batch_size (int): batch size to notify.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">SyncWaitDataset</span><span class="p">):</span>
            <span class="n">dataset</span><span class="o">.</span><span class="n">update_sync_batch_size</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">input_dataset</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
            <span class="n">PaddedBatchDataset</span><span class="o">.</span><span class="n">_update_batch_size_for_syncwait</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__deepcopy__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memodict</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__safe_deepcopy__</span><span class="p">(</span><span class="n">memodict</span><span class="p">,</span> <span class="n">exclude</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;batch_size_func&quot;</span><span class="p">,</span> <span class="s2">&quot;__transfer_dataset__&quot;</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">SyncWaitDataset</span><span class="p">(</span><span class="n">UnionBaseDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The result of adding a blocking condition to the input Dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_dataset (Dataset): Input dataset to apply flow control.</span>
<span class="sd">        num_batch (int): Number of batches without blocking at the start of each epoch.</span>
<span class="sd">        condition_name (str): Condition name that is used to toggle sending next row.</span>
<span class="sd">        callback (function): Callback function that will be invoked when sync_update is called. Default: ``None``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: If condition name already exists.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dataset</span><span class="p">,</span> <span class="n">condition_name</span><span class="p">,</span> <span class="n">num_batch</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">input_dataset</span><span class="p">)</span>

        <span class="c1"># set to the default value, waiting for the batch to update it</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_condition_name</span> <span class="o">=</span> <span class="n">condition_name</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_batch</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_batch</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;num_batch need to be greater than 0.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_pair</span> <span class="o">=</span> <span class="n">BlockReleasePair</span><span class="p">(</span><span class="n">num_batch</span><span class="p">,</span> <span class="n">callback</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_condition_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_sync_notifiers</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Condition name is already in use.&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Please remember to add dataset.sync_update(condition=</span><span class="si">%s</span><span class="s2">), otherwise hanging will result. &quot;</span>
                    <span class="s2">&quot;If dataset.sync_update(condition=</span><span class="si">%s</span><span class="s2">) has already been added, you can ignore the info.&quot;</span><span class="p">,</span>
                    <span class="n">condition_name</span><span class="p">,</span> <span class="n">condition_name</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">SyncWaitNode</span><span class="p">(</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_condition_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pair</span><span class="o">.</span><span class="n">block_func</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_sync_notifiers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_sync_notifiers</span><span class="p">(),</span> <span class="o">**</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_condition_name</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pair</span><span class="o">.</span><span class="n">release_func</span><span class="p">}}</span>

    <span class="k">def</span> <span class="nf">is_sync</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">update_sync_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">batch_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;num_batch need to be greater than 0.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pair</span><span class="o">.</span><span class="n">update_batched_size</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">disable_sync</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Disabling Sync&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pair</span><span class="o">.</span><span class="n">disable_lock</span><span class="p">()</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_is_ancestor_of_batch</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Utility function to find the case where sync_wait is used before batch.</span>

<span class="sd">        Args:</span>
<span class="sd">             dataset (Dataset): Dataset to be checked.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool, whether sync_wait is used before batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">(</span><span class="n">BatchDataset</span><span class="p">,</span> <span class="n">PaddedBatchDataset</span><span class="p">)):</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="n">flag</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">input_dataset</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
            <span class="n">flag</span> <span class="o">=</span> <span class="n">flag</span> <span class="o">|</span> <span class="n">SyncWaitDataset</span><span class="o">.</span><span class="n">_is_ancestor_of_batch</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">flag</span>

    <span class="k">def</span> <span class="nf">iterator_bootstrap</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pair</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">ShuffleDataset</span><span class="p">(</span><span class="n">UnionBaseDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The result of applying Shuffle operation to the input Dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_dataset (Dataset): Input Dataset to be shuffled.</span>
<span class="sd">        buffer_size (int): Size of the buffer.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: If exist sync operations before shuffle.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dataset</span><span class="p">,</span> <span class="n">buffer_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">input_dataset</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span> <span class="o">=</span> <span class="n">buffer_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshuffle_each_epoch</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_sync</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;No shuffle after sync operators.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">ShuffleNode</span><span class="p">(</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshuffle_each_epoch</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">is_shuffled</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">True</span>


<span class="c1"># Pyfunc collection for multiprocess pyfunc</span>
<span class="c1"># This global variable will only be used within subprocesses</span>
<span class="n">_OP_NAME</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="n">_OP_PROCESS</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>


<span class="c1"># PythonCallable wrapper for multiprocess pyfunc</span>
<span class="k">class</span> <span class="nc">_PythonCallable</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Internal Python function wrapper for multiprocessing pyfunc.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">py_callable</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">pool</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Original Python callable from user.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">py_callable</span> <span class="o">=</span> <span class="n">py_callable</span>
        <span class="c1"># Process pool created for current iterator.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">pool</span>
        <span class="c1"># Python callable index</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">idx</span> <span class="o">=</span> <span class="n">idx</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">get_data_from_worker_process</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">while</span> <span class="n">get_data_from_worker_process</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="o">.</span><span class="n">is_running</span><span class="p">()</span> <span class="ow">and</span> <span class="n">check_iterator_cleanup</span><span class="p">()</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
                <span class="k">except</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">TimeoutError</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="n">get_data_from_worker_process</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># worker process is stopped</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;The worker process of map operation is stopped. &quot;</span>
                            <span class="s2">&quot;So return None to main thread and break the main thread.&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">None</span>
        <span class="c1"># got value from worker process</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="n">get_data_from_worker_process</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="p">(</span><span class="n">result</span><span class="p">,)</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">to_json</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">py_callable</span><span class="o">.</span><span class="n">to_json</span><span class="p">()</span>


<span class="c1"># used when python_multiprocessing=True in map</span>
<span class="k">class</span> <span class="nc">Pipe</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class to handle communication between the master process and the worker processes.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">warning_ctl</span><span class="p">,</span> <span class="n">shared_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_rowsize</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shared_memory</span> <span class="o">=</span> <span class="n">shared_memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eof</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">Event</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shared_memory</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">in_queue</span> <span class="o">=</span> <span class="n">_SharedQueue</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">warning_ctl</span><span class="p">,</span> <span class="n">max_rowsize</span><span class="o">=</span><span class="n">max_rowsize</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">res_queue</span> <span class="o">=</span> <span class="n">_SharedQueue</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">warning_ctl</span><span class="p">,</span> <span class="n">max_rowsize</span><span class="o">=</span><span class="n">max_rowsize</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">in_queue</span> <span class="o">=</span> <span class="n">_Queue</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">res_queue</span> <span class="o">=</span> <span class="n">_Queue</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_queue</span><span class="o">.</span><span class="n">cancel_join_thread</span><span class="p">()</span>  <span class="c1"># Ensure that the process does not hung when exiting</span>

    <span class="k">def</span> <span class="nf">master_send</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func_index</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_queue</span><span class="o">.</span><span class="n">put_nowait</span><span class="p">((</span><span class="n">func_index</span><span class="p">,</span> <span class="o">*</span><span class="n">data</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">master_receive</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eof</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;EOF is none when get data from worker.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eof</span><span class="o">.</span><span class="n">is_set</span><span class="p">():</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">res_queue</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">master_close</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eof</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">send_finish_signal_to_worker</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">send_finish_signal</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">send_finish_signal</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">worker_send</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">send_finish_signal_to_worker</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">master_send</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;QUIT&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">worker_send</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">res_queue</span><span class="o">.</span><span class="n">put_until</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">exit_signal</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eof</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">worker_receive</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_queue</span><span class="o">.</span><span class="n">get_until</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">exit_signal</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eof</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">result</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Corrupted data. Worker received </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="si">}</span><span class="s2"> elements, it should be more than 1.&quot;</span><span class="p">)</span>
        <span class="n">func_index</span><span class="p">,</span> <span class="o">*</span><span class="n">data</span> <span class="o">=</span> <span class="n">result</span>
        <span class="k">return</span> <span class="n">func_index</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_main_process_already_exit</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Judge whether main process already exit.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ppid</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getppid</span><span class="p">()</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s1">&#39;windows&#39;</span> <span class="ow">and</span>
            <span class="ow">not</span> <span class="n">_PythonMultiprocessing</span><span class="o">.</span><span class="n">is_process_alive</span><span class="p">(</span><span class="n">ppid</span><span class="p">)):</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span> <span class="nf">_worker_loop</span><span class="p">(</span><span class="n">operations</span><span class="p">,</span> <span class="n">pipe</span><span class="p">,</span> <span class="n">worker_id</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Multiprocess worker process loop.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Ensure that the process does not hung when exiting</span>
    <span class="n">pipe</span><span class="o">.</span><span class="n">res_queue</span><span class="o">.</span><span class="n">cancel_join_thread</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_ignore_sigint</span><span class="p">():</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        We need to ignore sigint signal here so subprocesses can exit normally and clear.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">signal</span><span class="o">.</span><span class="n">signal</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">SIGINT</span><span class="p">,</span> <span class="n">signal</span><span class="o">.</span><span class="n">SIG_IGN</span><span class="p">)</span>

    <span class="c1"># If the default random seed has not been changed, there is no need to fix the randomness.</span>
    <span class="c1"># Otherwise, set the random seed for each child process to &quot;base_seed + worker_id&quot; to ensure</span>
    <span class="c1"># that the random results of each process are different.</span>
    <span class="k">if</span> <span class="n">get_seed</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">5489</span><span class="p">:</span>
        <span class="n">set_seed</span><span class="p">(</span><span class="n">get_seed</span><span class="p">()</span> <span class="o">+</span> <span class="n">worker_id</span><span class="p">)</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">_main_process_already_exit</span><span class="p">():</span>
        <span class="n">_ignore_sigint</span><span class="p">()</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">worker_receive</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">input_tensors</span><span class="p">)</span> <span class="o">=</span> <span class="n">result</span>
        <span class="k">if</span> <span class="n">input_tensors</span> <span class="o">==</span> <span class="s2">&quot;QUIT&quot;</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">output_tensors</span> <span class="o">=</span> <span class="n">operations</span><span class="p">[</span><span class="n">idx</span><span class="p">](</span><span class="o">*</span><span class="n">input_tensors</span><span class="p">)</span>

            <span class="n">pipe</span><span class="o">.</span><span class="n">worker_send</span><span class="p">(</span><span class="n">output_tensors</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">pipe</span><span class="o">.</span><span class="n">worker_send</span><span class="p">(</span><span class="n">ExceptionHandler</span><span class="p">(</span><span class="n">where</span><span class="o">=</span><span class="s2">&quot;in map(or batch) worker and execute Python function&quot;</span><span class="p">))</span>
            <span class="c1"># Do not return</span>

    <span class="c1"># release the queue when stop the worker by master</span>
    <span class="k">del</span> <span class="n">pipe</span><span class="o">.</span><span class="n">in_queue</span>
    <span class="k">del</span> <span class="n">pipe</span><span class="o">.</span><span class="n">res_queue</span>


<span class="k">def</span> <span class="nf">worker_target</span><span class="p">(</span><span class="n">operations</span><span class="p">,</span> <span class="n">worker_id</span><span class="p">):</span>
    <span class="k">return</span> <span class="k">lambda</span> <span class="n">pipe</span><span class="p">:</span> <span class="n">_worker_loop</span><span class="p">(</span><span class="n">operations</span><span class="p">,</span> <span class="n">pipe</span><span class="p">,</span> <span class="n">worker_id</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_MPWorker</span><span class="p">(</span><span class="n">multiprocessing</span><span class="o">.</span><span class="n">Process</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Worker process for multiprocessing.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">operations</span><span class="p">,</span> <span class="n">warning_ctl</span><span class="p">,</span> <span class="n">max_rowsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">worker_id</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="n">shared_memory</span> <span class="o">=</span> <span class="n">get_enable_shared_mem</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipe</span><span class="p">(</span><span class="n">warning_ctl</span><span class="p">,</span> <span class="n">shared_memory</span><span class="o">=</span><span class="n">shared_memory</span><span class="p">,</span> <span class="n">max_rowsize</span><span class="o">=</span><span class="n">max_rowsize</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_interval</span> <span class="o">=</span> <span class="n">get_multiprocessing_timeout_interval</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">worker_target</span><span class="p">(</span><span class="n">operations</span><span class="p">,</span> <span class="n">worker_id</span><span class="p">),</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipe</span><span class="p">,),</span> <span class="n">daemon</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Acquiring data from a worker in an infinite loop&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipe</span><span class="o">.</span><span class="n">master_send</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
        <span class="n">time_s</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">wait_count</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">cost_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">time_s</span>
            <span class="k">if</span> <span class="n">cost_time</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">check_interval</span> <span class="o">&gt;=</span> <span class="n">wait_count</span><span class="p">:</span>
                <span class="n">wait_count</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;It has been waiting for &quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">cost_time</span> <span class="o">+</span> <span class="s2">&quot;s because the sub-process &quot;</span>
                               <span class="s2">&quot;worker of the map operation is hanging. &quot;</span>
                               <span class="s2">&quot;Check whether the user defined data transform is too slow or the &quot;</span>
                               <span class="s2">&quot;output data is too large. You can also set the timeout interval by &quot;</span>
                               <span class="s2">&quot;ds.config.set_multiprocessing_timeout_interval to adjust the output frequency &quot;</span>
                               <span class="s2">&quot;of this log.&quot;</span><span class="p">)</span>
                <span class="n">pid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pid</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Map worker subprocess ID </span><span class="si">{}</span><span class="s2"> is stuck.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pid</span><span class="p">))</span>
                <span class="n">install_status</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">getstatusoutput</span><span class="p">(</span><span class="s2">&quot;py-spy --version&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">install_status</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">stack</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">getoutput</span><span class="p">(</span><span class="s2">&quot;py-spy dump -p </span><span class="si">{}</span><span class="s2"> -l&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pid</span><span class="p">))</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Map worker subprocess stack:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">stack</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Please `pip install py-spy` to get the stacks of the stuck process.&quot;</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipe</span><span class="o">.</span><span class="n">master_receive</span><span class="p">()</span>
            <span class="k">except</span> <span class="n">queue</span><span class="o">.</span><span class="n">Empty</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="n">res</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># receive finish signal</span>
                <span class="k">return</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">ExceptionHandler</span><span class="p">):</span>
                <span class="n">res</span><span class="o">.</span><span class="n">reraise</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">res</span>

    <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_alive</span><span class="p">():</span>
                <span class="c1"># release the eager executor which is used by current process</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">clean_unused_executors</span><span class="p">()</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Closing worker with PID: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipe</span><span class="o">.</span><span class="n">master_close</span><span class="p">()</span>
                <span class="c1"># del the handle which hold by master</span>
                <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipe</span><span class="o">.</span><span class="n">in_queue</span>
                <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipe</span><span class="o">.</span><span class="n">res_queue</span>
                <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>
                <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
                <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="c1"># Process has been closed already</span>
            <span class="k">return</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">is_alive</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">is_alive</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>


<span class="k">class</span> <span class="nc">_PythonMultiprocessing</span><span class="p">(</span><span class="n">cde</span><span class="o">.</span><span class="n">PythonMultiprocessingRuntime</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A wrapper to multiprocessing.pool that performs cleanup and ensure proper termination of forked processes.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">class</span> <span class="nc">_ExceptHookHandler</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Internal class ExceptionHandler</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">origin_hook</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">excepthook</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">excepthook</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__handler_exception</span>

        <span class="nd">@staticmethod</span>
        <span class="k">def</span> <span class="nf">mp_pool_exit_preprocess</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">check_iterator_cleanup</span><span class="p">()</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="c1"># Set the iterator_cleanup flag to True before exiting, and wait 3s for all apply_async</span>
                <span class="c1"># applied to the multiprocessing task to prevent multiprocessing from hang when exiting</span>
                <span class="n">_set_iterator_cleanup</span><span class="p">()</span>
                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">__handler_exception</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ex_type</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">tb</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">origin_hook</span><span class="p">(</span><span class="n">ex_type</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">tb</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mp_pool_exit_preprocess</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op_name</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="p">,</span> <span class="n">operations</span><span class="p">,</span> <span class="n">max_rowsize</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_PythonMultiprocessing</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op_name</span> <span class="o">=</span> <span class="n">op_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span> <span class="o">=</span> <span class="n">num_parallel_workers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">operations</span> <span class="o">=</span> <span class="n">operations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_rowsize</span> <span class="o">=</span> <span class="n">max_rowsize</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">workers</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pids</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op_id</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">queues_map</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">next_queue</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">eot</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">watch_dog</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ppid</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hook</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warning_ctl</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># cache thread (get_ident()) to worker_id mapping in Python layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">python_threads_to_workers</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
            <span class="k">pass</span>

    <span class="c1"># This wait function is for cleaning zombie subprocesses</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">wait_pid</span><span class="p">():</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function is used by the main process to release subprocess resources.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">child_pid</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">waitpid</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">WNOHANG</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">child_pid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">break</span>
        <span class="k">except</span> <span class="ne">OSError</span><span class="p">:</span>
            <span class="c1"># waitpid may be failed for some reasons so we ignore this error</span>
            <span class="k">pass</span>

    <span class="c1"># Dataset need watch_dog thread to monitoring fork multi-processing,</span>
    <span class="c1"># and thread can&#39;t be a member function otherwise python won&#39;t collect and release resources.</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_watch_dog</span><span class="p">(</span><span class="n">eot</span><span class="p">,</span> <span class="n">workers</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This thread is for monitoring subprocesses forked by GeneratorDataset/map/batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">workers</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;[Internal Error] The 2nd parameter of watch dog thread should be list of process, &quot;</span>
                            <span class="s2">&quot;but got </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">workers</span><span class="p">)))</span>

        <span class="k">while</span> <span class="ow">not</span> <span class="n">eot</span><span class="o">.</span><span class="n">is_set</span><span class="p">():</span>
            <span class="c1"># Monitoring and count how many subprocesses already exit</span>
            <span class="n">clear_subprocess_timeout</span> <span class="o">=</span> <span class="n">_PythonMultiprocessing</span><span class="o">.</span><span class="n">_monitor_subprocess_exit</span><span class="p">(</span><span class="n">workers</span><span class="p">)</span>
            <span class="c1"># If find subprocess exit, we will wait for 30s and do some waitpid operations</span>
            <span class="k">if</span> <span class="n">clear_subprocess_timeout</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                <span class="k">while</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span> <span class="o">&lt;</span> <span class="n">clear_subprocess_timeout</span><span class="p">:</span>
                    <span class="c1"># We need to distinguishing get_dataset_size or train finished normally and hang scenario.</span>
                    <span class="c1"># If get_dataset_size or train finished normally, _stop_subprocess can be execute and</span>
                    <span class="c1"># self.need_abort can be set to True. If main process is hang in get(), self.need_abort</span>
                    <span class="c1"># will never set to True, then we wait for 30s and kill main process</span>
                    <span class="k">if</span> <span class="n">eot</span><span class="o">.</span><span class="n">is_set</span><span class="p">():</span>
                        <span class="k">return</span>
                    <span class="c1"># Sometimes subprocess may be zombie, so in 30s we can wait and do some useful tasks(waitpid).</span>
                    <span class="n">_PythonMultiprocessing</span><span class="o">.</span><span class="n">wait_pid</span><span class="p">()</span>
                <span class="c1"># multiprocessing.queue may hang in .get() forever when put() process was killed.</span>
                <span class="c1"># We have to exit main process otherwise main process will hang.</span>
                <span class="n">_PythonMultiprocessing</span><span class="o">.</span><span class="n">_terminate_processes</span><span class="p">(</span><span class="n">workers</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">critical</span><span class="p">(</span><span class="s2">&quot;The subprocess of dataset may exit unexpected or be killed, &quot;</span>
                                <span class="s2">&quot;main process will exit. If this is not an artificial operation, you can use &quot;</span>
                                <span class="s2">&quot;ds.config.set_enable_watchdog(False) to block this error.&quot;</span><span class="p">)</span>
                <span class="n">os</span><span class="o">.</span><span class="n">kill</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">(),</span> <span class="n">signal</span><span class="o">.</span><span class="n">SIGTERM</span><span class="p">)</span>

        <span class="c1"># release the workers</span>
        <span class="k">del</span> <span class="n">workers</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_terminate_processes</span><span class="p">(</span><span class="n">processes</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Terminate subprocesses&quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">processes</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">exitcode</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>  <span class="c1"># pylint: disable=broad-except</span>
                <span class="c1"># process has been closed already</span>
                <span class="k">pass</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">processes</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">_closed</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>  <span class="c1"># pylint: disable=W0212</span>
                <span class="c1"># We don&#39;t use w.join because join can only used in main process or join will raise an error.</span>
                <span class="n">p</span><span class="o">.</span><span class="n">_popen</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>  <span class="c1"># pylint: disable=W0212</span>

    <span class="c1"># Monitor the exit number of subprocesses</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_monitor_subprocess_exit</span><span class="p">(</span><span class="n">workers</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        To monitor whether process is exit.</span>

<span class="sd">        Args:</span>
<span class="sd">            workers (list of multiprocessing.Process): multiprocessing.Process.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int, the timeout(in seconds) when process exit.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">workers</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">exit_code</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">exitcode</span>
                <span class="k">if</span> <span class="n">exit_code</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># For kill -9, we can exit quickly</span>
                    <span class="k">if</span> <span class="n">exit_code</span> <span class="o">==</span> <span class="o">-</span><span class="mi">9</span><span class="p">:</span>
                        <span class="k">return</span> <span class="mi">1</span>
                    <span class="c1"># For kill -15, we still exit after 30s</span>
                    <span class="k">if</span> <span class="n">exit_code</span> <span class="o">==</span> <span class="o">-</span><span class="mi">15</span><span class="p">:</span>
                        <span class="k">return</span> <span class="mi">30</span>
                <span class="c1"># In some cases the subprocess has been killed but the exitcode is still None.</span>
                <span class="c1"># So we use os.kill(pid, 0) to check if it is alive.</span>
                <span class="n">subprocess_alive</span> <span class="o">=</span> <span class="n">_PythonMultiprocessing</span><span class="o">.</span><span class="n">is_process_alive</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">pid</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">subprocess_alive</span><span class="p">:</span>
                    <span class="c1"># Like kill -15, we wait 30s before exit</span>
                    <span class="k">return</span> <span class="mi">30</span>
            <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                <span class="c1"># process has been closed already</span>
                <span class="k">return</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="mi">0</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">is_process_alive</span><span class="p">(</span><span class="n">pid</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check if the process is alive or not.</span>
<span class="sd">        Note:  We hit a deadlock when we use psutil or w.exitcode to check whether a process is alive.</span>
<span class="sd">        Instead we use os.kill(ppid, 0).</span>

<span class="sd">        Args:</span>
<span class="sd">            pid: pid of the process to be checked</span>

<span class="sd">        Returns:</span>
<span class="sd">            True if the process is alive</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">os</span><span class="o">.</span><span class="n">kill</span><span class="p">(</span><span class="n">pid</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">OSError</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="c1"># When main process exit, subprocesses will be terminate</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_clean_process</span><span class="p">(</span><span class="n">ppid</span><span class="p">,</span> <span class="n">workers</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            This is the execute function of clean process, if we found main process exited, we will clean subprocesses.</span>

<span class="sd">        Args:</span>
<span class="sd">            ppid: The process id of main process.</span>
<span class="sd">            workers: The list of subprocesses.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">signal</span><span class="o">.</span><span class="n">signal</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">SIGINT</span><span class="p">,</span> <span class="n">signal</span><span class="o">.</span><span class="n">SIG_IGN</span><span class="p">)</span>
        <span class="k">while</span> <span class="n">_PythonMultiprocessing</span><span class="o">.</span><span class="n">is_process_alive</span><span class="p">(</span><span class="n">ppid</span><span class="p">):</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>

        <span class="n">_PythonMultiprocessing</span><span class="o">.</span><span class="n">_terminate_processes</span><span class="p">(</span><span class="n">workers</span><span class="p">)</span>
        <span class="k">del</span> <span class="n">workers</span>
        <span class="n">os</span><span class="o">.</span><span class="n">kill</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">(),</span> <span class="n">signal</span><span class="o">.</span><span class="n">SIGTERM</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">launch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op_id</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Launch Python multiprocessing pool.</span>

<span class="sd">        Args:</span>
<span class="sd">            pop_id: ID for operation to have Python multiprocessing pool launched</span>

<span class="sd">        Returns:</span>
<span class="sd">            Python multiprocssing pool is launched.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">python_threads_to_workers</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op_id</span> <span class="o">=</span> <span class="n">op_id</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Launching new Python Multiprocessing pool for Op:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">op_id</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_mp_enabled</span><span class="p">():</span>
            <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;Launching a new Python multiprocessing pool while a pool already exists!&quot;</span> <span class="o">+</span> \
                <span class="s2">&quot; The existing pool will be terminated first.&quot;</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">create_pool</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">create_pool</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">get_enable_shared_mem</span><span class="p">():</span>
            <span class="n">_check_shm_usage</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_rowsize</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_rowsize</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Pool was already created, close it first.&quot;</span><span class="p">)</span>

        <span class="c1"># Let gc collect unreferenced memory to avoid child processes in the pool to do it</span>
        <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

        <span class="c1"># Construct python worker processes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">workers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warning_ctl</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="s1">&#39;i&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">worker_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span><span class="p">):</span>
            <span class="n">worker</span> <span class="o">=</span> <span class="n">_MPWorker</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">operations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">warning_ctl</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_rowsize</span><span class="p">,</span> <span class="n">worker_id</span><span class="p">)</span>
            <span class="n">worker</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">worker</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Op: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">op_id</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; Python multiprocessing pool workers&#39; PIDs: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pids</span><span class="p">()))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">hook</span> <span class="o">=</span> <span class="n">_PythonMultiprocessing</span><span class="o">.</span><span class="n">_ExceptHookHandler</span><span class="p">()</span>

        <span class="c1"># The op (Map, Batch, etc) multiprocessing will launch a watch dog thread for monitoring sub processes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_launch_watch_dog</span><span class="p">()</span>

        <span class="n">atexit</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">terminate</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">terminate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># close watch dog first and then close all the workers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">abort_watchdog</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">close_all_workers</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;warning_ctl&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">warning_ctl</span>

    <span class="k">def</span> <span class="nf">get_pids</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get list of worker&#39;s PIDs</span>

<span class="sd">        Returns:</span>
<span class="sd">            list of strings</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_mp_enabled</span><span class="p">():</span>
            <span class="k">return</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pids</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pids</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">pids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">pid</span><span class="p">)</span>
                    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                        <span class="k">continue</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pids</span>

    <span class="k">def</span> <span class="nf">add_new_workers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_new_workers</span><span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Increasing num_parallel_workers of Python Multiprocessing pool for Op:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">op_id</span><span class="p">)</span> <span class="o">+</span>
            <span class="s2">&quot;, old num_workers=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; new num_workers=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span> <span class="o">+</span>
                <span class="n">num_new_workers</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span> <span class="o">+=</span> <span class="n">num_new_workers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">op_id</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">remove_workers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_removed_workers</span><span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Decreasing num_parallel_workers of Python Multiprocessing pool for Op:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">op_id</span><span class="p">)</span> <span class="o">+</span>
            <span class="s2">&quot;, old num_workers=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; new num_workers=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span> <span class="o">-</span>
                <span class="n">num_removed_workers</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span> <span class="o">-=</span> <span class="n">num_removed_workers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">op_id</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">is_mp_enabled</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Execute</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">t_id</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">get_ident</span><span class="p">()</span>
        <span class="c1"># get the worker_id from Python layer cache first, get from Cpp layer if not found.</span>
        <span class="n">worker_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">python_threads_to_workers</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">t_id</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_thread_to_worker</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">worker_id</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;[Internal] worker_id value is greater than number of available workers!&quot;</span><span class="p">)</span>

        <span class="c1"># todo check_iterator_cleanup</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_running</span><span class="p">()</span> <span class="ow">and</span> <span class="n">check_iterator_cleanup</span><span class="p">()</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">[</span><span class="n">worker_id</span><span class="p">]</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>

        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_launch_watch_dog</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        We will launch a watchdog thread and a clean process to cleaning subprocess when there is process was killed.</span>
<span class="sd">        The watchdog thread will cleanup subprocesses and main process when one of the subprocesses was killed.</span>
<span class="sd">        The cleaning subprocess will cleanup subprocesses when main process was killed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">!=</span> <span class="s1">&#39;windows&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cleaning_process</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_clean_process</span><span class="p">,</span>
                                                            <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ppid</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">),</span>
                                                            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;OrphanCleaner&quot;</span><span class="p">,</span>
                                                            <span class="n">daemon</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cleaning_process</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">get_enable_watchdog</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">eot</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Event</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">watch_dog</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_watch_dog</span><span class="p">,</span>
                                                  <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eot</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">cleaning_process</span><span class="p">]),</span>
                                                  <span class="n">name</span><span class="o">=</span><span class="s2">&quot;WatchDog&quot;</span><span class="p">,</span>
                                                  <span class="n">daemon</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">watch_dog</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_abort_watchdog</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">eot</span><span class="o">.</span><span class="n">is_set</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eot</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">abort_watchdog</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;watch_dog&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">watch_dog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;eot&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">eot</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_abort_watchdog</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;cleaning_process&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">cleaning_process</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_PythonMultiprocessing</span><span class="o">.</span><span class="n">_terminate_processes</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">cleaning_process</span><span class="p">])</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">cleaning_process</span>

    <span class="k">def</span> <span class="nf">is_running</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;workers&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">all</span><span class="p">([</span><span class="n">w</span><span class="o">.</span><span class="n">is_alive</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">])</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">close_all_workers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Close all the subprocess workers&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;workers&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">:</span>
                <span class="n">w</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="n">check_interval</span> <span class="o">=</span> <span class="n">get_multiprocessing_timeout_interval</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">subprocess_file_descriptor</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">sentinel</span>
                    <span class="n">st</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                    <span class="k">while</span> <span class="n">_PythonMultiprocessing</span><span class="o">.</span><span class="n">is_process_alive</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">pid</span><span class="p">):</span>
                        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>  <span class="c1"># sleep 10ms, waiting for the subprocess exit</span>
                        <span class="k">if</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">st</span> <span class="o">&gt;</span> <span class="n">check_interval</span><span class="p">:</span>
                            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Waiting for the subprocess worker [</span><span class="si">{}</span><span class="s2">] to exit.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">pid</span><span class="p">))</span>
                            <span class="n">st</span> <span class="o">+=</span> <span class="n">check_interval</span>
                <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="k">if</span> <span class="s2">&quot;process object is closed&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
                        <span class="k">continue</span>
                    <span class="k">raise</span> <span class="n">e</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">w</span><span class="o">.</span><span class="n">is_alive</span><span class="p">():</span>
                        <span class="n">os</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">subprocess_file_descriptor</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">OSError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="c1"># Maybe the file descriptor had been released, so ignore the &#39;Bad file descriptor&#39;</span>
                    <span class="k">if</span> <span class="s2">&quot;Bad file descriptor&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="n">e</span>

            <span class="c1"># use clear to release the handle which is better than self.workers = None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">workers</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pids</span> <span class="o">=</span> <span class="kc">None</span>


<span class="k">class</span> <span class="nc">MapDataset</span><span class="p">(</span><span class="n">UnionBaseDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The result of applying the Map operation to the input Dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_dataset (Dataset): Input Dataset to be mapped.</span>
<span class="sd">        operations (Union[list[TensorOperation], list[functions]]): A function mapping a nested structure of tensors</span>
<span class="sd">            to another nested structure of tensor. Default: ``None``.</span>
<span class="sd">        input_columns (Union[str, list[str]]): List of names of the input columns.</span>
<span class="sd">            Default: ``None``, the operations will be applied on the first columns in the dataset.</span>
<span class="sd">            The size of the list should match the number of inputs of the first operation.</span>
<span class="sd">        output_columns (Union[str, list[str]], optional): List of names of the output columns.</span>
<span class="sd">            The size of the list should match the number of outputs of the last operation.</span>
<span class="sd">            Default: ``None``, output columns will be the input columns, i.e., the columns will</span>
<span class="sd">            be replaced.</span>
<span class="sd">        num_parallel_workers (int, optional): Number of workers to process the dataset</span>
<span class="sd">            in parallel. Default: ``None``.</span>
<span class="sd">        python_multiprocessing (bool, optional): Parallelize Python operations with multiple worker process. This</span>
<span class="sd">            option could be beneficial if the Python operation is computational heavy. Default: ``False``.</span>
<span class="sd">        cache (DatasetCache, optional): Use tensor caching service to speed up dataset processing.</span>
<span class="sd">            Default: ``None``, which means no cache is used.</span>
<span class="sd">        callbacks (DSCallback, list[DSCallback], optional): List of Dataset callbacks to be called. Default: ``None``.</span>
<span class="sd">        max_rowsize(Union[int, list[int]], optional): Maximum size of row in MB that is used for shared memory</span>
<span class="sd">            allocation to copy data between processes, the total occupied shared memory will increase as</span>
<span class="sd">            ``num_parallel_workers`` and :func:`mindspore.dataset.config.set_prefetch_size` increase. This is only</span>
<span class="sd">            used if python_multiprocessing is set to True. If it is an int value, it represents ``input_columns`` and</span>
<span class="sd">            ``output_columns`` use this value as the unit to create shared memory. If it is a list, the first element</span>
<span class="sd">            represents the ``input_columns`` use this value as the unit to create shared memory, and the second element</span>
<span class="sd">            represents ``output_columns`` use this value as the unit to create shared memory. Default: 16.</span>
<span class="sd">        offload (bool, optional): Flag to indicate whether offload is used. Default: ``None``.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dataset</span><span class="p">,</span> <span class="n">operations</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">num_parallel_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">python_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_rowsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                 <span class="n">offload</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">input_dataset</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="n">cache</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">operations</span> <span class="o">=</span> <span class="n">to_list</span><span class="p">(</span><span class="n">operations</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">operations</span><span class="p">:</span>
            <span class="c1"># user define c_vision.HWC2CHW without parentheses is error</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">op</span><span class="p">)</span> <span class="o">==</span> <span class="nb">type</span><span class="p">:</span>  <span class="c1"># pylint: disable=unidiomatic-typecheck</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Parameter operations&#39;s element of method map should be a dataset processing &quot;</span>
                                 <span class="s2">&quot;operation instance, but got: </span><span class="si">{}</span><span class="s2">. It may be missing parentheses for &quot;</span>
                                 <span class="s2">&quot;instantiation.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">op</span><span class="p">))</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="p">(</span><span class="n">c_transforms</span><span class="o">.</span><span class="n">TensorOperation</span><span class="p">,</span> <span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">))</span> \
                    <span class="ow">and</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Parameter operations&#39;s element of method map should be a python function or &quot;</span>
                                 <span class="s2">&quot;class method which should be callable, but got: </span><span class="si">{}</span><span class="s2">. It doesn&#39;t need parentheses &quot;</span>
                                 <span class="s2">&quot;for python function or class method.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">op</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_columns</span> <span class="o">=</span> <span class="n">to_list</span><span class="p">(</span><span class="n">input_columns</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_columns</span> <span class="o">=</span> <span class="n">to_list</span><span class="p">(</span><span class="n">output_columns</span><span class="p">)</span>

        <span class="c1">#  If output_columns were not provided then use input_columns</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_columns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_columns</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_columns</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_columns</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">python_multiprocessing</span> <span class="o">=</span> <span class="n">python_multiprocessing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">process_pool</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span> <span class="o">=</span> <span class="n">to_list</span><span class="p">(</span><span class="n">callbacks</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">max_rowsize</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">max_rowsize</span> <span class="o">=</span> <span class="p">[</span><span class="n">max_rowsize</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">max_rowsize</span> <span class="o">=</span> <span class="n">max_rowsize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">offload</span> <span class="o">=</span> <span class="n">offload</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">operations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__decompose_callable_operations</span><span class="p">()</span>

        <span class="n">count_old_transforms</span><span class="p">,</span> <span class="n">count_new_transforms</span><span class="p">,</span> <span class="n">count_non_data_vision_transforms</span> <span class="o">=</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">__count_transforms</span><span class="p">(</span><span class="n">operations</span><span class="p">)</span>
        <span class="n">count_pyfunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__count_pyfuncs</span><span class="p">(</span><span class="n">operations</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">count_new_transforms</span> <span class="o">+</span> <span class="n">count_pyfunc</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">operations</span><span class="p">):</span>
            <span class="n">prev_op</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">operations</span><span class="p">:</span>
                <span class="c1"># skip user added DebugHook to avoid changing to Py-implementation.</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__is_debug_hook_op</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">prev_op</span><span class="p">:</span>
                        <span class="c1"># manually set previous_op_name</span>
                        <span class="n">prev_op_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__parse_op_name</span><span class="p">(</span><span class="n">prev_op</span><span class="p">)</span>
                        <span class="n">op</span><span class="o">.</span><span class="n">set_previous_op_name</span><span class="p">(</span><span class="n">prev_op_name</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">implementation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">prev_op</span> <span class="ow">and</span> <span class="n">prev_op</span><span class="o">.</span><span class="n">implementation</span> <span class="o">==</span> <span class="n">Implementation</span><span class="o">.</span><span class="n">PY</span><span class="p">:</span>
                        <span class="n">op</span><span class="o">.</span><span class="n">implementation</span> <span class="o">=</span> <span class="n">Implementation</span><span class="o">.</span><span class="n">PY</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">op</span><span class="o">.</span><span class="n">implementation</span> <span class="o">=</span> <span class="n">Implementation</span><span class="o">.</span><span class="n">C</span>
                <span class="n">prev_op</span> <span class="o">=</span> <span class="n">op</span>
            <span class="n">operations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__insert_debug_wrapper</span><span class="p">(</span><span class="n">operations</span><span class="p">)</span>
            <span class="n">operations</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">operations</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">count_old_transforms</span> <span class="o">+</span> <span class="n">count_pyfunc</span> <span class="o">+</span> <span class="n">count_non_data_vision_transforms</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">operations</span><span class="p">):</span>
            <span class="n">operations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__insert_debug_wrapper</span><span class="p">(</span><span class="n">operations</span><span class="p">)</span>
            <span class="n">operations</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">Compose</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">operations</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Mixing old legacy c/py_transforms and new unified transforms is not allowed.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">operations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__process_final_operations</span><span class="p">(</span><span class="n">operations</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_multiprocessing</span><span class="p">()</span>

        <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">cb</span><span class="o">.</span><span class="n">create_runtime_obj</span><span class="p">()</span> <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">MapNode</span><span class="p">(</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">operations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_columns</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_columns</span><span class="p">,</span>
                           <span class="n">callbacks</span><span class="p">,</span> <span class="n">OffloadToManualOffloadMode</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">offload</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_pool</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__deepcopy__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memodict</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__safe_deepcopy__</span><span class="p">(</span><span class="n">memodict</span><span class="p">,</span> <span class="n">exclude</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;operations&quot;</span><span class="p">,</span> <span class="s2">&quot;callbacks&quot;</span><span class="p">,</span> <span class="s2">&quot;__transfer_dataset__&quot;</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;process_pool&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_pool</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">process_pool</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_pool</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">__parse_op_name</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Utility method to get operation name.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">op_name</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">transforms</span><span class="o">.</span><span class="n">py_transforms_util</span><span class="o">.</span><span class="n">FuncWrapper</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">op_name</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="vm">__name__</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">AttributeError</span><span class="p">,):</span>
                <span class="n">op_name</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">op_name</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="k">return</span> <span class="n">op_name</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">__construct_debug_hook</span><span class="p">(</span><span class="n">previous_op_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">is_first_op</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Wrap debug hook into FuncWrapper.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">inserted_functions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">debug_hook_list</span> <span class="o">=</span> <span class="n">_get_debug_hook_list</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">debug_hook_list</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">debug_hook_list</span><span class="p">:</span>
                <span class="c1"># making deep copy to allow each debug hook instance hold unique variables</span>
                <span class="n">new_fn</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
                <span class="n">new_fn</span><span class="o">.</span><span class="n">set_previous_op_name</span><span class="p">(</span><span class="n">previous_op_name</span><span class="p">)</span>
                <span class="n">new_fn</span><span class="o">.</span><span class="n">set_is_first</span><span class="p">(</span><span class="n">is_first_op</span><span class="p">)</span>
                <span class="n">inserted_func</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">py_transforms_util</span><span class="o">.</span><span class="n">FuncWrapper</span><span class="p">(</span><span class="n">new_fn</span><span class="p">)</span>
                <span class="n">inserted_func</span><span class="o">.</span><span class="n">implementation</span> <span class="o">=</span> <span class="n">Implementation</span><span class="o">.</span><span class="n">PY</span>
                <span class="n">inserted_functions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inserted_func</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">inserted_functions</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">__is_debug_hook_op</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check if the op is user added DebugHook and skip it to avoid changing transforms implementation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">DebugHook</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">get_debug_mode</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;It is not allowed to inject DebugHook object in non-debug mode.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">__count_pyfuncs</span><span class="p">(</span><span class="n">operations</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Count the number of pyfuncs operations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">([</span><span class="mi">1</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">FuncWrapper</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">operations</span><span class="p">])</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">__count_transforms</span><span class="p">(</span><span class="n">operations</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Count the various flavors of transforms operations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Count the number of old legacy data and vision c_transforms and py_transforms</span>
        <span class="n">count_old_transforms</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">[</span><span class="mi">1</span> <span class="k">if</span> <span class="s2">&quot;c_transforms&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
             <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="p">(</span><span class="n">c_transforms</span><span class="o">.</span><span class="n">TensorOperation</span><span class="p">,</span> <span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">))</span>
             <span class="ow">or</span> <span class="p">(</span><span class="s2">&quot;py_transforms&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">op</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">FuncWrapper</span><span class="p">))</span>
             <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">operations</span><span class="p">])</span>
        <span class="c1"># Count the number of new unified data and vision transforms</span>
        <span class="n">count_new_transforms</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="mi">1</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="s2">&quot;implementation&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">FuncWrapper</span><span class="p">)</span>
                                    <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">operations</span><span class="p">])</span>
        <span class="c1"># Count the number of non-data transforms and non-vision transforms</span>
        <span class="n">count_non_data_vision_transforms</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">[</span><span class="mi">1</span> <span class="k">if</span> <span class="s2">&quot;text.transforms&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">op</span><span class="p">)</span> <span class="ow">or</span> <span class="s2">&quot;audio.transforms&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">op</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">operations</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">count_old_transforms</span><span class="p">,</span> <span class="n">count_new_transforms</span><span class="p">,</span> <span class="n">count_non_data_vision_transforms</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">__operation_valid_for_multiprocessing</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">op</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">str</span><span class="p">(</span><span class="n">op</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;c_transform&quot;</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">__process_final_operations</span><span class="p">(</span><span class="n">operations</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build final list of operations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">operations_fin</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">operations</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="s2">&quot;implementation&quot;</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">implementation</span> <span class="o">==</span> <span class="n">Implementation</span><span class="o">.</span><span class="n">C</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="p">(</span><span class="n">FuncWrapper</span><span class="p">,</span> <span class="n">ToNumpy</span><span class="p">)):</span>
                    <span class="n">operations_fin</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">parse</span><span class="p">())</span>
                <span class="k">elif</span> <span class="n">op</span><span class="o">.</span><span class="n">implementation</span> <span class="o">==</span> <span class="n">Implementation</span><span class="o">.</span><span class="n">PY</span><span class="p">:</span>
                    <span class="n">operations_fin</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="p">(</span><span class="n">FuncWrapper</span><span class="p">,</span> <span class="n">ToNumpy</span><span class="p">)):</span>
                    <span class="n">operations_fin</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Wrong implementation&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">op</span> <span class="ow">and</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="s1">&#39;parse&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
                    <span class="n">operations_fin</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">parse</span><span class="p">())</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">operations_fin</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">operations_fin</span>

    <span class="c1"># Iterator bootstrap will be called on iterator construction.</span>
    <span class="c1"># A deep copy of Dataset object is created prior of iterator_bootstrap.</span>
    <span class="c1"># This method will create per iterator process pool and bind pyfunc execution to the pool.</span>
    <span class="k">def</span> <span class="nf">prepare_multiprocessing</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Per iterator bootstrap callback.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">python_multiprocessing</span> <span class="ow">and</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;windows&#39;</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Python multiprocessing is not supported on Windows platform.&quot;</span><span class="p">)</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">python_multiprocessing</span> <span class="ow">and</span> <span class="n">get_debug_mode</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Python multiprocessing is not supported in debug mode.&quot;</span>
                           <span class="s2">&quot; Ignoring Python multiprocessing for map operation.&quot;</span><span class="p">)</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">python_multiprocessing</span><span class="p">:</span>
            <span class="n">iter_specific_operations</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">callable_list</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="c1"># If user didn&#39;t specify num_parallel_workers, set it to default</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span> <span class="o">=</span> <span class="n">get_num_parallel_workers</span><span class="p">()</span>

            <span class="c1"># Pass #1, look for Python callables and build list</span>
            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">operations</span><span class="p">:</span>
                <span class="c1"># our c transforms is now callable and should not be run in Python multithreading</span>
                <span class="k">if</span> <span class="n">MapDataset</span><span class="o">.</span><span class="n">__operation_valid_for_multiprocessing</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
                    <span class="n">callable_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">callable_list</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">process_pool</span> <span class="o">=</span> <span class="n">_PythonMultiprocessing</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_parallel_workers</span><span class="p">,</span> <span class="n">callable_list</span><span class="p">,</span>
                                                           <span class="bp">self</span><span class="o">.</span><span class="n">max_rowsize</span><span class="p">)</span>
                <span class="c1"># Pass #2</span>
                <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">operations</span><span class="p">:</span>
                    <span class="c1"># our c transforms is now callable and should not be run in Python multithreading</span>
                    <span class="k">if</span> <span class="n">MapDataset</span><span class="o">.</span><span class="n">__operation_valid_for_multiprocessing</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
                        <span class="c1"># Wrap Python callable into _PythonCallable</span>
                        <span class="n">iter_specific_operations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_PythonCallable</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_pool</span><span class="p">))</span>
                        <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># CPP ops remain the same</span>
                        <span class="n">iter_specific_operations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">operations</span> <span class="o">=</span> <span class="n">iter_specific_operations</span>

    <span class="k">def</span> <span class="nf">__insert_debug_wrapper</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">operations</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Insert DebuggerWrapper before and after each op if debug mode is on.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">get_debug_mode</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">operations</span>
        <span class="n">first_op_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__parse_op_name</span><span class="p">(</span><span class="n">operations</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">inserted_operations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__construct_debug_hook</span><span class="p">(</span><span class="n">first_op_name</span><span class="p">,</span> <span class="n">is_first_op</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">operations</span><span class="p">:</span>
            <span class="n">inserted_operations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="n">op_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__parse_op_name</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="n">inserted_operations</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__construct_debug_hook</span><span class="p">(</span><span class="n">op_name</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">inserted_operations</span>

    <span class="k">def</span> <span class="nf">__decompose_callable_operations</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Decompose operations and build list of old legacy ops which are callable</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">decomposed_operations</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="o">.</span><span class="n">decompose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">operations</span><span class="p">)</span>
        <span class="n">operations</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">decomposed_operations</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">op</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="s2">&quot;implementation&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">str</span><span class="p">(</span><span class="n">op</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span>
                    <span class="s2">&quot;c_transform&quot;</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">c_transforms</span><span class="o">.</span><span class="n">TensorOperation</span><span class="p">)</span> <span class="ow">and</span> \
                    <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
                <span class="n">op</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">py_transforms_util</span><span class="o">.</span><span class="n">FuncWrapper</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="n">operations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">operations</span>


<span class="k">class</span> <span class="nc">FilterDataset</span><span class="p">(</span><span class="n">UnionBaseDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The result of applying filter predicate to the input Dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_dataset (Dataset): Input Dataset to be mapped.</span>
<span class="sd">        predicate (callable): Python callable which returns a boolean value. If False then filter the element.</span>
<span class="sd">        input_columns (Union[str, list[str]], optional): List of names of the input columns.</span>
<span class="sd">            Default: ``None``, the predicate will be applied to all columns in the dataset.</span>
<span class="sd">        num_parallel_workers (int, optional): Number of workers to process the dataset</span>
<span class="sd">            in parallel. Default: ``None``.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dataset</span><span class="p">,</span> <span class="n">predicate</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">input_dataset</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="n">num_parallel_workers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predicate</span> <span class="o">=</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="nb">bool</span><span class="p">(</span><span class="n">predicate</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_columns</span> <span class="o">=</span> <span class="n">to_list</span><span class="p">(</span><span class="n">input_columns</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">FilterNode</span><span class="p">(</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">predicate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_columns</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">RepeatDataset</span><span class="p">(</span><span class="n">UnionBaseDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The result of applying Repeat operation to the input Dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_dataset (Dataset): Input Dataset to be repeated.</span>
<span class="sd">        count (int): Number of times the dataset will be repeated. Default: -1, repeat indefinitely.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dataset</span><span class="p">,</span> <span class="n">count</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">input_dataset</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">RepeatNode</span><span class="p">(</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">SkipDataset</span><span class="p">(</span><span class="n">UnionBaseDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The result of applying Skip operation to the input Dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_dataset (Dataset): Input dataset to have elements skipped.</span>
<span class="sd">        count (int): Number of elements to be skipped in the dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dataset</span><span class="p">,</span> <span class="n">count</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">input_dataset</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="n">count</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">SkipNode</span><span class="p">(</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">TakeDataset</span><span class="p">(</span><span class="n">UnionBaseDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The result of applying Take operation to the input Dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_dataset (Dataset): Input Dataset to have elements taken from.</span>
<span class="sd">        count (int): Number of elements to be taken from the dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dataset</span><span class="p">,</span> <span class="n">count</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">input_dataset</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="n">count</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">TakeNode</span><span class="p">(</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ZipDataset</span><span class="p">(</span><span class="n">UnionBaseDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The result of applying Zip operation to the input Dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        datasets (tuple): A tuple of datasets to be zipped together.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If dataset is not an instance of Dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datasets</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">datasets</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">ZipNode</span><span class="p">(</span><span class="n">children</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">is_sync</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">any</span><span class="p">([</span><span class="n">c</span><span class="o">.</span><span class="n">is_sync</span><span class="p">()</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">])</span>


<span class="k">class</span> <span class="nc">ConcatDataset</span><span class="p">(</span><span class="n">UnionBaseDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The result of applying Concat operation to the input Dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        datasets (list): A list of datasets to be concatenated together.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If dataset is not an instance of Dataset.</span>
<span class="sd">        ValueError: If there is no samples in the one of the datasets.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datasets</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">datasets</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Invalid dataset, expected Dataset object, but got </span><span class="si">%s</span><span class="s2">!&quot;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="o">=</span> <span class="n">datasets</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sampler</span> <span class="o">=</span> <span class="n">samplers</span><span class="o">.</span><span class="n">SequentialSampler</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">children_sizes_</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">]</span>
        <span class="n">child_index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children_sizes_</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">item</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;There are no samples in the dataset number </span><span class="si">%d</span><span class="s2">. Please make sure there are &quot;</span>
                                 <span class="s2">&quot;valid samples in the dataset.&quot;</span> <span class="o">%</span> <span class="n">child_index</span><span class="p">)</span>
            <span class="n">child_index</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_children_sizes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">children_sizes_</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># _children_flag_and_nums: A list of pair&lt;int ,int&gt;.The first element of pair is flag that characterizes</span>
        <span class="c1"># whether the dataset is mappable. The second element of pair is length of the dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_children_flag_and_nums</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># _children_start_end_index_: A list of pair&lt;int ,int&gt;.The elements of pair are used to characterize</span>
        <span class="c1"># the valid position of the dataset corresponding to the subscript when sampling</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_children_start_end_index_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">child</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">):</span>
            <span class="n">tem_list</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_children_start_end_index_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tem_list</span><span class="p">)</span>
            <span class="n">dataset_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">children_sizes_</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

            <span class="kn">from</span> <span class="nn">mindspore.dataset.engine.datasets_user_defined</span> <span class="kn">import</span> <span class="n">GeneratorDataset</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">child</span><span class="p">,</span> <span class="n">GeneratorDataset</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">child</span><span class="o">.</span><span class="n">source</span><span class="p">,</span> <span class="s2">&quot;__getitem__&quot;</span><span class="p">):</span>
                <span class="n">dataset_len</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">children_sizes_</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">child</span><span class="p">,</span> <span class="n">MappableDataset</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_children_flag_and_nums</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">dataset_len</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_children_flag_and_nums</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">dataset_len</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">ConcatNode</span><span class="p">(</span><span class="n">children</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sampler</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_children_flag_and_nums</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_children_start_end_index_</span><span class="p">,</span>
                              <span class="bp">self</span><span class="o">.</span><span class="n">_children_sizes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">use_sampler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sampler</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the distributedSampler to concat dataset</span>

<span class="sd">        Args:</span>
<span class="sd">            sampler (Sampler): The sampler to use for the current dataset.</span>
<span class="sd">                Currently supported: DistributedSampler.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If the sampler is not an instance of DistributedSampler</span>
<span class="sd">            ValueError: If the parameter shuffle of sampler is True</span>
<span class="sd">            ValueError: If the parameter NumSamples of sampler is not None.</span>
<span class="sd">            ValueError: If num_shards &lt;=0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sampler</span><span class="p">,</span> <span class="p">(</span><span class="n">samplers</span><span class="o">.</span><span class="n">DistributedSampler</span><span class="p">,</span> <span class="n">samplers</span><span class="o">.</span><span class="n">RandomSampler</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;The parameter </span><span class="si">%s</span><span class="s2"> of concat must be DistributedSampler or RandomSampler!&quot;</span> <span class="o">%</span> <span class="n">sampler</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sampler</span><span class="p">,</span> <span class="n">samplers</span><span class="o">.</span><span class="n">RandomSampler</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">sampler</span><span class="o">.</span><span class="n">replacement</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The parameter replacement of RandomSampler must be False!&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">sampler</span><span class="o">.</span><span class="n">get_num_samples</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The parameter num_samples of RandomSampler is not support to be set!&quot;</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_sampler</span> <span class="o">=</span> <span class="n">sampler</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_children_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">]</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="n">sampler</span><span class="o">.</span><span class="n">is_shuffled</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The parameter shuffle of DistributedSampler must be False!&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">sampler</span><span class="o">.</span><span class="n">num_shards</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The parameter num_shards of DistributedSampler must be positive int!&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">sampler</span><span class="o">.</span><span class="n">get_num_samples</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The parameter num_samples of DistributedSampler is not support to be set!&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_size</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_sampler</span> <span class="o">=</span> <span class="n">sampler</span>
        <span class="n">cumulative_samples_nums</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">child</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">child</span><span class="p">,</span> <span class="s1">&#39;sampler&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">child</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">get_num_samples</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The parameter NumSamples of </span><span class="si">%s</span><span class="s2"> is not support to be set!&quot;</span> <span class="o">%</span> <span class="n">child</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">child</span><span class="p">,</span> <span class="p">(</span><span class="n">BatchDataset</span><span class="p">,</span> <span class="n">PaddedBatchDataset</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;The parameter </span><span class="si">%s</span><span class="s2"> of concat must not be BatchDataset or PaddedBatchDataset!&quot;</span> <span class="o">%</span> <span class="n">child</span><span class="p">)</span>

            <span class="c1"># if child is mappable and the length is greater than 0</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_children_flag_and_nums</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_children_flag_and_nums</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">1</span><span class="p">]:</span>

                <span class="n">tem_value</span> <span class="o">=</span> <span class="n">cumulative_samples_nums</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_children_flag_and_nums</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_children_flag_and_nums</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">num_shards</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">tem_value</span> <span class="o">&lt;</span> <span class="n">sampler</span><span class="o">.</span><span class="n">num_shards</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_children_start_end_index_</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">cumulative_samples_nums</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_children_start_end_index_</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">tem_value</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_children_start_end_index_</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">cumulative_samples_nums</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_children_start_end_index_</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">tem_value</span> <span class="o">%</span> <span class="n">sampler</span><span class="o">.</span><span class="n">num_shards</span>

                <span class="n">tem_sampler</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">sampler</span><span class="p">)</span>
                <span class="n">tem_sampler</span><span class="o">.</span><span class="n">set_offset</span><span class="p">(</span><span class="n">cumulative_samples_nums</span><span class="p">)</span>
                <span class="n">child</span><span class="o">.</span><span class="n">use_sampler</span><span class="p">(</span><span class="n">tem_sampler</span><span class="p">)</span>

            <span class="n">cumulative_samples_nums</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">children_sizes_</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
            <span class="n">cumulative_samples_nums</span> <span class="o">%=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">num_shards</span>


<span class="k">class</span> <span class="nc">RenameDataset</span><span class="p">(</span><span class="n">UnionBaseDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The result of applying Rename operation to the input Dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_dataset (Dataset): Input Dataset to be Renamed.</span>
<span class="sd">        input_columns (Union[str, list[str]]): List of names of the input columns.</span>
<span class="sd">        output_columns (Union[str, list[str]]): List of names of the output columns.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dataset</span><span class="p">,</span> <span class="n">input_columns</span><span class="p">,</span> <span class="n">output_columns</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">input_dataset</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_column_names</span> <span class="o">=</span> <span class="n">to_list</span><span class="p">(</span><span class="n">input_columns</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_column_names</span> <span class="o">=</span> <span class="n">to_list</span><span class="p">(</span><span class="n">output_columns</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">RenameNode</span><span class="p">(</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_column_names</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_column_names</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">to_list</span><span class="p">(</span><span class="n">items</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">items</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">items</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">items</span>


<span class="k">class</span> <span class="nc">ProjectDataset</span><span class="p">(</span><span class="n">UnionBaseDataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The result of applying Project operation to the input Dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_dataset (Dataset): Input Dataset to be Projected.</span>
<span class="sd">        columns (Union[str, list[str]]): List of names of the columns to project.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dataset</span><span class="p">,</span> <span class="n">columns</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">input_dataset</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">to_list</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">ProjectNode</span><span class="p">(</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_ToDevice</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Internal class to handle sending data to device.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">get_debug_mode</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;MindData debugger cannot be used in dataset sink mode. Please manually turn off &quot;</span>
                         <span class="s2">&quot;sink mode and try debugger again.&quot;</span><span class="p">)</span>
        <span class="n">ir_tree</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">api_tree</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_ir_tree</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_runtime_context</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">PythonRuntimeContext</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_runtime_context</span><span class="o">.</span><span class="n">Init</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">ToDevice</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_init_step</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">init_step</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_init_step</span><span class="p">()</span>
            <span class="n">dataset_size</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="o">.</span><span class="n">Init</span><span class="p">(</span><span class="n">ir_tree</span><span class="p">,</span> <span class="n">init_step</span><span class="p">,</span> <span class="n">dataset_size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="o">.</span><span class="n">Init</span><span class="p">(</span><span class="n">ir_tree</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_runtime_context</span><span class="o">.</span><span class="n">AssignConsumer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="p">)</span>

        <span class="n">ITERATORS_LIST</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weakref</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="n">_unset_iterator_cleanup</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">send</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="o">.</span><span class="n">Send</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">stop_send</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        send stop send signal to pipeline, it is used when end of sequence is sent at the epoch end.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="o">.</span><span class="n">StopSend</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">continue_send</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        send continue send signal to pipeline, it is used when end of sequence is sent at the epoch end.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="o">.</span><span class="n">ContinueSend</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_data_info</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get type and shape of current batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="o">.</span><span class="n">GetDataInfo</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_send_info</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        In sink mode, it returns the send information of dataset at this moment.</span>
<span class="sd">        Send information includes number of send batches, time summary of fetching data on host</span>
<span class="sd">        and time summary of sending data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="o">.</span><span class="n">GetSendInfo</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">release</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Manually terminate Device Queue instead of relying on out of scope destruction.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_runtime_context&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_runtime_context</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_to_device&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_runtime_context</span><span class="o">.</span><span class="n">Terminate</span><span class="p">()</span>
                <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_runtime_context</span>

    <span class="k">def</span> <span class="nf">__deepcopy__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memodict</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">get_offload_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">col_names</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get offload model containing removed offload ops from pipeline.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">offload_model</span> <span class="o">=</span> <span class="n">GetOffloadModel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="p">,</span> <span class="n">col_names</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">offload_model</span>

    <span class="k">def</span> <span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">dataset_size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="o">.</span><span class="n">Reset</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">dataset_size</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">TransferDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The result of applying TDT operation to the input Dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_dataset (Dataset): Input Dataset to be transferred.</span>
<span class="sd">        send_epoch_end (bool, optional): Whether to send end of sequence to device or not. Default: ``True``.</span>
<span class="sd">        create_data_info_queue (bool, optional): Whether to create queue which stores</span>
<span class="sd">            types and shapes of data or not. Default: ``False``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If device_type is empty.</span>
<span class="sd">        ValueError: If device_type is not &#39;Ascend&#39;, &#39;GPU&#39; or &#39;CPU&#39;.</span>
<span class="sd">        RuntimeError: If dataset is unknown.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dataset</span><span class="p">,</span> <span class="n">send_epoch_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">create_data_info_queue</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">queue_name</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="n">input_dataset</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">queue_name</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">queue_name</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid1</span><span class="p">())</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;queue_name is newly generated. value is </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">queue_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">queue_name</span> <span class="o">=</span> <span class="n">queue_name</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;queue_name is read from compile cache. value is </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">queue_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device_type</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">get_context</span><span class="p">(</span><span class="s2">&quot;device_target&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">context</span> <span class="k">else</span> <span class="s2">&quot;CPU&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device_id</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">get_context</span><span class="p">(</span><span class="s2">&quot;device_id&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">context</span> <span class="k">else</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_send_epoch_end</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">send_epoch_end</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_create_data_info_queue</span> <span class="o">=</span> <span class="n">create_data_info_queue</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">column_name</span> <span class="o">=</span> <span class="n">input_dataset</span><span class="o">.</span><span class="n">get_col_names</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">total_batch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;__total_batch__&quot;</span><span class="p">):</span>
            <span class="n">total_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">__total_batch__</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">DataQueueNode</span><span class="p">(</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_type</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_id</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_send_epoch_end</span><span class="p">,</span>
                                 <span class="n">total_batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_data_info_queue</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">create_dict_iterator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;TransferDataset is not iterable.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">create_tuple_iterator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">do_copy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;TransferDataset is not iterable.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;TransferDataset is not iterable.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">output_shapes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;TransferDataset does not support obtaining output_shapes.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">output_types</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;TransferDataset does not support obtaining output_types.&quot;</span><span class="p">)</span>

    <span class="nd">@check_to_device_send</span>
    <span class="k">def</span> <span class="nf">send</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Send to device</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">_noop_mode</span><span class="p">():</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span> <span class="o">=</span> <span class="n">_ToDevice</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="o">.</span><span class="n">send</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">stop_send</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="o">.</span><span class="n">stop_send</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">continue_send</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="o">.</span><span class="n">continue_send</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_data_info</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get type and shape of current batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="o">.</span><span class="n">get_data_info</span><span class="p">()</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Calling get_data_info with bad state.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_send_info</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        In sink mode, it returns the send information of dataset at this moment.</span>
<span class="sd">        Send information includes number of send batches, time summary of fetching data on host</span>
<span class="sd">        and time summary of sending data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="o">.</span><span class="n">get_send_info</span><span class="p">()</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Calling get_send_info with bad state, data queue is not initialized.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_offload_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="o">.</span><span class="n">get_offload_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">column_name</span><span class="p">)</span>

        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;get_offload_model, _to_device is None&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">release</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Manually terminate Device Queue instead of relying on out of scope destruction.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">dataset_size</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Reset the dataset pipeline to step: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">step</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;, epoch: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">step</span> <span class="o">//</span> <span class="n">dataset_size</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span><span class="o">.</span><span class="n">_reset</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">dataset_size</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>


<div class="viewcode-block" id="Schema"><a class="viewcode-back" href="../../../../api_python/dataset/mindspore.dataset.Schema.html#mindspore.dataset.Schema">[docs]</a><span class="k">class</span> <span class="nc">Schema</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class to represent a schema of a dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        schema_file (str): Path of the schema file. Default: ``None``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: If schema file failed to load.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import dtype as mstype</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Create schema; specify column name, mindspore.dtype and shape of the column</span>
<span class="sd">        &gt;&gt;&gt; schema = ds.Schema()</span>
<span class="sd">        &gt;&gt;&gt; schema.add_column(name=&#39;col1&#39;, de_type=mstype.int64, shape=[2])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_schema</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">schema_file</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">schema_file</span> <span class="o">=</span> <span class="n">replace_none</span><span class="p">(</span><span class="n">schema_file</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cpp_schema</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">SchemaObj</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">schema_file</span><span class="p">)</span>

<div class="viewcode-block" id="Schema.add_column"><a class="viewcode-back" href="../../../../api_python/dataset/mindspore.dataset.Schema.html#mindspore.dataset.Schema.add_column">[docs]</a>    <span class="nd">@check_add_column</span>
    <span class="k">def</span> <span class="nf">add_column</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">de_type</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add new column to the schema.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): The new name of the column.</span>
<span class="sd">            de_type (str): Data type of the column.</span>
<span class="sd">            shape (list[int], optional): Shape of the column.</span>
<span class="sd">                Default: ``None``, [-1] which is an unknown shape of rank 1.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If column type is unknown.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; from mindspore import dtype as mstype</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; schema = ds.Schema()</span>
<span class="sd">            &gt;&gt;&gt; schema.add_column(&#39;col_1d&#39;, de_type=mstype.int64, shape=[2])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">de_type</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Type</span><span class="p">):</span>
            <span class="n">de_type</span> <span class="o">=</span> <span class="n">mstype_to_detype</span><span class="p">(</span><span class="n">de_type</span><span class="p">)</span>
            <span class="n">col_type</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">de_type</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">col_type</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">cde</span><span class="o">.</span><span class="n">DataType</span><span class="p">(</span><span class="n">de_type</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cpp_schema</span><span class="o">.</span><span class="n">add_column</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">col_type</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cpp_schema</span><span class="o">.</span><span class="n">add_column</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">col_type</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span></div>

<div class="viewcode-block" id="Schema.parse_columns"><a class="viewcode-back" href="../../../../api_python/dataset/mindspore.dataset.Schema.html#mindspore.dataset.Schema.parse_columns">[docs]</a>    <span class="k">def</span> <span class="nf">parse_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parse the columns and add it to self.</span>

<span class="sd">        Args:</span>
<span class="sd">            columns (Union[dict, list[dict], tuple[dict]]): Dataset attribute information, decoded from schema file.</span>

<span class="sd">                - list[dict], `name` and `type` must be in keys, `shape` optional.</span>

<span class="sd">                - dict, columns.keys() as name, columns.values() is dict, and `type` inside, `shape` optional.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: If failed to parse columns.</span>
<span class="sd">            RuntimeError: If column&#39;s name field is missing.</span>
<span class="sd">            RuntimeError: If column&#39;s type field is missing.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from mindspore.dataset import Schema</span>
<span class="sd">            &gt;&gt;&gt; schema = Schema()</span>
<span class="sd">            &gt;&gt;&gt; columns1 = [{&#39;name&#39;: &#39;image&#39;, &#39;type&#39;: &#39;int8&#39;, &#39;shape&#39;: [3, 3]},</span>
<span class="sd">            ...             {&#39;name&#39;: &#39;label&#39;, &#39;type&#39;: &#39;int8&#39;, &#39;shape&#39;: [1]}]</span>
<span class="sd">            &gt;&gt;&gt; schema.parse_columns(columns1)</span>
<span class="sd">            &gt;&gt;&gt; columns2 = {&#39;image&#39;: {&#39;shape&#39;: [3, 3], &#39;type&#39;: &#39;int8&#39;}, &#39;label&#39;: {&#39;shape&#39;: [1], &#39;type&#39;: &#39;int8&#39;}}</span>
<span class="sd">            &gt;&gt;&gt; schema.parse_columns(columns2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cpp_schema</span><span class="o">.</span><span class="n">parse_columns</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span></div>

<div class="viewcode-block" id="Schema.to_json"><a class="viewcode-back" href="../../../../api_python/dataset/mindspore.dataset.Schema.html#mindspore.dataset.Schema.to_json">[docs]</a>    <span class="k">def</span> <span class="nf">to_json</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get a JSON string of the schema.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str, JSON string of the schema.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from mindspore.dataset import Schema</span>
<span class="sd">            &gt;&gt;&gt; from mindspore import dtype as mstype</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; schema = Schema()</span>
<span class="sd">            &gt;&gt;&gt; schema.add_column(&#39;col_1d&#39;, de_type=mstype.int64, shape=[2])</span>
<span class="sd">            &gt;&gt;&gt; json = schema.to_json()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpp_schema</span><span class="o">.</span><span class="n">to_json</span><span class="p">()</span></div>

<div class="viewcode-block" id="Schema.from_json"><a class="viewcode-back" href="../../../../api_python/dataset/mindspore.dataset.Schema.html#mindspore.dataset.Schema.from_json">[docs]</a>    <span class="k">def</span> <span class="nf">from_json</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">json_obj</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get schema file from JSON object.</span>

<span class="sd">        Args:</span>
<span class="sd">            json_obj(dictionary): Object of JSON parsed.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: if there is unknown item in the object.</span>
<span class="sd">            RuntimeError: if dataset type is missing in the object.</span>
<span class="sd">            RuntimeError: if columns are missing in the object.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import json</span>
<span class="sd">            &gt;&gt;&gt; from mindspore.dataset import Schema</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; with open(&quot;/path/to/schema_file&quot;, &quot;r&quot;) as file:</span>
<span class="sd">            ...     json_obj = json.load(file)</span>
<span class="sd">            ...     schema = Schema()</span>
<span class="sd">            ...     schema.from_json(json_obj)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cpp_schema</span><span class="o">.</span><span class="n">from_string</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">json_obj</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span></div>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_json</span><span class="p">()</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">get_num_rows</span><span class="p">(</span><span class="n">schema</span><span class="p">):</span>
        <span class="n">schema_obj</span> <span class="o">=</span> <span class="n">schema</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema_obj</span><span class="p">,</span> <span class="n">Schema</span><span class="p">):</span>
            <span class="n">schema_obj</span> <span class="o">=</span> <span class="n">Schema</span><span class="p">(</span><span class="n">schema_obj</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">schema_obj</span><span class="o">.</span><span class="n">cpp_schema</span><span class="o">.</span><span class="n">get_num_rows</span><span class="p">()</span></div>


<span class="k">class</span> <span class="nc">DeserializedDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_obj</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_obj</span> <span class="o">=</span> <span class="n">input_obj</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">children</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_obj</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">json_str</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_obj</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_json_string</span><span class="p">(</span><span class="n">json_str</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cde</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_json_file</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_obj</span><span class="p">)</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>