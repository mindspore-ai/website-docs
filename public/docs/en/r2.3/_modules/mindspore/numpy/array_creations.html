<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.numpy.array_creations &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script><script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/js/theme.js"></script><script src="../../../_static/underscore.js"></script><script src="../../../_static/doctools.js"></script><script src="../../../_static/js/mermaid-9.3.0.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/programming_paradigm.html">Functional and Object-Oriented Fusion Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/distributed_training_design.html">Distributed Parallel Native</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/all_scenarios.html">Full-scenarios Unified Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../note/official_models.html">Official Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.multiprocessing.html">mindspore.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.experimental.html">mindspore.experimental</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/enveriment_preparation.html">Environment Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/model_development/model_development.html">Network Constructing Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/faq.html">FAQs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Syntax Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../note/static_graph_syntax_support.html">Static Graph Syntax Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../note/static_graph_syntax/operators.html">Static Graph Syntax - Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../note/static_graph_syntax/statements.html">Static Graph Syntax - Python Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../note/static_graph_syntax/python_builtin_functions.html">Static Graph Syntax - Python Built-in Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../note/index_support.html">Tensor Index Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../note/env_var_list.html">Environment Variables</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>mindspore.numpy.array_creations</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for mindspore.numpy.array_creations</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2020-2021 Huawei Technologies Co., Ltd</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ============================================================================</span>
<span class="sd">&quot;&quot;&quot;array operations, the function docs are adapted from Numpy API.&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">operator</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">onp</span>

<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">mindspore.common</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore.common</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">from</span> <span class="nn">mindspore.common.seed</span> <span class="kn">import</span> <span class="n">get_seed</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">mindspore.ops.primitive</span> <span class="kn">import</span> <span class="n">constexpr</span><span class="p">,</span> <span class="n">_primexpr</span>
<span class="kn">from</span> <span class="nn">mindspore.ops.function.random_func</span> <span class="kn">import</span> <span class="n">_get_seed</span>
<span class="kn">from</span> <span class="nn">mindspore.nn.layer.basic</span> <span class="kn">import</span> <span class="n">tril</span> <span class="k">as</span> <span class="n">nn_tril</span>
<span class="kn">from</span> <span class="nn">mindspore.nn.layer.basic</span> <span class="kn">import</span> <span class="n">triu</span> <span class="k">as</span> <span class="n">nn_triu</span>
<span class="kn">from</span> <span class="nn">mindspore._c_expression</span> <span class="kn">import</span> <span class="n">Tensor</span> <span class="k">as</span> <span class="n">Tensor_</span>

<span class="kn">from</span> <span class="nn">mindspore.numpy.utils</span> <span class="kn">import</span> <span class="n">_check_input_for_asarray</span><span class="p">,</span> <span class="n">_deep_list</span><span class="p">,</span> <span class="n">_deep_tensor_to_nparray</span><span class="p">,</span> \
    <span class="n">_check_input_tensor</span><span class="p">,</span> <span class="n">_convert_64_to_32</span><span class="p">,</span> <span class="n">_get_dtype_from_scalar</span><span class="p">,</span> \
    <span class="n">_expand</span><span class="p">,</span> <span class="n">_to_tensor</span><span class="p">,</span> <span class="n">_slice_along_axis</span><span class="p">,</span> <span class="n">_callable</span>
<span class="kn">from</span> <span class="nn">mindspore.numpy.utils_const</span> <span class="kn">import</span> <span class="n">_raise_value_error</span><span class="p">,</span> <span class="n">_empty</span><span class="p">,</span> <span class="n">_max</span><span class="p">,</span> <span class="n">_min</span><span class="p">,</span> \
    <span class="n">_check_same_type</span><span class="p">,</span> <span class="n">_is_shape_empty</span><span class="p">,</span> <span class="n">_check_shape</span><span class="p">,</span> <span class="n">_check_dtype</span><span class="p">,</span> <span class="n">_tile_size</span><span class="p">,</span> <span class="n">_abs</span><span class="p">,</span> \
    <span class="n">_raise_type_error</span><span class="p">,</span> <span class="n">_expanded_shape</span><span class="p">,</span> <span class="n">_check_is_float</span><span class="p">,</span> <span class="n">_iota</span><span class="p">,</span> <span class="n">_type_convert</span><span class="p">,</span> \
    <span class="n">_canonicalize_axis</span><span class="p">,</span> <span class="n">_list_comprehensions</span><span class="p">,</span> <span class="n">_ceil</span><span class="p">,</span> <span class="n">_tuple_slice</span><span class="p">,</span> <span class="n">_raise_unimplemented_error</span><span class="p">,</span> \
    <span class="n">_tuple_setitem</span>
<span class="kn">from</span> <span class="nn">mindspore.numpy.array_ops</span> <span class="kn">import</span> <span class="n">ravel</span><span class="p">,</span> <span class="n">concatenate</span><span class="p">,</span> <span class="n">broadcast_arrays</span><span class="p">,</span> <span class="n">reshape</span><span class="p">,</span> <span class="n">broadcast_to</span><span class="p">,</span> <span class="n">flip</span><span class="p">,</span> \
    <span class="n">apply_along_axis</span><span class="p">,</span> <span class="n">where</span><span class="p">,</span> <span class="n">moveaxis</span>
<span class="kn">from</span> <span class="nn">mindspore.numpy.dtypes</span> <span class="kn">import</span> <span class="n">nan</span><span class="p">,</span> <span class="n">pi</span>

<span class="c1"># According to official numpy reference, the dimension of a numpy array must be less</span>
<span class="c1"># than 32</span>
<span class="n">MAX_NUMPY_DIMS</span> <span class="o">=</span> <span class="mi">32</span>
<span class="c1"># All types that can be accepted as &quot;array_like&quot; parameters in graph mode.</span>
<span class="n">ARRAY_TYPES</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span>

<span class="n">_reduce_min_keepdims</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceMin</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">_reduce_max_keepdims</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceMax</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">_reduce_mean_keepdims</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>


<div class="viewcode-block" id="array"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.array.html#mindspore.numpy.array">[docs]</a><span class="k">def</span> <span class="nf">array</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ndmin</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a tensor.</span>

<span class="sd">    This function creates tensors from an array-like object.</span>

<span class="sd">    Args:</span>
<span class="sd">        obj (Union[int, float, bool, list, tuple]): Input data, in any form that</span>
<span class="sd">            can be converted to a `Tensor`. This includes Tensor, list, tuple and numbers.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.int32, or \&#39;int32\&#39;. If dtype is ``None``, the data type</span>
<span class="sd">            of the new tensor will be inferred from obj. Default is ``None``.</span>
<span class="sd">        copy (bool): If `True`, then the object is copied. Otherwise, a copy will</span>
<span class="sd">            only be made if necessary. Default: ``True``.</span>
<span class="sd">        ndmin (int): Specifies the minimum number of dimensions that the resulting</span>
<span class="sd">            tensor should have. Ones will be pre-pended to the shape as needed to</span>
<span class="sd">            meet this requirement. Default: ``0`` .</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, generated tensor with the specified dtype.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If input `obj` has different sizes at different dimensions.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.array([1,2,3]))</span>
<span class="sd">        [1 2 3]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">asarray</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">ndmin</span> <span class="o">&gt;</span> <span class="n">res</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">res</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;Empty tensor cannot be expanded beyond the current dimension.&quot;</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">_expand</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">ndmin</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">copy</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">copy_</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">dtype</span> <span class="o">!=</span> <span class="n">res</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">res</span></div>


<span class="nd">@constexpr</span>
<span class="k">def</span> <span class="nf">asarray_const</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Converts the input to tensor. Note here `a` cannot be tensor itself.&quot;&quot;&quot;</span>
    <span class="n">_check_input_for_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">bool</span><span class="p">))</span> <span class="ow">and</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">_get_dtype_from_scalar</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="c1"># Convert all tuple/nested tuples to lists</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">_deep_list</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="c1"># Convert all tensor sub-elements to numpy arrays</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">_deep_tensor_to_nparray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">onp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">onp</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;object&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Input array must have the same size across all dimensions.&#39;</span><span class="p">)</span>
        <span class="c1"># If dtype is not specified, we keep consistent with numpy decision</span>
        <span class="c1"># only exceptions are: we use int/float32</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">pytype_to_dtype</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span>
            <span class="k">elif</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">:</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span>
        <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">Tensor_</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">onp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">onp</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;object&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;For Tensor conversion, the input_data is </span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s2"> that contains unsupported element.&quot;</span><span class="p">)</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">pytype_to_dtype</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>


<div class="viewcode-block" id="asarray"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.asarray.html#mindspore.numpy.asarray">[docs]</a><span class="k">def</span> <span class="nf">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts the input to tensor.</span>

<span class="sd">    This function converts tensors from an array-like object.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Union[int, float, bool, list, tuple, Tensor]): Input data, in any form that can</span>
<span class="sd">            be converted to a `Tensor`. This includes Tensor, list, tuple and numbers.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.int32, or \&#39;int32\&#39;. If dtype is ``None``, the data type</span>
<span class="sd">            of the new tensor will be inferred from obj. Default is ``None`` .</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, generated tensor with the specified dtype.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If input `a` has different sizes at different dimensions.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.asarray([1,2,3]))</span>
<span class="sd">        [1 2 3]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">a</span>
        <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">asarray_const</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span></div>


<span class="nd">@constexpr</span>
<span class="k">def</span> <span class="nf">asfarray_const</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Converts the input to tensor. Note here `a` cannot be tensor itself.&quot;&quot;&quot;</span>
    <span class="n">_check_input_for_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="c1"># Convert all tuple/nested tuples to lists</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">_deep_list</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="c1"># Convert all tensor sub-elements to numpy arrays</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">_deep_tensor_to_nparray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">onp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="n">onp</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;object&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;For Tensor conversion, the input_data is </span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s2"> that contains unsupported element.&quot;</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>


<div class="viewcode-block" id="asfarray"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.asfarray.html#mindspore.numpy.asfarray">[docs]</a><span class="k">def</span> <span class="nf">asfarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Similar to asarray, converts the input to a float tensor.</span>

<span class="sd">    If non-float dtype is defined, this function will return a float32 tensor instead.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Union[int, float, bool, list, tuple, Tensor]): Input data, in any form that can</span>
<span class="sd">            be converted to a `Tensor`. This includes Tensor, list, tuple and numbers.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.int32, or \&#39;int32\&#39;. If dtype is ``None``, the data type</span>
<span class="sd">            of the new tensor will be inferred from `a`. Default is ``mstype.float32``.</span>


<span class="sd">    Returns:</span>
<span class="sd">        Tensor, generated tensor with the specified float dtype.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If input `a` has different sizes at different dimensions.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.asfarray([1,2,3]))</span>
<span class="sd">        [1. 2. 3.]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">):</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">asfarray_const</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">copy_</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a tensor copy of the given object.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Union[int, float, bool, list, tuple, Tensor]): Input data, in any form that can</span>
<span class="sd">            be converted to a Tensor. This includes Tensor, list, tuple and numbers.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, has the same data as `a`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input `a` has type not specified above.</span>
<span class="sd">        ValueError: If input `a` has different sizes at different dimensions.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; x = np.ones((2,2))</span>
<span class="sd">        &gt;&gt;&gt; print(np.copy(x))</span>
<span class="sd">        [[1. 1.]</span>
<span class="sd">         [1. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>


<div class="viewcode-block" id="ones"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.ones.html#mindspore.numpy.ones">[docs]</a><span class="k">def</span> <span class="nf">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new tensor of given shape and type, filled with ones.</span>

<span class="sd">    Args:</span>
<span class="sd">        shape (Union[int, tuple, list]): the shape of the new tensor.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype.</span>
<span class="sd">            Default is :class:`mstype.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, with the designated `shape` and `dtype`, filled with ones.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If `shape` entries have values :math:`&lt; 0`.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.ones((2,2)))</span>
<span class="sd">        [[1. 1.]</span>
<span class="sd">        [1. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">_check_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">_is_shape_empty</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="zeros"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.zeros.html#mindspore.numpy.zeros">[docs]</a><span class="k">def</span> <span class="nf">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new tensor of given shape and type, filled with zeros.</span>

<span class="sd">    Args:</span>
<span class="sd">        shape (Union[int, tuple, list]): the shape of the new tensor.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype.</span>
<span class="sd">            Default is :class:`mstype.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, with the designated `shape` and `dtype`, filled with zeros.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If `shape` entries have values :math:`&lt; 0`.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.zeros((2,2)))</span>
<span class="sd">        [[0. 0.]</span>
<span class="sd">        [0. 0.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">_check_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">_is_shape_empty</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="full"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.full.html#mindspore.numpy.full">[docs]</a><span class="k">def</span> <span class="nf">full</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new tensor of given shape and type, filled with `fill_value`.</span>

<span class="sd">    Args:</span>
<span class="sd">        shape (Union[int, tuple(int), list(int)]): Shape of the new tensor, e.g.,</span>
<span class="sd">            :math:`(2, 3)` or :math:`2`.</span>
<span class="sd">        fill_value (Union[int, float, bool, list, tuple]): Scalar or array_like</span>
<span class="sd">            fill value.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype,</span>
<span class="sd">            if `dtype` is ``None``, the data type of the new tensor will be inferred from</span>
<span class="sd">            `fill_value`. Default is ``None``.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, with the designated shape and dtype, filled with `fill_value`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If `shape` has entries &lt; 0.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.full((2,2), True))</span>
<span class="sd">        [[True True]</span>
<span class="sd">        [True True]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">_check_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="n">ARRAY_TYPES</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;fill value should be int, float, bool, list, tuple, Tensor, but got&quot;</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)):</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">_get_dtype_from_scalar</span><span class="p">(</span><span class="n">fill_value</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">fill_value</span><span class="o">.</span><span class="n">dtype</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_shape_empty</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)):</span>
            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">fill_value</span> <span class="o">=</span> <span class="n">asarray_const</span><span class="p">(</span><span class="n">fill_value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">broadcast_to</span><span class="p">(</span><span class="n">fill_value</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
    <span class="c1"># if shape contains zero, use c.Tensor()</span>
    <span class="k">return</span> <span class="n">_convert_64_to_32</span><span class="p">(</span><span class="n">empty_compile</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">))</span></div>


<span class="nd">@_primexpr</span>
<span class="k">def</span> <span class="nf">_generate_shapes</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate shapes for randn and rand.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">shape</span><span class="p">:</span>
        <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">size</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">size</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">size</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;If the length of the argument &#39;shape&#39; is 1, the type of the argument &#39;shape&#39; must be &quot;</span>
                              <span class="s2">&quot;one of [&#39;int&#39;, &#39;list&#39;, &#39;tuple&#39;], but got &quot;</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;If the length of the argument &#39;shape&#39; is &gt; 1, the type of the argument &#39;shape&#39; must &quot;</span>
                                  <span class="s2">&quot;all be int, but got &quot;</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">shape</span>
    <span class="k">return</span> <span class="n">size</span>


<span class="nd">@constexpr</span>
<span class="k">def</span> <span class="nf">_check_rand_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check type for randn and rand&quot;&quot;&quot;</span>
    <span class="n">type_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;float&#39;</span><span class="p">,</span> <span class="s1">&#39;float16&#39;</span><span class="p">,</span> <span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="s1">&#39;float64&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">type_list</span><span class="p">:</span>
            <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;If the argument &#39;dtype&#39; is str, it must be one of [&#39;float&#39;, &#39;float16&#39;, &#39;float32&#39;, &quot;</span>
                               <span class="s2">&quot;&#39;float64&#39;], but got &quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float16</span><span class="p">):</span>
        <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;The argument &#39;dtype&#39; must be &#39;mindspore.float64&#39;, &#39;mindspore.float32&#39; or &quot;</span>
                           <span class="s2">&quot;&#39;mindspore.float16&#39;, but got &quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>


<div class="viewcode-block" id="randn"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.randn.html#mindspore.numpy.randn">[docs]</a><span class="k">def</span> <span class="nf">randn</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new Tensor with given shape and dtype, filled with a sample (or samples)</span>
<span class="sd">    from the standard normal distribution.</span>

<span class="sd">    Args:</span>
<span class="sd">        *shape (Union[int, tuple(int), list(int)]): Shape of the new tensor, e.g.,</span>
<span class="sd">            :math:`(2, 3)` or :math:`2`.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype, it must</span>
<span class="sd">            be float type. Default is :class:`mindspore.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, with the designated shape and dtype, filled with a sample (or samples)</span>
<span class="sd">        from the &quot;standard normal&quot; distribution.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If `dtype` is not float type.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import set_seed</span>
<span class="sd">        &gt;&gt;&gt; set_seed(1)</span>
<span class="sd">        &gt;&gt;&gt; print(np.randn((2,3)))</span>
<span class="sd">        [[ 0.30639967 -0.42438635 -0.20454668]</span>
<span class="sd">        [-0.4287376   1.3054721   0.64747655]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_rand_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">_generate_shapes</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">get_seed</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">seed1</span><span class="p">,</span> <span class="n">seed2</span> <span class="o">=</span> <span class="n">_get_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="s2">&quot;StandardNormal&quot;</span><span class="p">)</span>
        <span class="n">stdnormal</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">StandardNormal</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed1</span><span class="p">,</span> <span class="n">seed2</span><span class="o">=</span><span class="n">seed2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">stdnormal</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">StandardNormal</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">stdnormal</span><span class="p">(</span><span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="rand"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.rand.html#mindspore.numpy.rand">[docs]</a><span class="k">def</span> <span class="nf">rand</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new Tensor with given shape and dtype, filled with random numbers from the</span>
<span class="sd">    uniform distribution on the interval :math:`[0, 1)`.</span>

<span class="sd">    Args:</span>
<span class="sd">        *shape (Union[int, tuple(int), list(int)]): Shape of the new tensor, e.g.,</span>
<span class="sd">            :math:`(2, 3)` or :math:`2`.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype, it must</span>
<span class="sd">            be float type. Default is :class:`mindspore.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, with the designated shape and dtype, filled with random numbers from the</span>
<span class="sd">        uniform distribution on the interval :math:`[0, 1)`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If `dtype` is not float type.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import set_seed</span>
<span class="sd">        &gt;&gt;&gt; set_seed(1)</span>
<span class="sd">        &gt;&gt;&gt; print(np.rand((2,3)))</span>
<span class="sd">        [[4.1702199e-01 9.9718481e-01 7.2032452e-01]</span>
<span class="sd">        [9.3255734e-01 1.1438108e-04 1.2812445e-01]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_rand_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">_generate_shapes</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">get_seed</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">seed1</span><span class="p">,</span> <span class="n">seed2</span> <span class="o">=</span> <span class="n">_get_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="s2">&quot;UniformReal&quot;</span><span class="p">)</span>
        <span class="n">uniformreal</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">UniformReal</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed1</span><span class="p">,</span> <span class="n">seed2</span><span class="o">=</span><span class="n">seed2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">uniformreal</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">UniformReal</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">uniformreal</span><span class="p">(</span><span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="randint"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.randint.html#mindspore.numpy.randint">[docs]</a><span class="k">def</span> <span class="nf">randint</span><span class="p">(</span><span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return random integers from minval (inclusive) to maxval (exclusive). Return random integers from the discrete</span>
<span class="sd">    uniform distribution of the specified dtype in the half-open interval :math:`[minval, maxval)`. If maxval is</span>
<span class="sd">    None (the default), the value range will be :math:`[0, minval)`, in this case, minval must be greater than 0.</span>

<span class="sd">    Args:</span>
<span class="sd">        minval(Union[int]): Start value of interval. The interval includes this value. When `maxval`</span>
<span class="sd">            is ``None``, `minval` must be greater than 0. When `maxval` is not ``None``,</span>
<span class="sd">            `minval` must be less than `maxval`.</span>
<span class="sd">        maxval(Union[int], optional): End value of interval. The interval does not include this value.</span>
<span class="sd">        shape (Union[int, tuple(int)]): Shape of the new tensor, e.g., :math:`(2, 3)` or :math:`2`.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype, it must</span>
<span class="sd">            be int type. Default is :class:`mindspore.int32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, with the designated shape and dtype, filled with random integers from minval (inclusive)</span>
<span class="sd">        to maxval (exclusive).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If input arguments have values not specified above.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import set_seed</span>
<span class="sd">        &gt;&gt;&gt; set_seed(1)</span>
<span class="sd">        &gt;&gt;&gt; print(np.randint(1, 10, (2,3)))</span>
<span class="sd">        [[4 9 7]</span>
<span class="sd">        [9 1 2]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">minval</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;For mindspore.numpy.randint, the type of the argument &#39;minval&#39; must be int, &quot;</span>
                          <span class="s2">&quot;but got &quot;</span><span class="p">,</span> <span class="n">minval</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">maxval</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">minval</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;For mindspore.numpy.randint, the argument &#39;minval&#39; must be &gt; 0 when the argument &quot;</span>
                               <span class="s2">&quot;&#39;maxval&#39; is None, but got &quot;</span><span class="p">,</span> <span class="n">minval</span><span class="p">)</span>
        <span class="n">maxval</span> <span class="o">=</span> <span class="n">minval</span>
        <span class="n">minval</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">maxval</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;For mindspore.numpy.randint, the type of the argument &#39;maxval&#39; must be int, &quot;</span>
                              <span class="s2">&quot;but got &quot;</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">minval</span> <span class="o">&gt;=</span> <span class="n">maxval</span><span class="p">:</span>
            <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;For mindspore.numpy.randint, the value of &#39;minval&#39; must be greater than the &quot;</span>
                               <span class="s2">&quot;value of &#39;maxval&#39;.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">,</span> <span class="s1">&#39;int8&#39;</span><span class="p">,</span> <span class="s1">&#39;int16&#39;</span><span class="p">,</span> <span class="s1">&#39;int32&#39;</span><span class="p">,</span> <span class="s1">&#39;int64&#39;</span><span class="p">):</span>
            <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;For &#39;mindspore.numpy.randint&#39;, if the argument &#39;dtype&#39; is str, it must be one of &quot;</span>
                               <span class="s2">&quot;[&#39;int&#39;, &#39;int8&#39;, &#39;int16&#39;, &#39;int32&#39;, &#39;int64&#39;], but got &quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int16</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int8</span><span class="p">):</span>
        <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;For &#39;mindspore.numpy.randint&#39;, the argument &#39;dtype&#39; must be &#39;mindspore.int64&#39;, &quot;</span>
                           <span class="s2">&quot;&#39;mindspore.int32&#39;, &#39;mindspore.int16&#39; or &#39;mindspore.int8&#39;, but got &quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">_check_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">get_seed</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">seed1</span><span class="p">,</span> <span class="n">seed2</span> <span class="o">=</span> <span class="n">_get_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="s2">&quot;UniformInt&quot;</span><span class="p">)</span>
        <span class="n">uniformint</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">UniformInt</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed1</span><span class="p">,</span> <span class="n">seed2</span><span class="o">=</span><span class="n">seed2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">uniformint</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">UniformInt</span><span class="p">()</span>
    <span class="n">t_min</span> <span class="o">=</span> <span class="n">_type_convert</span><span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">minval</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">t_max</span> <span class="o">=</span> <span class="n">_type_convert</span><span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">maxval</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">uniformint</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">t_min</span><span class="p">,</span> <span class="n">t_max</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="arange"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.arange.html#mindspore.numpy.arange">[docs]</a><span class="k">def</span> <span class="nf">arange</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns evenly spaced values within a given interval.</span>

<span class="sd">    Args:</span>
<span class="sd">        start(Union[int, float]): Start of interval. The interval includes this value.</span>
<span class="sd">            When `stop` is provided as a position argument, `start` must be given, when `stop`</span>
<span class="sd">            is a normal argument, `start` can be optional, and default: ``0`` .</span>
<span class="sd">            Please see additional examples below.</span>
<span class="sd">        stop(Union[int, float], optional): End of interval. The interval does not</span>
<span class="sd">            include this value, except in some cases where `step` is not an integer</span>
<span class="sd">            and floating point round-off affects the length of out.</span>
<span class="sd">        step(Union[int, float], optional): Spacing between values. For any output</span>
<span class="sd">            `out`, this is the distance between two adjacent values, :math:`out[i+1] - out[i]`.</span>
<span class="sd">            The default step size is 1. If `step` is specified as a position argument,</span>
<span class="sd">            `start` must also be given.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype.</span>
<span class="sd">            If dtype is None, the data type of the new tensor will be inferred from start,</span>
<span class="sd">            stop and step. Default: ``None`` .</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor with evenly spaced values.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError(PyNative Mode): If input arguments have types not specified above,</span>
<span class="sd">            or arguments are not given in the correct orders specified above.</span>
<span class="sd">        RuntimeError(Graph Mode): The inputs that lead to TypeError in Pynative Mode</span>
<span class="sd">            will lead to RuntimeError in Graph Mode.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.arange(0, 5, 1))</span>
<span class="sd">        [0 1 2 3 4]</span>
<span class="sd">        &gt;&gt;&gt; print(np.arange(3))</span>
<span class="sd">        [0 1 2]</span>
<span class="sd">        &gt;&gt;&gt; print(np.arange(start=0, stop=3))</span>
<span class="sd">        [0 1 2]</span>
<span class="sd">        &gt;&gt;&gt; print(np.arange(0, stop=3, step=0.5))</span>
<span class="sd">        [0.  0.5 1.  1.5 2.  2.5]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># This implementation was inspired by jax.numpy.arange</span>
    <span class="c1"># infer the dtype</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">_get_dtype_from_scalar</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">stop</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">step</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># (start, stop, step) -&gt; (0, start, 1)</span>
        <span class="n">num</span> <span class="o">=</span> <span class="n">_ceil</span><span class="p">(</span><span class="n">start</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">_iota</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">step</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># (start, stop, step) -&gt; (start, stop, 1)</span>
        <span class="n">num</span> <span class="o">=</span> <span class="n">_ceil</span><span class="p">(</span><span class="n">stop</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">_iota</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span> <span class="o">+</span> <span class="n">start</span>
    <span class="k">elif</span> <span class="n">stop</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># (start, stop, step) -&gt; (0, start, step)</span>
        <span class="n">num</span> <span class="o">=</span> <span class="n">_ceil</span><span class="p">((</span><span class="n">start</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">)</span> <span class="o">/</span> <span class="n">step</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">_iota</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span> <span class="o">*</span> <span class="n">step</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">num</span> <span class="o">=</span> <span class="n">_ceil</span><span class="p">((</span><span class="n">stop</span> <span class="o">-</span> <span class="n">start</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">)</span> <span class="o">/</span> <span class="n">step</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">_iota</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span> <span class="o">*</span> <span class="n">step</span> <span class="o">+</span> <span class="n">start</span>
    <span class="k">return</span> <span class="n">out</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_type_checking_for_xspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;utility parameter checking function for linspace, logspace, geomspace.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">ARRAY_TYPES</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;start should be int, float, bool, list, tuple, Tensor, but got&quot;</span><span class="p">,</span> <span class="n">start</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stop</span><span class="p">,</span> <span class="n">ARRAY_TYPES</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;end should be int, float, bool, list, tuple, Tensor, but got&quot;</span><span class="p">,</span> <span class="n">stop</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">_type_convert</span><span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">start</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stop</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">stop</span> <span class="o">=</span> <span class="n">_type_convert</span><span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">stop</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;num should be an integer, but got &quot;</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">endpoint</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;endpoint should be an boolean, but got &quot;</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span>
    <span class="n">start</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">broadcast_arrays</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span>


<span class="k">def</span> <span class="nf">_compute_shapes</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes shapes for local variables for np.linspace&quot;&quot;&quot;</span>
    <span class="n">bounds_shape</span> <span class="o">=</span> <span class="n">start</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">bounds_shape</span> <span class="o">=</span> <span class="n">_tuple_slice</span><span class="p">(</span><span class="n">bounds_shape</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">_tuple_slice</span><span class="p">(</span><span class="n">bounds_shape</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">iota_shape</span> <span class="o">=</span> <span class="n">_list_comprehensions</span><span class="p">(</span><span class="n">start</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">iota_shape</span> <span class="o">=</span> <span class="n">_tuple_slice</span><span class="p">(</span><span class="n">iota_shape</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">num</span><span class="p">,)</span> <span class="o">+</span> <span class="n">_tuple_slice</span><span class="p">(</span><span class="n">iota_shape</span><span class="p">,</span> <span class="n">axis</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">num_tensor</span> <span class="o">=</span> <span class="n">_type_convert</span><span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">div</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_tensor</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">endpoint</span> <span class="k">else</span> <span class="n">num_tensor</span>
    <span class="k">return</span> <span class="n">bounds_shape</span><span class="p">,</span> <span class="n">iota_shape</span><span class="p">,</span> <span class="n">div</span>


<div class="viewcode-block" id="linspace"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.linspace.html#mindspore.numpy.linspace">[docs]</a><span class="k">def</span> <span class="nf">linspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">retstep</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns evenly spaced values within a given interval.</span>

<span class="sd">    Args:</span>
<span class="sd">        start (Union[int, list(int), tuple(int), tensor]): The starting value of the sequence.</span>
<span class="sd">        stop (Union[int, list(int), tuple(int), tensor]): The end value of the sequence,</span>
<span class="sd">            unless `endpoint` is set to False. In that case, the sequence consists</span>
<span class="sd">            of all but the last of `num + 1` evenly spaced samples, so that `stop`</span>
<span class="sd">            is excluded.  Note that the step size changes when `endpoint` is False.</span>
<span class="sd">        num (int, optional): Number of samples to generate. Default: ``50`` .</span>
<span class="sd">        endpoint (bool, optional): If True, `stop` is the last sample. Otherwise, it is</span>
<span class="sd">            not included. Default: ``True`` .</span>
<span class="sd">        retstep (bool, optional): If True, return (`samples`, `step`), where `step` is</span>
<span class="sd">            the spacing between samples.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype,</span>
<span class="sd">            If `dtype` is None, infer the data type from other input arguments. Default: ``None`` .</span>
<span class="sd">        axis (int, optional): The axis in the result to store the samples. Relevant</span>
<span class="sd">            only if start or stop are array-like. By default, the samples will</span>
<span class="sd">            be along a new axis inserted at the beginning. Use -1 to get an axis at the end.</span>
<span class="sd">            Default: ``0`` .</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, with `num` equally spaced samples in the closed interval</span>
<span class="sd">        :math:`[start, stop]` or the half-open interval :math:`[start, stop)`</span>
<span class="sd">        (depending on whether `endpoint` is True or False).</span>

<span class="sd">        Step, the size of spacing between samples, only returned if `retstep` is True.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.linspace(0, 5, 6))</span>
<span class="sd">        [0. 1. 2. 3. 4. 5.]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># This implementation was inspired by jax.numpy.linspace and numpy.linspace</span>
    <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">_type_checking_for_xspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="n">_canonicalize_axis</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">start</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">retstep</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;retstep should be an boolean, but got &quot;</span><span class="p">,</span> <span class="n">retstep</span><span class="p">)</span>
    <span class="n">bounds_shape</span><span class="p">,</span> <span class="n">iota_shape</span><span class="p">,</span> <span class="n">div</span> <span class="o">=</span> <span class="n">_compute_shapes</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">num</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="p">(</span><span class="n">stop</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">/</span> <span class="n">div</span>
        <span class="c1"># This is similar to how numpy and jax compute linspace</span>
        <span class="n">start_expand</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">bounds_shape</span><span class="p">)</span>
        <span class="n">incremental_expand</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">_iota</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">num</span><span class="p">),</span> <span class="n">iota_shape</span><span class="p">)</span>
        <span class="n">delta_expand</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">bounds_shape</span><span class="p">)</span>
        <span class="n">start_expand</span><span class="p">,</span> <span class="n">incremental_expand</span><span class="p">,</span> <span class="n">delta_expand</span> <span class="o">=</span> <span class="n">broadcast_arrays</span><span class="p">(</span>
            <span class="n">start_expand</span><span class="p">,</span> <span class="n">incremental_expand</span><span class="p">,</span> <span class="n">delta_expand</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">start_expand</span> <span class="o">+</span> <span class="p">(</span><span class="n">incremental_expand</span> <span class="o">*</span> <span class="n">delta_expand</span><span class="p">)</span>
        <span class="c1"># recover endpoint</span>
        <span class="k">if</span> <span class="n">endpoint</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">moveaxis</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">stop</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">moveaxis</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">num</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">nan</span> <span class="k">if</span> <span class="n">endpoint</span> <span class="k">else</span> <span class="n">stop</span> <span class="o">-</span> <span class="n">start</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">bounds_shape</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># num == 0</span>
        <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;cannot support Tensor with num=0.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">retstep</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">out</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">),</span> <span class="n">delta</span>
    <span class="k">return</span> <span class="n">out</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="logspace"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.logspace.html#mindspore.numpy.logspace">[docs]</a><span class="k">def</span> <span class="nf">logspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">base</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns numbers spaced evenly on a log scale.</span>

<span class="sd">    In linear space, the sequence starts at base ** start (base to the power of</span>
<span class="sd">    start) and ends with base ** stop (see endpoint below).</span>

<span class="sd">    Args:</span>
<span class="sd">        start (Union[int, list(int), tuple(int), tensor]): ``base ** start`` is the starting</span>
<span class="sd">            value of the sequence.</span>
<span class="sd">        stop (Union[int, list(int), tuple(int), tensor]): ``base ** stop`` is the final value of</span>
<span class="sd">            the sequence, unless `endpoint` is False. In that case, ``num + 1`` values are spaced</span>
<span class="sd">            over the interval in log-space, of which all but the last (a sequence of length num)</span>
<span class="sd">            are returned.</span>
<span class="sd">        num (int, optional): Number of samples to generate. Default: ``50`` .</span>
<span class="sd">        endpoint (bool, optional): If True, `stop` is the last sample. Otherwise, it is</span>
<span class="sd">            not included. Default: ``True`` .</span>
<span class="sd">        base (Union[int, float], optional): The base of the log space. The step size</span>
<span class="sd">            between the elements in :math:`ln(samples) / ln(base)` (or :math:`log_{base}(samples)`)</span>
<span class="sd">            is uniform. Default: ``10.0`` .</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype.</span>
<span class="sd">            If `dtype` is None, infer the data type from other input arguments. Default: ``None`` .</span>
<span class="sd">        axis (int, optional): The axis in the result to store the samples. Relevant</span>
<span class="sd">            only if start or stop is array-like.  By default, the samples will</span>
<span class="sd">            be along a new axis inserted at the beginning. Use -1 to get an axis at the end.</span>
<span class="sd">            Default: ``0`` .</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, equally spaced on a log scale.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.logspace(0, 5, 6, base=2.0))</span>
<span class="sd">        [ 1.  2.  4.  8. 16. 32.]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># This implementation was inspired by jax.numpy.linspace and numpy.linspace</span>
    <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">_type_checking_for_xspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="n">_canonicalize_axis</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">start</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;base should be a number, but got &quot;</span><span class="p">,</span> <span class="n">base</span><span class="p">)</span>
    <span class="n">linspace_res</span> <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="n">endpoint</span><span class="p">,</span> <span class="n">retstep</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_pow</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">linspace_res</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="geomspace"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.geomspace.html#mindspore.numpy.geomspace">[docs]</a><span class="k">def</span> <span class="nf">geomspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns numbers spaced evenly on a log scale (a geometric progression).</span>

<span class="sd">    This is similar to logspace, but with endpoints specified directly. Each output sample</span>
<span class="sd">    is a constant multiple of the previous.</span>

<span class="sd">    Args:</span>
<span class="sd">        start (Union[int, list(int), tuple(int), tensor]): The starting value of the sequence.</span>
<span class="sd">        stop (Union[int, list(int), tuple(int), tensor]): The final value of the sequence,</span>
<span class="sd">            unless endpoint is False. In that case, num + 1 values are spaced over the</span>
<span class="sd">            interval in log-space, of which all but the last (a sequence of length num) are</span>
<span class="sd">            returned.</span>
<span class="sd">        num (int, optional): Number of samples to generate. Default: ``50`` .</span>
<span class="sd">        endpoint (bool, optional): If True, `stop` is the last sample. Otherwise, it is</span>
<span class="sd">            not included. Default: ``True`` .</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype, can</span>
<span class="sd">            be in format of np.float32, or `float32`.If `dtype` is None, infer the data</span>
<span class="sd">            type from other input arguments. Default: ``None`` .</span>
<span class="sd">        axis (int, optional): The axis in the result to store the samples. Relevant</span>
<span class="sd">            only if start or stop is array-like. By default (0), the samples will</span>
<span class="sd">            be along a new axis inserted at the beginning. Use -1 to get an axis at the end.</span>
<span class="sd">            Default: ``0`` .</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, with samples equally spaced on a log scale.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; output = np.geomspace(1, 256, num=9)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [  1.   2.   4.   8.  16.  32.  64. 128. 256.]</span>
<span class="sd">        &gt;&gt;&gt; output = np.geomspace(1, 256, num=8, endpoint=False)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [  1.   2.   4.   8.  16.  32.  64. 128.]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">_type_checking_for_xspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="n">_canonicalize_axis</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">start</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">root</span> <span class="o">=</span> <span class="n">num</span>
    <span class="k">if</span> <span class="n">endpoint</span><span class="p">:</span>
        <span class="n">root</span> <span class="o">-=</span> <span class="mi">1</span>
    <span class="n">bases</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_pow</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor_div</span><span class="p">(</span><span class="n">stop</span><span class="p">,</span> <span class="n">start</span><span class="p">),</span> <span class="n">asarray_const</span><span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="p">(</span><span class="n">root</span><span class="p">)))</span>
    <span class="n">exponents</span> <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="n">zeros</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">bases</span><span class="p">)),</span> <span class="n">F</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">bases</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">bases</span><span class="p">),</span> <span class="n">root</span><span class="p">),</span>
                         <span class="n">num</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="n">endpoint</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">bases</span><span class="p">)</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span> <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">bases</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">axis</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">axis</span>
    <span class="n">expanded_shape</span> <span class="o">=</span> <span class="n">_tuple_slice</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">_tuple_slice</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">bases</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">bases</span><span class="p">,</span> <span class="n">expanded_shape</span><span class="p">)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">expanded_shape</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_mul</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor_pow</span><span class="p">(</span><span class="n">bases</span><span class="p">,</span> <span class="n">exponents</span><span class="p">),</span> <span class="n">start</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="eye"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.eye.html#mindspore.numpy.eye">[docs]</a><span class="k">def</span> <span class="nf">eye</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.</span>

<span class="sd">    Args:</span>
<span class="sd">        N (int): Number of rows in the output, must be larger than 0.</span>
<span class="sd">        M (int, optional): Number of columns in the output. If is ``None``, default: ``N`` ,</span>
<span class="sd">            if defined, must be larger than 0. Default: ``None``.</span>
<span class="sd">        k (int, optional): Index of the diagonal: ``0`` (the default) refers to the main</span>
<span class="sd">            diagonal, a positive value refers to an upper diagonal, and a negative value</span>
<span class="sd">            to a lower diagonal. Default: ``0`` .</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype.</span>
<span class="sd">            Default: ``mstype.float32`` .</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tensor of shape (N, M). A tensor where all elements are equal to zero,</span>
<span class="sd">        except for the k-th diagonal, whose values are equal to one.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.eye(2, 2))</span>
<span class="sd">        [[1. 0.]</span>
<span class="sd">        [0. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">M</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">N</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;Input tensor dimensions should be integers.&quot;</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">N</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">M</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Fill the shape with any value is fine.</span>
        <span class="k">return</span> <span class="n">full</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>

    <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;=</span> <span class="n">M</span> <span class="ow">or</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="n">N</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">full</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">out_left</span> <span class="o">=</span> <span class="n">full</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">k</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
            <span class="n">out_right</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="n">M</span> <span class="o">-</span> <span class="n">k</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">concatenate</span><span class="p">((</span><span class="n">out_left</span><span class="p">,</span> <span class="n">out_right</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">out_upper</span> <span class="o">=</span> <span class="n">full</span><span class="p">((</span><span class="o">-</span><span class="n">k</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
            <span class="n">out_lower</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">N</span> <span class="o">+</span> <span class="n">k</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">concatenate</span><span class="p">((</span><span class="n">out_upper</span><span class="p">,</span> <span class="n">out_lower</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span></div>


<div class="viewcode-block" id="identity"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.identity.html#mindspore.numpy.identity">[docs]</a><span class="k">def</span> <span class="nf">identity</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the identity tensor.</span>

<span class="sd">    Args:</span>
<span class="sd">        n (int): Number of rows and columns in the output, must be larger than 0.</span>
<span class="sd">        dtype (Union[:class:`mindspore.dtype`, str], optional): Designated tensor dtype,</span>
<span class="sd">            default is `mstype.float32`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tensor of shape `(n, n)`, where all elements are equal to zero,</span>
<span class="sd">        except for the diagonal, whose values are equal to one.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.identity(2))</span>
<span class="sd">        [[1. 0.]</span>
<span class="sd">        [0. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;Input tensor dimensions should be integers.&quot;</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_check_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span></div>


<span class="nd">@constexpr</span>
<span class="k">def</span> <span class="nf">empty_compile</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns an empty Tensor.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Tensor_</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>


<div class="viewcode-block" id="empty"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.empty.html#mindspore.numpy.empty">[docs]</a><span class="k">def</span> <span class="nf">empty</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new array of given shape and type, without initializing</span>
<span class="sd">    entries.</span>

<span class="sd">    Note:</span>
<span class="sd">        Numpy argument `order` is not supported.</span>
<span class="sd">        Object arrays are not supported.</span>

<span class="sd">    Args:</span>
<span class="sd">        shape (Union[int, tuple(int)]): Shape of the empty array, e.g.,</span>
<span class="sd">            (2, 3) or 2.</span>
<span class="sd">        dtype (:class:`mindspore.dtype`, optional): Desired output data-type for the</span>
<span class="sd">            array, e.g, mstype.int8. Default: ``mstype.float32`` .</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, array of uninitialized (arbitrary) data of the given</span>
<span class="sd">        shape and dtype.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input shape or dtype is invalid.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; output = np.empty((2, 3))</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[0. 0. 0.]</span>
<span class="sd">         [0. 0. 0.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_get_shape</span><span class="p">(</span><span class="n">array_like</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns the shape of the array like object.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">array_like</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">array_like</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">return</span> <span class="n">asarray_const</span><span class="p">(</span><span class="n">array_like</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>


<span class="k">def</span> <span class="nf">_get_dtype</span><span class="p">(</span><span class="n">array_like</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns the data type of the array like object.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">array_like</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">array_like</span><span class="o">.</span><span class="n">dtype</span>
    <span class="k">return</span> <span class="n">asarray_const</span><span class="p">(</span><span class="n">array_like</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span>


<span class="k">def</span> <span class="nf">_x_like</span><span class="p">(</span><span class="n">prototype</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">constructor</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a tensor with the same shape and type as prototype,</span>
<span class="sd">    using constructor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prototype</span><span class="p">,</span> <span class="n">ARRAY_TYPES</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;prototype should be int, float, bool, list, tuple, Tensor, but got&quot;</span><span class="p">,</span> <span class="n">prototype</span><span class="p">)</span>
    <span class="n">dtype_out</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="n">shape_out</span> <span class="o">=</span> <span class="n">shape</span>
    <span class="k">if</span> <span class="n">dtype_out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype_out</span> <span class="o">=</span> <span class="n">_get_dtype</span><span class="p">(</span><span class="n">prototype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">shape_out</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape_out</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">shape_out</span><span class="p">:</span>
        <span class="n">shape_out</span> <span class="o">=</span> <span class="n">_get_shape</span><span class="p">(</span><span class="n">prototype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">fill_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">constructor</span><span class="p">(</span><span class="n">shape_out</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">dtype_out</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">constructor</span><span class="p">(</span><span class="n">shape_out</span><span class="p">,</span> <span class="n">dtype_out</span><span class="p">)</span>


<div class="viewcode-block" id="empty_like"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.empty_like.html#mindspore.numpy.empty_like">[docs]</a><span class="k">def</span> <span class="nf">empty_like</span><span class="p">(</span><span class="n">prototype</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new array with the same shape and type as a given array.</span>

<span class="sd">    Note:</span>
<span class="sd">        Input array must have the same size across a dimension.</span>
<span class="sd">        If `prototype` is not a Tensor, dtype is float32 by default if not provided.</span>

<span class="sd">    Args:</span>
<span class="sd">        prototype (Union[Tensor, list, tuple]): The shape and data-type of `prototype`</span>
<span class="sd">            define these same attributes of the returned array.</span>
<span class="sd">        dtype (:class:`mindspore.dtype`, optional): Overrides the data type of the</span>
<span class="sd">            result.</span>
<span class="sd">        shape (int or sequence of ints, optional): Overrides the shape</span>
<span class="sd">            of the result.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, array of uninitialized (arbitrary) data with the same</span>
<span class="sd">        shape and type as `prototype`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If `prototype` is not a Tensor, list or tuple.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; a = np.ones((4,1,2))</span>
<span class="sd">        &gt;&gt;&gt; output = np.empty_like(a)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[[0. 0.]]</span>
<span class="sd">         [[0. 0.]]</span>
<span class="sd">         [[0. 0.]]</span>
<span class="sd">         [[0. 0.]]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_x_like</span><span class="p">(</span><span class="n">prototype</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">empty</span><span class="p">)</span></div>


<div class="viewcode-block" id="ones_like"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.ones_like.html#mindspore.numpy.ones_like">[docs]</a><span class="k">def</span> <span class="nf">ones_like</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns an array of ones with the same shape and type as a given array.</span>

<span class="sd">    Note:</span>
<span class="sd">        Input array must have the same size across a dimension.</span>
<span class="sd">        If `a` is not a Tensor, dtype is float32 by default if not provided.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Union[Tensor, list, tuple]): The shape and data-type of a define these same</span>
<span class="sd">            attributes of the returned array.</span>
<span class="sd">        dtype (:class:`mindspore.dtype`, optional): Overrides the data type of the</span>
<span class="sd">            result.</span>
<span class="sd">        shape (int or sequence of ints, optional): Overrides the shape</span>
<span class="sd">            of the result.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, array of ones with the same shape and type as `a`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If `a` is not a Tensor, list or tuple.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; a = np.ones((4,1,2))</span>
<span class="sd">        &gt;&gt;&gt; output = np.ones_like(a)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[[1. 1.]]</span>
<span class="sd">        [[1. 1.]]</span>
<span class="sd">        [[1. 1.]]</span>
<span class="sd">        [[1. 1.]]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_x_like</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">ones</span><span class="p">)</span></div>


<div class="viewcode-block" id="zeros_like"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.zeros_like.html#mindspore.numpy.zeros_like">[docs]</a><span class="k">def</span> <span class="nf">zeros_like</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns an array of zeros with the same shape and type as a given array.</span>

<span class="sd">    Note:</span>
<span class="sd">        Input array must have the same size across a dimension.</span>
<span class="sd">        If `a` is not a Tensor, dtype is float32 by default if not provided.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Union[Tensor, list, tuple]): The shape and data-type of a define these same</span>
<span class="sd">            attributes of the returned array.</span>
<span class="sd">        dtype (:class:`mindspore.dtype`, optional): Overrides the data type of the</span>
<span class="sd">            result.</span>
<span class="sd">        shape (int or sequence of ints, optional): Overrides the shape</span>
<span class="sd">            of the result.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, array of zeros with the same shape and type as `a`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If `a` is not a Tensor, list or tuple.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; a = np.ones((4,1,2))</span>
<span class="sd">        &gt;&gt;&gt; output = np.zeros_like(a)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[[0. 0.]]</span>
<span class="sd">        [[0. 0.]]</span>
<span class="sd">        [[0. 0.]]</span>
<span class="sd">        [[0. 0.]]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_x_like</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">zeros</span><span class="p">)</span></div>


<div class="viewcode-block" id="full_like"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.full_like.html#mindspore.numpy.full_like">[docs]</a><span class="k">def</span> <span class="nf">full_like</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a full array with the same shape and type as a given array.</span>

<span class="sd">    Note:</span>
<span class="sd">        Input array must have the same size across a dimension.</span>
<span class="sd">        If `a` is not a Tensor, dtype is float32 by default if not provided.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Union[Tensor, list, tuple]): The shape and data-type of `a` define these same</span>
<span class="sd">            attributes of the returned array.</span>
<span class="sd">        fill_value (scalar): Fill value.</span>
<span class="sd">        dtype (:class:`mindspore.dtype`, optional): Overrides the data type of the</span>
<span class="sd">            result.</span>
<span class="sd">        shape (int or sequence of ints, optional): Overrides the shape</span>
<span class="sd">            of the result.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, array of fill_value with the same shape and type as `a`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If `a` is not a Tensor, list or tuple.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; a = np.ones((4,1,2))</span>
<span class="sd">        &gt;&gt;&gt; output = np.full_like(a, 0.5)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[[0.5 0.5]]</span>
<span class="sd">        [[0.5 0.5]]</span>
<span class="sd">        [[0.5 0.5]]</span>
<span class="sd">        [[0.5 0.5]]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_x_like</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">full</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">fill_value</span><span class="p">)</span></div>


<div class="viewcode-block" id="tri"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.tri.html#mindspore.numpy.tri">[docs]</a><span class="k">def</span> <span class="nf">tri</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a tensor with ones at and below the given diagonal and zeros elsewhere.</span>

<span class="sd">    Args:</span>
<span class="sd">        N(int): Number of rows in the array.</span>
<span class="sd">        M(int, optional): Number of columns in the array. By default, `M` is taken</span>
<span class="sd">            equal to N.</span>
<span class="sd">        k(int, optional): The sub-diagonal at and below which the array is filled.</span>
<span class="sd">            :math:`k = 0` is the main diagonal, while :math:`k &lt; 0` is below it, and :math:`k &gt; 0` is above.</span>
<span class="sd">            Default: ``0`` .</span>
<span class="sd">        dtype(:class:`mindspore.dtype`, optional): Data type of the returned array. Default: ``mstype.float32`` .</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor with shape `(N, M)`, with its lower triangle filled with</span>
<span class="sd">        ones and zeros elsewhere; in other words :math:`T[i,j] = 1` for :math:`j &lt;= i + k`,</span>
<span class="sd">        0 otherwise.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; output = np.tri(3, 3, 1)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[1. 1. 0.]</span>
<span class="sd">        [1. 1. 1.]</span>
<span class="sd">        [1. 1. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">M</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">N</span>
    <span class="k">return</span> <span class="n">nn_tril</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span></div>


<span class="nd">@constexpr</span>
<span class="k">def</span> <span class="nf">_device_target</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">context</span><span class="o">.</span><span class="n">get_context</span><span class="p">(</span><span class="s2">&quot;device_target&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="tril"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.tril.html#mindspore.numpy.tril">[docs]</a><span class="k">def</span> <span class="nf">tril</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a lower triangle of a tensor.</span>

<span class="sd">    Returns a copy of a tensor with elements above the `k-th` diagonal zeroed.</span>

<span class="sd">    Args:</span>
<span class="sd">        m (Union[Tensor, list, tuple]): The shape and data-type of `m` define these same</span>
<span class="sd">            attributes of the returned tensor.</span>
<span class="sd">        k (int, optional): Diagonal above which to zero elements. :math:`k = 0` (the default)</span>
<span class="sd">            is the main diagonal, :math:`k &lt; 0` is below it and :math:`k &gt; 0` is above.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Lower triangle of `m`, of same shape and data-type as `m`.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If input `m`\&#39;s rank :math:`&lt; 1`.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; output = np.tril(np.ones((3, 3)))</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[1. 0. 0.]</span>
<span class="sd">        [1. 1. 0.]</span>
<span class="sd">        [1. 1. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">asarray_const</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">device_target</span> <span class="o">=</span> <span class="n">_device_target</span><span class="p">()</span>
    <span class="c1"># check rank</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;input m&#39;s rank should be larger than 0&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">tri</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
    <span class="c1"># Only Ascend hardware will reduce accuracy</span>
    <span class="k">if</span> <span class="n">device_target</span> <span class="o">==</span> <span class="s2">&quot;Ascend&quot;</span><span class="p">:</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">assist</span> <span class="o">=</span> <span class="n">nn_tril</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="c1"># MindSpore binary op do not support bool</span>
    <span class="k">elif</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">mstype</span><span class="o">.</span><span class="n">bool_</span><span class="p">:</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">assist</span> <span class="o">=</span> <span class="n">nn_tril</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">assist</span> <span class="o">=</span> <span class="n">nn_tril</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_mul</span><span class="p">(</span><span class="n">assist</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="triu"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.triu.html#mindspore.numpy.triu">[docs]</a><span class="k">def</span> <span class="nf">triu</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns an upper triangle of a tensor.</span>

<span class="sd">    Returns a copy of a tensor with elements below the `k-th` diagonal zeroed.</span>

<span class="sd">    Args:</span>
<span class="sd">        m (Union[Tensor, list, tuple]): The shape and data-type of `m` define these same</span>
<span class="sd">            attributes of the returned tensor.</span>
<span class="sd">        k (int, optional): Diagonal below which to zero elements. :math:`k = 0` (the default)</span>
<span class="sd">            is the main diagonal, :math:`k &lt; 0` is below it and :math:`k &gt; 0` is above.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Upper triangle of `m`, of same shape and data-type as `m`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input arguments have types not specified above.</span>
<span class="sd">        ValueError: If input `m`\&#39;s rank &lt; 1.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; output = np.triu(np.ones((3, 3)))</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[1. 1. 1.]</span>
<span class="sd">        [0. 1. 1.]</span>
<span class="sd">        [0. 0. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">asarray_const</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">device_target</span> <span class="o">=</span> <span class="n">_device_target</span><span class="p">()</span>
    <span class="c1"># check rank</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;input m&#39;s rank should be larger than 0&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">tri</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">m</span><span class="p">)</span>
    <span class="c1"># Only Ascend hardware will reduce accuracy</span>
    <span class="k">if</span> <span class="n">device_target</span> <span class="o">==</span> <span class="s2">&quot;Ascend&quot;</span><span class="p">:</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">assist</span> <span class="o">=</span> <span class="n">nn_triu</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="c1"># MindSpore binary op do not support bool</span>
    <span class="k">elif</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">mstype</span><span class="o">.</span><span class="n">bool_</span><span class="p">:</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">assist</span> <span class="o">=</span> <span class="n">nn_triu</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">assist</span> <span class="o">=</span> <span class="n">nn_triu</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_mul</span><span class="p">(</span><span class="n">assist</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="diagonal"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.diagonal.html#mindspore.numpy.diagonal">[docs]</a><span class="k">def</span> <span class="nf">diagonal</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns specified diagonals.</span>

<span class="sd">    If `a` is 2-D, returns the diagonal of `a` with the given offset, i.e., the</span>
<span class="sd">    collection of elements of the form ``a[i, i+offset]``. If `a` has more than two</span>
<span class="sd">    dimensions, then the axes specified by `axis1` and `axis2` are used to determine</span>
<span class="sd">    the 2-D sub-array whose diagonal is returned. The shape of the resulting</span>
<span class="sd">    array can be determined by removing `axis1` and `axis2` and appending an index</span>
<span class="sd">    to the right equal to the size of the resulting diagonals.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Tensor): Array from which the diagonals are taken.</span>
<span class="sd">        offset (int, optional): Offset of the diagonal from the main diagonal.</span>
<span class="sd">            Can be positive or negative. Defaults to main diagonal.</span>
<span class="sd">        axis1 (int, optional): Axis to be used as the first axis of the 2-D</span>
<span class="sd">            sub-arrays from which the diagonals should be taken. Defaults to</span>
<span class="sd">            first axis (0).</span>
<span class="sd">        axis2 (int, optional): Axis to be used as the second axis of the 2-D</span>
<span class="sd">            sub-arrays from which the diagonals should be taken. Defaults to</span>
<span class="sd">            second axis.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, if `a` is 2-D, then `a` 1-D array containing the diagonal. If</span>
<span class="sd">        ``a.ndim &gt; 2``, then the dimensions specified by `axis1` and `axis2` are removed,</span>
<span class="sd">        and a new axis inserted at the end corresponding to the diagonal.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If the input tensor has less than two dimensions.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; a = np.arange(4).reshape(2,2).astype(np.float32)</span>
<span class="sd">        &gt;&gt;&gt; print(a)</span>
<span class="sd">        [[0. 1.]</span>
<span class="sd">        [2. 3.]]</span>
<span class="sd">        &gt;&gt;&gt; output = np.diagonal(a)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [0. 3.]</span>
<span class="sd">        &gt;&gt;&gt; output = np.diagonal(a, 1)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [1.]</span>
<span class="sd">        &gt;&gt;&gt; a = np.arange(8).reshape(2, 2, 2).astype(np.float32)</span>
<span class="sd">        &gt;&gt;&gt; print(a)</span>
<span class="sd">        [[[0. 1.]</span>
<span class="sd">        [2. 3.]]</span>
<span class="sd">        [[4. 5.]</span>
<span class="sd">        [6. 7.]]]</span>
<span class="sd">        &gt;&gt;&gt; output = np.diagonal(a, 0, 0, 1)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[0. 6.]</span>
<span class="sd">        [1. 7.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis1</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="n">axis2</span><span class="p">)</span></div>


<div class="viewcode-block" id="trace"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.trace.html#mindspore.numpy.trace">[docs]</a><span class="k">def</span> <span class="nf">trace</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the sum along diagonals of the array.</span>

<span class="sd">    If `a` is 2-D, the sum along its diagonal with the given offset is returned,</span>
<span class="sd">    i.e., the sum of elements ``a[i,i+offset]`` for all `i`.</span>
<span class="sd">    If `a` has more than two dimensions, then the axes specified by `axis1` and</span>
<span class="sd">    `axis2` are used to determine the 2-D sub-arrays whose traces are returned.</span>
<span class="sd">    The shape of the resulting array is the same as that of a with `axis1` and</span>
<span class="sd">    `axis2` removed.</span>

<span class="sd">    Note:</span>
<span class="sd">        On GPU, the supported dtypes are np.float16, and np.float32.</span>
<span class="sd">        On CPU, the supported dtypes are np.float16, np.float32, and np.float64.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Tensor): Array from which the diagonals are taken.</span>
<span class="sd">        offset (int, optional): Offset of the diagonal from the main diagonal.</span>
<span class="sd">            Can be positive or negative. Defaults to main diagonal.</span>
<span class="sd">        axis1 (int, optional): Axis to be used as the first axis of the 2-D</span>
<span class="sd">            sub-arrays from which the diagonals should be taken. Defaults to</span>
<span class="sd">            first axis (0).</span>
<span class="sd">        axis2 (int, optional): Axis to be used as the second axis of the 2-D</span>
<span class="sd">            sub-arrays from which the diagonals should be taken. Defaults to</span>
<span class="sd">            second axis.</span>
<span class="sd">        dtype (:class:`mindspore.dtype`, optional): Default: ``None`` . Overrides the dtype of the</span>
<span class="sd">            output Tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, sum_along_diagonals. If `a` is 2-D, the sum along the diagonal</span>
<span class="sd">        is returned. If `a` has larger dimensions, then an array of sums along</span>
<span class="sd">        diagonals is returned.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If the input tensor has less than two dimensions.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; output = np.trace(np.eye(3))</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        3.0</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis1</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="n">axis2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_index</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cartesian</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;If cartesian=True, index 0 is swapped with index 1.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">cartesian</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">size</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">i</span>


<div class="viewcode-block" id="meshgrid"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.meshgrid.html#mindspore.numpy.meshgrid">[docs]</a><span class="k">def</span> <span class="nf">meshgrid</span><span class="p">(</span><span class="o">*</span><span class="n">xi</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">indexing</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns coordinate matrices from coordinate vectors.</span>

<span class="sd">    Make `N-D` coordinate arrays for vectorized evaluations of `N-D`</span>
<span class="sd">    scalar/vector fields over `N-D` grids, given one-dimensional</span>
<span class="sd">    coordinate arrays `x1, x2,, xn`.</span>

<span class="sd">    Note:</span>
<span class="sd">        Numpy argument copy is not supported, and a copy is always</span>
<span class="sd">        returned.</span>

<span class="sd">    Args:</span>
<span class="sd">        *xi (Tensor): 1-D arrays representing the coordinates</span>
<span class="sd">            of a grid.</span>
<span class="sd">        indexing (&#39;xy&#39;, &#39;ij&#39;, optional): Cartesian (&#39;xy&#39;, default) or</span>
<span class="sd">            matrix (&#39;ij&#39;) indexing of output. In the 2-D case with</span>
<span class="sd">            inputs of length `M` and `N`, the outputs are of shape `(N, M)`</span>
<span class="sd">            for &#39;xy&#39; indexing and `(M, N)` for &#39;ij&#39; indexing. In the 3-D</span>
<span class="sd">            case with inputs of length `M`, `N` and `P`, outputs are of shape</span>
<span class="sd">            `(N, M, P)` for &#39;xy&#39; indexing and `(M, N, P)` for &#39;ij&#39; indexing.</span>
<span class="sd">        sparse (bool, optional): If True a sparse grid is returned in</span>
<span class="sd">            order to conserve memory. Default is False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple of tensors, for vectors `x1, x2,, xn` with lengths</span>
<span class="sd">        ``Ni=len(xi)``, return `(N1, N2, N3,...Nn)` shaped arrays if</span>
<span class="sd">        ``indexing=&#39;ij&#39;`` or `(N2, N1, N3,...Nn)` shaped arrays if</span>
<span class="sd">        ``indexing=&#39;xy&#39;`` with the elements of `xi` repeated to fill the matrix</span>
<span class="sd">        along the first dimension for `x1`, the second for `x2` and so on.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input is not a tensor, or sparse is not boolean, or</span>
<span class="sd">            indexing is not &#39;xy&#39; or &#39;ij&#39;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; x = np.linspace(0, 1, 3)</span>
<span class="sd">        &gt;&gt;&gt; y = np.linspace(0, 1, 2)</span>
<span class="sd">        &gt;&gt;&gt; xv, yv = np.meshgrid(x, y)</span>
<span class="sd">        &gt;&gt;&gt; print(xv)</span>
<span class="sd">        [[0.  0.5 1. ]</span>
<span class="sd">        [0.  0.5 1. ]]</span>
<span class="sd">        &gt;&gt;&gt; print(yv)</span>
<span class="sd">        [[0.  0.  0.]</span>
<span class="sd">        [1.  1.  1.]]</span>
<span class="sd">        &gt;&gt;&gt; xv, yv = np.meshgrid(x, y, sparse=True)</span>
<span class="sd">        &gt;&gt;&gt; print(xv)</span>
<span class="sd">        [[0.  0.5  1. ]]</span>
<span class="sd">        &gt;&gt;&gt; print(yv)</span>
<span class="sd">        [[0.]</span>
<span class="sd">        [1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_input_tensor</span><span class="p">(</span><span class="o">*</span><span class="n">xi</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sparse</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s1">&#39;argument sparse should be boolean&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">indexing</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="s1">&#39;ij&#39;</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;Valid values for `indexing` are &#39;xy&#39; and &#39;ij&#39;.&quot;</span><span class="p">)</span>

    <span class="n">shape_out</span> <span class="o">=</span> <span class="p">()</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xi</span><span class="p">:</span>
        <span class="n">shape_out</span> <span class="o">+=</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">,)</span>
    <span class="k">if</span> <span class="n">_is_shape_empty</span><span class="p">(</span><span class="n">shape_out</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ones</span><span class="p">(</span><span class="n">shape_out</span><span class="p">)</span>

    <span class="n">grids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xi</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">grids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">grids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ravel</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">grids</span><span class="p">)</span>

    <span class="n">cartesian</span> <span class="o">=</span> <span class="n">indexing</span> <span class="o">==</span> <span class="s1">&#39;xy&#39;</span>
    <span class="n">shape_out</span> <span class="o">=</span> <span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">grids</span><span class="p">)):</span>
        <span class="n">grid_index</span> <span class="o">=</span> <span class="n">_index</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">ndim</span><span class="p">,</span> <span class="n">cartesian</span><span class="o">=</span><span class="n">cartesian</span><span class="p">)</span>
        <span class="n">shape_out</span> <span class="o">+=</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">grids</span><span class="p">[</span><span class="n">grid_index</span><span class="p">])[</span><span class="mi">0</span><span class="p">],)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">grids</span><span class="p">):</span>
        <span class="n">grid_index</span> <span class="o">=</span> <span class="n">_index</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">ndim</span><span class="p">,</span> <span class="n">cartesian</span><span class="o">=</span><span class="n">cartesian</span><span class="p">)</span>
        <span class="n">shape_expanded</span> <span class="o">=</span> <span class="n">_expanded_shape</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="n">shape_out</span><span class="p">[</span><span class="n">grid_index</span><span class="p">],</span> <span class="n">grid_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape_expanded</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">sparse</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">_tile_size</span><span class="p">(</span><span class="n">shape_expanded</span><span class="p">,</span> <span class="n">shape_out</span><span class="p">,</span> <span class="n">ndim</span><span class="p">))</span>
        <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>


<span class="k">class</span> <span class="nc">NdGrid</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Construct a multi-dimensional &quot;meshgrid&quot;.</span>

<span class="sd">    ``grid = NdGrid()`` creates an instance which will return a mesh-grid</span>
<span class="sd">    when indexed.</span>
<span class="sd">    If instantiated with an argument of ``sparse=True``, the mesh-grid is</span>
<span class="sd">    open (or not fleshed out) so that only one-dimension of each</span>
<span class="sd">    returned argument is greater than 1.</span>

<span class="sd">    Args:</span>
<span class="sd">        sparse (bool): Whether the grid is sparse or not. Default is</span>
<span class="sd">            False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor or tuple of tensor, a meshgrid. If ``sparse=False``, returns</span>
<span class="sd">        tensors are all of the same dimensions; and if ``sparse=True``,</span>
<span class="sd">        returns tensors with only one dimension not equal to `1`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span> <span class="o">=</span> <span class="n">sparse</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keys</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
            <span class="n">keys</span> <span class="o">=</span> <span class="p">(</span><span class="n">keys</span><span class="p">,)</span>

        <span class="n">xi</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">stop</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">_raise_type_error</span><span class="p">(</span><span class="s1">&#39;slice indices must be integers&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">step</span><span class="p">:</span>
                <span class="n">step</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">step</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">step</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="nb">complex</span><span class="p">):</span>
                <span class="n">v</span> <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">k</span><span class="o">.</span><span class="n">stop</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">step</span><span class="p">)))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">v</span> <span class="o">=</span> <span class="n">arange</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">k</span><span class="o">.</span><span class="n">stop</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="n">xi</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="n">grids</span> <span class="o">=</span> <span class="n">meshgrid</span><span class="p">(</span><span class="o">*</span><span class="n">xi</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sparse</span><span class="p">,</span> <span class="n">indexing</span><span class="o">=</span><span class="s1">&#39;ij&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">grids</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">grids</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">grids</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">grids</span><span class="p">,</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor_</span><span class="p">)):</span>
            <span class="k">return</span> <span class="n">grids</span>
        <span class="n">expanded</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">grid</span> <span class="ow">in</span> <span class="n">grids</span><span class="p">:</span>
            <span class="n">expanded</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">expanded</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">res</span>


<span class="k">class</span> <span class="nc">MGridClass</span><span class="p">(</span><span class="n">NdGrid</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    mgrid is an :class:`NdGrid` instance with ``sparse=False``.</span>

<span class="sd">    The dimension and number of the output arrays are equal to the number</span>
<span class="sd">    of indexing dimensions. If the step length is not a complex number,</span>
<span class="sd">    then the stop is not inclusive. However, if the step length is a complex</span>
<span class="sd">    number (e.g. 5j), then the integer part of its magnitude is interpreted</span>
<span class="sd">    as specifying the number of points to create between the start and</span>
<span class="sd">    stop values, where the stop value is inclusive.</span>

<span class="sd">    Note:</span>
<span class="sd">        Not supported in graph mode.</span>
<span class="sd">        Unlike Numpy, if the step length is a complex number with a real</span>
<span class="sd">        component, the step length is handled as equivalent to</span>
<span class="sd">        ``int(abs(step))``.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor or tuple of tensor, a meshgrid.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If slicing indices are not integers.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; output = np.mgrid[0:5, 0:5]</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[[0 0 0 0 0]</span>
<span class="sd">        [1 1 1 1 1]</span>
<span class="sd">        [2 2 2 2 2]</span>
<span class="sd">        [3 3 3 3 3]</span>
<span class="sd">        [4 4 4 4 4]]</span>
<span class="sd">        [[0 1 2 3 4]</span>
<span class="sd">        [0 1 2 3 4]</span>
<span class="sd">        [0 1 2 3 4]</span>
<span class="sd">        [0 1 2 3 4]</span>
<span class="sd">        [0 1 2 3 4]]]</span>
<span class="sd">        &gt;&gt;&gt; output = mgrid[-1:1:5j]</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [-1.  -0.5  0.   0.5  1. ]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MGridClass</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">OGridClass</span><span class="p">(</span><span class="n">NdGrid</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ogrid is an :class:`NdGrid` instance with ``sparse=True``.</span>

<span class="sd">    The dimension and number of the output arrays are equal to the number</span>
<span class="sd">    of indexing dimensions. If the step length is not a complex number,</span>
<span class="sd">    then the stop is not inclusive. However, if the step length is a complex</span>
<span class="sd">    number (e.g. 5j), then the integer part of its magnitude is interpreted</span>
<span class="sd">    as specifying the number of points to create between the start and</span>
<span class="sd">    stop values, where the stop value is inclusive.</span>

<span class="sd">    Note:</span>
<span class="sd">        Not supported in graph mode.</span>
<span class="sd">        Unlike Numpy, if the step length is a complex number with a real</span>
<span class="sd">        component, the step length is handled as equivalent to</span>
<span class="sd">        ``int(abs(step))``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If slicing indices are not integers.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; output = np.ogrid[0:5,0:5]</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [Tensor(shape=[5, 1], dtype=Int32, value=</span>
<span class="sd">        [[0],</span>
<span class="sd">        [1],</span>
<span class="sd">        [2],</span>
<span class="sd">        [3],</span>
<span class="sd">        [4]]), Tensor(shape=[1, 5], dtype=Int32, value=</span>
<span class="sd">        [[0, 1, 2, 3, 4]])]</span>
<span class="sd">        &gt;&gt;&gt; output = ogrid[-1:1:5j]</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [-1.  -0.5  0.   0.5  1. ]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OGridClass</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="n">mgrid</span> <span class="o">=</span> <span class="n">MGridClass</span><span class="p">()</span>

<span class="n">ogrid</span> <span class="o">=</span> <span class="n">OGridClass</span><span class="p">()</span>


<div class="viewcode-block" id="diag"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.diag.html#mindspore.numpy.diag">[docs]</a><span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extracts a diagonal or construct a diagonal array.</span>

<span class="sd">    Args:</span>
<span class="sd">        v (Tensor): If `v` is a 2-D array, return a copy of its `k-th` diagonal.</span>
<span class="sd">            If `v` is a 1-D array, return a 2-D array with v on the `k-th` diagonal.</span>
<span class="sd">        k (int, optional): Diagonal in question. The default is 0. Use ``k&gt;0`` for</span>
<span class="sd">            diagonals above the main diagonal, and ``k&lt;0`` for diagonals below the</span>
<span class="sd">            main diagonal.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, the extracted diagonal or constructed diagonal array.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If input is not 1-D or 2-D.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; x = np.arange(9).reshape((3,3))</span>
<span class="sd">        &gt;&gt;&gt; print(x)</span>
<span class="sd">        [[0 1 2]</span>
<span class="sd">        [3 4 5]</span>
<span class="sd">        [6 7 8]]</span>
<span class="sd">        &gt;&gt;&gt; output = np.diag(x)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [0 4 8]</span>
<span class="sd">        &gt;&gt;&gt; output = np.diag(x, k=1)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [1 5]</span>
<span class="sd">        &gt;&gt;&gt; output = np.diag(x, k=-1)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [3 7]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">diagflat</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">_is_shape_empty</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">_empty</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
        <span class="n">e</span> <span class="o">=</span> <span class="n">eye</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">k</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="n">prod</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_mul</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>

        <span class="n">cast_type</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_is_float</span><span class="p">(</span><span class="n">dtype</span><span class="p">):</span>
            <span class="c1"># reduce sum only supports float types</span>
            <span class="n">cast_type</span> <span class="o">=</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span>
            <span class="n">prod</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">prod</span><span class="p">,</span> <span class="n">cast_type</span><span class="p">)</span>

        <span class="n">res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">prod</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="n">_max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="n">k</span><span class="p">):</span> <span class="n">_min</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">_max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">k</span><span class="p">))]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_same_type</span><span class="p">(</span><span class="n">cast_type</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">res</span>
    <span class="k">return</span> <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;Input must be 1- or 2-d.&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="diagflat"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.diagflat.html#mindspore.numpy.diagflat">[docs]</a><span class="k">def</span> <span class="nf">diagflat</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a two-dimensional array with the flattened input as a diagonal.</span>

<span class="sd">    Note:</span>
<span class="sd">        On GPU, the supported dtypes are np.float16, and np.float32.</span>

<span class="sd">    Args:</span>
<span class="sd">        v (Tensor): Input data, which is flattened and set as the `k-th` diagonal</span>
<span class="sd">            of the output.</span>
<span class="sd">        k (int, optional): Diagonal to set; 0, the default, corresponds to the</span>
<span class="sd">            &quot;main&quot; diagonal, a positive (negative) `k` giving the number of the</span>
<span class="sd">            diagonal above (below) the main.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, The 2-D output array.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input is not a tensor.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; output = np.diagflat(np.asarray([[1,2], [3,4]]))</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[1 0 0 0]</span>
<span class="sd">        [0 2 0 0]</span>
<span class="sd">        [0 0 3 0]</span>
<span class="sd">        [0 0 0 4]]</span>
<span class="sd">        &gt;&gt;&gt; output = np.diagflat(np.asarray([1,2]), 1)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        [[0 1 0]</span>
<span class="sd">        [0 0 2]</span>
<span class="sd">        [0 0 0]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_input_tensor</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">k_abs</span> <span class="o">=</span> <span class="n">_abs</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">_is_shape_empty</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">v</span><span class="p">)):</span>
        <span class="k">return</span> <span class="n">zeros</span><span class="p">((</span><span class="n">k_abs</span><span class="p">,</span> <span class="n">k_abs</span><span class="p">),</span> <span class="n">dtype</span><span class="p">)</span>

    <span class="n">v</span> <span class="o">=</span> <span class="n">ravel</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">v</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">eye</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_mul</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">pad_y</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">((</span><span class="n">size</span><span class="p">,</span> <span class="n">k_abs</span><span class="p">),</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="n">pad_x</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">((</span><span class="n">k_abs</span><span class="p">,</span> <span class="n">size</span> <span class="o">+</span> <span class="n">k_abs</span><span class="p">),</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">((</span><span class="n">res</span><span class="p">,</span> <span class="n">pad_y</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">((</span><span class="n">pad_x</span><span class="p">,</span> <span class="n">res</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">((</span><span class="n">pad_y</span><span class="p">,</span> <span class="n">res</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">((</span><span class="n">res</span><span class="p">,</span> <span class="n">pad_x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="diag_indices"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.diag_indices.html#mindspore.numpy.diag_indices">[docs]</a><span class="k">def</span> <span class="nf">diag_indices</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the indices to access the main diagonal of an array.</span>

<span class="sd">    This returns a tuple of indices that can be used to access the main</span>
<span class="sd">    diagonal of an array a with ``a.ndim &gt;= 2`` dimensions and shape `(n, n, , n)`.</span>
<span class="sd">    For ``a.ndim = 2`` this is the usual diagonal, for ``a.ndim &gt; 2`` this is the set</span>
<span class="sd">    of indices to access ``a[i, i, ..., i]`` for ``i = [0..n-1]``.</span>

<span class="sd">    Args:</span>
<span class="sd">        n (int): The size, along each dimension, of the arrays for which</span>
<span class="sd">            the returned indices can be used.</span>
<span class="sd">        ndim (int, optional): The number of dimensions.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple of Tensor.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input are not integers.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; output = np.diag_indices(5, 3)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">        (Tensor(shape=[5], dtype=Int32, value= [0, 1, 2, 3, 4]),</span>
<span class="sd">        Tensor(shape=[5], dtype=Int32, value= [0, 1, 2, 3, 4]),</span>
<span class="sd">        Tensor(shape=[5], dtype=Int32, value= [0, 1, 2, 3, 4]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s1">&#39;input must be integers&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_list_comprehensions</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="n">n</span><span class="p">),</span> <span class="kc">True</span><span class="p">)</span></div>


<div class="viewcode-block" id="ix_"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.ix_.html#mindspore.numpy.ix_">[docs]</a><span class="k">def</span> <span class="nf">ix_</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs an open mesh from multiple sequences.</span>

<span class="sd">    This function takes `N` 1-D sequences and returns `N` outputs with `N`</span>
<span class="sd">    dimensions each, such that the shape is 1 in all but one dimension</span>
<span class="sd">    and the dimension with the non-unit shape value cycles through all</span>
<span class="sd">    N dimensions.</span>
<span class="sd">    Using ix\_ one can quickly construct index arrays that will index</span>
<span class="sd">    the cross product. ``a[np.ix_([1,3],[2,5])]`` returns the array</span>
<span class="sd">    ``[[a[1,2] a[1,5]], [a[3,2] a[3,5]]]``.</span>

<span class="sd">    Note:</span>
<span class="sd">        Boolean masks are not supported.</span>

<span class="sd">    Args:</span>
<span class="sd">        *args (Tensor): 1-D sequences.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple of Tensor, `N` arrays with `N` dimensions each, with `N` the</span>
<span class="sd">        number of input sequences. Together these arrays form an open</span>
<span class="sd">        mesh.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input is not a tensor.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; ixgrid = np.ix_(np.array([0, 1]), np.array([2, 4]))</span>
<span class="sd">        &gt;&gt;&gt; print(ixgrid)</span>
<span class="sd">        (Tensor(shape=[2, 1], dtype=Int32, value=</span>
<span class="sd">        [[0],</span>
<span class="sd">        [1]]), Tensor(shape=[1, 2], dtype=Int32, value=</span>
<span class="sd">        [[2, 4]]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_input_tensor</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">arr</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_raise_value_error</span><span class="p">(</span><span class="s1">&#39;Cross index must be 1 dimensional&#39;</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">+=</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">_expanded_shape</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="n">arr</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">i</span><span class="p">)),)</span>
    <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="vander"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.vander.html#mindspore.numpy.vander">[docs]</a><span class="k">def</span> <span class="nf">vander</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">increasing</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates a Vandermonde matrix.</span>

<span class="sd">    The columns of the output matrix are powers of the input vector. The order of</span>
<span class="sd">    the powers is determined by the increasing boolean argument. Specifically, when</span>
<span class="sd">    increasing is `False`, the i-th output column is the input vector raised element-wise</span>
<span class="sd">    to the power of :math:`N - i - 1`. Such a matrix with a geometric progression in each row</span>
<span class="sd">    is named for Alexandre-Theophile Vandermonde.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (Union[list, tuple, Tensor]): 1-D input array.</span>
<span class="sd">        N (int, optional): Number of columns in the output. If N is not specified, a</span>
<span class="sd">            square array is returned (``N = len(x)``).</span>
<span class="sd">        increasing (bool, optional): Order of the powers of the columns. If True, the</span>
<span class="sd">            powers increase from left to right, if False (the default) they are reversed.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Vandermonde matrix. If `increasing` is `False`, the first column is :math:`x^{(N-1)}`,</span>
<span class="sd">        the second :math:`x^{(N-2)}` and so forth. If `increasing` is `True`, the columns are</span>
<span class="sd">        :math:`x^0, x^1, ..., x^{(N-1)}`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If inputs have types not specified above.</span>
<span class="sd">        ValueError: If `x` is not 1-D, or `N` &lt; 0.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.vander([1., 2., 3., 4., 5.]))</span>
<span class="sd">        [[  1.   1.   1.   1.   1.]</span>
<span class="sd">         [ 16.   8.   4.   2.   1.]</span>
<span class="sd">         [ 81.  27.   9.   3.   1.]</span>
<span class="sd">         [256.  64.  16.   4.   1.]</span>
<span class="sd">         [625. 125.  25.   5.   1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">asarray_const</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;Input x must be list, tuple or Tensor, but got &quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;Input x must be 1-D, but got dimension=&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">N</span> <span class="ow">or</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;Input N must be an integer.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">N</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;Input N must &gt; 0.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">increasing</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s2">&quot;increasing must be a bool.&quot;</span><span class="p">)</span>
    <span class="n">exponent</span> <span class="o">=</span> <span class="n">_iota</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">increasing</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">exponent</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">exponent</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor_pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">exponent</span><span class="p">)</span></div>


<div class="viewcode-block" id="indices"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.indices.html#mindspore.numpy.indices">[docs]</a><span class="k">def</span> <span class="nf">indices</span><span class="p">(</span><span class="n">dimensions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns an array representing the indices of a grid.</span>

<span class="sd">    Computes an array where the subarrays contain index values 0, 1, </span>
<span class="sd">    varying only along the corresponding axis.</span>

<span class="sd">    Args:</span>
<span class="sd">        dimensions (tuple or list of ints): The shape of the grid.</span>
<span class="sd">        dtype (:class:`mindspore.dtype`, optional): Data type of the result.</span>
<span class="sd">        sparse (boolean, optional): Default: ``False`` . Return a sparse</span>
<span class="sd">            representation of the grid instead of a dense representation.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor or tuple of Tensor, If `sparse` is False, returns one array</span>
<span class="sd">        of grid indices, ``grid.shape = (len(dimensions),) + tuple(dimensions)``.</span>
<span class="sd">        If sparse is True, returns a tuple of arrays, with</span>
<span class="sd">        ``grid[i].shape = (1, ..., 1, dimensions[i], 1, ..., 1)`` with</span>
<span class="sd">        ``dimensions[i]`` in the `ith` place</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input dimensions is not a tuple or list.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; grid = np.indices((2, 3))</span>
<span class="sd">        &gt;&gt;&gt; print(grid)</span>
<span class="sd">        [Tensor(shape=[2, 3], dtype=Int32, value=</span>
<span class="sd">        [[0, 0, 0],</span>
<span class="sd">        [1, 1, 1]]), Tensor(shape=[2, 3], dtype=Int32, value=</span>
<span class="sd">        [[0, 1, 2],</span>
<span class="sd">        [0, 1, 2]])]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dimensions</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s1">&#39;Shape of the grid must be tuple or list&#39;</span><span class="p">)</span>
    <span class="n">grids</span> <span class="o">=</span> <span class="p">()</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">dimensions</span><span class="p">:</span>
        <span class="n">grids</span> <span class="o">+=</span> <span class="p">(</span><span class="n">arange</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),)</span>
    <span class="k">return</span> <span class="n">meshgrid</span><span class="p">(</span><span class="o">*</span><span class="n">grids</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="n">sparse</span><span class="p">,</span> <span class="n">indexing</span><span class="o">=</span><span class="s1">&#39;ij&#39;</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_check_window_size</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns True if window size is greater than 1.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">_raise_type_error</span><span class="p">(</span><span class="s1">&#39;the number fo points should be an int&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">1</span>


<div class="viewcode-block" id="bartlett"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.bartlett.html#mindspore.numpy.bartlett">[docs]</a><span class="k">def</span> <span class="nf">bartlett</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the Bartlett window.</span>
<span class="sd">    The Bartlett window is very similar to a triangular window, except that the</span>
<span class="sd">    end points are at zero. It is often used in signal processing for tapering a</span>
<span class="sd">    signal, without generating too much ripple in the frequency domain.</span>

<span class="sd">    Args:</span>
<span class="sd">        M (int): Number of points in the output window. If zero or less, an empty</span>
<span class="sd">            array is returned.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, the triangular window, with the maximum value normalized to one</span>
<span class="sd">        (the value one appears only if the number of samples is odd), with the</span>
<span class="sd">        first and last samples equal to zero.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `M` is not an int.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.bartlett(12))</span>
<span class="sd">        [0.         0.18181819 0.36363637 0.5454545  0.72727275 0.9090909</span>
<span class="sd">        0.9090909  0.72727275 0.5454545  0.36363637 0.18181819 0.        ]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_window_size</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ones</span><span class="p">(</span><span class="n">_max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">M</span><span class="p">))</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">_iota</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
    <span class="n">m_minus_one</span> <span class="o">=</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="n">M</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">F</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">_to_tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">n</span> <span class="o">-</span> <span class="n">m_minus_one</span><span class="p">)</span> <span class="o">/</span> <span class="n">m_minus_one</span></div>


<div class="viewcode-block" id="blackman"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.blackman.html#mindspore.numpy.blackman">[docs]</a><span class="k">def</span> <span class="nf">blackman</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the Blackman window.</span>
<span class="sd">    The Blackman window is a taper formed by using the first three terms of a</span>
<span class="sd">    summation of cosines. It was designed to have close to the minimal leakage</span>
<span class="sd">    possible. It is close to optimal, only slightly worse than a Kaiser window.</span>

<span class="sd">    Args:</span>
<span class="sd">        M (int): Number of points in the output window. If zero or less, an empty</span>
<span class="sd">            array is returned.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, the window, with the maximum value normalized to one (the value</span>
<span class="sd">        one appears only if the number of samples is odd).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `M` is not an int.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.blackman(12))</span>
<span class="sd">        [-1.4901161e-08  3.2606430e-02  1.5990365e-01  4.1439798e-01</span>
<span class="sd">        7.3604518e-01  9.6704674e-01  9.6704674e-01  7.3604518e-01</span>
<span class="sd">        4.1439798e-01  1.5990365e-01  3.2606430e-02 -1.4901161e-08]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_window_size</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ones</span><span class="p">(</span><span class="n">_max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">M</span><span class="p">))</span>
    <span class="n">n_doubled</span> <span class="o">=</span> <span class="n">arange</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">M</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">_to_tensor</span><span class="p">(</span><span class="mf">0.42</span><span class="p">)</span> <span class="o">+</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">_to_tensor</span><span class="p">(</span><span class="n">pi</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">n_doubled</span><span class="p">)</span> <span class="o">+</span>
            <span class="n">_to_tensor</span><span class="p">(</span><span class="mf">0.08</span><span class="p">)</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">_to_tensor</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">pi</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">n_doubled</span><span class="p">))</span></div>


<div class="viewcode-block" id="hamming"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.hamming.html#mindspore.numpy.hamming">[docs]</a><span class="k">def</span> <span class="nf">hamming</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the Hamming window.</span>
<span class="sd">    The Hamming window is a taper formed by using a weighted cosine.</span>

<span class="sd">    Args:</span>
<span class="sd">        M (int): Number of points in the output window. If zero or less, an empty</span>
<span class="sd">            array is returned.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, the window, with the maximum value normalized to one (the value</span>
<span class="sd">        one appears only if the number of samples is odd).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `M` is not an int.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.hamming(12))</span>
<span class="sd">        [0.08000001 0.15302339 0.34890914 0.6054648  0.841236   0.9813669</span>
<span class="sd">        0.9813668  0.8412359  0.6054647  0.34890908 0.15302327 0.08000001]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_window_size</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ones</span><span class="p">(</span><span class="n">_max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">M</span><span class="p">))</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">_iota</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="mf">0.54</span><span class="p">)</span> <span class="o">-</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="mf">0.46</span><span class="p">)</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">_to_tensor</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">pi</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">n</span><span class="p">)</span></div>


<div class="viewcode-block" id="hanning"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.hanning.html#mindspore.numpy.hanning">[docs]</a><span class="k">def</span> <span class="nf">hanning</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the Hanning window.</span>
<span class="sd">    The Hanning window is a taper formed by using a weighted cosine.</span>

<span class="sd">    Args:</span>
<span class="sd">        M (int): Number of points in the output window. If zero or less, an empty</span>
<span class="sd">            array is returned.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, the window, with the maximum value normalized to one (the value</span>
<span class="sd">        one appears only if the number of samples is odd).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `M` is not an int.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.hanning(12))</span>
<span class="sd">        [0.         0.07937324 0.29229254 0.5711574  0.8274304  0.9797465</span>
<span class="sd">        0.97974646 0.82743025 0.5711573  0.29229245 0.07937312 0.        ]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_window_size</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ones</span><span class="p">(</span><span class="n">_max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">M</span><span class="p">))</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">_iota</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">-</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">_to_tensor</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">pi</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">n</span><span class="p">)</span></div>


<span class="nd">@constexpr</span>
<span class="k">def</span> <span class="nf">tri_indices</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns triu/tril indices in o(nm) time.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Input n must be a number.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Input k must be a number.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">n</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Input m must be a number.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">upper</span><span class="p">:</span>
        <span class="n">compare</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">ge</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">compare</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">le</span>
    <span class="n">x_coordinate</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">y_coordinate</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># math.ceil is used to match numpy&#39;s behaviour</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n</span><span class="p">)):</span>
        <span class="n">curr_limit</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="n">k</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">m</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">compare</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">curr_limit</span><span class="p">):</span>
                <span class="n">x_coordinate</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="n">y_coordinate</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">asarray_const</span><span class="p">(</span><span class="n">x_coordinate</span><span class="p">),</span> <span class="n">asarray_const</span><span class="p">(</span><span class="n">y_coordinate</span><span class="p">)</span>


<div class="viewcode-block" id="triu_indices"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.triu_indices.html#mindspore.numpy.triu_indices">[docs]</a><span class="k">def</span> <span class="nf">triu_indices</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the indices for the upper-triangle of an (n, m) array.</span>

<span class="sd">    Args:</span>
<span class="sd">        n (int): The size of the arrays for which the returned indices will be valid.</span>
<span class="sd">        k (int, optional): Diagonal offset, default: ``0`` .</span>
<span class="sd">        m (int, optional): The column dimension of the arrays for which the returned</span>
<span class="sd">            arrays will be valid. By default `m` is taken equal to `n`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The indices for the triangle. The returned tuple contains two tensors, each</span>
<span class="sd">        with the indices along one dimension of the tensor.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `n`, `k`, `m` are not numbers.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.triu_indices(3))</span>
<span class="sd">        (Tensor(shape=[6], dtype=Int32, value= [0, 0, 0, 1, 1, 2]),</span>
<span class="sd">         Tensor(shape=[6], dtype=Int32, value= [0, 1, 2, 1, 2, 2]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">tri_indices</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span></div>


<div class="viewcode-block" id="tril_indices"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.tril_indices.html#mindspore.numpy.tril_indices">[docs]</a><span class="k">def</span> <span class="nf">tril_indices</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the indices for the lower-triangle of an (n, m) array.</span>

<span class="sd">    Args:</span>
<span class="sd">        n (int): The size of the arrays for which the returned indices will be valid.</span>
<span class="sd">        k (int, optional): Diagonal offset, default: ``0`` .</span>
<span class="sd">        m (int, optional): The column dimension of the arrays for which the returned</span>
<span class="sd">            arrays will be valid. By default `m` is taken equal to `n`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The indices for the triangle. The returned tuple contains two tensors, each</span>
<span class="sd">        with the indices along one dimension of the tensor.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `n`, `k`, `m` are not numbers.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; print(np.tril_indices(3))</span>
<span class="sd">        (Tensor(shape=[6], dtype=Int32, value= [0, 1, 1, 2, 2, 2]),</span>
<span class="sd">        Tensor(shape=[6], dtype=Int32, value= [0, 0, 1, 0, 1, 2]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">tri_indices</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span></div>


<div class="viewcode-block" id="triu_indices_from"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.triu_indices_from.html#mindspore.numpy.triu_indices_from">[docs]</a><span class="k">def</span> <span class="nf">triu_indices_from</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the indices for the upper-triangle of `arr`.</span>

<span class="sd">    Args:</span>
<span class="sd">        arr (Union[Tensor, list, tuple]): 2-dimensional array.</span>
<span class="sd">        k (int, optional): Diagonal offset, default: ``0`` .</span>

<span class="sd">    Returns:</span>
<span class="sd">        triu_indices_from, tuple of 2 tensor, shape(N)</span>
<span class="sd">        Indices for the upper-triangle of `arr`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `arr` cannot be converted to tensor, or `k` is not a number.</span>
<span class="sd">        ValueError: If `arr` cannot be converted to a 2-dimensional tensor.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; tensor = np.ones((3,3))</span>
<span class="sd">        &gt;&gt;&gt; print(np.triu_indices_from(tensor))</span>
<span class="sd">        (Tensor(shape=[6], dtype=Int32, value= [0, 0, 0, 1, 1, 2]),</span>
<span class="sd">        Tensor(shape=[6], dtype=Int32, value= [0, 1, 2, 1, 2, 2]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">arr</span> <span class="o">=</span> <span class="n">asarray</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">arr</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;input array must be 2-d&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">triu_indices</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span></div>


<div class="viewcode-block" id="tril_indices_from"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.tril_indices_from.html#mindspore.numpy.tril_indices_from">[docs]</a><span class="k">def</span> <span class="nf">tril_indices_from</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the indices for the lower-triangle of `arr`.</span>

<span class="sd">    Args:</span>
<span class="sd">        arr (Union[Tensor, list, tuple]): 2-dimensional array.</span>
<span class="sd">        k (int, optional): Diagonal offset, default: ``0`` .</span>

<span class="sd">    Returns:</span>
<span class="sd">        triu_indices_from, tuple of 2 tensor, shape(N)</span>
<span class="sd">        Indices for the upper-triangle of `arr`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `arr` cannot be converted to tensor, or `k` is not a number.</span>
<span class="sd">        ValueError: If `arr` cannot be converted to a 2-dimensional tensor.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; tensor = np.ones((3,3))</span>
<span class="sd">        &gt;&gt;&gt; print(np.tril_indices_from(tensor))</span>
<span class="sd">        (Tensor(shape=[6], dtype=Int32, value= [0, 1, 1, 2, 2, 2]),</span>
<span class="sd">         Tensor(shape=[6], dtype=Int32, value= [0, 0, 1, 0, 1, 2]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">arr</span> <span class="o">=</span> <span class="n">asarray</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">arr</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;input array must be 2-d&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tril_indices</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span></div>


<div class="viewcode-block" id="histogram_bin_edges"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.histogram_bin_edges.html#mindspore.numpy.histogram_bin_edges">[docs]</a><span class="k">def</span> <span class="nf">histogram_bin_edges</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># pylint: disable=redefined-builtin</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to calculate only the edges of the bins used by the histogram function.</span>

<span class="sd">    Note:</span>
<span class="sd">        String values for `bins` is not supported.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Union[int, float, bool, list, tuple, Tensor]): Input data. The histogram</span>
<span class="sd">            is computed over the flattened array.</span>
<span class="sd">        bins ((Union[int, tuple, list, Tensor])): If `bins` is an int, it defines the number</span>
<span class="sd">            of equal-width bins in the given range (10, by default). If `bins` is a</span>
<span class="sd">            sequence, it defines the bin edges, including the rightmost edge,</span>
<span class="sd">            allowing for non-uniform bin widths.</span>
<span class="sd">        range((float, float), optional): The lower and upper range of the bins. If</span>
<span class="sd">            not provided, `range` is simply ``(a.min(), a.max())``. Values outside</span>
<span class="sd">            the range are ignored. The first element of the range must be less than</span>
<span class="sd">            or equal to the second. Default: ``None`` .</span>
<span class="sd">        weights(Union[int, float, bool, list, tuple, Tensor], optional):  An array of weights,</span>
<span class="sd">            of the same shape as `a`. Each value in `a` only contributes its associated weight</span>
<span class="sd">            towards the bin count (instead of 1). This is currently not used by any of the bin</span>
<span class="sd">            estimators, but may be in the future. Default: ``None`` .</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, the edges to pass into `histogram`.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `bins` is an array and not one-dimensional.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; arr = np.array([0, 0, 0, 1, 2, 3, 3, 4, 5])</span>
<span class="sd">        &gt;&gt;&gt; print(np.histogram_bin_edges(arr, bins=2))</span>
<span class="sd">        [0.  2.5 5. ]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">!=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>
            <span class="n">_raise_value_error</span><span class="p">(</span><span class="s1">&#39;weights should have the same shape as a&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)):</span>
        <span class="n">bins</span> <span class="o">=</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="n">bins</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">bins</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">_raise_value_error</span><span class="p">(</span><span class="s1">&#39;`bins` must be 1d, when an array&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">bins</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="c1"># linspace does not support Tensor for num</span>
        <span class="n">_raise_unimplemented_error</span><span class="p">(</span><span class="s1">&#39;string value for `bins` not implemented&#39;</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reduce_min</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">range</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="nb">range</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">_raise_value_error</span><span class="p">(</span><span class="s1">&#39;`range` should take the form (start, end)&#39;</span><span class="p">)</span>
        <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="nb">range</span>
        <span class="k">if</span> <span class="n">start</span> <span class="o">&gt;</span> <span class="n">end</span><span class="p">:</span>
            <span class="n">_raise_value_error</span><span class="p">(</span><span class="s1">&#39;max must be larger than min in range parameter&#39;</span><span class="p">)</span>
        <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span>
    <span class="n">no_range</span> <span class="o">=</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">where</span><span class="p">(</span><span class="n">no_range</span><span class="p">,</span> <span class="n">start</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">start</span><span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">where</span><span class="p">(</span><span class="n">no_range</span><span class="p">,</span> <span class="n">end</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">linspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">bins</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_pad_empty</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    pads the array with constant values, used in mode: &quot;empty&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">dtype</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">ndim</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">pad_before</span> <span class="o">=</span> <span class="p">()</span>
        <span class="n">pad_after</span> <span class="o">=</span> <span class="p">()</span>
        <span class="c1"># To avoid any memory issues, we don&#39;t make tensor with 0s in their shapes</span>
        <span class="k">if</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">pad_before</span> <span class="o">+=</span> <span class="p">(</span><span class="n">empty</span><span class="p">(</span><span class="n">_tuple_setitem</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),)</span>
        <span class="k">if</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">pad_after</span> <span class="o">+=</span> <span class="p">(</span><span class="n">empty</span><span class="p">(</span><span class="n">_tuple_setitem</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),)</span>
        <span class="n">tensor_with_pad</span> <span class="o">=</span> <span class="n">pad_before</span> <span class="o">+</span> <span class="p">(</span><span class="n">arr</span><span class="p">,)</span> <span class="o">+</span> <span class="n">pad_after</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">(</span><span class="n">tensor_with_pad</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">arr</span>


<span class="k">def</span> <span class="nf">_pad_constant</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    pads the array with constant values, used in mode: &quot;constant&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">dtype</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">ndim</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">pad_before</span> <span class="o">=</span> <span class="p">()</span>
        <span class="n">pad_after</span> <span class="o">=</span> <span class="p">()</span>
        <span class="c1"># To avoid any memory issues, we don&#39;t make tensor with 0s in their shapes</span>
        <span class="k">if</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">pad_before</span> <span class="o">+=</span> <span class="p">(</span><span class="n">full</span><span class="p">(</span><span class="n">_tuple_setitem</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span> <span class="n">value</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),)</span>
        <span class="k">if</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">pad_after</span> <span class="o">+=</span> <span class="p">(</span><span class="n">full</span><span class="p">(</span><span class="n">_tuple_setitem</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]),</span> <span class="n">value</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),)</span>
        <span class="n">tensor_with_pad</span> <span class="o">=</span> <span class="n">pad_before</span> <span class="o">+</span> <span class="p">(</span><span class="n">arr</span><span class="p">,)</span> <span class="o">+</span> <span class="n">pad_after</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">(</span><span class="n">tensor_with_pad</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">arr</span>


<span class="k">def</span> <span class="nf">_pad_statistic</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">,</span> <span class="n">stat_length</span><span class="p">,</span> <span class="n">stat_op</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    pads the array with values calculated along the given axis, used in mode: &quot;maximum&quot;,</span>
<span class="sd">    &quot;minimum&quot;, &quot;mean&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">ndim</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="n">stat_length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">stat_length</span> <span class="o">=</span> <span class="n">_make_stat_length</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">stat_length</span> <span class="o">=</span> <span class="n">_convert_pad_to_nd</span><span class="p">(</span><span class="n">stat_length</span><span class="p">,</span> <span class="n">ndim</span><span class="p">)</span>
    <span class="n">stat_length</span> <span class="o">=</span> <span class="n">_limit_stat_length</span><span class="p">(</span><span class="n">stat_length</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndim</span><span class="p">):</span>
        <span class="n">pad_before</span> <span class="o">=</span> <span class="n">stat_op</span><span class="p">(</span><span class="n">_slice_along_axis</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">stat_length</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">pad_before</span> <span class="o">=</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">pad_before</span><span class="p">,</span> <span class="n">_tuple_setitem</span><span class="p">((</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="n">ndim</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])),)</span>
        <span class="n">pad_after</span> <span class="o">=</span> <span class="n">stat_op</span><span class="p">(</span><span class="n">_slice_along_axis</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">stat_length</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">pad_after</span> <span class="o">=</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">pad_after</span><span class="p">,</span> <span class="n">_tuple_setitem</span><span class="p">((</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="n">ndim</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">])),)</span>
        <span class="n">tensor_with_pad</span> <span class="o">=</span> <span class="n">pad_before</span> <span class="o">+</span> <span class="p">(</span><span class="n">arr</span><span class="p">,)</span> <span class="o">+</span> <span class="n">pad_after</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">(</span><span class="n">tensor_with_pad</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">arr</span>


<span class="k">def</span> <span class="nf">_pad_edge</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;pad_edge is equivalent to pad_statistic with stat_lenght=1, used in mode:&quot;edge&quot;.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">identity_op</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">axis</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">arr</span>

    <span class="k">return</span> <span class="n">_pad_statistic</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">identity_op</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_pad_wrap</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The behaviour of wrap mode is consistent with jax.numpy, used in mode:&quot;wrap&quot;.&quot;&quot;&quot;</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">ndim</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndim</span><span class="p">):</span>
        <span class="n">padsize_before</span> <span class="o">=</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">%</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">padsize_after</span> <span class="o">=</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">%</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">total_repeats</span> <span class="o">=</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">tensor_with_pad</span> <span class="o">=</span> <span class="p">()</span>
        <span class="c1"># To avoid any memory issues, we don&#39;t make tensor with 0s in their shapes</span>
        <span class="k">if</span> <span class="n">padsize_before</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">tensor_with_pad</span> <span class="o">+=</span> <span class="p">(</span><span class="n">_slice_along_axis</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">padsize_before</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]),)</span>
        <span class="n">tensor_with_pad</span> <span class="o">+=</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">_tuple_setitem</span><span class="p">((</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="n">ndim</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">total_repeats</span><span class="p">)),)</span>
        <span class="k">if</span> <span class="n">padsize_after</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">tensor_with_pad</span> <span class="o">+=</span> <span class="p">(</span><span class="n">_slice_along_axis</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">padsize_after</span><span class="p">),)</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">(</span><span class="n">tensor_with_pad</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">arr</span>


<span class="k">def</span> <span class="nf">_pad_linear</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">,</span> <span class="n">end_values</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Pads the arr with linear range values, used in mode: &quot;linear_ramp&quot;.&quot;&quot;&quot;</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">ndim</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">end_values</span> <span class="o">=</span> <span class="n">_convert_pad_to_nd</span><span class="p">(</span><span class="n">end_values</span><span class="p">,</span> <span class="n">ndim</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndim</span><span class="p">):</span>
        <span class="n">left_value</span> <span class="o">=</span> <span class="n">_slice_along_axis</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">right_value</span> <span class="o">=</span> <span class="n">_slice_along_axis</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">pad_before</span> <span class="o">=</span> <span class="p">()</span>
        <span class="n">pad_after</span> <span class="o">=</span> <span class="p">()</span>
        <span class="k">if</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">pad_before</span> <span class="o">=</span> <span class="p">(</span><span class="n">linspace</span><span class="p">(</span><span class="n">end_values</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">left_value</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                                   <span class="n">endpoint</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),)</span>
        <span class="k">if</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">pad_after</span> <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="n">right_value</span><span class="p">,</span> <span class="n">end_values</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">num</span><span class="o">=</span><span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                                 <span class="n">endpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">pad_after</span> <span class="o">=</span> <span class="p">(</span><span class="n">_slice_along_axis</span><span class="p">(</span><span class="n">pad_after</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),)</span>
        <span class="n">tensor_with_pad</span> <span class="o">=</span> <span class="n">pad_before</span> <span class="o">+</span> <span class="p">(</span><span class="n">arr</span><span class="p">,)</span> <span class="o">+</span> <span class="n">pad_after</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">(</span><span class="n">tensor_with_pad</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">arr</span>


<span class="k">def</span> <span class="nf">_add_pads_before</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_args</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;handle pads before the array&quot;&quot;&quot;</span>
    <span class="n">idx</span><span class="p">,</span> <span class="n">array_length</span><span class="p">,</span> <span class="n">times_to_pad_before</span><span class="p">,</span> <span class="n">additional_pad_before</span><span class="p">,</span> <span class="n">reflect_type</span> <span class="o">=</span> <span class="n">pad_args</span>
    <span class="n">curr_pad</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">endpoint_adder</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">edge_before</span> <span class="o">=</span> <span class="n">_slice_along_axis</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;reflect&quot;</span><span class="p">:</span>
        <span class="n">endpoint_adder</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">endpoint_adder</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># Deal with paddings before the original array</span>
    <span class="k">for</span> <span class="n">times</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">times_to_pad_before</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">times</span> <span class="o">&lt;</span> <span class="n">times_to_pad_before</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">endpoint</span> <span class="o">=</span> <span class="n">array_length</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">endpoint</span> <span class="o">=</span> <span class="n">additional_pad_before</span> <span class="o">+</span> <span class="n">endpoint_adder</span>
        <span class="k">if</span> <span class="n">endpoint</span> <span class="o">!=</span> <span class="n">endpoint_adder</span><span class="p">:</span>
            <span class="n">curr_pad</span> <span class="o">=</span> <span class="n">_slice_along_axis</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">endpoint_adder</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">)</span>
            <span class="n">curr_pad</span> <span class="o">=</span> <span class="n">flip</span><span class="p">(</span><span class="n">curr_pad</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">idx</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">reflect_type</span> <span class="o">==</span> <span class="s2">&quot;odd&quot;</span><span class="p">:</span>
                <span class="n">curr_pad</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">edge_before</span> <span class="o">-</span> <span class="n">curr_pad</span>
            <span class="n">arr</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Concat</span><span class="p">(</span><span class="n">idx</span><span class="p">)((</span><span class="n">curr_pad</span><span class="p">,</span> <span class="n">arr</span><span class="p">))</span>
            <span class="n">edge_before</span> <span class="o">=</span> <span class="n">_slice_along_axis</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">arr</span>


<span class="k">def</span> <span class="nf">_add_pads_after</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_args</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;handle pads after the array&quot;&quot;&quot;</span>
    <span class="n">idx</span><span class="p">,</span> <span class="n">array_length</span><span class="p">,</span> <span class="n">times_to_pad_after</span><span class="p">,</span> <span class="n">additional_pad_after</span><span class="p">,</span> <span class="n">reflect_type</span> <span class="o">=</span> <span class="n">pad_args</span>
    <span class="n">curr_pad</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">endpoint_adder</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">edge_end</span> <span class="o">=</span> <span class="n">_slice_along_axis</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;reflect&quot;</span><span class="p">:</span>
        <span class="n">endpoint_adder</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">endpoint_adder</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># Deal with paddings after the original array</span>
    <span class="k">for</span> <span class="n">times</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">times_to_pad_after</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">times</span> <span class="o">&lt;</span> <span class="n">times_to_pad_after</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">startpoint</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">-</span> <span class="n">array_length</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">startpoint</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">-</span> <span class="n">additional_pad_after</span> <span class="o">-</span> <span class="n">endpoint_adder</span>
        <span class="k">if</span> <span class="n">startpoint</span> <span class="o">!=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">-</span> <span class="n">endpoint_adder</span><span class="p">:</span>
            <span class="n">curr_pad</span> <span class="o">=</span> <span class="n">_slice_along_axis</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">startpoint</span><span class="p">,</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">-</span> <span class="n">endpoint_adder</span><span class="p">)</span>
            <span class="n">curr_pad</span> <span class="o">=</span> <span class="n">flip</span><span class="p">(</span><span class="n">curr_pad</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">idx</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">reflect_type</span> <span class="o">==</span> <span class="s2">&quot;odd&quot;</span><span class="p">:</span>
                <span class="n">curr_pad</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">edge_end</span> <span class="o">-</span> <span class="n">curr_pad</span>
            <span class="n">arr</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Concat</span><span class="p">(</span><span class="n">idx</span><span class="p">)((</span><span class="n">arr</span><span class="p">,</span> <span class="n">curr_pad</span><span class="p">))</span>
            <span class="n">edge_end</span> <span class="o">=</span> <span class="n">_slice_along_axis</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">arr</span>


<span class="k">def</span> <span class="nf">_pad_symmetric</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">,</span> <span class="n">reflect_type</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;pad the array with symmetric paddings&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">ndim</span><span class="p">):</span>
        <span class="n">array_length</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="n">has_pad_before</span> <span class="o">=</span> <span class="p">(</span><span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">has_pad_after</span> <span class="o">=</span> <span class="p">(</span><span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>

        <span class="n">times_to_pad_before</span> <span class="o">=</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">array_length</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">additional_pad_before</span> <span class="o">=</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">%</span> <span class="n">array_length</span>
        <span class="n">times_to_pad_after</span> <span class="o">=</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="n">array_length</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">additional_pad_after</span> <span class="o">=</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">%</span> <span class="n">array_length</span>
        <span class="k">if</span> <span class="n">has_pad_before</span><span class="p">:</span>
            <span class="c1"># Deal with paddings before the original array</span>
            <span class="n">pad_args</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">array_length</span><span class="p">,</span> <span class="n">times_to_pad_before</span><span class="p">,</span> <span class="n">additional_pad_before</span><span class="p">,</span> <span class="n">reflect_type</span><span class="p">)</span>
            <span class="n">arr</span> <span class="o">=</span> <span class="n">_add_pads_before</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_args</span><span class="p">,</span> <span class="s2">&quot;symmetric&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">has_pad_after</span><span class="p">:</span>
            <span class="c1"># Deal with paddings after the original array</span>
            <span class="n">pad_args</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">array_length</span><span class="p">,</span> <span class="n">times_to_pad_after</span><span class="p">,</span> <span class="n">additional_pad_after</span><span class="p">,</span> <span class="n">reflect_type</span><span class="p">)</span>
            <span class="n">arr</span> <span class="o">=</span> <span class="n">_add_pads_after</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_args</span><span class="p">,</span> <span class="s2">&quot;symmetric&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">arr</span>


<span class="k">def</span> <span class="nf">_pad_reflect</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">,</span> <span class="n">reflect_type</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    pad the array with reflect paddings, this is very similar to symmetric paddings,</span>
<span class="sd">    but differs at how edges are selected.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">ndim</span><span class="p">):</span>
        <span class="n">array_length</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">array_length</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">total_repeats</span> <span class="o">=</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">arr</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">_tuple_setitem</span><span class="p">((</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="n">arr</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">total_repeats</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">has_pad_before</span> <span class="o">=</span> <span class="p">(</span><span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">has_pad_after</span> <span class="o">=</span> <span class="p">(</span><span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>

            <span class="n">pad_size</span> <span class="o">=</span> <span class="n">array_length</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="n">times_to_pad_before</span> <span class="o">=</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">pad_size</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">additional_pad_before</span> <span class="o">=</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">%</span> <span class="n">pad_size</span>
            <span class="n">times_to_pad_after</span> <span class="o">=</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="n">pad_size</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">additional_pad_after</span> <span class="o">=</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">%</span> <span class="n">pad_size</span>
            <span class="k">if</span> <span class="n">has_pad_before</span><span class="p">:</span>
                <span class="c1"># Deal with paddings before the original array</span>
                <span class="n">pad_args</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">array_length</span><span class="p">,</span> <span class="n">times_to_pad_before</span><span class="p">,</span> <span class="n">additional_pad_before</span><span class="p">,</span> <span class="n">reflect_type</span><span class="p">)</span>
                <span class="n">arr</span> <span class="o">=</span> <span class="n">_add_pads_before</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_args</span><span class="p">,</span> <span class="s2">&quot;reflect&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">has_pad_after</span><span class="p">:</span>
                <span class="c1"># Deal with paddings after the original array</span>
                <span class="n">pad_args</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">array_length</span><span class="p">,</span> <span class="n">times_to_pad_after</span><span class="p">,</span> <span class="n">additional_pad_after</span><span class="p">,</span> <span class="n">reflect_type</span><span class="p">)</span>
                <span class="n">arr</span> <span class="o">=</span> <span class="n">_add_pads_after</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_args</span><span class="p">,</span> <span class="s2">&quot;reflect&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">arr</span>


<span class="k">def</span> <span class="nf">_pad_func</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;applies padding function over different axis.&quot;&quot;&quot;</span>
    <span class="c1"># first creates a padded array with fixed length.</span>
    <span class="n">arr_dim</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">ndim</span>
    <span class="n">pad_width</span> <span class="o">=</span> <span class="n">_convert_pad_to_nd</span><span class="p">(</span><span class="n">pad_width</span><span class="p">,</span> <span class="n">arr_dim</span><span class="p">)</span>
    <span class="n">arr</span> <span class="o">=</span> <span class="n">_pad_empty</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">arr_dim</span><span class="p">):</span>
        <span class="c1"># function signature: padding_func(tensor, iaxis_pad_width, iaxis, kwargs)</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">apply_along_axis</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">i</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">arr</span>


<span class="nd">@_primexpr</span>
<span class="k">def</span> <span class="nf">_make_stat_length</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;converts the stat_length values.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">((</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>


<span class="nd">@_primexpr</span>
<span class="k">def</span> <span class="nf">_limit_stat_length</span><span class="p">(</span><span class="n">stat_length</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;limits the stat_length to current array length along given dimension.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">((</span><span class="nb">min</span><span class="p">(</span><span class="n">stat_pair</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="nb">min</span><span class="p">(</span><span class="n">stat_pair</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">stat_pair</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">stat_length</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_convert_pad_to_nd</span><span class="p">(</span><span class="n">pad_values</span><span class="p">,</span> <span class="n">ndim</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;broadcasts the pad_values to (ndim * 2)&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pad_values</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="s2">&quot;pad_width, stat_length, constant_values or end_values should only be int, list, tuple or tensor&quot;</span><span class="p">)</span>
    <span class="n">pad_tensor</span> <span class="o">=</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="n">pad_values</span><span class="p">)</span>
    <span class="n">pad_shape</span> <span class="o">=</span> <span class="n">pad_tensor</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">pad_shape</span><span class="p">:</span>
        <span class="n">pad_values</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">((((</span><span class="n">pad_values</span><span class="p">,)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndim</span><span class="p">)))</span>
    <span class="k">elif</span> <span class="n">pad_shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,):</span>
        <span class="n">pad_values</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">((</span><span class="nb">tuple</span><span class="p">(</span><span class="n">pad_values</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndim</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">pad_shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">2</span><span class="p">,):</span>
        <span class="n">pad_values</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">pad_values</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndim</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">pad_shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
        <span class="n">pad_values</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">pad_values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndim</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">pad_shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
        <span class="n">pad_values</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">pad_pair</span><span class="p">)</span> <span class="k">for</span> <span class="n">pad_pair</span> <span class="ow">in</span> <span class="n">pad_values</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;input values must be able to broadcast to </span><span class="si">{</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pad_values</span>


<div class="viewcode-block" id="pad"><a class="viewcode-back" href="../../../api_python/numpy/mindspore.numpy.pad.html#mindspore.numpy.pad">[docs]</a><span class="k">def</span> <span class="nf">pad</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="n">stat_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">constant_values</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">end_values</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">reflect_type</span><span class="o">=</span><span class="s2">&quot;even&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Pads an array.</span>

<span class="sd">    Note:</span>
<span class="sd">        Currently, `median` mode is not supported. `reflect` and `symmetric` mode</span>
<span class="sd">        only supports GPU backend.</span>

<span class="sd">    Args:</span>
<span class="sd">        arr (Union[list, tuple, Tensor]): The array to pad.</span>
<span class="sd">        pad_width (Union[int, tuple, list]): Number of values padded to the edges of</span>
<span class="sd">            each axis. :class:`((before_1, after_1), ... (before_N, after_N))` creates</span>
<span class="sd">            unique pad widths for each axis. :class:`((before, after),)` yields same</span>
<span class="sd">            before and after pad for each axis. :class:`(pad,)` or int is a shortcut</span>
<span class="sd">            for :class:`before = after = pad width` for all axes.</span>
<span class="sd">        mode (string, optional):</span>
<span class="sd">            One of the following string values:</span>

<span class="sd">            - constant (default): Pads with a constant value.</span>
<span class="sd">            - edge: Pads with the edge values of `arr`.</span>
<span class="sd">            - linear_ramp: Pads with the linear ramp between end_value and the `arr` edge value.</span>
<span class="sd">            - maximum: Pads with the maximum value of all or part of the vector along each axis.</span>
<span class="sd">            - mean: Pads with the mean value of all or part of the vector along each axis.</span>
<span class="sd">            - median: Pads with the median value of all or part of the vector along each axis.</span>
<span class="sd">            - minimum: Pads with the minimum value of all or part of the vector along each axis.</span>
<span class="sd">            - reflect: Pads with the reflection of the vector mirrored on the first</span>
<span class="sd">              and last values of the vector along each axis.</span>
<span class="sd">            - symmetric: Pads with the reflection of the vector mirrored along the edge</span>
<span class="sd">              of the `arr`.</span>
<span class="sd">            - wrap: Pads with the wrap of the vector along the axis. The first values</span>
<span class="sd">              are used to pad the end and the end values are used to pad the beginning.</span>
<span class="sd">            - empty: Pads with undefined values.</span>
<span class="sd">            - &lt;function&gt;: The padding function, if used, should modify and return a new 1-d tensor.</span>
<span class="sd">              It has the following signature: :class:`padding_func(tensor, iaxis_pad_width, iaxis, kwargs)`</span>
<span class="sd">        stat_length (Union[tuple, list, int], optional): Used in \&#39;maximum\&#39;, \&#39;mean\&#39;,</span>
<span class="sd">            \&#39;median\&#39;, and \&#39;minimum\&#39;.  Number of values at edge of each axis used</span>
<span class="sd">            to calculate the statistic value. :class:`((before_1, after_1), ... (before_N, after_N))`</span>
<span class="sd">            creates unique statistic lengths for each axis. :class:`((before, after),)`</span>
<span class="sd">            yields same before and after statistic lengths for each axis. :class:`(stat_length,)`</span>
<span class="sd">            or int is a shortcut for :class:`before = after = statistic length` for all</span>
<span class="sd">            axes. Default: ``None``, to use the entire axis.</span>
<span class="sd">        constant_values (Union[tuple, list, int], optional):</span>
<span class="sd">            Used in :class:`constant mode`. The values to set the padded values for each</span>
<span class="sd">            axis. :class:`((before_1, after_1), ... (before_N, after_N))` creates unique pad</span>
<span class="sd">            constants for each axis. :class:`((before, after),)` yields same before and</span>
<span class="sd">            after constants for each axis. :class:`(constant,)` or :class:`constant` is</span>
<span class="sd">            a shortcut for :class:`before = after = constant` for all axes. Default: ``0`` .</span>
<span class="sd">        end_values (Union[tuple, list, int], optional): Used in &#39;linear_ramp&#39;.  The values</span>
<span class="sd">            used for the ending value of the linear_ramp and that will form the edge of</span>
<span class="sd">            the padded `arr`. :class:`((before_1, after_1), ... (before_N, after_N))`</span>
<span class="sd">            unique end values for each axis. :class:`((before, after),)` yields same before</span>
<span class="sd">            and after end values for each axis. :class:`(constant,)` or :class:`constant`</span>
<span class="sd">            is a shortcut for :class:`before = after = constant` for all axes. Default: ``0`` .</span>
<span class="sd">        reflect_type(string, optional) can choose between \&#39;even\&#39; and \&#39;odd\&#39;. Used in</span>
<span class="sd">            \&#39;reflect\&#39;, and \&#39;symmetric\&#39;. The \&#39;even\&#39; style is the default with an</span>
<span class="sd">            unaltered reflection around the edge value. For the \&#39;odd\&#39; style, the extended</span>
<span class="sd">            part of the `arr` is created by subtracting the reflected values from two times</span>
<span class="sd">            the edge value.</span>
<span class="sd">        kwargs (anytype, optional): Any keyword arguments that will be used only in &lt;function&gt;</span>
<span class="sd">            mode.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Padded tensor of rank equal to `arr` with shape increased according to `pad_width`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `arr`, `pad_width`, `stat_length`, `constant_values` or `end_values`</span>
<span class="sd">            have types not specified above.</span>
<span class="sd">        ValueError: If `mode` cannot be recognized, or if `pad_width`, `stat_length`,</span>
<span class="sd">            `constant_values`, `end_values` cannot broadcast to :class:`(arr.ndim, 2)`,</span>
<span class="sd">            or if keyword arguments got unexpected inputs.</span>
<span class="sd">        NotImplementedError: If mode is function or \&#39;median\&#39;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as np</span>
<span class="sd">        &gt;&gt;&gt; tensor = np.array([1., 2., 3., 4., 5.])</span>
<span class="sd">        &gt;&gt;&gt; print(np.pad(tensor, (3, 4)))</span>
<span class="sd">        [0. 0. 0. 1. 2. 3. 4. 5. 0. 0. 0. 0.]</span>
<span class="sd">        &gt;&gt;&gt; print(np.pad(tensor, (3, 4), mode=&quot;wrap&quot;))</span>
<span class="sd">        [3. 4. 5. 1. 2. 3. 4. 5. 1. 2. 3. 4.]</span>
<span class="sd">        &gt;&gt;&gt; print(np.pad(tensor, (3, 4), mode=&quot;linear_ramp&quot;, end_values=(10, 10)))</span>
<span class="sd">        [10.    7.    4.    1.    2.    3.    4.    5.    6.25  7.5   8.75 10.  ]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">arr</span> <span class="o">=</span> <span class="n">_to_tensor</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">arr</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">arr</span>
    <span class="n">pad_width</span> <span class="o">=</span> <span class="n">_convert_pad_to_nd</span><span class="p">(</span><span class="n">pad_width</span><span class="p">,</span> <span class="n">arr</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="n">stat_func</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;maximum&quot;</span><span class="p">:</span> <span class="n">_reduce_max_keepdims</span><span class="p">,</span>
                 <span class="s2">&quot;minimum&quot;</span><span class="p">:</span> <span class="n">_reduce_min_keepdims</span><span class="p">,</span>
                 <span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">_reduce_mean_keepdims</span><span class="p">,</span>
                 <span class="s2">&quot;median&quot;</span><span class="p">:</span> <span class="s2">&quot;not implemented&quot;</span><span class="p">}</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="s2">&quot;maximum&quot;</span><span class="p">,</span> <span class="s2">&quot;minimum&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;median&quot;</span><span class="p">,</span> <span class="s2">&quot;edge&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;wrap&quot;</span><span class="p">,</span> <span class="s2">&quot;linear_ramp&quot;</span><span class="p">,</span> <span class="s2">&quot;symmetric&quot;</span><span class="p">,</span> <span class="s2">&quot;reflect&quot;</span><span class="p">,</span> <span class="s2">&quot;empty&quot;</span><span class="p">)</span> <span class="ow">and</span> \
            <span class="ow">not</span> <span class="n">_callable</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
        <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;Input mode not supported.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;constant&quot;</span><span class="p">:</span>
        <span class="n">constant_values</span> <span class="o">=</span> <span class="n">_convert_pad_to_nd</span><span class="p">(</span><span class="n">constant_values</span><span class="p">,</span> <span class="n">arr</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_pad_constant</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">,</span> <span class="n">constant_values</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;maximum&quot;</span><span class="p">,</span> <span class="s2">&quot;minimum&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;median&quot;</span><span class="p">):</span>
        <span class="c1"># support median mode once P.Sort/P.Median is supported on GPU/CPU</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;median&quot;</span><span class="p">:</span>
            <span class="n">_raise_unimplemented_error</span><span class="p">(</span><span class="s2">&quot;median mode is not supported yet&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_pad_statistic</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">,</span> <span class="n">stat_length</span><span class="p">,</span> <span class="n">stat_func</span><span class="p">[</span><span class="n">mode</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;edge&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_pad_edge</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;wrap&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_pad_wrap</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;linear_ramp&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_pad_linear</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">,</span> <span class="n">end_values</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;symmetric&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_pad_symmetric</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">,</span> <span class="n">reflect_type</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;reflect&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_pad_reflect</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">,</span> <span class="n">reflect_type</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;empty&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_pad_empty</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_pad_func</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>