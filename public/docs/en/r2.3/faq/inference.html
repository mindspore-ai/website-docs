<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Inference &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script src="../_static/js/mermaid-9.3.0.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Feature Advice" href="feature_advice.html" />
    <link rel="prev" title="Distributed Parallel" href="distributed_parallel.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/tensor_view.html">TENSOR VIEWS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/programming_paradigm.html">Functional and Object-Oriented Fusion Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/distributed_training_design.html">Distributed Parallel Native</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/all_scenarios.html">Full-scenarios Unified Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/official_models.html">Official Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.extend.html">mindspore.ops.extend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.hal.html">mindspore.hal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.multiprocessing.html">mindspore.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.experimental.html">mindspore.experimental</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/enveriment_preparation.html">Environment Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/model_development/model_development.html">Network Constructing Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/faq.html">FAQs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Syntax Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax_support.html">Static Graph Syntax Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/operators.html">Static Graph Syntax - Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/statements.html">Static Graph Syntax - Python Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/python_builtin_functions.html">Static Graph Syntax - Python Built-in Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/index_support.html">Tensor Index Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/env_var_list.html">Environment Variables</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#q-in-the-previous-version,-atlas-200/300/500-inference-product-inference-is-performed-based-on-the-mindspore-installation-package-however,-the-mindspore-release-package-of-the-new-version-does-not-support-atlas-200/300/500-inference-product-inference-how-do-i-use-atlas-200/300/500-inference-product-for-inference?-changes-in-the-mindspore-atlas-200/300/500-inference-product-inference-release-package">Q: In the previous version, Atlas 200/300/500 inference product inference is performed based on the MindSpore installation package. However, the MindSpore release package of the new version does not support Atlas 200/300/500 inference product inference. How do I use Atlas 200/300/500 inference product for inference? (Changes in the MindSpore Atlas 200/300/500 Inference Product Inference Release Package)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#q-what-should-i-do-when-an-error-/usr/bin/ld-warning-libxxx-so,-needed-by-libmindspore-so,-not-found-prompts-during-application-compiling?">Q: What should I do when an error <code class="docutils literal notranslate"><span class="pre">/usr/bin/ld:</span> <span class="pre">warning:</span> <span class="pre">libxxx.so,</span> <span class="pre">needed</span> <span class="pre">by</span> <span class="pre">libmindspore.so,</span> <span class="pre">not</span> <span class="pre">found</span></code> prompts during application compiling?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#q-after-updating-mindspore-version,-the-application-compilation-reports-errors-warning-packages-not-found-mindspore-ascend,-cmake-error-the-following-variables-are-use-in-this-project,-but-they-are-set-to-notfound-please-set-them-or-make-sure-they-are-set-and-tested-correctly-in-the-cmake-files-ms-lib-what-should-i-do?">Q: After updating MindSpore version, the application compilation reports errors <code class="docutils literal notranslate"><span class="pre">WARNING:</span> <span class="pre">Package(s)</span> <span class="pre">not</span> <span class="pre">found:</span> <span class="pre">mindspore-ascend</span></code>, <code class="docutils literal notranslate"><span class="pre">CMake</span> <span class="pre">Error:</span> <span class="pre">The</span> <span class="pre">following</span> <span class="pre">variables</span> <span class="pre">are</span> <span class="pre">use</span> <span class="pre">in</span> <span class="pre">this</span> <span class="pre">project,</span> <span class="pre">but</span> <span class="pre">they</span> <span class="pre">are</span> <span class="pre">set</span> <span class="pre">to</span> <span class="pre">NOTFOUND.</span> <span class="pre">Please</span> <span class="pre">set</span> <span class="pre">them</span> <span class="pre">or</span> <span class="pre">make</span> <span class="pre">sure</span> <span class="pre">they</span> <span class="pre">are</span> <span class="pre">set</span> <span class="pre">and</span> <span class="pre">tested</span> <span class="pre">correctly</span> <span class="pre">in</span> <span class="pre">the</span> <span class="pre">CMake</span> <span class="pre">files:</span> <span class="pre">MS_LIB</span></code>. What should I do?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#q-what-should-i-do-when-error-error-while-loading-shared-libraries-libge-compiler-so-cannot-open-shared-object-file-no-such-file-or-directory-prompts-during-application-running?">Q: What should I do when error <code class="docutils literal notranslate"><span class="pre">error</span> <span class="pre">while</span> <span class="pre">loading</span> <span class="pre">shared</span> <span class="pre">libraries:</span> <span class="pre">libge_compiler.so:</span> <span class="pre">cannot</span> <span class="pre">open</span> <span class="pre">shared</span> <span class="pre">object</span> <span class="pre">file:</span> <span class="pre">No</span> <span class="pre">such</span> <span class="pre">file</span> <span class="pre">or</span> <span class="pre">directory</span></code> prompts during application running?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#q-how-to-configure-aipp-files?">Q: How to configure AIPP files?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Inference</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/faq/inference.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section class="tex2jax_ignore mathjax_ignore" id="inference">
<h1>Inference<a class="headerlink" href="#inference" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r2.3/docs/mindspore/source_en/faq/inference.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3/resource/_static/logo_source_en.svg" /></a></p>
<section id="q-in-the-previous-version,-atlas-200/300/500-inference-product-inference-is-performed-based-on-the-mindspore-installation-package-however,-the-mindspore-release-package-of-the-new-version-does-not-support-atlas-200/300/500-inference-product-inference-how-do-i-use-atlas-200/300/500-inference-product-for-inference?-changes-in-the-mindspore-atlas-200/300/500-inference-product-inference-release-package">
<h2>Q: In the previous version, Atlas 200/300/500 inference product inference is performed based on the MindSpore installation package. However, the MindSpore release package of the new version does not support Atlas 200/300/500 inference product inference. How do I use Atlas 200/300/500 inference product for inference? (Changes in the MindSpore Atlas 200/300/500 Inference Product Inference Release Package)<a class="headerlink" href="#q-in-the-previous-version,-atlas-200/300/500-inference-product-inference-is-performed-based-on-the-mindspore-installation-package-however,-the-mindspore-release-package-of-the-new-version-does-not-support-atlas-200/300/500-inference-product-inference-how-do-i-use-atlas-200/300/500-inference-product-for-inference?-changes-in-the-mindspore-atlas-200/300/500-inference-product-inference-release-package" title="Permalink to this headline"></a></h2>
<p>A: The MindSpore inference function is provided by MindSpore Lite, a core component of MindSpore. Since version 2.0, the Atlas 200/300/500 inference product inference package is released by MindSpore Lite and provides continuous maintenance and evolution of related functions. The corresponding interfaces in the MindSpore main release package are not maintained or evolved. Since version 2.2, the MindSpore main release package does not provide the inference interface enabling for the Atlas 200/300/500 inference product. If you need to use the inference interface, install the MindSpore Lite release package or download the MindSpore version earlier than 2.0. For details about how to install and use MindSpore Lite, see <a class="reference external" href="https://www.mindspore.cn/lite/en">https://www.mindspore.cn/lite/en</a>.</p>
<p>HUAWEI Atlas 200/300/500 inference product is an energy-efficient and highly integrated AI processor for edge scenarios. It supports inference on MindIR models. In the earlier version, MindSpore provides two methods for enabling inference on the Atlas 200/300/500 inference product hardware:</p>
<ol class="arabic simple">
<li><p>The MindSpore main release package provides the matching Atlas 200/300/500 inference product version that supports C++ inference interfaces.</p></li>
<li><p>The MindSpore Lite release package provides the matching Ascend version and supports C++ and Java inference.</p></li>
</ol>
<p>The C++ APIs provided by the two solutions are basically the same. In the future, MindSpore Lite is used instead of building and maintaining two sets of interfaces.</p>
<p>The original Atlas 200/300/500 inference product inference service built based on the MindSpore main release package can be switched to MindSpore Lite with a few modifications. The following is an example:</p>
<ol class="arabic">
<li><p>compiling a C++ Project</p>
<p>You do not need to use the MindSpore installation package. You need to download the MindSpore Lite C++ version package and decompress it to any working directory. The directory structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>mindspore-lite-{version}-linux-{arch}
├── runtime
│   ├── include
│   ├── lib
</pre></div>
</div>
<p>The path to the include header file is changed to the include directory, and the link to the dynamic library is changed to lib/libmindspore-lite.so during compilation. If minddata is required, also link lib/libminddata-lite.so.</p>
<p>For example, set the environment variable <code class="docutils literal notranslate"><span class="pre">MINDSPORE_PATH=/path/to/mindspore-lite</span></code>, and cmake is rewritten in the following way:</p>
<div class="highlight-cmake notranslate"><div class="highlight"><pre><span></span>...
include_directories(${MINDSPORE_PATH})
include_directories(${MINDSPORE_PATH}/include)
...

if(EXISTS ${MINDSPORE_PATH}/lib/libmindspore-lite.so)
    message(--------------- Compile-with-MindSpore-Lite ----------------)
    set(MS_LIB ${MINDSPORE_PATH}/lib/libmindspore-lite.so)
    set(MD_LIB ${MINDSPORE_PATH}/lib/libminddata-lite.so)
endif()

add_executable(main src/main.cc)
target_link_libraries(main ${MS_LIB} ${MD_LIB})
</pre></div>
</div>
</li>
<li><p>inference</p>
<p>Except that the usage of the following two classes is different, all the methods for obtaining and structuring input and output, and executing inference are the same.</p>
<ul>
<li><p>2.1 structuring context</p>
<p>The method for structuring context is modified as follows: <code class="docutils literal notranslate"><span class="pre">Ascend310DeviceInfo</span></code> is replaced with <code class="docutils literal notranslate"><span class="pre">AscendDeviceInfo</span></code>.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Original MindSpore</span>
<span class="o">-</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">Context</span><span class="o">&gt;</span><span class="p">();</span>
<span class="o">-</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">ascend310</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">Ascend310DeviceInfo</span><span class="o">&gt;</span><span class="p">();</span>
<span class="o">-</span><span class="w"> </span><span class="n">ascend310</span><span class="o">-&gt;</span><span class="n">SetDeviceID</span><span class="p">(</span><span class="n">device_id</span><span class="p">);</span>
<span class="o">-</span><span class="w"> </span><span class="n">context</span><span class="o">-&gt;</span><span class="n">MutableDeviceInfo</span><span class="p">().</span><span class="n">push_back</span><span class="p">(</span><span class="n">ascend310</span><span class="p">);</span>

<span class="c1">// MindSpore lite</span>
<span class="o">+</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">Context</span><span class="o">&gt;</span><span class="p">();</span>
<span class="o">+</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">ascend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">mindspore</span><span class="o">::</span><span class="n">AscendDeviceInfo</span><span class="o">&gt;</span><span class="p">();</span>
<span class="o">+</span><span class="w"> </span><span class="n">ascend</span><span class="o">-&gt;</span><span class="n">SetDeviceID</span><span class="p">(</span><span class="n">device_id</span><span class="p">);</span>
<span class="o">+</span><span class="w"> </span><span class="n">context</span><span class="o">-&gt;</span><span class="n">MutableDeviceInfo</span><span class="p">().</span><span class="n">push_back</span><span class="p">(</span><span class="n">ascend</span><span class="p">);</span>
</pre></div>
</div>
</li>
<li><p>2.2 graph compilation</p>
<p>The graph compilation interface is adjusted as follows: You do not need to construct and load graph objects. Instead, you can directly transfer the mindir model file through the <code class="docutils literal notranslate"><span class="pre">Build</span></code> interface.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Original MindSpore</span>
<span class="o">-</span><span class="w">  </span><span class="n">mindspore</span><span class="o">::</span><span class="n">Graph</span><span class="w"> </span><span class="n">graph</span><span class="p">;</span>
<span class="o">-</span><span class="w">  </span><span class="n">Serialization</span><span class="o">::</span><span class="n">Load</span><span class="p">(</span><span class="n">mindir_path</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kMindIR</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graph</span><span class="p">);</span>
<span class="o">-</span><span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">Build</span><span class="p">(</span><span class="n">GraphCell</span><span class="p">(</span><span class="n">graph</span><span class="p">),</span><span class="w"> </span><span class="n">context</span><span class="p">);</span>

<span class="c1">// MindSpore lite</span>
<span class="o">+</span><span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="o">-&gt;</span><span class="n">Build</span><span class="p">(</span><span class="n">mindir_path</span><span class="p">,</span><span class="w"> </span><span class="n">mindspore</span><span class="o">::</span><span class="n">kMindIR</span><span class="p">,</span><span class="w"> </span><span class="n">context</span><span class="p">);</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ol>
<br/>
</section>
<section id="q-what-should-i-do-when-an-error-/usr/bin/ld-warning-libxxx-so,-needed-by-libmindspore-so,-not-found-prompts-during-application-compiling?">
<h2>Q: What should I do when an error <code class="docutils literal notranslate"><span class="pre">/usr/bin/ld:</span> <span class="pre">warning:</span> <span class="pre">libxxx.so,</span> <span class="pre">needed</span> <span class="pre">by</span> <span class="pre">libmindspore.so,</span> <span class="pre">not</span> <span class="pre">found</span></code> prompts during application compiling?<a class="headerlink" href="#q-what-should-i-do-when-an-error-/usr/bin/ld-warning-libxxx-so,-needed-by-libmindspore-so,-not-found-prompts-during-application-compiling?" title="Permalink to this headline"></a></h2>
<p>A: Find the directory where the missing dynamic library file is located.</p>
<br/>
</section>
<section id="q-after-updating-mindspore-version,-the-application-compilation-reports-errors-warning-packages-not-found-mindspore-ascend,-cmake-error-the-following-variables-are-use-in-this-project,-but-they-are-set-to-notfound-please-set-them-or-make-sure-they-are-set-and-tested-correctly-in-the-cmake-files-ms-lib-what-should-i-do?">
<h2>Q: After updating MindSpore version, the application compilation reports errors <code class="docutils literal notranslate"><span class="pre">WARNING:</span> <span class="pre">Package(s)</span> <span class="pre">not</span> <span class="pre">found:</span> <span class="pre">mindspore-ascend</span></code>, <code class="docutils literal notranslate"><span class="pre">CMake</span> <span class="pre">Error:</span> <span class="pre">The</span> <span class="pre">following</span> <span class="pre">variables</span> <span class="pre">are</span> <span class="pre">use</span> <span class="pre">in</span> <span class="pre">this</span> <span class="pre">project,</span> <span class="pre">but</span> <span class="pre">they</span> <span class="pre">are</span> <span class="pre">set</span> <span class="pre">to</span> <span class="pre">NOTFOUND.</span> <span class="pre">Please</span> <span class="pre">set</span> <span class="pre">them</span> <span class="pre">or</span> <span class="pre">make</span> <span class="pre">sure</span> <span class="pre">they</span> <span class="pre">are</span> <span class="pre">set</span> <span class="pre">and</span> <span class="pre">tested</span> <span class="pre">correctly</span> <span class="pre">in</span> <span class="pre">the</span> <span class="pre">CMake</span> <span class="pre">files:</span> <span class="pre">MS_LIB</span></code>. What should I do?<a class="headerlink" href="#q-after-updating-mindspore-version,-the-application-compilation-reports-errors-warning-packages-not-found-mindspore-ascend,-cmake-error-the-following-variables-are-use-in-this-project,-but-they-are-set-to-notfound-please-set-them-or-make-sure-they-are-set-and-tested-correctly-in-the-cmake-files-ms-lib-what-should-i-do?" title="Permalink to this headline"></a></h2>
<p>A: MindSpore 2.0 has unified the installation packages of various platforms and no longer distinguishes different installation packages with suffixes such as <code class="docutils literal notranslate"><span class="pre">-ascend</span></code>, <code class="docutils literal notranslate"><span class="pre">-gpu</span></code>, etc. Therefore, the old compilation command or the old <code class="docutils literal notranslate"><span class="pre">build.sh</span></code> with <code class="docutils literal notranslate"><span class="pre">MINDSPORE_PATH=&quot;`pip</span> <span class="pre">show</span> <span class="pre">mindspore-ascend</span> <span class="pre">|</span> <span class="pre">grep</span> <span class="pre">Location</span> <span class="pre">|</span> <span class="pre">awk</span> <span class="pre">'{print</span> <span class="pre">$2&quot;/mindspore&quot;}'</span> <span class="pre">|</span> <span class="pre">xargs</span> <span class="pre">realpath`&quot;</span></code> needs to be modified to <code class="docutils literal notranslate"><span class="pre">MINDSPORE_PATH=&quot;`pip</span> <span class="pre">show</span> <span class="pre">mindspore</span> <span class="pre">|</span> <span class="pre">grep</span> <span class="pre">Location</span> <span class="pre">|</span> <span class="pre">awk</span> <span class="pre">'{print</span> <span class="pre">$2&quot;/mindspore&quot;}'</span> <span class="pre">|</span> <span class="pre">xargs</span> <span class="pre">realpath`&quot;</span></code>.</p>
<br/>
</section>
<section id="q-what-should-i-do-when-error-error-while-loading-shared-libraries-libge-compiler-so-cannot-open-shared-object-file-no-such-file-or-directory-prompts-during-application-running?">
<h2>Q: What should I do when error <code class="docutils literal notranslate"><span class="pre">error</span> <span class="pre">while</span> <span class="pre">loading</span> <span class="pre">shared</span> <span class="pre">libraries:</span> <span class="pre">libge_compiler.so:</span> <span class="pre">cannot</span> <span class="pre">open</span> <span class="pre">shared</span> <span class="pre">object</span> <span class="pre">file:</span> <span class="pre">No</span> <span class="pre">such</span> <span class="pre">file</span> <span class="pre">or</span> <span class="pre">directory</span></code> prompts during application running?<a class="headerlink" href="#q-what-should-i-do-when-error-error-while-loading-shared-libraries-libge-compiler-so-cannot-open-shared-object-file-no-such-file-or-directory-prompts-during-application-running?" title="Permalink to this headline"></a></h2>
<p>A: While Atlas 200/300/500 inference product software packages relied by MindSpore is installed, the <code class="docutils literal notranslate"><span class="pre">CANN</span></code> package should install the full-featured <code class="docutils literal notranslate"><span class="pre">toolkit</span></code> version instead of the <code class="docutils literal notranslate"><span class="pre">nnrt</span></code> version.</p>
<br/>
</section>
<section id="q-how-to-configure-aipp-files?">
<h2>Q: How to configure AIPP files?<a class="headerlink" href="#q-how-to-configure-aipp-files?" title="Permalink to this headline"></a></h2>
<p>A: AIPP (artistic intelligence pre-processing) AI preprocessing is used to complete image preprocessing on AI core, including changing image size, color gamut conversion (converting image format), subtracting mean / multiplication coefficient (changing image pixels). Real-time inference is performed after data processing. The related configuration introduction is complex. Please refer to <a class="reference external" href="https://www.hiascend.com/document/detail/zh/canncommercial/51RC2/inferapplicationdev/atctool/atctool_0017.html">AIPP enable chapter of ATC tool</a>.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="distributed_parallel.html" class="btn btn-neutral float-left" title="Distributed Parallel" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="feature_advice.html" class="btn btn-neutral float-right" title="Feature Advice" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>