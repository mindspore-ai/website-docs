<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>FAQs &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script src="../_static/js/mermaid-9.3.0.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Using Third-party Operator Libraries Based on Customized Interfaces" href="use_third_party_op.html" />
    <link rel="prev" title="Network Migration Debugging Example" href="sample_code.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/tensor_view.html">TENSOR VIEWS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/programming_paradigm.html">Functional and Object-Oriented Fusion Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/distributed_training_design.html">Distributed Parallel Native</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/all_scenarios.html">Full-scenarios Unified Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/official_models.html">Official Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.hal.html">mindspore.hal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.multiprocessing.html">mindspore.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.experimental.html">mindspore.experimental</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="enveriment_preparation.html">Environment Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_development/model_development.html">Network Constructing Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">FAQs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="use_third_party_op.html">Using Third-party Operator Libraries Based on Customized Interfaces</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Syntax Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax_support.html">Static Graph Syntax Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/operators.html">Static Graph Syntax - Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/statements.html">Static Graph Syntax - Python Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax/python_builtin_functions.html">Static Graph Syntax - Python Built-in Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/index_support.html">Tensor Index Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/env_var_list.html">Environment Variables</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>FAQs</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/migration_guide/faq.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="faqs">
<h1>FAQs<a class="headerlink" href="#faqs" title="Permalink to this headline"></a></h1>
<a class="reference external image-reference" href="https://gitee.com/mindspore/docs/blob/r2.3/docs/mindspore/source_en/migration_guide/faq.rst"><img alt="View Source on Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3/resource/_static/logo_source_en.svg" /></a>
<div class="toctree-wrapper compound">
</div>
<p>MindSpore provides a <a class="reference external" href="https://mindspore.cn/docs/en/r2.3/faq/installation.html">FAQ</a> during using MindSpore. This chapter also collates the solutions to the set of common problems mentioned in the migration documentation.</p>
<ul>
<li><p>Environmental Preparations</p>
<p><strong>Q: How do I set up a MindSpore environment?</strong></p>
<p>A: MindSpore currently supports running on various devices such as Ascend, GPU, CPU. However, you need to pay attention to choosing the matching hardware platform, operating system, and Python version during the installation process, or else there will be a lot of unpredictable errors. For details, please refer to <a class="reference external" href="https://www.mindspore.cn/install/">Installation guide</a> .</p>
<p>For more environmental preparation FAQs, please refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/faq/installation.html">Environmental Preparation FAQ Analysis</a> .</p>
</li>
<li><p>Model Analysis and Preparation</p>
<p><strong>Q: How can I see how well MindSpore supports the APIs in the migrated code?</strong></p>
<p>A: The API automated scanning tool MindSpore Dev Toolkit can be used (recommended), or we can manually query the API mapping table. For details, please refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/migration_guide/analysis_and_preparation.html#analyzing-api-compliance">Analyzing API Compliance</a> .</p>
</li>
<li><p>Constructing Dataset</p>
<p><strong>Q: How do I convert a PyTorch `dataset` to a MindSpore `dataset`?</strong></p>
<p>A: The customized dataset logic of MindSpore is similar to that of PyTorch. You need to define a <cite>dataset</cite> class containing <cite>__init__</cite>, <cite>__getitem__</cite>, and <cite>__len__</cite> to read your dataset, instantiate the class into an object (for example, <cite>dataset/dataset_generator</cite>), and transfer the instantiated object to <cite>GeneratorDataset</cite> (on MindSpore) or <cite>DataLoader</cite> (on PyTorch). Then, you are ready to load the customized dataset.</p>
<p>MindSpore provides further <cite>map</cite>-&gt;`batch` operations based on <cite>GeneratorDataset</cite>. Users can easily add other customized operations to <cite>map</cite> and start <cite>batch</cite>.
The customized dataset of MindSpore is loaded as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1 Data enhancement,shuffle,sampler.</span>
<span class="k">class</span> <span class="nc">Mydata</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">58</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">__label</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">)</span>
<span class="n">dataset_generator</span> <span class="o">=</span> <span class="n">Mydata</span><span class="p">()</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">dataset_generator</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># 2 Customized data enhancement</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">pyFunc</span><span class="p">,</span> <span class="p">{</span><span class="n">other_params</span><span class="p">})</span>
<span class="c1"># 3 batch</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Q: Why does it report an error when iterating over the data: “The actual amount of data read from generator xx is different from generator.len xx, you should adjust generator.len to make them match” ?</strong></p>
<p>A: When defining a randomizable datasets, the result returned by the <cite>__len__</cite> method must be the real dataset size, if it is set to a large size, there will be an out-of-bounds problem when <cite>__getitem__</cite> fetches the value. If the size of the dataset is not defined, you can use an iterable dataset, see <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.3/beginner/dataset.html">Customize dataset</a> for details.</p>
<p><strong>Q: Why does it report an error when iterating over the data: “Invalid Python function, the ‘source’ of ‘GeneratorDataset’ should return same number of NumPy arrays as specified in column_names, the size of column_names is:xx and number of returned NumPy array is:xx” ?</strong></p>
<p>A: This is because the number of column names specified in the column_names parameter of GeneratorDataset does not match the number of data output by the source parameter.</p>
<p><strong>Q: When using GeneratorDataset or map to load/process data, there may be syntax errors, calculation overflow and other issues that cause data errors, how to troubleshoot and debug?</strong></p>
<p>A: Observe the error stack information and locate the error code block from the error stack information, add a print or debugging point near the block of code where the error occurred, to further debugging. For details, please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.3/advanced/error_analysis/minddata_debug.html#method-1-errors-in-data-processing-execution,-print-logs-or-add-debug-points-to-code-debugging">Data Processing Debugging Method 1</a> .</p>
<p><strong>Q: How to test the each data processing operator in the map operation if data-enhanced map operation error is reported?</strong></p>
<p>A: Map operation can be debugged through the execution of individual operators or through data pipeline debugging mode. For details, please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.3/advanced/error_analysis/minddata_debug.html#method-2-data-enhanced-map-operation-error,-testing-the-each-data-processing-operator-in-the-map-operation">Data Processing Debugging Method 2</a> .</p>
<p><strong>Q: While training, we will get very many WARNINGs suggesting that our dataset performance is slow, how should we handle this?</strong></p>
<p>A: It is possible to iterate through the dataset individually and see the processing time for each piece of data to determine how well the dataset is performing. For details, please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.3/advanced/error_analysis/minddata_debug.html#method-3-testing-data-processing-performance">Data Processing Debugging Method 3</a> .</p>
<p><strong>Q: In the process of processing data, if abnormal result values are generated due to computational errors, numerical overflow, etc., resulting in operator computation overflow and weight update anomalies during network training, how should we troubleshoot them?</strong></p>
<p>A: Turn off shuffling and fix random seeds to ensure reproductivity, and then use tools such as NumPy to quickly verify the results. For details, please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.3/advanced/error_analysis/minddata_debug.html#method-4-checking-for-exception-data-in-data-processing">Data Processing Debugging Method 4</a> .</p>
<p>For more common data processing problems, please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.3/advanced/error_analysis/minddata_debug.html#analyzing-common-data-processing-problems">Analyzing Common Data Processing Problems</a> , and for differences in data processing during migration, please refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/migration_guide/model_development/dataset.html#comparison-of-data-processing-differences">Data Pre-Processing Differences Between MindSpore And PyTorch</a> .</p>
</li>
<li><p>Gradient Derivation</p>
<p><strong>Q: How can I implement the backward computation of an operator?</strong></p>
<p>A: MindSpore provides an automated interface for gradient derivation, a feature that shields the user from a great deal of the details and process of derivation. However, if there are some special scenarios where the user needs to manually control the calculation of its backward computation, the user can also define its backward computation through the Cell.bprop interface. For details, please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.3/advanced/modules/layer.html#custom-cell-reverse">Customize Cell reverse</a> .</p>
<p><strong>Q: How to deal with training instability due to gradient overflow?</strong></p>
<p>A: Network overflows are usually manifested as loss Nan/INF, the loss suddenly becomes very large. MindSpore provides <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r2.3/debug/dump.html">dump data</a> to get the information about the overflow operator information. When there is gradient underflow in the network, we can use loss scale to support gradient derivation. For details, please refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/migration_guide/model_development/gradient.html#loss-scale">loss scale</a>; When the network has gradient explosion, you can consider adding gradient trimming. For details, please refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/migration_guide/model_development/gradient.html#gradient-cropping">gradient cropping</a> .</p>
</li>
<li><p>Debugging and Tuning</p>
<p><strong>Q: How do I load a pre-trained PyTorch model for fine-tuning on MindSpore?</strong></p>
<p>A: Map parameters of PyTorch and MindSpore one by one. No unified conversion script is provided due to flexible network definitions.</p>
<p>In general, the parameters names and parameters values are saved in the CheckPoint file. After invoking the loading interface of the corresponding framework and obtaining the parameter names and values, construct the object according to the MindSpore format, and then you can directly invoke the MindSpore interface to save as CheckPoint files in the MindSpore format.</p>
<p>The main work is to compare the parameter names between different frameworks, so that all parameter names in the network of the two frameworks correspond to each other (a map can be used for mapping). The logic of the following code is transforming the parameter format, excluding the corresponding parameter name.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="k">def</span> <span class="nf">pytorch2mindspore</span><span class="p">(</span><span class="n">default_file</span> <span class="o">=</span> <span class="s1">&#39;torch_resnet.pth&#39;</span><span class="p">):</span>
    <span class="c1"># read pth file</span>
    <span class="n">par_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">default_file</span><span class="p">)[</span><span class="s1">&#39;state_dict&#39;</span><span class="p">]</span>
    <span class="n">params_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">par_dict</span><span class="p">:</span>
        <span class="n">param_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">parameter</span> <span class="o">=</span> <span class="n">par_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="n">param_dict</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">name</span>
        <span class="n">param_dict</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">parameter</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">params_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param_dict</span><span class="p">)</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">params_list</span><span class="p">,</span>  <span class="s1">&#39;ms_resnet.ckpt&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Q: How can I deal with the problem where a loss does not converge or the accuracy doen not meet the standard?</strong></p>
<p>A: Substandard accuracy is generally reflected in the loss not converging, but the accuracy is not as expected, which has many complex reasons, and is more difficult to locate. Here are a few guide links for users to troubleshoot the problem one by one.</p>
<p><a class="reference external" href="https://www.hiascend.com/forum/thread-0215121673876901029-1-1.html">MindSpore Model Accuracy Tuning Practice (1): Common Accuracy Problems, Causes, and Tuning Approach</a>.</p>
<p><a class="reference external" href="https://www.hiascend.com/forum/thread-0235121941309178031-1-1.html">MindSpore Model Accuracy Tuning Practice (2): Accuracy Debugging and Tuning Approach</a>.</p>
<p><a class="reference external" href="https://www.hiascend.com/forum/thread-0235121941523411032-1-1.html">MindSpore Model Accuracy Tuning Practice (3): Common Accuracy Problems</a>.</p>
<p>For more debugging and tuning FAQs, please refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/migration_guide/debug_and_tune.html#debugging-tools">Tuning FAQs and Solutions</a> .</p>
<p><strong>Q: During model training, the first step takes a long time, how to optimize it?</strong></p>
<p>A: During the model training process, the first step contains the network compilation time. If you want to optimize the performance of the first step, you can analyze whether the model compilation can be optimized. For details, please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.3/advanced/static_graph_expert_programming.html">Static graph network compilation performance optimization</a>.</p>
<p><strong>Q: The non-first step takes a long time during model training, how to optimize it?</strong></p>
<p>A: The time-consumption of non-first step during model training includes iteration gap, forward-backward computation and iteration trailing. If we want to optimize the performance of non-first step, we need to obtain the iteration trajectory of the network, and then analyze which part is the performance bottleneck, and optimize the performance recently.</p>
<p>For details, please refer to <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r2.2/performance_tuning_guide.html">Performance Tuning Guide</a>; and <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r2.2/performance_optimization.html">Performance Debugging Examples</a> .</p>
<p><strong>Q: When loading benchmark weights for model inference to validate the forward process, there is a warning warning that the weights were not loaded successfully, how to solve it?</strong></p>
<p>A: During the load_checkpoint process, if there are weights that are not loaded, MindSpore will give a warning prompt. Generally there are two reasons for loading failure: 1, the weight name is not correct; 2, the weight is missing in the network.</p>
<p>If the weight names don’t match, you need to print MindSpore weight names and the benchmark weight names to see if MindSpore weight names have extra prefixes such as backbone or network, and if so, check whether MindSpore adds auto_prefix=False when initializing <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/api_python/nn/mindspore.nn.Cell.html">Cell</a> when initializing _ with auto_prefix=False.</p>
<p>If the weight name is missing, you need to analyze whether it is reasonable or not. If it is reasonable, you can ignore the alarm prompts, if it is not reasonable, you need to analyze whether the network definition is wrong, and locate and modify it.</p>
<p><strong>Q: The migration process is tuned using PyNative, and the process is successful. When I switch to Graph mode, why do I get reported errors?</strong></p>
<p>A: The behavior of the model for inference in PyNative mode is no different from normal Python code. However, when switching to Graph mode, MindSpore converts Python source code to Intermediate Representation (IR) by means of source code conversion, and optimizes IR graphs on this basis, and finally executes the optimized graphs on hardware devices.</p>
<p>In this step of operation, currently MindSpore does not yet support the complete Python syntax, so there are some limitations in the writing of the construct function.</p>
<p>For example, PyNative mode can directly determine whether a Tensor value is 0, but switching to Graph mode will report an error that it is not supported.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">response</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">loss</span>
<span class="k">return</span> <span class="n">loss</span><span class="o">/</span><span class="n">response</span>
</pre></div>
</div>
<p>In similar cases, the code can be modified to:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">response_gt</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">/</span><span class="n">response_gt</span>
<span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/note/static_graph_syntax_support.html">Static diagram syntax support</a> for details.</p>
<p><strong>Q: What can I do if the error is reported during training: RuntimeError: “Launch kernel failed, name:Default/… What to do” ?</strong></p>
<p>A: This type of error is usually because MindSpore does not support a certain operator, and may require the user to implement the operator themselves. For more details, see <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API mapping table</a> .</p>
<p><strong>Q: How can I effectively locate the cause of an error reported during PyNative dynamic graph migration?</strong></p>
<p>A: If you encounter dynamic graph problems, you can set mindspore.set_context(pynative_synchronize=True) to view the error stack to assist in locating them. For details, please refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/api_python/mindspore/mindspore.set_context.html?highlight=pynative_synchronize">pynative_synchronize description</a> .</p>
<p><strong>Q: How can I effectively locate the cause of an error reported during Graph mode static graph training?</strong></p>
<p>A: There are many reasons for static graph errors, and the general failure will be printed in the log. If you can’t intuitively get the error information from the log, you can analyze it by export GLOG_v=1 to specify the log level to get more detailed information about the error.</p>
<p>Meanwhile, when the compilation of computational graphs reports errors, it will automatically save the file analyze_failed.ir, which can help to analyze the location of the error code. For more details, please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.3/advanced/error_analysis/error_scenario_analysis.html">Static Graph Mode Error Analysis</a>.</p>
<p><strong>Q: Out Of Memory error is reported during Graph mode static graph training, what should I do?</strong></p>
<p>A: There are two possible reasons for this error: 1. resources are occupied; 2. not enough video memory.</p>
<p>When resources are occupied, release them via pkill -9 python and retrain.</p>
<p>When there is not enough memory, try lowering the batch_size; analyze the memory to see if there are too many communication operators resulting in low overall memory reuse.</p>
<p>For more details, please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.3/advanced/error_analysis/mindrt_debug.html#insufficient-resources">Analysis of the problem of insufficient resources</a> .</p>
<p>See <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/faq/implement_problem.html">Execution Issues</a> for more tuning FAQs.</p>
</li>
</ul>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="sample_code.html" class="btn btn-neutral float-left" title="Network Migration Debugging Example" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="use_third_party_op.html" class="btn btn-neutral float-right" title="Using Third-party Operator Libraries Based on Customized Interfaces" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>