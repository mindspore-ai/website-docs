<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Constructing Dataset &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script><script src="../../_static/jquery.js"></script>
        <script src="../../_static/js/theme.js"></script><script src="../../_static/underscore.js"></script><script src="../../_static/doctools.js"></script><script src="../../_static/js/mermaid-9.3.0.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Network Construction" href="model_and_cell.html" />
    <link rel="prev" title="Network Constructing Comparison" href="model_development.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../design/overview.html">MindSpore Design Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/programming_paradigm.html">Functional and Object-Oriented Fusion Programming Paradigm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/dynamic_graph_and_static_graph.html">Combination of Dynamic and Static Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/distributed_training_design.html">Distributed Parallel Native</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/data_engine.html">High Performance Data Processing Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/all_scenarios.html">Full-scenarios Unified Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/graph_fusion_engine.html">Graph-Kernel Fusion Acceleration Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/pluggable_device.html">Third-Party Hardware Interconnection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/official_models.html">Official Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.hal.html">mindspore.hal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.multiprocessing.html">mindspore.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.experimental.html">mindspore.experimental</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Mapping</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Migration Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Overview of Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../enveriment_preparation.html">Environment Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../analysis_and_preparation.html">Model Analysis and Preparation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="model_development.html">Network Constructing Comparison</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Constructing Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_and_cell.html">Network Construction</a></li>
<li class="toctree-l2"><a class="reference internal" href="learning_rate_and_optimizer.html">Learning Rate and Optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="gradient.html">Gradient Derivation</a></li>
<li class="toctree-l2"><a class="reference internal" href="training_and_evaluation.html">Inference and Training Process</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../debug_and_tune.html">Debugging and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sample_code.html">Network Migration Debugging Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Syntax Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax_support.html">Static Graph Syntax Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax/operators.html">Static Graph Syntax - Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax/statements.html">Static Graph Syntax - Python Statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax/python_builtin_functions.html">Static Graph Syntax - Python Built-in Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/index_support.html">Tensor Index Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Environment Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/env_var_list.html">Environment Variables</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/network_compilation.html">Network Compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/distributed_parallel.html">Distributed Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/feature_advice.html">Feature Advice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="model_development.html">Network Constructing Comparison</a> &raquo;</li>
      <li>Constructing Dataset</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/migration_guide/model_development/dataset.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section class="tex2jax_ignore mathjax_ignore" id="constructing-dataset">
<h1>Constructing Dataset<a class="headerlink" href="#constructing-dataset" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r2.3/docs/mindspore/source_en/migration_guide/model_development/dataset.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3/resource/_static/logo_source_en.svg" /></a></p>
<p>This chapter focuses on considerations related to data processing in network migration. For basic data processing, please refer to:</p>
<p><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.3/beginner/dataset.html">Data Processing</a></p>
<p><a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r2.3/dataset/augment.html">Auto Augmentation</a></p>
<p><a class="reference external" href="https://mindspore.cn/tutorials/en/r2.3/advanced/dataset/eager.html">Lightweight Data Processing</a></p>
<p><a class="reference external" href="https://www.mindspore.cn/tutorials/experts/en/r2.3/dataset/optimize.html">Optimizing the Data Processing</a></p>
<section id="comparison-of-data-processing-differences">
<h2>Comparison of Data Processing Differences<a class="headerlink" href="#comparison-of-data-processing-differences" title="Permalink to this headline"></a></h2>
<p>The basic process of data construction in MindSpore and PyTorch mainly includes two aspects: dataset loading and data augmentation.The following is a comparison of the differences between the two writing methods in terms of reading common dataset processing flow and reading customized dataset processing flow:</p>
<section id="processing-common-datasets">
<h3>Processing Common Datasets<a class="headerlink" href="#processing-common-datasets" title="Permalink to this headline"></a></h3>
<p>MindSpore provides <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/api_python/mindspore.dataset.html">interfaces</a> for loading common datasets from many different domains.
In addition to the above commonly used datasets in the industry, MindSpore has also developed MindRecord data format to cope with efficient reading, mega data storage and reading scenarios, and you can refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.3/advanced/dataset/record.html">MindRecord</a> . Since this article is to introduce similar APIs and the differences in the writing style, so we have selected one of the more classic dataset APIs as an example of migration comparison. For other dataset interface differences, please refer to the <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/note/api_mapping/pytorch_api_mapping.html#torchaudio">torchaudio</a>, <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/note/api_mapping/pytorch_api_mapping.html#torchtext">torchtext</a>, <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/note/api_mapping/pytorch_api_mapping.html#torchvision">torchvision</a> modules of PyTorch and MindSpore API mapping table.</p>
<p>Here is an example of FashionMnistDataset. The following figure shows how to use the PyTorch API (left part), and how to use the MindSpore API (right part). The main reading process is: use FashionMnist API to load the source dataset, then use transforms to transform the data content, and finally according to the batch operation on the dataset. The key parts of the code on both sides are marked with color boxes.</p>
<p><img alt="FashionMnistDataset" src="../../_images/fashionmnist_ms_pytorch.png" /></p>
<p>You can see the following differences between MindSpore and PyTorch in reading common data.</p>
<ol class="arabic">
<li><p>Different ways to get and read datasets:</p>
<ul class="simple">
<li><p>PyTorch can download the dataset locally and pass it to the API interface for reading and parsing, or set the <code class="docutils literal notranslate"><span class="pre">download</span></code> parameter of the API interface to download the dataset and read it.</p></li>
<li><p>MindSpore needs to download the dataset locally and then pass it to the API for reading and parsing.</p></li>
</ul>
</li>
<li><p>Functions such as shuffling, batch processing, and parallel loading of the dataset itself are supported in different ways:</p>
<ul class="simple">
<li><p>PyTorch supports configuring parameters <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> , <code class="docutils literal notranslate"><span class="pre">batch</span></code> , <code class="docutils literal notranslate"><span class="pre">num_workers</span></code> , etc. in the <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> to realize the corresponding functions.</p></li>
<li><p>Due to the difference of interface API design, MindSpore directly carries the functions of shuffle and parallel loading in the dataset API interface through the parameters <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> and <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> , and then uses the <code class="docutils literal notranslate"><span class="pre">batch</span></code> operation to merge the consecutive data of the dataset into one batch after the data augmentation is finished. For <code class="docutils literal notranslate"><span class="pre">batch</span></code> operation, please refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/api_python/dataset/dataset_method/batch/mindspore.dataset.Dataset.batch.html#mindspore.dataset.Dataset.batch">batch</a> for more details. Due to the difference in API design, it should be noted that the parameter <code class="docutils literal notranslate"><span class="pre">drop_remainder</span></code> of <code class="docutils literal notranslate"><span class="pre">batch</span></code> operation in MindSpore has the same meaning as the parameter <code class="docutils literal notranslate"><span class="pre">drop_last</span></code> in PyTorch’s DataLoader.</p></li>
</ul>
<p>Except for FashionMnist API, all dataset loading APIs have the same parameter design, and <code class="docutils literal notranslate"><span class="pre">batch</span></code> operations in the above examples are applicable to all dataset APIs. The following is an example of a dataset API that can return fake images, <code class="docutils literal notranslate"><span class="pre">FakeImageDataset</span></code> , and the related data operations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">FakeImageDataset</span><span class="p">(</span><span class="n">num_images</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">base_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>\
    <span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;When drop_remainder=True, the last batch will be drop, the total batch number is &quot;</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">())</span>
<span class="c1"># 1000 // 32 = 31</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">FakeImageDataset</span><span class="p">(</span><span class="n">num_images</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">base_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>\
    <span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;When drop_remainder=False, the last batch will not be drop, the total batch number is &quot;</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">())</span>
<span class="c1"># ceil(1000 / 32) = 32</span>
</pre></div>
</div>
<p>Outputs:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>When drop_remainder=True, the last batch will be drop, the total batch number is 31
When drop_remainder=False, the last batch will not be drop, the total batch number is 32
</pre></div>
</div>
<p>The batch operation can also use some augmentation operations within batch, see <a class="reference external" href="https://gitee.com/mindspore/models/blob/master/official/cv/YOLOv3/src/yolo_dataset.py#L177">YOLOv3</a> for details.</p>
<p>As mentioned above, <strong>the dataset loading API contains the same parameters</strong>. Here are some common ones:</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Attributes</p></th>
<th class="head"><p>Introduction</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>num_samples(int)</p></td>
<td><p>Specify the total number of data samples</p></td>
</tr>
<tr class="row-odd"><td><p>shuffle(bool)</p></td>
<td><p>Whether to do random disruptions to the data</p></td>
</tr>
<tr class="row-even"><td><p>sampler(Sampler)</p></td>
<td><p>Data sampler, customizing data disruption, allocation. <code class="docutils literal notranslate"><span class="pre">sampler</span></code> setting and <code class="docutils literal notranslate"><span class="pre">num_shards</span></code>, <code class="docutils literal notranslate"><span class="pre">shard_id</span></code> mutually exclusive</p></td>
</tr>
<tr class="row-odd"><td><p>num_shards(int)</p></td>
<td><p>Used in distributed scenarios to divide data into several parts, used in conjunction with <code class="docutils literal notranslate"><span class="pre">shard_id</span></code></p></td>
</tr>
<tr class="row-even"><td><p>shard_id(int)</p></td>
<td><p>For distributed scenarios, taking nth data (n ranges from 0 to n-1, and n is the set <code class="docutils literal notranslate"><span class="pre">num_shards</span></code>), used in conjunction with <code class="docutils literal notranslate"><span class="pre">num_shards</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>num_parallel_workers(int)</p></td>
<td><p>Number of threads in parallel configuration</p></td>
</tr>
</tbody>
</table>
<p>Here is an example of <code class="docutils literal notranslate"><span class="pre">FakeImageDataset</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">FakeImageDataset</span><span class="p">(</span><span class="n">num_images</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">base_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">())</span>
<span class="c1"># 1000</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">FakeImageDataset</span><span class="p">(</span><span class="n">num_images</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">base_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">())</span>
<span class="c1"># 3</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">FakeImageDataset</span><span class="p">(</span><span class="n">num_images</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">base_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                              <span class="n">num_shards</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">())</span>
<span class="c1"># 1000 / 8 = 125</span>
</pre></div>
</div>
<p>Outputs:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>1000
3
125
</pre></div>
</div>
</li>
<li><p>Data augmentation operations use different:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># PyTorch
trans = torchvision.transforms.Resize(...)
mnist_train = torchvision.datasets.FashionMNIST(..., transforms=trans, ...)

# MindSpore
trans = mindspore.dataset.vision.Resize(...)
mnist_train = mindspore.dataset.FashionMnistDataset(...)
mnist_train = mnist_train.map(trans, ...)
</pre></div>
</div>
<ul class="simple">
<li><p>PyTorch passes data augmentation operations as parameters to the API interface when reading common datasets.</p></li>
<li><p>MindSpore uses <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/api_python/dataset/dataset_method/operation/mindspore.dataset.Dataset.map.html">map</a> for a series of data augmentation operations. Simply put, <code class="docutils literal notranslate"><span class="pre">map</span></code> fetches data one by one from the
previous data node and performs the specified transformations on each piece of data. The data augmentation operation passed into the <code class="docutils literal notranslate"><span class="pre">map</span></code> operation can contain the various types of data augmentation methods pre-provided by MindSpore: <a class="reference external" href="https://mindspore.cn/docs/en/r2.3/api_python/mindspore.dataset.transforms.html#module-mindspore.dataset.audio">audio</a>, <a class="reference external" href="https://mindspore.cn/docs/en/r2.3/api_python/mindspore.dataset.transforms.html#module-mindspore.dataset.text">text</a>, <a class="reference external" href="https://mindspore.cn/docs/en/r2.3/api_python/mindspore.dataset.transforms.html#module-mindspore.dataset.vision">vision</a>, and <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/api_python/mindspore.dataset.transforms.html">transforms</a>. For more details, please refer to <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.3/beginner/transforms.html">Data Transforms Transforms</a>. It can also be a Python function, in which you can freely use some third-party libraries or methods such as opencv, PIL, pandas and so on. Something to keep in mind:</p></li>
</ul>
<blockquote>
<div><p>The ops or nn operator of MindSpore cannot be used during dataset loading and data augmentation, or an exception will be thrown.</p>
</div></blockquote>
</li>
</ol>
</section>
<section id="processing-custom-datasets">
<h3>Processing Custom Datasets<a class="headerlink" href="#processing-custom-datasets" title="Permalink to this headline"></a></h3>
<p>In addition to common datasets, when encountering scenarios that require customized loading logic, you need to use a custom dataset API, the corresponding API in MindSpore is <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> , and the corresponding API in PyTorch is <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> .
The basic process of constructing custom Dataset objects in PyTorch and MindSpore requires the creation of an iterator class, such as <code class="docutils literal notranslate"><span class="pre">MyCustomDataset</span></code> below, in which <code class="docutils literal notranslate"><span class="pre">__init__</span></code> , <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> , <code class="docutils literal notranslate"><span class="pre">__len__</span></code> three methods are defined.</p>
<p><img alt="GeneratorDataset " src="../../_images/generatordataset_dataloader.png" /></p>
<p>You can see the following differences between MindSpore and PyTorch in defining and reading custom datasets.</p>
<ol class="arabic">
<li><p>Different ways of building and reading custom dataset classes:</p>
<ul class="simple">
<li><p>PyTorch customize a data loading class, the class needs to inherit <code class="docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code> , and then passed to the <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> to generate data iteration object.</p></li>
<li><p>MindSpore custom data loading class does not need to inherit from <code class="docutils literal notranslate"><span class="pre">mindspore.dataset.Dataset</span></code> and can be passed to the custom dataset interface <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> to generate data iteration objects. It is important to note that when using a custom dataset <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> , you need to set a column name for each output column, e.g. <code class="docutils literal notranslate"><span class="pre">column_names=[&quot;image&quot;]</span></code> above, which means that the first output column of the iterator is called <code class="docutils literal notranslate"><span class="pre">image</span></code> . In the subsequent data augmentation and iterative data acquisition phases, different columns can be processed separately by using the data column names. For details, please refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/note/api_mapping/pytorch_diff/DataLoader.html">Differences from torch.utils.data.DataLoader</a>. The following things need to be kept in mind when customizing the data loading class:</p></li>
</ul>
<blockquote>
<div><p>You can’t use MindSpore’s operators in the iterator class.</p>
<p>The output of the iterator needs to be a numpy array.</p>
<p>When defining a randomizable dataset, you must set the <code class="docutils literal notranslate"><span class="pre">__len__</span></code> method, the returned result must be the real dataset size, if you set it too big, there will be an out-of-bounds problem when getitem fetches the value. If the dataset size is not defined, you can use an iterable dataset, see <a class="reference external" href="https://www.mindspore.cn/tutorials/en/r2.3/beginner/dataset.html">Customize dataset</a> for details.</p>
</div></blockquote>
</li>
<li><p>Different data types for data augmentation operations:</p>
<ul class="simple">
<li><p>PyTorch’s data augmentation input is of type <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>.</p></li>
<li><p>MindSpore’s data augmentation input is of type <code class="docutils literal notranslate"><span class="pre">numpy</span></code>.</p></li>
</ul>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># PyTorch
...
img_resize = torchvision.transforms.Resize(...)(input_ids)
img_resize = torchvision.transforms.ToTensor()(img_resize)

tmp_tensor = torch.tensor(np.ones_like(img_resize))
img_resize = torch.mul(img_resize, tmp_tensor)

img_resize = torchvision.transforms.Normalize(...)(img_resize)
...

# MindSpore
...
img_resize = mindspore.dataset.vision.Resize(...)(input_ids)
img_resize = mindspore.dataset.vision.ToTensor()(img_resize)

tmp_array = np.ones_like(img_resize)
img_resize = np.multiply(img_resize, tmp_array)

img_resize = mindspore.dataset.vision.Normalize(...)(img_resize)
...
</pre></div>
</div>
<p>When PyTorch uses the <code class="docutils literal notranslate"><span class="pre">torch</span></code> operator for data processing, MindSpore cannot directly use the corresponding <code class="docutils literal notranslate"><span class="pre">ops</span></code> operator
(for details, please refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/note/api_mapping/pytorch_api_mapping.html">PyTorch and MindSpore API Mapping Table</a>), which needs to be replaced with a third party library or method such as numpy, opencv, PIL, pandas, etc. Generally speaking, MindSpore’s operators can find corresponding methods in numpy, if the function of the corresponding method is inconsistent, you can give feedback to <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues">MindSpore community</a>.</p>
</li>
<li><p>Different data processing formats:</p>
<ul class="simple">
<li><p>The data transform of <code class="docutils literal notranslate"><span class="pre">torchvision</span></code> in PyTorch processes <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> data in <code class="docutils literal notranslate"><span class="pre">CHW</span></code> format by default, and processes <code class="docutils literal notranslate"><span class="pre">PIL</span></code> data in <code class="docutils literal notranslate"><span class="pre">HWC</span></code> format by default.</p></li>
<li><p>MindSpore’s <code class="docutils literal notranslate"><span class="pre">vision</span></code> data transformation processing data is in <code class="docutils literal notranslate"><span class="pre">HWC</span></code> format by default.
For details, please refer to <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/note/api_mapping/pytorch_api_mapping.html#torchvision">the difference between torchvision and dataset.vision</a>.</p></li>
</ul>
<p>One thing to keep in mind is whether the data format should be converted from <code class="docutils literal notranslate"><span class="pre">HWC</span></code> to <code class="docutils literal notranslate"><span class="pre">CHW</span></code> in the network,
which is determined by whether the first input format of the network structure matches the data format or not,
and since the data processing is based on the <code class="docutils literal notranslate"><span class="pre">HWC</span></code> format, the result is usually <code class="docutils literal notranslate"><span class="pre">HWC</span></code>,
if it is necessary to convert the data format, then call <a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/api_python/dataset_vision/mindspore.dataset.vision.HWC2CHW.html">HWC2CHW</a> method at the last <code class="docutils literal notranslate"><span class="pre">map</span></code> of data processing.</p>
</li>
</ol>
</section>
</section>
<section id="comparison-of-data-iteration-differences">
<h2>Comparison of Data Iteration Differences<a class="headerlink" href="#comparison-of-data-iteration-differences" title="Permalink to this headline"></a></h2>
<section id="traversing-directly-over-dataset-objects">
<h3>Traversing Directly over dataset Objects<a class="headerlink" href="#traversing-directly-over-dataset-objects" title="Permalink to this headline"></a></h3>
<p>A common use of PyTorch’s data objects is to traverse them using a for loop.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">tensor_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">tensor_x</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>Outputs:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>0 torch.Size([10, 32, 32, 3])
1 torch.Size([10, 32, 32, 3])
</pre></div>
</div>
<p>MindSpore can also traverse data objects directly.</p>
<blockquote>
<div><p>Note that this writing method does not <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> after traversing an epoch, so it may affect the precision when used in training. The following two methods are recommended when direct data iterations are needed during training.</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>Outputs:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>(10, 32, 32, 3)
(10, 32, 32, 3)
</pre></div>
</div>
<p>MindSpore data objects are obtained iteratively in the following ways.</p>
</section>
<section id="create-tuple-iterator">
<h3><a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/api_python/dataset/dataset_method/iterator/mindspore.dataset.Dataset.create_tuple_iterator.html#mindspore.dataset.Dataset.create_tuple_iterator">create_tuple_iterator</a><a class="headerlink" href="#create-tuple-iterator" title="Permalink to this headline"></a></h3>
<p>Create an iterator based on the dataset object, and output data is a list of <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> data.</p>
<p>You can specify all column names and the order of the columns in the output by the parameter <code class="docutils literal notranslate"><span class="pre">columns</span></code> . If columns is not specified, the order of the columns will remain the same.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">iterator</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_tuple_iterator</span><span class="p">()</span>

<span class="k">for</span> <span class="n">data_tuple</span> <span class="ow">in</span> <span class="n">iterator</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>Outputs:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>(10, 32, 32, 3)
(10, 32, 32, 3)
</pre></div>
</div>
<p>The above two of these can be used directly when the order of data read is the same as the order required by the network.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>for data in dataset:
    loss = net(*data)
</pre></div>
</div>
</section>
<section id="create-dict-iterator">
<h3><a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/api_python/dataset/dataset_method/iterator/mindspore.dataset.Dataset.create_dict_iterator.html#mindspore.dataset.Dataset.create_dict_iterator">create_dict_iterator</a><a class="headerlink" href="#create-dict-iterator" title="Permalink to this headline"></a></h3>
<p>Creates an iterator based on the dataset object, and the output data is of dictionary type.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">iterator</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">()</span>

<span class="k">for</span> <span class="n">data_dict</span> <span class="ow">in</span> <span class="n">iterator</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>Outputs:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>data (10, 32, 32, 3)
data (10, 32, 32, 3)
</pre></div>
</div>
</section>
</section>
<section id="migration-examples">
<h2>Migration Examples<a class="headerlink" href="#migration-examples" title="Permalink to this headline"></a></h2>
<p>The following migration examples are contributed by MindSpore developers/users in the community for reference and exchange,
and more examples are very welcome to be provided to the community.</p>
<p><a class="reference external" href="https://www.hiascend.com/forum/thread-0263137175098201010-1-1.html">Migration from PyTorch to MindSpore - Data Processing</a></p>
<p><a class="reference external" href="https://www.hiascend.com/forum/thread-0283137235691918013-1-1.html">Migrating from PyTorch to MindSpore - Data Processing (Practical)</a></p>
<p><a class="reference external" href="https://www.hiascend.com/forum/thread-0244128586212080089-1-1.html">PyTorch migration to MindSpore records (top)</a></p>
<p><a class="reference external" href="https://www.hiascend.com/forum/thread-0247128586317458099-1-1.html">PyTorch migration to MindSpore records (below)</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="model_development.html" class="btn btn-neutral float-left" title="Network Constructing Comparison" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="model_and_cell.html" class="btn btn-neutral float-right" title="Network Construction" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>