<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Inference &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Feature Advice" href="feature_advice.html" />
    <link rel="prev" title="Distributed Configure" href="distributed_configure.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_processing.html">Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="implement_problem.html">Implement Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators_compile.html">Operators Compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage_migrate_3rd.html">Migration from a Third-party Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_tuning.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="precision_tuning.html">Precision Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_configure.html">Distributed Configure</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_advice.html">Feature Advice</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Inference</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/inference.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="inference">
<h1>Inference<a class="headerlink" href="#inference" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.5/docs/mindspore/faq/source_en/inference.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source_en.png"></a></p>
<p><font size=3><strong>Q: MindSpore 1.3 is installed on the Ascend 310 hardware platform. When I run the <code class="docutils literal notranslate"><span class="pre">add_model.py</span></code> sample in mindspore_serving, an error message is displayed. Why?</strong></font></p>
<p>A: Ascend 310 supports model export and Serving inference, but does not support direct inference using the MindSpore frontend Python script. In the <code class="docutils literal notranslate"><span class="pre">add</span></code> sample, the code for direct inference using the MindSpore frontend Python script is added. You only need to comment out the code in the Ascend 310 scenario.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">export_net</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Export add net of 2x2 + 2x2, and copy output model `tensor_add.mindir` to directory ../add/1&quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">add</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
    <span class="c1"># Comment out the MindSpore frontend Python script used for direct inference in the Ascend 310 scenario.</span>
    <span class="c1"># output = add(ms.Tensor(x), ms.Tensor(y))</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">add</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;tensor_add&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;MINDIR&#39;</span><span class="p">)</span>
    <span class="n">dst_dir</span> <span class="o">=</span> <span class="s1">&#39;../add/1&#39;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">dst_dir</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">OSError</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="n">dst_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dst_dir</span><span class="p">,</span> <span class="s1">&#39;tensor_add.mindir&#39;</span><span class="p">)</span>
    <span class="n">copyfile</span><span class="p">(</span><span class="s1">&#39;tensor_add.mindir&#39;</span><span class="p">,</span> <span class="n">dst_file</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;copy tensor_add.mindir to &quot;</span> <span class="o">+</span> <span class="n">dst_dir</span> <span class="o">+</span> <span class="s2">&quot; success&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="c1"># print(output.asnumpy()).</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: What should I do when error <code class="docutils literal notranslate"><span class="pre">/usr/bin/ld:</span> <span class="pre">warning:</span> <span class="pre">libxxx.so,</span> <span class="pre">needed</span> <span class="pre">by</span> <span class="pre">libmindspore.so,</span> <span class="pre">not</span> <span class="pre">found</span></code> prompts during application compiling?</strong></font></p>
<p>A: Find the directory where the missing dynamic library file is located, add the path to the environment variable <code class="docutils literal notranslate"><span class="pre">LD_LIBRARY_PATH</span></code>, and refer to <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/multi_platform_inference_ascend_310_mindir.html#building-inference-code">Inference Using the MindIR Model on Ascend 310 AI Processors#Building Inference Code</a> for environment variable settings.</p>
<br/>
<p><font size=3><strong>Q: What should I do when error <code class="docutils literal notranslate"><span class="pre">ModuleNotFoundError:</span> <span class="pre">No</span> <span class="pre">module</span> <span class="pre">named</span> <span class="pre">'te'</span></code> prompts during application running?</strong></font></p>
<p>A: First confirm whether the system environment is installed correctly and whether the whl packages such as <code class="docutils literal notranslate"><span class="pre">te</span></code> and <code class="docutils literal notranslate"><span class="pre">topi</span></code> are installed correctly. If there are multiple Python versions in the user environment, such as Conda virtual environment, you need to execute <code class="docutils literal notranslate"><span class="pre">ldd</span> <span class="pre">name_of_your_executable_app</span></code> to confirm whether the application link <code class="docutils literal notranslate"><span class="pre">libpython3.7m.so.1.0</span></code> is consistent with the current Python directory, if not, you need to adjust the order of the environment variable <code class="docutils literal notranslate"><span class="pre">LD_LIBRARY_PATH</span></code> .</p>
<br/>
<p><font size=3><strong>Q: What should I do when error <code class="docutils literal notranslate"><span class="pre">error</span> <span class="pre">while</span> <span class="pre">loading</span> <span class="pre">shared</span> <span class="pre">libraries:</span> <span class="pre">libge_compiler.so:</span> <span class="pre">cannot</span> <span class="pre">open</span> <span class="pre">shared</span> <span class="pre">object</span> <span class="pre">file:</span> <span class="pre">No</span> <span class="pre">such</span> <span class="pre">file</span> <span class="pre">or</span> <span class="pre">directory</span></code> prompts during application running?</strong></font></p>
<p>A: While installing Ascend 310 AI Processor software packages，the <code class="docutils literal notranslate"><span class="pre">CANN</span></code> package should install the full-featured <code class="docutils literal notranslate"><span class="pre">toolkit</span></code> version instead of the <code class="docutils literal notranslate"><span class="pre">nnrt</span></code> version.</p>
<p><font size=3><strong>Q: How to set high-precision or high-performance mode when performing inference on Ascend 310 AI Processor?</strong></font></p>
<p>A: Set in the inference code through the SetPrecisionMode interface of Ascend310DeviceInfo. Optional: force_fp16，allow_fp32_to_fp16，must_keep_origin_dtype，allow_mix_precision. The default value is force_fp16, which refers to the high-performance mode. High precision mode can be set to allow_fp32_to_fp16 or must_keep_origin_dtype.
<br/></p>
<p><font size=3><strong>Q: How to configure AIPP files?</strong></font></p>
<p>A: AIPP (artistic intelligence pre-processing) AI preprocessing is used to complete image preprocessing on AI core, including changing image size, color gamut conversion (converting image format), subtracting mean / multiplication coefficient (changing image pixels), and real-time inference after data processing. The related configuration introduction is complex. Please refer to <a class="reference external" href="https://support.huaweicloud.com/atctool-cann502alpha3infer/atlasatc_16_0015.html">AIPP enable chapter of ATC tool</a>
<br/></p>
<p><font size=3><strong>Q: How to set the log level in the inferenct process of Ascend 310 AI Processor?</strong></font></p>
<p>A: Use ASCEND_GLOBAL_LOG_LEVEL to set log level, 0: debug level; 1: Info level; 2: Warning level; 3: Error level; 4: Null level, no log output; Other values are illegal. Configuration example: export ASCEND_GLOBAL_LOG_LEVEL=1. If there are errors in the inference process, you can modify the log level to obtain more detailed log information.</p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="distributed_configure.html" class="btn btn-neutral float-left" title="Distributed Configure" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="feature_advice.html" class="btn btn-neutral float-right" title="Feature Advice" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>