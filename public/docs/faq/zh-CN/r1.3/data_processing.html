<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>数据处理 &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="执行问题" href="implement_problem.html" />
    <link rel="prev" title="安装" href="installation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">安装</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="implement_problem.html">执行问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage_migrate_3rd.html">第三方框架迁移使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_configure.html">分布式配置</a></li>
<li class="toctree-l1"><a class="reference internal" href="inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_advice.html">特性咨询</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>数据处理</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/data_processing.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1>数据处理<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Windows</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">环境准备</span></code> <code class="docutils literal notranslate"><span class="pre">初级</span></code> <code class="docutils literal notranslate"><span class="pre">中级</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.3/docs/mindspore/faq/source_zh_cn/data_processing.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.3/resource/_static/logo_source.png"></a></p>
<p><font size=3><strong>Q: 请问<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>支持<code class="docutils literal notranslate"><span class="pre">ds.PKSampler</span></code>采样吗？</strong></font></p>
<p>A: 自定义数据集<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>不支持<code class="docutils literal notranslate"><span class="pre">PKSampler</span></code>采样逻辑。主要原因是自定义数据操作灵活度太大了，内置的<code class="docutils literal notranslate"><span class="pre">PKSampler</span></code>难以做到通用性，所以选择在接口层面直接提示不支持。但是对于<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>，可以方便的定义自己需要的<code class="docutils literal notranslate"><span class="pre">Sampler</span></code>逻辑，即在<code class="docutils literal notranslate"><span class="pre">ImageDataset</span></code>类的<code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>函数中定义具体的<code class="docutils literal notranslate"><span class="pre">sampler</span></code>规则，返回自己需要的数据即可。</p>
<br/>
<p><font size=3><strong>Q: MindSpore如何加载已有的预训练词向量？</strong></font></p>
<p>A: 可以在定义EmbedingLookup或者Embedding时候，把预训练的词向量传进来就可以了，把预训练的词向量封装成一个Tensor作为EmbeddingLookup初始值。</p>
<br/>
<p><font size=3><strong>Q: 请问<code class="docutils literal notranslate"><span class="pre">c_transforms</span></code>和<code class="docutils literal notranslate"><span class="pre">py_transforms</span></code>有什么区别，比较推荐使用哪个？</strong></font></p>
<p>A: 推荐使用<code class="docutils literal notranslate"><span class="pre">c_transforms</span></code>，因为纯C层执行，所以性能会更好。</p>
<p>原理:<code class="docutils literal notranslate"><span class="pre">c_transform</span></code>底层使用的是C版本<code class="docutils literal notranslate"><span class="pre">opencv/jpeg-turbo</span></code>进行的数据处理，<code class="docutils literal notranslate"><span class="pre">py_transform</span></code>使用的是Python版本的<code class="docutils literal notranslate"><span class="pre">Pillow</span></code>进行数据处理。</p>
<br/>
<p><font size=3><strong>Q: 由于我一条数据包含多个图像，并且每个图像的宽高都不一致，我需要对转成mindrecord的格式进行<code class="docutils literal notranslate"><span class="pre">map</span></code>操作来进行数据处理。可是我从<code class="docutils literal notranslate"><span class="pre">record</span></code>读取的数据是<code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code>格式的数据，我的数据处理的<code class="docutils literal notranslate"><span class="pre">operations</span></code>是针对图像格式的。我应该怎么样才能对所生成的mindrecord的格式的数据进行预处理呢？</strong></font></p>
<p>A: 建议你按照如下操作进行:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#1 The defined schema is as follows: Among them, data1, data2, data3, ... These fields store your image, and only the binary of the image is stored here.</span>

<span class="n">cv_schema_json</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;int32&quot;</span><span class="p">},</span> <span class="s2">&quot;data1&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;bytes&quot;</span><span class="p">},</span> <span class="s2">&quot;data2&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;bytes&quot;</span><span class="p">},</span> <span class="s2">&quot;data3&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;bytes&quot;</span><span class="p">}}</span>

<span class="c1">#2 The organized data can be as follows, and then this data_list can be written by FileWriter.write_raw_data(...).</span>

<span class="n">data_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;1.jpg&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
<span class="n">image_bytes</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span>

<span class="n">data</span><span class="p">[</span><span class="s1">&#39;data1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_bytes</span>

<span class="n">f2</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;2.jpg&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
<span class="n">image_bytes2</span> <span class="o">=</span> <span class="n">f2</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">f2</span><span class="o">.</span><span class="n">close</span>

<span class="n">data</span><span class="p">[</span><span class="s1">&#39;data2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_bytes2</span>

<span class="n">f3</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;3.jpg&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
<span class="n">image_bytes3</span> <span class="o">=</span> <span class="n">f3</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">f3</span><span class="o">.</span><span class="n">close</span>

<span class="n">data</span><span class="p">[</span><span class="s1">&#39;data3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_bytes3</span>

<span class="n">data_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1">#3 Use MindDataset to load, then use the decode operator we provide to decode, and then perform subsequent processing.</span>

<span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">MindDataset</span><span class="p">(</span><span class="s2">&quot;mindrecord_file_name&quot;</span><span class="p">)</span>
<span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data1&quot;</span><span class="p">],</span> <span class="n">operations</span><span class="o">=</span><span class="n">vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data2&quot;</span><span class="p">],</span> <span class="n">operations</span><span class="o">=</span><span class="n">vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data3&quot;</span><span class="p">],</span> <span class="n">operations</span><span class="o">=</span><span class="n">vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">resize_op</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">)</span>
<span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">resize_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data1&quot;</span><span class="p">],</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data_set</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: 我的自定义图像数据集转为mindrecord格式时，我的数据是<code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>格式的，且<code class="docutils literal notranslate"><span class="pre">shape</span></code>为[4,100,132,3]，这个<code class="docutils literal notranslate"><span class="pre">shape</span></code>的含义是四幅三通道的帧，且每个值都在0~255。可是当我查看转化成mindrecord的格式的数据时，发现是<code class="docutils literal notranslate"><span class="pre">[19800]</span></code>的<code class="docutils literal notranslate"><span class="pre">shape</span></code>，我原数据的维度全部展开有<code class="docutils literal notranslate"><span class="pre">[158400]</span></code>，请问这是为什么？</strong></font></p>
<p>A: 可能是你数据中<code class="docutils literal notranslate"><span class="pre">ndarray</span></code>的<code class="docutils literal notranslate"><span class="pre">dtype</span></code>是<code class="docutils literal notranslate"><span class="pre">int8</span></code>，因为<code class="docutils literal notranslate"><span class="pre">[158400]</span></code>和<code class="docutils literal notranslate"><span class="pre">[19800]</span></code>刚好相差了8倍，建议将数据中<code class="docutils literal notranslate"><span class="pre">ndarray</span></code>的<code class="docutils literal notranslate"><span class="pre">dtype</span></code>指定为<code class="docutils literal notranslate"><span class="pre">float64</span></code>。</p>
<br/>
<p><font size=3><strong>Q: 想要保存生成的图片，代码运行完毕以后在相应目录找不到图片。相似的，在JupyterLab中生成数据集用于训练，训练时可以在相应路径读取到数据，但是自己却无法在路径中找到图片或数据集？</strong></font></p>
<p>A: 可能是JumperLab生成的图片或者数据集都是在Docker内，<code class="docutils literal notranslate"><span class="pre">moxing</span></code>下载的数据只能训练进程的Docker内看见，训练完成后这些数据就随着Docker释放了。 可以试试在训练任务中将需要<code class="docutils literal notranslate"><span class="pre">download</span></code>的数据再通过<code class="docutils literal notranslate"><span class="pre">moxing</span></code>传回<code class="docutils literal notranslate"><span class="pre">obs</span></code>，然后再在<code class="docutils literal notranslate"><span class="pre">obs</span></code>里面下载到你本地。</p>
<br/>
<p><font size=3><strong>Q: MindSpore中<code class="docutils literal notranslate"><span class="pre">model.train</span></code>的<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code>参数该如何理解？</strong></font></p>
<p>A: 当<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode=True</span></code>时，数据处理会和网络计算构成Pipeline方式，即: 数据处理在逐步处理数据时，处理完一个<code class="docutils literal notranslate"><span class="pre">batch</span></code>的数据，会把数据放到一个队列里，这个队列用于缓存已经处理好的数据，然后网络计算从这个队列里面取数据用于训练，那么此时数据处理与网络计算就<code class="docutils literal notranslate"><span class="pre">Pipeline</span></code>起来了，整个训练耗时就是数据处理/网络计算耗时最长的那个。</p>
<p>当<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode=False</span></code>时，数据处理会和网络计算构成串行的过程，即: 数据处理在处理完一个<code class="docutils literal notranslate"><span class="pre">batch</span></code>后，把这个<code class="docutils literal notranslate"><span class="pre">batch</span></code>的数据传递给网络用于计算，在计算完成后，数据处理再处理下一个<code class="docutils literal notranslate"><span class="pre">batch</span></code>，然后把这个新的<code class="docutils literal notranslate"><span class="pre">batch</span></code>数据传递给网络用于计算，如此的循环往复，直到训练完。该方法的总耗时是数据处理的耗时+网络计算的耗时=训练总耗时。</p>
<br/>
<p><font size=3><strong>Q: MindSpore能否支持按批次对不同尺寸的图片数据进行训练？</strong></font></p>
<p>A: 你可以参考yolov3对于此场景的使用，里面有对于图像的不同缩放,脚本见<a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.3/model_zoo/official/cv/yolov3_darknet53/src/yolo_dataset.py">yolo_dataset</a>。</p>
<br/>
<p><font size=3><strong>Q: 使用MindSpore做分割训练，必须将数据转为MindRecord吗？</strong></font></p>
<p>A: <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.3/model_zoo/official/cv/deeplabv3/src/data/build_seg_data.py">build_seg_data.py</a>是将数据集生成MindRecord的脚本，可以直接使用/适配下你的数据集。或者如果你想尝试自己实现数据集的读取，可以使用<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>自定义数据集加载。</p>
<p><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.3/dataset_loading.html#id5">GenratorDataset 示例</a></p>
<p><a class="reference external" href="https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/dataset/mindspore.dataset.GeneratorDataset.html#mindspore.dataset.GeneratorDataset">GenratorDataset API说明</a></p>
<br/>
<p><font size=3><strong>Q: 如何不将数据处理为MindRecord格式，直接进行训练呢？</strong></font></p>
<p>A: 可以使用自定义的数据加载方式 <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>，具体可以参考<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.3/dataset_loading.html#id5">数据集加载</a>文档中的自定义数据集加载。</p>
<br/>
<p><font size=3><strong>Q: MindSpore在Ascend硬件平台进行多卡训练，自定义数据集如何给不同卡传递不同数据？</strong></font></p>
<p>A: 使用<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>的时候，可以使用<code class="docutils literal notranslate"><span class="pre">num_shards=num_shards</span></code>,<code class="docutils literal notranslate"><span class="pre">shard_id=device_id</span></code>参数来控制不同卡读取哪个分片的数据，<code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>和<code class="docutils literal notranslate"><span class="pre">__len__</span></code>按全量数据集处理即可。</p>
<p>举例:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 卡0:</span>
<span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="c1"># 卡1:</span>
<span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="c1"># 卡2:</span>
<span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="o">...</span>
<span class="c1"># 卡7:</span>
<span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: 如何构建图像的多标签MindRecord格式数据集？</strong></font></p>
<p>A: 数据Schema可以按如下方式定义: <code class="docutils literal notranslate"><span class="pre">cv_schema_json</span> <span class="pre">=</span> <span class="pre">{&quot;label&quot;:</span> <span class="pre">{&quot;type&quot;:</span> <span class="pre">&quot;int32&quot;,</span> <span class="pre">&quot;shape&quot;:</span> <span class="pre">[-1]},</span> <span class="pre">&quot;data&quot;:</span> <span class="pre">{&quot;type&quot;:</span> <span class="pre">&quot;bytes&quot;}}</span></code></p>
<p>说明: label是一个数组，numpy类型，这里面可以存 1， 1，0，1， 0， 1 这么多label值，这些label值对应同一个data，即: 同一个图像的二进制值。
可以参考<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.3/convert_dataset.html#%E5%B0%86%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BD%AC%E6%8D%A2%E4%B8%BAMindRecord">将数据集转换为MindRecord</a>教程。</p>
<br/>
<p><font size=3><strong>Q: 请问自己制作的黑底白字<code class="docutils literal notranslate"><span class="pre">28*28</span></code>的数字图片，使用MindSpore训练出来的模型做预测，报错提示<code class="docutils literal notranslate"><span class="pre">wrong</span> <span class="pre">shape</span> <span class="pre">of</span> <span class="pre">image</span></code>是怎么回事？</strong></font></p>
<p>A: 首先MindSpore训练使用的灰度图MNIST数据集。所以模型使用时对数据是有要求的，需要设置为<code class="docutils literal notranslate"><span class="pre">28*28</span></code>的灰度图，就是单通道才可以。</p>
<br/>
<p><font size=3><strong>Q: 第一次看到有专门的数据处理框架，能介绍下么？</strong></font></p>
<p>A: MindData提供数据处理异构硬件加速功能，高并发数据处理<code class="docutils literal notranslate"><span class="pre">pipeline</span></code>同时支持<code class="docutils literal notranslate"><span class="pre">Ascend/GPU/CPU</span></code>，<code class="docutils literal notranslate"><span class="pre">CPU</span></code>占用降低30%，点击查询<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.3/optimize_data_processing.html">优化数据处理</a>。</p>
<br/>
<p><font size=3><strong>Q: 网络训练时出现报错提示数据下发失败“TDT Push data into device Failed”，如何定位原因？</strong></font></p>
<p>A: 首先上述报错指的是通过训练数据下发通道（TDT，train data transfer)发送数据到卡（device）上失败，导致这一报错的原因可能有多种，因此日志中给出了相应的检查建议，具体而言:</p>
<ol class="arabic">
<li><p>通常我们会找到日志中最先抛出的错误（第一个ERROR级别的错误）或报错堆栈（TraceBack)，并尝试从中找到有助于定位错误原因的信息。</p></li>
<li><p><strong>在图编译阶段，训练还没开始报错时</strong>（例如日志中还没打印loss)，请先检查下报错（ERROR）日志中是否有网络中涉及的相关算子报错或涉及环境没配置好导致的报错（如hccl.json不对导致多卡通信初始化异常）。</p></li>
<li><p><strong>在中间训练过程中报错时</strong>，通常为下发的数据量（batch数）与网络训练需要的数据量（step数）不匹配导致的，可以通过<code class="docutils literal notranslate"><span class="pre">get_dataset_size</span></code>接口打印一个epoch中包含的batch数，导致异常的部分可能原因如下：</p>
<ul>
<li><p>通过查看打印loss次数的等方式判断如果数据量（step数）刚好为一个epoch中batch数的整数倍，则可能是数据处理部分涉及epoch的处理存在问题，如下面这场景:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_tuple_iteator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 此处如果要返回一个迭代器则num_epochs应该给1, 但建议直接返回dataset</span>
<span class="k">return</span> <span class="n">dataset</span>
</pre></div>
</div>
</li>
<li><p>考虑是否是数据处理性能较慢，跟不上网络训练的速度，针对这一场景，可借助profiler工具和MindInsight看一下是否存在明显的迭代间隙，或手动遍历一下dataset，并打印计算下平均单batch的耗时，是否比网络正反向加起来的时间更长，如果是则大概率需要对数据处理部分进行性能优化。</p></li>
<li><p>训练过程中出现异常数据抛出异常导致下发数据失败，通常这种情况会有其他报错（ERROR）日志会提示数据处理哪个环节出现了异常及检查建议。如果不明显，也可以通过遍历dataset每条数据的方式尝试找出异常的数据（如关闭shuffle, 然后进行二分法）。</p></li>
</ul>
</li>
<li><p>如果<strong>在训练结束后</strong>打印这条日志（大抵是强制释放资源导致），可忽略这个报错。</p></li>
<li><p>如果仍不能定位具体原因，请通过提issue或论坛提问等方式找模块开发人员协助定位。</p></li>
</ol>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="installation.html" class="btn btn-neutral float-left" title="安装" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="implement_problem.html" class="btn btn-neutral float-right" title="执行问题" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>