<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>数据处理 &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="执行问题" href="implement_problem.html" />
    <link rel="prev" title="安装" href="installation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">安装</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="implement_problem.html">执行问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="network_compilation.html">网络编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage_migrate_3rd.html">第三方框架迁移使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_configure.html">分布式配置</a></li>
<li class="toctree-l1"><a class="reference internal" href="inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_advice.html">特性咨询</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>数据处理</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/data_processing.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1>数据处理<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.6/docs/mindspore/faq/source_zh_cn/data_processing.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.6/resource/_static/logo_source.png"></a></p>
<p><font size=3><strong>Q: 请问如果不使用高阶API，怎么实现数据下沉？</strong></font></p>
<p>A: 可以参考此手动下沉方式的<a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.6/tests/st/data_transfer/test_tdt_data_transfer.py">test_tdt_data_transfer.py</a>示例实现，不用借助<code class="docutils literal notranslate"><span class="pre">model.train</span></code>接口，目前支持：GPU和Ascend硬件使用。</p>
<br/>
<p><font size=3><strong>Q: 在<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>中，看到有参数<code class="docutils literal notranslate"><span class="pre">shuffle</span></code>，在跑任务时发现<code class="docutils literal notranslate"><span class="pre">shuffle=True</span></code>和<code class="docutils literal notranslate"><span class="pre">shuffle=False</span></code>，两者没有区别，这是为什么？</strong></font></p>
<p>A: 开启<code class="docutils literal notranslate"><span class="pre">shuffle</span></code>,需要传入的<code class="docutils literal notranslate"><span class="pre">Dataset</span></code>是支持随机访问的（例如自定义的<code class="docutils literal notranslate"><span class="pre">Dataset</span></code>有<code class="docutils literal notranslate"><span class="pre">getitem</span></code>方法），如果是在自定义的<code class="docutils literal notranslate"><span class="pre">Dataset</span></code>里面通过<code class="docutils literal notranslate"><span class="pre">yeild</span></code>方式返回回来的数据，是不支持随机访问的，具体可查看教程中的<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.6/dataset_loading.html#id5">数据集加载</a>章节。</p>
<br/>
<p><font size=3><strong>Q: 请问<code class="docutils literal notranslate"><span class="pre">Dataset</span></code>如何把两个<code class="docutils literal notranslate"><span class="pre">columns</span></code>合并成一个<code class="docutils literal notranslate"><span class="pre">column</span></code>？</strong></font></p>
<p>A: 可以添加如下操作把 两个字段合成一个。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">combine</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">combine</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;data2&quot;</span><span class="p">],</span> <span class="n">output_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>注：因为两个<code class="docutils literal notranslate"><span class="pre">columns</span></code>是不同的<code class="docutils literal notranslate"><span class="pre">shape</span></code>，需要先<code class="docutils literal notranslate"><span class="pre">flatten</span></code>下，然后再合并。</p>
<br/>
<p><font size=3><strong>Q: 请问<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>支持<code class="docutils literal notranslate"><span class="pre">ds.PKSampler</span></code>采样吗？</strong></font></p>
<p>A: 自定义数据集<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>不支持<code class="docutils literal notranslate"><span class="pre">PKSampler</span></code>采样逻辑。主要原因是自定义数据操作灵活度太大了，内置的<code class="docutils literal notranslate"><span class="pre">PKSampler</span></code>难以做到通用性，所以选择在接口层面直接提示不支持。但是对于<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>，可以方便的定义自己需要的<code class="docutils literal notranslate"><span class="pre">Sampler</span></code>逻辑，即在<code class="docutils literal notranslate"><span class="pre">ImageDataset</span></code>类的<code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>函数中定义具体的<code class="docutils literal notranslate"><span class="pre">sampler</span></code>规则，返回自己需要的数据即可。</p>
<br/>
<p><font size=3><strong>Q: MindSpore如何加载已有的预训练词向量？</strong></font></p>
<p>A: 可以在定义EmbedingLookup或者Embedding时候，把预训练的词向量传进来，把预训练的词向量封装成一个Tensor作为EmbeddingLookup初始值。</p>
<br/>
<p><font size=3><strong>Q: 请问<code class="docutils literal notranslate"><span class="pre">c_transforms</span></code>和<code class="docutils literal notranslate"><span class="pre">py_transforms</span></code>有什么区别，比较推荐使用哪个？</strong></font></p>
<p>A: 推荐使用<code class="docutils literal notranslate"><span class="pre">c_transforms</span></code>，因为纯C层执行，所以性能会更好。</p>
<p>原理:<code class="docutils literal notranslate"><span class="pre">c_transform</span></code>底层使用的是C版本<code class="docutils literal notranslate"><span class="pre">opencv/jpeg-turbo</span></code>进行的数据处理，<code class="docutils literal notranslate"><span class="pre">py_transform</span></code>使用的是Python版本的<code class="docutils literal notranslate"><span class="pre">Pillow</span></code>进行数据处理。</p>
<br/>
<p><font size=3><strong>Q: 由于我一条数据包含多个图像，并且每个图像的宽高都不一致，需要对转成mindrecord格式的数据进行<code class="docutils literal notranslate"><span class="pre">map</span></code>操作。可是我从<code class="docutils literal notranslate"><span class="pre">record</span></code>读取的数据是<code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code>格式的数据，我的数据处理的<code class="docutils literal notranslate"><span class="pre">operations</span></code>是针对图像格式的。我应该怎么样才能对所生成的mindrecord的格式的数据进行预处理呢？</strong></font></p>
<p>A: 建议你按照如下操作进行:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#1 The defined schema is as follows: Among them, data1, data2, data3, ... These fields store your image, and only the binary of the image is stored here.</span>

<span class="n">cv_schema_json</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;int32&quot;</span><span class="p">},</span> <span class="s2">&quot;data1&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;bytes&quot;</span><span class="p">},</span> <span class="s2">&quot;data2&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;bytes&quot;</span><span class="p">},</span> <span class="s2">&quot;data3&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;bytes&quot;</span><span class="p">}}</span>

<span class="c1">#2 The organized data can be as follows, and then this data_list can be written by FileWriter.write_raw_data(...).</span>

<span class="n">data_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;1.jpg&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
<span class="n">image_bytes</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span>

<span class="n">data</span><span class="p">[</span><span class="s1">&#39;data1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_bytes</span>

<span class="n">f2</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;2.jpg&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
<span class="n">image_bytes2</span> <span class="o">=</span> <span class="n">f2</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">f2</span><span class="o">.</span><span class="n">close</span>

<span class="n">data</span><span class="p">[</span><span class="s1">&#39;data2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_bytes2</span>

<span class="n">f3</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;3.jpg&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
<span class="n">image_bytes3</span> <span class="o">=</span> <span class="n">f3</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">f3</span><span class="o">.</span><span class="n">close</span>

<span class="n">data</span><span class="p">[</span><span class="s1">&#39;data3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_bytes3</span>

<span class="n">data_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1">#3 Use MindDataset to load, then use the decode operator we provide to decode, and then perform subsequent processing.</span>

<span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">MindDataset</span><span class="p">(</span><span class="s2">&quot;mindrecord_file_name&quot;</span><span class="p">)</span>
<span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data1&quot;</span><span class="p">],</span> <span class="n">operations</span><span class="o">=</span><span class="n">vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data2&quot;</span><span class="p">],</span> <span class="n">operations</span><span class="o">=</span><span class="n">vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data3&quot;</span><span class="p">],</span> <span class="n">operations</span><span class="o">=</span><span class="n">vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">resize_op</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">)</span>
<span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">resize_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data1&quot;</span><span class="p">],</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data_set</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: 我的自定义图像数据集转为mindrecord格式时，我的数据是<code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>格式的，且<code class="docutils literal notranslate"><span class="pre">shape</span></code>为[4,100,132,3]，这个<code class="docutils literal notranslate"><span class="pre">shape</span></code>的含义是四幅三通道的帧，且每个值都在0~255。可是当我查看转化成mindrecord的格式的数据时，发现是<code class="docutils literal notranslate"><span class="pre">[19800]</span></code>的<code class="docutils literal notranslate"><span class="pre">shape</span></code>，我原数据的维度全部展开有<code class="docutils literal notranslate"><span class="pre">[158400]</span></code>，请问这是为什么？</strong></font></p>
<p>A: 可能是你数据中<code class="docutils literal notranslate"><span class="pre">ndarray</span></code>的<code class="docutils literal notranslate"><span class="pre">dtype</span></code>是<code class="docutils literal notranslate"><span class="pre">int8</span></code>，因为<code class="docutils literal notranslate"><span class="pre">[158400]</span></code>和<code class="docutils literal notranslate"><span class="pre">[19800]</span></code>刚好相差了8倍，建议将数据中<code class="docutils literal notranslate"><span class="pre">ndarray</span></code>的<code class="docutils literal notranslate"><span class="pre">dtype</span></code>指定为<code class="docutils literal notranslate"><span class="pre">float64</span></code>。</p>
<br/>
<p><font size=3><strong>Q: 想要保存生成的图片，代码运行完毕以后在相应目录找不到图片。相似的，在JupyterLab中生成数据集用于训练，训练时可以在相应路径读取到数据，但是自己却无法在路径中找到图片或数据集？</strong></font></p>
<p>A: 可能是JumperLab生成的图片或者数据集都是在Docker内，<code class="docutils literal notranslate"><span class="pre">moxing</span></code>下载的数据只能训练进程的Docker内看见，训练完成后这些数据就随着Docker释放了。 可以试试在训练任务中将需要<code class="docutils literal notranslate"><span class="pre">download</span></code>的数据再通过<code class="docutils literal notranslate"><span class="pre">moxing</span></code>传回<code class="docutils literal notranslate"><span class="pre">obs</span></code>，然后再在<code class="docutils literal notranslate"><span class="pre">obs</span></code>里面下载到你本地。</p>
<br/>
<p><font size=3><strong>Q: MindSpore中<code class="docutils literal notranslate"><span class="pre">model.train</span></code>的<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code>参数该如何理解？</strong></font></p>
<p>A: 当<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode=True</span></code>时，数据处理会和网络计算构成Pipeline方式，即: 数据处理在逐步处理数据时，处理完一个<code class="docutils literal notranslate"><span class="pre">batch</span></code>的数据，会把数据放到一个队列里，这个队列用于缓存已经处理好的数据，然后网络计算从这个队列里面取数据用于训练，那么此时数据处理与网络计算就<code class="docutils literal notranslate"><span class="pre">Pipeline</span></code>起来了，整个训练耗时就是数据处理/网络计算耗时最长的那个。</p>
<p>当<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode=False</span></code>时，数据处理会和网络计算构成串行的过程，即: 数据处理在处理完一个<code class="docutils literal notranslate"><span class="pre">batch</span></code>后，把这个<code class="docutils literal notranslate"><span class="pre">batch</span></code>的数据传递给网络用于计算，在计算完成后，数据处理再处理下一个<code class="docutils literal notranslate"><span class="pre">batch</span></code>，然后把这个新的<code class="docutils literal notranslate"><span class="pre">batch</span></code>数据传递给网络用于计算，如此的循环往复，直到训练完。该方法的总耗时是数据处理的耗时+网络计算的耗时=训练总耗时。</p>
<br/>
<p><font size=3><strong>Q: MindSpore能否支持按批次对不同尺寸的图片数据进行训练？</strong></font></p>
<p>A: 你可以参考yolov3对于此场景的使用，里面有对于图像的不同缩放,脚本见<a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.6/official/cv/yolov3_darknet53/src/yolo_dataset.py">yolo_dataset</a>。</p>
<br/>
<p><font size=3><strong>Q: 使用MindSpore做分割训练，必须将数据转为MindRecord吗？</strong></font></p>
<p>A: <a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.6/official/cv/deeplabv3/src/data/build_seg_data.py">build_seg_data.py</a>是将数据集生成MindRecord的脚本，可以直接使用/适配下你的数据集。或者如果你想尝试自己实现数据集的读取，可以使用<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>自定义数据集加载。</p>
<p><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.6/dataset_loading.html#id5">GenratorDataset 示例</a></p>
<p><a class="reference external" href="https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/dataset/mindspore.dataset.GeneratorDataset.html#mindspore.dataset.GeneratorDataset">GenratorDataset API说明</a></p>
<br/>
<p><font size=3><strong>Q: MindSpore在Ascend硬件平台进行多卡训练，自定义数据集如何给不同卡传递不同数据？</strong></font></p>
<p>A: 使用<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>的时候，可以使用<code class="docutils literal notranslate"><span class="pre">num_shards=num_shards</span></code>,<code class="docutils literal notranslate"><span class="pre">shard_id=device_id</span></code>参数来控制不同卡读取哪个分片的数据，<code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>和<code class="docutils literal notranslate"><span class="pre">__len__</span></code>按全量数据集处理即可。</p>
<p>举例:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 卡0:</span>
<span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="c1"># 卡1:</span>
<span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="c1"># 卡2:</span>
<span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="o">...</span>
<span class="c1"># 卡7:</span>
<span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: 如何构建图像的多标签MindRecord格式数据集？</strong></font></p>
<p>A: 数据Schema可以按如下方式定义: <code class="docutils literal notranslate"><span class="pre">cv_schema_json</span> <span class="pre">=</span> <span class="pre">{&quot;label&quot;:</span> <span class="pre">{&quot;type&quot;:</span> <span class="pre">&quot;int32&quot;,</span> <span class="pre">&quot;shape&quot;:</span> <span class="pre">[-1]},</span> <span class="pre">&quot;data&quot;:</span> <span class="pre">{&quot;type&quot;:</span> <span class="pre">&quot;bytes&quot;}}</span></code></p>
<p>说明: label是一个数组，numpy类型，这里面可以存 1， 1，0，1， 0， 1 这么多label值，这些label值对应同一个data，即: 同一个图像的二进制值。
可以参考<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.6/convert_dataset.html#%E5%B0%86%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BD%AC%E6%8D%A2%E4%B8%BAMindRecord">将数据集转换为MindRecord</a>教程。</p>
<br/>
<p><font size=3><strong>Q: 请问自己制作的黑底白字<code class="docutils literal notranslate"><span class="pre">28*28</span></code>的数字图片，使用MindSpore训练出来的模型做预测，报错提示<code class="docutils literal notranslate"><span class="pre">wrong</span> <span class="pre">shape</span> <span class="pre">of</span> <span class="pre">image</span></code>是怎么回事？</strong></font></p>
<p>A: 首先MindSpore训练使用的灰度图MNIST数据集。所以模型使用时对数据是有要求的，需要设置为<code class="docutils literal notranslate"><span class="pre">28*28</span></code>的灰度图，就是单通道才可以。</p>
<br/>
<p><font size=3><strong>Q: 第一次看到有专门的数据处理框架，能介绍下么？</strong></font></p>
<p>A: MindData提供数据处理异构硬件加速功能，高并发数据处理<code class="docutils literal notranslate"><span class="pre">pipeline</span></code>同时支持<code class="docutils literal notranslate"><span class="pre">Ascend/GPU/CPU</span></code>，<code class="docutils literal notranslate"><span class="pre">CPU</span></code>占用降低30%，点击查询<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.6/optimize_data_processing.html">优化数据处理</a>。</p>
<br/>
<p><font size=3><strong>Q: 网络训练时出现报错提示数据下发失败“TDT Push data into device Failed”，如何定位原因？</strong></font></p>
<p>A: 首先上述报错指的是通过训练数据下发通道（TDT，train data transfer)发送数据到卡（device）上失败，导致这一报错的原因可能有多种，因此日志中给出了相应的检查建议，具体而言:</p>
<ol class="arabic">
<li><p>通常我们会找到日志中最先抛出的错误（第一个ERROR级别的错误）或报错堆栈（TraceBack)，并尝试从中找到有助于定位错误原因的信息。</p></li>
<li><p><strong>在图编译阶段，训练还没开始报错时</strong>（例如日志中还没打印loss)，请先检查下报错（ERROR）日志中是否有网络中涉及的相关算子报错或涉及环境没配置好导致的报错（如hccl.json不对导致多卡通信初始化异常）。</p></li>
<li><p><strong>在中间训练过程中报错时</strong>，通常为下发的数据量（batch数）与网络训练需要的数据量（step数）不匹配导致的，可以通过<code class="docutils literal notranslate"><span class="pre">get_dataset_size</span></code>接口打印一个epoch中包含的batch数，导致异常的部分可能原因如下：</p>
<ul>
<li><p>通过查看打印loss次数的等方式判断如果数据量（step数）刚好为一个epoch中batch数的整数倍，则可能是数据处理部分涉及epoch的处理存在问题，如下面这场景:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_tuple_iteator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 此处如果要返回一个迭代器则num_epochs应该给1, 但建议直接返回dataset</span>
<span class="k">return</span> <span class="n">dataset</span>
</pre></div>
</div>
</li>
<li><p>考虑是否是数据处理性能较慢，跟不上网络训练的速度，针对这一场景，可借助profiler工具和MindInsight看一下是否存在明显的迭代间隙，或手动遍历一下dataset，并打印计算下平均单batch的耗时，是否比网络正反向加起来的时间更长，如果是则大概率需要对数据处理部分进行性能优化。</p></li>
<li><p>训练过程中出现异常数据抛出异常导致下发数据失败，通常这种情况会有其他报错（ERROR）日志会提示数据处理哪个环节出现了异常及检查建议。如果不明显，也可以通过遍历dataset每条数据的方式尝试找出异常的数据（如关闭shuffle, 然后进行二分法）。</p></li>
</ul>
</li>
<li><p>如果<strong>在训练结束后</strong>打印这条日志（大抵是强制释放资源导致），可忽略这个报错。</p></li>
<li><p>如果仍不能定位具体原因，请通过提issue或论坛提问等方式找模块开发人员协助定位。</p></li>
</ol>
<br/>
<p><font size=3><strong>Q: py_transforms 和 c_transforms 算子能否混合使用，如果混合使用具体需要怎么使用？</strong></font></p>
<p>A: 出于高性能考虑，通常不建议将py_transforms 与 c_transforms算子混合使用，<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.6/augmentation.html#%E4%BD%BF%E7%94%A8%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9">文档</a>也对此进行了说明。但若不追求极致的性能，主要考虑打通流程，在无法全部使用c_transforms算子（缺少对应的c_transforms算子）的情况下，可使用py_transforms算子替代，此时即存在混合使用。
对此我们需要注意c_transforms 算子的输出通常是numpy array，py_transforms算子的输出是PIL Image，具体可查看算子说明，为此通常的混合使用方法为：</p>
<ul class="simple">
<li><p>c_transforms 算子 + ToPIL 算子 + py_transforms 算子 + ToTensor算子</p></li>
<li><p>py_transforms 算子 + ToTensor 算子 + c_transforms 算子</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># example that using c_transforms and py_transforms operators together</span>
<span class="c1"># in following case: c_vision refers to c_transforms, py_vision refer to py_transforms</span>

<span class="n">decode_op</span> <span class="o">=</span> <span class="n">c_vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">()</span>

<span class="c1"># If input type is not PIL, then add ToPIL operator.</span>
<span class="n">transforms</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">py_vision</span><span class="o">.</span><span class="n">ToPIL</span><span class="p">(),</span>
    <span class="n">py_vision</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">375</span><span class="p">),</span>
    <span class="n">py_vision</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">]</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span><span class="n">transforms</span><span class="p">)</span>
<span class="n">data1</span> <span class="o">=</span> <span class="n">data1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">decode_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>
<span class="n">data1</span> <span class="o">=</span> <span class="n">data1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: 当错误提示 “The data pipeline is not a tree (i.e., one node has 2 consumers)” 应该怎么检查？</strong></font></p>
<p>A: 上述错误通常是脚本书写错误导致，具体发生在下面这种场景；正常情况下数据处理pipeline中的操作是依次串联的，下面的异常场景中dataset1有两个消费节点 dataset2和dataset3，就会出现上述错误。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span> <span class="n">dataset2</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">***</span><span class="p">)</span>
 <span class="n">dataset3</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">***</span><span class="p">)</span>
</pre></div>
</div>
<p>正确的写法如下所示，dataset3是由dataset2进性数据增强得到的，而不是在dataset1基础上进行数据增强操作得到。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span> <span class="n">dataset2</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">***</span><span class="p">)</span>
 <span class="n">dataset3</span> <span class="o">=</span> <span class="n">dataset2</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">***</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: MindSpore中和Dataloader对应的算子是什么？</strong></font></p>
<p>A：如果将Dataloader考虑为接收自定义Dataset的API接口，MindSpore数据处理API中和Dataloader较为相似的是GeneratorDataset，可接收用户自定义的Dataset，具体使用方式参考<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.6/dataset_loading.html#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8A%A0%E8%BD%BD">GeneratorDataset 文档</a>，差异对比也可查看<a class="reference external" href="https://www.mindspore.cn/docs/migration_guide/zh-CN/r1.6/api_mapping/pytorch_api_mapping.html">API算子映射表</a>。</p>
<br/>
<p><font size=3><strong>Q: 自定义的Dataset出现错误时，应该如何调试？</strong></font></p>
<p>A：自定义的Dataset通常会传入到GeneratorDataset，在使用过程中错误指向了自定义的Dataset时，可通过一些方式进行调试（如增加打印信息，打印返回值的shape、dtype等），自定义Dataset通常要保持中间处理结果为numpy array，且不建议与MindSpore网络计算的算子混合使用。此外针对自定义的Dataset如下面的MyDataset，初始化后也可直接进行如下遍历（主要为简化调试，分析原始Dataset中的问题，可不传入GeneratorDataset)，调试遵循常规的Python语法规则。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Dataset</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">()</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">Dataset</span><span class="p">:</span>
   <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;item:&quot;</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: 数据处理算子与网络计算算子能否混合使用？</strong></font></p>
<p>A：通常数据处理算子与网络计算算子混合使用会导致性能有所降低，在缺少对应的数据处理算子且自定义py_transforms算子不合适时可进行尝试。需要注意的是，因为二者需要的输入不一致，数据处理算子通常输入为numpy array 或 PIL Image，但网络计算算子输入需要是MindSpore.Tensor;
将二者混合使用需要使上一个算子的输出格式和下一个算子所需的输入格式一致。数据处理算子指的是官网API文档中mindspore.dataset开头的算子，如 mindspore.dataset.vision.c_transforms.CenterCrop，网络计算算子包含 mindspore.nn、 mindspore.ops等目录下的算子。</p>
<br/>
<p><font size=3><strong>Q: MindRecord为何会生成.db文件？ 缺少.db文件时加载数据集会有什么报错？</strong></font></p>
<p>A：.db文件为MindRecord文件对应的索引文件，缺少.db文件通常会在获取数据集总的数据量时报错，错误提示如：<code class="docutils literal notranslate"><span class="pre">MindRecordOp</span> <span class="pre">Count</span> <span class="pre">total</span> <span class="pre">rows</span> <span class="pre">failed</span></code>。</p>
<br/>
<p><font size=3><strong>Q: 自定义Dataset中如何进行图像读取并进行Decode操作？</strong></font></p>
<p>A：传入GeneratorDataset的自定义Dataset，在接口内部（如<code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>函数）进行图像读取后可以直接返回bytes类型的数据、numpy array类型的数组或已经做了解码操作的numpy array, 具体如下所示：</p>
<ul>
<li><p>读取图像后直接返回bytes类型的数据</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ImageDataset</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_path</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data_path</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="c1"># use file open and read method</span>
        <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span>
        <span class="n">img_bytes</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="c1"># return bytes directly</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">img_bytes</span><span class="p">,</span> <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># data_path is a list of image file name</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">ImageDataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">),</span> <span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
<span class="n">decode_op</span> <span class="o">=</span> <span class="n">py_vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">()</span>
<span class="n">to_tensor</span> <span class="o">=</span> <span class="n">py_vision</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(</span><span class="n">output_type</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="p">[</span><span class="n">decode_op</span><span class="p">,</span> <span class="n">to_tensor</span><span class="p">],</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
</pre></div>
</div>
</li>
<li><p>读取图像后返回numpy array</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 在上面的用例中，对__getitem__函数可进行如下修改, Decode操作同上述用例一致</span>
<span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
    <span class="c1"># use np.fromfile to read image</span>
    <span class="n">img_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromfile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>

    <span class="c1"># return Numpy array directly</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">img_np</span><span class="p">,</span> <span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>读取图像后直接进行Decode操作</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 依据上面的用例，对__getitem__函数可进行如下修改, 直接返回Decode之后的数据，此后可以不需要通过map算子接Decode操作</span>
<span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
    <span class="c1"># use Image.Open to open file, and convert to RGC</span>
    <span class="n">img_rgb</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">Open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">index</span><span class="p">])</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">img_rgb</span><span class="p">,</span> <span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="installation.html" class="btn btn-neutral float-left" title="安装" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="implement_problem.html" class="btn btn-neutral float-right" title="执行问题" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>