<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Network Migration Debugging Example &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="API Mapping" href="api_mapping.html" />
    <link rel="prev" title="Inference Execution" href="inference.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="preparation.html">Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="script_analysis.html">Network Script Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="script_development.html">Network Script Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="neural_network_debug.html">Network Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_optimization.html">Using Performance Profiling Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="inference.html">Inference Execution</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Network Migration Debugging Example</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#analysis-and-reproduce-of-the-network">Analysis and Reproduce of the Network</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#determine-the-migration-target">Determine the Migration Target</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#resnet50-migration-example">ResNet50 Migration Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#reproduce-the-migration-target">Reproduce the Migration Target</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reproduce-the-single-step-results">Reproduce the Single Step Results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#script-development">Script Development</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pre-script-development-analysis">Pre-script Development Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">ResNet50 Migration Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#data-preprocessing">Data Preprocessing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id2">ResNet50 Migration Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#subnet-development">Subnet Development</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id3">ResNet50 Migration Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#other-modules">Other Modules</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id4">ResNet50 migration example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hyperparameters-comparison">Hyperparameters Comparison</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id5">ResNet50 Migration Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#process-hitting">Process Hitting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#stand-alone-training">Stand-alone Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id6">ResNet50 Migration Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#distributed-training">Distributed training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id7">ResNet50 Migration Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#inference">Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id8">ResNet50 Migration Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#problem-location">Problem Location</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#precision-tuning">Precision tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#performance-tuning">Performance Tuning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#analyzing-profiling-data">Analyzing Profiling Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#common-problems-and-corresponding-optimization-methods">Common Problems and Corresponding Optimization Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#minddata-performance">MindData Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="#multi-machine-synchronization-performance">Multi-machine Synchronization Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="#operator-performance">Operator Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="#framework-performance">Framework Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="#other-general-optimization-methods">Other General Optimization Methods</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api_mapping.html">API Mapping</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Network Migration Debugging Example</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/sample_code.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="network-migration-debugging-example">
<h1>Network Migration Debugging Example<a class="headerlink" href="#network-migration-debugging-example" title="Permalink to this headline"></a></h1>
<p>Translator: <a class="reference external" href="https://gitee.com/Liu-HongYe">AQUA</a></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.5/docs/mindspore/migration_guide/source_en/sample_code.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source_en.png"></a></p>
<p>This chapter will introduce the basic steps of network migration, common tools, ideas for locating problems and solutions with use cases.</p>
<p>Here we take the classical network ResNet50 as an example and introduce the network migration method in detail with codes.</p>
<section id="analysis-and-reproduce-of-the-network">
<h2>Analysis and Reproduce of the Network<a class="headerlink" href="#analysis-and-reproduce-of-the-network" title="Permalink to this headline"></a></h2>
<section id="determine-the-migration-target">
<h3>Determine the Migration Target<a class="headerlink" href="#determine-the-migration-target" title="Permalink to this headline"></a></h3>
<p>The first step of network migration is to determine the migration goal. Usually the delivery goal of a deep neural network includes the following four parts.</p>
<ol class="arabic simple">
<li><p>network implementation: this is the most basic part of the migration goal. Sometimes a single neural network may have different versions, a single version may be implemented differently, or a single neural network may adopt different configurations of hyperparameters, and these differences will have some impacts on the final convergence accuracy and performance. Usually, we take the neural network author’s own implementation as the standard, but we can also refer to the official implementations of different frameworks (e.g., TensorFlow, PyTorch, etc.) or other mainstream open source toolkits (e.g., MMDetection).</p></li>
<li><p>dataset: the same neural network and parameters often vary greatly in datasets, so we need to confirm the dataset used for the migration network. The data content of some datasets will be updated frequently, and it is necessary to pay attention to the version of the dataset, the ratio of training data to test data division, etc. when using the dataset.</p></li>
<li><p>convergence accuracy: different frameworks, GPU models, and whether the training is distributed will have an impact on the accuracy, so we need to analyze the framework, hardware and other information of the counterpart when determining the migration target.</p></li>
<li><p>training performance: the same as convergence accuracy, training performance is mainly affected by the network script, framework performance, GPU hardware itself and whether the training is distributed or not.</p></li>
</ol>
<section id="resnet50-migration-example">
<h4>ResNet50 Migration Example<a class="headerlink" href="#resnet50-migration-example" title="Permalink to this headline"></a></h4>
<p>ResNet50 is a classic deep neural network in CV, which attracts more developers’ attention and replication, and the syntax of PyTorch is more similar to MindSpore, so we choose PyTorch as the benchmark framework.</p>
<p>The official PyTorch implementation script can be found at <a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py">torchvision model</a> or <a class="reference external" href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/resnet50v1.5">Nvidia PyTorch implementation script</a>, which includes implementations of the mainstream ResNet family of networks (ResNet18, ResNet18, ResNet18, ResNet18, and ResNet18). (ResNet18, ResNet34, ResNet50, ResNet101, ResNet152). The dataset used for ResNet50 is ImageNet2012, and the convergence accuracy can be found in <a class="reference external" href="https://pytorch.org/hub/">PyTorch Hub</a> pytorch_vision_resnet/#model-description).</p>
<p>Developers can run PyTorch-based ResNet50 scripts directly on the benchmark hardware environment and then evaluate the performance of the model, or they can refer to the official data on the same hardware environment. For example, when we benchmark the Nvidia DGX-1 32GB (8x V100 32GB) hardware, we can refer to <a class="reference external" href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/resnet50v15#training-performance-nvidia-dgx-1-32gb-8x-v100-32gb">Nvidia’s official ResNet50 performance data</a>.</p>
</section>
</section>
<section id="reproduce-the-migration-target">
<h3>Reproduce the Migration Target<a class="headerlink" href="#reproduce-the-migration-target" title="Permalink to this headline"></a></h3>
<p>Once the network migration target is determined, the next thing to do is to reproduce the metrics. When there is an accuracy/performance gap between the network we developed in MindSpore and the benchmark script, we often use the benchmark data as a base line to analyze the difference between the migration script and the benchmark script step by step. If the benchmark script cannot reproduce the metrics, then the MindSpore scripts we develop based on the benchmark will not be able to achieve the migration goals. When reproducing migration metrics, it is not only important to reproduce the training phase, but also the inference phase.</p>
<p>It is important to note that for some networks, using the same hardware environment and scripts, the final convergence accuracy and performance may be slightly different from the results presented by the original authors, which is a normal range of fluctuation and should be taken into account when migrating the network.</p>
</section>
<section id="reproduce-the-single-step-results">
<h3>Reproduce the Single Step Results<a class="headerlink" href="#reproduce-the-single-step-results" title="Permalink to this headline"></a></h3>
<p>The main purpose of reproducing the single Step results is for the next script development and network tuning. For complex neural networks, the complete training takes days or even months, and only if the final training accuracy and results are used as reference, it will greatly reduce the development efficiency. Therefore, we need to reproduce the results of a single Step in advance, i.e., get the state of the network after executing only the first Step (the state is the result after data preprocessing, weight initialization, forward calculation, loss calculation, reverse gradient calculation and optimizer update, covering all aspects of network training), and use it as a reference to start the subsequent development work.</p>
</section>
</section>
<section id="script-development">
<h2>Script Development<a class="headerlink" href="#script-development" title="Permalink to this headline"></a></h2>
<section id="pre-script-development-analysis">
<h3>Pre-script Development Analysis<a class="headerlink" href="#pre-script-development-analysis" title="Permalink to this headline"></a></h3>
<p>Before starting the actual script development, a benchmark script analysis is performed. The purpose of the script analysis is to identify missing operators or features in MindSpore compared to the benchmark framework. The methodology can be found in the <a class="reference external" href="https://www.mindspore.cn/docs/migration_guide/en/r1.5/script_analysis.html">Script Evaluation Tutorial</a>.</p>
<p>MindSpore already supports most of the common <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/index.html">functions</a> and <a class="reference external" href="https://www.mindspore.cn/docs/note/en/r1.5/operator_list.html">operators</a>. MindSpore supports both dynamic graph (PyNative) mode and static graph (Graph) mode, dynamic graph mode is flexible and easy to debug, so dynamic graph mode is mainly used for network debugging. Static graph mode has good performance and is mainly used for whole network training. When analyzing missing operators and functions, these two modes should be analyzed separately.</p>
<p>If missing operators and functions are found, we can first consider combining the missing operators and functions based on the current operators or functions, and for mainstream CV and NLP networks, new missing operators can generally be solved by combining existing operators.</p>
<p>The combined operator can be implemented by means of a cell, which is the case in MindSpore for <a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.5/mindspore/nn">nn class operator</a>. For example, the following <code class="docutils literal notranslate"><span class="pre">ReduceSumExp</span></code> operator is a combination of the existing <code class="docutils literal notranslate"><span class="pre">Exp</span></code>, <code class="docutils literal notranslate"><span class="pre">ReduceSum</span></code>, and <code class="docutils literal notranslate"><span class="pre">Log</span></code> suboperators.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ReduceLogSumExp</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ReduceLogSumExp</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">validator</span><span class="o">.</span><span class="n">check_value_type</span><span class="p">(</span><span class="s1">&#39;axis&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls_name</span><span class="p">)</span>
        <span class="n">validator</span><span class="o">.</span><span class="n">check_value_type</span><span class="p">(</span><span class="s1">&#39;keep_dims&#39;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="p">[</span><span class="nb">bool</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls_name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exp</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Exp</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Log</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">exp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">sumexp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">exp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">axis</span><span class="p">)</span>
        <span class="n">logsumexp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sumexp</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logsumexp</span>
</pre></div>
</div>
<p>If the missing functions and operators cannot be circumvented, or if the performance of the combined operators is poor and seriously affects the training and inference of the network, you can contact <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues">MindSpore Community</a> for feedback and we will have a dedicated staff to solve it for you.</p>
<section id="id1">
<h4>ResNet50 Migration Example<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h4>
<p>The following is the structure of the ResNet family of networks.</p>
<p><img alt="image-20210318152607548" src="_images/image-20210318152607548.png" /></p>
<p>The PyTorch implementation of the ResNet50 script is referenced in the <a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py">torchvision model</a>.</p>
<p>We can analyze it based on both operator and functional aspects.</p>
<ul class="simple">
<li><p>Algorithm analysis</p></li>
</ul>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>PyTorch operator</p></th>
<th class="head"><p>MindSpore operator</p></th>
<th class="head"><p>supported</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.Conv2D</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Conv2d</span></code></p></td>
<td><p>yes</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">nn.BatchNorm2D</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.BatchNom2d</span></code></p></td>
<td><p>yes</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.ReLU</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.ReLU</span></code></p></td>
<td><p>yes</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">nn.MaxPool2D</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.MaxPool2d</span></code></p></td>
<td><p>yes</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.AdaptiveAvgPool2D</span></code></p></td>
<td><p>none</p></td>
<td><p>no</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Dense</span></code></p></td>
<td><p>yes</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">torch.flatten</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Flatten</span></code></p></td>
<td><p>yes</p></td>
</tr>
</tbody>
</table>
<p>Note: For PyTorch scripts, MindSpore provides the <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/index.html#operator_api">PyTorch operator mapping tool</a>, which can directly query whether the operator is supported.</p>
<ul class="simple">
<li><p>Feature Analysis</p></li>
</ul>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Pytorch Features</p></th>
<th class="head"><p>MindSpore Features</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.init.kaiming_normal_</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">initializer(init='HeNormal')</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">nn.init.constant_</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">initializer(init='Constant')</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.SequentialCell</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Cell</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.distibuted</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">context.set_auto_parallel_context</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">torch.optim.SGD</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.optim.SGD</span></code> or <code class="docutils literal notranslate"><span class="pre">nn.optim.Momentum</span></code></p></td>
</tr>
</tbody>
</table>
<p>(Since the interface design of MindSpore and PyTorch are not exactly the same, only the key functions are listed here for comparison)</p>
<p>After the operator and function analysis, we found that compared to PyTorch, MindSpore has no missing functions, but the missing operator <code class="docutils literal notranslate"><span class="pre">nn.AdaptiveAvgPool</span></code> is missing. In the ResNet50 network, the input image shape is fixed and uniform as <code class="docutils literal notranslate"><span class="pre">N,3,224,224</span></code>, where N is the batch size, 3 is the number of channels, 224 and 224 are the width and height of the image, respectively, and the operators that change the image size in the network are <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code> and <code class="docutils literal notranslate"><span class="pre">Maxpool2d</span></code>, the effect of these two operators on the shape is fixed, so the input and output shapes of <code class="docutils literal notranslate"><span class="pre">nn.AdaptiveAvgPool2D</span></code> can be determined in advance, as long as we calculate the input and output shapes of <code class="docutils literal notranslate"><span class="pre">nn.AvgPool</span></code> or <code class="docutils literal notranslate"><span class="pre">nn.ReduceMean</span></code>, so the absence of this operator is replaceable and does not affect the training of the network.</p>
</section>
</section>
<section id="data-preprocessing">
<h3>Data Preprocessing<a class="headerlink" href="#data-preprocessing" title="Permalink to this headline"></a></h3>
<p>To understand the implementation of a neural network, it is necessary to know the input data of the network first, so data preprocessing is the first part of the script development.MindSpore has designed a module dedicated to data processing - MindData, and data preprocessing with MindData consists of the following steps.</p>
<ol class="arabic simple">
<li><p>Importing the data path and reading the data file.</p></li>
<li><p>parsing the data.</p></li>
<li><p>data processing (e.g. common data slicing, shuffle, data augmentation, etc.).</p></li>
<li><p>data distribution (distribution of data in batch_size units, distributed training involves multi-machine distribution).</p></li>
</ol>
<p>In the process of reading and parsing data, MindSpore provides a more friendly data format - <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/convert_dataset.html">MindRecord</a>. Users can convert the dataset in regular format to MindSpore data format, i.e. MindRecord, so that it can be easily loaded into MindSpore for training. At the same time, MindSpore is optimized for performance in some scenarios, and better performance can be obtained by using the MindRecord data format.</p>
<p>Data processing is usually the most time-consuming phase of data preparation, and most of the operations on data are included in this step, such as Resize, Rescale, Crop, etc. in CV-like networks. MindSpore provides a set of common data processing integration interfaces, which can be called directly by users without implementing them. These integration interfaces not only improve the user-friendliness, but also improve the performance of data preprocessing and reduce the time consuming data preparation during training. For details, please refer to the <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/optimize_data_processing.html">Data Preprocessing Tutorial</a>.</p>
<p>In the data distribution, MindData provides an extremely simple API, which can be used to combine and repeat data by directly calling batch and repeat operations.</p>
<p>When the above 4 steps are completed, we can theoretically get the exact same data after processing the dataset using MindSpore script and alignment script (if there are operations that introduce random cases need to be removed).</p>
<section id="id2">
<h4>ResNet50 Migration Example<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h4>
<p>The ResNet50 network uses the ImageNet2012 dataset with the following PyTorch code for data pre-processing:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># sample execution (requires torchvision)</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="n">input_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="n">preprocess</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
<span class="p">])</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span>
<span class="n">input_batch</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># create a mini-batch as expected by the model</span>
</pre></div>
</div>
<p>By looking at the above code, we find that the data preprocessing of ResNet50 mainly does Resize, CenterCrop, and Normalize operations, and there are two ways to implement these operations in MindSpore, one is to use MindSpore’s data processing module MindData to call the encapsulated MindSpore’s data processing module MindData to call the encapsulated data preprocessing interface, or through <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/dataset_loading.html#loading-user-defined-dataset">Custom Dataset</a>. Here it is more recommended for developers to choose the first way, which not only can reduce the development of repetitive code and the introduction of errors, but also can get better data processing performance. For more information about MindData data processing, please refer to the Data Pipeline section in <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/index.html">Programming Guide</a>.</p>
<p>The following data processing functions are developed based on MindData:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">do_train</span><span class="p">,</span> <span class="n">repeat_num</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">,</span> <span class="n">distribute</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="c1"># device number: total number of devices of training</span>
    <span class="c1"># rank_id: the sequence of current device of training</span>
    <span class="n">device_num</span><span class="p">,</span> <span class="n">rank_id</span> <span class="o">=</span> <span class="n">_get_rank_info</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">distribute</span><span class="p">:</span>
        <span class="n">init</span><span class="p">()</span>
        <span class="n">rank_id</span> <span class="o">=</span> <span class="n">get_rank</span><span class="p">()</span>
        <span class="n">device_num</span> <span class="o">=</span> <span class="n">get_group_size</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">device_num</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">device_num</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># standalone training</span>
        <span class="c1"># num_paralel_workers: parallel degree of data process</span>
        <span class="c1"># shuffle: whether shuffle data or not</span>
        <span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">ImageFolderDataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># distributing traing (meaning of num_parallel_workers and shuffle is same as above)</span>
        <span class="c1"># num_shards: total number devices for distribute training, which equals number shard of data</span>
        <span class="c1"># shard_id: the sequence of current device in all distribute training devices, which equals the data shard sequence for current device</span>
        <span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">ImageFolderDataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="n">device_num</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="n">rank</span><span class="p">)</span>

    <span class="c1"># define data operations</span>
    <span class="n">trans</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">do_train</span><span class="p">:</span>
        <span class="n">trans</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="n">C</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="n">trans</span> <span class="o">+=</span> <span class="p">[</span>
        <span class="n">C</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">Rescale</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
    <span class="p">]</span>

    <span class="n">type_cast_op</span> <span class="o">=</span> <span class="n">C2</span><span class="o">.</span><span class="n">TypeCast</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="c1"># call data operations by map</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">type_cast_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">trans</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="c1"># batchinng data</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># repeat data, usually repeat_num equals epoch_size</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repeat_num</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">data_set</span>
</pre></div>
</div>
<p>In the above code we can find that for common classical datasets (e.g. ImageNet2012), MindData also provides us with <code class="docutils literal notranslate"><span class="pre">ImageFolderDataset</span></code> interface to read the raw data directly, which saves the workload of reading files by hand-written code. Note that MindData creates datasets with different parameters for single-machine training and multi-machine distributed training, and distributed training requires two additional parameters <code class="docutils literal notranslate"><span class="pre">num_shard</span></code> and <code class="docutils literal notranslate"><span class="pre">shard_id</span></code>.</p>
</section>
</section>
<section id="subnet-development">
<h3>Subnet Development<a class="headerlink" href="#subnet-development" title="Permalink to this headline"></a></h3>
<p>Usually subnet development consists of two parts: training subnets and loss subnets, where the training subnets can be divided or not depending on the complexity of the network. Developing a large neural network script directly can be overwhelming, so we can separate different modules or submodules of the network as a single subnet to ensure that each subnet is developed in parallel without interfering with each other. After the subnets are developed, we can also fix the subnet inputs and weights to form a comparison with the subnet code of the alignment script, which can be used as test cases for subsequent network development.</p>
<p>During the accuracy tuning phase, we often encounter situations where the accuracy is not up to standard, and then we revisit the developed scripts and troubleshoot them line by line. It is much easier to find suspicious points from dozens of operators than from hundreds of operators, especially when the same subnet is invoked many times, which can reduce a lot of work when we troubleshoot by subnet.</p>
<section id="id3">
<h4>ResNet50 Migration Example<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h4>
<p>Analyzing the ResNet50 network code, it can be divided into the following main subnets.</p>
<ul class="simple">
<li><p>conv1x1, conv3x3: convolution with different kernel_size is defined.</p></li>
<li><p>BasicBlock: the smallest subnet of ResNet18 and ResNet34 in the ResNet family of networks, consisting of Conv, BN, ReLU and residuals.</p></li>
<li><p>BottleNeck: The smallest sub-network of ResNet50, ResNet101 and ResNet152 in the ResNet family of networks, with an additional layer of Conv, BN and ReLU compared to BasicBlock, and the convolution position of downsampling has been changed.</p></li>
<li><p>ResNet: A network that encapsulates the structure of BasicBlock, BottleNeck and Layer, different ResNet series networks can be constructed by passing different parameters. In this structure, some PyTorch self-defined initialization functions are also used.</p></li>
</ul>
<p>Based on the above subnetwork division, we redevelop the above development in conjunction with MindSpore syntax.</p>
<p>Redeveloping the weight initialization (also directly using <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.5/api_python/mindspore.common.initializer.html">MindSpore’s defined weight initialization methods</a>).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_conv_variance_scaling_initializer</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">):</span>
    <span class="n">fan_in</span> <span class="o">=</span> <span class="n">in_channel</span> <span class="o">*</span> <span class="n">kernel_size</span> <span class="o">*</span> <span class="n">kernel_size</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">scale</span> <span class="o">/=</span> <span class="nb">max</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">fan_in</span><span class="p">)</span>
    <span class="n">stddev</span> <span class="o">=</span> <span class="p">(</span><span class="n">scale</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="mf">.87962566103423978</span>
    <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">stddev</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">truncnorm</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">out_channel</span> <span class="o">*</span> <span class="n">in_channel</span> <span class="o">*</span> <span class="n">kernel_size</span> <span class="o">*</span> <span class="n">kernel_size</span><span class="p">)</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_weight_variable</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="n">init_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="n">factor</span>
    <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">init_value</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">calculate_gain</span><span class="p">(</span><span class="n">nonlinearity</span><span class="p">,</span> <span class="n">param</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;calculate_gain&quot;&quot;&quot;</span>
    <span class="n">linear_fns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;conv1d&#39;</span><span class="p">,</span> <span class="s1">&#39;conv2d&#39;</span><span class="p">,</span> <span class="s1">&#39;conv3d&#39;</span><span class="p">,</span> <span class="s1">&#39;conv_transpose1d&#39;</span><span class="p">,</span> <span class="s1">&#39;conv_transpose2d&#39;</span><span class="p">,</span> <span class="s1">&#39;conv_transpose3d&#39;</span><span class="p">]</span>
    <span class="n">res</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">nonlinearity</span> <span class="ow">in</span> <span class="n">linear_fns</span> <span class="ow">or</span> <span class="n">nonlinearity</span> <span class="o">==</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">elif</span> <span class="n">nonlinearity</span> <span class="o">==</span> <span class="s1">&#39;tanh&#39;</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="mf">5.0</span> <span class="o">/</span> <span class="mi">3</span>
    <span class="k">elif</span> <span class="n">nonlinearity</span> <span class="o">==</span> <span class="s1">&#39;relu&#39;</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">nonlinearity</span> <span class="o">==</span> <span class="s1">&#39;leaky_relu&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">param</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">negative_slope</span> <span class="o">=</span> <span class="mf">0.01</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="c1"># True/False are instances of int, hence check above</span>
            <span class="n">negative_slope</span> <span class="o">=</span> <span class="n">param</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;negative_slope </span><span class="si">{}</span><span class="s2"> not a valid number&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">param</span><span class="p">))</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">negative_slope</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unsupported nonlinearity </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nonlinearity</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span>


<span class="k">def</span> <span class="nf">_calculate_fan_in_and_fan_out</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;_calculate_fan_in_and_fan_out&quot;&quot;&quot;</span>
    <span class="n">dimensions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dimensions</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Fan in and fan out can not be computed for tensor with fewer than 2 dimensions&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dimensions</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Linear</span>
        <span class="n">fan_in</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">fan_out</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">num_input_fmaps</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">num_output_fmaps</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">receptive_field_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">dimensions</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">receptive_field_size</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
        <span class="n">fan_in</span> <span class="o">=</span> <span class="n">num_input_fmaps</span> <span class="o">*</span> <span class="n">receptive_field_size</span>
        <span class="n">fan_out</span> <span class="o">=</span> <span class="n">num_output_fmaps</span> <span class="o">*</span> <span class="n">receptive_field_size</span>
    <span class="k">return</span> <span class="n">fan_in</span><span class="p">,</span> <span class="n">fan_out</span>


<span class="k">def</span> <span class="nf">_calculate_correct_fan</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">valid_modes</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;fan_in&#39;</span><span class="p">,</span> <span class="s1">&#39;fan_out&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_modes</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Mode </span><span class="si">{}</span><span class="s2"> not supported, please use one of </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">valid_modes</span><span class="p">))</span>
    <span class="n">fan_in</span><span class="p">,</span> <span class="n">fan_out</span> <span class="o">=</span> <span class="n">_calculate_fan_in_and_fan_out</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fan_in</span> <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;fan_in&#39;</span> <span class="k">else</span> <span class="n">fan_out</span>


<span class="k">def</span> <span class="nf">kaiming_normal</span><span class="p">(</span><span class="n">inputs_shape</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fan_in&#39;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;leaky_relu&#39;</span><span class="p">):</span>
    <span class="n">fan</span> <span class="o">=</span> <span class="n">_calculate_correct_fan</span><span class="p">(</span><span class="n">inputs_shape</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
    <span class="n">gain</span> <span class="o">=</span> <span class="n">calculate_gain</span><span class="p">(</span><span class="n">nonlinearity</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">gain</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fan</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">inputs_shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<p>Redevelopment of convolution operators with 3x3 and 1x1 convolution kernels.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># conv3x3 and conv1x1</span>
<span class="k">def</span> <span class="nf">_conv3x3</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>  
    <span class="n">weight_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="c1"># unlike pytorch, weight initialization is introduced when define conv2d</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">kaiming_normal</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;fan_out&quot;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">weight</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_conv1x1</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># unlike pytorch, weight initialization is introduced when define conv2d</span>
    <span class="n">weight_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">kaiming_normal</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;fan_out&quot;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
                     <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">weight</span><span class="p">)</span>
</pre></div>
</div>
<p>Redevelopment of BasicBlock and BottleNeck.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BasicBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">in_channel</span><span class="p">,</span>
                 <span class="n">out_channel</span><span class="p">,</span>
                 <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BasicBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">_conv3x3</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1d</span> <span class="o">=</span> <span class="n">_bn</span><span class="p">(</span><span class="n">out_channel</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">_conv3x3</span><span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2d</span> <span class="o">=</span> <span class="n">_bn</span><span class="p">(</span><span class="n">out_channel</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">in_channel</span> <span class="o">!=</span> <span class="n">out_channel</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span><span class="n">_conv1x1</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="p">,),</span> <span class="n">_bn</span><span class="p">(</span><span class="n">out_channel</span><span class="p">)])</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">identity</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1d</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2d</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span><span class="p">:</span>
            <span class="n">identity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span><span class="p">(</span><span class="n">identity</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span> <span class="o">+</span> <span class="n">identity</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>


<span class="k">class</span> <span class="nc">BottleNeck</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="n">expansion</span> <span class="o">=</span> <span class="mi">4</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">in_channel</span><span class="p">,</span>
                 <span class="n">out_channel</span><span class="p">,</span>
                 <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BottleNeck</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="n">channel</span> <span class="o">=</span> <span class="n">out_channel</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">expansion</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">_conv1x1</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">_bn</span><span class="p">(</span><span class="n">channel</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">_conv3x3</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="n">channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">_bn</span><span class="p">(</span><span class="n">channel</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">_conv1x1</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span> <span class="o">=</span> <span class="n">_bn_last</span><span class="p">(</span><span class="n">out_channel</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">in_channel</span> <span class="o">!=</span> <span class="n">out_channel</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span><span class="n">_conv1x1</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span> <span class="n">_bn</span><span class="p">(</span><span class="n">out_channel</span><span class="p">)])</span>
    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">identity</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span><span class="p">:</span>
            <span class="n">identity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span><span class="p">(</span><span class="n">identity</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span> <span class="o">+</span> <span class="n">identity</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
<p>Redevelopment of the whole ResNet family of nets.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ResNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">block</span><span class="p">,</span>
                 <span class="n">layer_nums</span><span class="p">,</span>
                 <span class="n">in_channels</span><span class="p">,</span>
                 <span class="n">out_channels</span><span class="p">,</span>
                 <span class="n">strides</span><span class="p">,</span>
                 <span class="n">num_classes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ResNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_nums</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_channels</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_channels</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;the length of layer_num, in_channels, out_channels list must be 4!&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">_conv7x7</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">_bn</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maxpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="n">block</span><span class="p">,</span>
                                       <span class="n">layer_nums</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                       <span class="n">in_channel</span><span class="o">=</span><span class="n">in_channels</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                       <span class="n">out_channel</span><span class="o">=</span><span class="n">out_channels</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                       <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="n">block</span><span class="p">,</span>
                                       <span class="n">layer_nums</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                       <span class="n">in_channel</span><span class="o">=</span><span class="n">in_channels</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                       <span class="n">out_channel</span><span class="o">=</span><span class="n">out_channels</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                       <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="n">block</span><span class="p">,</span>
                                       <span class="n">layer_nums</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                                       <span class="n">in_channel</span><span class="o">=</span><span class="n">in_channels</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                                       <span class="n">out_channel</span><span class="o">=</span><span class="n">out_channels</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                                       <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="n">block</span><span class="p">,</span>
                                       <span class="n">layer_nums</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                                       <span class="n">in_channel</span><span class="o">=</span><span class="n">in_channels</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                                       <span class="n">out_channel</span><span class="o">=</span><span class="n">out_channels</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                                       <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">(</span><span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end_point</span> <span class="o">=</span> <span class="n">_fc</span><span class="p">(</span><span class="n">out_channels</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_make_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="n">layer_num</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">resnet_block</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">)</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">resnet_block</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">layer_num</span><span class="p">):</span>
            <span class="n">resnet_block</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">resnet_block</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">c1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxpool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">c2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">c1</span><span class="p">)</span>
        <span class="n">c3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">c2</span><span class="p">)</span>
        <span class="n">c4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer3</span><span class="p">(</span><span class="n">c3</span><span class="p">)</span>
        <span class="n">c5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer4</span><span class="p">(</span><span class="n">c4</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">c5</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_point</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
<p>Constructing the whole ResNet50 network by passing in information about the number of layers of ResNet50.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">resnet50</span><span class="p">(</span><span class="n">class_num</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">ResNet</span><span class="p">(</span><span class="n">ResidualBlock</span><span class="p">,</span>
                  <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">2048</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="n">class_num</span><span class="p">)</span>
</pre></div>
</div>
<p>After the above steps, the MindSpore-based ResNet50 whole network structure and each sub-network structure have been developed, and the next step is to develop other modules.</p>
</section>
</section>
<section id="other-modules">
<h3>Other Modules<a class="headerlink" href="#other-modules" title="Permalink to this headline"></a></h3>
<p>Other modules usually include: reverse construction, gradient clipping, optimizer, learning rate generation, etc. These modules either have a single structure or rely on the results of the developed subnets in order to compare with the benchmark script. The development of scripts for these modules is less difficult than subnet development.</p>
<section id="id4">
<h4>ResNet50 migration example<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h4>
<p>For additional training configurations, see <a class="reference external" href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/resnet50v1.5#default-configuration">Configuration Information for NVIDIA Training ResNet50</a>, the training of ResNet50 mainly involves the following items.</p>
<ul class="simple">
<li><p>SGD + Momentum optimizer is used.</p></li>
<li><p>WeightDecay function is used (but gamma and bias of BatchNorm are not used).</p></li>
<li><p>The cosine LR schedule is used.</p></li>
<li><p>Label Smoothing is used.</p></li>
</ul>
<p>Implemented cosine LR schedule.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_generate_cosine_lr</span><span class="p">(</span><span class="n">lr_init</span><span class="p">,</span> <span class="n">lr_end</span><span class="p">,</span> <span class="n">lr_max</span><span class="p">,</span> <span class="n">total_steps</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies cosine decay to generate learning rate array.</span>

<span class="sd">    Args:</span>
<span class="sd">       lr_init(float): init learning rate.</span>
<span class="sd">       lr_end(float): end learning rate</span>
<span class="sd">       lr_max(float): max learning rate.</span>
<span class="sd">       total_steps(int): all steps in training.</span>
<span class="sd">       warmup_steps(int): all steps in warmup epochs.</span>

<span class="sd">    Returns:</span>
<span class="sd">       np.array, learning rate array.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">decay_steps</span> <span class="o">=</span> <span class="n">total_steps</span> <span class="o">-</span> <span class="n">warmup_steps</span>
    <span class="n">lr_each_step</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_steps</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">warmup_steps</span><span class="p">:</span>
            <span class="n">lr_inc</span> <span class="o">=</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">lr_max</span><span class="p">)</span> <span class="o">-</span> <span class="nb">float</span><span class="p">(</span><span class="n">lr_init</span><span class="p">))</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">warmup_steps</span><span class="p">)</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">lr_init</span><span class="p">)</span> <span class="o">+</span> <span class="n">lr_inc</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">linear_decay</span> <span class="o">=</span> <span class="p">(</span><span class="n">total_steps</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span> <span class="o">/</span> <span class="n">decay_steps</span>
            <span class="n">cosine_decay</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="mf">0.47</span> <span class="o">*</span> <span class="n">i</span> <span class="o">/</span> <span class="n">decay_steps</span><span class="p">))</span>
            <span class="n">decayed</span> <span class="o">=</span> <span class="n">linear_decay</span> <span class="o">*</span> <span class="n">cosine_decay</span> <span class="o">+</span> <span class="mf">0.00001</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">lr_max</span> <span class="o">*</span> <span class="n">decayed</span>
        <span class="n">lr_each_step</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lr_each_step</span>
</pre></div>
</div>
<p>Implemented SGD optimizer with Momentum, and applied WeightDecay to all weights except gamma and bias of BN.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Momentum</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="n">class_num</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">_generate_cosine_lr</span><span class="p">()</span>
<span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.875</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">32768</span>

<span class="n">decayed_params</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">no_decayed_params</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">():</span>
    <span class="k">if</span> <span class="s1">&#39;beta&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span> <span class="ow">and</span> <span class="s1">&#39;gamma&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span> <span class="ow">and</span> <span class="s1">&#39;bias&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
        <span class="n">decayed_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">no_decayed_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>

<span class="n">group_params</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">decayed_params</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="n">weight_decay</span><span class="p">},</span>
                <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">no_decayed_params</span><span class="p">},</span>
                <span class="p">{</span><span class="s1">&#39;order_params&#39;</span><span class="p">:</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()}]</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">group_params</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="p">)</span>
</pre></div>
</div>
<p>Define Loss Function and implement Label Smoothing.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">LossBase</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="c1"># define cross entropy loss</span>
<span class="k">class</span> <span class="nc">CrossEntropySmooth</span><span class="p">(</span><span class="n">LossBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;CrossEntropy&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">smooth_factor</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CrossEntropySmooth</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">onehot</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">OneHot</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span> <span class="o">=</span> <span class="n">sparse</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">smooth_factor</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">smooth_factor</span> <span class="o">/</span> <span class="p">(</span><span class="n">num_classes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ce</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logit</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span><span class="p">:</span>
            <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">onehot</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">logit</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ce</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

<span class="c1"># define loss with label smooth</span>
<span class="n">label_smooth_factor</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">CrossEntropySmooth</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span><span class="n">smooth_factor</span><span class="o">=</span><span class="n">label_smooth_factor</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="hyperparameters-comparison">
<h3>Hyperparameters Comparison<a class="headerlink" href="#hyperparameters-comparison" title="Permalink to this headline"></a></h3>
<p>When the subnetworks have been opened, the last step to do is to align the hyperparameters with the alignment script to ensure the network structure is consistent. It should be noted that the same set of hyperparameters may have different accuracy performance on different frameworks, so it is not necessary to strictly follow the hyperparameters of the peer script when migrating the network, and fine tuning can be done without changing the network structure.</p>
<section id="id5">
<h4>ResNet50 Migration Example<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h4>
<p>In the training of ResNet50, the following hyperparameters are mainly involved.</p>
<ul class="simple">
<li><p>momentum =0.875</p></li>
<li><p>batch_size = 256</p></li>
<li><p>learning rate = 0.256</p></li>
<li><p>learing rate schedule = cosine</p></li>
<li><p>weight_decay = 1/32768</p></li>
<li><p>label_smooth = 0.1</p></li>
<li><p>epoch size = 90</p></li>
</ul>
</section>
</section>
</section>
<section id="process-hitting">
<h2>Process Hitting<a class="headerlink" href="#process-hitting" title="Permalink to this headline"></a></h2>
<p>After the above steps, we have finished developing the necessary scripts for network migration, and the next step is to break through the stand-alone training, distributed training, and inference processes.</p>
<section id="stand-alone-training">
<h3>Stand-alone Training<a class="headerlink" href="#stand-alone-training" title="Permalink to this headline"></a></h3>
<section id="id6">
<h4>ResNet50 Migration Example<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h4>
<p>For a better reading of the code, it is recommended to organize the script according to the following structure.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>.
└──resnet
  ├── README.md
  ├── scripts
    ├── run_distribute_train.sh
    ├── run_eval.sh
    ├── run_standalone_train.sh
  ├── src
    ├── resnet18_cifar10_config.yaml
    ├── resnet18_imagenet2012_config.yaml
    ├── resnet34_imagenet2012_config.yaml
    ├── resnet50_cifar10_config.yaml
    ├── resnet50_imagenet2012_Ascend_config.yaml
    ├── resnet50_imagenet2012_config.yaml
    ├── resnet50_imagenet2012_GPU_config.yaml
    ├── resnet101_imagenet2012_config.yaml
    ├── se-resnet50_imagenet2012_config.yaml
    ├── dataset.py
    ├── CrossEntropySmooth.py
    ├── lr_generator.py
    └── resnet.py
  ├── eval.py
  └── train.py
</pre></div>
</div>
<p>train.py is defined as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">ast</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Momentum</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">CheckpointConfig</span><span class="p">,</span> <span class="n">LossMonitor</span><span class="p">,</span> <span class="n">TimeMonitor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">FixedLossScaleManager</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span><span class="p">,</span> <span class="n">get_group_size</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">set_seed</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.common.initializer</span> <span class="k">as</span> <span class="nn">weight_init</span>
<span class="kn">from</span> <span class="nn">src.lr_generator</span> <span class="kn">import</span> <span class="n">get_lr</span>
<span class="kn">from</span> <span class="nn">src.CrossEntropySmooth</span> <span class="kn">import</span> <span class="n">CrossEntropySmooth</span>
<span class="kn">from</span> <span class="nn">resnet50_imagenet2012_config.yaml</span> <span class="kn">import</span> <span class="n">config</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">src.resnet</span> <span class="kn">import</span> <span class="n">resnet50</span> <span class="k">as</span> <span class="n">resnet</span>
<span class="kn">from</span> <span class="nn">src.dataset</span> <span class="kn">import</span> <span class="n">create_dataset</span> <span class="k">as</span> <span class="n">create_dataset</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">ckpt_save_dir</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">checkpoint_path</span>

    <span class="c1"># init context</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">save_graphs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># create dataset</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="n">do_train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">repeat_num</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                             <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">step_size</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>

    <span class="c1"># define net</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">class_num</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">class_num</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">cell</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
           <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">weight_init</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="n">weight_init</span><span class="o">.</span><span class="n">XavierUniform</span><span class="p">(),</span>
                                                        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                                                        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">):</span>
           <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">weight_init</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="n">weight_init</span><span class="o">.</span><span class="n">TruncatedNormal</span><span class="p">(),</span>
                                                        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                                                        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">get_lr</span><span class="p">(</span><span class="n">lr_init</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_init</span><span class="p">,</span> <span class="n">lr_end</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_end</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_max</span><span class="p">,</span>
                <span class="n">warmup_epochs</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">warmup_epochs</span><span class="p">,</span> <span class="n">total_epochs</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">epoch_size</span><span class="p">,</span>
                <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">step_size</span><span class="p">,</span> <span class="n">lr_decay_mode</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_decay_mode</span><span class="p">)</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

    <span class="c1"># define opt</span>
    <span class="n">decayed_params</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">no_decayed_params</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">():</span>
        <span class="k">if</span> <span class="s1">&#39;beta&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span> <span class="ow">and</span> <span class="s1">&#39;gamma&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span> <span class="ow">and</span> <span class="s1">&#39;bias&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
            <span class="n">decayed_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">no_decayed_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>

    <span class="n">group_params</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">decayed_params</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="n">config</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">},</span>
                    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">no_decayed_params</span><span class="p">},</span>
                    <span class="p">{</span><span class="s1">&#39;order_params&#39;</span><span class="p">:</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()}]</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">group_params</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">)</span>
    <span class="c1"># define loss, model</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">CrossEntropySmooth</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="n">smooth_factor</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">label_smooth_factor</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">class_num</span><span class="p">)</span>
    <span class="n">loss_scale</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">drop_overflow_update</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">},</span>
                  <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O2&quot;</span><span class="p">,</span> <span class="n">keep_batchnorm_fp32</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># define callbacks</span>
    <span class="n">time_cb</span> <span class="o">=</span> <span class="n">TimeMonitor</span><span class="p">(</span><span class="n">data_size</span><span class="o">=</span><span class="n">step_size</span><span class="p">)</span>
    <span class="n">loss_cb</span> <span class="o">=</span> <span class="n">LossMonitor</span><span class="p">()</span>
    <span class="n">cb</span> <span class="o">=</span> <span class="p">[</span><span class="n">time_cb</span><span class="p">,</span> <span class="n">loss_cb</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">:</span>
        <span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">save_checkpoint_epochs</span> <span class="o">*</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">keep_checkpoint_max</span><span class="p">)</span>
        <span class="n">ckpt_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;resnet&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="n">ckpt_save_dir</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
        <span class="n">cb</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ckpt_cb</span><span class="p">]</span>

    <span class="c1"># train model</span>
    <span class="n">dataset_sink_mode</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">epoch_size</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">cb</span><span class="p">,</span> <span class="n">sink_size</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">(),</span>
                <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="n">dataset_sink_mode</span><span class="p">)</span>
</pre></div>
</div>
<p>Note: For codes in other files in the directory, refer to MindSpore model_zoo’s <a class="reference external" href="https://gitee.com/mindspore/models/tree/r1.5/official/cv/resnet">ResNet50 implementation</a>(this script incorporates other ResNet family networks and ResNet-SE networks, and the specific implementation may differ from the benchmark script).</p>
</section>
</section>
<section id="distributed-training">
<h3>Distributed training<a class="headerlink" href="#distributed-training" title="Permalink to this headline"></a></h3>
<p>Distributed training has no impact on the network structure compared to stand-alone training, and can be done by modifying the stand-alone script by calling the distributed training interface provided by MindSpore, as described in <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/distributed_training.html">Distributed Training Tutorial</a>.</p>
<section id="id7">
<h4>ResNet50 Migration Example<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h4>
<p>Add the following interface to the standalone training script.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">ast</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span><span class="p">,</span> <span class="n">get_group_size</span>
<span class="kn">from</span> <span class="nn">resnet50_imagenet2012_config.yaml</span> <span class="kn">import</span> <span class="n">config</span>

<span class="c1"># ...</span>
<span class="n">device_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;DEVICE_ID&#39;</span><span class="p">))</span> <span class="c1"># get the current device id</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_id</span><span class="o">=</span><span class="n">device_id</span><span class="p">)</span>
<span class="c1"># enable distribute training</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">device_num</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">device_num</span><span class="p">,</span>
                                  <span class="n">parallel_mode</span><span class="o">=</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">DATA_PARALLEL</span><span class="p">,</span> <span class="n">gradients_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># init distribute training</span>
<span class="n">init</span><span class="p">()</span>
</pre></div>
</div>
<p>Modify the create_dataset interface to shard the data on data load to support distributed training by.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span><span class="p">,</span> <span class="n">get_group_size</span>
<span class="c1"># ....</span>
<span class="n">device_num</span><span class="p">,</span> <span class="n">rank_id</span> <span class="o">=</span> <span class="n">_get_rank_info</span><span class="p">()</span>
<span class="k">if</span> <span class="n">device_num</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="c1"># standalone training</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># distribute training</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">num_shards</span><span class="o">=</span><span class="n">device_num</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="n">rank_id</span><span class="p">)</span>
<span class="c1"># ...</span>
</pre></div>
</div>
</section>
</section>
<section id="inference">
<h3>Inference<a class="headerlink" href="#inference" title="Permalink to this headline"></a></h3>
<p>The inference process differs from training in the following ways.</p>
<ul class="simple">
<li><p>No need to define losses and optimizers.</p></li>
<li><p>No need for repeat operations when constructing the dataset.</p></li>
<li><p>Need to load trained CheckPoint after network definition.</p></li>
<li><p>Define the metric for computing inference accuracy.</p></li>
</ul>
<section id="id8">
<h4>ResNet50 Migration Example<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h4>
<p>Modified inference script:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">set_seed</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">src.resnet</span> <span class="kn">import</span> <span class="n">resnet50</span> <span class="k">as</span> <span class="n">resnet</span>
<span class="kn">from</span> <span class="nn">src.dataset</span> <span class="kn">import</span> <span class="n">create_dataset</span>
<span class="kn">from</span> <span class="nn">resnet50_imagenet2012_config.yaml</span> <span class="kn">import</span> <span class="n">config</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">device_target</span>

    <span class="c1"># init context</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">save_graphs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">device_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;DEVICE_ID&#39;</span><span class="p">))</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_id</span><span class="o">=</span><span class="n">device_id</span><span class="p">)</span>

    <span class="c1"># create dataset</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="n">do_train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">step_size</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>

    <span class="c1"># define net</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">class_num</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">class_num</span><span class="p">)</span>

    <span class="c1"># load checkpoint</span>
    <span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">checkpoint_path</span><span class="p">)</span>
    <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># define model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;top_1_accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;top_5_accuracy&#39;</span><span class="p">})</span>

    <span class="c1"># eval model</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;result:&quot;</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="s2">&quot;ckpt=&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">checkpoint_path</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="problem-location">
<h3>Problem Location<a class="headerlink" href="#problem-location" title="Permalink to this headline"></a></h3>
<p>You may encounter some interruptions in the training during the process, you can refer to the <a class="reference external" href="https://www.mindspore.cn/docs/migration_guide/en/r1.5/neural_network_debug.html">Network Training Debug Tutorial</a> to locate and solve them.</p>
</section>
</section>
<section id="precision-tuning">
<h2>Precision tuning<a class="headerlink" href="#precision-tuning" title="Permalink to this headline"></a></h2>
<p>After hitting the flow, you can get the accuracy of network training by both training and inference steps. Usually, it is difficult to reproduce the accuracy of the alignment script at once, and we need to gradually improve the accuracy by accuracy tuning, which is less intuitive, less efficient, and more work than performance tuning.</p>
</section>
<section id="performance-tuning">
<h2>Performance Tuning<a class="headerlink" href="#performance-tuning" title="Permalink to this headline"></a></h2>
<p>Usually, we refer to performance tuning to improve training performance with a fixed dataset, network size, and number of hardware, while improving performance by changing dataset size, network size, and number of hardware is obvious and out of the scope of this paper.</p>
<p>Unless the performance problem has seriously hindered the accuracy debugging, the performance tuning must be placed after the accuracy has reached the standard, which has two main reasons: first, many modifications will affect the performance when locating the accuracy problem, making the already tuned performance again not up to standard, which may waste the workload; second, the performance tuning may introduce new accuracy problems, and if there is no accuracy that has reached the standard as a caretaker, the difficulty of locating the accuracy problem introduced this time will be greatly increased later.</p>
<section id="analyzing-profiling-data">
<h3>Analyzing Profiling Data<a class="headerlink" href="#analyzing-profiling-data" title="Permalink to this headline"></a></h3>
<p>Analyzing Profiling data is an essential step in the performance tuning phase, and MindSpore’s performance and precision tuning tool <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.5/index.html">MindInsight</a> provides a rich set of performance and precision tuning methods, and the most important information for performance tuning is the Profiling data. In the iteration trajectory, you can see very detailed information about the start run time, end run time, number of calls and call order of each operator, which is very helpful for our performance tuning. The way to generate Profiling data is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.profiler</span> <span class="kn">import</span> <span class="n">Profiler</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">context</span>

<span class="c1"># init context</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">,</span> <span class="n">device_id</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;DEVICE_ID&quot;</span><span class="p">]))</span>

<span class="c1"># init profiler, profiling data will be stored under folder ./data by default</span>
<span class="n">profiler</span> <span class="o">=</span> <span class="n">Profiler</span><span class="p">()</span>

<span class="c1"># start training</span>
<span class="n">Model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="c1"># end training，parse profiling data to readable text</span>
<span class="n">profiler</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
</pre></div>
</div>
<p>For more detailed usage of Profiling, you can refer to <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.5/performance_profiling.html">Profiling Performance Analysis Methods</a>.</p>
<p>After obtaining Profiling data, we can analyze the performance bottleneck stages and operators, and then perform performance optimization, which can be referred to <a class="reference external" href="https://www.mindspore.cn/docs/migration_guide/en/r1.5/performance_optimization.html">Performance Tuning Guide</a>.</p>
</section>
<section id="common-problems-and-corresponding-optimization-methods">
<h3>Common Problems and Corresponding Optimization Methods<a class="headerlink" href="#common-problems-and-corresponding-optimization-methods" title="Permalink to this headline"></a></h3>
<section id="minddata-performance">
<h4>MindData Performance<a class="headerlink" href="#minddata-performance" title="Permalink to this headline"></a></h4>
<p>Single-Step performance jitter and data queues that remain empty for a period of time are caused by poor performance of the data preprocessing part, which makes the data processing speed unable to keep up with the single-Step iteration speed, and these two phenomena usually occur in pairs.</p>
<p>When the data processing speed is slow, the queue is gradually depleted from the initial full queue to an empty queue, and the training process will start waiting for the empty queue to be filled with data, and the network will continue the single-step training only once new data is filled. Since there is no queue as buffer for data processing, the performance jitter of data processing is directly reflected in the performance of single-Step, so it will also cause single-Step performance jitter.</p>
</section>
<section id="multi-machine-synchronization-performance">
<h4>Multi-machine Synchronization Performance<a class="headerlink" href="#multi-machine-synchronization-performance" title="Permalink to this headline"></a></h4>
<p>When distributed training is performed, after the forward propagation and gradient computation are completed during a Step, each machine starts to synchronize the AllReduce gradient, and the AllReduce synchronization time is mainly affected by the number of weights and machines.</p>
<p>Normally, AllReduce gradient synchronization waits until all the inverse operators are finished, i.e., all the gradients of all weights are computed before synchronizing the gradients of all machines at once, but with AllReduce tangent, we can synchronize the gradients of some weights as soon as they are computed, so that the gradient synchronization and the gradient computation of the remaining operators can be This way, the gradient synchronization and the gradient computation of the remaining operators can be performed in parallel, hiding this part of the AllReduce gradient synchronization time. The slicing strategy is usually a manual attempt to find an optimal solution (supporting slicing greater than two segments).
As an example, <a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.5/official/cv/resnet/train.py">ResNet50 network</a> has 160 weights and [85, 160] means that the gradient synchronization is performed immediately after the gradient is calculated for the 0th to 85th weights, and the gradient synchronization is performed after the gradient is calculated for the 86th to 160th weights. The code implementation is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">resnet50_imagenet2012_config.yaml</span> <span class="kn">import</span> <span class="n">config</span>
<span class="o">...</span>

<span class="n">device_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;DEVICE_ID&#39;</span><span class="p">))</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_id</span><span class="o">=</span><span class="n">device_id</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">device_num</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">device_num</span><span class="p">,</span>
                                  <span class="n">parallel_mode</span><span class="o">=</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">DATA_PARALLEL</span><span class="p">,</span> <span class="n">gradients_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">set_algo_parameters</span><span class="p">(</span><span class="n">elementwise_op_strategy_follow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">net_name</span> <span class="o">==</span> <span class="s2">&quot;resnet50&quot;</span> <span class="ow">or</span> <span class="n">config</span><span class="o">.</span><span class="n">net_name</span> <span class="o">==</span> <span class="s2">&quot;se-resnet50&quot;</span><span class="p">:</span>
    <span class="c1"># AllReduce split</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">all_reduce_fusion_config</span><span class="o">=</span><span class="p">[</span><span class="mi">85</span><span class="p">,</span> <span class="mi">160</span><span class="p">])</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># Another split stratety</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">all_reduce_fusion_config</span><span class="o">=</span><span class="p">[</span><span class="mi">180</span><span class="p">,</span> <span class="mi">313</span><span class="p">])</span>
<span class="n">init</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="operator-performance">
<h4>Operator Performance<a class="headerlink" href="#operator-performance" title="Permalink to this headline"></a></h4>
<p>The situation that a single operator takes a long time and the performance of the same operator varies greatly under different shapes or different datatypes is mainly caused by the operator performance problem, which usually has the following two solutions.</p>
<ol class="arabic simple">
<li><p>Use less computationally intensive data types. For example, there is no significant difference in precision between float16 and float32 for the same operator, so use the less computationally intensive float16 format.</p></li>
<li><p>Use other operators with the same algorithm to circumvent it.</p></li>
</ol>
<p>If you find any arithmetic with poor performance, we suggest you contact <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues">MindSpore Community</a> for feedback, and we will optimize it as soon as we confirm the performance problem.</p>
</section>
<section id="framework-performance">
<h4>Framework Performance<a class="headerlink" href="#framework-performance" title="Permalink to this headline"></a></h4>
<p>If there are too many conversion operators (TransData, Cast-like operators) and they take too much time, we can analyze the necessity of Cast operators if we add them manually, and remove the redundant Cast and TransData operators if they have no impact on the accuracy.</p>
<p>If MindSpore automatically generates too many conversion operators, it may be that the MindSpore framework is not fully optimized for some special cases, you can contact <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues">MindSpore Community</a> for feedback.</p>
</section>
<section id="other-general-optimization-methods">
<h4>Other General Optimization Methods<a class="headerlink" href="#other-general-optimization-methods" title="Permalink to this headline"></a></h4>
<ul>
<li><p>Using mixed precision training</p>
<p>The mixed precision training method accelerates the process of deep neural network training by using a mixture of single precision and half precision data formats, while maintaining the network accuracy that can be achieved with single precision training. Mixed precision training accelerates the computation process while reducing memory usage and access, and allows for training larger models or batch sizes on specific hardware.</p>
<p>For details, please refer to the <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/enable_mixed_precision.html">Mixed precision tutorial</a>.</p>
</li>
<li><p>Enabling graph kernel fusion</p>
<p>Graph-calculus fusion is a network performance optimization technique unique to MindSpore. It can automatically analyze and optimize existing network computation graph logic and combine with target hardware capabilities to perform computation reduction and substitution, operator splitting and fusion, operator special case compilation, etc. to improve the utilization of device computation resources and achieve overall optimization of network performance. Compared with traditional optimization techniques, graph computation fusion has unique advantages such as joint optimization of multiple operators across boundaries, cross-layer collaboration with operator compilation, and instant compilation of operators based on Polyhedral. In addition, graph fusion only requires the user to open the corresponding configuration, and then the whole optimization process can be completed automatically, without the need for additional sensing by the network developer, allowing the user to focus on the network algorithm implementation.</p>
<p>The scenarios for graph fusion include: scenarios with high performance requirements for network execution time; scenarios where custom combinatorial operators are implemented by splicing basic operators, and where automatic fusion of these basic operators is desired to improve the performance of the custom combinatorial operators.</p>
<p>For details, please refer to the <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/enable_graph_kernel_fusion.html">tutorial on graph arithmetic fusion</a>.</p>
</li>
</ul>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="inference.html" class="btn btn-neutral float-left" title="Inference Execution" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="api_mapping.html" class="btn btn-neutral float-right" title="API Mapping" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>