<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>网络迁移调试实例 &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="常见问题" href="faq.html" />
    <link rel="prev" title="推理执行" href="inference.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="preparation.html">准备工作</a></li>
<li class="toctree-l1"><a class="reference internal" href="script_analysis.html">网络脚本分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="script_development.html">网络脚本开发</a></li>
<li class="toctree-l1"><a class="reference internal" href="neural_network_debug.html">网络调试</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.3/accuracy_optimization.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_optimization.html">性能调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="inference.html">推理执行</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">网络迁移调试实例</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id2">对标网络分析与复现</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id3">确定迁移目标</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#resnet50">ResNet50 迁移示例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id4">复现迁移目标</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step">复现单Step结果</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id5">脚本开发</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id6">脚本开发前分析</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id7">ResNet50 迁移示例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id8">数据预处理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id9">ResNet50 迁移示例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id10">子网开发</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id11">ResNet50 迁移示例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id12">其他模块</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id13">ResNet50 迁移示例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id14">超参对比</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id15">ResNet50 迁移示例</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id16">流程打通</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id17">单机训练</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id18">ResNet50 迁移示例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id19">分布式训练</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id20">ResNet50 迁移示例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id21">推理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id22">ResNet50 迁移示例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id23">问题定位</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id24">精度调优</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id25">性能调优</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#profiling">分析Profiling数据</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id26">常见问题及相应优化方法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#minddata">MindData 性能问题</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id27">多机同步性能问题</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id28">算子性能问题</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id29">框架性能问题</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id30">其他通用优化方法</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">常见问题</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>网络迁移调试实例</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/sample_code.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="id1">
<h1>网络迁移调试实例<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.3/docs/mindspore/migration_guide/source_zh_cn/sample_code.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.3/resource/_static/logo_source.png"></a></p>
<p>本章将结合用例来介绍网络迁移的基本步骤、常用工具、定位问题的思路及解决方法。</p>
<p>这里以经典网络 ResNet50 为例，结合代码来详细介绍网络迁移方法。</p>
<section id="id2">
<h2>对标网络分析与复现<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h2>
<section id="id3">
<h3>确定迁移目标<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h3>
<p>网络迁移的第一步是确定迁移目标，即先找到一个合适的、可达成的标准，通常一个深度神经网络的交付目标包括以下四个部分：</p>
<ol class="arabic simple">
<li><p>网络实现：这是迁移目标中最基本的部分，有时同一个神经网络有不同的版本、同一个版本有不同的实现方式或者在相同的神经网络下使用不同的超参，这些差别会对最终的收敛精度和性能造成一定影响。通常，我们以神经网络作者本身的实现为准，也可以参考不同框架（例如TensorFlow、PyTorch等）的官方实现或其他主流开源工具箱（例如 MMDetection）。</p></li>
<li><p>数据集：相同的神经网络和参数，在不同的数据集上往往差别很大，因此我们需要确认迁移网络所使用的数据集。一些数据集的数据内容会频繁更新，确定数据集时需要注意数据集的版本、训练数据和测试数据划分比例等问题。</p></li>
<li><p>收敛精度：不同的框架、不同的GPU型号、是否为分布式训练等因素会对精度有所影响，在确定迁移目标时需要分析清楚对标的框架、硬件等信息。</p></li>
<li><p>训练性能：和收敛精度相同，训练性能主要受网络脚本、框架性能、GPU硬件本身和是否为分布式训练等因素影响。</p></li>
</ol>
<section id="resnet50">
<h4>ResNet50 迁移示例<a class="headerlink" href="#resnet50" title="Permalink to this headline"></a></h4>
<p>ResNet50 是 CV 中经典的深度神经网络，有较多开发者关注和复现，而 PyTorch 的语法和 MindSpore 较为相似，因此，我们选择 PyTorch 作为对标框架。</p>
<p>PyTorch 官方实现脚本可参考 <a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py">torchvision model</a> 或者 <a class="reference external" href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/resnet50v1.5">英伟达 PyTorch 实现脚本</a>，其中包括了主流 ResNet 系列网络的实现（ResNet18、ResNet34、ResNet50、ResNet101、ResNet152）。ResNet50 所使用的数据集为 ImageNet2012，收敛精度可参考 <a class="reference external" href="https://pytorch.org/hub/pytorch_vision_resnet/#model-description">PyTorch Hub</a>。</p>
<p>开发者可以基于 PyTorch 的 ResNet50 脚本直接在对标的硬件环境下运行，然后计算出性能数据，也可以参考同硬件环境下的官方数据。例如，当我们对标 Nvidia DGX-1 32GB(8x V100 32GB) 硬件时，可参考 <a class="reference external" href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/resnet50v1.5#training-performance-nvidia-dgx-1-32gb-8x-v100-32gb">Nvidia 官方发布的 ResNet50 性能数据</a>。</p>
</section>
</section>
<section id="id4">
<h3>复现迁移目标<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h3>
<p>网络迁移目标确定完成后，接下来要做的就是复现指标。复现标杆数据对后续精度和性能调优十分重要，当我们在 MindSpore 开发的网络和对标脚本有精度/性能差距时，很多时候都是以标杆数据作为基准，一步一步地分析迁移脚本和对标脚本的差别，如果对标脚本无法复现指标，那我们以此为基准开发的 MindSpore 脚本就很难达到迁移目标。复现迁移指标时，不仅要复现训练阶段，推理阶段也同样重要。</p>
<p>需要注意的是，对于部分网络，使用相同的硬件环境和脚本，最终达到的收敛精度和性能也可能与原作者提出的结果有细微差别，这属于正常的波动范围，我们在迁移网络时要把这种波动考虑在内。</p>
</section>
<section id="step">
<h3>复现单Step结果<a class="headerlink" href="#step" title="Permalink to this headline"></a></h3>
<p>复现单 Step 结果主要是为了接下来的脚本开发和网络调优。对于复杂的神经网络，完整的训练需要耗时几天甚至几个月，如果仅以最终的训练精度和结果做参考，会极大地降低开发效率。因此，我们需要提前复现单 Step 的运行结果，即获取只执行第一个 Step 后网络的状态（该状态是经历了数据预处理、权重初始化、正向计算、loss 计算、反向梯度计算和优化器更新之后的结果，覆盖了网络训练的全部环节），并以此为对照展开后续的开发工作。</p>
</section>
</section>
<section id="id5">
<h2>脚本开发<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h2>
<section id="id6">
<h3>脚本开发前分析<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h3>
<p>在开始真正的开发脚本前，需要进行对标脚本分析。脚本分析的目的是识别出 MindSpore 与对标框架相比缺失的算子或功能。具体方法可以参考<a class="reference external" href="https://www.mindspore.cn/docs/migration_guide/zh-CN/r1.3/script_analysis.html">脚本评估教程</a>。</p>
<p>MindSpore 已支持绝大多数常用 <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.3/index.html">功能</a> 和 <a class="reference external" href="https://www.mindspore.cn/docs/note/zh-CN/r1.3/operator_list.html">算子</a>。MindSpore 既支持动态图（PyNative）模式，又支持静态图（Graph）模式，动态图模式灵活、易于调试，因此动态图模式主要用于网络调试，静态图模式性能好，主要用于整网训练，在分析缺失算子和功能时，要分别分析这两种模式。</p>
<p>如果发现有缺失的算子和功能，首先可考虑基于当前算子或功能来组合出缺失的算子和功能，对于主流的 CV 和 NLP 类网络，新的缺失算子一般都可以通过组合已有算子的方式来解决。</p>
<p>组合的算子可以通过 Cell 的方式实现，在 MindSpore 中，<a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.3/mindspore/nn">nn类算子</a> 就是通过这种方式实现的。例如下面的 <code class="docutils literal notranslate"><span class="pre">ReduceSumExp</span></code> 算子，它是由已有的<code class="docutils literal notranslate"><span class="pre">Exp</span></code>、<code class="docutils literal notranslate"><span class="pre">ReduceSum</span></code>、<code class="docutils literal notranslate"><span class="pre">Log</span></code>小算子组合而成：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ReduceLogSumExp</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ReduceLogSumExp</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">validator</span><span class="o">.</span><span class="n">check_value_type</span><span class="p">(</span><span class="s1">&#39;axis&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls_name</span><span class="p">)</span>
        <span class="n">validator</span><span class="o">.</span><span class="n">check_value_type</span><span class="p">(</span><span class="s1">&#39;keep_dims&#39;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="p">[</span><span class="nb">bool</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls_name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exp</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Exp</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Log</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">exp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">sumexp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">exp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">axis</span><span class="p">)</span>
        <span class="n">logsumexp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sumexp</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logsumexp</span>
</pre></div>
</div>
<p>如果缺失的功能和算子无法规避，或者组合算子性能较差，严重影响网络的训练和推理，可联系 <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues">MindSpore社区</a> 反馈，我们会有专门的工作人员为您解决。</p>
<section id="id7">
<h4>ResNet50 迁移示例<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h4>
<p>以下为 ResNet 系列网络结构：</p>
<p><img alt="image-20210318152607548" src="_images/image-20210318152607548.png" /></p>
<p>PyTorch 实现的 ResNet50 脚本参考 <a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py">torchvision model</a>。</p>
<p>我们可以基于算子和功能两个方面分析：</p>
<ul class="simple">
<li><p>算子分析</p></li>
</ul>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>PyTorch 使用算子</p></th>
<th class="head"><p>MindSpore 对应算子</p></th>
<th class="head"><p>是否支持该算子所需功能</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.Conv2D</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Conv2d</span></code></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">nn.BatchNorm2D</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.BatchNom2d</span></code></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.ReLU</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.ReLU</span></code></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">nn.MaxPool2D</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.MaxPool2d</span></code></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.AdaptiveAvgPool2D</span></code></p></td>
<td><p>无</p></td>
<td><p>不支持</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Dense</span></code></p></td>
<td><p>是</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">torch.flatten</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Flatten</span></code></p></td>
<td><p>是</p></td>
</tr>
</tbody>
</table>
<p>注：对于 PyTorch 脚本，MindSpore 提供了 <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.3/index.html#operator_api">PyTorch 算子映射工具</a>，可直接查询该算子是否支持。</p>
<ul class="simple">
<li><p>功能分析</p></li>
</ul>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Pytorch 使用功能</p></th>
<th class="head"><p>MindSpore 对应功能</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.init.kaiming_normal_</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">initializer(init='HeNormal')</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">nn.init.constant_</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">initializer(init='Constant')</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.SequentialCell</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Cell</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nn.distibuted</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">context.set_auto_parallel_context</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">torch.optim.SGD</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.optim.SGD</span></code> or <code class="docutils literal notranslate"><span class="pre">nn.optim.Momentum</span></code></p></td>
</tr>
</tbody>
</table>
<p>（由于MindSpore 和 PyTorch 在接口设计上不完全一致，这里仅列出关键功能的比对）</p>
<p>经过算子和功能分析，我们发现，相比 PyTorch，MindSpore 功能上没有缺失，但算子上缺失 <code class="docutils literal notranslate"><span class="pre">nn.AdaptiveAvgPool</span></code> ，这时我们需要更一步的分析，该缺失算子是否有可替代方案。在 ResNet50 网络中，输入的图片 shape 是固定的，统一为 <code class="docutils literal notranslate"><span class="pre">N,3,224,224</span></code>，其中 N 为 batch size，3 为通道的数量，224 和 224 分别为图片的宽和高，网络中改变图片大小的算子有 <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code>  和 <code class="docutils literal notranslate"><span class="pre">Maxpool2d</span></code>，这两个算子对shape 的影响是固定的，因此，<code class="docutils literal notranslate"><span class="pre">nn.AdaptiveAvgPool2D</span></code> 的输入和输出 shape 是可以提前确定的，只要我们计算出 <code class="docutils literal notranslate"><span class="pre">nn.AdaptiveAvgPool2D</span></code> 的输入和输出 shape，就可以通过 <code class="docutils literal notranslate"><span class="pre">nn.AvgPool</span></code> 或 <code class="docutils literal notranslate"><span class="pre">nn.ReduceMean</span></code> 来实现，所以该算子的缺失是可替代的，并不影响网络的训练。</p>
</section>
</section>
<section id="id8">
<h3>数据预处理<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h3>
<p>要理解一个神经网络的实现，首先要清楚网络的输入数据，因此，数据预处理是脚本开发的第一个环节。MindSpore 设计了一个专门进行数据处理的模块 - MindData，使用 MindData 进行数据预处理主要包括以下几个步骤：</p>
<ol class="arabic simple">
<li><p>传入数据路径，读取数据文件。</p></li>
<li><p>解析数据。</p></li>
<li><p>数据处理（如常见数据切分、shuffle、数据增强等操作）。</p></li>
<li><p>数据分发（以 batch_size 为单位分发数据，分布式训练涉及多机分发）。</p></li>
</ol>
<p>在读取和解析数据过程中，MindSpore 提供了一种更友好的数据格式 - <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.3/convert_dataset.html">MindRecord</a>。用户可以将常规格式的数据集转换为 MindSpore数据格式，即 MindRecord，从而方便地加载到 MindSpore 中进行训练。同时，MindSpore 在部分场景做了性能优化，使用 MindRecord 数据格式可以获得更好的性能。</p>
<p>数据处理通常是数据准备中最耗时的阶段，大部分对数据的操作都被包含在这一步骤里，例如 CV 类网络中的Resize、Rescale、Crop 等操作。MindSpore 提供了一套常用的数据处理集成接口，用户可以不用自己实现而直接调用这些接口，这些集成接口不仅可以提升用户的易用性，还可以提升数据预处理的性能，减少训练过程中数据准备的耗时。具体可以参考<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.3/optimize_data_processing.html">数据预处理教程</a>。</p>
<p>在数据分发环节，MindData 提供了极为简洁的 API，可以通过直接调用 batch、repeat 等操作完成数据的 batch 组合、重复等操作。</p>
<p>当完成以上4个步骤后，我们理论上使用 MindSpore 脚本和对标脚本处理数据集后，可以得到完全相同的数据（如果有引入随机情况的操作需要去除）。</p>
<section id="id9">
<h4>ResNet50 迁移示例<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h4>
<p>ResNet50 网络使用的是 ImageNet2012 数据集，其数据预处理的 PyTorch 代码如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># sample execution (requires torchvision)</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="n">input_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="n">preprocess</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
<span class="p">])</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span>
<span class="n">input_batch</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># create a mini-batch as expected by the model</span>
</pre></div>
</div>
<p>通过观察以上代码，我们发现 ResNet50 的数据预处理主要做了 Resize、CenterCrop、Normalize 操作，在 MindSpore 中实现这些操作有两种方式，一是使用 MindSpore 的数据处理模块 MindData 来调用已封装好的数据预处理接口，二是通过 <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.3/dataset_loading.html?highlight=data%20generator#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8A%A0%E8%BD%BD">自定义数据集</a> 进行加载。这里更建议开发者选择第一种方式，这样不仅可以减少重复代码的开发，减少错误的引入，还可以得到更好的数据处理性能。更多关于MindData数据处理的介绍，可参考 <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.3/index.html">编程指南</a>中的数据管道部分。</p>
<p>以下是基于 MindData 开发的数据处理函数：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">do_train</span><span class="p">,</span> <span class="n">repeat_num</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">,</span> <span class="n">distribute</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="c1"># device number: total number of devices of training</span>
    <span class="c1"># rank_id: the sequence of current device of training</span>
    <span class="n">device_num</span><span class="p">,</span> <span class="n">rank_id</span> <span class="o">=</span> <span class="n">_get_rank_info</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">distribute</span><span class="p">:</span>
        <span class="n">init</span><span class="p">()</span>
        <span class="n">rank_id</span> <span class="o">=</span> <span class="n">get_rank</span><span class="p">()</span>
        <span class="n">device_num</span> <span class="o">=</span> <span class="n">get_group_size</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">device_num</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">device_num</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># standalone training</span>
        <span class="c1"># num_paralel_workers: parallel degree of data process</span>
        <span class="c1"># shuffle: whether shuffle data or not</span>
        <span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">ImageFolderDataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># distributing traing (meaning of num_parallel_workers and shuffle is same as above)</span>
        <span class="c1"># num_shards: total number devices for distribute training, which equals number shard of data</span>
        <span class="c1"># shard_id: the sequence of current device in all distribute training devices, which equals the data shard sequence for current device</span>
        <span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">ImageFolderDataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="n">device_num</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="n">rank</span><span class="p">)</span>

    <span class="c1"># define data operations</span>
    <span class="n">trans</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">do_train</span><span class="p">:</span>
        <span class="n">trans</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="n">C</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="n">trans</span> <span class="o">+=</span> <span class="p">[</span>
        <span class="n">C</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">Rescale</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
        <span class="n">C</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()</span>
    <span class="p">]</span>

    <span class="n">type_cast_op</span> <span class="o">=</span> <span class="n">C2</span><span class="o">.</span><span class="n">TypeCast</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="c1"># call data operations by map</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">type_cast_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">trans</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="c1"># batchinng data</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># repeat data, usually repeat_num equals epoch_size</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">repeat_num</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">data_set</span>
</pre></div>
</div>
<p>在以上代码中我们可以发现，针对常用的经典数据集（如 ImageNet2012），MindData 也为我们提供了 <code class="docutils literal notranslate"><span class="pre">ImageFolderDataset</span></code> 接口直接读取原始数据，省去了手写代码读取文件的工作量。需要注意的是，单机训练和多机分布式训练时 MindData 创建数据集的参数是不一样的，分布式训练需要额外指定 <code class="docutils literal notranslate"><span class="pre">num_shard</span></code> 和 <code class="docutils literal notranslate"><span class="pre">shard_id</span></code> 两个参数。</p>
</section>
</section>
<section id="id10">
<h3>子网开发<a class="headerlink" href="#id10" title="Permalink to this headline"></a></h3>
<p>通常子网开发包含两个部分：训练子网和 loss 子网，其中训练子网可根据网络的复杂程度决定是否继续划分。直接开发一个大型的神经网络脚本可能会让我们无从下手，因此，我们可以将网络中不同模块或子模块作为一个个子网抽离出来单独开发，这样可以保证各个子网并行开发，互相不受干扰。子网开发完成后，还可以固定子网输入和权重，与对标脚本的子网代码形成对比，作为后续网络开发的测试用例。</p>
<p>在精度调优阶段，我们常常会遇到精度不达标的情况，这时我们会重新审视已开发的脚本并逐行排查。而使用子网方式开发脚本并形成测试用例可以高效地帮助我们排除怀疑点，从几十个算子里寻找可疑点，要比从成百上千个算子中找可疑点轻松得多，尤其是在很多时候，同一个子网会被重复调用多次，当我们以子网为单位排查时，可以减少很多工作量。</p>
<section id="id11">
<h4>ResNet50 迁移示例<a class="headerlink" href="#id11" title="Permalink to this headline"></a></h4>
<p>分析 ResNet50 网络代码，主要可以分成以下几个子网：</p>
<ul class="simple">
<li><p>conv1x1、conv3x3：定义了不同 kernel_size 的卷积。</p></li>
<li><p>BasicBlock：ResNet 系列网络中 ResNet18 和 ResNet34 的最小子网，由 Conv、BN、ReLU 和 残差组成。</p></li>
<li><p>BottleNeck：ResNet 系列网络中 ResNet50、ResNet101 和 ResNet152 的最小子网，相比 BasicBlock 多了一层 Conv、BN 和 ReLU的结构，下采样的卷积位置也做了改变。</p></li>
<li><p>ResNet：封装了 BasiclBlock、BottleNeck 和 Layer 结构的网络，传入不同的参数即可构造不同的ResNet系列网络。在该结构中，也使用了一些 PyTorch 自定义的初始化功能。</p></li>
</ul>
<p>基于以上子网划分，我们结合 MindSpore 语法，重新完成上述开发。</p>
<p>重新开发权重初始化（也可以直接使用 <a class="reference external" href="https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/mindspore.common.initializer.html?highlight=common%20initializer#">MindSpore 已定义的权重初始化方法</a>）：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_conv_variance_scaling_initializer</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">):</span>
    <span class="n">fan_in</span> <span class="o">=</span> <span class="n">in_channel</span> <span class="o">*</span> <span class="n">kernel_size</span> <span class="o">*</span> <span class="n">kernel_size</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">scale</span> <span class="o">/=</span> <span class="nb">max</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">fan_in</span><span class="p">)</span>
    <span class="n">stddev</span> <span class="o">=</span> <span class="p">(</span><span class="n">scale</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="mf">.87962566103423978</span>
    <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">stddev</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">truncnorm</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">out_channel</span> <span class="o">*</span> <span class="n">in_channel</span> <span class="o">*</span> <span class="n">kernel_size</span> <span class="o">*</span> <span class="n">kernel_size</span><span class="p">)</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_weight_variable</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="n">init_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="n">factor</span>
    <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">init_value</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">calculate_gain</span><span class="p">(</span><span class="n">nonlinearity</span><span class="p">,</span> <span class="n">param</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;calculate_gain&quot;&quot;&quot;</span>
    <span class="n">linear_fns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;conv1d&#39;</span><span class="p">,</span> <span class="s1">&#39;conv2d&#39;</span><span class="p">,</span> <span class="s1">&#39;conv3d&#39;</span><span class="p">,</span> <span class="s1">&#39;conv_transpose1d&#39;</span><span class="p">,</span> <span class="s1">&#39;conv_transpose2d&#39;</span><span class="p">,</span> <span class="s1">&#39;conv_transpose3d&#39;</span><span class="p">]</span>
    <span class="n">res</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">nonlinearity</span> <span class="ow">in</span> <span class="n">linear_fns</span> <span class="ow">or</span> <span class="n">nonlinearity</span> <span class="o">==</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">elif</span> <span class="n">nonlinearity</span> <span class="o">==</span> <span class="s1">&#39;tanh&#39;</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="mf">5.0</span> <span class="o">/</span> <span class="mi">3</span>
    <span class="k">elif</span> <span class="n">nonlinearity</span> <span class="o">==</span> <span class="s1">&#39;relu&#39;</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">nonlinearity</span> <span class="o">==</span> <span class="s1">&#39;leaky_relu&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">param</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">negative_slope</span> <span class="o">=</span> <span class="mf">0.01</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="c1"># True/False are instances of int, hence check above</span>
            <span class="n">negative_slope</span> <span class="o">=</span> <span class="n">param</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;negative_slope </span><span class="si">{}</span><span class="s2"> not a valid number&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">param</span><span class="p">))</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">negative_slope</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unsupported nonlinearity </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nonlinearity</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span>


<span class="k">def</span> <span class="nf">_calculate_fan_in_and_fan_out</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;_calculate_fan_in_and_fan_out&quot;&quot;&quot;</span>
    <span class="n">dimensions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dimensions</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Fan in and fan out can not be computed for tensor with fewer than 2 dimensions&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dimensions</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Linear</span>
        <span class="n">fan_in</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">fan_out</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">num_input_fmaps</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">num_output_fmaps</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">receptive_field_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">dimensions</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">receptive_field_size</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
        <span class="n">fan_in</span> <span class="o">=</span> <span class="n">num_input_fmaps</span> <span class="o">*</span> <span class="n">receptive_field_size</span>
        <span class="n">fan_out</span> <span class="o">=</span> <span class="n">num_output_fmaps</span> <span class="o">*</span> <span class="n">receptive_field_size</span>
    <span class="k">return</span> <span class="n">fan_in</span><span class="p">,</span> <span class="n">fan_out</span>


<span class="k">def</span> <span class="nf">_calculate_correct_fan</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">valid_modes</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;fan_in&#39;</span><span class="p">,</span> <span class="s1">&#39;fan_out&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_modes</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Mode </span><span class="si">{}</span><span class="s2"> not supported, please use one of </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">valid_modes</span><span class="p">))</span>
    <span class="n">fan_in</span><span class="p">,</span> <span class="n">fan_out</span> <span class="o">=</span> <span class="n">_calculate_fan_in_and_fan_out</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fan_in</span> <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;fan_in&#39;</span> <span class="k">else</span> <span class="n">fan_out</span>


<span class="k">def</span> <span class="nf">kaiming_normal</span><span class="p">(</span><span class="n">inputs_shape</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fan_in&#39;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;leaky_relu&#39;</span><span class="p">):</span>
    <span class="n">fan</span> <span class="o">=</span> <span class="n">_calculate_correct_fan</span><span class="p">(</span><span class="n">inputs_shape</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
    <span class="n">gain</span> <span class="o">=</span> <span class="n">calculate_gain</span><span class="p">(</span><span class="n">nonlinearity</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">gain</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fan</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">inputs_shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<p>重新开发卷积核为 3x3 和 1x1 的卷积算子：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># conv3x3 and conv1x1</span>
<span class="k">def</span> <span class="nf">_conv3x3</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>  
    <span class="n">weight_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="c1"># unlike pytorch, weight initialization is introduced when define conv2d</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">kaiming_normal</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;fan_out&quot;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">weight</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_conv1x1</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># unlike pytorch, weight initialization is introduced when define conv2d</span>
    <span class="n">weight_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">kaiming_normal</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;fan_out&quot;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
                     <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">weight</span><span class="p">)</span>
</pre></div>
</div>
<p>重新开发 BasicBlock 和 BottleNeck：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BasicBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">in_channel</span><span class="p">,</span>
                 <span class="n">out_channel</span><span class="p">,</span>
                 <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BasicBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">_conv3x3</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1d</span> <span class="o">=</span> <span class="n">_bn</span><span class="p">(</span><span class="n">out_channel</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">_conv3x3</span><span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2d</span> <span class="o">=</span> <span class="n">_bn</span><span class="p">(</span><span class="n">out_channel</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">in_channel</span> <span class="o">!=</span> <span class="n">out_channel</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span><span class="n">_conv1x1</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="p">,),</span> <span class="n">_bn</span><span class="p">(</span><span class="n">out_channel</span><span class="p">)])</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">identity</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1d</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2d</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span><span class="p">:</span>
            <span class="n">identity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span><span class="p">(</span><span class="n">identity</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span> <span class="o">+</span> <span class="n">identity</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>


<span class="k">class</span> <span class="nc">BottleNeck</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="n">expansion</span> <span class="o">=</span> <span class="mi">4</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">in_channel</span><span class="p">,</span>
                 <span class="n">out_channel</span><span class="p">,</span>
                 <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BottleNeck</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="n">channel</span> <span class="o">=</span> <span class="n">out_channel</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">expansion</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">_conv1x1</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">_bn</span><span class="p">(</span><span class="n">channel</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">_conv3x3</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="n">channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">_bn</span><span class="p">(</span><span class="n">channel</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">_conv1x1</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span> <span class="o">=</span> <span class="n">_bn_last</span><span class="p">(</span><span class="n">out_channel</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">in_channel</span> <span class="o">!=</span> <span class="n">out_channel</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span><span class="n">_conv1x1</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span> <span class="n">_bn</span><span class="p">(</span><span class="n">out_channel</span><span class="p">)])</span>
    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">identity</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample</span><span class="p">:</span>
            <span class="n">identity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_sample_layer</span><span class="p">(</span><span class="n">identity</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span> <span class="o">+</span> <span class="n">identity</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
<p>重新开发 ResNet 系列整网：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ResNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">block</span><span class="p">,</span>
                 <span class="n">layer_nums</span><span class="p">,</span>
                 <span class="n">in_channels</span><span class="p">,</span>
                 <span class="n">out_channels</span><span class="p">,</span>
                 <span class="n">strides</span><span class="p">,</span>
                 <span class="n">num_classes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ResNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_nums</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_channels</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_channels</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;the length of layer_num, in_channels, out_channels list must be 4!&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">_conv7x7</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">_bn</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maxpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="n">block</span><span class="p">,</span>
                                       <span class="n">layer_nums</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                       <span class="n">in_channel</span><span class="o">=</span><span class="n">in_channels</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                       <span class="n">out_channel</span><span class="o">=</span><span class="n">out_channels</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                       <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="n">block</span><span class="p">,</span>
                                       <span class="n">layer_nums</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                       <span class="n">in_channel</span><span class="o">=</span><span class="n">in_channels</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                       <span class="n">out_channel</span><span class="o">=</span><span class="n">out_channels</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                       <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="n">block</span><span class="p">,</span>
                                       <span class="n">layer_nums</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                                       <span class="n">in_channel</span><span class="o">=</span><span class="n">in_channels</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                                       <span class="n">out_channel</span><span class="o">=</span><span class="n">out_channels</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                                       <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="n">block</span><span class="p">,</span>
                                       <span class="n">layer_nums</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                                       <span class="n">in_channel</span><span class="o">=</span><span class="n">in_channels</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                                       <span class="n">out_channel</span><span class="o">=</span><span class="n">out_channels</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                                       <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">(</span><span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end_point</span> <span class="o">=</span> <span class="n">_fc</span><span class="p">(</span><span class="n">out_channels</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_make_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="n">layer_num</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">resnet_block</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">)</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">resnet_block</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">layer_num</span><span class="p">):</span>
            <span class="n">resnet_block</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">resnet_block</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">c1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxpool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">c2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">c1</span><span class="p">)</span>
        <span class="n">c3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">c2</span><span class="p">)</span>
        <span class="n">c4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer3</span><span class="p">(</span><span class="n">c3</span><span class="p">)</span>
        <span class="n">c5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer4</span><span class="p">(</span><span class="n">c4</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">c5</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_point</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
<p>传入 ResNet50 层数信息，构造 ResNet50 整网：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">resnet50</span><span class="p">(</span><span class="n">class_num</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">ResNet</span><span class="p">(</span><span class="n">ResidualBlock</span><span class="p">,</span>
                  <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">2048</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="n">class_num</span><span class="p">)</span>
</pre></div>
</div>
<p>经过以上步骤，基于 MindSpore 的 ResNet50 整网结构和各子网结构已经开发完成，接下来就是开发其他模块。</p>
</section>
</section>
<section id="id12">
<h3>其他模块<a class="headerlink" href="#id12" title="Permalink to this headline"></a></h3>
<p>其他模块通常包括：反向构造、梯度裁剪、优化器、学习率生成等，这些模块要么本身结构单一，要么依赖已开发完成的子网结果才能和对标脚本形成对比。相比子网开发，这些模块的脚本开发难度更小一些。</p>
<section id="id13">
<h4>ResNet50 迁移示例<a class="headerlink" href="#id13" title="Permalink to this headline"></a></h4>
<p>关于其他训练配置，可以参考 <a class="reference external" href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/resnet50v1.5#default-configuration">英伟达训练 ResNet50 的配置信息</a>，ResNet50 的训练主要涉及以下几项：</p>
<ul class="simple">
<li><p>使用了 SGD + Momentum 优化器</p></li>
<li><p>使用了 WeightDecay 功能（但 BatchNorm 的 gamma 和 bias 没有使用）</p></li>
<li><p>使用了 cosine LR schedule</p></li>
<li><p>使用了 Label Smoothing</p></li>
</ul>
<p>实现 cosine LR schedule：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_generate_cosine_lr</span><span class="p">(</span><span class="n">lr_init</span><span class="p">,</span> <span class="n">lr_end</span><span class="p">,</span> <span class="n">lr_max</span><span class="p">,</span> <span class="n">total_steps</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies cosine decay to generate learning rate array.</span>

<span class="sd">    Args:</span>
<span class="sd">       lr_init(float): init learning rate.</span>
<span class="sd">       lr_end(float): end learning rate</span>
<span class="sd">       lr_max(float): max learning rate.</span>
<span class="sd">       total_steps(int): all steps in training.</span>
<span class="sd">       warmup_steps(int): all steps in warmup epochs.</span>

<span class="sd">    Returns:</span>
<span class="sd">       np.array, learning rate array.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">decay_steps</span> <span class="o">=</span> <span class="n">total_steps</span> <span class="o">-</span> <span class="n">warmup_steps</span>
    <span class="n">lr_each_step</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_steps</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">warmup_steps</span><span class="p">:</span>
            <span class="n">lr_inc</span> <span class="o">=</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">lr_max</span><span class="p">)</span> <span class="o">-</span> <span class="nb">float</span><span class="p">(</span><span class="n">lr_init</span><span class="p">))</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">warmup_steps</span><span class="p">)</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">lr_init</span><span class="p">)</span> <span class="o">+</span> <span class="n">lr_inc</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">linear_decay</span> <span class="o">=</span> <span class="p">(</span><span class="n">total_steps</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span> <span class="o">/</span> <span class="n">decay_steps</span>
            <span class="n">cosine_decay</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="mf">0.47</span> <span class="o">*</span> <span class="n">i</span> <span class="o">/</span> <span class="n">decay_steps</span><span class="p">))</span>
            <span class="n">decayed</span> <span class="o">=</span> <span class="n">linear_decay</span> <span class="o">*</span> <span class="n">cosine_decay</span> <span class="o">+</span> <span class="mf">0.00001</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">lr_max</span> <span class="o">*</span> <span class="n">decayed</span>
        <span class="n">lr_each_step</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lr_each_step</span>
</pre></div>
</div>
<p>实现带 Momentum 的 SGD 优化器，除 BN 的 gamma 和 bias 外，其他权重应用 WeightDecay ：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.nn.optim</span> <span class="kn">import</span> <span class="n">Momentum</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="n">class_num</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">_generate_cosine_lr</span><span class="p">()</span>
<span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.875</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">32768</span>

<span class="n">decayed_params</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">no_decayed_params</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">():</span>
    <span class="k">if</span> <span class="s1">&#39;beta&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span> <span class="ow">and</span> <span class="s1">&#39;gamma&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span> <span class="ow">and</span> <span class="s1">&#39;bias&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
        <span class="n">decayed_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">no_decayed_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>

<span class="n">group_params</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">decayed_params</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="n">weight_decay</span><span class="p">},</span>
                <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">no_decayed_params</span><span class="p">},</span>
                <span class="p">{</span><span class="s1">&#39;order_params&#39;</span><span class="p">:</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()}]</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">group_params</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="p">)</span>
</pre></div>
</div>
<p>定义 Loss 函数和实现 Label Smoothing：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore.common</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">LossBase</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>


<span class="c1"># define cross entropy loss</span>
<span class="k">class</span> <span class="nc">CrossEntropySmooth</span><span class="p">(</span><span class="n">LossBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;CrossEntropy&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">smooth_factor</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CrossEntropySmooth</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">onehot</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">OneHot</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span> <span class="o">=</span> <span class="n">sparse</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">smooth_factor</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">smooth_factor</span> <span class="o">/</span> <span class="p">(</span><span class="n">num_classes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ce</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logit</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span><span class="p">:</span>
            <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">onehot</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">logit</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">off_value</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ce</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

<span class="c1"># define loss with label smooth</span>
<span class="n">label_smooth_factor</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">CrossEntropySmooth</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span><span class="n">smooth_factor</span><span class="o">=</span><span class="n">label_smooth_factor</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="id14">
<h3>超参对比<a class="headerlink" href="#id14" title="Permalink to this headline"></a></h3>
<p>当各子网已经打通，最后一步要做的是和对标脚本对齐超参，保证网络结构一致。需要注意的是，在不同的框架上，同一套超参可能有不同的精度表现，在迁移网络时不一定要严格按照对标脚本的超参进行设置，可在不改变网络结构的情况下进行微调。</p>
<section id="id15">
<h4>ResNet50 迁移示例<a class="headerlink" href="#id15" title="Permalink to this headline"></a></h4>
<p>在 ResNet50 的训练中，主要涉及以下超参：</p>
<ul class="simple">
<li><p>momentum =0.875</p></li>
<li><p>batch_size = 256</p></li>
<li><p>learning rate = 0.256</p></li>
<li><p>learing rate schedule = cosine</p></li>
<li><p>weight_decay = 1/32768</p></li>
<li><p>label_smooth = 0.1</p></li>
<li><p>epoch size = 90</p></li>
</ul>
</section>
</section>
</section>
<section id="id16">
<h2>流程打通<a class="headerlink" href="#id16" title="Permalink to this headline"></a></h2>
<p>经过以上步骤后，我们已经开发完了网络迁移的必备脚本，接下来就是打通单机训练、分布式训练、推理流程。</p>
<section id="id17">
<h3>单机训练<a class="headerlink" href="#id17" title="Permalink to this headline"></a></h3>
<section id="id18">
<h4>ResNet50 迁移示例<a class="headerlink" href="#id18" title="Permalink to this headline"></a></h4>
<p>为了更好的阅读代码，建议按照以下结构组织脚本：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>.
└──resnet
  ├── README.md
  ├── scripts
    ├── run_distribute_train.sh            # 启动Ascend分布式训练（8卡）
    ├── run_eval.sh                        # 启动Ascend评估
    ├── run_standalone_train.sh            # 启动Ascend单机训练（单卡）
  ├── src
    ├── resnet18_cifar10_config.yaml         # resnet18_cifar10参数配置
    ├── resnet18_imagenet2012_config.yaml    # resnet18_imagenet2012参数配置
    ├── resnet34_imagenet2012_config.yaml    # resnet34_imagenet2012参数配置
    ├── resnet50_cifar10_config.yaml         # resnet50_cifar10参数配置
    ├── resnet50_imagenet2012_Ascend_config.yaml # resnet50_imagenet2012参数配置
    ├── resnet50_imagenet2012_config.yaml    # resnet50_imagenet2012参数配置
    ├── resnet50_imagenet2012_GPU_config.yaml # resnet50_imagenet2012参数配置
    ├── resnet101_imagenet2012_config.yaml   # resnet101_imagenet2012参数配置
    ├── se-resnet50_imagenet2012_config.yaml # se-resnet50_imagenet2012参数配置
    ├── dataset.py                         # 数据预处理
    ├── CrossEntropySmooth.py              # ImageNet2012数据集的损失定义
    ├── lr_generator.py                    # 生成每个步骤的学习率
    └── resnet.py                          # ResNet骨干网络
  ├── eval.py                              # 评估网络
  └── train.py                             # 训练网络
</pre></div>
</div>
<p>其中 train.py 定义如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">ast</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore.nn.optim</span> <span class="kn">import</span> <span class="n">Momentum</span>
<span class="kn">from</span> <span class="nn">mindspore.train.model</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">CheckpointConfig</span><span class="p">,</span> <span class="n">LossMonitor</span><span class="p">,</span> <span class="n">TimeMonitor</span>
<span class="kn">from</span> <span class="nn">mindspore.train.loss_scale_manager</span> <span class="kn">import</span> <span class="n">FixedLossScaleManager</span>
<span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>
<span class="kn">from</span> <span class="nn">mindspore.communication.management</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span><span class="p">,</span> <span class="n">get_group_size</span>
<span class="kn">from</span> <span class="nn">mindspore.common</span> <span class="kn">import</span> <span class="n">set_seed</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.common.initializer</span> <span class="k">as</span> <span class="nn">weight_init</span>
<span class="kn">from</span> <span class="nn">src.lr_generator</span> <span class="kn">import</span> <span class="n">get_lr</span>
<span class="kn">from</span> <span class="nn">src.CrossEntropySmooth</span> <span class="kn">import</span> <span class="n">CrossEntropySmooth</span>
<span class="kn">from</span> <span class="nn">resnet50_imagenet2012_config.yaml</span> <span class="kn">import</span> <span class="n">config</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">src.resnet</span> <span class="kn">import</span> <span class="n">resnet50</span> <span class="k">as</span> <span class="n">resnet</span>
<span class="kn">from</span> <span class="nn">src.dataset</span> <span class="kn">import</span> <span class="n">create_dataset</span> <span class="k">as</span> <span class="n">create_dataset</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">ckpt_save_dir</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">checkpoint_path</span>

    <span class="c1"># init context</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">save_graphs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># create dataset</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="n">do_train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">repeat_num</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                             <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">step_size</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>

    <span class="c1"># define net</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">class_num</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">class_num</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">cell</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
           <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">weight_init</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="n">weight_init</span><span class="o">.</span><span class="n">XavierUniform</span><span class="p">(),</span>
                                                        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                                                        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">):</span>
           <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">weight_init</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="n">weight_init</span><span class="o">.</span><span class="n">TruncatedNormal</span><span class="p">(),</span>
                                                        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                                                        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">get_lr</span><span class="p">(</span><span class="n">lr_init</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_init</span><span class="p">,</span> <span class="n">lr_end</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_end</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_max</span><span class="p">,</span>
                <span class="n">warmup_epochs</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">warmup_epochs</span><span class="p">,</span> <span class="n">total_epochs</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">epoch_size</span><span class="p">,</span>
                <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">step_size</span><span class="p">,</span> <span class="n">lr_decay_mode</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_decay_mode</span><span class="p">)</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

    <span class="c1"># define opt</span>
    <span class="n">decayed_params</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">no_decayed_params</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">():</span>
        <span class="k">if</span> <span class="s1">&#39;beta&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span> <span class="ow">and</span> <span class="s1">&#39;gamma&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span> <span class="ow">and</span> <span class="s1">&#39;bias&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
            <span class="n">decayed_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">no_decayed_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>

    <span class="n">group_params</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">decayed_params</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="n">config</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">},</span>
                    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">no_decayed_params</span><span class="p">},</span>
                    <span class="p">{</span><span class="s1">&#39;order_params&#39;</span><span class="p">:</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()}]</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">(</span><span class="n">group_params</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">)</span>
    <span class="c1"># define loss, model</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">CrossEntropySmooth</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="n">smooth_factor</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">label_smooth_factor</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">class_num</span><span class="p">)</span>
    <span class="n">loss_scale</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">drop_overflow_update</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">},</span>
                  <span class="n">amp_level</span><span class="o">=</span><span class="s2">&quot;O2&quot;</span><span class="p">,</span> <span class="n">keep_batchnorm_fp32</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># define callbacks</span>
    <span class="n">time_cb</span> <span class="o">=</span> <span class="n">TimeMonitor</span><span class="p">(</span><span class="n">data_size</span><span class="o">=</span><span class="n">step_size</span><span class="p">)</span>
    <span class="n">loss_cb</span> <span class="o">=</span> <span class="n">LossMonitor</span><span class="p">()</span>
    <span class="n">cb</span> <span class="o">=</span> <span class="p">[</span><span class="n">time_cb</span><span class="p">,</span> <span class="n">loss_cb</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">:</span>
        <span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">save_checkpoint_epochs</span> <span class="o">*</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">keep_checkpoint_max</span><span class="p">)</span>
        <span class="n">ckpt_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;resnet&quot;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="n">ckpt_save_dir</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
        <span class="n">cb</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ckpt_cb</span><span class="p">]</span>

    <span class="c1"># train model</span>
    <span class="n">dataset_sink_mode</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">epoch_size</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">cb</span><span class="p">,</span> <span class="n">sink_size</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">(),</span>
                <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="n">dataset_sink_mode</span><span class="p">)</span>
</pre></div>
</div>
<p>注意：关于目录中其他文件的代码，可以参考 MindSpore model_zoo 的 <a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.3/model_zoo/official/cv/resnet">ResNet50 实现</a>（该脚本融合了其他 ResNet 系列网络及ResNet-SE 网络，具体实现可能和对标脚本有差异）。</p>
</section>
</section>
<section id="id19">
<h3>分布式训练<a class="headerlink" href="#id19" title="Permalink to this headline"></a></h3>
<p>分布式训练相比单机训练对网络结构没有影响，可以通过调用 MindSpore 提供的分布式训练接口改造单机脚本即可完成分布式训练，具体可参考 <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.3/distributed_training.html">分布式训练教程</a>。</p>
<section id="id20">
<h4>ResNet50 迁移示例<a class="headerlink" href="#id20" title="Permalink to this headline"></a></h4>
<p>对单机训练脚本添加以下接口：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">ast</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore.communication.management</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span><span class="p">,</span> <span class="n">get_group_size</span>
<span class="kn">from</span> <span class="nn">resnet50_imagenet2012_config.yaml</span> <span class="kn">import</span> <span class="n">config</span>

<span class="c1"># ...</span>
<span class="n">device_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;DEVICE_ID&#39;</span><span class="p">))</span> <span class="c1"># get the current device id</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_id</span><span class="o">=</span><span class="n">device_id</span><span class="p">)</span>
<span class="c1"># enable distribute training</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">device_num</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">device_num</span><span class="p">,</span>
                                  <span class="n">parallel_mode</span><span class="o">=</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">DATA_PARALLEL</span><span class="p">,</span> <span class="n">gradients_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># init distribute training</span>
<span class="n">init</span><span class="p">()</span>
</pre></div>
</div>
<p>修改 create_dataset 接口，使数据加载时对数据进行 shard 操作以支持分布式训练：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">from</span> <span class="nn">mindspore.communication.management</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span><span class="p">,</span> <span class="n">get_group_size</span>
<span class="c1"># ....</span>
<span class="n">device_num</span><span class="p">,</span> <span class="n">rank_id</span> <span class="o">=</span> <span class="n">_get_rank_info</span><span class="p">()</span>
<span class="k">if</span> <span class="n">device_num</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="c1"># standalone training</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># distribute training</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">num_shards</span><span class="o">=</span><span class="n">device_num</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="n">rank_id</span><span class="p">)</span>
<span class="c1"># ...</span>
</pre></div>
</div>
</section>
</section>
<section id="id21">
<h3>推理<a class="headerlink" href="#id21" title="Permalink to this headline"></a></h3>
<p>推理流程与训练相比有以下不同：</p>
<ul class="simple">
<li><p>无需定义loss 和 优化器</p></li>
<li><p>无需在构造数据集时进行 repeat 操作</p></li>
<li><p>网络定义后需要加载已训练好的 CheckPoint</p></li>
<li><p>定义计算推理精度的 metric</p></li>
</ul>
<section id="id22">
<h4>ResNet50 迁移示例<a class="headerlink" href="#id22" title="Permalink to this headline"></a></h4>
<p>修改后的推理脚本：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore.common</span> <span class="kn">import</span> <span class="n">set_seed</span>
<span class="kn">from</span> <span class="nn">mindspore.train.model</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">mindspore.train.serialization</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">src.resnet</span> <span class="kn">import</span> <span class="n">resnet50</span> <span class="k">as</span> <span class="n">resnet</span>
<span class="kn">from</span> <span class="nn">src.dataset</span> <span class="kn">import</span> <span class="n">create_dataset</span>
<span class="kn">from</span> <span class="nn">resnet50_imagenet2012_config.yaml</span> <span class="kn">import</span> <span class="n">config</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">device_target</span>

    <span class="c1"># init context</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">save_graphs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">device_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;DEVICE_ID&#39;</span><span class="p">))</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_id</span><span class="o">=</span><span class="n">device_id</span><span class="p">)</span>

    <span class="c1"># create dataset</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="n">do_train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">step_size</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_dataset_size</span><span class="p">()</span>

    <span class="c1"># define net</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">class_num</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">class_num</span><span class="p">)</span>

    <span class="c1"># load checkpoint</span>
    <span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">checkpoint_path</span><span class="p">)</span>
    <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">set_train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># define model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;top_1_accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;top_5_accuracy&#39;</span><span class="p">})</span>

    <span class="c1"># eval model</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;result:&quot;</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="s2">&quot;ckpt=&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">checkpoint_path</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="id23">
<h3>问题定位<a class="headerlink" href="#id23" title="Permalink to this headline"></a></h3>
<p>在流程打通中可能会遇到一些中断训练的问题，可以参考 <a class="reference external" href="https://www.mindspore.cn/docs/migration_guide/zh-CN/r1.3/neural_network_debug.html">网络训练调试教程</a> 定位和解决。</p>
</section>
</section>
<section id="id24">
<h2>精度调优<a class="headerlink" href="#id24" title="Permalink to this headline"></a></h2>
<p>在打通流程后，就可以通过训练和推理两个步骤获得网络训练的精度。通常情况下，我们很难一次就复现对标脚本的精度，需要通过精度调优来逐渐提高精度，精度调优相比性能调优不够直观，效率低，工作量大。</p>
</section>
<section id="id25">
<h2>性能调优<a class="headerlink" href="#id25" title="Permalink to this headline"></a></h2>
<p>通常我们所指的性能调优是在固定数据集、网络规模和硬件数量的情况下提高训练性能，而通过改变数据集大小、网络规模、硬件数量来提高性能是显然的，不在本文的讨论范围内。</p>
<p>除非性能问题已严重阻碍了精度调试，否则性能调优一定要放在精度达标以后进行，这其中主要有两个原因：一是在定位精度问题时很多修改会影响性能，使得已经调优过的性能再次未达标，可能浪费工作量；二是性能调优时有可能引入新的精度问题，如果没有已经达标的精度作为看护，后面再定位这次引入的精度问题难度会极大的增加。</p>
<section id="profiling">
<h3>分析Profiling数据<a class="headerlink" href="#profiling" title="Permalink to this headline"></a></h3>
<p>分析Profiling数据是性能调优阶段必不可少的步骤，MindSpore 的性能和精度调优工具 <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.3/index.html">MindInsight</a> 提供了丰富的性能和精度调优方法，对于性能调优，最重要的信息就是Profiling数据。Profiling可以收集整网训练过程中端到端的详细性能数据，包含数据准备和迭代轨迹。在迭代轨迹中，你可以看到每个算子的起始运行时间、结束运行时间、调用次数和调用顺序等非常详细的信息，这对我们性能调优非常有帮助。生成Profiling数据的方式如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.profiler</span> <span class="kn">import</span> <span class="n">Profiler</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">context</span>

<span class="c1"># init context</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">,</span> <span class="n">device_id</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;DEVICE_ID&quot;</span><span class="p">]))</span>

<span class="c1"># init profiler, profiling data will be stored under folder ./data by default</span>
<span class="n">profiler</span> <span class="o">=</span> <span class="n">Profiler</span><span class="p">()</span>

<span class="c1"># start training</span>
<span class="n">Model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="c1"># end training，parse profiling data to readable text</span>
<span class="n">profiler</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
</pre></div>
</div>
<p>关于Profiling更详细的使用方法，可以参考 <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.3/performance_profiling.html">Profiling 性能分析方法</a>。</p>
<p>获取到 Profiling 数据后，我们可以分析出性能瓶颈阶段和算子，然后进行性能优化，可以参考 <a class="reference external" href="https://www.mindspore.cn/docs/migration_guide/zh-CN/r1.3/performance_optimization.html">性能调优指导</a>。</p>
</section>
<section id="id26">
<h3>常见问题及相应优化方法<a class="headerlink" href="#id26" title="Permalink to this headline"></a></h3>
<section id="minddata">
<h4>MindData 性能问题<a class="headerlink" href="#minddata" title="Permalink to this headline"></a></h4>
<p>单Step性能抖动、数据队列一段时间内持续为空的情况都是由于数据预处理部分性能较差，使得数据处理速度跟不上单Step迭代速度导致，这两个现象通常成对出现。</p>
<p>当数据处理速度较慢时，队列从最开始的满队列情况逐渐消耗为空队列，训练进程会开始等待空队列填入数据，一旦有新的数据填入，网络才会继续进行单Step训练。由于数据处理没有队列作为缓冲，数据处理的性能抖动直接体现在单Step的性能上，因此还会造成单Step性能抖动。</p>
</section>
<section id="id27">
<h4>多机同步性能问题<a class="headerlink" href="#id27" title="Permalink to this headline"></a></h4>
<p>当进行分布式训练时，在一个Step的训练过程中，完成前向传播和梯度计算后，各个机器开始进行AllReduce梯度同步，AllReduce同步时间主要受权重数量、机器数量影响，对于越复杂、机器规模越大的网络，其 AllReduce 梯度更新时间也越久，此时我们可以进行AllReduce 切分来优化这部分耗时。</p>
<p>正常情况下，AllReduce 梯度同步会等所有反向算子执行结束，也就是对所有权重都计算出梯度后再一次性同步所有机器的梯度，而使用AllReduce切分后，我们可以在计算出一部分权重的梯度后，就立刻进行这部分权重的梯度同步，这样梯度同步和剩余算子的梯度计算可以并行执行，也就隐藏了这部分 AllReduce 梯度同步时间。切分策略通常是手动尝试，寻找一个最优的方案（支持切分大于两段）。
以 <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.3/model_zoo/official/cv/resnet/train.py">ResNet50网络</a> 为例，该网络共有 160  个 权重，  [85, 160] 表示第 0 至 85个权重计算完梯度后立刻进行梯度同步，第 86 至 160 个 权重计算完后再进行梯度同步，这里共切分两段，因此需要进行两次梯度同步。代码实现如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">resnet50_imagenet2012_config.yaml</span> <span class="kn">import</span> <span class="n">config</span>
<span class="o">...</span>

<span class="n">device_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;DEVICE_ID&#39;</span><span class="p">))</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_id</span><span class="o">=</span><span class="n">device_id</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">device_num</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">device_num</span><span class="p">,</span>
                                  <span class="n">parallel_mode</span><span class="o">=</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">DATA_PARALLEL</span><span class="p">,</span> <span class="n">gradients_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">set_algo_parameters</span><span class="p">(</span><span class="n">elementwise_op_strategy_follow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">net_name</span> <span class="o">==</span> <span class="s2">&quot;resnet50&quot;</span> <span class="ow">or</span> <span class="n">config</span><span class="o">.</span><span class="n">net_name</span> <span class="o">==</span> <span class="s2">&quot;se-resnet50&quot;</span><span class="p">:</span>
    <span class="c1"># AllReduce split</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">all_reduce_fusion_config</span><span class="o">=</span><span class="p">[</span><span class="mi">85</span><span class="p">,</span> <span class="mi">160</span><span class="p">])</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># Another split stratety</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">all_reduce_fusion_config</span><span class="o">=</span><span class="p">[</span><span class="mi">180</span><span class="p">,</span> <span class="mi">313</span><span class="p">])</span>
<span class="n">init</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="id28">
<h4>算子性能问题<a class="headerlink" href="#id28" title="Permalink to this headline"></a></h4>
<p>单算子耗时久、对于同一种算子在不同shape或者不同 datatype 下性能差异较大的情况主要是由算子性能问题引起，通常有以下两个解决思路：</p>
<ol class="arabic simple">
<li><p>使用计算量更小的数据类型。例如，同一个算子在 float16 和 float32 下精度无明显差别，可使用计算量更小的 float16 格式。</p></li>
<li><p>使用算法相同的其他算子规避。</p></li>
</ol>
<p>如果您发现有性能较差的算子时，建议联系 <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues">MindSpore社区</a> 反馈，我们确认为性能问题后会及时优化。</p>
</section>
<section id="id29">
<h4>框架性能问题<a class="headerlink" href="#id29" title="Permalink to this headline"></a></h4>
<p>转换算子过多（TransData、Cast类算子）且耗时明显时，如果是我们手动加入的Cast算子，可分析其必要性，如果对精度没有影响，可去掉冗余的Cast、TransData算子。</p>
<p>如果是MindSpore自动生成的转换算子过多，可能是MindSpore框架针对某些特殊情况没有充分优化，可联系 <a class="reference external" href="https://gitee.com/mindspore/mindspore/issues">MindSpore社区</a> 反馈。</p>
</section>
<section id="id30">
<h4>其他通用优化方法<a class="headerlink" href="#id30" title="Permalink to this headline"></a></h4>
<ul>
<li><p>使用自动混合精度</p>
<p>混合精度训练方法是通过混合使用单精度和半精度数据格式来加速深度神经网络训练的过程，同时保持了单精度训练所能达到的网络精度。混合精度训练能够加速计算过程，同时减少内存使用和存取，并使得在特定的硬件上可以训练更大的模型或 batch size。</p>
<p>具体可参考 <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.3/enable_mixed_precision.html">混合精度教程</a>。</p>
</li>
<li><p>使能图算融合</p>
<p>图算融合是 MindSpore 特有的网络性能优化技术。它可以通过自动分析和优化现有网络计算图逻辑，并结合目标硬件能力，对计算图进行计算化简和替代、算子拆分和融合、算子特例化编译等优化，以提升设备计算资源利用率，实现对网络性能的整体优化。相比传统优化技术，图算融合具有多算子跨边界联合优化、与算子编译跨层协同、基于Polyhedral的算子即时编译等独特优势。另外，图算融合只需要用户打开对应配置后，整个优化过程即可自动完成，不需要网络开发人员进行其它额外感知，使得用户可以聚焦网络算法实现。</p>
<p>图算融合的适用场景包括：对网络执行时间具有较高性能要求的场景；通过拼接基本算子实现自定义组合算子，并希望对这些基本算子进行自动融合，以提升自定义组合算子性能的场景。</p>
<p>具体可参考 <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.3/enable_graph_kernel_fusion.html">图算融合教程</a>。</p>
</li>
</ul>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="inference.html" class="btn btn-neutral float-left" title="推理执行" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="faq.html" class="btn btn-neutral float-right" title="常见问题" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>