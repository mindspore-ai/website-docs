<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Evaluating the Model during Training &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Incremental Operator Build" href="incremental_operator_build.html" />
    <link rel="prev" title="Custom Debugging Information" href="custom_debugging_info.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Overall Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quick_start/linear_regression.html">Implementing Simple Linear Function Fitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start/quick_video.html">Hands-on Installation and Experience</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dtype.html">dtype</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="cell.html">Cell</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Numpy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">NumPy Interfaces in MindSpore</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Execution Management</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="context.html">Configuring Running Information</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Pipeline</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataset_sample.html">Quick Start of Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Processing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_advanced.html">Advanced Usage of Pipeline</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build the Network</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="initializer.html">Initialization of Network Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter.html">Updating Network Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="layer.html">Model Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="loss.html">Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">Optimization Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_net.html">Building a Customized Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="network_component.html">Common Network Components</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Train Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="run.html">Running Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="callback.html">Callback Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_model.html">Saving Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="load_model_for_inference_and_transfer.html">Loading a Model for Inference and Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="train.html">Advanced Usage of Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_ascend_910.html">Inference on the Ascend 910 AI processor</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_ascend_310.html">Inference on Ascend 310</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_gpu.html">Inference on a GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_cpu.html">Inference on a CPU</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">Distributed Training Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_ascend.html">Parallel Distributed Training (Ascend)</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_gpu.html">Distributed Parallel Training (GPU)</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_pipeline_parallel.html">Pipeline Parallelism Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_host_device_training.html">Applying Host&amp;Device Hybrid Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_parameter_server_training.html">Training with Parameter Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_load_model_hybrid_parallel.html">Saving and Loading Models in Hybrid Parallel Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_inference.html">Distributed Inference With Multi Devices</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_parallel.html">Parallel Distributed Training Interfaces</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Function Debugging</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Evaluating the Model during Training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#defining-the-callback-function-evalcallback">Defining the Callback Function EvalCallBack</a></li>
<li class="toctree-l2"><a class="reference internal" href="#defining-and-executing-the-training-network">Defining and Executing the Training Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="#defining-the-function-to-obtain-the-model-accuracy-in-different-epochs">Defining the Function to Obtain the Model Accuracy in Different Epochs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="optimize_data_processing.html">Optimizing the Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Applying a Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_post_training_quantization.html">Applying Post Training Quantization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Evaluating the Model during Training</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/evaluate_the_model_during_training.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="evaluating-the-model-during-training">
<h1>Evaluating the Model during Training<a class="headerlink" href="#evaluating-the-model-during-training" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Export</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Training</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.3/docs/mindspore/programming_guide/source_en/evaluate_the_model_during_training.md"><img alt="View Source On Gitee" src="https://gitee.com/mindspore/docs/raw/r1.3/resource/_static/logo_source.png" /></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>For a complex network, epoch training usually needs to be performed for dozens or even hundreds of times. Before training, it is difficult to know when a model can achieve required accuracy in epoch training. Therefore, the accuracy of the model is usually validated at a fixed epoch interval during training and the corresponding model is saved. After the training is completed, you can quickly select the optimal model by viewing the change of the corresponding model accuracy. This section uses this method and takes the LeNet network as an example.</p>
<p>The procedure is as follows:</p>
<ol class="arabic simple">
<li><p>Define the callback function EvalCallBack to implement synchronous training and validation.</p></li>
<li><p>Define a training network and execute it.</p></li>
<li><p>Draw a line chart based on the model accuracy under different epochs and select the optimal model.</p></li>
</ol>
<p>Source code address of this example: <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.3/docs/sample_code/evaluate_the_model_during_training/evaluate_the_model_during_training.py">https://gitee.com/mindspore/docs/blob/r1.3/docs/sample_code/evaluate_the_model_during_training/evaluate_the_model_during_training.py</a>.</p>
</section>
<section id="defining-the-callback-function-evalcallback">
<h2>Defining the Callback Function EvalCallBack<a class="headerlink" href="#defining-the-callback-function-evalcallback" title="Permalink to this headline"></a></h2>
<p>Implementation idea: The model accuracy is validated every n epochs. The model accuracy needs to be implemented in the custom callback function. For details about the usage, see <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.3/api_python/mindspore.train.html#mindspore.train.callback.Callback">API Description</a>.</p>
<p>Core implementation: Validation points are set in <code class="docutils literal notranslate"><span class="pre">epoch_end</span></code> of the callback function as follows:</p>
<p><code class="docutils literal notranslate"><span class="pre">cur_epoch</span> <span class="pre">%</span> <span class="pre">eval_per_epoch</span> <span class="pre">==</span> <span class="pre">0</span></code>: indicates that the model accuracy is validated every <code class="docutils literal notranslate"><span class="pre">eval_per_epoch</span></code> epoch.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cur_epoch</span></code>: indicates <code class="docutils literal notranslate"><span class="pre">epoch</span></code> value in the current training process.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">eval_per_epoch</span></code>: indicates user-defined value, that is, the validation frequency.</p></li>
</ul>
<p>Other parameters are described as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model</span></code>: indicates the <code class="docutils literal notranslate"><span class="pre">Model</span></code> class in MindSpore.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">eval_dataset</span></code>: indicates the validation dataset.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">epoch_per_eval</span></code>: records the accuracy of the validation model and the corresponding number of epochs. The data format is <code class="docutils literal notranslate"><span class="pre">{&quot;epoch&quot;:</span> <span class="pre">[],</span> <span class="pre">&quot;acc&quot;:</span> <span class="pre">[]}</span></code>.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">Callback</span>

<span class="k">class</span> <span class="nc">EvalCallBack</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">eval_dataset</span><span class="p">,</span> <span class="n">eval_per_epoch</span><span class="p">,</span> <span class="n">epoch_per_eval</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">eval_dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_per_epoch</span> <span class="o">=</span> <span class="n">eval_per_epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_per_eval</span> <span class="o">=</span> <span class="n">epoch_per_eval</span>

    <span class="k">def</span> <span class="nf">epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">cb_param</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">cur_epoch</span> <span class="o">=</span> <span class="n">cb_param</span><span class="o">.</span><span class="n">cur_epoch_num</span>
        <span class="k">if</span> <span class="n">cur_epoch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_per_epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">acc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">epoch_per_eval</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_epoch</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">epoch_per_eval</span><span class="p">[</span><span class="s2">&quot;acc&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc</span><span class="p">[</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">])</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span>

</pre></div>
</div>
</section>
<section id="defining-and-executing-the-training-network">
<h2>Defining and Executing the Training Network<a class="headerlink" href="#defining-and-executing-the-training-network" title="Permalink to this headline"></a></h2>
<p>In the <code class="docutils literal notranslate"><span class="pre">CheckpointConfig</span></code> parameter for saving the model, you need to calculate the number of steps in a single epoch, then set the <code class="docutils literal notranslate"><span class="pre">checkpointconfig</span></code> file according to the number of required steps to save the model weight parameter <code class="docutils literal notranslate"><span class="pre">ckpt</span></code> file. In this example, each epoch has 1875 steps. Based on the principle of validating once every two epochs, set <code class="docutils literal notranslate"><span class="pre">save_checkpoint_steps=eval_per_epoch*1875</span></code>. The variable <code class="docutils literal notranslate"><span class="pre">eval_per_epoch</span></code> is equal to 2.</p>
<p>The parameters are described as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">config_ck</span></code>: configures the information for saving the model.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">save_checkpoint_steps</span></code>: indicates the number of steps for saving the weight parameter <code class="docutils literal notranslate"><span class="pre">ckpt</span></code> file of the model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">keep_checkpoint_max</span></code>: indicates the maximum number of model’s weight parameter that can be saved.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">ckpoint_cb</span></code>: configures the prefix information of the name and path for saving the model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model</span></code>: indicates the <code class="docutils literal notranslate"><span class="pre">Model</span></code> class in MindSpore.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model.train</span></code>: indicates the <code class="docutils literal notranslate"><span class="pre">Model</span></code> class training function.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">epoch_per_eval</span></code>: defines the number for collecting <code class="docutils literal notranslate"><span class="pre">epoch</span></code> and the dictionary of corresponding model accuracy information.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train_data</span></code>: indicates the training dataset.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">eval_data</span></code>: indicates the validation dataset.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">CheckpointConfig</span><span class="p">,</span> <span class="n">LossMonitor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">mindspore.nn.metrics</span> <span class="kn">import</span> <span class="n">Accuracy</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;GPU&quot;</span><span class="p">)</span>
    <span class="n">ckpt_save_dir</span> <span class="o">=</span> <span class="s2">&quot;./lenet_ckpt&quot;</span>
    <span class="n">eval_per_epoch</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">epoch_size</span> <span class="o">=</span><span class="mi">10</span>

    <span class="o">...</span> <span class="o">...</span>

    <span class="c1"># need to calculate how many steps are in each epoch, in this example, 1875 steps per epoch.</span>
    <span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="n">eval_per_epoch</span><span class="o">*</span><span class="mi">1875</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">ckpoint_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;checkpoint_lenet&quot;</span><span class="p">,</span><span class="n">directory</span><span class="o">=</span><span class="n">ckpt_save_dir</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">net_loss</span><span class="p">,</span> <span class="n">net_opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">Accuracy</span><span class="p">()})</span>

    <span class="n">epoch_per_eval</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;acc&quot;</span><span class="p">:</span> <span class="p">[]}</span>
    <span class="n">eval_cb</span> <span class="o">=</span> <span class="n">EvalCallBack</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">eval_data</span><span class="p">,</span> <span class="n">eval_per_epoch</span><span class="p">,</span> <span class="n">epoch_per_eval</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch_size</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ckpoint_cb</span><span class="p">,</span> <span class="n">LossMonitor</span><span class="p">(</span><span class="mi">375</span><span class="p">),</span> <span class="n">eval_cb</span><span class="p">],</span>
                <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch: 1 step: 375, loss is 2.298612
epoch: 1 step: 750, loss is 2.075152
epoch: 1 step: 1125, loss is 0.39205977
epoch: 1 step: 1500, loss is 0.12368304
epoch: 1 step: 1875, loss is 0.20988345
epoch: 2 step: 375, loss is 0.20582482
epoch: 2 step: 750, loss is 0.029070046
epoch: 2 step: 1125, loss is 0.041760832
epoch: 2 step: 1500, loss is 0.067035824
epoch: 2 step: 1875, loss is 0.0050643035
{&#39;Accuracy&#39;: 0.9763621794871795}

... ...

epoch: 9 step: 375, loss is 0.021227183
epoch: 9 step: 750, loss is 0.005586236
epoch: 9 step: 1125, loss is 0.029125651
epoch: 9 step: 1500, loss is 0.00045874066
epoch: 9 step: 1875, loss is 0.023556218
epoch: 10 step: 375, loss is 0.0005807788
epoch: 10 step: 750, loss is 0.02574059
epoch: 10 step: 1125, loss is 0.108463734
epoch: 10 step: 1500, loss is 0.01950589
epoch: 10 step: 1875, loss is 0.10563098
{&#39;Accuracy&#39;: 0.979667467948718}
</pre></div>
</div>
<p>Find the <code class="docutils literal notranslate"><span class="pre">lenet_ckpt</span></code> folder in the same directory. The folder contains five models and data related to a calculation graph. The structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>lenet_ckpt
├── checkpoint_lenet-10_1875.ckpt
├── checkpoint_lenet-2_1875.ckpt
├── checkpoint_lenet-4_1875.ckpt
├── checkpoint_lenet-6_1875.ckpt
├── checkpoint_lenet-8_1875.ckpt
└── checkpoint_lenet-graph.meta
</pre></div>
</div>
</section>
<section id="defining-the-function-to-obtain-the-model-accuracy-in-different-epochs">
<h2>Defining the Function to Obtain the Model Accuracy in Different Epochs<a class="headerlink" href="#defining-the-function-to-obtain-the-model-accuracy-in-different-epochs" title="Permalink to this headline"></a></h2>
<p>Define the drawing function <code class="docutils literal notranslate"><span class="pre">eval_show</span></code>, load <code class="docutils literal notranslate"><span class="pre">epoch_per_eval</span></code> to <code class="docutils literal notranslate"><span class="pre">eval_show</span></code>, and draw the model accuracy variation chart based on different <code class="docutils literal notranslate"><span class="pre">epoch</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">eval_show</span><span class="p">(</span><span class="n">epoch_per_eval</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;epoch number&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Model accuracy&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Model accuracy variation chart&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_per_eval</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">],</span> <span class="n">epoch_per_eval</span><span class="p">[</span><span class="s2">&quot;acc&quot;</span><span class="p">],</span> <span class="s2">&quot;red&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">eval_show</span><span class="p">(</span><span class="n">epoch_per_eval</span><span class="p">)</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<p><img alt="png" src="_images/evaluate_the_model_during_training.png" /></p>
<p>You can easily select the optimal model weight parameter <code class="docutils literal notranslate"><span class="pre">ckpt</span></code> file based on the preceding figure.</p>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline"></a></h2>
<p>The MNIST dataset is used for training through the convolutional neural network LeNet5. This section describes how to validate a model during training, save the model weight parameter <code class="docutils literal notranslate"><span class="pre">ckpt</span></code> file corresponding to the <code class="docutils literal notranslate"><span class="pre">epoch</span></code>, and select the optimal model.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="custom_debugging_info.html" class="btn btn-neutral float-left" title="Custom Debugging Information" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="incremental_operator_build.html" class="btn btn-neutral float-right" title="Incremental Operator Build" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>