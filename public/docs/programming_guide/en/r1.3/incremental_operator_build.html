<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Incremental Operator Build &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Optimizing the Data Processing" href="optimize_data_processing.html" />
    <link rel="prev" title="Evaluating the Model during Training" href="evaluate_the_model_during_training.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Overall Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quick_start/linear_regression.html">Implementing Simple Linear Function Fitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start/quick_video.html">Hands-on Installation and Experience</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dtype.html">dtype</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="cell.html">Cell</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Numpy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">NumPy Interfaces in MindSpore</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Execution Management</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="context.html">Configuring Running Information</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Pipeline</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataset_sample.html">Quick Start of Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Processing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_advanced.html">Advanced Usage of Pipeline</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build the Network</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="initializer.html">Initialization of Network Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter.html">Updating Network Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="layer.html">Model Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="loss.html">Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">Optimization Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_net.html">Building a Customized Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="network_component.html">Common Network Components</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Train Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="run.html">Running Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="callback.html">Callback Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_model.html">Saving Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="load_model_for_inference_and_transfer.html">Loading a Model for Inference and Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="train.html">Advanced Usage of Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_ascend_910.html">Inference on the Ascend 910 AI processor</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_ascend_310.html">Inference on Ascend 310</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_gpu.html">Inference on a GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_cpu.html">Inference on a CPU</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">Distributed Training Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_ascend.html">Parallel Distributed Training (Ascend)</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_gpu.html">Distributed Parallel Training (GPU)</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_pipeline_parallel.html">Pipeline Parallelism Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_host_device_training.html">Applying Host&amp;Device Hybrid Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_parameter_server_training.html">Training with Parameter Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_load_model_hybrid_parallel.html">Saving and Loading Models in Hybrid Parallel Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_inference.html">Distributed Inference With Multi Devices</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_parallel.html">Parallel Distributed Training Interfaces</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Function Debugging</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluate_the_model_during_training.html">Evaluating the Model during Training</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Incremental Operator Build</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#usage">Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="#faqs">FAQs</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="optimize_data_processing.html">Optimizing the Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Applying a Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_post_training_quantization.html">Applying Post Training Quantization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Incremental Operator Build</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/incremental_operator_build.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="incremental-operator-build">
<h1>Incremental Operator Build<a class="headerlink" href="#incremental-operator-build" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Linux</span></code> <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Training</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code> <code class="docutils literal notranslate"><span class="pre">Intermediate</span></code> <code class="docutils literal notranslate"><span class="pre">Expert</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.3/docs/mindspore/programming_guide/source_en/incremental_operator_build.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.3/resource/_static/logo_source.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>When a network model is executed, MindSpore builds the used operators. The time consumed in this stage increases with the scale of the network model. To improve the performance of secondary model execution, an incremental operator build mechanism is provided. When MindSpore executes a network model, the <code class="docutils literal notranslate"><span class="pre">kernel_meta</span></code> folder is generated in the directory where the execution is performed. During the execution, operator cache files (in the <code class="docutils literal notranslate"><span class="pre">.o</span></code>, <code class="docutils literal notranslate"><span class="pre">.info</span></code>, or <code class="docutils literal notranslate"><span class="pre">.json</span></code> format) generated during network build are saved to this directory. If you execute the same network model again or only part of the model changes, MindSpore automatically calls the reusable operator cache files in the <code class="docutils literal notranslate"><span class="pre">kernel_meta</span></code> folder, which significantly reduces the network build time and improves the execution performance. Currently, the incremental operator build function can be used only on the Ascend AI chips.</p>
<p>The following demonstrates how to use the incremental operator build function.</p>
</section>
<section id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this headline"></a></h2>
<p>Incremental operator build is enabled by default on MindSpore and does not need to be controlled. The following describes how to build a simple network model case <code class="docutils literal notranslate"><span class="pre">test_square.py</span></code> in the <code class="docutils literal notranslate"><span class="pre">src</span></code> directory. The current directory structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─src
    └── test_square.py
</pre></div>
</div>
<p>Execute the following test case:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.context</span> <span class="k">as</span> <span class="nn">context</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">square</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Square</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">test_net</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">square</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">square</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x: &quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output: &quot;</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>


</pre></div>
</div>
<p>The network model consists of a single operator <code class="docutils literal notranslate"><span class="pre">Square</span></code>, and the output is a square value of the input. The command output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>x: [1. 4. 9.]
output: [1. 16. 81.]
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">kernel_meta</span></code> folder is generated in the directory where the execution is performed, which contains the <code class="docutils literal notranslate"><span class="pre">.o</span></code>, <code class="docutils literal notranslate"><span class="pre">.json</span></code>, and <code class="docutils literal notranslate"><span class="pre">.info</span></code> files of the Square operator. The current directory structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─src
    ├── test_square.py
    └── kernel_meta
        ├── Square_3307185124911971026_7.info
        ├── Square_3307185124911971026_7.json
        └── Square_3307185124911971026_7.o
</pre></div>
</div>
<p>For an operator:</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.o</span></code> file is an executable file generated by MindSpore for the operator during network model execution.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.info</span></code> file records all valid information about the operator, including the operator name, attributes, input and output formats, and input and output data types. The <code class="docutils literal notranslate"><span class="pre">.info</span></code> file is used to search for and determine whether the <code class="docutils literal notranslate"><span class="pre">.o</span></code> file of the operator can be reused. The details are as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{&quot;SocInfo&quot;:{&quot;autoTilingMode&quot;:&quot;NO_TUNE&quot;,&quot;coreNum&quot;:&quot;&quot;,&quot;coreType&quot;:&quot;&quot;,&quot;l1Fusion&quot;:&quot;false&quot;,&quot;l2Fusion&quot;:&quot;false&quot;,&quot;l2Mode&quot;:&quot;2&quot;,&quot;op_debug_level&quot;:&quot;&quot;,&quot;op_impl_mode&quot;:&quot;&quot;,&quot;op_impl_mode_list&quot;:[],&quot;socVersion&quot;:&quot;Ascend910A&quot;},&quot;impl_path&quot;:&quot;&quot;,&quot;op_info&quot;:{&quot;Type&quot;:&quot;Square&quot;,&quot;attrs&quot;:null,&quot;full_name&quot;:&quot;Default/Square-op1&quot;,&quot;gen_model&quot;:&quot;single&quot;,&quot;graph_id&quot;:0,&quot;inputs&quot;:[[{&quot;dtype&quot;:&quot;float32&quot;,&quot;format&quot;:&quot;NCHW&quot;,&quot;name&quot;:&quot;x_0&quot;,&quot;ori_format&quot;:&quot;NCHW&quot;,&quot;ori_shape&quot;:[3],&quot;param_type&quot;:&quot;required&quot;,&quot;range&quot;:[[3,3]],&quot;shape&quot;:[3],&quot;valid&quot;:true}]],&quot;is_dynamic_shape&quot;:false,&quot;kernel_name&quot;:&quot;Square_2989580383048251395_7&quot;,&quot;module_name&quot;:&quot;impl.square&quot;,&quot;name&quot;:&quot;square&quot;,&quot;outputs&quot;:[[{&quot;dtype&quot;:&quot;float32&quot;,&quot;format&quot;:&quot;NCHW&quot;,&quot;name&quot;:&quot;y&quot;,&quot;ori_format&quot;:&quot;NCHW&quot;,&quot;ori_shape&quot;:[3],&quot;param_type&quot;:&quot;required&quot;,&quot;range&quot;:[[3,3]],&quot;shape&quot;:[3],&quot;valid&quot;:true}]],&quot;py_module_path&quot;:&quot;/usr/local/Ascend/opp/op_impl/built-in/ai_core/tbe&quot;,&quot;socVersion&quot;:&quot;Ascend910A&quot;},&quot;platform&quot;:&quot;TBE&quot;}
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">.json</span></code> file stores the operator build result, which will be used during running. The details are as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{
  &quot;batchBindOnly&quot;:1,
  &quot;binFileName&quot;:&quot;Square_3307185124911971026_7&quot;,
  &quot;binFileSuffix&quot;:&quot;.o&quot;,
  &quot;blockDim&quot;:1,
  &quot;kernelName&quot;:&quot;Square_3307185124911971026_7__kernel0&quot;,
  &quot;magic&quot;:&quot;RT_DEV_BINARY_MAGIC_ELF&quot;,
  &quot;opParaSize&quot;:0,
  &quot;parameters&quot;:[
    0,
    0
  ],
  &quot;sha256&quot;:&quot;64d4963bf6b619c2d85da67611f5677e0ea11bba0413ed3620b0926b1d072a1a&quot;
}
</pre></div>
</div>
<p>After the preceding three types of operator cache files are generated, you can perform incremental operator build when executing the network model. That is, only new or modified operators are built, greatly improving the network build performance.</p>
</section>
<section id="faqs">
<h2>FAQs<a class="headerlink" href="#faqs" title="Permalink to this headline"></a></h2>
<ul>
<li><p>Cache files cannot be shared in different scenarios, such as multi-device and single-device scenarios, or training and inference scenarios.</p></li>
<li><p>When multiple devices are running, the <code class="docutils literal notranslate"><span class="pre">kernel_meta</span></code> folder is generated in multiple <code class="docutils literal notranslate"><span class="pre">device</span></code> directories when the network model is executed.</p>
<p>Note that when multiple devices are running, if the operator cache files in <code class="docutils literal notranslate"><span class="pre">kernel_meta</span></code> of some devices are deleted and the same network model is executed again, devices that do not need to be rebuilt may time out. As a result, the execution fails. In this case, you can set the environment variable <code class="docutils literal notranslate"><span class="pre">HCCL_CONNECT_TIMEOUT</span></code>, that is, the waiting time between multiple devices, to avoid failure. However, this method takes a long time, which is equivalent to deleting and rebuilding all devices.</p>
</li>
<li><p>If the process is interrupted during network build, there is a possibility that an error occurs when the cache files in <code class="docutils literal notranslate"><span class="pre">kernel_meta</span></code> are generated. As a result, the subsequent re-execution fails. In this case, you need to delete the <code class="docutils literal notranslate"><span class="pre">kernel_meta</span></code> folder and rebuild the network.</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="evaluate_the_model_during_training.html" class="btn btn-neutral float-left" title="Evaluating the Model during Training" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="optimize_data_processing.html" class="btn btn-neutral float-right" title="Optimizing the Data Processing" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>