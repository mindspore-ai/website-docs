<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Tensor &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Operators" href="operators.html" />
    <link rel="prev" title="dtype" href="dtype.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Overall Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quick_start/linear_regression.html">Implementing Simple Linear Function Fitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start/quick_start.html">Implementing an Image Classification Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start/quick_video.html">Hands-on Installation and Experience</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Concepts</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="dtype.html">dtype</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Tensor</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tensor-structure">Tensor Structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tensor-operations-attributes-and-methods">Tensor Operations, Attributes and Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#operations">Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#attributes">Attributes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#methods">Methods</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#sparse-tensor">Sparse Tensor</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#rowtensor">RowTensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sparsetensor">SparseTensor</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="operators.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="cell.html">Cell</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Numpy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">NumPy Interfaces in MindSpore</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Execution Management</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="context.html">Configuring Running Information</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Pipeline</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataset_sample.html">Quick Start of Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Processing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_advanced.html">Advanced Usage of Pipeline</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build the Network</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="initializer.html">Initialization of Network Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter.html">Updating Network Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="layer.html">Model Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="loss.html">Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">Optimization Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_net.html">Building a Customized Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="network_component.html">Common Network Components</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Train Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="run.html">Running Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="callback.html">Callback Mechanism</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_model.html">Saving Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="load_model_for_inference_and_transfer.html">Loading a Model for Inference and Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="train.html">Advanced Usage of Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_ascend_910.html">Inference on the Ascend 910 AI processor</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_ascend_310.html">Inference on Ascend 310</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_gpu.html">Inference on a GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference_cpu.html">Inference on a CPU</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">Distributed Training Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_ascend.html">Parallel Distributed Training (Ascend)</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_training_gpu.html">Distributed Parallel Training (GPU)</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_pipeline_parallel.html">Pipeline Parallelism Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_host_device_training.html">Applying Host&amp;Device Hybrid Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_parameter_server_training.html">Training with Parameter Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_load_model_hybrid_parallel.html">Saving and Loading Models in Hybrid Parallel Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_inference.html">Distributed Inference With Multi Devices</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_parallel.html">Parallel Distributed Training Interfaces</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Function Debugging</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluate_the_model_during_training.html">Evaluating the Model during Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="optimize_data_processing.html">Optimizing the Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Applying a Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_post_training_quantization.html">Applying Post Training Quantization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Tensor</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/tensor.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="tensor">
<h1>Tensor<a class="headerlink" href="#tensor" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.3/docs/mindspore/programming_guide/source_en/tensor.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.3/resource/_static/logo_source.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>Tensor is a basic data structure in the MindSpore network computing. For details about data types in tensors, see <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.3/dtype.html">dtype</a>.</p>
<p>Tensors of different dimensions represent different data. For example, a 0-dimensional tensor represents a scalar, a 1-dimensional tensor represents a vector, a 2-dimensional tensor represents a matrix, and a 3-dimensional tensor may represent the three channels of RGB images.</p>
</section>
<section id="tensor-structure">
<h2>Tensor Structure<a class="headerlink" href="#tensor-structure" title="Permalink to this headline"></a></h2>
<p>During tensor creation, the <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">int</span></code>, <code class="docutils literal notranslate"><span class="pre">bool</span></code>, <code class="docutils literal notranslate"><span class="pre">tuple</span></code>, <code class="docutils literal notranslate"><span class="pre">list</span></code>, and <code class="docutils literal notranslate"><span class="pre">NumPy.array</span></code> types can be transferred, while <code class="docutils literal notranslate"><span class="pre">tuple</span></code> and <code class="docutils literal notranslate"><span class="pre">list</span></code> can only store <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">int</span></code>, and <code class="docutils literal notranslate"><span class="pre">bool</span></code> data.</p>
<p><code class="docutils literal notranslate"><span class="pre">dtype</span></code> can be specified when <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> is initialized. When the <code class="docutils literal notranslate"><span class="pre">dtype</span></code> is not specified, if the initial value is <code class="docutils literal notranslate"><span class="pre">int</span></code>, <code class="docutils literal notranslate"><span class="pre">float</span></code> or <code class="docutils literal notranslate"><span class="pre">bool</span></code>, then a 0-dimensional <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> with data types <code class="docutils literal notranslate"><span class="pre">mindspore.int32</span></code>, <code class="docutils literal notranslate"><span class="pre">mindspore.float64</span></code> or <code class="docutils literal notranslate"><span class="pre">mindspore.bool_</span></code> will be generated respectively. If the initial values are <code class="docutils literal notranslate"><span class="pre">tuple</span></code> and <code class="docutils literal notranslate"><span class="pre">list</span></code>, the generated 1-dimensional <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> data type corresponds to the type stored in <code class="docutils literal notranslate"><span class="pre">tuple</span></code> and <code class="docutils literal notranslate"><span class="pre">list</span></code>. If it contains multiple different types of data, follow the below priority: <code class="docutils literal notranslate"><span class="pre">bool</span></code> &lt; <code class="docutils literal notranslate"><span class="pre">int</span></code> &lt; <code class="docutils literal notranslate"><span class="pre">float</span></code>, to select the mindspore data type corresponding to the highest relative priority type. If the initial value is <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>,  the consistent data type <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> is generated. If the initial value is <code class="docutils literal notranslate"><span class="pre">NumPy.array</span></code>, the corresponding data type <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> is generated.</p>
<p>A code example is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int16</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">],</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">q</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[1 2]
 [3 4]]

1

2

True

[1 2 3]

[4. 5. 6.]

[4. 5. 6.]
</pre></div>
</div>
</section>
<section id="tensor-operations-attributes-and-methods">
<h2>Tensor Operations, Attributes and Methods<a class="headerlink" href="#tensor-operations-attributes-and-methods" title="Permalink to this headline"></a></h2>
<section id="operations">
<h3>Operations<a class="headerlink" href="#operations" title="Permalink to this headline"></a></h3>
<p>Tensor supports a variety of operations, including arithmetic operations and logical operations. Some commonly used operators are as follows:</p>
<ul class="simple">
<li><p>arithmetic operations: add (<code class="docutils literal notranslate"><span class="pre">+</span></code>), subtract (<code class="docutils literal notranslate"><span class="pre">-</span></code>), multiply (<code class="docutils literal notranslate"><span class="pre">*</span></code>), divide (<code class="docutils literal notranslate"><span class="pre">/</span></code>), modulus (<code class="docutils literal notranslate"><span class="pre">%</span></code>), power (<code class="docutils literal notranslate"><span class="pre">**</span></code>), divide (<code class="docutils literal notranslate"><span class="pre">//</span></code>)</p></li>
<li><p>logical operations：equal to (<code class="docutils literal notranslate"><span class="pre">==</span></code>), not equal to (<code class="docutils literal notranslate"><span class="pre">!=</span></code>), greater than (<code class="docutils literal notranslate"><span class="pre">&gt;</span></code>), greater than or equal to (<code class="docutils literal notranslate"><span class="pre">&gt;=</span></code>), less than (<code class="docutils literal notranslate"><span class="pre">&lt;</span></code>), less than or equal to (<code class="docutils literal notranslate"><span class="pre">&lt;=</span></code>)</p></li>
</ul>
<p>A code example is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">output_add</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="n">output_sub</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">y</span>
<span class="n">output_mul</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span>
<span class="n">output_div</span> <span class="o">=</span> <span class="n">y</span> <span class="o">/</span> <span class="n">x</span>
<span class="n">output_mod</span> <span class="o">=</span> <span class="n">x</span> <span class="o">%</span> <span class="n">y</span>
<span class="n">output_pow</span> <span class="o">=</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span>
<span class="n">output_floordiv</span> <span class="o">=</span> <span class="n">y</span> <span class="o">//</span> <span class="n">x</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;add:&quot;</span><span class="p">,</span> <span class="n">output_add</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sub:&quot;</span><span class="p">,</span> <span class="n">output_sub</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mul:&quot;</span><span class="p">,</span> <span class="n">output_mul</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;div:&quot;</span><span class="p">,</span> <span class="n">output_div</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mod:&quot;</span><span class="p">,</span> <span class="n">output_mod</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pow:&quot;</span><span class="p">,</span> <span class="n">output_pow</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;floordiv:&quot;</span><span class="p">,</span> <span class="n">output_floordiv</span><span class="p">)</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">output_eq</span> <span class="o">=</span> <span class="n">a</span> <span class="o">==</span> <span class="n">b</span>
<span class="n">output_ne</span> <span class="o">=</span> <span class="n">a</span> <span class="o">!=</span> <span class="n">b</span>
<span class="n">output_gt</span> <span class="o">=</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="n">b</span>
<span class="n">output_gq</span> <span class="o">=</span> <span class="n">a</span> <span class="o">&gt;=</span> <span class="n">b</span>
<span class="n">output_lt</span> <span class="o">=</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">b</span>
<span class="n">output_lq</span> <span class="o">=</span> <span class="n">a</span> <span class="o">&lt;=</span> <span class="n">b</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;equal:&quot;</span><span class="p">,</span> <span class="n">output_eq</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;not equal:&quot;</span><span class="p">,</span> <span class="n">output_ne</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;greater than:&quot;</span><span class="p">,</span> <span class="n">output_gt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;greater or equal:&quot;</span><span class="p">,</span> <span class="n">output_gq</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;less than:&quot;</span><span class="p">,</span> <span class="n">output_lt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;less or equal:&quot;</span><span class="p">,</span> <span class="n">output_lq</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>add: [5. 7. 9.]
sub: [-3. -3. -3.]
mul: [ 4. 10. 18.]
div: [4. 2.5 2. ]
mod: [1. 2. 3.]
pow: [1. 4. 9.]
floordiv: [4. 2. 2.]
equal: [False True False]
not equal: [ True False True]
greater than: [ True False False]
greater or equal: [ True True False]
less than: [False False True]
less or equal: [False True True]
</pre></div>
</div>
</section>
<section id="attributes">
<h3>Attributes<a class="headerlink" href="#attributes" title="Permalink to this headline"></a></h3>
<p>Tensor attributes include <code class="docutils literal notranslate"><span class="pre">shape</span></code>，<code class="docutils literal notranslate"><span class="pre">dtype</span></code>, <code class="docutils literal notranslate"><span class="pre">T</span></code>, <code class="docutils literal notranslate"><span class="pre">itemsize</span></code>, <code class="docutils literal notranslate"><span class="pre">nbytes</span></code>, <code class="docutils literal notranslate"><span class="pre">ndim</span></code>, <code class="docutils literal notranslate"><span class="pre">size</span></code>, <code class="docutils literal notranslate"><span class="pre">strides</span></code>.</p>
<ul class="simple">
<li><p>shape: a tuple</p></li>
<li><p>dtype: a data type of MindSpore</p></li>
<li><p>T: transposed view of original tensor</p></li>
<li><p>itemsize: an integer, representing the number of bytes consumed by a single element in the <code class="docutils literal notranslate"><span class="pre">Tensor</span></code></p></li>
<li><p>nbytes: an integer, representing the total number of bytes consumed by <code class="docutils literal notranslate"><span class="pre">Tensor</span></code></p></li>
<li><p>ndim: an integer, representing the rank of the <code class="docutils literal notranslate"><span class="pre">Tensor</span></code></p></li>
<li><p>size: an integer, representing the total number of elements in <code class="docutils literal notranslate"><span class="pre">Tensor</span></code></p></li>
<li><p>strides: the tuple of bytes to traverse in each dimension in <code class="docutils literal notranslate"><span class="pre">Tensor</span></code></p></li>
</ul>
<p>A code example is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">x_shape</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
<span class="n">x_dtype</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span>
<span class="n">x_transposed</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span>
<span class="n">x_itemsize</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">itemsize</span>
<span class="n">x_nbytes</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">nbytes</span>
<span class="n">x_ndim</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span>
<span class="n">x_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span>
<span class="n">x_strides</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">strides</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_shape:&quot;</span><span class="p">,</span> <span class="n">x_shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_dtype:&quot;</span><span class="p">,</span> <span class="n">x_dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_transposed:&quot;</span><span class="p">,</span> <span class="n">x_transposed</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_itemsize:&quot;</span><span class="p">,</span> <span class="n">x_itemsize</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_nbytes:&quot;</span><span class="p">,</span> <span class="n">x_nbytes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_ndim:&quot;</span><span class="p">,</span> <span class="n">x_ndim</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_size:&quot;</span><span class="p">,</span> <span class="n">x_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_strides:&quot;</span><span class="p">,</span> <span class="n">x_strides</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>x_shape: (2, 2)
x_dtype: Int32
x_transposed: [[1 3]
 [2 4]]
x_itemsize: 4
x_nbytes: 16
x_ndim: 2
x_size: 4
x_strides: (8, 4)
</pre></div>
</div>
</section>
<section id="methods">
<h3>Methods<a class="headerlink" href="#methods" title="Permalink to this headline"></a></h3>
<p>Tensor methods include <code class="docutils literal notranslate"><span class="pre">len</span></code>, <code class="docutils literal notranslate"><span class="pre">str</span></code>, <code class="docutils literal notranslate"><span class="pre">repr</span></code>, <code class="docutils literal notranslate"><span class="pre">hash</span></code>, <code class="docutils literal notranslate"><span class="pre">all</span></code>, <code class="docutils literal notranslate"><span class="pre">any</span></code>, <code class="docutils literal notranslate"><span class="pre">asnumpy</span></code> and many other functions. Numpy-like ndarray methods are also provided. For a full description of all tensor methods, please see <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.3/api_python/mindspore.html#mindspore.Tensor">API: mindspore.Tensor</a>. The following is a brief introduction to some of the tensor methods.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">len()</span></code>: returns the length of the tensor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">str()</span></code>: returns the string representation of the tensor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">repr()</span></code>: returns the string representation of the tensor for the interpreter to read.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">hash()</span></code>: get the hash value of the tensor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">all(axis,</span> <span class="pre">keep_dims)</span></code>: performs the <code class="docutils literal notranslate"><span class="pre">and</span></code> operation on a specified dimension to reduce the dimension. <code class="docutils literal notranslate"><span class="pre">axis</span></code> indicates the reduced dimension, and <code class="docutils literal notranslate"><span class="pre">keep_dims</span></code> indicates whether to retain the reduced dimension.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">any(axis,</span> <span class="pre">keep_dims)</span></code>: performs the <code class="docutils literal notranslate"><span class="pre">or</span></code> operation on a specified dimension to reduce the dimension. The parameter meaning is the same as that of <code class="docutils literal notranslate"><span class="pre">all</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">asnumpy()</span></code>: converts <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> to an array of NumPy.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sum(axis,</span> <span class="pre">dtype,</span> <span class="pre">keepdims,</span> <span class="pre">initial)</span></code>: sums the tensor over the given <code class="docutils literal notranslate"><span class="pre">axis</span></code>, <code class="docutils literal notranslate"><span class="pre">axis</span></code> indicates the reduced dimension, <code class="docutils literal notranslate"><span class="pre">dtype</span></code> specifies the output data type, <code class="docutils literal notranslate"><span class="pre">keepdims</span></code> indicates whether to retain the reduced dimension, and <code class="docutils literal notranslate"><span class="pre">initial</span></code> indicates the starting value for the sum.</p></li>
</ul>
<p>A code example is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>

<span class="n">t</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">t_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
<span class="n">t_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
<span class="n">t_repr</span> <span class="o">=</span> <span class="nb">repr</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
<span class="n">t_hash</span> <span class="o">=</span> <span class="nb">hash</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;t_len:&quot;</span><span class="p">,</span> <span class="n">t_len</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;t_str:&quot;</span><span class="p">,</span> <span class="n">t_str</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;t_repr:&quot;</span><span class="p">,</span> <span class="n">t_repr</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;t_hash:&quot;</span><span class="p">,</span> <span class="n">t_hash</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">],</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">]]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>
<span class="n">x_all</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="n">x_any</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
<span class="n">x_array</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_all:&quot;</span><span class="p">,</span> <span class="n">x_all</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_any:&quot;</span><span class="p">,</span> <span class="n">x_any</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_array:&quot;</span><span class="p">,</span> <span class="n">x_array</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">mindspore.numpy</span> <span class="k">as</span> <span class="nn">mnp</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">]]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># y.sum() and mindspore.numpy.sum(y) are equivalent methods</span>
<span class="n">y_sum_tensor</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">y_sum_mnp</span> <span class="o">=</span> <span class="n">mnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;y_sum_tensor:&quot;</span><span class="p">,</span> <span class="n">y_sum_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;y_sum_mnp:&quot;</span><span class="p">,</span> <span class="n">y_sum_mnp</span><span class="p">)</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>t_len: 3
t_str: [1 2 3]
t_repr: Tensor(shape=[3], dtype=Int32, value= [1, 2, 3])
t_hash: 281470264268272
x_all: False
x_any: True
x_array: [[ True  True]
 [False False]]
y_sum_tensor: 10.0
y_sum_mnp: 10.0
</pre></div>
</div>
</section>
</section>
<section id="sparse-tensor">
<h2>Sparse Tensor<a class="headerlink" href="#sparse-tensor" title="Permalink to this headline"></a></h2>
<p>Sparse tensor is a special kind of tensor which most of the elements are zero. In some scenario, like in the
recommendation system, the data is sparse. If we use common dense tensors to represent the data, we may introduce many
unnecessary calculations, storage and communication costs. In this situation, it is better to use sparse tensor to
represent the data.</p>
<p>The common structure of sparse tensor is <code class="docutils literal notranslate"><span class="pre">&lt;indices:Tensor,values:Tensor,dense_shape:Tensor&gt;</span></code>. <code class="docutils literal notranslate"><span class="pre">indices</span></code> means index of
non-zero elements, <code class="docutils literal notranslate"><span class="pre">values</span></code> means the values of these non-zero elements and <code class="docutils literal notranslate"><span class="pre">dense_shape</span></code> means the dense shape of
the sparse tensor. Using this structure, we define data structure <code class="docutils literal notranslate"><span class="pre">RowTensor</span></code> and <code class="docutils literal notranslate"><span class="pre">SparseTensor</span></code>.</p>
<blockquote>
<div><p>Now, PyNative mode does not support sparse tensor.</p>
</div></blockquote>
<section id="rowtensor">
<h3>RowTensor<a class="headerlink" href="#rowtensor" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">RowTensor</span></code> is typically used to represent a subset of a larger tensor dense of shape <code class="docutils literal notranslate"><span class="pre">[L0,</span> <span class="pre">D1,</span> <span class="pre">...,</span> <span class="pre">DN]</span></code>
where <code class="docutils literal notranslate"><span class="pre">L0</span></code> &gt;&gt; <code class="docutils literal notranslate"><span class="pre">D0</span></code>, and <code class="docutils literal notranslate"><span class="pre">D0</span></code> is the number of non-zero elements.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">indices</span></code>: A 1-D integer tensor of shape <code class="docutils literal notranslate"><span class="pre">[D0]</span></code>. Represents the position of non-zero elements.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">values</span></code>: A tensor of any data type of shape <code class="docutils literal notranslate"><span class="pre">[D0,</span> <span class="pre">D1,</span> <span class="pre">...,</span> <span class="pre">DN]</span></code>. Represents the value of non-zero elements.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dense_shape</span></code>: An integer tuple which contains the shape of the corresponding dense tensor.</p></li>
</ul>
<p>A code example is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">RowTensor</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dense_shape</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense_shape</span> <span class="o">=</span> <span class="n">dense_shape</span>
    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">RowTensor</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dense_shape</span>

<span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">Net</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[1. 2.]]

[0]

(3, 2)
</pre></div>
</div>
</section>
<section id="sparsetensor">
<h3>SparseTensor<a class="headerlink" href="#sparsetensor" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">SparseTensor</span></code> represents a set of nonzero elememts from a tensor at given indices. If the number of non-zero elements
is <code class="docutils literal notranslate"><span class="pre">N</span></code> and the dense shape of the sparse tensor is <code class="docutils literal notranslate"><span class="pre">ndims</span></code>：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">indices</span></code>: A 2-D integer Tensor of shape <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">ndims]</span></code>. Each line represents the index of non-zero elements.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">values</span></code>: A 1-D tensor of any type and shape <code class="docutils literal notranslate"><span class="pre">[N]</span></code>. Represents the value of non-zero elements.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dense_shape</span></code>: A integer tuple of size <code class="docutils literal notranslate"><span class="pre">ndims</span></code>, which specifies the dense shape of the sparse tensor.</p></li>
</ul>
<p>A code example is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">SparseTensor</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dense_shape</span><span class="p">):</span>
       <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
       <span class="bp">self</span><span class="o">.</span><span class="n">dense_shape</span> <span class="o">=</span> <span class="n">dense_shape</span>
    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
       <span class="n">x</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">)</span>
       <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dense_shape</span>

<span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">Net</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
<p>The following information is displayed:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[1. 2.]

[[0 1]
 [1 2]]

(3, 4)
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="dtype.html" class="btn btn-neutral float-left" title="dtype" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="operators.html" class="btn btn-neutral float-right" title="Operators" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>