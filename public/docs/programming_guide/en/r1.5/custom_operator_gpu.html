

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Custom Operators (GPU) &mdash; MindSpore master documentation</title>
  

  
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Custom Operators (CPU)" href="custom_operator_cpu.html" />
    <link rel="prev" title="Custom Operators (Ascend)" href="custom_operator_ascend.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Overall Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API Overview</a></li>
</ul>
<p class="caption"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/technical_white_paper.html">Technical White Paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/gradient.html">MindSpore Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.5/training_visual_design.html">Design of Visualization↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/glossary.html">Glossary</a></li>
</ul>
<p class="caption"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.5/linear_regression.html">Implementing Simple Linear Function Fitting↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.5/quick_start.html">Implementing an Image Classification Application↗</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic Concepts</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="dtype.html">DataType</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter_introduction.html">Parameter</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="operators.html">Operators</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="operators_usage.html">Operators Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="operators_classification.html">Operators Classification</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="custom_operator.html">Custom Operator</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="custom_operator_ascend.html">Custom Operators (Ascend)</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Custom Operators (GPU)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="#registering-the-operator-primitive">Registering the Operator Primitive</a></li>
<li class="toctree-l4"><a class="reference internal" href="#implementing-a-gpu-operator">Implementing a GPU operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="#registering-the-operator-information">Registering the Operator Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="#compiling-mindspore">Compiling Mindspore</a></li>
<li class="toctree-l4"><a class="reference internal" href="#operator-verification">Operator verification</a></li>
<li class="toctree-l4"><a class="reference internal" href="#defining-operators-bprop-functions">Defining Operators’ BProp Functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="custom_operator_cpu.html">Custom Operators (CPU)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cell.html">Cell</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_introduction.html">Dataset</a></li>
</ul>
<p class="caption"><span class="caption-text">Data Pipeline</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataset_sample.html">Quick Start of Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Processing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_advanced.html">Advanced Usage of Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_usage.html">Data Iteration</a></li>
</ul>
<p class="caption"><span class="caption-text">Build the Network</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="build_net.html">Constructing Single Operator Network and Multi-layer Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="initializer.html">Initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter.html">Network Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="control_flow.html">Using the Process Control Statement</a></li>
<li class="toctree-l1"><a class="reference internal" href="loss.html">Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="grad_operation.html">Gradient Operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="indefinite_parameter.html">Parameter Passing</a></li>
<li class="toctree-l1"><a class="reference internal" href="constexpr.html">Construct Constants In the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypermap.html">Operation Overloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">Optimization Algorithms</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Running</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="context.html">Configuring Running Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="run.html">Running Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_and_load_models.html">Save and Load Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="model.html">Application of Model</a></li>
</ul>
<p class="caption"><span class="caption-text">Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="online_inference.html">Online Inference with Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="offline_inference.html">Using Offline Model for Inference</a></li>
</ul>
<p class="caption"><span class="caption-text">Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">Distributed Parallel Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_advanced.html">Distributed Parallel Advanced Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_example.html">Distributed Parallel Usage Example</a></li>
</ul>
<p class="caption"><span class="caption-text">PyNative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
</ul>
<p class="caption"><span class="caption-text">Numpy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">NumPy Interfaces in MindSpore</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced Features</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="second_order_optimizer.html">Second Order Optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
</ul>
<p class="caption"><span class="caption-text">Function Debugging</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="read_ir_files.html">Reading IR</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/debug_in_pynative_mode.html">Debugging in PyNative Mode↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_tune.html">Enabling AutoTune</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Applying a Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.5/performance_profiling.html">Debugging performance with Profiler↗</a></li>
</ul>
<p class="caption"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="operators.html">Operators</a> &raquo;</li>
        
          <li><a href="custom_operator.html">Custom Operator</a> &raquo;</li>
        
      <li>Custom Operators (GPU)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/custom_operator_gpu.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="custom-operators-gpu">
<h1>Custom Operators (GPU)<a class="headerlink" href="#custom-operators-gpu" title="Permalink to this headline">¶</a></h1>
<p>Translator: <a class="reference external" href="https://gitee.com/Leon_02">Leon_02</a></p>
<p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Development</span></code></p>
<!-- TOC -->
<ul class="simple">
<li><p><a class="reference external" href="#custom-operators-gpu">Custom Operators (GPU)</a></p>
<ul>
<li><p><a class="reference external" href="#overview">Overview</a></p></li>
<li><p><a class="reference external" href="#registering-the-operator-primitive">Registering the Operator Primitive</a></p></li>
<li><p><a class="reference external" href="#implementing-a-GPU-operator">Implementing a GPU operator</a></p></li>
<li><p><a class="reference external" href="#registering-the-operator-information">Registering the Operator Information</a></p></li>
<li><p><a class="reference external" href="#compiling-for-mindspore">Compiling Mindspore</a></p></li>
<li><p><a class="reference external" href="#operator-verification">Operator verification</a></p></li>
</ul>
</li>
</ul>
<!-- /TOC -->
<p><a href="https://gitee.com/mindspore/docs/blob/r1.5/docs/mindspore/programming_guide/source_en/custom_operator_gpu.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source_en.png"></a></p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>Operator is the basic element of constructing neural network. When built-in operators cannot meet requirements during network development, you can utilize MindSpore to quickly extend custom operators of the Graphics Processing Unit.</p>
<ul class="simple">
<li><p>Primitive registration: the register operator primitive is the basic unit of constructing network model. Users can directly or indirectly call the operator primitive to build a neural network model.</p></li>
<li><p>GPU Kernel implementation: GPU kernel is used to call GPU to accelerate computing.</p></li>
<li><p>GPU Kernel registration: operator registration is used to register the GPU kernel and necessary information to the framework, and the framework completes the call to the GPU kernel.</p></li>
</ul>
<p>In this tutorial, we will develop a TensorAddV2 operator using C++ and CUDA in the mindspore framework. TensorAddV2 is used to add two tensors of the same dimension element by element.</p>
</div>
<div class="section" id="registering-the-operator-primitive">
<h2>Registering the Operator Primitive<a class="headerlink" href="#registering-the-operator-primitive" title="Permalink to this headline">¶</a></h2>
<p>Operator primitives usually include:</p>
<ul class="simple">
<li><p>Aperator names: operator names are used to uniquely identify operators.</p></li>
<li><p>Annotations: describe the algorithm and usage constraints of operators. The annotations will be exported as Mindspore API interface documentation for developers to refer to.</p></li>
<li><p>Input: the tensor(s) for operator input.</p></li>
<li><p>Attributes: for example, the <code class="docutils literal notranslate"><span class="pre">data_format</span></code> attribute in Conv2d describes that the input data is in <code class="docutils literal notranslate"><span class="pre">NCHW</span></code> or <code class="docutils literal notranslate"><span class="pre">NHWC</span></code> format.</p></li>
<li><p>Validation of input data: verify the validity of input data and attributes, which is convenient for developers to find the problems of network model as soon as possible.</p></li>
<li><p>Output data type and dimension derivation: used to derive the data type and dimension of output.</p></li>
</ul>
<p>The following code defines an operator called TensorAddV2:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">TensorAddV2</span></code> is a subclass inherited from <code class="docutils literal notranslate"><span class="pre">PrimitiveWithInfer</span></code>.</p></li>
<li><p>The constructor <code class="docutils literal notranslate"><span class="pre">__init__</span></code> is used to initialize the operator, since TensorAddV2 doesn’t have any attributes, there is none additional input for <code class="docutils literal notranslate"><span class="pre">__init__</span></code>.</p></li>
<li><p>The function <code class="docutils literal notranslate"><span class="pre">infer_shape</span></code> constraints two input dimensions must be the same and the output dimension will be same as the dimension of x1.</p></li>
<li><p>The function <code class="docutils literal notranslate"><span class="pre">infer_dtype</span></code> constrains that two input data must be of type float32 and the output data type is the same as the input data type.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mindspore/ops/operations/math_ops.py</span>
<span class="k">class</span> <span class="nc">TensorAddV2</span><span class="p">(</span><span class="n">PrimitiveWithInfer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Adds two input tensors element-wise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@prim_attr_register</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_prim_io_names</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">infer_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1_shape</span><span class="p">,</span> <span class="n">x2_shape</span><span class="p">):</span>
        <span class="n">validator</span><span class="o">.</span><span class="n">check_integer</span><span class="p">(</span><span class="s1">&#39;input dims&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x1_shape</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">x2_shape</span><span class="p">),</span> <span class="n">Rel</span><span class="o">.</span><span class="n">EQ</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x1_shape</span><span class="p">)):</span>
            <span class="n">validator</span><span class="o">.</span><span class="n">check_integer</span><span class="p">(</span><span class="s1">&#39;input_shape&#39;</span><span class="p">,</span> <span class="n">x1_shape</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">x2_shape</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">Rel</span><span class="o">.</span><span class="n">EQ</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x1_shape</span>

    <span class="k">def</span> <span class="nf">infer_dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1_dtype</span><span class="p">,</span> <span class="n">x2_type</span><span class="p">):</span>
        <span class="n">validator</span><span class="o">.</span><span class="n">check_tensor_type_same</span><span class="p">({</span><span class="s1">&#39;x1_dtype&#39;</span><span class="p">:</span> <span class="n">x1_dtype</span><span class="p">},</span> <span class="p">[</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="n">validator</span><span class="o">.</span><span class="n">check_tensor_type_same</span><span class="p">({</span><span class="s1">&#39;x2_dtype&#39;</span><span class="p">:</span> <span class="n">x2_dtype</span><span class="p">},</span> <span class="p">[</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x1_dtype</span>
</pre></div>
</div>
<p>Next we’ll export TensorAddV2 type in ‘<strong>init</strong>.py’, which convenient for users to import and use in the network.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mindspore/ops/operations/__init__.py</span>
<span class="kn">from</span> <span class="nn">.math_ops</span> <span class="kn">import</span> <span class="p">(</span><span class="n">Abs</span><span class="p">,</span> <span class="n">ACos</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">TensorAddV2</span><span class="p">)</span>
<span class="o">...</span>
<span class="o">...</span>
<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
  <span class="s1">&#39;ReverseSequence&#39;</span><span class="p">,</span>
  <span class="s1">&#39;CropAndResize&#39;</span><span class="p">,</span>
  <span class="o">...</span><span class="p">,</span>
  <span class="s1">&#39;TensorAddV2&#39;</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="implementing-a-gpu-operator">
<h2>Implementing a GPU operator<a class="headerlink" href="#implementing-a-gpu-operator" title="Permalink to this headline">¶</a></h2>
<p>Custom GPU operators inherit from <code class="docutils literal notranslate"><span class="pre">GPUKernel</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Init()</span></code>: it is used to initialize the GPU kernel, usually includes recording the input / output dimension of the operator, and completing the preparation before launch.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GetInputSizeList()</span></code>: feedback to the frame the number of bytes of video memory to input tensor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GetOutputSizeList()</span></code>: feedback to the frame the number of bytes of video memory to output tensor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GetWorkspaceSizeList()</span></code>: feedback to the frame the number of bytes for <code class="docutils literal notranslate"><span class="pre">Workspace</span></code>, where <code class="docutils literal notranslate"><span class="pre">Workspace</span></code> is the space used to store temporary data during calculation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Launch()</span></code>: generally, CUDA kernel (CUDA kernel is a kernel function developed by Nvidia GPU’s parallel computing architecture) or cudnn interface are called to complete the operator acceleration on GPU.</p></li>
</ul>
<p>The following code shows the implementation of TensorAddV2:
In order to support generalization of data types, we use class template to define <code class="docutils literal notranslate"><span class="pre">TensorAddV2GpuKernel</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Init()</span></code> records the number of tensor elements.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GetInputSizeList()</span></code> returns the number of bytes the input tensor needs to occupy. TensorAddV2 has two Input and the number of bytes per input equals to element_num * sizeof(T).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GetOutputSizeList()</span></code> returns the number of bytes the output tensor needs to occupy. TensorAddV2 has one output and the output occupies element_num * sizeof(T) bytes.</p></li>
<li><p>Since TensorAddV2 doesn’t need <code class="docutils literal notranslate"><span class="pre">Workspace</span></code>, the <code class="docutils literal notranslate"><span class="pre">GetWorkspaceSizeList()</span></code> returns a null <code class="docutils literal notranslate"><span class="pre">std::vector&lt;size_t&gt;</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Launch()</span></code> receives the addresses of input and output in video memory, and then calls <code class="docutils literal notranslate"><span class="pre">TensorAddV2</span></code> to complete acceleration.</p></li>
</ul>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// mindspore/ccsrc/backend/kernel_compiler/gpu/math/tensor_add_v2_gpu_kernel.h</span>

<span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span> <span class="nc">T</span><span class="o">&gt;</span><span class="w"></span>
<span class="k">class</span> <span class="nc">TensorAddV2GpuKernel</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">GpuKernel</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w"> </span><span class="k">public</span><span class="o">:</span><span class="w"></span>
<span class="w">  </span><span class="n">TensorAddV2GpuKernel</span><span class="p">()</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">element_num_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{}</span><span class="w"></span>
<span class="w">  </span><span class="o">~</span><span class="n">TensorAddV2GpuKernel</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">default</span><span class="p">;</span><span class="w"></span>

<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">Init</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">CNodePtr</span><span class="w"> </span><span class="o">&amp;</span><span class="n">kernel_node</span><span class="p">)</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">AnfAlgo</span><span class="o">::</span><span class="n">GetPrevNodeOutputInferShape</span><span class="p">(</span><span class="n">kernel_node</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">shape</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">      </span><span class="n">element_num_</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>
<span class="w">    </span><span class="n">InitSizeLists</span><span class="p">();</span><span class="w"></span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>

<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">GetInputSizeList</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">input_size_list_</span><span class="p">;</span><span class="w"> </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">GetOutputSizeList</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">output_size_list_</span><span class="p">;</span><span class="w"> </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">GetWorkspaceSizeList</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">workspace_size_list_</span><span class="p">;</span><span class="w"> </span><span class="p">}</span><span class="w"></span>

<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="n">Launch</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">AddressPtr</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">AddressPtr</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="p">,</span><span class="w"></span>
<span class="w">              </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">AddressPtr</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">stream_ptr</span><span class="p">)</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">T</span><span class="w"> </span><span class="o">*</span><span class="n">x1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetDeviceAddress</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="n">T</span><span class="w"> </span><span class="o">*</span><span class="n">x2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetDeviceAddress</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="n">T</span><span class="w"> </span><span class="o">*</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetDeviceAddress</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="n">TensorAddV2</span><span class="p">(</span><span class="n">element_num_</span><span class="p">,</span><span class="w"> </span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">x2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="n">cudaStream_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">stream_ptr</span><span class="p">));</span><span class="w"></span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>

<span class="w"> </span><span class="k">protected</span><span class="o">:</span><span class="w"></span>
<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">InitSizeLists</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">input_size_list_</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">element_num_</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">T</span><span class="p">));</span><span class="w"></span>
<span class="w">    </span><span class="n">input_size_list_</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">element_num_</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">T</span><span class="p">));</span><span class="w"></span>
<span class="w">    </span><span class="n">output_size_list_</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">element_num_</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">T</span><span class="p">));</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>

<span class="w"> </span><span class="k">private</span><span class="o">:</span><span class="w"></span>
<span class="w">  </span><span class="kt">size_t</span><span class="w"> </span><span class="n">element_num_</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">input_size_list_</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">output_size_list_</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">workspace_size_list_</span><span class="p">;</span><span class="w"></span>
<span class="p">};</span><span class="w"></span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">TensorAddV2</span></code> calls CUDA kernel<code class="docutils literal notranslate"><span class="pre">TensorAddV2Kernel</span></code> to implement the parallel addition of <code class="docutils literal notranslate"><span class="pre">element_num</span></code> elements:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// mindspore/ccsrc/backend/kernel_compiler/gpu/math/tensor_add_v2_gpu_kernel.h</span>

<span class="w"> </span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span> <span class="nc">T</span><span class="o">&gt;</span><span class="w"></span>
<span class="w"> </span><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">TensorAddV2Kernel</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">element_num</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">x2</span><span class="p">,</span><span class="w"> </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">element_num</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x2</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="w"> </span><span class="p">}</span><span class="w"></span>

<span class="w"> </span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span> <span class="nc">T</span><span class="o">&gt;</span><span class="w"></span>
<span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">TensorAddV2</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="o">&amp;</span><span class="n">element_num</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">x2</span><span class="p">,</span><span class="w"> </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">stream</span><span class="p">){</span><span class="w"></span>
<span class="w">    </span><span class="kt">size_t</span><span class="w"> </span><span class="n">thread_per_block</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">256</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="kt">size_t</span><span class="w"> </span><span class="n">block_per_grid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">element_num</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">thread_per_block</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">thread_per_block</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">TensorAddV2Kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">block_per_grid</span><span class="p">,</span><span class="w"> </span><span class="n">thread_per_block</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">element_num</span><span class="p">,</span><span class="w"> </span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">x2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">);</span><span class="w"></span>
<span class="w">   </span><span class="k">return</span><span class="p">;</span><span class="w"></span>
<span class="w"> </span><span class="p">}</span><span class="w"></span>

<span class="w"> </span><span class="k">template</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">TensorAddV2</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="o">&amp;</span><span class="n">element_num</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">x2</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
</div>
<div class="section" id="registering-the-operator-information">
<h2>Registering the Operator Information<a class="headerlink" href="#registering-the-operator-information" title="Permalink to this headline">¶</a></h2>
<p>Operator information includes:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Primive</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Input</span> <span class="pre">dtype,</span> <span class="pre">output</span> <span class="pre">dtype</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GPU</span> <span class="pre">Kernel</span> <span class="pre">class</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CUDA</span> <span class="pre">built-in</span> <span class="pre">dtype</span></code></p></li>
</ul>
<p>Framework calls <code class="docutils literal notranslate"><span class="pre">CUDA</span> <span class="pre">built-in</span> <span class="pre">dtype</span></code> to instantiate <code class="docutils literal notranslate"><span class="pre">GPU</span> <span class="pre">Kernel</span> <span class="pre">class</span></code> template class based on <code class="docutils literal notranslate"><span class="pre">Primive</span></code> and <code class="docutils literal notranslate"><span class="pre">Input</span> <span class="pre">dtype,</span> <span class="pre">output</span> <span class="pre">dtype</span></code>.</p>
<p>The TensorAddV2 operators supporting float and int are registered in the code below:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// mindspore/ccsrc/backend/kernel_compiler/gpu/math/tensor_add_v2_gpu_kernel.cc</span>

<span class="n">MS_REG_GPU_KERNEL_ONE</span><span class="p">(</span><span class="n">TensorAddV2</span><span class="p">,</span><span class="w"> </span><span class="n">KernelAttr</span><span class="p">()</span><span class="w"></span>
<span class="w">                                    </span><span class="p">.</span><span class="n">AddInputAttr</span><span class="p">(</span><span class="n">kNumberTypeFloat32</span><span class="p">)</span><span class="w"></span>
<span class="w">                                    </span><span class="p">.</span><span class="n">AddInputAttr</span><span class="p">(</span><span class="n">kNumberTypeFloat32</span><span class="p">)</span><span class="w"></span>
<span class="w">                                    </span><span class="p">.</span><span class="n">AddOutputAttr</span><span class="p">(</span><span class="n">kNumberTypeFloat32</span><span class="p">),</span><span class="w"></span>
<span class="w">                      </span><span class="n">TensorAddV2GpuKernel</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="p">)</span><span class="w"></span>

<span class="n">MS_REG_GPU_KERNEL_ONE</span><span class="p">(</span><span class="n">TensorAddV2</span><span class="p">,</span><span class="w"> </span><span class="n">KernelAttr</span><span class="p">()</span><span class="w"></span>
<span class="w">                                    </span><span class="p">.</span><span class="n">AddInputAttr</span><span class="p">(</span><span class="n">kNumberTypeInt32</span><span class="p">)</span><span class="w"></span>
<span class="w">                                    </span><span class="p">.</span><span class="n">AddInputAttr</span><span class="p">(</span><span class="n">kNumberTypeInt32</span><span class="p">)</span><span class="w"></span>
<span class="w">                                    </span><span class="p">.</span><span class="n">AddOutputAttr</span><span class="p">(</span><span class="n">kNumberTypeInt32</span><span class="p">),</span><span class="w"></span>
<span class="w">                      </span><span class="n">TensorAddV2GpuKernel</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="p">)</span><span class="w"></span>
</pre></div>
</div>
</div>
<div class="section" id="compiling-mindspore">
<h2>Compiling Mindspore<a class="headerlink" href="#compiling-mindspore" title="Permalink to this headline">¶</a></h2>
<p>After writing the custom GPU operator, you need to recompile and install MindSpore, see <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.5/install/mindspore_gpu_install_source_en.md">Installation Documentation</a>.</p>
</div>
<div class="section" id="operator-verification">
<h2>Operator verification<a class="headerlink" href="#operator-verification" title="Permalink to this headline">¶</a></h2>
<p>At the end of the tutorial, we construct a single operator network to validate the TensorAddV2 operator we just developed：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># tests/st/ops/gpu/test_tensoraddv2_op.py</span>

<span class="kn">import</span> <span class="nn">mindspore.context</span> <span class="k">as</span> <span class="nn">context</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">level0</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">platform_x86_gpu_training</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">env_onecard</span>
<span class="k">def</span> <span class="nf">test_TensorAdd</span><span class="p">():</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">TensorAddV2</span><span class="p">()(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;result: &#39;</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>When the command <code class="docutils literal notranslate"><span class="pre">pytest</span> <span class="pre">-s</span> <span class="pre">tests/st/ops/gpu/test_tensoraddv2_op.py::test_TensorAdd</span></code> executes, you can see the results meeting expectations：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>result: [[2. 2. 2. 2.]
  [2. 2. 2. 2.]
  [2. 2. 2. 2.]]
</pre></div>
</div>
</div>
<div class="section" id="defining-operators-bprop-functions">
<h2>Defining Operators’ BProp Functions<a class="headerlink" href="#defining-operators-bprop-functions" title="Permalink to this headline">¶</a></h2>
<p>If an operator needs to support automatic differentiation, its back-propagation function (bprop) needs to be defined in its primitives. You need to describe the reverse computing logic that uses forward input, forward output, and output gradient to get the input gradient in bprop. Reverse computation logic can be composed of built-in operators or custom reverse operators.</p>
<p>The following points should be paid attention to when defining operators’ bprop functions:</p>
<ul class="simple">
<li><p>The order of input parameters of bprop function is defined as positive input, positive output and output gradient. If the operator is a multi-output operator, the forward output and output gradient will be provided in the form of tuples.</p></li>
<li><p>The form of the return values of bprop function is arranged as a tuple composed of input gradient, and the order of elements in the tuple is consistent with that of forward input parameters. Even if there is only one input gradient, the return value must be in the form of tuples.</p></li>
</ul>
<p>For example, the bprop primitives of <code class="docutils literal notranslate"><span class="pre">TensorAddV2</span></code> are:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="nd">@bprop_getters</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">TensorAddV2</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">get_bprop_tensoraddv2</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generate bprop for TensorAddV2&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">bprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">dout</span><span class="p">,</span> <span class="n">dout</span>

    <span class="k">return</span> <span class="n">bprop</span>
</pre></div>
</div>
<p>Define the bprop case in document <code class="docutils literal notranslate"><span class="pre">test_tensoraddv2_op.py</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="k">class</span> <span class="nc">Grad</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Grad</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">GradOperation</span><span class="p">(</span><span class="n">sens_param</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">sens</span><span class="p">):</span>
        <span class="n">gout</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">)(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">sens</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">gout</span>

<span class="k">def</span> <span class="nf">test_grad_net</span><span class="p">():</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">sens</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">Grad</span><span class="p">(</span><span class="n">Net</span><span class="p">())</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">sense</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dx[0]: &quot;</span><span class="p">,</span> <span class="n">dx</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
</pre></div>
</div>
<p>Running case:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pytest -s tests/st/ops/gpu/test_tensoraddv2_op.py::test_grad_net
</pre></div>
</div>
<p>Running results:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>dx[0]: [[0. 1. 2. 3.]
        [4. 5. 6. 7.]
        [8. 9. 10. 11.]]
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="custom_operator_cpu.html" class="btn btn-neutral float-right" title="Custom Operators (CPU)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="custom_operator_ascend.html" class="btn btn-neutral float-left" title="Custom Operators (Ascend)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>