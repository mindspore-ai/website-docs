<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Using MobileNetV2 to Implement Fine-Tuning &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Natural Language Processing" href="nlp.html" />
    <link rel="prev" title="Image Classification Using ResNet-50 Network" href="cv_resnet50.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Overall Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/technical_white_paper.html">Technical White Paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/gradient.html">MindSpore Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.5/training_visual_design.html">Design of Visualization↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.5/linear_regression.html">Implementing Simple Linear Function Fitting↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.5/quick_start.html">Implementing an Image Classification Application↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dtype.html">DataType</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter_introduction.html">Parameter</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="cell.html">Cell</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_introduction.html">Dataset</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Pipeline</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataset_sample.html">Quick Start of Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Processing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_advanced.html">Advanced Usage of Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_usage.html">Data Iteration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build the Network</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="build_net.html">Constructing Single Operator Network and Multi-layer Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="initializer.html">Initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter.html">Network Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="control_flow.html">Using the Process Control Statement</a></li>
<li class="toctree-l1"><a class="reference internal" href="loss.html">Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="grad_operation.html">Gradient Operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="indefinite_parameter.html">Parameter Passing</a></li>
<li class="toctree-l1"><a class="reference internal" href="constexpr.html">Construct Constants In the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypermap.html">Operation Overloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">Optimization Algorithms</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Running</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="context.html">Configuring Running Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="run.html">Running Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_and_load_models.html">Save and Load Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="model.html">Application of Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="online_inference.html">Online Inference with Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="offline_inference.html">Using Offline Model for Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">Distributed Parallel Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_advanced.html">Distributed Parallel Advanced Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_example.html">Distributed Parallel Usage Example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyNative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Numpy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">NumPy Interfaces in MindSpore</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="second_order_optimizer.html">Second Order Optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Function Debugging</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="read_ir_files.html">Reading IR</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/debug_in_pynative_mode.html">Debugging in PyNative Mode↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_tune.html">Enabling AutoTune</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Applying a Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.5/performance_profiling.html">Debugging performance with Profiler↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="cv.html">Computer Vision</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="cv_resnet50.html">Image Classification Using ResNet-50 Network</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Using MobileNetV2 to Implement Fine-Tuning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#task-description-and-preparations">Task Description and Preparations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#environment-configuration">Environment Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#downloading-code">Downloading Code</a></li>
<li class="toctree-l4"><a class="reference internal" href="#preparing-a-pre-trained-model">Preparing a Pre-Trained Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#preparing-data">Preparing Data</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#code-for-loading-a-pre-trained-model">Code for Loading a Pre-Trained Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#parameter-description">Parameter Description</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#running-python-files">Running Python Files</a></li>
<li class="toctree-l4"><a class="reference internal" href="#running-shell-scripts">Running Shell Scripts</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#loading-fine-tuning-training">Loading Fine-Tuning Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#loading-training-on-cpu">Loading Training on CPU</a></li>
<li class="toctree-l4"><a class="reference internal" href="#loading-training-on-gpu">Loading Training on GPU</a></li>
<li class="toctree-l4"><a class="reference internal" href="#loading-training-on-ascend-ai-processor">Loading Training on Ascend AI Processor</a></li>
<li class="toctree-l4"><a class="reference internal" href="#fine-tuning-training-result">Fine-Tuning Training Result</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#validating-the-fine-tuning-training-model">Validating the Fine-Tuning Training Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#validating-the-model">Validating the Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#validation-result">Validation Result</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="cv.html">Computer Vision</a> &raquo;</li>
      <li>Using MobileNetV2 to Implement Fine-Tuning</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/cv_mobilenetv2_fine_tune.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section class="tex2jax_ignore mathjax_ignore" id="using-mobilenetv2-to-implement-fine-tuning">
<h1>Using MobileNetV2 to Implement Fine-Tuning<a class="headerlink" href="#using-mobilenetv2-to-implement-fine-tuning" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">Whole</span> <span class="pre">Peocess</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.5/docs/mindspore/programming_guide/source_en/cv_mobilenetv2_fine_tune.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source_en.png"></a>  </p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>In a computer vision task, training a network from scratch is time-consuming and requires a large amount of computing power. Pre-trained models often select open large datasets such as OpenImage, ImageNet, VOC, and COCO. The number of images in these datasets reaches hundreds of thousands or even millions. Most tasks have a large amount of data. If a pre-trained model is not used during network model training, the training from scratch consumes a large amount of time and computing power. As a result, the model is prone to local minimum and overfitting. Therefore, most tasks perform fine-tuning on pre-trained models.</p>
<p>MindSpore is a diversified machine learning framework. It can run on devices such as mobile phones and PCs, or on server clusters on the cloud. Currently, MobileNetV2 supports fine-tuning on a single CPU or on one or more Ascend AI Processors or GPUs on Windows, EulerOS, and Ubuntu systems. This tutorial describes how to perform fine-tuning training and validation in the MindSpore frameworks of different systems and processors.</p>
<p>Currently, only the CPU is supported on Windows, and the CPU, GPU, and Ascend AI Processor are supported on Ubuntu and EulerOS.</p>
<blockquote>
<div><p>You can obtain the complete executable sample code at <a class="reference external" href="https://gitee.com/mindspore/models/tree/r1.5/official/cv/mobilenetv2">https://gitee.com/mindspore/models/tree/r1.5/official/cv/mobilenetv2</a>.</p>
</div></blockquote>
</section>
<section id="task-description-and-preparations">
<h2>Task Description and Preparations<a class="headerlink" href="#task-description-and-preparations" title="Permalink to this headline"></a></h2>
<section id="environment-configuration">
<h3>Environment Configuration<a class="headerlink" href="#environment-configuration" title="Permalink to this headline"></a></h3>
<p>If running a task in a local environment, install the MindSpore framework and configure the CPU, GPU, or Ascend AI Processor. If running a task in the HUAWEI CLOUD environment, skip this section because the installation and configuration are not required.</p>
<p>On the Windows operating system, backslashes <code class="docutils literal notranslate"><span class="pre">\</span></code> are used to separate directories of different levels in a path address. On the Linux operating system, slashes <code class="docutils literal notranslate"><span class="pre">/</span></code> are used. The following uses <code class="docutils literal notranslate"><span class="pre">/</span></code> by default. If you use Windows operating system, replace <code class="docutils literal notranslate"><span class="pre">/</span></code> in the path address with <code class="docutils literal notranslate"><span class="pre">\</span></code>.</p>
<ol class="arabic">
<li><p>Install the MindSpore framework.
<a class="reference external" href="https://www.mindspore.cn/install/en">Install</a> a MindSpore framework based on the processor architecture and the EulerOS, Ubuntu, or Windows system.</p></li>
<li><p>Configure the CPU environment.<br />
Set the following code before calling the CPU to start training or testing:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s2">&quot;CPU&quot;</span><span class="p">:</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">platform</span><span class="p">,</span> \
        <span class="n">save_graphs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Configure the GPU environment.<br />
Set the following code before calling the GPU to start training or testing:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s2">&quot;GPU&quot;</span><span class="p">:</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">platform</span><span class="p">,</span> <span class="n">save_graphs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">run_distribute</span><span class="p">:</span>
        <span class="n">init</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>
        <span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">device_num</span><span class="o">=</span><span class="n">get_group_size</span><span class="p">(),</span>
                                          <span class="n">parallel_mode</span><span class="o">=</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">DATA_PARALLEL</span><span class="p">,</span>
                                          <span class="n">gradients_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Configure the Ascend environment.<br />
The following uses the JSON configuration file <code class="docutils literal notranslate"><span class="pre">hccl_config.json</span></code> in an environment with eight Ascend 910 AI processors as an example. Adjust <code class="docutils literal notranslate"><span class="pre">&quot;server_count&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">device</span></code> based on the following example to switch between the single-device and multi-device environments:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;version&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1.0&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;server_count&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;server_list&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;server_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;10.155.111.140&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.1.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.2.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.3.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;3&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.4.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;3&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;4&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.1.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;4&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;5&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.2.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;5&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;6&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.3.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;6&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;7&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.4.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;7&quot;</span><span class="p">}],</span>
<span class="w">            </span><span class="nt">&quot;host_nic_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;reserve&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">],</span>
<span class="w">    </span><span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;completed&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Set the following code before calling the Ascend AI Processor to start training or testing:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s2">&quot;Ascend&quot;</span><span class="p">:</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">platform</span><span class="p">,</span> <span class="n">device_id</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">device_id</span><span class="p">,</span>
                        <span class="n">save_graphs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">run_distribute</span><span class="p">:</span>
        <span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">device_num</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">rank_size</span><span class="p">,</span>
                                          <span class="n">parallel_mode</span><span class="o">=</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">DATA_PARALLEL</span><span class="p">,</span>
                                          <span class="n">gradients_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                          <span class="n">all_reduce_fusion_config</span><span class="o">=</span><span class="p">[</span><span class="mi">140</span><span class="p">])</span>
        <span class="n">init</span><span class="p">()</span>
<span class="o">...</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="downloading-code">
<h3>Downloading Code<a class="headerlink" href="#downloading-code" title="Permalink to this headline"></a></h3>
<p>Run the following command to clone <a class="reference external" href="https://gitee.com/mindspore/models.git">MindSpore open-source project repository</a> in Gitee and go to <code class="docutils literal notranslate"><span class="pre">./models/official/cv/mobilenetv2/</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://gitee.com/mindspore/models.git<span class="w"> </span>-b<span class="w"> </span>r1.5
<span class="nb">cd</span><span class="w"> </span>./models/official/cv/mobilenetv2
</pre></div>
</div>
<p>The code structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>├── MobileNetV2
  ├── README.md                  # descriptions about MobileNetV2
  ├── ascend310_infer            # application for 310 inference
  ├── scripts
  │   ├──run_infer_310.sh        # shell script for 310 inference
  │   ├──run_train.sh            # shell script for training, fine-tuning or incremental learning with CPU, GPU or Ascend
  │   ├──run_eval.sh             # shell script for evaluation with CPU, GPU or Ascend
  │   ├──cache_util.sh           # a collection of helper functions to manage cache
  │   ├──run_train_nfs_cache.sh  # shell script for training with NFS dataset and leverage caching service for better performance
  ├── src
  │   ├──aipp.cfg                # aipp config
  │   ├──dataset.py              # creating dataset
  │   ├──lr_generator.py         # learning rate config
  │   ├──mobilenetV2.py          # MobileNetV2 architecture
  │   ├──models.py               # loading define_net, Loss and Monitor
  │   ├──utils.py                # loading ckpt_file for fine-tuning or incremental learning
  │   └──model_utils
  │      ├──config.py            # processing configuration parameters
  │      ├──device_adapter.py    # getting cloud ID
  │      ├──local_adapter.py     # getting local ID
  │      └──moxing_adapter.py    # parameter processing
  ├── default_config.yaml        # training parameter profile(ascend)
  ├── default_config_cpu.yaml    # training parameter profile(cpu)
  ├── default_config_gpu.yaml    # training parameter profile(gpu)
  ├── train.py                   # training script
  ├── eval.py                    # evaluation script
  ├── export.py                  # exporting mindir script
  ├── mindspore_hub_conf.py      # mindspore hub interface
  ├── postprocess.py             # postprocess script
</pre></div>
</div>
<p>During fine-tuning training and testing, python files <code class="docutils literal notranslate"><span class="pre">train.py</span></code> and <code class="docutils literal notranslate"><span class="pre">eval.py</span></code> can be used on Windows, Ubuntu, and EulerOS, and shell script files <code class="docutils literal notranslate"><span class="pre">run_train.sh</span></code> and <code class="docutils literal notranslate"><span class="pre">run_eval.sh</span></code> can be used on Ubuntu and EulerOS.</p>
<p>If the script file <code class="docutils literal notranslate"><span class="pre">run_train.sh</span></code> is used, it runs <code class="docutils literal notranslate"><span class="pre">launch.py</span></code> and inputs parameters to <code class="docutils literal notranslate"><span class="pre">launch.py</span></code> which starts one or more processes to run <code class="docutils literal notranslate"><span class="pre">train.py</span></code> based on the number of allocated CPUs, GPUs, or Ascend AI Processors. Each process is allocated with a processor.</p>
</section>
<section id="preparing-a-pre-trained-model">
<h3>Preparing a Pre-Trained Model<a class="headerlink" href="#preparing-a-pre-trained-model" title="Permalink to this headline"></a></h3>
<p>Download a <a class="reference external" href="https://download.mindspore.cn/model_zoo/official/lite/mobilenetv2_openimage_lite/mobilenetv2_cpu_gpu.ckpt">CPU/GPU pre-trained model</a> or <a class="reference external" href="https://download.mindspore.cn/model_zoo/r1.2/mobilenetv2_ascend_v120_imagenet2012_official_cv_bs256_acc71/mobilenetv2_ascend_v120_imagenet2012_official_cv_bs256_acc71.ckpt">Ascend pre-trained model</a> to the following directories based on the processor type:<br />
<code class="docutils literal notranslate"><span class="pre">./pretrain_checkpoint/</span></code></p>
<ul>
<li><p>CPU/GPU</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>pretrain_checkpoint
wget<span class="w"> </span>-P<span class="w"> </span>./pretrain_checkpoint<span class="w"> </span>https://download.mindspore.cn/model_zoo/official/lite/mobilenetv2_openimage_lite/mobilenetv2_cpu_gpu.ckpt<span class="w"> </span>--no-check-certificate
</pre></div>
</div>
</li>
<li><p>Ascend AI Processor</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>pretrain_checkpoint
wget<span class="w"> </span>-P<span class="w"> </span>./pretrain_checkpoint<span class="w"> </span>https://download.mindspore.cn/model_zoo/r1.2/mobilenetv2_ascend_v120_imagenet2012_official_cv_bs256_acc71/mobilenetv2_ascend_v120_imagenet2012_official_cv_bs256_acc71.ckpt<span class="w"> </span>--no-check-certificate
</pre></div>
</div>
</li>
</ul>
</section>
<section id="preparing-data">
<h3>Preparing Data<a class="headerlink" href="#preparing-data" title="Permalink to this headline"></a></h3>
<p>Prepare the dataset managed in ImageFolder format. Add the <code class="docutils literal notranslate"><span class="pre">&lt;dataset_path&gt;</span></code> parameter when running <code class="docutils literal notranslate"><span class="pre">run_train.sh</span></code>, and add the <code class="docutils literal notranslate"><span class="pre">--dataset_path</span> <span class="pre">&lt;dataset_path&gt;</span></code> parameter when running <code class="docutils literal notranslate"><span class="pre">train.py</span></code>.</p>
<p>The dataset structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─ImageFolder
    ├─train
    │   class1Folder
    │   class2Folder
    │   ......
    └─eval
        class1Folder
        class2Folder
        ......
</pre></div>
</div>
</section>
</section>
<section id="code-for-loading-a-pre-trained-model">
<h2>Code for Loading a Pre-Trained Model<a class="headerlink" href="#code-for-loading-a-pre-trained-model" title="Permalink to this headline"></a></h2>
<p>During fine-tuning, you need to load a pre-trained model. The distribution of the feature extraction layer (convolutional layer) in different datasets and tasks tends to be consistent. However, the combination of feature vectors (fully connected layer) is different, and the number of classes (output_size of the fully connected layer) is usually different. During fine-tuning, parameters of the feature extraction layer are loaded and trained, while those of the fully connected layer are not. During fine-tuning and initial training, both feature extraction layer parameters and fully connected layer parameters are loaded and trained.</p>
<p>Before training and testing, build a backbone network and a head network of MobileNetV2 on the first line of the code, and build a MobileNetV2 network containing the two subnets. Lines 3 to 10 of the code show how to define <code class="docutils literal notranslate"><span class="pre">backbone_net</span></code> and <code class="docutils literal notranslate"><span class="pre">head_net</span></code> and how to add the two subnets to <code class="docutils literal notranslate"><span class="pre">mobilenet_v2</span></code>. Lines 12 to 27 of the code show that in fine-tuning training mode, the pre-trained model needs to be loaded to the <code class="docutils literal notranslate"><span class="pre">backbone_net</span></code> subnet, and parameters in <code class="docutils literal notranslate"><span class="pre">backbone_net</span></code> are frozen and do not participate in training. Lines 21 to 27 of the code show how to freeze network parameters.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span> <span class="mi">1</span><span class="p">:</span>  <span class="n">backbone_net</span><span class="p">,</span> <span class="n">head_net</span><span class="p">,</span> <span class="n">net</span> <span class="o">=</span> <span class="n">define_net</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">is_training</span><span class="p">)</span>
 <span class="mi">2</span><span class="p">:</span>  <span class="o">...</span>
 <span class="mi">3</span><span class="p">:</span>  <span class="k">def</span> <span class="nf">define_net</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
 <span class="mi">4</span><span class="p">:</span>      <span class="n">backbone_net</span> <span class="o">=</span> <span class="n">MobileNetV2Backbone</span><span class="p">()</span>
 <span class="mi">5</span><span class="p">:</span>      <span class="n">activation</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">activation</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">is_training</span> <span class="k">else</span> <span class="s2">&quot;None&quot;</span>
 <span class="mi">6</span><span class="p">:</span>      <span class="n">head_net</span> <span class="o">=</span> <span class="n">MobileNetV2Head</span><span class="p">(</span><span class="n">input_channel</span><span class="o">=</span><span class="n">backbone_net</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span>
 <span class="mi">7</span><span class="p">:</span>                              <span class="n">num_classes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span>
 <span class="mi">8</span><span class="p">:</span>                              <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">)</span>
 <span class="mi">9</span><span class="p">:</span>      <span class="n">net</span> <span class="o">=</span> <span class="n">mobilenet_v2</span><span class="p">(</span><span class="n">backbone_net</span><span class="p">,</span> <span class="n">head_net</span><span class="p">)</span>
<span class="mi">10</span><span class="p">:</span>      <span class="k">return</span> <span class="n">backbone_net</span><span class="p">,</span> <span class="n">head_net</span><span class="p">,</span> <span class="n">net</span>
<span class="mi">11</span><span class="p">:</span>  <span class="o">...</span>
<span class="mi">12</span><span class="p">:</span>  <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">pretrain_ckpt</span><span class="p">:</span>
<span class="mi">13</span><span class="p">:</span>      <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">freeze_layer</span> <span class="o">==</span> <span class="s2">&quot;backbone&quot;</span><span class="p">:</span>
<span class="mi">14</span><span class="p">:</span>         <span class="n">load_ckpt</span><span class="p">(</span><span class="n">backbone_net</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">pretrain_ckpt</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="mi">15</span><span class="p">:</span>         <span class="n">step_size</span> <span class="o">=</span> <span class="n">extract_features</span><span class="p">(</span><span class="n">backbone_net</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<span class="mi">16</span><span class="p">:</span>      <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">filter_head</span><span class="p">:</span>
<span class="mi">17</span><span class="p">:</span>           <span class="n">load_ckpt</span><span class="p">(</span><span class="n">backbone_net</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">pretrain_ckpt</span><span class="p">)</span>
<span class="mi">18</span><span class="p">:</span>      <span class="k">else</span><span class="p">:</span>
<span class="mi">19</span><span class="p">:</span>           <span class="n">load_ckpt</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">pretrain_ckpt</span><span class="p">)</span>
<span class="mi">20</span><span class="p">:</span>  <span class="o">...</span>
<span class="mi">21</span><span class="p">:</span>  <span class="k">def</span> <span class="nf">load_ckpt</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">pretrain_ckpt_path</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="mi">22</span><span class="p">:</span>      <span class="s2">&quot;&quot;&quot; train the param weight or not &quot;&quot;&quot;</span>
<span class="mi">23</span><span class="p">:</span>      <span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">pretrain_ckpt_path</span><span class="p">)</span>
<span class="mi">24</span><span class="p">:</span>      <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="mi">25</span><span class="p">:</span>      <span class="k">if</span> <span class="ow">not</span> <span class="n">trainable</span><span class="p">:</span>
<span class="mi">26</span><span class="p">:</span>          <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">():</span>
<span class="mi">27</span><span class="p">:</span>              <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
</section>
<section id="parameter-description">
<h2>Parameter Description<a class="headerlink" href="#parameter-description" title="Permalink to this headline"></a></h2>
<p>Change the value of each parameter based on the local processor type, data path, and pre-trained model path.</p>
<section id="running-python-files">
<h3>Running Python Files<a class="headerlink" href="#running-python-files" title="Permalink to this headline"></a></h3>
<p>When using <code class="docutils literal notranslate"><span class="pre">train.py</span></code> for training on Windows and Linux, input <code class="docutils literal notranslate"><span class="pre">config_path</span></code>, <code class="docutils literal notranslate"><span class="pre">dataset_path</span></code>, <code class="docutils literal notranslate"><span class="pre">platform</span></code>, <code class="docutils literal notranslate"><span class="pre">pretrain_ckpt</span></code>, and <code class="docutils literal notranslate"><span class="pre">freeze_layer</span></code>. When using <code class="docutils literal notranslate"><span class="pre">eval.py</span></code> for validation, input <code class="docutils literal notranslate"><span class="pre">config_path</span></code>, <code class="docutils literal notranslate"><span class="pre">dataset_path</span></code>, <code class="docutils literal notranslate"><span class="pre">platform</span></code>, and <code class="docutils literal notranslate"><span class="pre">pretrain_ckpt</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Windows/Linux train with Python file</span>
python<span class="w"> </span>train.py<span class="w"> </span>--config_path<span class="w"> </span><span class="o">[</span>CONFIG_PATH<span class="o">]</span><span class="w"> </span>--platform<span class="w"> </span><span class="o">[</span>PLATFORM<span class="o">]</span><span class="w"> </span>--dataset_path<span class="w"> </span>&lt;DATASET_PATH&gt;<span class="w">  </span>--pretrain_ckpt<span class="w"> </span><span class="o">[</span>PRETRAIN_CHECKPOINT_PATH<span class="o">]</span><span class="w"> </span>--freeze_layer<span class="o">[(</span><span class="s2">&quot;none&quot;</span>,<span class="w"> </span><span class="s2">&quot;backbone&quot;</span><span class="o">)]</span>

<span class="c1"># Windows/Linux eval with Python file</span>
python<span class="w"> </span>eval.py<span class="w"> </span>--config_path<span class="w"> </span><span class="o">[</span>CONFIG_PATH<span class="o">]</span><span class="w"> </span>--platform<span class="w"> </span><span class="o">[</span>PLATFORM<span class="o">]</span><span class="w"> </span>--dataset_path<span class="w"> </span>&lt;DATASET_PATH&gt;<span class="w"> </span>--pretrain_ckpt<span class="w"> </span>&lt;PRETRAIN_CHECKPOINT_PATH&gt;
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--config_path</span></code>: parameters required for training and verification.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--dataset_path</span></code>: path of the training or validation dataset. There is no default value. This parameter is mandatory for training or validation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--platform</span></code>: processor type. The default value is <code class="docutils literal notranslate"><span class="pre">Ascend</span></code>. You can set it to <code class="docutils literal notranslate"><span class="pre">CPU</span></code> or <code class="docutils literal notranslate"><span class="pre">GPU</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--pretrain_ckpt</span></code>: path of the <code class="docutils literal notranslate"><span class="pre">pretrain_checkpoint</span></code> file required for loading a weight of a pre-trained model parameter during incremental training or optimization.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--freeze_layer</span></code>: frozen network layer. Enter <code class="docutils literal notranslate"><span class="pre">none</span></code> or <code class="docutils literal notranslate"><span class="pre">backbone</span></code>.</p></li>
</ul>
</section>
<section id="running-shell-scripts">
<h3>Running Shell Scripts<a class="headerlink" href="#running-shell-scripts" title="Permalink to this headline"></a></h3>
<p>You can run the shell scripts <code class="docutils literal notranslate"><span class="pre">./scripts/run_train.sh</span></code> and <code class="docutils literal notranslate"><span class="pre">./scripts/run_eval.sh</span></code> on Linux. Input parameters on the interaction interface.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Windows doesn&#39;t support Shell</span>
<span class="c1"># Linux train with Shell script</span>
sh<span class="w"> </span>run_train.sh<span class="w"> </span><span class="o">[</span>PLATFORM<span class="o">]</span><span class="w"> </span><span class="o">[</span>DEVICE_NUM<span class="o">]</span><span class="w"> </span><span class="o">[</span>VISIABLE_DEVICES<span class="o">(</span><span class="m">0</span>,1,2,3,4,5,6,7<span class="o">)]</span><span class="w"> </span><span class="o">[</span>RANK_TABLE_FILE<span class="o">]</span><span class="w"> </span><span class="o">[</span>DATASET_PATH<span class="o">]</span><span class="w"> </span><span class="o">[</span>CKPT_PATH<span class="o">](</span>optional<span class="o">)</span><span class="w"> </span><span class="o">[</span>FREEZE_LAYER<span class="o">](</span>optional<span class="o">)</span><span class="w"> </span><span class="o">[</span>FILTER_HEAD<span class="o">](</span>optional<span class="o">)</span>

<span class="c1"># Linux eval with Shell script for fine tune</span>
sh<span class="w"> </span>run_eval.sh<span class="w"> </span><span class="o">[</span>PLATFORM<span class="o">]</span><span class="w"> </span><span class="o">[</span>DATASET_PATH<span class="o">]</span><span class="w"> </span><span class="o">[</span>PRETRAIN_CKPT_PATH<span class="o">]</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;PLATFORM&gt;</span></code>: processor type. The default value is <code class="docutils literal notranslate"><span class="pre">Ascend</span></code>. You can set it to <code class="docutils literal notranslate"><span class="pre">GPU</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;DEVICE_NUM&gt;</span></code>: number of processes on each node (equivalent to a server or PC). You are advised to set this parameter to the number of Ascend AI Processors or GPUs on a server.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;VISIABLE_DEVICES(0,1,2,3,4,5,6,7)&gt;</span></code>: device ID of character string type. During training, a process is bound to a device with the corresponding ID based on <code class="docutils literal notranslate"><span class="pre">&lt;VISIABLE_DEVICES&gt;</span></code>. Multiple device IDs are separated by commas (,). It is recommended that the number of IDs be the same as the number of processes.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;RANK_TABLE_FILE&gt;</span></code>: a JSON file configured when platform is set to <code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;DATASET_PATH&gt;</span></code>: path of the training or validation dataset. There is no default value. This parameter is mandatory for training or validation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;CKPT_PATH&gt;</span></code>: path of the checkpoint file required for loading a weight of a pre-trained model parameter during incremental training or optimization.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[FREEZE_LAYER]</span></code>: frozen network layer during fine-tuned model validation. Enter <code class="docutils literal notranslate"><span class="pre">none</span></code> or <code class="docutils literal notranslate"><span class="pre">backbone</span></code>.</p></li>
</ul>
</section>
</section>
<section id="loading-fine-tuning-training">
<h2>Loading Fine-Tuning Training<a class="headerlink" href="#loading-fine-tuning-training" title="Permalink to this headline"></a></h2>
<p>Only <code class="docutils literal notranslate"><span class="pre">train.py</span></code> can be run on Windows when MobileNetV2 is used for fine-tuning training. You can run the shell script <code class="docutils literal notranslate"><span class="pre">run_train.sh</span></code> and input <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/cv_mobilenetv2_fine_tune.html#id8">parameters</a> on Linux when MobileNetV2 is used for fine-tuning training.</p>
<p>The Windows system outputs information to an interactive command line. When running <code class="docutils literal notranslate"><span class="pre">run_train.sh</span></code> on the Linux system, use <code class="docutils literal notranslate"><span class="pre">&amp;&gt;</span> <span class="pre">&lt;log_file_path&gt;</span></code> at the end of the command line to write the standard output and error output to the log file. After the fine-tuning is successful, training starts. The training time and loss of each epoch are continuously written into the <code class="docutils literal notranslate"><span class="pre">./train/rank*/log*.log</span></code> file. If the fine-tuning fails, an error message is recorded in the preceding log file.</p>
<section id="loading-training-on-cpu">
<h3>Loading Training on CPU<a class="headerlink" href="#loading-training-on-cpu" title="Permalink to this headline"></a></h3>
<ul>
<li><p>Set the number of nodes.</p>
<p>Currently, <code class="docutils literal notranslate"><span class="pre">train.py</span></code> supports only a single processor. You do not need to adjust the number of processors. When the <code class="docutils literal notranslate"><span class="pre">run_train.sh</span></code> file is run, a single <code class="docutils literal notranslate"><span class="pre">CPU</span></code> is used by default. The number of CPUs cannot be changed.</p>
</li>
<li><p>Start incremental training.</p>
<p>Example 1: Use the python file to call a CPU.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Windows or Linux with Python</span>
python<span class="w"> </span>train.py<span class="w"> </span>--config_path<span class="w"> </span>./default_config_cpu.yaml<span class="w"> </span>--platform<span class="w"> </span>CPU<span class="w"> </span>--dataset_path<span class="w"> </span>&lt;TRAIN_DATASET_PATH&gt;<span class="w">  </span>--pretrain_ckpt<span class="w"> </span>./pretrain_checkpoint/mobilenetv2_cpu_gpu.ckpt<span class="w"> </span>--freeze_layer<span class="w"> </span>backbone
</pre></div>
</div>
<p>Example 2: Use the shell file to call a CPU.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Linux with Shell</span>
sh<span class="w"> </span>run_train.sh<span class="w"> </span>CPU<span class="w"> </span><span class="o">[</span>DATASET_PATH<span class="o">]</span><span class="w"> </span><span class="o">[</span>CKPT_PATH<span class="o">](</span>optional<span class="o">)</span><span class="w"> </span><span class="o">[</span>FREEZE_LAYER<span class="o">](</span>optional<span class="o">)</span><span class="w"> </span><span class="o">[</span>FILTER_HEAD<span class="o">](</span>optional<span class="o">)</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="loading-training-on-gpu">
<h3>Loading Training on GPU<a class="headerlink" href="#loading-training-on-gpu" title="Permalink to this headline"></a></h3>
<ul>
<li><p>Set the number of nodes.</p>
<p>Currently, <code class="docutils literal notranslate"><span class="pre">train.py</span></code> supports only a single processor. You do not need to adjust the number of nodes. When running the <code class="docutils literal notranslate"><span class="pre">run_train.sh</span></code> file, set <code class="docutils literal notranslate"><span class="pre">&lt;nproc_per_node&gt;</span></code> to the number of GPUs and <code class="docutils literal notranslate"><span class="pre">&lt;visible_devices&gt;</span></code> to IDs of available processors, that is, GPU IDs. You can select one or more device IDs and separate them with commas (,).</p>
</li>
<li><p>Start incremental training.</p>
<ul>
<li><p>Example 1: Use the python file to call a GPU.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Windows or Linux with Python</span>
python<span class="w"> </span>train.py<span class="w"> </span>--config_path<span class="w"> </span>./default_config_gpu.yaml<span class="w"> </span>--platform<span class="w"> </span>GPU<span class="w"> </span>--dataset_path<span class="w"> </span>&lt;TRAIN_DATASET_PATH&gt;<span class="w"> </span>--pretrain_ckpt<span class="w"> </span>./pretrain_checkpoint/mobilenetv2_cpu_gpu.ckpt<span class="w"> </span>--freeze_layer<span class="w"> </span>backbone
</pre></div>
</div>
</li>
<li><p>Example 2: Use the shell script to call a GPU whose device ID is <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Linux with Shell</span>
sh<span class="w"> </span>run_train.sh<span class="w"> </span>GPU<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">[</span>DATASET_PATH<span class="o">]</span><span class="w"> </span><span class="o">[</span>CKPT_PATH<span class="o">](</span>optional<span class="o">)</span><span class="w"> </span><span class="o">[</span>FREEZE_LAYER<span class="o">](</span>optional<span class="o">)</span><span class="w"> </span><span class="o">[</span>FILTER_HEAD<span class="o">](</span>optional<span class="o">)</span>
</pre></div>
</div>
</li>
<li><p>Example 3: Use the shell script to call eight GPUs whose device IDs are <code class="docutils literal notranslate"><span class="pre">0,1,2,3,4,5,6,7</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Linux with Shell</span>
sh<span class="w"> </span>run_train.sh<span class="w"> </span>GPU<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="m">0</span>,1,2,3,4,5,6,7<span class="w"> </span><span class="o">[</span>DATASET_PATH<span class="o">]</span><span class="w"> </span><span class="o">[</span>CKPT_PATH<span class="o">](</span>optional<span class="o">)</span><span class="w"> </span><span class="o">[</span>FREEZE_LAYER<span class="o">](</span>optional<span class="o">)</span><span class="w"> </span><span class="o">[</span>FILTER_HEAD<span class="o">](</span>optional<span class="o">)</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</section>
<section id="loading-training-on-ascend-ai-processor">
<h3>Loading Training on Ascend AI Processor<a class="headerlink" href="#loading-training-on-ascend-ai-processor" title="Permalink to this headline"></a></h3>
<ul>
<li><p>Set the number of nodes.</p>
<p>Currently, <code class="docutils literal notranslate"><span class="pre">train.py</span></code> supports only a single processor. You do not need to adjust the number of nodes. When running the <code class="docutils literal notranslate"><span class="pre">run_train.sh</span></code> file, set <code class="docutils literal notranslate"><span class="pre">&lt;nproc_per_node&gt;</span></code> to the number of Ascend AI Processors and <code class="docutils literal notranslate"><span class="pre">&lt;visible_devices&gt;</span></code> to IDs of available processors, that is, Ascend AI Processor IDs. You can select one or more device IDs from 0 to 7 on an 8-device server and separate them with commas (,). Currently, the number of Ascend AI Processors can only be set to 1 or 8.</p>
</li>
<li><p>Start incremental training.</p>
<ul>
<li><p>Example 1: Use the python file to call an Ascend AI Processor.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Windows or Linux with Python</span>
python<span class="w"> </span>train.py<span class="w"> </span>--config_path<span class="w"> </span>./default_config.yaml<span class="w"> </span>--platform<span class="w"> </span>Ascend<span class="w"> </span>--dataset_path<span class="w"> </span>&lt;TRAIN_DATASET_PATH&gt;<span class="w">  </span>--pretrain_ckpt<span class="w">  </span>./pretrain_checkpoint/mobilenetv2_ascend_v120_imagenet2012_official_cv_bs256_acc71.ckpt<span class="w"> </span>--freeze_layer<span class="w"> </span>backbone
</pre></div>
</div>
</li>
<li><p>Example 2: Use the shell script to call an Ascend AI Processor whose device ID is <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Linux with Shell</span>
sh<span class="w"> </span>run_train.sh<span class="w"> </span>Ascend<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">0</span><span class="w"> </span>~/rank_table.json<span class="w"> </span>&lt;TRAIN_DATASET_PATH&gt;<span class="w"> </span>../pretrain_checkpoint/mobilenetv2_ascend_v120_imagenet2012_official_cv_bs256_acc71.ckpt<span class="w"> </span>backbone
</pre></div>
</div>
</li>
<li><p>Example 3: Use the shell script to call eight Ascend AI Processors whose device IDs are <code class="docutils literal notranslate"><span class="pre">0,1,2,3,4,5,6,7</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Linux with Shell</span>
sh<span class="w"> </span>run_train.sh<span class="w"> </span>Ascend<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="m">0</span>,1,2,3,4,5,6,7<span class="w"> </span>~/rank_table.json<span class="w"> </span>&lt;TRAIN_DATASET_PATH&gt;<span class="w"> </span>../pretrain_checkpoint/mobilenetv2_ascend_v120_imagenet2012_official_cv_bs256_acc71.ckpt<span class="w"> </span>backbone
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</section>
<section id="fine-tuning-training-result">
<h3>Fine-Tuning Training Result<a class="headerlink" href="#fine-tuning-training-result" title="Permalink to this headline"></a></h3>
<ul>
<li><p>View the running result.</p>
<ul>
<li><p>When running the python file, view the output information in the interactive command line. After running the shell script on <code class="docutils literal notranslate"><span class="pre">Linux</span></code>, run the <code class="docutils literal notranslate"><span class="pre">cat</span> <span class="pre">./train/rank0/log0.log</span></code> command to view the output information. The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>train args: Namespace(dataset_path=&#39;./dataset/train&#39;, platform=&#39;CPU&#39;, \
pretrain_ckpt=&#39;./pretrain_checkpoint/mobilenetv2_cpu_gpu.ckpt&#39;, freeze_layer=&#39;backbone&#39;)
cfg: {&#39;num_classes&#39;: 26, &#39;image_height&#39;: 224, &#39;image_width&#39;: 224, &#39;batch_size&#39;: 150, \
&#39;epoch_size&#39;: 200, &#39;warmup_epochs&#39;: 0, &#39;lr_max&#39;: 0.03, &#39;lr_end&#39;: 0.03, &#39;momentum&#39;: 0.9, \
&#39;weight_decay&#39;: 4e-05, &#39;label_smooth&#39;: 0.1, &#39;loss_scale&#39;: 1024, &#39;save_checkpoint&#39;: True, \
&#39;save_checkpoint_epochs&#39;: 1, &#39;keep_checkpoint_max&#39;: 20, &#39;save_checkpoint_path&#39;: &#39;./&#39;, \
&#39;platform&#39;: &#39;CPU&#39;}
Processing batch: 16: 100%|███████████████████████████████████████████ █████████████████████| 16/16 [00:00&lt;?, ?it/s]
epoch[200], iter[16] cost: 256.030, per step time: 256.030, avg loss: 1.775total cos 7.2574 s
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>Check the saved checkpoint files.</p>
<ul>
<li><p>On Windows, run the <code class="docutils literal notranslate"><span class="pre">dir</span> <span class="pre">checkpoint</span></code> command to view the saved model files.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>dir ckpt_0
2020//0814 11:20        267,727 mobilenetv2_1.ckpt
2020//0814 11:21        267,727 mobilenetv2_10.ckpt
2020//0814 11:21        267,727 mobilenetv2_11.ckpt
...
2020//0814 11:21        267,727 mobilenetv2_7.ckpt
2020//0814 11:21        267,727 mobilenetv2_8.ckpt
2020//0814 11:21        267,727 mobilenetv2_9.ckpt
</pre></div>
</div>
</li>
<li><p>On Linux, run the <code class="docutils literal notranslate"><span class="pre">ls</span> <span class="pre">./checkpoint</span></code> command to view the saved model files.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ls ./ckpt_0/
mobilenetv2_1.ckpt  mobilenetv2_2.ckpt
mobilenetv2_3.ckpt  mobilenetv2_4.ckpt
...
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</section>
</section>
<section id="validating-the-fine-tuning-training-model">
<h2>Validating the Fine-Tuning Training Model<a class="headerlink" href="#validating-the-fine-tuning-training-model" title="Permalink to this headline"></a></h2>
<section id="validating-the-model">
<h3>Validating the Model<a class="headerlink" href="#validating-the-model" title="Permalink to this headline"></a></h3>
<p>Set mandatory <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/cv_mobilenetv2_fine_tune.html#id8">parameters</a> when using the validation set to test model performance. The default value of <code class="docutils literal notranslate"><span class="pre">--platform</span></code> is <code class="docutils literal notranslate"><span class="pre">Ascend</span></code>. You can set it to <code class="docutils literal notranslate"><span class="pre">CPU</span></code> or <code class="docutils literal notranslate"><span class="pre">GPU</span></code>. Finally, the standard output and error output are displayed in the interactive command line or written to the <code class="docutils literal notranslate"><span class="pre">eval.log</span></code> file.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Windows/Linux with Python</span>
python<span class="w"> </span>eval.py<span class="w"> </span>--config_path<span class="w"> </span>./default_config_cpu.yaml<span class="w"> </span>--platform<span class="w"> </span>CPU<span class="w"> </span>--dataset_path<span class="w"> </span>&lt;VAL_DATASET_PATH&gt;<span class="w"> </span>--pretrain_ckpt<span class="w"> </span>./ckpt_0/mobilenetv2_15.ckpt

<span class="c1"># Linux with Shell</span>
sh<span class="w"> </span>run_eval.sh<span class="w"> </span>CPU<span class="w"> </span>&lt;VAL_DATASET_PATH&gt;<span class="w"> </span>../ckpt_0/mobilenetv2_15.ckpt
</pre></div>
</div>
</section>
<section id="validation-result">
<h3>Validation Result<a class="headerlink" href="#validation-result" title="Permalink to this headline"></a></h3>
<p>When the python file is run, the validation result is output in the interactive command line. The shell script writes the information to <code class="docutils literal notranslate"><span class="pre">./eval.log</span></code>. You need to run the <code class="docutils literal notranslate"><span class="pre">cat</span> <span class="pre">./eval.log</span></code> command to view the information. The result is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>result:{&#39;acc&#39;: 0.9466666666666666666667}
pretrain_ckpt = ./ckpt_0/mobilenetv2_15.ckpt
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="cv_resnet50.html" class="btn btn-neutral float-left" title="Image Classification Using ResNet-50 Network" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="nlp.html" class="btn btn-neutral float-right" title="Natural Language Processing" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>