<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Dataset &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Quick Start of Dataset" href="dataset_sample.html" />
    <link rel="prev" title="Cell" href="cell.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Overall Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/technical_white_paper.html">Technical White Paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/gradient.html">MindSpore Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.5/training_visual_design.html">Design of Visualization↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.5/linear_regression.html">Implementing Simple Linear Function Fitting↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.5/quick_start.html">Implementing an Image Classification Application↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Concepts</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="dtype.html">DataType</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter_introduction.html">Parameter</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="cell.html">Cell</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Dataset</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="#dataset-loading">Dataset Loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="#data-processing">Data Processing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#shuffle-operation">Shuffle Operation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#map-operation">Map Operation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#batch-operation">Batch Operation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Pipeline</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataset_sample.html">Quick Start of Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Processing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_advanced.html">Advanced Usage of Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_usage.html">Data Iteration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build the Network</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="build_net.html">Constructing Single Operator Network and Multi-layer Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="initializer.html">Initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter.html">Network Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="control_flow.html">Using the Process Control Statement</a></li>
<li class="toctree-l1"><a class="reference internal" href="loss.html">Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="grad_operation.html">Gradient Operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="indefinite_parameter.html">Parameter Passing</a></li>
<li class="toctree-l1"><a class="reference internal" href="constexpr.html">Construct Constants In the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypermap.html">Operation Overloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">Optimization Algorithms</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Running</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="context.html">Configuring Running Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="run.html">Running Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_and_load_models.html">Save and Load Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="model.html">Application of Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="online_inference.html">Online Inference with Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="offline_inference.html">Using Offline Model for Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">Distributed Parallel Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_advanced.html">Distributed Parallel Advanced Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_example.html">Distributed Parallel Usage Example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyNative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Numpy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">NumPy Interfaces in MindSpore</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="second_order_optimizer.html">Second Order Optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Function Debugging</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="read_ir_files.html">Reading IR</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/debug_in_pynative_mode.html">Debugging in PyNative Mode↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_tune.html">Enabling AutoTune</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Applying a Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.5/performance_profiling.html">Debugging performance with Profiler↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Dataset</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/dataset_introduction.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="dataset">
<h1>Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">Beginner</span></code></p>
<p>Translator: <a class="reference external" href="https://gitee.com/wei-zz">Wei_zz</a></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.5/docs/mindspore/programming_guide/source_en/dataset_introduction.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source_en.png"></a></p>
<p>Data is the foundation of deep learning, and high-quality data input will play a positive role in the entire deep neural network.
In the network training and inference process, the original data is generally stored in a disk or a database, and it needs to be first read into the memory space through the data loading step, converted into the framework’s common tensor (Tensor) format, and then processed and enhanced by the data step, map it to a feature space that is easier to learn, while increasing the number of samples and generalization, and finally input to the network for calculation.</p>
<p>The overall process is shown in the figure below:</p>
<p><img alt="avatar" src="_images/basic_dataset_pipeline.png" /></p>
<p>This chapter introduces some basic concepts involved in data loading, data processing, and enhancement operations in <code class="docutils literal notranslate"><span class="pre">mindspore.dataset</span></code>(hereinafter referred to as Dataset).</p>
<section id="id1">
<h2>Dataset<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h2>
<p><img alt="avatar" src="_images/basic_dataset_data.png" /></p>
<p>A dataset is a collection of samples. A row of the dataset is a sample that contains one or more features, and may also contain a label. The dataset needs to meet certain specifications to facilitate the evaluation of the model’s effect.</p>
<p>Dataset supports multiple format data sets, including MindSpore self-developed data format MindRecord, commonly used public image data sets and text data sets, user-defined data sets, etc. For detailed data sets supported by Mindspore, please refer to: <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/dataset_loading.html">MindSpore Support Data Sets</a>.</p>
<p>Dataset also supports the conversion of commonly used data sets and user-defined data sets to MindSpore data format (MindRecord). For details, please refer to: <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/convert_dataset.html">Converting Data Sets to MindRecord</a>.</p>
</section>
<section id="dataset-loading">
<h2>Dataset Loading<a class="headerlink" href="#dataset-loading" title="Permalink to this headline"></a></h2>
<p><img alt="avatar" src="_images/basic_dataset_load.png" /></p>
<p>The dataset loading makes the model training continuously obtain data for training.</p>
<p>Dataset provides corresponding classes for a variety of commonly used data sets to load data sets. At the same time, for data files in different storage formats, Dataset also has corresponding classes for data loading. For loading of MindSpore dataset, please refer to: <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/dataset_loading.html">loading of MindSpore dataset</a>.</p>
<p>Dataset provides a sampler for multiple purposes (Sampler), the sampler is responsible for generating the read index sequence, the Dataset is responsible for reading the corresponding data according to the index, and helping users to sample the dataset in different forms to meet training needs and solve problems such as the dataset is too large or the sample category distribution is uneven. Note that the sampler is responsible for filtering and reordering the samples, and will not perform the batch operation.</p>
<p>For the introduction of Mindspore data sampling, please refer to: <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/sampler.html">MindSpore data sampling</a>.</p>
</section>
<section id="data-processing">
<h2>Data Processing<a class="headerlink" href="#data-processing" title="Permalink to this headline"></a></h2>
<p>After the Dataset loads the data into the memory, the data is organized in the form of Tensor. At the same time, Tensor is also the basic data structure in data augmentation operations.</p>
<section id="shuffle-operation">
<h3>Shuffle Operation<a class="headerlink" href="#shuffle-operation" title="Permalink to this headline"></a></h3>
<p><img alt="avatar" src="_images/basic_dataset_shuffle.png" /></p>
<p>Training is generally multiple epochs, and the shuffle operation disrupts the order of the data to ensure that the data order of each epoch is different during training to prevent training from overfitting.</p>
<p>Dataset provides multiple ways to implement global shuffle operations.</p>
<ol class="arabic">
<li><p><code class="docutils literal notranslate"><span class="pre">shuffle</span></code> parameters of the dataset loading class</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;column_1&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>For details, please refer to: <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.5/api_python/dataset/mindspore.dataset.NumpySlicesDataset.html">NumpySlicesDataset</a>.</p>
</li>
<li><p>shuffle operator</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;column_1&quot;</span><span class="p">])</span>
<span class="c1"># buffer_size equal to the number of rows in the entire dataset will result in a global     shuffle</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p>For details, please refer to: <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.5/api_python/dataset/mindspore.dataset.GeneratorDataset.html#mindspore.dataset.GeneratorDataset.shuffle">shuffle API</a>.</p>
</li>
<li><p>Random sampling</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">RandomSampler</span><span class="p">()</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;column_1&quot;</span><span class="p">],</span><span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>
</pre></div>
</div>
<p>For details, please refer to: <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.5/api_python/dataset/mindspore.dataset.RandomSampler.html#mindspore-dataset-randomsampler">RandomSampler</a>.</p>
</li>
</ol>
</section>
<section id="map-operation">
<h3>Map Operation<a class="headerlink" href="#map-operation" title="Permalink to this headline"></a></h3>
<p><img alt="avatar" src="_images/basic_dataset_map.png" /></p>
<p>The Map operation performs data enhancement on all kinds of data, is responsible for starting and executing the data enhancement operators provided by the Dataset or user-defined, and mapping and transforming the data. Among them, data enhancement is a method of creating “new” data with different directions. One is to generate “more data” from limited data, and the other is to prevent overfitting.</p>
<p>Dataset’s <code class="docutils literal notranslate"><span class="pre">c_transforms</span></code> and <code class="docutils literal notranslate"><span class="pre">py_transforms</span></code> modules provide implementations of data enhancement operators based on <code class="docutils literal notranslate"><span class="pre">C++</span></code> and <code class="docutils literal notranslate"><span class="pre">Python</span></code> respectively, and users can customize functions for data enhancement.</p>
<p>For image data enhancement operations, please refer to: <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/augmentation.html">image data enhancement</a>.</p>
<p>For text data enhancement operations, please refer to: [<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/tokenizer.html">text data enhancement</a>.</p>
<p>For Map operation, please refer to: <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.5/api_python/dataset/mindspore.dataset.CelebADataset.html#mindspore.dataset.CelebADataset.map">Map operation</a>.</p>
</section>
<section id="batch-operation">
<h3>Batch Operation<a class="headerlink" href="#batch-operation" title="Permalink to this headline"></a></h3>
<p><img alt="avatar" src="_images/basic_dataset_batch.png" /></p>
<p>Only one sample is used to train the model at a time, which has good randomness, but poor parallelization, resulting in low training efficiency. The introduction of mini-batch can better balance the training speed and training effect.</p>
<p>The Batch operation is responsible for “packing” multiple <code class="docutils literal notranslate"><span class="pre">Tensors</span></code> with the same <code class="docutils literal notranslate"><span class="pre">shape</span></code> together to achieve training in a mini-batch manner. The Batch operation also provides the drop_remainder parameter, which means that the last batch that does not have a batch_size is deleted, and it will be retained by default. If the dataset size is 17373, 8 cards are used for training and the Batch size is 16, each card is allocated 2172 samples. When drop_remainder is True, 135 mini-batch can be packed on each card.</p>
<p>Before the “packing” action, Batch supports <code class="docutils literal notranslate"><span class="pre">Tensors</span></code> with inconsistent <code class="docutils literal notranslate"><span class="pre">shapes</span></code> according to user requirements, or automatically fills the <code class="docutils literal notranslate"><span class="pre">shapes</span></code> of <code class="docutils literal notranslate"><span class="pre">Tensors</span></code> in the same way, and executes user-defined functions through <code class="docutils literal notranslate"><span class="pre">Per_batch_map</span></code> before “packing”.</p>
<ol class="arabic">
<li><p>padding operation</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="c1"># col1d: [0],[1]</span>
<span class="c1"># col2d: [[100],[200]], [[101],[201]]</span>
<span class="k">def</span> <span class="nf">gen_2cols</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
    <span class="k">yield</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">i</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">100</span><span class="p">],</span> <span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">200</span><span class="p">]]))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">((</span><span class="k">lambda</span><span class="p">:</span> <span class="n">gen_2cols</span><span class="p">(</span><span class="mi">2</span><span class="p">)),</span> <span class="p">[</span><span class="s2">&quot;col1d&quot;</span><span class="p">,</span> <span class="s2">&quot;col2d&quot;</span><span class="p">])</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_info</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;col2d&quot;</span><span class="p">:</span> <span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="p">,</span> <span class="s2">&quot;col1d&quot;</span><span class="p">:</span> <span class="p">([</span><span class="mi">2</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)})</span>
<span class="c1"># col1d: [0, -1], [1, -1]</span>
<span class="c1"># col2d: [[100, -2], [200, -2]], [[101, -2], [201, -2]]</span>
</pre></div>
</div>
</li>
<li><p>per_batch_map operation</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="c1"># first column: 0, 3, 6, 9 ...</span>
<span class="c1"># second column:1, 4, 7, 10 ...</span>
<span class="c1"># third column: 2, 5, 8, 11 ...</span>
<span class="k">def</span> <span class="nf">gen_3_cols</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
    <span class="k">yield</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">i</span> <span class="o">*</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">i</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">i</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]))</span>
<span class="c1"># first epoch batch_size per batch: 1, 2 ,3 ...</span>
<span class="c1"># second epoch batch_size per batch: 2, 4, 6 ...</span>
<span class="c1"># third epoch batch_size per batch: 3, 6 ,9 ...</span>
<span class="k">def</span> <span class="nf">batch_func</span><span class="p">(</span><span class="n">batchInfo</span><span class="p">):</span>
<span class="k">return</span> <span class="p">(</span><span class="n">batchInfo</span><span class="o">.</span><span class="n">get_batch_num</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">batchInfo</span><span class="o">.</span><span class="n">get_epoch_num</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># multiply first col by batch_num, multiply second col by -batch_num</span>
<span class="k">def</span> <span class="nf">map_func</span><span class="p">(</span><span class="n">col1</span><span class="p">,</span> <span class="n">col2</span><span class="p">,</span> <span class="n">batchInfo</span><span class="p">):</span>
<span class="k">return</span> <span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">((</span><span class="mi">1</span> <span class="o">+</span> <span class="n">batchInfo</span><span class="o">.</span><span class="n">get_batch_num</span><span class="p">())</span> <span class="o">*</span> <span class="n">arr</span><span class="p">)</span> <span class="k">for</span> <span class="n">arr</span> <span class="ow">in</span> <span class="n">col1</span><span class="p">],</span>
    <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">batchInfo</span><span class="o">.</span><span class="n">get_batch_num</span><span class="p">())</span> <span class="o">*</span> <span class="n">arr</span><span class="p">)</span> <span class="k">for</span> <span class="n">arr</span> <span class="ow">in</span> <span class="n">col2</span><span class="p">])</span>
<span class="c1"># col1: [[0]], [[ 6], [12]], [[27]]</span>
<span class="c1"># col2: [[-1]],[[ -8], [-14]],  [[-30]]</span>
<span class="c1"># col3: [[2]], [[5], [8]], [[11]]</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">((</span><span class="k">lambda</span><span class="p">:</span> <span class="n">gen_3_cols</span><span class="p">(</span><span class="mi">4</span><span class="p">)),</span> <span class="p">[</span><span class="s2">&quot;col1&quot;</span><span class="p">,</span> <span class="s2">&quot;col2&quot;</span><span class="p">,</span> <span class="s2">&quot;col3&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">batch</span> <span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_func</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;col1&quot;</span><span class="p">,</span> <span class="s2">&quot;col2&quot;</span><span class="p">],</span> <span class="n">per_batch_map</span><span class="o">=</span><span class="n">map_func</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
<p>For Batch operation, please refer to: <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.5/api_python/dataset/mindspore.dataset.CelebADataset.html#mindspore.dataset.CelebADataset.batch">Batch operation</a>.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="cell.html" class="btn btn-neutral float-left" title="Cell" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="dataset_sample.html" class="btn btn-neutral float-right" title="Quick Start of Dataset" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>