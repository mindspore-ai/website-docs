<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Text Data Processing and Enhancement &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Lightweight Data Processing" href="eager.html" />
    <link rel="prev" title="Image Data Processing and Enhancement" href="augmentation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Overall Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/technical_white_paper.html">Technical White Paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/gradient.html">MindSpore Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.5/training_visual_design.html">Design of Visualizationâ†—</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.5/linear_regression.html">Implementing Simple Linear Function Fittingâ†—</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.5/quick_start.html">Implementing an Image Classification Applicationâ†—</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dtype.html">DataType</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter_introduction.html">Parameter</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="cell.html">Cell</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_introduction.html">Dataset</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Pipeline</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="dataset_sample.html">Quick Start of Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">Loading Dataset</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="pipeline.html">Processing Data</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="pipeline_common.html">General Data Processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="augmentation.html">Image Data Processing and Enhancement</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Text Data Processing and Enhancement</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mindspore-tokenizers">MindSpore Tokenizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#berttokenizer">BertTokenizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="#jiebatokenizer">JiebaTokenizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="#sentencepiecetokenizer">SentencePieceTokenizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="#unicodechartokenizer">UnicodeCharTokenizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="#whitespacetokenizer">WhitespaceTokenizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="#wordpiecetokenizer">WordpieceTokenizer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="eager.html">Lightweight Data Processing</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dataset_advanced.html">Advanced Usage of Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_usage.html">Data Iteration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build the Network</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="build_net.html">Constructing Single Operator Network and Multi-layer Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="initializer.html">Initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter.html">Network Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="control_flow.html">Using the Process Control Statement</a></li>
<li class="toctree-l1"><a class="reference internal" href="loss.html">Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="grad_operation.html">Gradient Operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="indefinite_parameter.html">Parameter Passing</a></li>
<li class="toctree-l1"><a class="reference internal" href="constexpr.html">Construct Constants In the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypermap.html">Operation Overloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">Optimization Algorithms</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Running</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="context.html">Configuring Running Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="run.html">Running Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_and_load_models.html">Save and Load Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="model.html">Application of Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="online_inference.html">Online Inference with Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="offline_inference.html">Using Offline Model for Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">Distributed Parallel Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_advanced.html">Distributed Parallel Advanced Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_example.html">Distributed Parallel Usage Example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyNative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Numpy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">NumPy Interfaces in MindSpore</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="second_order_optimizer.html">Second Order Optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Applying Quantization Aware Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Function Debugging</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="read_ir_files.html">Reading IR</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.5/debug_in_pynative_mode.html">Debugging in PyNative Modeâ†—</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">Enabling Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_tune.html">Enabling AutoTune</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Applying a Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.5/performance_profiling.html">Debugging performance with Profilerâ†—</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="pipeline.html">Processing Data</a> &raquo;</li>
      <li>Text Data Processing and Enhancement</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/tokenizer.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section class="tex2jax_ignore mathjax_ignore" id="text-data-processing-and-enhancement">
<h1>Text Data Processing and Enhancement<a class="headerlink" href="#text-data-processing-and-enhancement" title="Permalink to this headline">ïƒ</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">Data</span> <span class="pre">Preparation</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.5/docs/mindspore/programming_guide/source_en/tokenizer.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source_en.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">ïƒ</a></h2>
<p>Tokenization is a process of re-combining continuous character sequences into word sequences according to certain specifications. Reasonable tokenization is helpful for semantic comprehension.</p>
<p>MindSpore provides a tokenizer for multiple purposes to help you process text with high performance. You can build your own dictionaries, use appropriate tokenizers to split sentences into different tokens, and search for indexes of the tokens in the dictionaries.</p>
<p>MindSpore provides the following tokenizers. In addition, you can customize tokenizers as required.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Tokenizer</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>BasicTokenizer</p></td>
<td><p>Performs tokenization on scalar text data based on specified rules.</p></td>
</tr>
<tr class="row-odd"><td><p>BertTokenizer</p></td>
<td><p>Processes BERT text data.</p></td>
</tr>
<tr class="row-even"><td><p>JiebaTokenizer</p></td>
<td><p>Dictionary-based Chinese character string tokenizer.</p></td>
</tr>
<tr class="row-odd"><td><p>RegexTokenizer</p></td>
<td><p>Performs tokenization on scalar text data based on a specified regular expression.</p></td>
</tr>
<tr class="row-even"><td><p>SentencePieceTokenizer</p></td>
<td><p>Performs tokenization based on the open-source tool package SentencePiece.</p></td>
</tr>
<tr class="row-odd"><td><p>UnicodeCharTokenizer</p></td>
<td><p>Tokenizes scalar text data into Unicode characters.</p></td>
</tr>
<tr class="row-even"><td><p>UnicodeScriptTokenizer</p></td>
<td><p>Performs tokenization on scalar text data based on Unicode boundaries.</p></td>
</tr>
<tr class="row-odd"><td><p>WhitespaceTokenizer</p></td>
<td><p>Performs tokenization on scalar text data based on spaces.</p></td>
</tr>
<tr class="row-even"><td><p>WordpieceTokenizer</p></td>
<td><p>Performs tokenization on scalar text data based on the word set.</p></td>
</tr>
</tbody>
</table>
<p>For details about tokenizers, see <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.5/api_python/mindspore.dataset.text.html">MindSpore API</a>.</p>
</section>
<section id="mindspore-tokenizers">
<h2>MindSpore Tokenizers<a class="headerlink" href="#mindspore-tokenizers" title="Permalink to this headline">ïƒ</a></h2>
<p>The following describes how to use common tokenizers.</p>
<section id="berttokenizer">
<h3>BertTokenizer<a class="headerlink" href="#berttokenizer" title="Permalink to this headline">ïƒ</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">BertTokenizer</span></code> performs tokenization by calling <code class="docutils literal notranslate"><span class="pre">BasicTokenizer</span></code> and <code class="docutils literal notranslate"><span class="pre">WordpieceTokenizer</span></code>.</p>
<p>The following example builds a text dataset and a character string list, uses <code class="docutils literal notranslate"><span class="pre">BertTokenizer</span></code> to perform tokenization on the dataset, and displays the text results before and after tokenization.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.text</span> <span class="k">as</span> <span class="nn">text</span>

<span class="n">input_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;åºŠå‰æ˜æœˆå…‰&quot;</span><span class="p">,</span> <span class="s2">&quot;ç–‘æ˜¯åœ°ä¸Šéœœ&quot;</span><span class="p">,</span> <span class="s2">&quot;ä¸¾å¤´æœ›æ˜æœˆ&quot;</span><span class="p">,</span> <span class="s2">&quot;ä½å¤´æ€æ•…ä¹¡&quot;</span><span class="p">,</span> <span class="s2">&quot;I am making small mistakes during working hours&quot;</span><span class="p">,</span>
                <span class="s2">&quot;ğŸ˜€å˜¿å˜¿ğŸ˜ƒå“ˆå“ˆğŸ˜„å¤§ç¬‘ğŸ˜å˜»å˜»&quot;</span><span class="p">,</span> <span class="s2">&quot;ç¹é«”å­—&quot;</span><span class="p">]</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">input_list</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------before tokenization----------------------------&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>

<span class="n">vocab_list</span> <span class="o">=</span> <span class="p">[</span>
  <span class="s2">&quot;åºŠ&quot;</span><span class="p">,</span> <span class="s2">&quot;å‰&quot;</span><span class="p">,</span> <span class="s2">&quot;æ˜&quot;</span><span class="p">,</span> <span class="s2">&quot;æœˆ&quot;</span><span class="p">,</span> <span class="s2">&quot;å…‰&quot;</span><span class="p">,</span> <span class="s2">&quot;ç–‘&quot;</span><span class="p">,</span> <span class="s2">&quot;æ˜¯&quot;</span><span class="p">,</span> <span class="s2">&quot;åœ°&quot;</span><span class="p">,</span> <span class="s2">&quot;ä¸Š&quot;</span><span class="p">,</span> <span class="s2">&quot;éœœ&quot;</span><span class="p">,</span> <span class="s2">&quot;ä¸¾&quot;</span><span class="p">,</span> <span class="s2">&quot;å¤´&quot;</span><span class="p">,</span> <span class="s2">&quot;æœ›&quot;</span><span class="p">,</span> <span class="s2">&quot;ä½&quot;</span><span class="p">,</span> <span class="s2">&quot;æ€&quot;</span><span class="p">,</span> <span class="s2">&quot;æ•…&quot;</span><span class="p">,</span> <span class="s2">&quot;ä¹¡&quot;</span><span class="p">,</span>
  <span class="s2">&quot;ç¹&quot;</span><span class="p">,</span> <span class="s2">&quot;é«”&quot;</span><span class="p">,</span> <span class="s2">&quot;å­—&quot;</span><span class="p">,</span> <span class="s2">&quot;å˜¿&quot;</span><span class="p">,</span> <span class="s2">&quot;å“ˆ&quot;</span><span class="p">,</span> <span class="s2">&quot;å¤§&quot;</span><span class="p">,</span> <span class="s2">&quot;ç¬‘&quot;</span><span class="p">,</span> <span class="s2">&quot;å˜»&quot;</span><span class="p">,</span> <span class="s2">&quot;i&quot;</span><span class="p">,</span> <span class="s2">&quot;am&quot;</span><span class="p">,</span> <span class="s2">&quot;mak&quot;</span><span class="p">,</span> <span class="s2">&quot;make&quot;</span><span class="p">,</span> <span class="s2">&quot;small&quot;</span><span class="p">,</span> <span class="s2">&quot;mistake&quot;</span><span class="p">,</span>
  <span class="s2">&quot;##s&quot;</span><span class="p">,</span> <span class="s2">&quot;during&quot;</span><span class="p">,</span> <span class="s2">&quot;work&quot;</span><span class="p">,</span> <span class="s2">&quot;##ing&quot;</span><span class="p">,</span> <span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;ğŸ˜€&quot;</span><span class="p">,</span> <span class="s2">&quot;ğŸ˜ƒ&quot;</span><span class="p">,</span> <span class="s2">&quot;ğŸ˜„&quot;</span><span class="p">,</span> <span class="s2">&quot;ğŸ˜&quot;</span><span class="p">,</span> <span class="s2">&quot;+&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="s2">&quot;=&quot;</span><span class="p">,</span> <span class="s2">&quot;12&quot;</span><span class="p">,</span>
  <span class="s2">&quot;28&quot;</span><span class="p">,</span> <span class="s2">&quot;40&quot;</span><span class="p">,</span> <span class="s2">&quot;16&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot;I&quot;</span><span class="p">,</span> <span class="s2">&quot;[CLS]&quot;</span><span class="p">,</span> <span class="s2">&quot;[SEP]&quot;</span><span class="p">,</span> <span class="s2">&quot;[UNK]&quot;</span><span class="p">,</span> <span class="s2">&quot;[PAD]&quot;</span><span class="p">,</span> <span class="s2">&quot;[MASK]&quot;</span><span class="p">,</span> <span class="s2">&quot;[unused1]&quot;</span><span class="p">,</span> <span class="s2">&quot;[unused10]&quot;</span><span class="p">]</span>

<span class="n">vocab</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">Vocab</span><span class="o">.</span><span class="n">from_list</span><span class="p">(</span><span class="n">vocab_list</span><span class="p">)</span>
<span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">BertTokenizer</span><span class="p">(</span><span class="n">vocab</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------after tokenization-----------------------------&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>------------------------before tokenization----------------------------
åºŠå‰æ˜æœˆå…‰
ç–‘æ˜¯åœ°ä¸Šéœœ
ä¸¾å¤´æœ›æ˜æœˆ
ä½å¤´æ€æ•…ä¹¡
I am making small mistakes during working hours
ğŸ˜€å˜¿å˜¿ğŸ˜ƒå“ˆå“ˆğŸ˜„å¤§ç¬‘ğŸ˜å˜»å˜»
ç¹é«”å­—
------------------------after tokenization-----------------------------
[&#39;åºŠ&#39; &#39;å‰&#39; &#39;æ˜&#39; &#39;æœˆ&#39; &#39;å…‰&#39;]
[&#39;ç–‘&#39; &#39;æ˜¯&#39; &#39;åœ°&#39; &#39;ä¸Š&#39; &#39;éœœ&#39;]
[&#39;ä¸¾&#39; &#39;å¤´&#39; &#39;æœ›&#39; &#39;æ˜&#39; &#39;æœˆ&#39;]
[&#39;ä½&#39; &#39;å¤´&#39; &#39;æ€&#39; &#39;æ•…&#39; &#39;ä¹¡&#39;]
[&#39;I&#39; &#39;am&#39; &#39;mak&#39; &#39;##ing&#39; &#39;small&#39; &#39;mistake&#39; &#39;##s&#39; &#39;during&#39; &#39;work&#39; &#39;##ing&#39;
 &#39;hour&#39; &#39;##s&#39;]
[&#39;ğŸ˜€&#39; &#39;å˜¿&#39; &#39;å˜¿&#39; &#39;ğŸ˜ƒ&#39; &#39;å“ˆ&#39; &#39;å“ˆ&#39; &#39;ğŸ˜„&#39; &#39;å¤§&#39; &#39;ç¬‘&#39; &#39;ğŸ˜&#39; &#39;å˜»&#39; &#39;å˜»&#39;]
[&#39;ç¹&#39; &#39;é«”&#39; &#39;å­—&#39;]
</pre></div>
</div>
</section>
<section id="jiebatokenizer">
<h3>JiebaTokenizer<a class="headerlink" href="#jiebatokenizer" title="Permalink to this headline">ïƒ</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">JiebaTokenizer</span></code> performs Chinese tokenization based on Jieba.</p>
<p>Download the dictionary files <code class="docutils literal notranslate"><span class="pre">hmm_model.utf8</span></code> and <code class="docutils literal notranslate"><span class="pre">jieba.dict.utf8</span></code> and put them in the specified location.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>-N<span class="w"> </span>https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/datasets/hmm_model.utf8<span class="w"> </span>--no-check-certificate
wget<span class="w"> </span>-N<span class="w"> </span>https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/datasets/jieba.dict.utf8<span class="w"> </span>--no-check-certificate
mkdir<span class="w"> </span>-p<span class="w"> </span>./datasets/tokenizer/
mv<span class="w"> </span>hmm_model.utf8<span class="w"> </span>jieba.dict.utf8<span class="w"> </span>-t<span class="w"> </span>./datasets/tokenizer/
tree<span class="w"> </span>./datasets/tokenizer/
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./datasets/tokenizer/
â”œâ”€â”€ hmm_model.utf8
â””â”€â”€ jieba.dict.utf8

0 directories, 2 files
</pre></div>
</div>
<p>The following example builds a text dataset, uses the HMM and MP dictionary files to create a <code class="docutils literal notranslate"><span class="pre">JiebaTokenizer</span></code> object, performs tokenization on the dataset, and displays the text results before and after tokenization.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.text</span> <span class="k">as</span> <span class="nn">text</span>

<span class="n">input_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;ä»Šå¤©å¤©æ°”å¤ªå¥½äº†æˆ‘ä»¬ä¸€èµ·å»å¤–é¢ç©å§&quot;</span><span class="p">]</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">input_list</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------before tokenization----------------------------&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>

<span class="c1"># files from open source repository https://github.com/yanyiwu/cppjieba/tree/master/dict</span>
<span class="n">HMM_FILE</span> <span class="o">=</span> <span class="s2">&quot;./datasets/tokenizer/hmm_model.utf8&quot;</span>
<span class="n">MP_FILE</span> <span class="o">=</span> <span class="s2">&quot;./datasets/tokenizer/jieba.dict.utf8&quot;</span>
<span class="n">jieba_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">JiebaTokenizer</span><span class="p">(</span><span class="n">HMM_FILE</span><span class="p">,</span> <span class="n">MP_FILE</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">jieba_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------after tokenization-----------------------------&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>------------------------before tokenization----------------------------
ä»Šå¤©å¤©æ°”å¤ªå¥½äº†æˆ‘ä»¬ä¸€èµ·å»å¤–é¢ç©å§
------------------------after tokenization-----------------------------
[&#39;ä»Šå¤©å¤©æ°”&#39; &#39;å¤ªå¥½äº†&#39; &#39;æˆ‘ä»¬&#39; &#39;ä¸€èµ·&#39; &#39;å»&#39; &#39;å¤–é¢&#39; &#39;ç©å§&#39;]
</pre></div>
</div>
</section>
<section id="sentencepiecetokenizer">
<h3>SentencePieceTokenizer<a class="headerlink" href="#sentencepiecetokenizer" title="Permalink to this headline">ïƒ</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">SentencePieceTokenizer</span></code> performs tokenization based on an open-source natural language processing tool package <a class="reference external" href="https://github.com/google/sentencepiece">SentencePiece</a>.</p>
<p>Download the text dataset file <code class="docutils literal notranslate"><span class="pre">botchan.txt</span></code> and place it in the specified location.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>-N<span class="w"> </span>https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/datasets/botchan.txt<span class="w"> </span>--no-check-certificate
mkdir<span class="w"> </span>-p<span class="w"> </span>./datasets/tokenizer/
mv<span class="w"> </span>botchan.txt<span class="w"> </span>./datasets/tokenizer/
tree<span class="w"> </span>./datasets/tokenizer/
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./datasets/tokenizer/
â””â”€â”€ botchan.txt

0 directories, 1 files
</pre></div>
</div>
<p>The following example builds a text dataset, creates a <code class="docutils literal notranslate"><span class="pre">vocab</span></code> object from the <code class="docutils literal notranslate"><span class="pre">vocab_file</span></code> file, uses <code class="docutils literal notranslate"><span class="pre">SentencePieceTokenizer</span></code> to perform tokenization on the dataset, and displays the text results before and after tokenization.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.text</span> <span class="k">as</span> <span class="nn">text</span>
<span class="kn">from</span> <span class="nn">mindspore.dataset.text</span> <span class="kn">import</span> <span class="n">SentencePieceModel</span><span class="p">,</span> <span class="n">SPieceTokenizerOutType</span>

<span class="n">input_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;I saw a girl with a telescope.&quot;</span><span class="p">]</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">input_list</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------before tokenization----------------------------&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>

<span class="c1"># file from MindSpore repository https://gitee.com/mindspore/mindspore/blob/r1.5/tests/ut/data/dataset/test_sentencepiece/botchan.txt</span>
<span class="n">vocab_file</span> <span class="o">=</span> <span class="s2">&quot;./datasets/tokenizer/botchan.txt&quot;</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">SentencePieceVocab</span><span class="o">.</span><span class="n">from_file</span><span class="p">([</span><span class="n">vocab_file</span><span class="p">],</span> <span class="mi">5000</span><span class="p">,</span> <span class="mf">0.9995</span><span class="p">,</span> <span class="n">SentencePieceModel</span><span class="o">.</span><span class="n">UNIGRAM</span><span class="p">,</span> <span class="p">{})</span>
<span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">SentencePieceTokenizer</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">SPieceTokenizerOutType</span><span class="o">.</span><span class="n">STRING</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------after tokenization-----------------------------&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>------------------------before tokenization----------------------------
I saw a girl with a telescope.
------------------------after tokenization-----------------------------
[&#39;â–I&#39; &#39;â–sa&#39; &#39;w&#39; &#39;â–a&#39; &#39;â–girl&#39; &#39;â–with&#39; &#39;â–a&#39; &#39;â–te&#39; &#39;les&#39; &#39;co&#39; &#39;pe&#39; &#39;.&#39;]
</pre></div>
</div>
</section>
<section id="unicodechartokenizer">
<h3>UnicodeCharTokenizer<a class="headerlink" href="#unicodechartokenizer" title="Permalink to this headline">ïƒ</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">UnicodeCharTokenizer</span></code> performs tokenization based on the Unicode character set.</p>
<p>The following example builds a text dataset, uses <code class="docutils literal notranslate"><span class="pre">UnicodeCharTokenizer</span></code> to perform tokenization on the dataset, and displays the text results before and after tokenization.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.text</span> <span class="k">as</span> <span class="nn">text</span>

<span class="n">input_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Welcome to Beijing!&quot;</span><span class="p">,</span> <span class="s2">&quot;åŒ—äº¬æ¬¢è¿æ‚¨ï¼&quot;</span><span class="p">,</span> <span class="s2">&quot;æˆ‘å–œæ¬¢English!&quot;</span><span class="p">]</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">input_list</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------before tokenization----------------------------&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>

<span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">UnicodeCharTokenizer</span><span class="p">()</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------after tokenization-----------------------------&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>------------------------before tokenization----------------------------
Welcome to Beijing!
åŒ—äº¬æ¬¢è¿æ‚¨ï¼
æˆ‘å–œæ¬¢English!
------------------------after tokenization-----------------------------
[&#39;W&#39;, &#39;e&#39;, &#39;l&#39;, &#39;c&#39;, &#39;o&#39;, &#39;m&#39;, &#39;e&#39;, &#39; &#39;, &#39;t&#39;, &#39;o&#39;, &#39; &#39;, &#39;B&#39;, &#39;e&#39;, &#39;i&#39;, &#39;j&#39;, &#39;i&#39;, &#39;n&#39;, &#39;g&#39;, &#39;!&#39;]
[&#39;åŒ—&#39;, &#39;äº¬&#39;, &#39;æ¬¢&#39;, &#39;è¿&#39;, &#39;æ‚¨&#39;, &#39;ï¼&#39;]
[&#39;æˆ‘&#39;, &#39;å–œ&#39;, &#39;æ¬¢&#39;, &#39;E&#39;, &#39;n&#39;, &#39;g&#39;, &#39;l&#39;, &#39;i&#39;, &#39;s&#39;, &#39;h&#39;, &#39;!&#39;]
</pre></div>
</div>
</section>
<section id="whitespacetokenizer">
<h3>WhitespaceTokenizer<a class="headerlink" href="#whitespacetokenizer" title="Permalink to this headline">ïƒ</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">WhitespaceTokenizer</span></code> performs tokenization based on spaces.</p>
<p>The following example builds a text dataset, uses <code class="docutils literal notranslate"><span class="pre">WhitespaceTokenizer</span></code> to perform tokenization on the dataset, and displays the text results before and after tokenization.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.text</span> <span class="k">as</span> <span class="nn">text</span>

<span class="n">input_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Welcome to Beijing!&quot;</span><span class="p">,</span> <span class="s2">&quot;åŒ—äº¬æ¬¢è¿æ‚¨ï¼&quot;</span><span class="p">,</span> <span class="s2">&quot;æˆ‘å–œæ¬¢English!&quot;</span><span class="p">]</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">input_list</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------before tokenization----------------------------&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>

<span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">WhitespaceTokenizer</span><span class="p">()</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------after tokenization-----------------------------&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>------------------------before tokenization----------------------------
Welcome to Beijing!
åŒ—äº¬æ¬¢è¿æ‚¨ï¼
æˆ‘å–œæ¬¢English!
------------------------after tokenization-----------------------------
[&#39;Welcome&#39;, &#39;to&#39;, &#39;Beijing!&#39;]
[&#39;åŒ—äº¬æ¬¢è¿æ‚¨ï¼&#39;]
[&#39;æˆ‘å–œæ¬¢English!&#39;]
</pre></div>
</div>
</section>
<section id="wordpiecetokenizer">
<h3>WordpieceTokenizer<a class="headerlink" href="#wordpiecetokenizer" title="Permalink to this headline">ïƒ</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">WordpieceTokenizer</span></code> performs tokenization based on the word set. A token can be a single word in the word set or a combination of words.</p>
<p>The following example builds a text dataset, creates a <code class="docutils literal notranslate"><span class="pre">vocab</span></code> object from the word list, uses <code class="docutils literal notranslate"><span class="pre">WordpieceTokenizer</span></code> to perform tokenization on the dataset, and displays the text results before and after tokenization.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.text</span> <span class="k">as</span> <span class="nn">text</span>

<span class="n">input_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;my&quot;</span><span class="p">,</span> <span class="s2">&quot;favorite&quot;</span><span class="p">,</span> <span class="s2">&quot;book&quot;</span><span class="p">,</span> <span class="s2">&quot;is&quot;</span><span class="p">,</span> <span class="s2">&quot;love&quot;</span><span class="p">,</span> <span class="s2">&quot;during&quot;</span><span class="p">,</span> <span class="s2">&quot;the&quot;</span><span class="p">,</span> <span class="s2">&quot;cholera&quot;</span><span class="p">,</span> <span class="s2">&quot;era&quot;</span><span class="p">,</span> <span class="s2">&quot;what&quot;</span><span class="p">,</span>
    <span class="s2">&quot;æˆ‘&quot;</span><span class="p">,</span> <span class="s2">&quot;æœ€&quot;</span><span class="p">,</span> <span class="s2">&quot;å–œ&quot;</span><span class="p">,</span> <span class="s2">&quot;æ¬¢&quot;</span><span class="p">,</span> <span class="s2">&quot;çš„&quot;</span><span class="p">,</span> <span class="s2">&quot;ä¹¦&quot;</span><span class="p">,</span> <span class="s2">&quot;æ˜¯&quot;</span><span class="p">,</span> <span class="s2">&quot;éœ&quot;</span><span class="p">,</span> <span class="s2">&quot;ä¹±&quot;</span><span class="p">,</span> <span class="s2">&quot;æ—¶&quot;</span><span class="p">,</span> <span class="s2">&quot;æœŸ&quot;</span><span class="p">,</span> <span class="s2">&quot;çš„&quot;</span><span class="p">,</span> <span class="s2">&quot;çˆ±&quot;</span><span class="p">,</span> <span class="s2">&quot;æƒ…&quot;</span><span class="p">,</span> <span class="s2">&quot;æ‚¨&quot;</span><span class="p">]</span>
<span class="n">vocab_english</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;book&quot;</span><span class="p">,</span> <span class="s2">&quot;cholera&quot;</span><span class="p">,</span> <span class="s2">&quot;era&quot;</span><span class="p">,</span> <span class="s2">&quot;favor&quot;</span><span class="p">,</span> <span class="s2">&quot;##ite&quot;</span><span class="p">,</span> <span class="s2">&quot;my&quot;</span><span class="p">,</span> <span class="s2">&quot;is&quot;</span><span class="p">,</span> <span class="s2">&quot;love&quot;</span><span class="p">,</span> <span class="s2">&quot;dur&quot;</span><span class="p">,</span> <span class="s2">&quot;##ing&quot;</span><span class="p">,</span> <span class="s2">&quot;the&quot;</span><span class="p">]</span>
<span class="n">vocab_chinese</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;æˆ‘&quot;</span><span class="p">,</span> <span class="s1">&#39;æœ€&#39;</span><span class="p">,</span> <span class="s1">&#39;å–œ&#39;</span><span class="p">,</span> <span class="s1">&#39;æ¬¢&#39;</span><span class="p">,</span> <span class="s1">&#39;çš„&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¹¦&#39;</span><span class="p">,</span> <span class="s1">&#39;æ˜¯&#39;</span><span class="p">,</span> <span class="s1">&#39;éœ&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¹±&#39;</span><span class="p">,</span> <span class="s1">&#39;æ—¶&#39;</span><span class="p">,</span> <span class="s1">&#39;æœŸ&#39;</span><span class="p">,</span> <span class="s1">&#39;çˆ±&#39;</span><span class="p">,</span> <span class="s1">&#39;æƒ…&#39;</span><span class="p">]</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">NumpySlicesDataset</span><span class="p">(</span><span class="n">input_list</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------before tokenization----------------------------&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>

<span class="n">vocab</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">Vocab</span><span class="o">.</span><span class="n">from_list</span><span class="p">(</span><span class="n">vocab_english</span><span class="o">+</span><span class="n">vocab_chinese</span><span class="p">)</span>
<span class="n">tokenizer_op</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">WordpieceTokenizer</span><span class="p">(</span><span class="n">vocab</span><span class="o">=</span><span class="n">vocab</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">tokenizer_op</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------after tokenization-----------------------------&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">to_str</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>------------------------before tokenization----------------------------
my
favorite
book
is
love
during
the
cholera
era
what
æˆ‘
æœ€
å–œ
æ¬¢
çš„
ä¹¦
æ˜¯
éœ
ä¹±
æ—¶
æœŸ
çš„
çˆ±
æƒ…
æ‚¨
------------------------after tokenization-----------------------------
[&#39;my&#39;]
[&#39;favor&#39; &#39;##ite&#39;]
[&#39;book&#39;]
[&#39;is&#39;]
[&#39;love&#39;]
[&#39;dur&#39; &#39;##ing&#39;]
[&#39;the&#39;]
[&#39;cholera&#39;]
[&#39;era&#39;]
[&#39;[UNK]&#39;]
[&#39;æˆ‘&#39;]
[&#39;æœ€&#39;]
[&#39;å–œ&#39;]
[&#39;æ¬¢&#39;]
[&#39;çš„&#39;]
[&#39;ä¹¦&#39;]
[&#39;æ˜¯&#39;]
[&#39;éœ&#39;]
[&#39;ä¹±&#39;]
[&#39;æ—¶&#39;]
[&#39;æœŸ&#39;]
[&#39;çš„&#39;]
[&#39;çˆ±&#39;]
[&#39;æƒ…&#39;]
[&#39;[UNK]&#39;]
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="augmentation.html" class="btn btn-neutral float-left" title="Image Data Processing and Enhancement" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="eager.html" class="btn btn-neutral float-right" title="Lightweight Data Processing" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>