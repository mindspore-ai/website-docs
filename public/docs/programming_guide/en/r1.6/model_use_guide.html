<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Basic Use of Model &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/training.css" type="text/css" /><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/js/training.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Callback Mechanism" href="callback.html" />
    <link rel="prev" title="Application of Model" href="model.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Overall Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/technical_white_paper.html">Technical White Paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/gradient.html">MindSpore Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.6/training_visual_design.html">Design of Visualization↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.6/linear_regression.html">Implementing Simple Linear Function Fitting↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.6/quick_start.html">Implementing an Image Classification Application↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dtype.html">DataType</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter_introduction.html">Parameter</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="cell.html">Cell</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_introduction.html">Dataset</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Pipeline</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataset_sample.html">Quick Start of Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Processing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_advanced.html">Advanced Usage of Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_usage.html">Data Iteration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build the Network</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="build_net.html">Constructing Single Operator Network and Multi-layer Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="initializer.html">Initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter.html">Network Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="control_flow.html">Using the Process Control Statement</a></li>
<li class="toctree-l1"><a class="reference internal" href="indefinite_parameter.html">Parameter Passing</a></li>
<li class="toctree-l1"><a class="reference internal" href="loss.html">Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="grad_operation.html">Gradient Operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="constexpr.html">Construct Constants In the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypermap.html">Operation Overloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">Optimization Algorithms</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Running</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="context.html">Configuring Running Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="run.html">Running Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_and_load_models.html">Save and Load Models</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="model.html">Application of Model</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Basic Use of Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#basic-introduction-of-model">Basic Introduction of Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-training-evaluation-and-inference">Model Training, Evaluation and Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-applications-for-custom-scenarios">Model Applications for Custom Scenarios</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#connect-forward-network-with-loss-function-manually">Connect Forward Network with Loss Function Manually</a></li>
<li class="toctree-l4"><a class="reference internal" href="#custom-training-network">Custom Training Network</a></li>
<li class="toctree-l4"><a class="reference internal" href="#weight-sharing-of-custom-network">Weight Sharing of Custom Network</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="callback.html">Callback Mechanism</a></li>
<li class="toctree-l2"><a class="reference internal" href="self_define_metric.html">Customize Metrics to Verify Model Evaluation Accuracy</a></li>
<li class="toctree-l2"><a class="reference internal" href="evaluate_the_model_during_training.html">Evaluating the Model during Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="on_device.html">On-Device Execution</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="online_inference.html">Online Inference with Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="offline_inference.html">Using Offline Model for Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">Distributed Parallel Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_advanced.html">Distributed Parallel Advanced Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_example.html">Distributed Parallel Usage Example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyNative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Numpy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">NumPy Interfaces in MindSpore</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Function Debugging</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="read_ir_files.html">Reading IR</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/debug_in_pynative_mode.html">Debugging in PyNative Mode↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_tune.html">AutoTune</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_dataset_autotune.html">Dataset AutoTune for Dataset Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_dataset_offload.html">Enabling Offload for Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.6/performance_profiling.html">Debugging performance with Profiler↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="second_order_optimizer.html">Second Order Optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_kernel_fusion.html">Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Quantization Aware Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="model.html">Application of Model</a> &raquo;</li>
      <li>Basic Use of Model</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/model_use_guide.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="basic-use-of-model">
<h1>Basic Use of Model<a class="headerlink" href="#basic-use-of-model" title="Permalink to this headline"></a></h1>
<p>Translator: <a class="reference external" href="https://gitee.com/deng-zhihua">Soleil</a></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Development</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.6/docs/mindspore/programming_guide/source_en/model_use_guide.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.6/resource/_static/logo_source_en.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>BUILD THE NETWORK of <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/index.html">Programming Guide</a>describes how to define the forward network, loss function and optimizer. In addition, it shows how to encapsulate these structures into training and evaluating networks and execute them. On this basis, this document is about how to use the high-level API <code class="docutils literal notranslate"><span class="pre">Model</span></code> for training and evaluating models.</p>
<p>In general, it is sufficient for basic needs when you can define training and evaluating networks and run them directly. However, it is still recommended to train and evaluate models by <code class="docutils literal notranslate"><span class="pre">Model</span></code>. On the one hand, <code class="docutils literal notranslate"><span class="pre">Model</span></code> can simplify the code in some degree. For example, there is no need to manually traverse the dataset. In the case without the need to customize <code class="docutils literal notranslate"><span class="pre">TrainOneStepCell</span></code>, <code class="docutils literal notranslate"><span class="pre">Model</span></code> can be used to automatically build the training network. The <code class="docutils literal notranslate"><span class="pre">eval</span></code> interface of <code class="docutils literal notranslate"><span class="pre">Model</span></code> can be used for model evaluation with direct output of evaluation results, which is not necessary to invoke the evaluation indicators’ functions such as <code class="docutils literal notranslate"><span class="pre">clear</span></code>, <code class="docutils literal notranslate"><span class="pre">update</span></code>, <code class="docutils literal notranslate"><span class="pre">eval</span></code>. On the other hand, <code class="docutils literal notranslate"><span class="pre">Model</span></code> provides many high-level functions, such as data sinking and mixing accuracy. Without the help of <code class="docutils literal notranslate"><span class="pre">Model</span></code>, it would take more time to use these functions by imitating <code class="docutils literal notranslate"><span class="pre">Model</span></code> for customization.</p>
<p>This document starts with a basic introduction of Model, and then focuses on how to use <code class="docutils literal notranslate"><span class="pre">Model</span></code> for Model Training, Evaluation and Inference.</p>
<blockquote>
<div><p>In the following example, the parameter initialization uses random values, which may result in different outputs from local execution. If you need a stable output of fixed values, you can set a fixed random seed. The setting method can be referred to <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.6/api_python/mindspore/mindspore.set_seed.html">mindspore.set_seed()</a>.</p>
</div></blockquote>
</section>
<section id="basic-introduction-of-model">
<h2>Basic Introduction of Model<a class="headerlink" href="#basic-introduction-of-model" title="Permalink to this headline"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">Model</span></code> is a high-level API for model training provided by MindSpore, which can be used for model training, evaluation and inference.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Model</span></code> contains the following input parameters:</p>
<ul class="simple">
<li><p>network (Cell)：In general, it is a forward network which inputs data and labels, and outputs predicted values.</p></li>
<li><p>loss_fn (Cell)：The loss function used.</p></li>
<li><p>optimizer (Cell)：The optimizer used.</p></li>
<li><p>metrics (set)：Evaluation metrics used for model evaluation. The default value <code class="docutils literal notranslate"><span class="pre">None</span></code> will be used when there is no need for model evaluation.</p></li>
<li><p>eval_network (Cell)：The network used for model evaluation which does not need to be specified in some simple cases.</p></li>
<li><p>eval_indexes (List)：It is used to indicate the meaning of the evaluation network output in combination with <code class="docutils literal notranslate"><span class="pre">eval_network</span></code>. The function of this parameter can be replaced by <code class="docutils literal notranslate"><span class="pre">set_indexes</span></code> of <code class="docutils literal notranslate"><span class="pre">nn.Metric</span></code>. It is recommenced to use <code class="docutils literal notranslate"><span class="pre">set_indexes</span></code>.</p></li>
<li><p>amp_level (str)：It is used to specify the mixed accuracy level.</p></li>
<li><p>kwargs：It can configure overflow detection and mixed accuracy policies.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Model</span></code> provides the following interfaces for model training, evaluation and inference:</p>
<ul class="simple">
<li><p>train：It is used for model training on the training set.</p></li>
<li><p>eval：It is used for model evaluation on the validation set.</p></li>
<li><p>predict：It is used to inference over the input dataset and output the prediction result.</p></li>
</ul>
</section>
<section id="model-training-evaluation-and-inference">
<h2>Model Training, Evaluation and Inference<a class="headerlink" href="#model-training-evaluation-and-inference" title="Permalink to this headline"></a></h2>
<p>For neural networks in simple scenarios, the forward network <code class="docutils literal notranslate"><span class="pre">network</span></code>, loss function <code class="docutils literal notranslate"><span class="pre">loss_fn</span></code>, optimizer <code class="docutils literal notranslate"><span class="pre">optimizer</span></code> and evaluation metrics <code class="docutils literal notranslate"><span class="pre">metrics</span></code> can be specified during defining <code class="docutils literal notranslate"><span class="pre">Model</span></code>. In this case, Model will use <code class="docutils literal notranslate"><span class="pre">network</span></code> as the inference network and build the training network using <code class="docutils literal notranslate"><span class="pre">nn.WithLossCell</span></code> and <code class="docutils literal notranslate"><span class="pre">nn.TrainOneStepCell</span></code> as well as build the evaluation network using <code class="docutils literal notranslate"><span class="pre">nn.WithEvalCell</span></code>.</p>
<p>Take the linear regression used in <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.6/train_and_eval.html">Build Training and Evaluating Network</a> as an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">Normal</span>

<span class="k">class</span> <span class="nc">LinearNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">),</span> <span class="n">Normal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">LinearNet</span><span class="p">()</span>
<span class="c1"># Set Loss Function</span>
<span class="n">crit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="c1"># Set Optimizer</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="c1"># Set Evaluation Metrics</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;mae&quot;</span><span class="p">}</span>
</pre></div>
</div>
<p><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.6/train_and_eval.html">Build Training and Evaluating Network</a> describes the way to build and directly run training and evaluating networks via <code class="docutils literal notranslate"><span class="pre">nn.</span> <span class="pre">WithLossCell</span></code>, <code class="docutils literal notranslate"><span class="pre">nn.TrainOneStepCell</span></code> and <code class="docutils literal notranslate"><span class="pre">nn.WithEvalCell</span></code>. When using <code class="docutils literal notranslate"><span class="pre">Model</span></code>, there is no need to build the training and evaluating networks manually. You can use the following way to define <code class="docutils literal notranslate"><span class="pre">Model</span></code> and invoke <code class="docutils literal notranslate"><span class="pre">train</span></code> and <code class="docutils literal notranslate"><span class="pre">eval</span></code> interfaces to achieve the same effect.</p>
<p>Create training and validation sets:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">3.0</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">noise</span>
        <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">num_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">get_data</span><span class="p">(</span><span class="n">num_data</span><span class="p">)),</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dataset</span>

<span class="c1"># Create Dataset</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">num_data</span><span class="o">=</span><span class="mi">160</span><span class="p">)</span>
<span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">num_data</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
</pre></div>
</div>
<p>Define Model and perform training, and check the value of the loss function during training by the <code class="docutils literal notranslate"><span class="pre">LossMonitor</span></code> callback function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">LossMonitor</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">crit</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>
<span class="c1"># Acquire Training Process Data</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">LossMonitor</span><span class="p">()],</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>The implementation results are as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch: 1 step: 1, loss is 158.6485
epoch: 1 step: 2, loss is 56.015274
epoch: 1 step: 3, loss is 22.507223
epoch: 1 step: 4, loss is 29.29523
epoch: 1 step: 5, loss is 54.613194
epoch: 1 step: 6, loss is 119.0715
epoch: 1 step: 7, loss is 47.707245
epoch: 1 step: 8, loss is 6.823062
epoch: 1 step: 9, loss is 12.838973
epoch: 1 step: 10, loss is 24.879482
epoch: 2 step: 1, loss is 38.01019
epoch: 2 step: 2, loss is 34.66765
epoch: 2 step: 3, loss is 13.370583
epoch: 2 step: 4, loss is 3.0936844
epoch: 2 step: 5, loss is 6.6003437
epoch: 2 step: 6, loss is 19.703354
epoch: 2 step: 7, loss is 28.276491
epoch: 2 step: 8, loss is 10.402792
epoch: 2 step: 9, loss is 6.908296
epoch: 2 step: 10, loss is 1.5971221
</pre></div>
</div>
<p>Perform model evaluation and obtain the results:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">eval_result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">eval_result</span><span class="p">)</span>
</pre></div>
</div>
<p>The implementation results are as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{&#39;mae&#39;: 2.4565244197845457}
</pre></div>
</div>
<p>Inference using <code class="docutils literal notranslate"><span class="pre">predict</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">eval_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]</span>
    <span class="k">break</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The implementation results are as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[ 13.330149  ]
 [ -3.380001  ]
 [ 11.5734005 ]
 [ -0.84721684]
 [ 11.391014  ]
 [ -9.029837  ]
 [  1.1881653 ]
 [  2.1025467 ]
 [ 13.401606  ]
 [  1.8194647 ]
 [  8.862836  ]
 [ 14.427877  ]
 [  4.330497  ]
 [-12.431898  ]
 [ -4.5104184 ]
 [  9.439548  ]]
</pre></div>
</div>
<p>In general, post-processing on the inference results is required to obtain more intuitive inference results.</p>
<p>Compared to building the network and then running it directly, there is no need for <code class="docutils literal notranslate"><span class="pre">set_train</span></code> to configure the execution patterns of the network structure when using Model for model training, inference and evaluation.</p>
</section>
<section id="model-applications-for-custom-scenarios">
<h2>Model Applications for Custom Scenarios<a class="headerlink" href="#model-applications-for-custom-scenarios" title="Permalink to this headline"></a></h2>
<p>As already mentioned in <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/loss.html">Loss Function</a> and <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.6/train_and_eval.html">Build Training and Evaluating Network</a>, the network encapsulation functions <code class="docutils literal notranslate"><span class="pre">nn.WithLossCell</span></code>, <code class="docutils literal notranslate"><span class="pre">nn.TrainOneStepCell</span></code> and <code class="docutils literal notranslate"><span class="pre">nn.WithEvalCell</span></code> provided by MindSpore are not applicable to all scenarios which means we often need to customize the encapsulation method of the network in real scenarios. In such cases it is obviously not reasonable for <code class="docutils literal notranslate"><span class="pre">Model</span></code> to use these encapsulation functions to encapsulate automatically. The next section will introduce how to properly use <code class="docutils literal notranslate"><span class="pre">Model</span></code> in these cases.</p>
<section id="connect-forward-network-with-loss-function-manually">
<h3>Connect Forward Network with Loss Function Manually<a class="headerlink" href="#connect-forward-network-with-loss-function-manually" title="Permalink to this headline"></a></h3>
<p>In scenarios with multiple data or multiple labels, you can manually link the forward network with the custom loss function as the <code class="docutils literal notranslate"><span class="pre">network</span></code> of the <code class="docutils literal notranslate"><span class="pre">model</span></code>, with the default value of <code class="docutils literal notranslate"><span class="pre">None</span></code> for <code class="docutils literal notranslate"><span class="pre">loss_fn</span></code>. Then, <code class="docutils literal notranslate"><span class="pre">model</span></code> will directly use <code class="docutils literal notranslate"><span class="pre">nn.TrainOneStepCell</span></code> to form <code class="docutils literal notranslate"><span class="pre">network</span></code> and <code class="docutils literal notranslate"><span class="pre">optimizer</span></code> into a training network without going through <code class="docutils literal notranslate"><span class="pre">nn.WithLossCell</span></code>.</p>
<p>The following example is from the <code class="docutils literal notranslate"><span class="pre">Loss</span> <span class="pre">Function</span></code> <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/loss.html">https://www.mindspore.cn/docs/programming_guide/en/r1.6/loss.html</a>:</p>
<ol class="arabic">
<li><p>Define Multi-Label Datasets</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>

<span class="k">def</span> <span class="nf">get_multilabel_data</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">3.0</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
        <span class="n">noise1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">noise2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">y1</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">noise1</span>
        <span class="n">y2</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">noise2</span>
        <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y2</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">create_multilabel_dataset</span><span class="p">(</span><span class="n">num_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">get_multilabel_data</span><span class="p">(</span><span class="n">num_data</span><span class="p">)),</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;label1&#39;</span><span class="p">,</span> <span class="s1">&#39;label2&#39;</span><span class="p">])</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dataset</span>
</pre></div>
</div>
</li>
<li><p>Customized Multi-Label Loss Function</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">LossBase</span>

<span class="k">class</span> <span class="nc">L1LossForMultiLabel</span><span class="p">(</span><span class="n">LossBase</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">L1LossForMultiLabel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">reduction</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">abs</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Abs</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base</span><span class="p">,</span> <span class="n">target1</span><span class="p">,</span> <span class="n">target2</span><span class="p">):</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">base</span> <span class="o">-</span> <span class="n">target1</span><span class="p">)</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">base</span> <span class="o">-</span> <span class="n">target2</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_loss</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_loss</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
</pre></div>
</div>
</li>
<li><p>Connect the forward network and the loss function, where <code class="docutils literal notranslate"><span class="pre">net</span></code> uses <code class="docutils literal notranslate"><span class="pre">LinearNet</span></code> defined in the previous section</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">CustomWithLossCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">backbone</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CustomWithLossCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_backbone</span> <span class="o">=</span> <span class="n">backbone</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">label1</span><span class="p">,</span> <span class="n">label2</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backbone</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label1</span><span class="p">,</span> <span class="n">label2</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">LinearNet</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">L1LossForMultiLabel</span><span class="p">()</span>
<span class="n">loss_net</span> <span class="o">=</span> <span class="n">CustomWithLossCell</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Define Model and Perform Training</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">LossMonitor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="n">opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="o">=</span><span class="n">loss_net</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">)</span>
<span class="n">multi_train_dataset</span> <span class="o">=</span> <span class="n">create_multilabel_dataset</span><span class="p">(</span><span class="n">num_data</span><span class="o">=</span><span class="mi">160</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">=</span><span class="n">multi_train_dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">LossMonitor</span><span class="p">()],</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>The implementation results are as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch: 1 step: 1, loss is 2.7395597
epoch: 1 step: 2, loss is 3.730921
epoch: 1 step: 3, loss is 6.393111
epoch: 1 step: 4, loss is 5.684395
epoch: 1 step: 5, loss is 6.089678
epoch: 1 step: 6, loss is 8.953241
epoch: 1 step: 7, loss is 9.357056
epoch: 1 step: 8, loss is 8.601417
epoch: 1 step: 9, loss is 9.339062
epoch: 1 step: 10, loss is 7.6557174
</pre></div>
</div>
</li>
<li><p>Model Evaluation</p>
<p><code class="docutils literal notranslate"><span class="pre">Model</span></code> uses <code class="docutils literal notranslate"><span class="pre">nn.WithEvalCell</span></code> to build the evaluation network by default, but it is also necessary to build the evaluating network manually when the demand is not satisfied, such as a typical case with multiple data and multiple labels. <code class="docutils literal notranslate"><span class="pre">Model</span></code> provides <code class="docutils literal notranslate"><span class="pre">eval_network</span></code> for setting up a custom evaluating network. The manual construction of the evaluating network is as follows:</p>
<p>Encapsulation method for the custom evaluation network：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">CustomWithEvalCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CustomWithEvalCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">label1</span><span class="p">,</span> <span class="n">label2</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">label1</span><span class="p">,</span> <span class="n">label2</span>
</pre></div>
</div>
<p>Build the Evaluating Network manually：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">eval_net</span> <span class="o">=</span> <span class="n">CustomWithEvalCell</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</pre></div>
</div>
<p>Use Model for model evaluation：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">LossMonitor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="n">mae1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MAE</span><span class="p">()</span>
<span class="n">mae2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MAE</span><span class="p">()</span>
<span class="n">mae1</span><span class="o">.</span><span class="n">set_indexes</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">mae2</span><span class="o">.</span><span class="n">set_indexes</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">network</span><span class="o">=</span><span class="n">loss_net</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">eval_network</span><span class="o">=</span><span class="n">eval_net</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;mae1&quot;</span><span class="p">:</span> <span class="n">mae1</span><span class="p">,</span> <span class="s2">&quot;mae2&quot;</span><span class="p">:</span> <span class="n">mae2</span><span class="p">})</span>
<span class="n">multi_eval_dataset</span> <span class="o">=</span> <span class="n">create_multilabel_dataset</span><span class="p">(</span><span class="n">num_data</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">multi_eval_dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
<p>The implementation results are as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{&#39;mae1&#39;: 8.572821712493896, &#39;mae2&#39;: 8.346409797668457}
</pre></div>
</div>
<ul class="simple">
<li><p>When performing model evaluation, the output of the evaluation network will be transmitted to the <code class="docutils literal notranslate"><span class="pre">update</span></code> function of the evaluation metrics. In other words, the <code class="docutils literal notranslate"><span class="pre">update</span></code> function will receive three inputs, which are <code class="docutils literal notranslate"><span class="pre">logits</span></code>, <code class="docutils literal notranslate"><span class="pre">label1</span></code> and <code class="docutils literal notranslate"><span class="pre">label2</span></code>. <code class="docutils literal notranslate"><span class="pre">nn.MAE</span></code> only allows to calculate evaluation metrics on two inputs. Therefore, <code class="docutils literal notranslate"><span class="pre">set_indexes</span></code> is used to specify <code class="docutils literal notranslate"><span class="pre">mae1</span></code> to calculate evaluation results using inputs with subscripts 0 and 1, i.e. <code class="docutils literal notranslate"><span class="pre">logits</span></code> and <code class="docutils literal notranslate"><span class="pre">label1</span></code>. It is also used to specify <code class="docutils literal notranslate"><span class="pre">mae2</span></code> to calculate evaluation results using inputs with subscripts 0 and 2, i.e. <code class="docutils literal notranslate"><span class="pre">logits</span></code> and <code class="docutils literal notranslate"><span class="pre">label2</span></code>.</p></li>
<li><p>In practice, it is often necessary for all tags to participate in the evaluation. In this case, you need to customize <code class="docutils literal notranslate"><span class="pre">Metric</span></code> to flexibly use all outputs of the evaluation network to calculate the evaluation results. The details of the <code class="docutils literal notranslate"><span class="pre">Metric</span></code> customized method can be found at: <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/self_define_metric.html">https://www.mindspore.cn/docs/programming_guide/en/r1.6/self_define_metric.html</a>.</p></li>
</ul>
</li>
<li><p>Inference</p>
<p><code class="docutils literal notranslate"><span class="pre">Model</span></code> does not provide parameters for specifying the custom inference network, so you can run the forward network directly to get the inference results.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">multi_eval_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]</span>
    <span class="k">break</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The implementation results are as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[ 7.147398  ]
[ 3.4073524 ]
[ 7.1618156 ]
[ 1.8599509 ]
[ 0.8132744 ]
[ 4.92359   ]
[ 0.6972816 ]
[ 6.6525955 ]
[ 1.2478441 ]
[ 2.791972  ]
[-1.2134678 ]
[ 7.424588  ]
[ 0.24634433]
[ 7.15598   ]
[ 0.68831706]
[ 6.171982  ]]
</pre></div>
</div>
</li>
</ol>
</section>
<section id="custom-training-network">
<h3>Custom Training Network<a class="headerlink" href="#custom-training-network" title="Permalink to this headline"></a></h3>
<p>When customizing <code class="docutils literal notranslate"><span class="pre">TrainOneStepCell</span></code>, you need to manually build the training network as <code class="docutils literal notranslate"><span class="pre">network</span></code> of <code class="docutils literal notranslate"><span class="pre">Model</span></code>, where <code class="docutils literal notranslate"><span class="pre">loss_fn</span></code> and <code class="docutils literal notranslate"><span class="pre">optimizer</span></code> both use the default value <code class="docutils literal notranslate"><span class="pre">None</span></code>. Then, <code class="docutils literal notranslate"><span class="pre">Model</span></code> will use <code class="docutils literal notranslate"><span class="pre">network</span></code> as the training network without any encapsulation.</p>
<p>Scenarios for customizing <code class="docutils literal notranslate"><span class="pre">TrainOneStepCell</span></code> can be found in <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.6/train_and_eval.html">Build Training and Evaluating Network</a>. The following is a simple example, where <code class="docutils literal notranslate"><span class="pre">loss_net</span></code> and <code class="docutils literal notranslate"><span class="pre">opt</span></code> are <code class="docutils literal notranslate"><span class="pre">CustomWithLossCell</span></code> and <code class="docutils literal notranslate"><span class="pre">Momentum</span></code> as defined in the previous section.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">TrainOneStepCell</span> <span class="k">as</span> <span class="n">CustomTrainOneStepCell</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">LossMonitor</span>

<span class="c1"># Build the Training Network Manually</span>
<span class="n">train_net</span> <span class="o">=</span> <span class="n">CustomTrainOneStepCell</span><span class="p">(</span><span class="n">loss_net</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>
<span class="c1"># Define `Model` and Perform Training</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">train_net</span><span class="p">)</span>
<span class="n">multi_train_ds</span> <span class="o">=</span> <span class="n">create_multilabel_dataset</span><span class="p">(</span><span class="n">num_data</span><span class="o">=</span><span class="mi">160</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">=</span><span class="n">multi_train_ds</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">LossMonitor</span><span class="p">()],</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>The implementation results are as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>epoch: 1 step: 1, loss is 8.834492
epoch: 1 step: 2, loss is 9.452023
epoch: 1 step: 3, loss is 6.974942
epoch: 1 step: 4, loss is 5.8168106
epoch: 1 step: 5, loss is 5.6446257
epoch: 1 step: 6, loss is 4.7653127
epoch: 1 step: 7, loss is 4.059086
epoch: 1 step: 8, loss is 3.5931993
epoch: 1 step: 9, loss is 2.8107128
epoch: 1 step: 10, loss is 2.3682175
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">train_net</span></code> is the training network. When customizing the training network, you also need to customize the evaluating network. The way to perform model evaluation and inference is same as <code class="docutils literal notranslate"><span class="pre">Connect</span> <span class="pre">Forward</span> <span class="pre">Network</span> <span class="pre">with</span> <span class="pre">Loss</span> <span class="pre">Function</span> <span class="pre">Manually</span></code> in the previous section.</p>
<p>When both the label and the predicted value of the custom training network are single values, the evaluation function does not require special treatment, such as customization or using <code class="docutils literal notranslate"><span class="pre">set_indexes</span></code>. However, it is still necessary to pay attention to the correct usage of evaluation metrics in other scenarios.</p>
</section>
<section id="weight-sharing-of-custom-network">
<h3>Weight Sharing of Custom Network<a class="headerlink" href="#weight-sharing-of-custom-network" title="Permalink to this headline"></a></h3>
<p>The weight sharing mechanism has been introduced in <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.6/train_and_eval.html">Build Training and Evaluating Network</a>. When using MindSpore to build different network structures, as long as they are encapsulated in a same instance, all weights in this instance are shared. So, if there is any weight change in one network structure, the weights in other network structures will be changed simultaneously.</p>
<p>When using Model for training, for simple scenarios, <code class="docutils literal notranslate"><span class="pre">Model</span></code> internally uses <code class="docutils literal notranslate"><span class="pre">nn.WithLossCell</span></code>, <code class="docutils literal notranslate"><span class="pre">nn.TrainOneStepCell</span></code> and <code class="docutils literal notranslate"><span class="pre">nn.WithEvalCell</span></code> to build training and evaluating networks based on the forward <code class="docutils literal notranslate"><span class="pre">network</span></code> Instance. <code class="docutils literal notranslate"><span class="pre">Model</span></code> itself ensures weight sharing among inference, training, and evaluating networks. However, for custom scenarios, users need to be aware that the forward network should be instantiated only once. If the forward network is instantiated separately when building the training network and the evaluating network, you need to manually load the weights in the training network when using <code class="docutils literal notranslate"><span class="pre">eval</span></code> for model evaluation. Otherwise the model evaluation will use the initial weight values.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="model.html" class="btn btn-neutral float-left" title="Application of Model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="callback.html" class="btn btn-neutral float-right" title="Callback Mechanism" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>