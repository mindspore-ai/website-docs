<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Multi-hop Knowledge Reasoning Question-answering Model TPRR &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/training.css" type="text/css" /><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/js/training.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="High Performance Computing" href="hpc.html" />
    <link rel="prev" title="Using the BERT Network to Implement Intelligent Poem Writing" href="nlp_bert_poetry.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Overall Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/technical_white_paper.html">Technical White Paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/gradient.html">MindSpore Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.6/training_visual_design.html">Design of Visualization↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.6/linear_regression.html">Implementing Simple Linear Function Fitting↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.6/quick_start.html">Implementing an Image Classification Application↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dtype.html">DataType</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter_introduction.html">Parameter</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="cell.html">Cell</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_introduction.html">Dataset</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Pipeline</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataset_sample.html">Quick Start of Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Processing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_advanced.html">Advanced Usage of Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_usage.html">Data Iteration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build the Network</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="build_net.html">Constructing Single Operator Network and Multi-layer Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="initializer.html">Initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter.html">Network Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="control_flow.html">Using the Process Control Statement</a></li>
<li class="toctree-l1"><a class="reference internal" href="indefinite_parameter.html">Parameter Passing</a></li>
<li class="toctree-l1"><a class="reference internal" href="loss.html">Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="grad_operation.html">Gradient Operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="constexpr.html">Construct Constants In the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypermap.html">Operation Overloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">Optimization Algorithms</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Running</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="context.html">Configuring Running Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="run.html">Running Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_and_load_models.html">Save and Load Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="model.html">Application of Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="online_inference.html">Online Inference with Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="offline_inference.html">Using Offline Model for Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">Distributed Parallel Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_advanced.html">Distributed Parallel Advanced Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_example.html">Distributed Parallel Usage Example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyNative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Numpy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">NumPy Interfaces in MindSpore</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Function Debugging</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="read_ir_files.html">Reading IR</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/debug_in_pynative_mode.html">Debugging in PyNative Mode↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_tune.html">AutoTune</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_dataset_autotune.html">Dataset AutoTune for Dataset Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_dataset_offload.html">Enabling Offload for Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.6/performance_profiling.html">Debugging performance with Profiler↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="second_order_optimizer.html">Second Order Optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_kernel_fusion.html">Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Quantization Aware Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="nlp.html">Natural Language Processing</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="nlp_sentimentnet.html">Realizing Sentiment Classification With SentimentNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp_bert_poetry.html">Using the BERT Network to Implement Intelligent Poem Writing</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Multi-hop Knowledge Reasoning Question-answering Model TPRR</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#preparation">Preparation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#installing-dependent-software">Installing Dependent Software</a></li>
<li class="toctree-l4"><a class="reference internal" href="#preparing-data">Preparing Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="#preparing-checkpoint">Preparing checkpoint</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#loading-data">Loading Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defining-the-network">Defining the Network</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#setting-model-parameters">Setting Model Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="#defining-the-model">Defining the Model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#inference-network">Inference Network</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#running-script">Running Script</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#reference">Reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="nlp.html">Natural Language Processing</a> &raquo;</li>
      <li>Multi-hop Knowledge Reasoning Question-answering Model TPRR</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/nlp_tprr.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="multi-hop-knowledge-reasoning-question-answering-model-tprr">
<h1>Multi-hop Knowledge Reasoning Question-answering Model TPRR<a class="headerlink" href="#multi-hop-knowledge-reasoning-question-answering-model-tprr" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">Natural</span> <span class="pre">Language</span> <span class="pre">Processing</span></code> <code class="docutils literal notranslate"><span class="pre">Whole</span> <span class="pre">Process</span></code></p>
<p>Translator: <a class="reference external" href="https://gitee.com/yuanyanglv">longvoyage</a></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.6/docs/mindspore/programming_guide/source_en/nlp_tprr.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.6/resource/_static/logo_source_en.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>TPRR(Thinking Path Re-Ranker) is an open-domain knowledge based multi-hop question-answering model proposed by Huawei, which is used to realize multi-hop knowledge reasoning question-answering. In traditional question-answering, as long as the sentences related to the original question is found by the model, the answer can be found. It requires multiple “jumps” to find the answer for multi-hop knowledge reasoning question. Specifically, the model needs to use knowledge from multiple related documents to infer the correct answer for the given question. There are three modules in TPRR model: Retriever, Reranker and Reader. According to the given multi hop question, Retriever selects the candidate document sequence containing the answer from millions of Wiki documents, Reranker selects the best document sequence from the candidate document sequence, and finally Reader parses the answer from multiple sentences of the best document to complete the multi-hop knowledge reasoning question-answering. TPRR model uses conditional probability to model the complete reasoning path, and introduces the negative sample selection strategy of “thinking” in the training. It ranks first in Fullwiki Setting of international authoritative HotpotQA evaluation, and ranks first in the joint accuracy, clue accuracy and other two indicators. Compared with the traditional multi-hop question-answering model, TPRR only uses pure text information and does not need additional entity extraction technology. MindSpore hybrid precision feature is used to speed up TPRR model from framework. Combined with Ascend, it can achieve significant performance improvement.</p>
<p>This tutorial will mainly introduce how to build and run a multi-hop knowledge reasoning question-answering model TPRR with MindSpore on Ascend.</p>
<blockquote>
<div><p>You can download the complete sample code here:
<a class="reference external" href="https://gitee.com/mindspore/models/tree/r1.6/research/nlp/tprr">https://gitee.com/mindspore/models/tree/r1.6/research/nlp/tprr</a>.</p>
</div></blockquote>
<p>The sample code directory structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>.
└─tprr
  ├─README.md
  ├─scripts
  | ├─run_eval_ascend.sh                      # Launch retriever evaluation in ascend
  | └─run_eval_ascend_reranker_reader.sh      # Launch re-ranker and reader evaluation in ascend
  |
  ├─src
  | ├─build_reranker_data.py                  # build data for re-ranker from result of retriever
  | ├─config.py                               # Evaluation configurations for retriever
  | ├─hotpot_evaluate_v1.py                   # Hotpotqa evaluation script
  | ├─onehop.py                               # Onehop model of retriever
  | ├─onehop_bert.py                          # Onehop bert model of retriever
  | ├─process_data.py                         # Data preprocessing for retriever
  | ├─reader.py                               # Reader model
  | ├─reader_albert_xxlarge.py                # Albert-xxlarge module of reader model
  | ├─reader_downstream.py                    # Downstream module of reader model
  | ├─reader_eval.py                          # Reader evaluation script
  | ├─rerank_albert_xxlarge.py                # Albert-xxlarge module of re-ranker model
  | ├─rerank_and_reader_data_generator.py     # Data generator for re-ranker and reader
  | ├─rerank_and_reader_utils.py              # Utils for re-ranker and reader
  | ├─rerank_downstream.py                    # Downstream module of re-ranker model
  | ├─reranker.py                             # Re-ranker model
  | ├─reranker_eval.py                        # Re-ranker evaluation script
  | ├─twohop.py                               # Twohop model of retriever
  | ├─twohop_bert.py                          # Twohop bert model of retriever
  | └─utils.py                                # Utils for retriever
  |
  ├─retriever_eval.py                         # Evaluation net for retriever
  └─reranker_and_reader_eval.py               # Evaluation net for re-ranker and reader
</pre></div>
</div>
<p>The overall execution process is as follows:</p>
<ol class="arabic simple">
<li><p>Prepare HotpotQA Development dataset, load processing data;</p></li>
<li><p>Prepare checkpoint for model;</p></li>
<li><p>Set TPRR model parameters;</p></li>
<li><p>Initialize the TPRR model;</p></li>
<li><p>Load the dataset and model CheckPoint and perform inference, check the results and save the output.</p></li>
</ol>
</section>
<section id="preparation">
<h2>Preparation<a class="headerlink" href="#preparation" title="Permalink to this headline"></a></h2>
<section id="installing-dependent-software">
<h3>Installing Dependent Software<a class="headerlink" href="#installing-dependent-software" title="Permalink to this headline"></a></h3>
<ol class="arabic">
<li><p>Install MindSpore</p>
<p>Before practicing, make sure that MindSpore has been installed correctly.If not, you can install it through <a class="reference external" href="https://www.mindspore.cn/install/en">the MindSpore installation page</a>.</p>
</li>
<li><p>Install transformers(recommended version is 3.4.0)</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span><span class="nv">transformers</span><span class="o">==</span><span class="m">3</span>.4.0
</pre></div>
</div>
</li>
</ol>
</section>
<section id="preparing-data">
<h3>Preparing Data<a class="headerlink" href="#preparing-data" title="Permalink to this headline"></a></h3>
<p>The data used in this tutorial is the preprocessed <a class="reference external" href="https://github.com/AkariAsai/learning_to_retrieve_reasoning_paths/tree/master/retriever">en-Wikipedia</a> and <a class="reference external" href="https://hotpotqa.github.io/">HotpotQA Development datasets</a>. Please download the <a class="reference external" href="https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/tprr/data.zip">preprocessed data</a> first, then decompress it and place it in ‘/scripts’.</p>
</section>
<section id="preparing-checkpoint">
<h3>Preparing checkpoint<a class="headerlink" href="#preparing-checkpoint" title="Permalink to this headline"></a></h3>
<p>Please download <a class="reference external" href="https://download.mindspore.cn/model_zoo/research/nlp/tprr/">checkpoint</a>, then make directory ‘/ckpt’ in ‘scripts’ and place downloaded checkpoint files in ‘/ckpt’, directory structure is as following:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>.
└─tprr
  ├─README.md
  |
  ├─scripts
  | ├─data
  | ├─ckpt
  | | ├─onehop_new.ckpt
  | | ├─onehop_mlp.ckpt
  | | ├─twohop_new.ckpt
  | | ├─twohop_mlp.ckpt
  | | ├─rerank_alberet.ckpt
  | | ├─rerank_downstream.ckpt
  | | ├─reader_alberet.ckpt
  | | ├─reader_downstream.ckpt
  | | |
  | | ├─albert-xxlarge
  | | | ├─config.json
  | | | └─spiece.model
  | | └─
  | ├─run_eval_ascend.sh                      # Launch retriever evaluation in ascend
  | └─run_eval_ascend_reranker_reader.sh      # Launch re-ranker and reader evaluation in ascend
  |
  └─src
</pre></div>
</div>
</section>
</section>
<section id="loading-data">
<h2>Loading Data<a class="headerlink" href="#loading-data" title="Permalink to this headline"></a></h2>
<p>Store the downloaded data in the scripts directory. The Retriever module loads the data files preprocessed by wiki and HotpotQA, and retrieves relevant documents from the data according to the given multi-hop question. The source code of data loading is in the file <code class="docutils literal notranslate"><span class="pre">src/process_data.py</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;load data&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;**********************  loading data  ********************** &#39;</span><span class="p">)</span>
    <span class="n">f_wiki</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">wiki_path</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span>
    <span class="n">f_train</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dev_path</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span>
    <span class="n">f_doc</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dev_data_path</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span>
    <span class="n">data_db</span> <span class="o">=</span> <span class="n">pkl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f_wiki</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;gbk&quot;</span><span class="p">)</span>
    <span class="n">dev_data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f_train</span><span class="p">)</span>
    <span class="n">q_doc_text</span> <span class="o">=</span> <span class="n">pkl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f_doc</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;gbk&#39;</span><span class="p">)</span>
    <span class="n">f_wiki</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">f_train</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">f_doc</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">data_db</span><span class="p">,</span> <span class="n">dev_data</span><span class="p">,</span> <span class="n">q_doc_text</span>
</pre></div>
</div>
<p>Retrieved results of the Retriever module are saved in the scripts directory. According to the results, the Reranker  module uses a custom DataGenerator class loading the data files preprocessed by wiki and HotpotQA to generator the reordering results and save them in the scripts directory. According to the reordering results, the Reader module also uses a custom DataGenerator class loading data files preprocessed by wiki and HotpotQA to extract answers and evidence. The source code of custom DataGenerator class is in the file <code class="docutils literal notranslate"><span class="pre">src/rerank_and_reader_data_generator.py</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DataGenerator</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;data generator for reranker and reader&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature_file_path</span><span class="p">,</span> <span class="n">example_file_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span>
                 <span class="n">para_limit</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sent_limit</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">task_type</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;init function&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">example_ptr</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bsz</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seq_length</span> <span class="o">=</span> <span class="n">seq_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">para_limit</span> <span class="o">=</span> <span class="n">para_limit</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sent_limit</span> <span class="o">=</span> <span class="n">sent_limit</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">task_type</span> <span class="o">=</span> <span class="n">task_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_file_path</span> <span class="o">=</span> <span class="n">feature_file_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">example_file_path</span> <span class="o">=</span> <span class="n">example_file_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_features</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">examples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_examples</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_feature_dict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">example_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_example_dict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_feature</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bsz</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="defining-the-network">
<h2>Defining the Network<a class="headerlink" href="#defining-the-network" title="Permalink to this headline"></a></h2>
<section id="setting-model-parameters">
<h3>Setting Model Parameters<a class="headerlink" href="#setting-model-parameters" title="Permalink to this headline"></a></h3>
<p>The class ThinkRetrieverConfig for customizing parameters of model is in the script <code class="docutils literal notranslate"><span class="pre">src/config.py</span></code>. The user can customize parameters such as topk and onehop_num in the model. Topk represents the number of candidate one-hop documents after Retriever sorting. The larger the topk, the more candidate documents. The recall rate will increase and more noise will be introduced, the accuracy rate will decrease; Onehop_num represents the number of one-hop candidate documents as two-hop candidate documents. The larger onehop_num, the more documents to be selected for the second hop. The recall rate will increase and more noise will be introduced, the accuracy rate will decrease.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ThinkRetrieverConfig</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;retriever config&quot;&quot;&quot;</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--q_len&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;max query len&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--d_len&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">192</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;max doc len&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--s_len&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">448</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;max seq len&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--in_len&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;in len&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--out_len&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;out len&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--num_docs&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;docs num&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--topk&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;top num&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--onehop_num&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;onehop num&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--batch_size&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;batch size&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--device_num&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;device num&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--vocab_path&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;../vocab.txt&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;vocab path&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--wiki_path&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;../db_docs_bidirection_new.pkl&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;wiki path&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--dev_path&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;../hotpot_dev_fullwiki_v1_for_retriever.json&#39;</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;dev path&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--dev_data_path&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;../dev_tf_idf_data_raw.pkl&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;dev data path&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--onehop_bert_path&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;../onehop.ckpt&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;onehop bert ckpt path&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--onehop_mlp_path&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;../onehop_mlp.ckpt&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;onehop mlp ckpt path&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--twohop_bert_path&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;../twohop.ckpt&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;twohop bert ckpt path&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--twohop_mlp_path&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;../twohop_mlp.ckpt&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;twohop mlp ckpt path&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--q_path&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;../queries&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;queries data path&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="defining-the-model">
<h3>Defining the Model<a class="headerlink" href="#defining-the-model" title="Permalink to this headline"></a></h3>
<p>Define the Retriever module and load the model parameters, the following example code is in the script <code class="docutils literal notranslate"><span class="pre">retriever_eval.py</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">evaluation</span><span class="p">(</span><span class="n">d_id</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;evaluation&quot;&quot;&quot;</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span>
                        <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">,</span>
                        <span class="n">device_id</span><span class="o">=</span><span class="n">d_id</span><span class="p">,</span>
                        <span class="n">save_graphs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;********************** loading corpus ********************** &#39;</span><span class="p">)</span>
    <span class="n">s_lc</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">data_generator</span> <span class="o">=</span> <span class="n">DataGen</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="n">queries</span> <span class="o">=</span> <span class="n">read_query</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">d_id</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;loading corpus time (h):&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">s_lc</span><span class="p">)</span> <span class="o">/</span> <span class="mi">3600</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;********************** loading model ********************** &#39;</span><span class="p">)</span>

    <span class="n">s_lm</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">model_onehop_bert</span> <span class="o">=</span> <span class="n">ModelOneHop</span><span class="p">(</span><span class="mi">256</span><span class="p">)</span>
    <span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">onehop_bert_path</span><span class="p">)</span>
    <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">model_onehop_bert</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
    <span class="n">model_twohop_bert</span> <span class="o">=</span> <span class="n">ModelOneHop</span><span class="p">(</span><span class="mi">448</span><span class="p">)</span>
    <span class="n">param_dict2</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">twohop_bert_path</span><span class="p">)</span>
    <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">model_twohop_bert</span><span class="p">,</span> <span class="n">param_dict2</span><span class="p">)</span>
    <span class="n">onehop</span> <span class="o">=</span> <span class="n">OneHopBert</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">model_onehop_bert</span><span class="p">)</span>
    <span class="n">twohop</span> <span class="o">=</span> <span class="n">TwoHopBert</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">model_twohop_bert</span><span class="p">)</span>
</pre></div>
</div>
<p>Define the Reranker module and load the model parameters, class Reranker is in the script <code class="docutils literal notranslate"><span class="pre">src/reranker.py</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">reranker</span> <span class="o">=</span> <span class="n">Reranker</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                        <span class="n">encoder_ck_file</span><span class="o">=</span><span class="n">encoder_ck_file</span><span class="p">,</span>
                        <span class="n">downstream_ck_file</span><span class="o">=</span><span class="n">downstream_ck_file</span><span class="p">)</span>
</pre></div>
</div>
<p>Define the Reader module and load the model parameters, class Reader is in the script <code class="docutils literal notranslate"><span class="pre">src/reader.py</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">reader</span> <span class="o">=</span> <span class="n">Reader</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">encoder_ck_file</span><span class="o">=</span><span class="n">encoder_ck_file</span><span class="p">,</span>
                    <span class="n">downstream_ck_file</span><span class="o">=</span><span class="n">downstream_ck_file</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="inference-network">
<h2>Inference Network<a class="headerlink" href="#inference-network" title="Permalink to this headline"></a></h2>
<section id="running-script">
<h3>Running Script<a class="headerlink" href="#running-script" title="Permalink to this headline"></a></h3>
<p>Run the shell script in the scripts directory to start the inference process. Run the script with the following command for the Retriever module, retriever result file ‘doc_path’ will be saved in ‘/scripts’:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sh<span class="w"> </span>run_eval_ascend.sh
</pre></div>
</div>
<p>After retrieving is completed, run the script with the following command for the Reranker module and Reader module:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sh<span class="w"> </span>run_eval_ascend_reranker_reader.sh
</pre></div>
</div>
<p>After the inference is completed, the result is saved to the log file in <code class="docutils literal notranslate"><span class="pre">scripts/eval/</span></code> directory, and the evaluation result can be checked in the corresponding log file.</p>
<p>Evaluation results of the Retriever module: val represents the number of questions found in the correct answer document, count represents the total number of questions, and PEM represents the accuracy of the top-8 documents after the problem-related documents are sorted.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># match query num
val:6959
# query num
count:7404
# one hop match query num
true count: 7112
# top8 paragraph exact match
PEM: 0.9398973527822798
# top8 paragraph exact match in recall
true top8 PEM: 0.9784870641169854
# evaluation time
evaluation time (h): 1.819070938428243
</pre></div>
</div>
<p>The following is Reranker and Reader module evaluation results, total_top1_pem represents the accuracy of the exact matching of the top-1 path after reordering, joint_em represents the joint accuracy of the predicted answer and the exact match of the evidence, joint_f1 represents the combined f1 score of the predicted answer and the evidence.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># top8 paragraph exact match
total top1 pem: 0.8803511141120864
...

# answer exact match
em: 0.67440918298447
# answer f1
f1: 0.8025625656569652
# answer precision
prec: 0.8292800393689271
# answer recall
recall: 0.8136908451841731
# supporting facts exact match
sp_em: 0.6009453072248481
# supporting facts f1
sp_f1: 0.844555664157302
# supporting facts precision
sp_prec: 0.8640844345841021
# supporting facts recall
sp_recall: 0.8446123918845106
# joint exact match
joint_em: 0.4537474679270763
# joint f1
joint_f1: 0.715119580346802
# joint precision
joint_prec: 0.7540052057184267
# joint recall
joint_recall: 0.7250240424067661
</pre></div>
</div>
</section>
</section>
<section id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this headline"></a></h2>
<ol class="arabic simple">
<li><p>Yang Z , Qi P , Zhang S , et al. HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering[C]// Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. 2018.</p></li>
<li><p>Asai A , Hashimoto K , Hajishirzi H , et al. Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering[J]. 2019.</p></li>
</ol>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="nlp_bert_poetry.html" class="btn btn-neutral float-left" title="Using the BERT Network to Implement Intelligent Poem Writing" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="hpc.html" class="btn btn-neutral float-right" title="High Performance Computing" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>