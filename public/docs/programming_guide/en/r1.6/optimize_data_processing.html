

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Optimizing the Data Processing &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script src="_static/js/training.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Data Iteration" href="dataset_usage.html" />
    <link rel="prev" title="Single-Node Tensor Cache" href="cache.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Overall Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API Overview</a></li>
</ul>
<p class="caption"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/technical_white_paper.html">Technical White Paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/gradient.html">MindSpore Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.6/training_visual_design.html">Design of Visualization↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/glossary.html">Glossary</a></li>
</ul>
<p class="caption"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.6/linear_regression.html">Implementing Simple Linear Function Fitting↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.6/quick_start.html">Implementing an Image Classification Application↗</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dtype.html">DataType</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter_introduction.html">Parameter</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="cell.html">Cell</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_introduction.html">Dataset</a></li>
</ul>
<p class="caption"><span class="caption-text">Data Pipeline</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="dataset_sample.html">Quick Start of Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Processing Data</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="dataset_advanced.html">Advanced Usage of Pipeline</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="auto_augmentation.html">Auto Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="cache.html">Single-Node Tensor Cache</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Optimizing the Data Processing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Preparations">Preparations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Importing-Modules">Importing Modules</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Downloading-the-Required-Dataset">Downloading the Required Dataset</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Optimizing-the-Data-Loading-Performance">Optimizing the Data Loading Performance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Performance-Optimization-Solution">Performance Optimization Solution</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Code-Example">Code Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Optimizing-the-Shuffle-Performance">Optimizing the Shuffle Performance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">Performance Optimization Solution</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id2">Code Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Optimizing-the-Data-Augmentation-Performance">Optimizing the Data Augmentation Performance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id3">Performance Optimization Solution</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id4">Code Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Optimizing-the-Operating-System-Performance">Optimizing the Operating System Performance</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Performance-Optimization-Solution-Summary">Performance Optimization Solution Summary</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Multi-thread-Optimization-Solution">Multi-thread Optimization Solution</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Multi-process-Optimization-Solution">Multi-process Optimization Solution</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Compose-Optimization-Solution">Compose Optimization Solution</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Operator-Fusion-Optimization-Solution">Operator Fusion Optimization Solution</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Operating-System-Optimization-Solution">Operating System Optimization Solution</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#References">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dataset_usage.html">Data Iteration</a></li>
</ul>
<p class="caption"><span class="caption-text">Build the Network</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="build_net.html">Constructing Single Operator Network and Multi-layer Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="initializer.html">Initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter.html">Network Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="control_flow.html">Using the Process Control Statement</a></li>
<li class="toctree-l1"><a class="reference internal" href="indefinite_parameter.html">Parameter Passing</a></li>
<li class="toctree-l1"><a class="reference internal" href="loss.html">Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="grad_operation.html">Gradient Operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="constexpr.html">Construct Constants In the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypermap.html">Operation Overloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">Optimization Algorithms</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Running</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="context.html">Configuring Running Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="run.html">Running Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_and_load_models.html">Save and Load Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="model.html">Application of Model</a></li>
</ul>
<p class="caption"><span class="caption-text">Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="online_inference.html">Online Inference with Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="offline_inference.html">Using Offline Model for Inference</a></li>
</ul>
<p class="caption"><span class="caption-text">Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">Distributed Parallel Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_advanced.html">Distributed Parallel Advanced Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_example.html">Distributed Parallel Usage Example</a></li>
</ul>
<p class="caption"><span class="caption-text">PyNative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
</ul>
<p class="caption"><span class="caption-text">Numpy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">NumPy Interfaces in MindSpore</a></li>
</ul>
<p class="caption"><span class="caption-text">Function Debugging</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="read_ir_files.html">Reading IR</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/debug_in_pynative_mode.html">Debugging in PyNative Mode↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_tune.html">AutoTune</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_dataset_autotune.html">Dataset AutoTune for Dataset Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_dataset_offload.html">Enabling Offload for Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.6/performance_profiling.html">Debugging performance with Profiler↗</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced Features</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="second_order_optimizer.html">Second Order Optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_kernel_fusion.html">Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Quantization Aware Training</a></li>
</ul>
<p class="caption"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="dataset_advanced.html">Advanced Usage of Pipeline</a> &raquo;</li>
        
      <li>Optimizing the Data Processing</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/optimize_data_processing.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Optimizing-the-Data-Processing">
<h1>Optimizing the Data Processing<a class="headerlink" href="#Optimizing-the-Data-Processing" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">Data</span> <span class="pre">Preparation</span></code></p>
<p><a class="reference external" href="https://authoring-modelarts-cnnorth4.huaweicloud.com/console/lab?share-url-b64=aHR0cHM6Ly9taW5kc3BvcmUtd2Vic2l0ZS5vYnMuY24tbm9ydGgtNC5teWh1YXdlaWNsb3VkLmNvbS9ub3RlYm9vay9tYXN0ZXIvcHJvZ3JhbW1pbmdfZ3VpZGUvZW4vbWluZHNwb3JlX29wdGltaXplX2RhdGFfcHJvY2Vzc2luZy5pcHluYg==&amp;imageid=65f636a0-56cf-49df-b941-7d2a07ba8c8c"><img alt="Run in ModelArts" src="https://gitee.com/mindspore/docs/raw/r1.6/resource/_static/logo_modelarts_en.png" /></a> <a class="reference external" href="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/r1.6/programming_guide/en/mindspore_optimize_data_processing.ipynb"><img alt="Download Notebook" src="https://gitee.com/mindspore/docs/raw/r1.6/resource/_static/logo_notebook_en.png" /></a> <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.6/docs/mindspore/programming_guide/source_en/optimize_data_processing.ipynb"><img alt="View Source On Gitee" src="https://gitee.com/mindspore/docs/raw/r1.6/resource/_static/logo_source_en.png" /></a></p>
<div class="section" id="Overview">
<h2>Overview<a class="headerlink" href="#Overview" title="Permalink to this headline">¶</a></h2>
<p>Data is the most important factor of deep learning. Data quality determines the upper limit of deep learning result, whereas model quality enables the result to approach the upper limit. Therefore, high-quality data input is beneficial to the entire deep neural network. During the entire data processing and data augmentation process, data continuously flows through a pipeline to the training system.</p>
<p><img alt="pipeline" src="https://gitee.com/mindspore/docs/raw/r1.6/docs/mindspore/programming_guide/source_en/images/pipeline.png" /></p>
<p>MindSpore provides data processing and data augmentation functions for users. In the pipeline process, if each step can be properly used, the data performance will be greatly improved. This section describes how to optimize performance during data loading, data processing, and data augmentation based on the <a class="reference external" href="#references">CIFAR-10 dataset[1]</a>.</p>
<p>In addition, the storage, architecture and computing resources of the operating system will influence the performance of data processing to a certain extent.</p>
</div>
<div class="section" id="Preparations">
<h2>Preparations<a class="headerlink" href="#Preparations" title="Permalink to this headline">¶</a></h2>
<div class="section" id="Importing-Modules">
<h3>Importing Modules<a class="headerlink" href="#Importing-Modules" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">dataset</span></code> module provides APIs for loading and processing datasets.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
</pre></div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">numpy</span></code> module is used to generate ndarrays.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Downloading-the-Required-Dataset">
<h3>Downloading the Required Dataset<a class="headerlink" href="#Downloading-the-Required-Dataset" title="Permalink to this headline">¶</a></h3>
<p>Run the following command to download the dataset: Download the CIFAR-10 Binary format dataset, decompress them and store them in the <code class="docutils literal notranslate"><span class="pre">./datasets</span></code> path, use this dataset when loading data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">tarfile</span>
<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="kn">import</span> <span class="nn">shutil</span>

<span class="n">requests</span><span class="o">.</span><span class="n">packages</span><span class="o">.</span><span class="n">urllib3</span><span class="o">.</span><span class="n">disable_warnings</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">download_dataset</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">target_path</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;download and decompress dataset&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">target_path</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">target_path</span><span class="p">)</span>
    <span class="n">download_file</span> <span class="o">=</span> <span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">download_file</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verify</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">download_file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;tgz&quot;</span><span class="p">,</span> <span class="s2">&quot;zip&quot;</span><span class="p">,</span> <span class="s2">&quot;tar&quot;</span><span class="p">,</span> <span class="s2">&quot;gz&quot;</span><span class="p">]:</span>
            <span class="n">download_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_path</span><span class="p">,</span> <span class="n">download_file</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">download_file</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">res</span><span class="o">.</span><span class="n">iter_content</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">512</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">chunk</span><span class="p">:</span>
                    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">download_file</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;zip&quot;</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">download_file</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span>
        <span class="n">z</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">target_path</span><span class="p">)</span>
        <span class="n">z</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">download_file</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.tar.gz&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">download_file</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.tar&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">download_file</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.tgz&quot;</span><span class="p">):</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">download_file</span><span class="p">)</span>
        <span class="n">names</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">getnames</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
            <span class="n">t</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">target_path</span><span class="p">)</span>
        <span class="n">t</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The </span><span class="si">{}</span><span class="s2"> file is downloaded and saved in the path </span><span class="si">{}</span><span class="s2"> after processing&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">url</span><span class="p">),</span> <span class="n">target_path</span><span class="p">))</span>

<span class="n">download_dataset</span><span class="p">(</span><span class="s2">&quot;https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/cifar-10-binary.tar.gz&quot;</span><span class="p">,</span> <span class="s2">&quot;./datasets&quot;</span><span class="p">)</span>
<span class="n">test_path</span> <span class="o">=</span> <span class="s2">&quot;./datasets/cifar-10-batches-bin/test&quot;</span>
<span class="n">train_path</span> <span class="o">=</span> <span class="s2">&quot;./datasets/cifar-10-batches-bin/train&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">test_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">test_path</span><span class="p">,</span> <span class="s2">&quot;test_batch.bin&quot;</span><span class="p">)):</span>
    <span class="n">shutil</span><span class="o">.</span><span class="n">move</span><span class="p">(</span><span class="s2">&quot;./datasets/cifar-10-batches-bin/test_batch.bin&quot;</span><span class="p">,</span> <span class="n">test_path</span><span class="p">)</span>
<span class="p">[</span><span class="n">shutil</span><span class="o">.</span><span class="n">move</span><span class="p">(</span><span class="s2">&quot;./datasets/cifar-10-batches-bin/&quot;</span><span class="o">+</span><span class="n">i</span><span class="p">,</span> <span class="n">train_path</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;./datasets/cifar-10-batches-bin/&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="s2">&quot;./datasets/cifar-10-batches-bin/&quot;</span><span class="o">+</span><span class="n">i</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">i</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.html&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="n">i</span><span class="p">))]</span>
</pre></div>
</div>
</div>
<p>The directory structure of the downloaded dataset file is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./datasets/cifar-10-batches-bin
├── readme.html
├── test
│   └── test_batch.bin
└── train
    ├── batches.meta.txt
    ├── data_batch_1.bin
    ├── data_batch_2.bin
    ├── data_batch_3.bin
    ├── data_batch_4.bin
    └── data_batch_5.bin
</pre></div>
</div>
<p>Download cifar-10 Python file format dataset, decompress them in the <code class="docutils literal notranslate"><span class="pre">./datasets/cifar-10-batches-py</span></code> path, use this dataset when converting data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">download_dataset</span><span class="p">(</span><span class="s2">&quot;https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/cifar-10-python.tar.gz&quot;</span><span class="p">,</span> <span class="s2">&quot;./datasets&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The directory structure of the extracted dataset file is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>./datasets/cifar-10-batches-py
├── batches.meta
├── data_batch_1
├── data_batch_2
├── data_batch_3
├── data_batch_4
├── data_batch_5
├── readme.html
└── test_batch
</pre></div>
</div>
</div>
</div>
<div class="section" id="Optimizing-the-Data-Loading-Performance">
<h2>Optimizing the Data Loading Performance<a class="headerlink" href="#Optimizing-the-Data-Loading-Performance" title="Permalink to this headline">¶</a></h2>
<p>MindSpore provides multiple data loading methods, including common dataset loading, user-defined dataset loading, and the MindSpore data format loading. The dataset loading performance varies depending on the underlying implementation method.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 31%" />
<col style="width: 19%" />
<col style="width: 26%" />
<col style="width: 24%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>Common Dataset</p></th>
<th class="head"><p>User-defined Dataset</p></th>
<th class="head"><p>MindRecord Dataset</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Underlying implementation</p></td>
<td><p>C++</p></td>
<td><p>Python</p></td>
<td><p>C++</p></td>
</tr>
<tr class="row-odd"><td><p>Performance</p></td>
<td><p>High</p></td>
<td><p>Medium</p></td>
<td><p>High</p></td>
</tr>
</tbody>
</table>
<div class="section" id="Performance-Optimization-Solution">
<h3>Performance Optimization Solution<a class="headerlink" href="#Performance-Optimization-Solution" title="Permalink to this headline">¶</a></h3>
<p><img alt="data-loading-performance-scheme" src="https://gitee.com/mindspore/docs/raw/r1.6/docs/mindspore/programming_guide/source_en/images/data_loading_performance_scheme.png" /></p>
<p>Suggestions on data loading performance optimization are as follows:</p>
<ul class="simple">
<li><p>Built-in loading operators are preferred for supported dataset formats. For details, see <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.6/api_python/mindspore.dataset.html">Built-in Loading Operators</a>, if the performance cannot meet the requirements, use the multi-thread concurrency solution. For details, see <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/optimize_data_processing.html#multi-thread-optimization-solution">Multi-thread Optimization Solution</a>.</p></li>
<li><p>For a dataset format that is not supported, convert the format to the mindspore data format and then use the <code class="docutils literal notranslate"><span class="pre">MindDataset</span></code> class to load the dataset (Please refer to the <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.6/api_python/dataset/mindspore.dataset.MindDataset.html">API</a> for detailed use). Please refer to <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/convert_dataset.html">Converting Dataset to MindRecord</a>, if the performance cannot meet the requirements, use the
multi-thread concurrency solution, for details, see <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/optimize_data_processing.html#multi-thread-optimization-solution">Multi-thread Optimization Solution</a>.</p></li>
<li><p>For dataset formats that are not supported, the user-defined <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> class is preferred for implementing fast algorithm verification (Please refer to the <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.6/api_python/dataset/mindspore.dataset.GeneratorDataset.html">API</a> for detailed use), if the performance cannot meet the requirements, the multi-process concurrency solution can be used. For details, see <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/optimize_data_processing.html#multi-process-optimization-solution">Multi-process Optimization
Solution</a>.</p></li>
</ul>
</div>
<div class="section" id="Code-Example">
<h3>Code Example<a class="headerlink" href="#Code-Example" title="Permalink to this headline">¶</a></h3>
<p>Based on the preceding suggestions of data loading performance optimization, the <code class="docutils literal notranslate"><span class="pre">Cifar10Dataset</span></code> class of built-in loading operators (Please refer to the <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.6/api_python/dataset/mindspore.dataset.Cifar10Dataset.html">API</a> for detailed use), the <code class="docutils literal notranslate"><span class="pre">MindDataset</span></code> class after data conversion, and the <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> class are used to load data. The sample code is displayed as follows:</p>
<ol class="arabic simple">
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">Cifar10Dataset</span></code> class of built-in operators to load the CIFAR-10 dataset in binary format. The multi-thread optimization solution is used for data loading. Four threads are enabled to concurrently complete the task. Finally, a dictionary iterator is created for the data and a data record is read through the iterator.</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cifar10_path</span> <span class="o">=</span> <span class="s2">&quot;./datasets/cifar-10-batches-bin/train&quot;</span>

<span class="c1"># create Cifar10Dataset for reading data</span>
<span class="n">cifar10_dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">cifar10_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="c1"># create a dictionary iterator and read a data record through the iterator</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">cifar10_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;image&#39;: Tensor(shape=[32, 32, 3], dtype=UInt8, value=
[[[209, 206, 192],
  [211, 209, 201],
  [221, 217, 213],
  ...
  [172, 175, 194],
  [169, 173, 190],
  [115, 121, 145]],
 [[226, 230, 211],
  [227, 229, 218],
  [230, 232, 221],
  ...
  [153, 153, 171],
  [156, 156, 173],
  [106, 111, 129]],
 [[214, 226, 203],
  [214, 222, 204],
  [217, 227, 206],
  ...
  [167, 166, 176],
  [147, 147, 156],
  [ 78,  84,  96]],
 ...
 [[ 40,  69,  61],
  [ 37,  63,  57],
  [ 43,  68,  66],
  ...
  [ 55,  70,  69],
  [ 40,  54,  51],
  [ 27,  44,  36]],
 [[ 33,  61,  50],
  [ 37,  65,  56],
  [ 54,  72,  74],
  ...
  [ 47,  60,  56],
  [ 58,  66,  64],
  [ 36,  50,  46]],
 [[ 29,  41,  37],
  [ 38,  60,  59],
  [ 51,  76,  81],
  ...
  [ 32,  51,  43],
  [ 47,  61,  54],
  [ 56,  67,  66]]]), &#39;label&#39;: Tensor(shape=[], dtype=UInt32, value= 5)}
</pre></div></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">Cifar10ToMR</span></code> class to convert the CIFAR-10 dataset into the MindSpore data format. In this example, the CIFAR-10 dataset in Python file format is used. Then use the <code class="docutils literal notranslate"><span class="pre">MindDataset</span></code> class to load the dataset in the MindSpore data format. The multi-thread optimization solution is used for data loading. Four threads are enabled to concurrently complete the task. Finally, a dictionary iterator is created for data and a data record is read through the iterator.</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">mindspore.mindrecord</span> <span class="kn">import</span> <span class="n">Cifar10ToMR</span>

<span class="n">trans_path</span> <span class="o">=</span> <span class="s2">&quot;./transform/&quot;</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">trans_path</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">trans_path</span><span class="p">)</span>

<span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s2">&quot;rm -f </span><span class="si">{}</span><span class="s2">cifar10*&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">trans_path</span><span class="p">))</span>

<span class="n">cifar10_path</span> <span class="o">=</span> <span class="s1">&#39;./datasets/cifar-10-batches-py&#39;</span>
<span class="n">cifar10_mindrecord_path</span> <span class="o">=</span> <span class="s1">&#39;./transform/cifar10.record&#39;</span>

<span class="n">cifar10_transformer</span> <span class="o">=</span> <span class="n">Cifar10ToMR</span><span class="p">(</span><span class="n">cifar10_path</span><span class="p">,</span> <span class="n">cifar10_mindrecord_path</span><span class="p">)</span>
<span class="c1"># execute transformation from CIFAR-10 to MindRecord</span>
<span class="n">cifar10_transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">([</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>

<span class="c1"># create MindDataset for reading data</span>
<span class="n">cifar10_mind_dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">MindDataset</span><span class="p">(</span><span class="n">dataset_files</span><span class="o">=</span><span class="n">cifar10_mindrecord_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="c1"># create a dictionary iterator and read a data record through the iterator</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">cifar10_mind_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;data&#39;: Tensor(shape=[1283], dtype=UInt8, value= [255, 216, 255, 224,   0,  16,  74,  70,  73,  70,   0,   1,   1,   0,   0,   1,   0,   1,   0,   0, 255, 219,   0,  67,
 107, 249,  17,  58, 213, 185, 117, 181, 143, 255, 217]), &#39;id&#39;: Tensor(shape=[], dtype=Int64, value= 32476), &#39;label&#39;: Tensor(shape=[], dtype=Int64, value= 9)}
</pre></div></div>
</div>
<ol class="arabic simple" start="3">
<li><p>The <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> class is used to load the user-defined dataset, and the multi-process optimization solution is used. Four processes are enabled to concurrently complete the task. Finally, a dictionary iterator is created for the data, and a data record is read through the iterator.</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generator_func</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
        <span class="k">yield</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">i</span><span class="p">]),)</span>

<span class="c1"># create a GeneratorDataset object for reading data</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">generator_func</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">],</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="c1"># create a dictionary iterator and read a data record through the iterator</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;data&#39;: Tensor(shape=[1], dtype=Int64, value= [0])}
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Optimizing-the-Shuffle-Performance">
<h2>Optimizing the Shuffle Performance<a class="headerlink" href="#Optimizing-the-Shuffle-Performance" title="Permalink to this headline">¶</a></h2>
<p>The shuffle operation is used to shuffle ordered datasets or repeated datasets. MindSpore provides the <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> function for users. A larger value of <code class="docutils literal notranslate"><span class="pre">buffer_size</span></code> indicates a higher shuffling degree, consuming more time and computing resources. This API allows users to shuffle the data at any time during the entire pipeline process.Please refer to <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/pipeline.html#shuffle">shuffle</a>. However, because the underlying implementation
methods are different, the performance of this method is not as good as that of setting the <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> parameter to directly shuffle data by referring to the <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.6/api_python/mindspore.dataset.html">Built-in Loading Operators</a>.</p>
<div class="section" id="id1">
<h3>Performance Optimization Solution<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p><img alt="shuffle-performance-scheme" src="https://gitee.com/mindspore/docs/raw/r1.6/docs/mindspore/programming_guide/source_en/images/shuffle_performance_scheme.png" /></p>
<p>Suggestions on shuffle performance optimization are as follows:</p>
<ul class="simple">
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> parameter of built-in loading operators to shuffle data.</p></li>
<li><p>If the <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> function is used and the performance still cannot meet the requirements, adjust the value of the <code class="docutils literal notranslate"><span class="pre">buffer_size</span></code> parameter to improve the performance.</p></li>
</ul>
</div>
<div class="section" id="id2">
<h3>Code Example<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>Based on the preceding shuffle performance optimization suggestions, the <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> parameter of the <code class="docutils literal notranslate"><span class="pre">Cifar10Dataset</span></code> class of built-in loading operators and the <code class="docutils literal notranslate"><span class="pre">Shuffle</span></code> function are used to shuffle data. The sample code is displayed as follows:</p>
<ol class="arabic simple">
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">Cifar10Dataset</span></code> class of built-in operators to load the CIFAR-10 dataset. In this example, the CIFAR-10 dataset in binary format is used, and the <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> parameter is set to True to perform data shuffle. Finally, a dictionary iterator is created for the data and a data record is read through the iterator.</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cifar10_path</span> <span class="o">=</span> <span class="s2">&quot;./datasets/cifar-10-batches-bin/train&quot;</span>

<span class="c1"># create Cifar10Dataset for reading data</span>
<span class="n">cifar10_dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">cifar10_path</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># create a dictionary iterator and read a data record through the iterator</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">cifar10_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;image&#39;: Tensor(shape=[32, 32, 3], dtype=UInt8, value=
[[[119, 193, 196],
  [121, 192, 204],
  [123, 193, 209],
  ...
  [110, 168, 177],
  [109, 167, 176],
  [110, 168, 178]],
 [[110, 188, 199],
  [109, 185, 202],
  [111, 186, 204],
  ...
  [107, 173, 179],
  [107, 173, 179],
  [109, 175, 182]],
 [[110, 186, 200],
  [108, 183, 199],
  [110, 184, 199],
  ...
  [115, 183, 189],
  [117, 185, 190],
  [117, 185, 191]],
 ...
 [[210, 253, 250],
  [212, 251, 250],
  [214, 250, 249],
  ...
  [194, 247, 247],
  [190, 246, 245],
  [184, 245, 244]],
 [[215, 253, 251],
  [218, 252, 250],
  [220, 251, 249],
  ...
  [200, 248, 248],
  [195, 247, 245],
  [189, 245, 244]],
 [[216, 253, 253],
  [222, 251, 250],
  [225, 250, 249],
  ...
  [204, 249, 248],
  [200, 246, 244],
  [196, 245, 244]]]), &#39;label&#39;: Tensor(shape=[], dtype=UInt32, value= 0)}
</pre></div></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> function to shuffle data. Set <code class="docutils literal notranslate"><span class="pre">buffer_size</span></code> to 3 and use the <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> class to generate data.</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generator_func</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="k">yield</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">3</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">4</span><span class="p">]),)</span>

<span class="n">ds1</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">generator_func</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;before shuffle:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">ds1</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>

<span class="n">ds2</span> <span class="o">=</span> <span class="n">ds1</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;after shuffle:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">ds2</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
before shuffle:
[0 1 2 3 4]
[1 2 3 4 5]
[2 3 4 5 6]
[3 4 5 6 7]
[4 5 6 7 8]
after shuffle:
[2 3 4 5 6]
[0 1 2 3 4]
[1 2 3 4 5]
[4 5 6 7 8]
[3 4 5 6 7]
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Optimizing-the-Data-Augmentation-Performance">
<h2>Optimizing the Data Augmentation Performance<a class="headerlink" href="#Optimizing-the-Data-Augmentation-Performance" title="Permalink to this headline">¶</a></h2>
<p>During image classification training, especially when the dataset is small, users can use data augmentation to preprocess images to enrich the dataset. MindSpore provides multiple data augmentation methods, including:</p>
<ul class="simple">
<li><p>Use the built-in C operator (<code class="docutils literal notranslate"><span class="pre">c_transforms</span></code> module) to perform data augmentation.</p></li>
<li><p>Use the built-in Python operator (<code class="docutils literal notranslate"><span class="pre">py_transforms</span></code> module) to perform data augmentation.</p></li>
<li><p>Users can define Python functions as needed to perform data augmentation.</p></li>
</ul>
<p>Please refer to <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/augmentation.html">Data Augmentation</a>. The performance varies according to the underlying implementation methods.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Module</p></th>
<th class="head"><p>Underlying API</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>c_transforms</p></td>
<td><p>C++ (based on OpenCV)</p></td>
<td><p>High performance</p></td>
</tr>
<tr class="row-odd"><td><p>py_transforms</p></td>
<td><p>Python (based on PIL)</p></td>
<td><p>This module provides multiple image augmentation
functions and the method for converting PIL
images into NumPy arrays</p></td>
</tr>
</tbody>
</table>
<div class="section" id="id3">
<h3>Performance Optimization Solution<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p><img alt="data-enhancement-performance-scheme" src="https://gitee.com/mindspore/docs/raw/r1.6/docs/mindspore/programming_guide/source_en/images/data_enhancement_performance_scheme.png" /></p>
<p>Suggestions on data augmentation performance optimization are as follows:</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">c_transforms</span></code> module is preferentially used to perform data augmentation for its highest performance. If the performance cannot meet the requirements, refer to <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/optimize_data_processing.html#multi-thread-optimization-solution">Multi-thread Optimization Solution</a>, <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/optimize_data_processing.html#compose-optimization-solution">Compose Optimization Solution</a>, or <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/optimize_data_processing.html#operator-fusion-optimization-solution">Operator
Fusion Optimization Solution</a>.</p></li>
<li><p>If the <code class="docutils literal notranslate"><span class="pre">py_transforms</span></code> module is used to perform data augmentation and the performance still cannot meet the requirements, refer to <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/optimize_data_processing.html#multi-thread-optimization-solution">Multi-thread Optimization Solution</a>, <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/optimize_data_processing.html#multi-process-optimization-solution">Multi-process Optimization Solution</a>, <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/optimize_data_processing.html#compose-optimization-solution">Compose Optimization
Solution</a>, or <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/optimize_data_processing.html#operator-fusion-optimization-solution">Operator Fusion Optimization Solution</a>.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">c_transforms</span></code> module maintains buffer management in C++, and the <code class="docutils literal notranslate"><span class="pre">py_transforms</span></code> module maintains buffer management in Python. Because of the performance cost of switching between Python and C++, it is advised not to use different operator types together.</p></li>
<li><p>If the user-defined Python functions are used to perform data augmentation and the performance still cannot meet the requirements, use the <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/optimize_data_processing.html#multi-thread-optimization-solution">Multi-thread Optimization Solution</a> or <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/optimize_data_processing.html#multi-process-optimization-solution">Multi-process Optimization Solution</a>. If the performance still
cannot be improved, in this case, optimize the user-defined Python code.</p></li>
</ul>
<p>MindSpore also supports users to use the data enhancement methods in the <code class="docutils literal notranslate"><span class="pre">c_transforms</span></code> and <code class="docutils literal notranslate"><span class="pre">py_transforms</span></code> modules at the same time, but due to the different underlying implementations of the two, excessive mixing will increase resource overhead and reduce processing performance. It is recommended that users can use the operators in <code class="docutils literal notranslate"><span class="pre">c_transforms</span></code> or <code class="docutils literal notranslate"><span class="pre">py_transforms</span></code> alone; or use one of them first, and then use the other. Please do not switch frequently between the data enhancement
interface of two different implementation modules.</p>
</div>
<div class="section" id="id4">
<h3>Code Example<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>Based on the preceding suggestions of data augmentation performance optimization, the <code class="docutils literal notranslate"><span class="pre">c_transforms</span></code> module and user-defined Python function are used to perform data augmentation. The code is displayed as follows:</p>
<ol class="arabic simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">c_transforms</span></code> module is used to perform data augmentation. During data augmentation, the multi-thread optimization solution is used. Four threads are enabled to concurrently complete the task. The operator fusion optimization solution is used and the <code class="docutils literal notranslate"><span class="pre">RandomResizedCrop</span></code> fusion class is used to replace the <code class="docutils literal notranslate"><span class="pre">RandomResize</span></code> and <code class="docutils literal notranslate"><span class="pre">RandomCrop</span></code> classes.</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset.vision.c_transforms</span> <span class="k">as</span> <span class="nn">C</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">cifar10_path</span> <span class="o">=</span> <span class="s2">&quot;./datasets/cifar-10-batches-bin/train&quot;</span>

<span class="c1"># create Cifar10Dataset for reading data</span>
<span class="n">cifar10_dataset</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">Cifar10Dataset</span><span class="p">(</span><span class="n">cifar10_path</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">transforms</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">((</span><span class="mi">800</span><span class="p">,</span> <span class="mi">800</span><span class="p">))</span>
<span class="c1"># apply the transform to the dataset through dataset.map()</span>
<span class="n">cifar10_dataset</span> <span class="o">=</span> <span class="n">cifar10_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">transforms</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">cifar10_dataset</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/optimize_data_processing_30_0.png" src="_images/optimize_data_processing_30_0.png" />
</div>
</div>
<ol class="arabic simple" start="2">
<li><p>A user-defined Python function is used to perform data augmentation. During data augmentation, the multi-process optimization solution is used, and four processes are enabled to concurrently complete the task.</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generator_func</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="k">yield</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">3</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">4</span><span class="p">]),)</span>

<span class="n">ds3</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">generator_func</span><span class="p">,</span> <span class="n">column_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;before map:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">ds3</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>

<span class="n">func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>
<span class="n">ds4</span> <span class="o">=</span> <span class="n">ds3</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">func</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">python_multiprocessing</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;after map:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">ds4</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
before map:
[0 1 2 3 4]
[1 2 3 4 5]
[2 3 4 5 6]
[3 4 5 6 7]
[4 5 6 7 8]
after map:
[ 0  1  4  9 16]
[ 1  4  9 16 25]
[ 4  9 16 25 36]
[ 9 16 25 36 49]
[16 25 36 49 64]
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Optimizing-the-Operating-System-Performance">
<h2>Optimizing the Operating System Performance<a class="headerlink" href="#Optimizing-the-Operating-System-Performance" title="Permalink to this headline">¶</a></h2>
<p>Data processing is performed on the host. Therefore, configurations of the host or operating system may affect the performance of data processing. Major factors include storage, NUMA architecture, and CPU (computing resources).</p>
<ol class="arabic">
<li><p>Storage</p>
<p>The data loading process involves frequent disk operations, and the performance of disk reading and writing directly affects the speed of data loading. Solid State Drive (SSD) is recommended for storing large datasets. SSD reduces the impact of I/O on data processing.</p>
<blockquote>
<div><p>In most cases, after a dataset is loaded, it is stored in page cache of the operating system. To some extent, this reduces I/O overheads and accelerates reading subsequent epochs.</p>
</div></blockquote>
</li>
<li><p>NUMA architecture</p>
<p>NUMA (Non-uniform Memory Architecture) is developed to solve the scalability problem of traditional Symmetric Multi-processor systems. The NUMA system has multiple memory buses. Several processors are connected to one memory via memory bus to form a group. This way, the entire large system is divided into several groups, the concept of this group is called a node in the NUMA system. Memory belonging to this node is called local memory, memory belonging to other nodes (with respect to this
node) is called foreign memory. Therefore, the latency for each node to access its local memory is different from accessing foreign memory. This needs to be avoided during data processing. Generally, the following command can be used to bind a process to a node:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>numactl --cpubind<span class="o">=</span><span class="m">0</span> --membind<span class="o">=</span><span class="m">0</span> python train.py
</pre></div>
</div>
<p>The example above binds the <code class="docutils literal notranslate"><span class="pre">train.py</span></code> process to <code class="docutils literal notranslate"><span class="pre">numa</span> <span class="pre">node</span></code> 0.</p>
</li>
</ol>
<ol class="arabic" start="3">
<li><p>CPU (computing resource)</p>
<p>Although the data processing speed can be accelerated through multi-threaded parallel technology, there is actually no guarantee that CPU computing resources will be fully utilized. If you can artificially complete the configuration of computing resources in advance, it will be able to improve the utilization of CPU computing resources to a certain extent.</p>
<ul>
<li><p>Resource allocation</p>
<p>In distributed training, multiple training processes are run on one device. These training processes allocate and compete for computing resources based on the policy of the operating system. When there is a large number of processes, data processing performance may deteriorate due to resource contention. In some cases, users need to manually allocate resources to avoid resource contention.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>numactl --cpubind<span class="o">=</span><span class="m">0</span> python train.py
</pre></div>
</div>
<p>or</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>taskset -c <span class="m">0</span>-15 python train.py

The <span class="sb">``</span>numactl<span class="sb">``</span> method directly specifies <span class="sb">``</span>numa node id<span class="sb">``</span>. The <span class="sb">``</span>taskset<span class="sb">``</span> method allows <span class="k">for</span> finer control by specifying <span class="sb">``</span>cpu core<span class="sb">``</span> within a <span class="sb">``</span>numa node<span class="sb">``</span>. The <span class="sb">``</span>core id<span class="sb">``</span> range from <span class="m">0</span> to <span class="m">15</span>.
</pre></div>
</div>
</li>
<li><p>CPU frequency</p>
<p>The setting of CPU frequency is critical to maximizing the computing power of the host CPU. Generally, the Linux kernel supports the tuning of the CPU frequency to reduce power consumption. Power consumption can be reduced to varying degrees by selecting power management policies for different system idle states. However, lower power consumption means slower CPU wake-up which in turn impacts performance. Therefore, if the CPU’s power setting is in the conservative or powersave mode,
<code class="docutils literal notranslate"><span class="pre">cpupower</span></code> command can be used to switch performance modes, resulting in significant data processing performance improvement.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cpupower frequency-set -g performance
</pre></div>
</div>
</li>
</ul>
</li>
</ol>
</div>
<div class="section" id="Performance-Optimization-Solution-Summary">
<h2>Performance Optimization Solution Summary<a class="headerlink" href="#Performance-Optimization-Solution-Summary" title="Permalink to this headline">¶</a></h2>
<div class="section" id="Multi-thread-Optimization-Solution">
<h3>Multi-thread Optimization Solution<a class="headerlink" href="#Multi-thread-Optimization-Solution" title="Permalink to this headline">¶</a></h3>
<p>During the data pipeline process, the number of threads for related operators can be set to improve the concurrency and performance. If the user does not manually specify the <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> parameter, each data processing operation will use 8 sub-threads for concurrent processing by default. For example:</p>
<ul class="simple">
<li><p>During data loading, the <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> parameter in the built-in data loading class is used to set the number of threads.</p></li>
<li><p>During data augmentation, the <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> parameter in the <code class="docutils literal notranslate"><span class="pre">map</span></code> function is used to set the number of threads.</p></li>
<li><p>During batch processing, the <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> parameter in the <code class="docutils literal notranslate"><span class="pre">batch</span></code> function is used to set the number of threads.</p></li>
</ul>
<p>For details, see <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.6/api_python/mindspore.dataset.html">Built-in Loading Operators</a>.</p>
<p>When using MindSpore for standalone or distributed training, the setting of the <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> parameter should follow the following principles:</p>
<ul class="simple">
<li><p>The summary of the <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> parameter set for each data loading and processing operation should not be greater than the maximum number of CPU cores of the machine, otherwise it will cause resource competition between each operation.</p></li>
<li><p>Before setting the <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> parameter, it is recommended to use MindSpore’s Profiler (performance analysis) tool to analyze the performance of each operation in the training, and allocate more resources to the operation with pool performance, that is, set a large <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> to balance the throughput between various operations and avoid unnecessary waiting.</p></li>
<li><p>In a standalone training scenario, increasing the <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> parameter can often directly improve processing performance, but in a distributed scenario, due to increased CPU competition, blindly increasing <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> may lead to performance degradation. You need to try to use a compromise value.</p></li>
</ul>
</div>
<div class="section" id="Multi-process-Optimization-Solution">
<h3>Multi-process Optimization Solution<a class="headerlink" href="#Multi-process-Optimization-Solution" title="Permalink to this headline">¶</a></h3>
<p>During data processing, operators implemented by Python support the multi-process mode. For example:</p>
<ul class="simple">
<li><p>By default, the <code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code> class is in multi-process mode. The <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> parameter indicates the number of enabled processes. The default value is 1. For details, see <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.6/api_python/dataset/mindspore.dataset.GeneratorDataset.html">GeneratorDataset</a>.</p></li>
<li><p>If the user-defined Python function or the <code class="docutils literal notranslate"><span class="pre">py_transforms</span></code> module is used to perform data augmentation and the <code class="docutils literal notranslate"><span class="pre">python_multiprocessing</span></code> parameter of the <code class="docutils literal notranslate"><span class="pre">map</span></code> function is set to True, the <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> parameter indicates the number of processes and the default value of the <code class="docutils literal notranslate"><span class="pre">python_multiprocessing</span></code> parameter is False. In this case, the <code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code> parameter indicates the number of threads. For details, see <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.6/api_python/mindspore.dataset.html">Built-in Loading
Operators</a>.</p></li>
</ul>
</div>
<div class="section" id="Compose-Optimization-Solution">
<h3>Compose Optimization Solution<a class="headerlink" href="#Compose-Optimization-Solution" title="Permalink to this headline">¶</a></h3>
<p>Map operators can receive the Tensor operator list and apply all these operators based on a specific sequence. Compared with the Map operator used by each Tensor operator, such Fat Map operators can achieve better performance, as shown in the following figure:</p>
<p><img alt="compose" src="https://gitee.com/mindspore/docs/raw/r1.6/docs/mindspore/programming_guide/source_en/images/compose.png" /></p>
</div>
<div class="section" id="Operator-Fusion-Optimization-Solution">
<h3>Operator Fusion Optimization Solution<a class="headerlink" href="#Operator-Fusion-Optimization-Solution" title="Permalink to this headline">¶</a></h3>
<p>Some fusion operators are provided to aggregate the functions of two or more operators into one operator. For details, see <a class="reference external" href="https://www.mindspore.cn/docs/api/en/r1.6/api_python/mindspore.dataset.vision.html">Augmentation Operators</a>. Compared with the pipelines of their components, such fusion operators provide better performance. As shown in the figure:</p>
<p><img alt="operator-fusion" src="https://gitee.com/mindspore/docs/raw/r1.6/docs/mindspore/programming_guide/source_en/images/operator_fusion.png" /></p>
</div>
<div class="section" id="Operating-System-Optimization-Solution">
<h3>Operating System Optimization Solution<a class="headerlink" href="#Operating-System-Optimization-Solution" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Use Solid State Drives to store the data.</p></li>
<li><p>Bind the process to a NUMA node.</p></li>
<li><p>Manually allocate more computing resources.</p></li>
<li><p>Set a higher CPU frequency.</p></li>
</ul>
</div>
</div>
<div class="section" id="References">
<h2>References<a class="headerlink" href="#References" title="Permalink to this headline">¶</a></h2>
<p>[1] Alex Krizhevsky. <a class="reference external" href="http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf">Learning Multiple Layers of Features from Tiny Images</a>.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="dataset_usage.html" class="btn btn-neutral float-right" title="Data Iteration" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="cache.html" class="btn btn-neutral float-left" title="Single-Node Tensor Cache" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>