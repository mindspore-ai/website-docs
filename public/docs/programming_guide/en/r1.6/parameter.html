<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Network Parameters &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/training.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/js/training.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Using the Process Control Statement" href="control_flow.html" />
    <link rel="prev" title="Initializer" href="initializer.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Overall Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/technical_white_paper.html">Technical White Paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/gradient.html">MindSpore Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.6/training_visual_design.html">Design of Visualization↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.6/linear_regression.html">Implementing Simple Linear Function Fitting↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.6/quick_start.html">Implementing an Image Classification Application↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dtype.html">DataType</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter_introduction.html">Parameter</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="cell.html">Cell</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_introduction.html">Dataset</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Pipeline</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataset_sample.html">Quick Start of Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Processing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_advanced.html">Advanced Usage of Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_usage.html">Data Iteration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build the Network</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="build_net.html">Constructing Single Operator Network and Multi-layer Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="initializer.html">Initializer</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Network Parameters</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#parameters">Parameters</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#declaration">Declaration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#attributes">Attributes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#methods">Methods</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#parametertuple">ParameterTuple</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-encapsulation-operator-to-initialize-parameters">Using Encapsulation Operator to Initialize Parameters</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#character-string">Character String</a></li>
<li class="toctree-l3"><a class="reference internal" href="#initializer-subclass">Initializer Subclass</a></li>
<li class="toctree-l3"><a class="reference internal" href="#the-custom-of-the-tensor">The Custom of the Tensor</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#dependency-control">Dependency Control</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="control_flow.html">Using the Process Control Statement</a></li>
<li class="toctree-l1"><a class="reference internal" href="indefinite_parameter.html">Parameter Passing</a></li>
<li class="toctree-l1"><a class="reference internal" href="loss.html">Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="grad_operation.html">Gradient Operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="constexpr.html">Construct Constants In the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypermap.html">Operation Overloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">Optimization Algorithms</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Running</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="context.html">Configuring Running Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="run.html">Running Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_and_load_models.html">Save and Load Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="model.html">Application of Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="online_inference.html">Online Inference with Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="offline_inference.html">Using Offline Model for Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">Distributed Parallel Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_advanced.html">Distributed Parallel Advanced Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_example.html">Distributed Parallel Usage Example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyNative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Numpy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">NumPy Interfaces in MindSpore</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Function Debugging</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="read_ir_files.html">Reading IR</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/debug_in_pynative_mode.html">Debugging in PyNative Mode↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_tune.html">AutoTune</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_dataset_autotune.html">Dataset AutoTune for Dataset Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_dataset_offload.html">Enabling Offload for Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.6/performance_profiling.html">Debugging performance with Profiler↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="second_order_optimizer.html">Second Order Optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_kernel_fusion.html">Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Quantization Aware Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Network Parameters</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/parameter.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="network-parameters">
<h1>Network Parameters<a class="headerlink" href="#network-parameters" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Development</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.6/docs/mindspore/programming_guide/source_en/parameter.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.6/resource/_static/logo_source_en.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">Parameter</span></code> is a variable tensor, indicating the parameters that need to be updated during network training. The following describes the <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> initialization, attributes, methods, and <code class="docutils literal notranslate"><span class="pre">ParameterTuple</span></code>. The following describes the Parameter initialization, attributes, methods,  ParameterTuple and dependency control.</p>
</section>
<section id="parameters">
<h2>Parameters<a class="headerlink" href="#parameters" title="Permalink to this headline"></a></h2>
<p>Parameter is a variable tensor, indicating the parameters that need to be updated during network training.</p>
<section id="declaration">
<h3>Declaration<a class="headerlink" href="#declaration" title="Permalink to this headline"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mindspore</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">default_input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">layerwise_parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">default_input</span></code>: Initialize a <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> object. The input data supports the <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">Initializer</span></code>, <code class="docutils literal notranslate"><span class="pre">int</span></code>, and <code class="docutils literal notranslate"><span class="pre">float</span></code> types. The <code class="docutils literal notranslate"><span class="pre">initializer</span></code> API can be called to generate the <code class="docutils literal notranslate"><span class="pre">Initializer</span></code> object. When <code class="docutils literal notranslate"><span class="pre">init</span></code> is used to initialize <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, the <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> only stores the shape and type of the tensor, not the actual data. Therefore, <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> does not occupy any memory, you can call the <code class="docutils literal notranslate"><span class="pre">init_data</span></code> API to convert <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> saved in <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> to the actual data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: You can specify a name for each <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> to facilitate subsequent operations and updates. It is recommended to use the default value of <code class="docutils literal notranslate"><span class="pre">name</span></code> when initialize a parameter as one attribute of a cell, otherwise, the parameter name may be different than expected.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">requires_grad</span></code>: update a parameter, set <code class="docutils literal notranslate"><span class="pre">requires_grad</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">layerwise_parallel</span></code>: When <code class="docutils literal notranslate"><span class="pre">layerwise_parallel</span></code> is set to True, this parameter will be filtered out during parameter broadcast and parameter gradient aggregation.</p></li>
</ul>
<p>For details about the configuration of distributed parallelism, see <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/auto_parallel.html">https://www.mindspore.cn/docs/programming_guide/en/r1.6/auto_parallel.html</a>.</p>
<p>In the following example, <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> objects are built using three different data types. All the three <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> objects need to be updated, and layerwise parallelism is not used.</p>
<p>The code sample is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Parameter</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">initializer</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">default_input</span><span class="o">=</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">default_input</span><span class="o">=</span><span class="n">initializer</span><span class="p">(</span><span class="s1">&#39;ones&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">default_input</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;z&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span> Parameter (name=x, shape=(2, 3), dtype=Int32, requires_grad=True)

 Parameter (name=y, shape=(1, 2, 3), dtype=Float32, requires_grad=True)

 Parameter (name=z, shape=(), dtype=Float32, requires_grad=True)
</pre></div>
</div>
</section>
<section id="attributes">
<h3>Attributes<a class="headerlink" href="#attributes" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">inited_param</span></code>: returns <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> that stores the actual data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: specifies a name for an instantiated <code class="docutils literal notranslate"><span class="pre">Parameter</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sliced</span></code>: specifies whether the data stored in <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> is sharded data in the automatic parallel scenario.</p></li>
</ul>
<p>If yes, do not shard the data. Otherwise, determine whether to shard the data based on the network parallel strategy.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">is_init</span></code>: initialization status of <code class="docutils literal notranslate"><span class="pre">Parameter</span></code>. At the GE backend, an <code class="docutils literal notranslate"><span class="pre">init</span> <span class="pre">graph</span></code> is required to synchronize data from the host to the device. This parameter specifies whether the data has been synchronized to the device.
This parameter takes effect only at the GE backend. This parameter is set to False at other backends.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">layerwise_parallel</span></code>: specifies whether <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> supports layerwise parallelism. If yes, parameters are not broadcasted and gradient aggregation is not performed. Otherwise, parameters need to be broadcasted and gradient aggregation is performed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">requires_grad</span></code>: specifies whether to compute the parameter gradient. If a parameter needs to be trained, the parameter gradient needs to be computed. Otherwise, the parameter gradient does not need to be computed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code>: <code class="docutils literal notranslate"><span class="pre">Parameter</span></code>.</p></li>
</ul>
<p>In the following example, <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> is initialized through <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> to obtain its attributes.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Parameter</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">default_input</span><span class="o">=</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;name: &quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="s2">&quot;sliced: &quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">sliced</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="s2">&quot;is_init: &quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">is_init</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="s2">&quot;inited_param: &quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">inited_param</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="s2">&quot;requires_grad: &quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="s2">&quot;layerwise_parallel: &quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">layerwise_parallel</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
      <span class="s2">&quot;data: &quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>name:  Parameter
sliced:  False
is_init:  False
inited_param:  None
requires_grad:  True
layerwise_parallel:  False

data:  Parameter (name=Parameter, shape=(2, 3), dtype=Int64, requires_grad=True)
</pre></div>
</div>
</section>
<section id="methods">
<h3>Methods<a class="headerlink" href="#methods" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">init_data</span></code>: When the network uses the semi-automatic or automatic parallel strategy, and the data input during <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> initialization is <code class="docutils literal notranslate"><span class="pre">Initializer</span></code>, this API can be called to convert the data saved by <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> to <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">set_data</span></code>: sets the data saved by <code class="docutils literal notranslate"><span class="pre">Parameter</span></code>. <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">Initializer</span></code>, <code class="docutils literal notranslate"><span class="pre">int</span></code>, and <code class="docutils literal notranslate"><span class="pre">float</span></code> can be input for setting.
When the input parameter <code class="docutils literal notranslate"><span class="pre">slice_shape</span></code> of the method is set to True, the shape of <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> can be changed. Otherwise, the configured shape must be the same as the original shape of <code class="docutils literal notranslate"><span class="pre">Parameter</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">set_param_ps</span></code>: controls whether training parameters are trained by using the <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/apply_parameter_server_training.html">Parameter Server</a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clone</span></code>: clones <code class="docutils literal notranslate"><span class="pre">Parameter</span></code>. You can specify the parameter name after cloning.</p></li>
</ul>
<p>In the following example, <code class="docutils literal notranslate"><span class="pre">Initializer</span></code> is used to initialize <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, and methods related to <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> are called.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Parameter</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">initializer</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">default_input</span><span class="o">=</span><span class="n">initializer</span><span class="p">(</span><span class="s1">&#39;ones&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x_clone</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="n">x_clone</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;x_clone&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_clone</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">init_data</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))))</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Parameter (name=Parameter, shape=(1, 2, 3), dtype=Float32, requires_grad=True)
Parameter (name=x_clone, shape=(1, 2, 3), dtype=Float32, requires_grad=True)
Parameter (name=Parameter, shape=(1, 2, 3), dtype=Float32, requires_grad=True)
Parameter (name=Parameter, shape=(1, 2, 3), dtype=Float32, requires_grad=True)
</pre></div>
</div>
</section>
</section>
<section id="parametertuple">
<h2>ParameterTuple<a class="headerlink" href="#parametertuple" title="Permalink to this headline"></a></h2>
<p>Inherited from <code class="docutils literal notranslate"><span class="pre">tuple</span></code>, <code class="docutils literal notranslate"><span class="pre">ParameterTuple</span></code> is used to store multiple <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> objects. <code class="docutils literal notranslate"><span class="pre">__new__(cls,</span> <span class="pre">iterable)</span></code> is used to transfer an iterator for storing <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> for building, and the <code class="docutils literal notranslate"><span class="pre">clone</span></code> API is provided for cloning.</p>
<p>The following example builds a <code class="docutils literal notranslate"><span class="pre">ParameterTuple</span></code> object and clones it.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">ParameterTuple</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">initializer</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">default_input</span><span class="o">=</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">default_input</span><span class="o">=</span><span class="n">initializer</span><span class="p">(</span><span class="s1">&#39;ones&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">default_input</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;z&#39;</span><span class="p">)</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">ParameterTuple</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">))</span>
<span class="n">params_copy</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="s2">&quot;params_copy&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">params_copy</span><span class="p">)</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>(Parameter (name=x, shape=(2, 3), dtype=Int32, requires_grad=True), Parameter (name=y, shape=(1, 2, 3), dtype=Float32, requires_grad=True), Parameter (name=z, shape=(), dtype=Float32, requires_grad=True))

(Parameter (name=params_copy.x, shape=(2, 3), dtype=Int32, requires_grad=True), Parameter (name=params_copy.y, shape=(1, 2, 3), dtype=Float32, requires_grad=True), Parameter (name=params_copy.z, shape=(), dtype=Float32, requires_grad=True))
</pre></div>
</div>
</section>
<section id="using-encapsulation-operator-to-initialize-parameters">
<h2>Using Encapsulation Operator to Initialize Parameters<a class="headerlink" href="#using-encapsulation-operator-to-initialize-parameters" title="Permalink to this headline"></a></h2>
<p>Mindspore provides a variety of methods of initializing parameters, and encapsulates parameter initialization functions in some operators. This section will introduce the method of initialization of parameters by operators with parameter initialization function. Taking <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> operator as an example, it will introduce the initialization of parameters in the network by strings, <code class="docutils literal notranslate"><span class="pre">Initializer</span></code> subclass and custom <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, etc. <code class="docutils literal notranslate"><span class="pre">Normal</span></code>, a subclass of <code class="docutils literal notranslate"><span class="pre">Initializer</span></code>, is used in the following code examples and can be replaced with any of the subclasses of Initializer in the code examples.</p>
<section id="character-string">
<h3>Character String<a class="headerlink" href="#character-string" title="Permalink to this headline"></a></h3>
<p>Network parameters are initialized using a string. The contents of the string need to be consistent with the name of the <code class="docutils literal notranslate"><span class="pre">Initializer</span></code> subclass(Letters are not case sensitive). Initialization using a string will use the default parameters in the <code class="docutils literal notranslate"><span class="pre">Initializer</span></code> subclass. For example, using the string <code class="docutils literal notranslate"><span class="pre">Normal</span></code> is equivalent to using the <code class="docutils literal notranslate"><span class="pre">Initializer</span></code> subclass <code class="docutils literal notranslate"><span class="pre">Normal()</span></code>. The code sample is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">set_seed</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">input_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;Normal&#39;</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[ 3.10382620e-02  4.38603461e-02  4.38603461e-02 ...  4.38603461e-02
     4.38603461e-02  1.38719045e-02]
   [ 3.26051228e-02  3.54298912e-02  3.54298912e-02 ...  3.54298912e-02
     3.54298912e-02 -5.54019120e-03]
   [ 3.26051228e-02  3.54298912e-02  3.54298912e-02 ...  3.54298912e-02
     3.54298912e-02 -5.54019120e-03]
   ...
   [ 3.26051228e-02  3.54298912e-02  3.54298912e-02 ...  3.54298912e-02
     3.54298912e-02 -5.54019120e-03]
   [ 3.26051228e-02  3.54298912e-02  3.54298912e-02 ...  3.54298912e-02
     3.54298912e-02 -5.54019120e-03]
   [ 9.66199022e-03  1.24104535e-02  1.24104535e-02 ...  1.24104535e-02
     1.24104535e-02 -1.38977719e-02]]

  ...

  [[ 3.98553275e-02 -1.35465711e-03 -1.35465711e-03 ... -1.35465711e-03
    -1.35465711e-03 -1.00310734e-02]
   [ 4.38403059e-03 -3.60766202e-02 -3.60766202e-02 ... -3.60766202e-02
    -3.60766202e-02 -2.95619294e-02]
   [ 4.38403059e-03 -3.60766202e-02 -3.60766202e-02 ... -3.60766202e-02
    -3.60766202e-02 -2.95619294e-02]
   ...
   [ 4.38403059e-03 -3.60766202e-02 -3.60766202e-02 ... -3.60766202e-02
    -3.60766202e-02 -2.95619294e-02]
   [ 4.38403059e-03 -3.60766202e-02 -3.60766202e-02 ... -3.60766202e-02
    -3.60766202e-02 -2.95619294e-02]
   [ 1.33139016e-02  6.74417242e-05  6.74417242e-05 ...  6.74417242e-05
     6.74417242e-05 -2.27325838e-02]]]]
</pre></div>
</div>
</section>
<section id="initializer-subclass">
<h3>Initializer Subclass<a class="headerlink" href="#initializer-subclass" title="Permalink to this headline"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Initializer</span></code> subclass is used to initialize network parameters, which is similar to the effect of using string to initialize parameters.  The difference is that using string to initialize parameters uses the default parameter of the <code class="docutils literal notranslate"><span class="pre">Initializer</span></code> subclass. If you want to use the parameters in the <code class="docutils literal notranslate"><span class="pre">Initializer</span></code> subclass, the <code class="docutils literal notranslate"><span class="pre">Initializer</span></code> subclass must be used to initialize the parameters. Taking <code class="docutils literal notranslate"><span class="pre">Normal(0.2)</span></code> as an example, the code sample is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">set_seed</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">Normal</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">input_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[ 6.2076533e-01  8.7720710e-01  8.7720710e-01 ...  8.7720710e-01
     8.7720710e-01  2.7743810e-01]
   [ 6.5210247e-01  7.0859784e-01  7.0859784e-01 ...  7.0859784e-01
     7.0859784e-01 -1.1080378e-01]
   [ 6.5210247e-01  7.0859784e-01  7.0859784e-01 ...  7.0859784e-01
     7.0859784e-01 -1.1080378e-01]
   ...
   [ 6.5210247e-01  7.0859784e-01  7.0859784e-01 ...  7.0859784e-01
     7.0859784e-01 -1.1080378e-01]
   [ 6.5210247e-01  7.0859784e-01  7.0859784e-01 ...  7.0859784e-01
     7.0859784e-01 -1.1080378e-01]
   [ 1.9323981e-01  2.4820906e-01  2.4820906e-01 ...  2.4820906e-01
     2.4820906e-01 -2.7795550e-01]]

  ...

  [[ 7.9710668e-01 -2.7093157e-02 -2.7093157e-02 ... -2.7093157e-02
    -2.7093157e-02 -2.0062150e-01]
   [ 8.7680638e-02 -7.2153252e-01 -7.2153252e-01 ... -7.2153252e-01
    -7.2153252e-01 -5.9123868e-01]
   [ 8.7680638e-02 -7.2153252e-01 -7.2153252e-01 ... -7.2153252e-01
    -7.2153252e-01 -5.9123868e-01]
   ...
   [ 8.7680638e-02 -7.2153252e-01 -7.2153252e-01 ... -7.2153252e-01
    -7.2153252e-01 -5.9123868e-01]
   [ 8.7680638e-02 -7.2153252e-01 -7.2153252e-01 ... -7.2153252e-01
    -7.2153252e-01 -5.9123868e-01]
   [ 2.6627803e-01  1.3488382e-03  1.3488382e-03 ...  1.3488382e-03
     1.3488382e-03 -4.5465171e-01]]]]
</pre></div>
</div>
</section>
<section id="the-custom-of-the-tensor">
<h3>The Custom of the Tensor<a class="headerlink" href="#the-custom-of-the-tensor" title="Permalink to this headline"></a></h3>
<p>In addition to the above two initialization methods,  when the network wants to use data types that are not available in MindSpore, users can customize <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> to initialize the parameters. The code sample is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>

<span class="n">weight</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">input_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="n">weight</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[12. 18. 18. ... 18. 18. 12.]
   [18. 27. 27. ... 27. 27. 18.]
   [18. 27. 27. ... 27. 27. 18.]
   ...
   [18. 27. 27. ... 27. 27. 18.]
   [18. 27. 27. ... 27. 27. 18.]
   [12. 18. 18. ... 18. 18. 12.]]

  ...

  [[12. 18. 18. ... 18. 18. 12.]
   [18. 27. 27. ... 27. 27. 18.]
   [18. 27. 27. ... 27. 27. 18.]
   ...
   [18. 27. 27. ... 27. 27. 18.]
   [18. 27. 27. ... 27. 27. 18.]
   [12. 18. 18. ... 18. 18. 12.]]]]
</pre></div>
</div>
</section>
</section>
<section id="dependency-control">
<h2>Dependency Control<a class="headerlink" href="#dependency-control" title="Permalink to this headline"></a></h2>
<p>If the result of a function depends on or affects an external state, we consider that the function has side effects, such as a function changing an external global variable, and the result of a function depends on the value of a global variable. If the operator changes the value of the input parameter or the output of the operator depends on the value of the global parameter, we think this is an operator with side effects.</p>
<p>Side effects are classified as memory side effects and IO side effects based on memory properties and IO status. At present, memory side effects are mainly Assign, optimizer operators and so on, IO side effects are mainly Print operators. You can view the operator definition in detail, the memory side effect operator has side_effect_mem properties in the definition, and the IO side effect operator has side_effect_io properties in the definition.</p>
<p>Depend is used for processing dependency operations.In most cases, if the operators have IO or memory side effects, they will be executed according to the user’s semantics, and there is no need to use the Depend operator to guarantee the execution order.In some cases, if the two operators A and B do not have sequential dependencies, and A must execute before B, we recommend that you use Depend to specify the order in which they are executed. Here’s how to use it:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">A</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>                <span class="o">---&gt;</span>        <span class="n">a</span> <span class="o">=</span> <span class="n">A</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">B</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>                <span class="o">---&gt;</span>        <span class="n">y</span> <span class="o">=</span> <span class="n">Depend</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
                        <span class="o">---&gt;</span>        <span class="n">b</span> <span class="o">=</span> <span class="n">B</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>Please note that a special set of operators for floating point overflow state detection have hidden side effects, but are not IO side effects or memory side effects. In addition, there are strict sequencing requirements for use, i.e., before using the NPUClearFloatStatus operator, you need to ensure that the NPU AllocFloatStatus has been executed, and before using the NPUGetFloatStatus operator, you need to ensure that the NPUClearFlotStatus has been executed. Because these operators are used less, the current scenario is to keep them defined as side-effect-free in the form of Depend ensuring execution order. These operators are only supported on Ascend. Examples are as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span><span class="p">,</span> <span class="n">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>

<span class="n">npu_alloc_status</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NPUAllocFloatStatus</span><span class="p">()</span>
<span class="n">npu_get_status</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NPUGetFloatStatus</span><span class="p">()</span>
<span class="n">npu_clear_status</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NPUClearFloatStatus</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">npu_alloc_status</span><span class="p">()</span>
<span class="n">sum_</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Add</span><span class="p">()(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">product</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">MatMul</span><span class="p">()(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">depend</span><span class="p">(</span><span class="n">init</span><span class="p">,</span> <span class="n">sum_</span><span class="p">)</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">depend</span><span class="p">(</span><span class="n">init</span><span class="p">,</span> <span class="n">product</span><span class="p">)</span>
<span class="n">get_status</span> <span class="o">=</span> <span class="n">npu_get_status</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
<span class="n">sum_</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">depend</span><span class="p">(</span><span class="n">sum_</span><span class="p">,</span> <span class="n">get_status</span><span class="p">)</span>
<span class="n">product</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">depend</span><span class="p">(</span><span class="n">product</span><span class="p">,</span> <span class="n">get_status</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Add</span><span class="p">()(</span><span class="n">sum_</span><span class="p">,</span> <span class="n">product</span><span class="p">)</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">depend</span><span class="p">(</span><span class="n">init</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
<span class="n">clear</span> <span class="o">=</span> <span class="n">npu_clear_status</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">depend</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">clear</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
<p>The output is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[5. 5. 5.]
 [5. 5. 5.]
 [5. 5. 5.]]
</pre></div>
</div>
<p>Specific usage methods can refer to the implementation of <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r1.6/mindspore/python/mindspore/nn/wrap/loss_scale.py">start_overflow_check functions</a> in the overflow detection logic.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="initializer.html" class="btn btn-neutral float-left" title="Initializer" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="control_flow.html" class="btn btn-neutral float-right" title="Using the Process Control Statement" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>