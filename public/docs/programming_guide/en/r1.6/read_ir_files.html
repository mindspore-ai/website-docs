<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Reading IR &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/training.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/js/training.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Using Dump in the Graph Mode" href="dump_in_graph_mode.html" />
    <link rel="prev" title="NumPy Interfaces in MindSpore" href="numpy.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Overall Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/technical_white_paper.html">Technical White Paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/gradient.html">MindSpore Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.6/training_visual_design.html">Design of Visualization↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.6/linear_regression.html">Implementing Simple Linear Function Fitting↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.6/quick_start.html">Implementing an Image Classification Application↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dtype.html">DataType</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter_introduction.html">Parameter</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="cell.html">Cell</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_introduction.html">Dataset</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Pipeline</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataset_sample.html">Quick Start of Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Processing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_advanced.html">Advanced Usage of Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_usage.html">Data Iteration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build the Network</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="build_net.html">Constructing Single Operator Network and Multi-layer Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="initializer.html">Initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter.html">Network Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="control_flow.html">Using the Process Control Statement</a></li>
<li class="toctree-l1"><a class="reference internal" href="indefinite_parameter.html">Parameter Passing</a></li>
<li class="toctree-l1"><a class="reference internal" href="loss.html">Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="grad_operation.html">Gradient Operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="constexpr.html">Construct Constants In the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypermap.html">Operation Overloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">Optimization Algorithms</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Running</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="context.html">Configuring Running Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="run.html">Running Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_and_load_models.html">Save and Load Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="model.html">Application of Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="online_inference.html">Online Inference with Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="offline_inference.html">Using Offline Model for Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">Distributed Parallel Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_advanced.html">Distributed Parallel Advanced Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_example.html">Distributed Parallel Usage Example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyNative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Numpy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">NumPy Interfaces in MindSpore</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Function Debugging</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Reading IR</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#saving-ir">Saving IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ir-file-contents-introduction">IR File Contents Introduction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#ir-introduction">ir Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dat-introduction">dat Introduction</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#reading-analyze-fail-dat">Reading analyze_fail.dat</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/debug_in_pynative_mode.html">Debugging in PyNative Mode↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_tune.html">AutoTune</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_dataset_autotune.html">Dataset AutoTune for Dataset Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_dataset_offload.html">Enabling Offload for Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.6/performance_profiling.html">Debugging performance with Profiler↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="second_order_optimizer.html">Second Order Optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_kernel_fusion.html">Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Quantization Aware Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Reading IR</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/read_ir_files.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="reading-ir">
<h1>Reading IR<a class="headerlink" href="#reading-ir" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Optimization</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.6/docs/mindspore/programming_guide/source_en/read_ir_files.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.6/resource/_static/logo_source_en.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>When a model compiled using MindSpore runs in the graph mode <code class="docutils literal notranslate"><span class="pre">context.set_context(mode=context.GRAPH_MODE)</span></code> and <code class="docutils literal notranslate"><span class="pre">context.set_context(save_graphs=True)</span></code> is set in the configuration, some intermediate files will be generated during graph compliation. These intermediate files are called IR files. Currently, there are three IR files:</p>
<ul class="simple">
<li><p>.ir file: An IR file that describes the model structure in text format and can be directly viewed using any text editors.</p></li>
<li><p>.dat file: An IR file that describes the model structure more strictly than the .ir file. It contains more contents and can be directly viewed using any text editors.</p></li>
<li><p>.dot file: An IR file that describes the topology relationships between different nodes. You can use this file by <a class="reference external" href="http://graphviz.org/">graphviz</a> as the input to generate images for users to view the model structure. For models with multiple operators, it is recommended using the visualization component <a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.6/dashboard.html#computational-graph-visualization">MindInsight</a> to visualize computing graphs.</p></li>
</ul>
</section>
<section id="saving-ir">
<h2>Saving IR<a class="headerlink" href="#saving-ir" title="Permalink to this headline"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">context.set_context(save_graphs=True)</span></code> is used to save the intermediate code in each compilation phase. The intermediate code can be saved in two formats. One is the text format with the suffix <code class="docutils literal notranslate"><span class="pre">.ir</span></code>, and the other is the graphical format with the suffix <code class="docutils literal notranslate"><span class="pre">.dot</span></code>. When the network scale is small, you are advised to use the graphical format that is more intuitive. When the network scale is large, you are advised to use the text format that is more efficient.</p>
<p>You can run the graphviz command to convert a .dot file to the picture format. For example, you can run the <code class="docutils literal notranslate"><span class="pre">dot</span> <span class="pre">-Tpng</span> <span class="pre">*.dot</span> <span class="pre">-o</span> <span class="pre">*.png</span></code> command to convert a <code class="docutils literal notranslate"><span class="pre">.dot</span></code> file to a .png file.</p>
<p>Add the following code to <code class="docutils literal notranslate"><span class="pre">train.py</span></code>. When running the script, MindSpore will automatically store the IR files generated during compilation under the specified path.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">save_graphs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_graphs_path</span><span class="o">=</span><span class="s2">&quot;path/to/ir/files&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>After the training command is executed, some files are generated in the path of <code class="docutils literal notranslate"><span class="pre">save_graphs_path</span></code>.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>.
├──00_parse_0000.ir
├──00_parse_0001.dat
├──00_parse_0002.dot
├──01_symbol_resolve_0003.ir
├──01_symbol_resolve_0004.dat
├──01_symbol_resolve_0005.dot
├──02_combine_like_graphs_0006.ir
├──02_combine_like_graphs_0007.dat
├──02_combine_like_graphs_0008.dot
├──03_inference_opt_prepare_0009.ir
├──03_inference_opt_prepare_0010.dat
├──03_inference_opt_prepare_0011.dot
├──04_abstract_specialize_0012.ir
├──04_abstract_specialize_0013.dat
├──04_abstract_specialize_0014.dot
...
</pre></div>
</div>
<p>The IR files starting with digits and underscores are generated during the ME graph compilation. The compute graph is
saved in each phase of the <code class="docutils literal notranslate"><span class="pre">pipeline</span></code>. Let’s see the important phases.</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">parse</span></code> phase parses the <code class="docutils literal notranslate"><span class="pre">construct</span></code> function of the entrance. If viewing the IR file, we can see that only the
graph information of the top cell is parsed in this phase.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">symbol_resolve</span></code> phase recursively parses other functions and objects directly or indirectly referenced by the
entry function. When using the unsupported syntax, it will get an error in this phase.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">abstract_specialize</span></code> phase infers every node’s <code class="docutils literal notranslate"><span class="pre">data</span> <span class="pre">type</span></code> and <code class="docutils literal notranslate"><span class="pre">shape</span></code> by the cell’s inputs. When you want to
know the shape or data type of a specific operator in IR, you can view this IR file.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">optimize</span></code> phase, hardware-independent optimization is performed, the automatic differential and automatic
parallel functions are also performed. Some ir files with the prefix <code class="docutils literal notranslate"><span class="pre">opt_pass</span></code> are saved here. No need to pay too
much attention to those files if you are not the framework developer.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">validate</span></code> phase will check the temporary operators which should be removed in the prior phase. If any temporary
operator exists, the process will report an error and exit.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">task_emit</span></code> phase will transfer the compute graph to the backend for further processing.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">execute</span></code> phase will execute the compute graph. This is the final graph in the phase of frontend.</p></li>
</ul>
<p>In addition, you don’t need to pay too much attention to the IR files (such as files beginning with <code class="docutils literal notranslate"><span class="pre">hwopt</span></code>) if you are
not the framework developer because the backend is close to the hardware. Only need pay attention to the
file <code class="docutils literal notranslate"><span class="pre">graph_build_[graph_id]_[IR_id].ir</span></code>. It is the MindIR after the frontend and backend optimization.</p>
<blockquote>
<div><p>Multiple files may be saved because the backend only can handle the single graph.
It is different with the frontend when the front save all sub-graphs in the one file.</p>
</div></blockquote>
</section>
<section id="ir-file-contents-introduction">
<h2>IR File Contents Introduction<a class="headerlink" href="#ir-file-contents-introduction" title="Permalink to this headline"></a></h2>
<p>The following is an example to describe the contents of the IR file. The content may have some changes with the version upgrade of MindSpore.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.context</span> <span class="k">as</span> <span class="nn">context</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">save_graphs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_graphs_path</span><span class="o">=</span><span class="s2">&quot;./&quot;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Add</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sub</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sub</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mul</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Mul</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">div</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Div</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">c</span>

<span class="n">input1</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">input2</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
<section id="ir-introduction">
<h3>ir Introduction<a class="headerlink" href="#ir-introduction" title="Permalink to this headline"></a></h3>
<p>Use a text editing software (for example, vi) to open the <code class="docutils literal notranslate"><span class="pre">04_abstract_specialize_0012.ir</span></code> file. The file contents are as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  1 #IR entry      : @1_construct_wrapper.21
  2 #attrs         :
  3 #Total params  : 2
  4
  5 %para1_x : &lt;Tensor[Float32]x()&gt;
  6 %para2_y : &lt;Tensor[Float32]x()&gt;
  7
  8 #Total subgraph : 3
  9
 10 subgraph attr:
 11 Undeterminate : 0
 12 subgraph @2_construct.22(%para3_x, %para4_y) {
 13   %0(a) = Sub(%para3_x, Tensor(shape=[], dtype=Float32, value= 1)) {instance name: sub} primitive_attrs: {input_names: [x, y], output_names: [output]}
 14       : (&lt;Tensor[Float32]x()&gt;, &lt;Tensor[Float32]x()&gt;) -&gt; (&lt;Tensor[Float32]x()&gt;)
 15       # In file train.py(34)/        a = self.sub(x, 1)/
 16   %1(b) = Add(%0, %para4_y) {instance name: add} primitive_attrs: {input_names: [x, y], output_names: [output]}
 17       : (&lt;Tensor[Float32]x()&gt;, &lt;Tensor[Float32]x()&gt;) -&gt; (&lt;Tensor[Float32]x()&gt;)
 18       # In file train.py(35)/        b = self.add(a, y)/
 19   %2([CNode]5) = call @3_func.23(%0, %1)
 20       : (&lt;Tensor[Float32]x()&gt;, &lt;Tensor[Float32]x()&gt;) -&gt; (&lt;Tensor[Float32]x()&gt;)
 21       # In file train.py(36)/        c = self.mul(b, self.func(a, b))/
 22   %3(c) = Mul(%1, %2) {instance name: mul} primitive_attrs: {input_names: [x, y], output_names: [output]}
 23       : (&lt;Tensor[Float32]x()&gt;, &lt;Tensor[Float32]x()&gt;) -&gt; (&lt;Tensor[Float32]x()&gt;)
 24       # In file train.py(36)/        c = self.mul(b, self.func(a, b))/
 25   Return(%3)
 26       : (&lt;Tensor[Float32]x()&gt;)
 27       # In file train.py(37)/        return c/
 28 }
 29
 30 subgraph attr:
 31 Undeterminate : 0
 32 subgraph @3_func.23(%para5_x, %para6_y) {
 33   %0([CNode]20) = Div(%para5_x, %para6_y) {instance name: div} primitive_attrs: {input_names: [x, y], output_names: [output]}
 34       : (&lt;Tensor[Float32]x()&gt;, &lt;Tensor[Float32]x()&gt;) -&gt; (&lt;Tensor[Float32]x()&gt;)
 35       # In file train.py(31)/        return self.div(x, y)/
 36   Return(%0)
 37       : (&lt;Tensor[Float32]x()&gt;)
 38       # In file train.py(31)/        return self.div(x, y)/
 39 }
 40
 41 subgraph attr:
 42 subgraph @1_construct_wrapper.21() {
 43   %0([CNode]2) = call @2_construct.22(%para1_x, %para2_y)
 44       : (&lt;Tensor[Float32]x()&gt;, &lt;Tensor[Float32]x()&gt;) -&gt; (&lt;Tensor[Float32]x()&gt;)
 45       # In file train.py(37)/        return c/
 46   Return(%0)
 47       : (&lt;Tensor[Float32]x()&gt;)
 48       # In file train.py(37)/        return c/
 49 }
</pre></div>
</div>
<p>The above contents can be divided into two parts, the first part is the input list and the second part is the graph structure.
The first line tells us the name of the top MindSpore graph about the network, <code class="docutils literal notranslate"><span class="pre">1_construct_wrapper.21</span></code>, or the entry graph.
Line 3 tells us how many inputs are in the network.
Line 5 to 6 are the input list, which is in the format of <code class="docutils literal notranslate"><span class="pre">%para[No.]_[name]</span> <span class="pre">:</span> <span class="pre">&lt;[data_type]x[shape]&gt;</span></code>.
Line 8 tells us the number of subgraph parsed by the network. There are 3 graphs in this IR. Line 42 is the entry graph <code class="docutils literal notranslate"><span class="pre">1_construct_wrapper.21</span></code>. Line 32 is graph <code class="docutils literal notranslate"><span class="pre">3_func.23</span></code>, parsed from the <code class="docutils literal notranslate"><span class="pre">func(x,</span> <span class="pre">y)</span></code> in the source script. Line 12 is graph <code class="docutils literal notranslate"><span class="pre">2_construct.22</span></code>, parsed from the function <code class="docutils literal notranslate"><span class="pre">construct</span></code>.
Taking graph <code class="docutils literal notranslate"><span class="pre">2_construct.22</span></code> as an example, Line 10 to 28 indicate the graph structure, which contains several nodes, namely, <code class="docutils literal notranslate"><span class="pre">CNode</span></code>. In this example, there are <code class="docutils literal notranslate"><span class="pre">Sub</span></code>, <code class="docutils literal notranslate"><span class="pre">Add</span></code>, <code class="docutils literal notranslate"><span class="pre">Mul</span></code>. They are defined in the function <code class="docutils literal notranslate"><span class="pre">__init__</span></code>. Line 19 calls a graph by <code class="docutils literal notranslate"><span class="pre">call</span> <span class="pre">&#64;3_func.23</span></code>. It indicates calling the graph <code class="docutils literal notranslate"><span class="pre">func(x,</span> <span class="pre">y)</span></code> to execute a division operation.</p>
<p>The ]<code class="docutils literal notranslate"><span class="pre">CNode</span></code>](https://www.mindspore.cn/docs/programming_guide/en/r1.6/design/mindir.html#syntax) information format is as follows: including the node name, attribute, input node, the specs of the inputs and outputs, and source code parsing call stack. The ANF graph is a unidirectional acyclic graph. So, the connection between nodes is displayed only based on the input relationship. The corresponding source code reflects the relationship between the <code class="docutils literal notranslate"><span class="pre">CNode</span></code> and the script source code. For example, line 15 is parsed from <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">=</span> <span class="pre">self.sub(x,</span> <span class="pre">1)</span></code>.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  %[No.]([debug_name]) = [op_name]([arg], ...) primitive_attrs: {[key]: [value], ...}
      : (&lt;[input data_type]x[input shape]&gt;, ...) -&gt; (&lt;[output data_type]x[output shape]&gt;, ...)
      # Corresponding source code
</pre></div>
</div>
<p>About the corresponding source code:</p>
<ul class="simple">
<li><p>There are two mode for the corresponding source code displaying. The first mode is to display the complete call stack, such as <code class="docutils literal notranslate"><span class="pre">15_execute_0141.ir</span></code> on the frontend and <code class="docutils literal notranslate"><span class="pre">graph_build_0_136.ir</span></code> on the backend. The second mode only displays one code line for reducing the size of the IR file, which eliminates the call stack, such as <code class="docutils literal notranslate"><span class="pre">04_abstract_specialize_0012.ir</span></code>.</p></li>
<li><p>If the operator is a back propagation operator, the associated code line will not only display its own code, but also the corresponding forward code, identified by “Corresponding forward node candidate:”.</p></li>
<li><p>If the operator is a fusion operator, the associated code line will display the fusion related code, identified by “Corresponding code candidate:”, where the separator “-” is used to distinguish different codes.</p></li>
</ul>
<blockquote>
<div><ul class="simple">
<li><p>After several optimizations by the compiler, the node may undergo several changes (such as operator splitting and operator merging). The source code parsing call stack information of the node may not be in a one-to-one correspondence with the script. This is only an auxiliary method.</p></li>
<li><p>After the <code class="docutils literal notranslate"><span class="pre">kernel</span> <span class="pre">select</span></code> phase at the backend, two lines of input and output specification information (that is, the content after <code class="docutils literal notranslate"><span class="pre">:</span></code>) will appear. The first line represents the specifications on the HOST side, and the second line represents the specifications on the DEVICE side.</p></li>
</ul>
</div></blockquote>
</section>
<section id="dat-introduction">
<h3>dat Introduction<a class="headerlink" href="#dat-introduction" title="Permalink to this headline"></a></h3>
<p>Use a text editing software (for example, vi) to open the <code class="docutils literal notranslate"><span class="pre">04_abstract_specialize_0013.dat</span></code> file. The file contents are as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  1 # [No.1] 1_construct_wrapper.21
  2 # In file train.py(33)/    def construct(self, x, y):/
  3 funcgraph fg_21(
  4         %para1 : Tensor(F32)[]    # x
  5         , %para2 : Tensor(F32)[]    # y
  6     ) {
  7     %1 : Tensor(F32)[] = FuncGraph::fg_22(%para1, %para2)    #(Tensor(F32)[], Tensor(F32)[])    # fg_22=2_construct.22 #scope: Default
  8       # In file train.py(37)/        return c/#[CNode]2
  9     Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[]) #scope: Default
 10       # In file train.py(37)/        return c/#[CNode]1
 11 }
 12 # order:
 13 #   1: 1_construct_wrapper.21:[CNode]2{[0]: ValueNode&lt;FuncGraph&gt; 2_construct.22, [1]: x, [2]: y}
 14 #   2: 1_construct_wrapper.21:[CNode]1{[0]: ValueNode&lt;Primitive&gt; Return, [1]: [CNode]2}
 15
 16
 17 # [No.2] 2_construct.22
 18 # In file train.py(33)/    def construct(self, x, y):/
 19 funcgraph fg_22(
 20         %para3 : Tensor(F32)[]    # x
 21         , %para4 : Tensor(F32)[]    # y
 22     ) {
 23     %1 : Tensor(F32)[] = PrimitivePy::Sub{prim_type=2}[input_names=[&quot;x&quot;, &quot;y&quot;], output_names=[&quot;output&quot;]](%para3, Tensor(43)[])    #(Tensor(F32)[], Tenso    r(F32)[]) #scope: Default
 24       # In file train.py(34)/        a = self.sub(x, 1)/#a
 25     %2 : Tensor(F32)[] = PrimitivePy::Add{prim_type=2}[input_names=[&quot;x&quot;, &quot;y&quot;], output_names=[&quot;output&quot;]](%1, %para4)    #(Tensor(F32)[], Tensor(F32)[])     #scope: Default
 26       # In file train.py(35)/        b = self.add(a, y)/#b
 27     %3 : Tensor(F32)[] = FuncGraph::fg_23(%1, %2)    #(Tensor(F32)[], Tensor(F32)[])    # fg_23=3_func.23 #scope: Default
 28       # In file train.py(36)/        c = self.mul(b, self.func(a, b))/#[CNode]5
 29     %4 : Tensor(F32)[] = PrimitivePy::Mul{prim_type=2}[input_names=[&quot;x&quot;, &quot;y&quot;], output_names=[&quot;output&quot;]](%2, %3)    #(Tensor(F32)[], Tensor(F32)[]) #sco    pe: Default
 30       # In file train.py(36)/        c = self.mul(b, self.func(a, b))/#c
 31     Primitive::Return{prim_type=1}(%4)    #(Tensor(F32)[]) #scope: Default
 32       # In file train.py(37)/        return c/#[CNode]4
 33 }
 34 # order:
 35 #   1: 2_construct.22:a{[0]: ValueNode&lt;PrimitivePy&gt; Sub, [1]: x, [2]: ValueNode&lt;Tensor&gt; Tensor(shape=[], dtype=Float32, value= 1)}
 36 #   2: 2_construct.22:b{[0]: ValueNode&lt;PrimitivePy&gt; Add, [1]: a, [2]: y}
 37 #   3: 2_construct.22:[CNode]5{[0]: ValueNode&lt;FuncGraph&gt; 3_func.23, [1]: a, [2]: b}
 38 #   4: 2_construct.22:c{[0]: ValueNode&lt;PrimitivePy&gt; Mul, [1]: b, [2]: [CNode]5}
 39 #   5: 2_construct.22:[CNode]4{[0]: ValueNode&lt;Primitive&gt; Return, [1]: c}
 40
 41
 42 # [No.3] 3_func.23
 43 # In file train.py(30)/    def func(x, y):/
 44 funcgraph fg_23(
 45         %para5 : Tensor(F32)[]    # x
 46         , %para6 : Tensor(F32)[]    # y
 47     ) {
 48     %1 : Tensor(F32)[] = PrimitivePy::Div{prim_type=2}[input_names=[&quot;x&quot;, &quot;y&quot;], output_names=[&quot;output&quot;]](%para5, %para6)    #(Tensor(F32)[], Tensor(F32)    []) #scope: Default
 49       # In file train.py(31)/        return self.div(x, y)/#[CNode]20
 50     Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[]) #scope: Default
 51       # In file train.py(31)/        return self.div(x, y)/#[CNode]19
 52 }
 53 # order:
 54 #   1: 3_func.23:[CNode]20{[0]: ValueNode&lt;PrimitivePy&gt; Div, [1]: x, [2]: y}
 55 #   2: 3_func.23:[CNode]19{[0]: ValueNode&lt;Primitive&gt; Return, [1]: [CNode]20}
 56
 57
 58 # num of total function graphs: 3
</pre></div>
</div>
<p>Above, it lists all the graphs beginning with the entry graph.
Line 1 indicates graph <code class="docutils literal notranslate"><span class="pre">1_construct_wrapper.21</span></code> whose id is <code class="docutils literal notranslate"><span class="pre">No.1</span></code>. And line 7 calls graph <code class="docutils literal notranslate"><span class="pre">2_construct.22</span></code>.
line 17 to 39 shows the information of graph <code class="docutils literal notranslate"><span class="pre">2_construct.22</span></code>.
Taking graph <code class="docutils literal notranslate"><span class="pre">2_construct.22</span></code> as an example. Line 18 tells us which function this graph is parsed from. Line 20 to 21 indicates the input information which is in the format of <code class="docutils literal notranslate"><span class="pre">%para[No.]</span> <span class="pre">:</span> <span class="pre">[data_type][shape]</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">[name]</span></code>.
Line 23 to 32 indicates the graph structure, which contains several nodes, namely, <code class="docutils literal notranslate"><span class="pre">CNode</span></code>. In this example, there are <code class="docutils literal notranslate"><span class="pre">Sub</span></code>, <code class="docutils literal notranslate"><span class="pre">Add</span></code>, <code class="docutils literal notranslate"><span class="pre">Mul</span></code>. They are defined in the function <code class="docutils literal notranslate"><span class="pre">__init__</span></code>.
Line 34 to 39 shows the execution order of the <code class="docutils literal notranslate"><span class="pre">CNode</span></code> from graph <code class="docutils literal notranslate"><span class="pre">2_construct.22</span></code>, corresponding to the order of code execution. The information format is: <code class="docutils literal notranslate"><span class="pre">No.:</span> <span class="pre">belonging</span> <span class="pre">graph:node</span> <span class="pre">name{[0]:</span> <span class="pre">the</span> <span class="pre">first</span> <span class="pre">input,</span> <span class="pre">[1]:</span> <span class="pre">the</span> <span class="pre">second</span> <span class="pre">input,</span> <span class="pre">...}</span></code>. For <code class="docutils literal notranslate"><span class="pre">CNode</span></code>, the first input indicates how to compute for this <code class="docutils literal notranslate"><span class="pre">CNode</span></code>.
Line 28 indicates the number of graphs. Here is 3.</p>
<p>The <a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/design/mindir.html#syntax">CNode</a> information format is as follows: including the node name, attribute, input node, output information, format and the corresponding source code.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>%[No,] : [outputs&#39; Spec] = [op_name]{[prim_type]}[attr0, attr1, ...](arg0, arg1, ...)    #(inputs&#39; Spec)#[scope]
  # Corresponding source code/#debug_name
</pre></div>
</div>
</section>
</section>
<section id="reading-analyze-fail-dat">
<h2>Reading analyze_fail.dat<a class="headerlink" href="#reading-analyze-fail-dat" title="Permalink to this headline"></a></h2>
<p>In the process of <code class="docutils literal notranslate"><span class="pre">MindSpore</span></code> compiling a graph, the exceptions about graph evaluating fail usually happen. But we can find
the reason by analyzing the exception information and analyze_fail.dat.</p>
<p>For example, we run the script below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>  <span class="mi">1</span> <span class="kn">import</span> <span class="nn">mindspore.context</span> <span class="k">as</span> <span class="nn">context</span>
  <span class="mi">2</span> <span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
  <span class="mi">3</span> <span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
  <span class="mi">4</span> <span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Cell</span>
  <span class="mi">5</span> <span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
  <span class="mi">6</span> <span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
  <span class="mi">7</span>
  <span class="mi">8</span> <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
  <span class="mi">9</span> <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">save_graphs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
 <span class="mi">10</span>
 <span class="mi">11</span> <span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
 <span class="mi">12</span>     <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
 <span class="mi">13</span>         <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
 <span class="mi">14</span>         <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Add</span><span class="p">()</span>
 <span class="mi">15</span>         <span class="bp">self</span><span class="o">.</span><span class="n">sub</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sub</span><span class="p">()</span>
 <span class="mi">16</span>         <span class="bp">self</span><span class="o">.</span><span class="n">mul</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Mul</span><span class="p">()</span>
 <span class="mi">17</span>         <span class="bp">self</span><span class="o">.</span><span class="n">div</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Div</span><span class="p">()</span>
 <span class="mi">18</span>
 <span class="mi">19</span>     <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
 <span class="mi">20</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
 <span class="mi">21</span>
 <span class="mi">22</span>     <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
 <span class="mi">23</span>         <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
 <span class="mi">24</span>         <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
 <span class="mi">25</span>         <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
 <span class="mi">26</span>         <span class="k">return</span> <span class="n">c</span>
 <span class="mi">27</span>
 <span class="mi">28</span> <span class="n">input1</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
 <span class="mi">29</span> <span class="n">input2</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
 <span class="mi">30</span> <span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
 <span class="mi">31</span> <span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">)</span>
 <span class="mi">32</span> <span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
<p>An error happens.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  1 [EXCEPTION] ANALYZER(31946,7f6f03941740,python):2021-09-18-15:10:49.094.863 [mindspore/ccsrc/pipeline/jit/static_analysis/stack_frame.cc:85] DoJump] The parameters number of the function is 2, but the number of provided arguments is 3.
  2 FunctionGraph ID : func.18
  3 NodeInfo: In file test.py(19)
  4     def func(x, y):
  5
  6 Traceback (most recent call last):
  7   File &quot;test.py&quot;, line 31, in &lt;module&gt;
  8     out = net(input1, input2)
  9   File &quot;/home/workspace/mindspore/mindspore/nn/cell.py&quot;, line 404, in __call__
 10     out = self.compile_and_run(*inputs)
 11   File &quot;/home/workspace/mindspore/mindspore/nn/cell.py&quot;, line 682, in compile_and_run
 12     self.compile(*inputs)
 13   File &quot;/home/workspace/mindspore/mindspore/nn/cell.py&quot;, line 669, in compile
 14     _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode)
 15   File &quot;/home/workspace/mindspore/mindspore/common/api.py&quot;, line 542, in compile
 16     result = self._graph_executor.compile(obj, args_list, phase, use_vm, self.queue_name)
 17 TypeError: mindspore/ccsrc/pipeline/jit/static_analysis/stack_frame.cc:85 DoJump] The parameters number of the function is 2, but the number of provided arguments is 3.
 18 FunctionGraph ID : func.18
 19 NodeInfo: In file test.py(19)
 20     def func(x, y):
 21
 22 The function call stack (See file &#39;/home/workspace/mindspore/rank_0/om/analyze_fail.dat&#39; for more details):
 23 # 0 In file test.py(26)
 24         return c
 25         ^
 26 # 1 In file test.py(25)
 27         c = self.mul(b, self.func(a, a, b))
 28                         ^
</pre></div>
</div>
<p>Above exception is ‘TypeError: mindspore/ccsrc/pipeline/jit/static_analysis/stack_frame.cc:85 DoJump] The parameters number of the function is 2, but the number of provided arguments is 3…’.
And it tells us <code class="docutils literal notranslate"><span class="pre">FunctionGraph</span> <span class="pre">ID</span> <span class="pre">:</span> <span class="pre">func.18</span></code> only needs two parameters, but actually gives 3.
We can find the related code is <code class="docutils literal notranslate"><span class="pre">self.func(a,</span> <span class="pre">a,</span> <span class="pre">b)</span></code> from ‘The function call stack … In file test.py(25)’.
Easily, by checking the code, we know that we gave too much parameter to the calling function.</p>
<p>Sometimes the exception information is not enough easy to understand. Or we want to see the part of graph information that have evaluated.
Then we can open <code class="docutils literal notranslate"><span class="pre">/home/workspace/mindspore/rank_0/om/analyze_fail.dat</span></code> that indicated in the exception text by using a text editing software (for example, vi).</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  1 # [No.1] construct_wrapper.0
  2 # In file test.py(22)/    def construct(self, x, y):/
  3 funcgraph fg_0(
  4         %para1 : Tensor(F32)[]    # x
  5         , %para2 : Tensor(F32)[]    # y
  6     ) {
  7
  8 #------------------------&gt; 0
  9     %1 = FuncGraph::fg_3(%para1, %para2)    #(Tensor(F32)[], Tensor(F32)[])    # fg_3=construct.3 #scope: Default
 10       # In file test.py(26)/        return c/#[CNode]2
 11     Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default
 12       # In file test.py(26)/        return c/#[CNode]1
 13 }
 14 # order:
 15 #   1: construct_wrapper.0:[CNode]2{[0]: ValueNode&lt;FuncGraph&gt; construct.3, [1]: x, [2]: y}
 16 #   2: construct_wrapper.0:[CNode]1{[0]: ValueNode&lt;Primitive&gt; Return, [1]: [CNode]2}
 17
 18
 19 # [No.2] construct.3
 20 # In file test.py(22)/    def construct(self, x, y):/
 21 funcgraph fg_3(
 22         %para3 : Tensor(F32)[]    # x
 23         , %para4 : Tensor(F32)[]    # y
 24     ) {
 25     %1 : Tensor(F32)[] = DoSignaturePrimitive::S-Prim-Sub{prim_type=1}[input_names=[&quot;x&quot;, &quot;y&quot;], output_names=[&quot;output&quot;]](%para3, I64(1))    #(Tensor(F32)[], I64) #scope: Default
 26       # In file test.py(23)/        a = self.sub(x, 1)/#a
 27     %2 : Tensor(F32)[] = DoSignaturePrimitive::S-Prim-Add{prim_type=1}[input_names=[&quot;x&quot;, &quot;y&quot;], output_names=[&quot;output&quot;]](%1, %para4)    #(Tensor(F32)[], Tensor(F32)[]) #scope: Default
 28       # In file test.py(24)/        b = self.add(a, y)/#b
 29
 30 #------------------------&gt; 1
 31     %3 = FuncGraph::fg_18(%1, %1, %2)    #(Tensor(F32)[], Tensor(F32)[], Tensor(F32)[])    # fg_18=func.18 #scope: Default
 32       # In file test.py(25)/        c = self.mul(b, self.func(a, a, b))/#[CNode]5
 33     %4 = DoSignaturePrimitive::S-Prim-Mul{prim_type=1}[input_names=[&quot;x&quot;, &quot;y&quot;], output_names=[&quot;output&quot;]](%2, %3)    #(Tensor(F32)[], Undefined) #scope: Default
 34       # In file test.py(25)/        c = self.mul(b, self.func(a, a, b))/#c
 35     Primitive::Return{prim_type=1}(%4)    #(Undefined) #scope: Default
 36       # In file test.py(26)/        return c/#[CNode]4
 37 }
 38 # order:
 39 #   1: construct.3:a{[0]: a, [1]: ValueNode&lt;Int64Imm&gt; 1, [2]: ValueNode&lt;Float&gt; Float32}
 40 #   2: construct.3:a{[0]: ValueNode&lt;DoSignaturePrimitive&gt; S-Prim-Sub, [1]: x, [2]: ValueNode&lt;Int64Imm&gt; 1}
 41 #   3: construct.3:b{[0]: ValueNode&lt;DoSignaturePrimitive&gt; S-Prim-Add, [1]: a, [2]: y}
 42 #   4: construct.3:[CNode]5{[0]: ValueNode&lt;FuncGraph&gt; func.18, [1]: a, [2]: a, [3]: b}
 43 #   5: construct.3:c{[0]: ValueNode&lt;DoSignaturePrimitive&gt; S-Prim-Mul, [1]: b, [2]: [CNode]5}
 44 #   6: construct.3:[CNode]4{[0]: ValueNode&lt;Primitive&gt; Return, [1]: c}
 45
 46
 47 #===============================================================================
 48 # num of function graphs in stack: 2
</pre></div>
</div>
<p>The file <code class="docutils literal notranslate"><span class="pre">analyze_fail.dat</span></code> has the same information format with the file <code class="docutils literal notranslate"><span class="pre">.dat</span></code>. The only difference is <code class="docutils literal notranslate"><span class="pre">analyze_fail.dat</span></code> will locate the node which inferring failed.
Searching the point by the text of <code class="docutils literal notranslate"><span class="pre">------------------------&gt;</span></code>, we reach the last position of the <code class="docutils literal notranslate"><span class="pre">------------------------&gt;</span> <span class="pre">1</span></code> at line 30.
The node at line 31 to 32 have an error. Its IR expression is <code class="docutils literal notranslate"><span class="pre">%3</span> <span class="pre">=</span> <span class="pre">FuncGraph::fg_18(%1,</span> <span class="pre">%1,</span> <span class="pre">%2)</span> <span class="pre">...</span></code>. We can know the node have 3 parameters from <code class="docutils literal notranslate"><span class="pre">(%1,</span> <span class="pre">%1,</span> <span class="pre">%2)</span></code>. But actually the function only need 2. So the compiler will fail when evaluating the node. To solve th problem, we should decrease the parameter number.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="numpy.html" class="btn btn-neutral float-left" title="NumPy Interfaces in MindSpore" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="dump_in_graph_mode.html" class="btn btn-neutral float-right" title="Using Dump in the Graph Mode" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>