<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Saving Models &mdash; MindSpore master documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/training.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/js/training.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Loading a Model for Inference and Transfer Learning" href="load_model_for_inference_and_transfer.html" />
    <link rel="prev" title="Save and Load Models" href="save_and_load_models.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Overall Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/technical_white_paper.html">Technical White Paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/gradient.html">MindSpore Automatic Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/distributed_training_design.html">Distributed Training Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindir.html">MindSpore IR (MindIR)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.6/training_visual_design.html">Design of Visualization↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.6/linear_regression.html">Implementing Simple Linear Function Fitting↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/en/r1.6/quick_start.html">Implementing an Image Classification Application↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dtype.html">DataType</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter_introduction.html">Parameter</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="cell.html">Cell</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_introduction.html">Dataset</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Pipeline</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataset_sample.html">Quick Start of Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">Loading Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Processing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_advanced.html">Advanced Usage of Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_usage.html">Data Iteration</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build the Network</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="build_net.html">Constructing Single Operator Network and Multi-layer Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="initializer.html">Initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter.html">Network Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="control_flow.html">Using the Process Control Statement</a></li>
<li class="toctree-l1"><a class="reference internal" href="indefinite_parameter.html">Parameter Passing</a></li>
<li class="toctree-l1"><a class="reference internal" href="loss.html">Loss Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="grad_operation.html">Gradient Operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="constexpr.html">Construct Constants In the Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypermap.html">Operation Overloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">Optimization Algorithms</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Running</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="context.html">Configuring Running Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="run.html">Running Mode</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="save_and_load_models.html">Save and Load Models</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Saving Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#saving-checkpoint-files">Saving CheckPoint files</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#using-callback-mechanism">Using Callback Mechanism</a></li>
<li class="toctree-l4"><a class="reference internal" href="#using-save-checkpoint-method">Using Save_checkpoint Method</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#export-mindir-model">Export MindIR Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#export-air-model">Export AIR Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#export-onnx-model">Export ONNX Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="load_model_for_inference_and_transfer.html">Loading a Model for Inference and Transfer Learning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model.html">Application of Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">Inference Model Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="online_inference.html">Online Inference with Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="offline_inference.html">Using Offline Model for Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">Distributed Parallel Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_advanced.html">Distributed Parallel Advanced Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_example.html">Distributed Parallel Usage Example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyNative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">Debugging in PyNative Mode</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Numpy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">NumPy Interfaces in MindSpore</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Function Debugging</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="read_ir_files.html">Reading IR</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/en/r1.6/debug_in_pynative_mode.html">Debugging in PyNative Mode↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">Using Dump in the Graph Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">Custom Debugging Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">Incremental Operator Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">Enabling Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_tune.html">AutoTune</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_dataset_autotune.html">Dataset AutoTune for Dataset Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_dataset_offload.html">Enabling Offload for Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">Gradient Accumulation Algorithm</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/en/r1.6/performance_profiling.html">Debugging performance with Profiler↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="second_order_optimizer.html">Second Order Optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_kernel_fusion.html">Graph Kernel Fusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">Quantization Aware Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">Using MindSpore on the Cloud</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="save_and_load_models.html">Save and Load Models</a> &raquo;</li>
      <li>Saving Models</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/save_model.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="saving-models">
<h1>Saving Models<a class="headerlink" href="#saving-models" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Export</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.6/docs/mindspore/programming_guide/source_en/save_model.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.6/resource/_static/logo_source_en.png"></a></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>During model training, you can add CheckPoints to save model parameters for inference and retraining after interruption. If you want to perform inference on different hardware platforms, you need to generate corresponding models based on the network and CheckPoint, such as MindIR, AIR and ONNX.</p>
<ul class="simple">
<li><p>MindIR: A functional IR of MindSpore based on graph representation, which defines an extensible graph structure and IR representation of operators, which eliminates the model differences between different backends. The model trained on Ascend 910 can be used for reasoning on the upper side of Ascend 310, GPU and MindSpore Lite.</p></li>
<li><p>CheckPoint: A CheckPoint file of MindSpore is a binary file that stores the values of all training parameters. The Google Protocol Buffers mechanism with good scalability is adopted, which is independent of the development language and platform. The protocol format of CheckPoints is defined in <code class="docutils literal notranslate"><span class="pre">mindspore/ccsrc/utils/checkpoint.proto</span></code>.</p></li>
<li><p>AIR: Ascend Intermediate Representation (AIR) is an open file format defined by Huawei for machine learning and can better adapt to the Ascend AI processor. It is similar to ONNX.</p></li>
<li><p>ONNX: Open Neural Network Exchange (ONNX) is an open file format designed for machine learning. It is used to store trained models.</p></li>
</ul>
<p>The following uses examples to describe how to save MindSpore CheckPoint files, and how to export MindIR, AIR and ONNX files.</p>
</section>
<section id="saving-checkpoint-files">
<h2>Saving CheckPoint files<a class="headerlink" href="#saving-checkpoint-files" title="Permalink to this headline"></a></h2>
<p>Here are two ways to save checkpoint files</p>
<section id="using-callback-mechanism">
<h3>Using Callback Mechanism<a class="headerlink" href="#using-callback-mechanism" title="Permalink to this headline"></a></h3>
<p>During model training, use the callback mechanism to transfer the object of the callback function <code class="docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> to save model parameters and generate CheckPoint files.</p>
<p>You can use the <code class="docutils literal notranslate"><span class="pre">CheckpointConfig</span></code> object to set the CheckPoint saving policies. The saved parameters are classified into network parameters and optimizer parameters.</p>
<p><code class="docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> provides default configuration policies for users to quickly get started. The following describes the usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span>
<span class="n">ckpoint_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">ckpoint_cb</span><span class="p">)</span>
</pre></div>
</div>
<p>You can configure the CheckPoint policies as required. The following describes the usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">CheckpointConfig</span>
<span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ckpoint_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;resnet50&#39;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">ckpoint_cb</span><span class="p">)</span>
</pre></div>
</div>
<p>In the preceding code, initialize a <code class="docutils literal notranslate"><span class="pre">TrainConfig</span></code> class object to set the saving policies.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">save_checkpoint_steps</span></code> indicates the saving frequency. That is, parameters are saved every specified number of steps.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">keep_checkpoint_max</span></code> indicates the maximum number of CheckPoint files that can be saved.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prefix</span></code> indicates the prefix name of the generated CheckPoint file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">directory</span></code> indicates the directory for storing the file.</p></li>
</ul>
<p>Create a <code class="docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> object and transfer it to the model.train method. Then you can use the CheckPoint function during training.</p>
<p>Generated CheckPoint files are as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>resnet50-graph.meta # Generate compiled computation graph.
resnet50-1_32.ckpt  # The file name extension is .ckpt.
resnet50-2_32.ckpt  # The file name format contains the epoch and step correspond to the saved parameters.
resnet50-3_32.ckpt  # The file name indicates that the model parameters generated during the 32th step of the third epoch are saved.
...
</pre></div>
</div>
<p>If you use the same prefix and run the training script for multiple times, CheckPoint files with the same name may be generated. MindSpore adds underscores (_) and digits at the end of the user-defined prefix to distinguish CheckPoints with the same name. If you want to delete the <code class="docutils literal notranslate"><span class="pre">.ckpt</span></code> file, please delete the <code class="docutils literal notranslate"><span class="pre">.meta</span></code> file simultaneously.</p>
<p>For example, <code class="docutils literal notranslate"><span class="pre">resnet50_3-2_32.ckpt</span></code> indicates the CheckPoint file generated during the 32th step of the second epoch after the script is executed for the third time.</p>
<blockquote>
<div><ul class="simple">
<li><p>When performing distributed parallel training tasks, each process needs to set different <code class="docutils literal notranslate"><span class="pre">directory</span></code> parameters to save the CheckPoint file to a different directory to prevent files from being read or written incorrectly.</p></li>
</ul>
</div></blockquote>
<section id="checkpoint-configuration-policies">
<h4>CheckPoint Configuration Policies<a class="headerlink" href="#checkpoint-configuration-policies" title="Permalink to this headline"></a></h4>
<p>MindSpore provides two types of CheckPoint saving policies: iteration policy and time policy. You can create the <code class="docutils literal notranslate"><span class="pre">CheckpointConfig</span></code> object to set the corresponding policies.
CheckpointConfig contains the following four parameters:</p>
<ul class="simple">
<li><p>save_checkpoint_steps: indicates the step interval for saving a CheckPoint file. That is, parameters are saved every specified number of steps. The default value is 1.</p></li>
<li><p>save_checkpoint_seconds: indicates the interval for saving a CheckPoint file. That is, parameters are saved every specified number of seconds. The default value is 0.</p></li>
<li><p>keep_checkpoint_max: indicates the maximum number of CheckPoint files that can be saved. The default value is 5.</p></li>
<li><p>keep_checkpoint_per_n_minutes: indicates the interval for saving a CheckPoint file. That is, parameters are saved every specified number of minutes. The default value is 0.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">save_checkpoint_steps</span></code> and <code class="docutils literal notranslate"><span class="pre">keep_checkpoint_max</span></code> are iteration policies, which can be configured based on the number of training iterations.
<code class="docutils literal notranslate"><span class="pre">save_checkpoint_seconds</span></code> and <code class="docutils literal notranslate"><span class="pre">keep_checkpoint_per_n_minutes</span></code> are time policies, which can be configured during training.</p>
<p>The two types of policies cannot be used together. Iteration policies have a higher priority than time policies. When the two types of policies are configured at the same time, only iteration policies take effect.
If a parameter is set to None, the related policy is cancelled.
After the training script is normally executed, the CheckPoint file generated during the last step is saved by default.</p>
</section>
<section id="resume-training-at-the-breakpoint">
<h4>Resume Training At The Breakpoint<a class="headerlink" href="#resume-training-at-the-breakpoint" title="Permalink to this headline"></a></h4>
<p>MindSpore provides the function of resuming training at the breakpoint. If an exception occurs during training, MindSpore will automatically save the CheckPoint file (the final CheckPoint) when the exception occurs. The <code class="docutils literal notranslate"><span class="pre">exception_save</span></code> parameter (bool type) in <code class="docutils literal notranslate"><span class="pre">CheckpointConfig</span></code> controls the function of resuming training at the breakpoint. If this parameter is set to True, this function is enabled, if this parameter is set to False, this function is disabled, and the default value is False. The final CheckPoint file does not affect the CheckPoint saved in the normal process, and the naming mechanism and save path are the same as those in the normal process. The only difference is that ‘_breakpoint’ is added to the end of the final CheckPoint file name.</p>
<p>The following describes the usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore.train.callback</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">CheckpointConfig</span>
<span class="n">config_ck</span> <span class="o">=</span> <span class="n">CheckpointConfig</span><span class="p">(</span><span class="n">save_checkpoint_steps</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">keep_checkpoint_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">exception_save</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ckpoint_cb</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;resnet50&#39;</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_ck</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">ckpoint_cb</span><span class="p">)</span>
</pre></div>
</div>
<p>If an exception occurs during the training process, the final Checkpoint is automatically saved. If an exception occurs in the tenth step of the tenth epoch during the training, the final Checkpoint file is saved as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>resnet50-10_10_breakpoint.ckpt  # The &#39;_breakpoint&#39; is added to the end of the final CheckPoint file name.
</pre></div>
</div>
</section>
</section>
<section id="using-save-checkpoint-method">
<h3>Using Save_checkpoint Method<a class="headerlink" href="#using-save-checkpoint-method" title="Permalink to this headline"></a></h3>
<p>You can use the <code class="docutils literal notranslate"><span class="pre">save_checkpoint</span></code> function to save the custom information as a checkpoint file. The function declaration is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="n">save_obj</span><span class="p">,</span> <span class="n">ckpt_file_name</span><span class="p">,</span> <span class="n">integrated_save</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">async_save</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">append_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">enc_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">enc_mode</span><span class="o">=</span><span class="s2">&quot;AES-GCM&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The required parameters are: <code class="docutils literal notranslate"><span class="pre">save_obj</span></code>, <code class="docutils literal notranslate"><span class="pre">ckpt_file_name</span></code>.</p>
<p>The following uses specific examples to illustrate how to use each parameter.</p>
<section id="save-obj-and-ckpt-file-name-parameters">
<h4><code class="docutils literal notranslate"><span class="pre">save_obj</span></code> and <code class="docutils literal notranslate"><span class="pre">ckpt_file_name</span></code> parameters<a class="headerlink" href="#save-obj-and-ckpt-file-name-parameters" title="Permalink to this headline"></a></h4>
<p><strong><code class="docutils literal notranslate"><span class="pre">save_obj</span></code></strong>: You can pass in a Cell class object or a list.
<strong><code class="docutils literal notranslate"><span class="pre">ckpt_file_name</span></code></strong>: string type, representing the name of the saved checkpoint file.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">save_checkpoint</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
</pre></div>
</div>
<ol class="arabic">
<li><p>Pass in the Cell object</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">()</span>
<span class="n">save_checkpoint</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="s2">&quot;lenet.ckpt&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>​After execution, you can save the parameters in net as a <code class="docutils literal notranslate"><span class="pre">lenet.ckpt</span></code> file.</p>
</li>
<li><p>Pass in the list object</p>
<p>The format of the list is as follows: [{“name”: param_name, “data”: param_data}], which consists of a set of dict objects.</p>
<p><code class="docutils literal notranslate"><span class="pre">param_name</span></code> is the name of the object that needs to be saved, and <code class="docutils literal notranslate"><span class="pre">param_data</span></code> is the data that needs to be saved, and it is of type Tensor.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">save_list</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)},</span> <span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;train_epoch&quot;</span><span class="p">,</span> <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)}]</span>
<span class="n">save_checkpoint</span><span class="p">(</span><span class="n">save_list</span><span class="p">,</span> <span class="s2">&quot;hyper_param.ckpt&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>After execution, you can save <code class="docutils literal notranslate"><span class="pre">save_list</span></code> as a <code class="docutils literal notranslate"><span class="pre">hyper_param.ckpt</span></code> file.</p>
</li>
</ol>
</section>
<section id="integrated-save-parameter">
<h4><code class="docutils literal notranslate"><span class="pre">integrated_save</span></code> parameter<a class="headerlink" href="#integrated-save-parameter" title="Permalink to this headline"></a></h4>
<p><strong><code class="docutils literal notranslate"><span class="pre">integrated_save</span></code></strong>: bool type, indicating whether the parameters are merged and saved, the default value is True. In the model parallel scenario, Tensor will be split into programs running on different cards. If <code class="docutils literal notranslate"><span class="pre">integrated_save</span></code> is set to True, these split Tensors will be merged and saved to each checkpoint file, so that the checkpoint file saves the complete training parameters.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="s2">&quot;lenet.ckpt&quot;</span><span class="p">,</span> <span class="n">integrated_save</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="async-save-parameter">
<h4><code class="docutils literal notranslate"><span class="pre">async_save</span></code> parameter<a class="headerlink" href="#async-save-parameter" title="Permalink to this headline"></a></h4>
<p><strong><code class="docutils literal notranslate"><span class="pre">async_save</span></code></strong>: bool type, indicating whether to enable the asynchronous save function, the default value is False. If set to True, multi-threaded execution of checkpoint file writing operations will be enabled, so that training and saving tasks can be executed in parallel, which will save the total time of script running when training large-scale networks.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="s2">&quot;lenet.ckpt&quot;</span><span class="p">,</span> <span class="n">async_save</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="append-dict-parameter">
<h4><code class="docutils literal notranslate"><span class="pre">append_dict</span></code> parameter<a class="headerlink" href="#append-dict-parameter" title="Permalink to this headline"></a></h4>
<p><strong><code class="docutils literal notranslate"><span class="pre">append_dict</span></code></strong>: dict type, indicating additional information that needs to be saved, for example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">save_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;epoch_num&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">}</span>
<span class="n">save_checkpoint</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="s2">&quot;lenet.ckpt&quot;</span><span class="p">,</span><span class="n">append_dict</span><span class="o">=</span><span class="n">save_dict</span><span class="p">)</span>
</pre></div>
</div>
<p>After execution, in addition to the parameters in net, the information of <code class="docutils literal notranslate"><span class="pre">save_dict</span></code> will also be saved in <code class="docutils literal notranslate"><span class="pre">lenet.ckpt</span></code>.
Currently, only basic types of storage are supported, including int, float, bool, etc.</p>
</section>
</section>
</section>
<section id="export-mindir-model">
<h2>Export MindIR Model<a class="headerlink" href="#export-mindir-model" title="Permalink to this headline"></a></h2>
<p>If you want to perform inference across platforms or hardware (Ascend AI processor, MindSpore on-device, GPU, etc.), you can generate the corresponding MindIR format model file through the network definition and CheckPoint. MindIR format file can be applied to MindSpore Lite. Currently, it supports inference network based on static graph mode.</p>
<p>If you want to perform inference on the device, then you need to generate corresponding MindIR models based on the network and CheckPoint.
Currently we support the export of MindIR models for inference based on the graph mode. Taking the export of MindIR model as an example to illustrate the implementation of model export,
the code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">export</span><span class="p">,</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">resnet</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">()</span>
<span class="c1"># load the parameter into net</span>
<span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50-2_32.ckpt&quot;</span><span class="p">,</span> <span class="n">net</span><span class="o">=</span><span class="n">resnet</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">export</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;resnet50-2_32&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;MINDIR&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>If you wish to save the data preprocess operations into MindIR and use them to perform inference,
you can pass the Dataset object into export method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.dataset</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">mindspore.dataset.vision.c_transforms</span> <span class="k">as</span> <span class="nn">C</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">export</span><span class="p">,</span> <span class="n">load_checkpoint</span>

<span class="k">def</span> <span class="nf">create_dataset_for_renset</span><span class="p">():</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">ImageFolderDataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">)</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.485</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.456</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.406</span> <span class="o">*</span> <span class="mi">255</span><span class="p">]</span>
    <span class="n">std</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.229</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.224</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mf">0.225</span> <span class="o">*</span> <span class="mi">255</span><span class="p">]</span>
    <span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="p">[</span><span class="n">C</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span> <span class="n">C</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span> <span class="n">C</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
                            <span class="n">C</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span><span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">),</span> <span class="n">C</span><span class="o">.</span><span class="n">HWC2CHW</span><span class="p">()],</span> <span class="n">input_columns</span><span class="o">=</span><span class="s2">&quot;image&quot;</span><span class="p">)</span>

<span class="c1"># create Dataset with preprocess operations</span>
<span class="n">de_dataset</span> <span class="o">=</span> <span class="n">create_dataset_for_renset</span><span class="p">()</span>
<span class="c1"># load the parameter into net</span>
<span class="n">resnet</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">()</span>
<span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50-2_32.ckpt&quot;</span><span class="p">,</span> <span class="n">net</span><span class="o">=</span><span class="n">resnet</span><span class="p">)</span>
<span class="n">export</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">de_dataset</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;resnet50-2_32&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;MINDIR&#39;</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">input</span></code> is the input parameter of the <code class="docutils literal notranslate"><span class="pre">export</span></code> method, representing the input of the network. If the network has multiple inputs, they need to be passed into the <code class="docutils literal notranslate"><span class="pre">export</span></code> method together. eg: <code class="docutils literal notranslate"><span class="pre">export(network,</span> <span class="pre">Tensor(input1),</span> <span class="pre">Tensor(input2),</span> <span class="pre">file_name='network',</span> <span class="pre">file_format='MINDIR')</span></code>.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">input</span></code> is a Tensor, it represents the input of network, the shape of <code class="docutils literal notranslate"><span class="pre">input</span></code> need to be consistent with input of network. In case of network with multiple inputs, <code class="docutils literal notranslate"><span class="pre">input</span></code> should be a tuple of Tensor. When <code class="docutils literal notranslate"><span class="pre">input</span></code> is a Dataset, the input shape of network will be infer by Dataset object and the data preprocess operations will be also exported to file(Only MindIR).</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">file_name</span></code> does not contain the “.mindir” suffix, the system will automatically add the “.mindir” suffix to it.</p></li>
<li><p>Make sure that the Dataset object is using the preprocess operations of evaluation, otherwise you may can not get the
expected preprocess results in inference.</p></li>
</ul>
</div></blockquote>
<p>In order to avoid the hardware limitation of protobuf, when the exported model parameter size exceeds 1G, the framework will save the network structure and parameters separately by default.</p>
<p>-The name of the network structure file ends with the user-specified prefix plus <code class="docutils literal notranslate"><span class="pre">_graph.mindir</span></code>.
-In the same level directory, there will be a folder with user-specified prefix plus <code class="docutils literal notranslate"><span class="pre">_variables</span></code>, which stores network parameters.
And when the parameter’s data size exceeds 1T, it will split to another file named data_1, data_2, etc.</p>
<p>Taking the above code as an example, if the parameter size with the model exceeds 1G, the generated directory structure is as follows:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>resnet50-2_32_graph.mindir
resnet50-2_32_variables
     data_0
</pre></div>
</div>
</section>
<section id="export-air-model">
<h2>Export AIR Model<a class="headerlink" href="#export-air-model" title="Permalink to this headline"></a></h2>
<p>If you want to perform inference on the Shengteng AI processor, you can also generate the corresponding AIR format model file through the network definition and CheckPoint. The code example of exporting this format file is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">export</span><span class="p">,</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>

<span class="n">resnet</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">()</span>
<span class="c1"># load the parameter into net</span>
<span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50-2_32.ckpt&quot;</span><span class="p">,</span> <span class="n">net</span><span class="o">=</span><span class="n">resnet</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">export</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;resnet50-2_32&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;AIR&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">input</span></code> parameter is used to specify the input shape and the data type of the exported model.</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">input</span></code> is the input parameter of the <code class="docutils literal notranslate"><span class="pre">export</span></code> method, representing the input of the network. If the network has multiple inputs, they need to be passed into the <code class="docutils literal notranslate"><span class="pre">export</span></code> method together. eg: <code class="docutils literal notranslate"><span class="pre">export(network,</span> <span class="pre">Tensor(input1),</span> <span class="pre">Tensor(input2),</span> <span class="pre">file_name='network',</span> <span class="pre">file_format='AIR')</span></code>.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">file_name</span></code> does not contain the “.air” suffix, the system will automatically add the “.air” suffix to it.</p></li>
</ul>
</div></blockquote>
</section>
<section id="export-onnx-model">
<h2>Export ONNX Model<a class="headerlink" href="#export-onnx-model" title="Permalink to this headline"></a></h2>
<p>When you have a CheckPoint file, if you want to do inference on Ascend AI processor, GPU, or CPU, you need to generate ONNX models based on the network and CheckPoint. ONNX format file is a general model file, which can be applied to many kinds of hardware, such as Ascend AI processor, GPU, CPU, etc. The code example of exporting this format file is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">export</span><span class="p">,</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">load_param_into_net</span>

<span class="n">resnet</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">()</span>
<span class="c1"># load the parameter into net</span>
<span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;resnet50-2_32.ckpt&quot;</span><span class="p">,</span> <span class="n">net</span><span class="o">=</span><span class="n">resnet</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">export</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">file_name</span><span class="o">=</span><span class="s1">&#39;resnet50-2_32&#39;</span><span class="p">,</span> <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;ONNX&#39;</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">input</span></code> is the input parameter of the <code class="docutils literal notranslate"><span class="pre">export</span></code> method, representing the input of the network. If the network has multiple inputs, they need to be passed into the <code class="docutils literal notranslate"><span class="pre">export</span></code> method together. eg: <code class="docutils literal notranslate"><span class="pre">export(network,</span> <span class="pre">Tensor(input1),</span> <span class="pre">Tensor(input2),</span> <span class="pre">file_name='network',</span> <span class="pre">file_format='ONNX')</span></code>.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">file_name</span></code> does not contain the “.onnx” suffix, the system will automatically add the “.onnx” suffix to it.</p></li>
<li><p>Currently, only the ONNX format export of ResNet series networks, YOLOV3, YOLOV4 and BERT are supported.</p></li>
</ul>
</div></blockquote>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="save_and_load_models.html" class="btn btn-neutral float-left" title="Save and Load Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="load_model_for_inference_and_transfer.html" class="btn btn-neutral float-right" title="Loading a Model for Inference and Transfer Learning" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>