

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>分布式并行接口说明 &mdash; MindSpore master documentation</title>
  

  
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="分布式并行训练模式" href="distributed_training_mode.html" />
    <link rel="prev" title="分布式并行总览" href="distributed_training.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">整体介绍</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">MindSpore总体架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API概述</a></li>
</ul>
<p class="caption"><span class="caption-text">设计介绍</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/technical_white_paper.html">技术白皮书</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/all_scenarios_architecture.html">全场景统一架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/gradient.html">函数式可微分编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/dynamic_graph_and_static_graph.html">动态图和静态图</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/distributed_training_design.html">分布式训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/heterogeneous_training.html">异构并行训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindir.html">MindSpore IR（MindIR）</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/training_visual_design.html">可视化调试调优↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindarmour/docs/zh-CN/r1.5/design.html">安全可信↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/glossary.html">术语</a></li>
</ul>
<p class="caption"><span class="caption-text">快速入门</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/r1.5/linear_regression.html">实现简单线性函数拟合↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/r1.5/quick_start.html">实现一个图片分类应用↗</a></li>
</ul>
<p class="caption"><span class="caption-text">基本概念</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dtype.html">DataType</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter_introduction.html">Parameter</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators.html">算子</a></li>
<li class="toctree-l1"><a class="reference internal" href="cell.html">Cell</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_introduction.html">Dataset</a></li>
</ul>
<p class="caption"><span class="caption-text">数据加载和处理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataset_sample.html">快速入门数据加载和处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">数据集加载</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_advanced.html">数据处理高级用法</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_usage.html">数据迭代</a></li>
</ul>
<p class="caption"><span class="caption-text">网络构建</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="build_net.html">构建单算子网络和多层网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="initializer.html">Initializer初始化器</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter.html">网络参数</a></li>
<li class="toctree-l1"><a class="reference internal" href="control_flow.html">使用流程控制语句</a></li>
<li class="toctree-l1"><a class="reference internal" href="indefinite_parameter.html">参数传递</a></li>
<li class="toctree-l1"><a class="reference internal" href="constexpr.html">网络内构造常量</a></li>
<li class="toctree-l1"><a class="reference internal" href="loss.html">损失函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="grad_operation.html">求导</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypermap.html">运算重载</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">优化器</a></li>
<li class="toctree-l1"><a class="reference internal" href="train_and_eval.html">构建训练与评估网络</a></li>
</ul>
<p class="caption"><span class="caption-text">模型运行</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="context.html">配置运行信息</a></li>
<li class="toctree-l1"><a class="reference internal" href="run.html">运行方式</a></li>
<li class="toctree-l1"><a class="reference internal" href="ms_function.html">ms_function动静结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_and_load_models.html">模型保存与加载</a></li>
<li class="toctree-l1"><a class="reference internal" href="model.html">Model接口应用</a></li>
</ul>
<p class="caption"><span class="caption-text">推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">推理模型总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="online_inference.html">加载Checkpoint在线推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="offline_inference.html">使用离线模型推理</a></li>
</ul>
<p class="caption"><span class="caption-text">分布式并行</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="distributed_training.html">分布式并行总览</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">分布式并行接口说明</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">概述</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">分布式并行配置</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id4">通用配置</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id5">自动并行配置</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id6">分布式通信接口</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#init">init</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-group-size">get_group_size</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-rank">get_rank</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id7">分布式属性配置</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#cross-batch">cross_batch</a></li>
<li class="toctree-l4"><a class="reference internal" href="#fusion">fusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="#layerwise-parallel">layerwise_parallel</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="distributed_training_mode.html">分布式并行训练模式</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed_training_ops.html">分布式集合通信原语</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="distributed_advanced.html">分布式并行高级特性</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_example.html">分布式并行使用样例</a></li>
</ul>
<p class="caption"><span class="caption-text">PyNative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">PyNative模式应用</a></li>
</ul>
<p class="caption"><span class="caption-text">Numpy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">MindSpore NumPy函数</a></li>
</ul>
<p class="caption"><span class="caption-text">高级特性</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="second_order_optimizer.html">二阶优化</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">应用感知量化训练</a></li>
</ul>
<p class="caption"><span class="caption-text">功能调试</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="read_ir_files.html">如何查看IR文件</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/debug_in_pynative_mode.html">使用PyNative模式调试↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">使用Dump功能在Graph模式调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">自定义调试信息</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">算子增量编译</a></li>
</ul>
<p class="caption"><span class="caption-text">精度调优</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/accuracy_problem_preliminary_location.html">精度问题初步定位指南↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/accuracy_optimization.html">精度问题详细定位和调优指南↗</a></li>
</ul>
<p class="caption"><span class="caption-text">性能优化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">使能混合精度</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">使能图算融合</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_tune.html">使能算子调优工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">应用梯度累积算法</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/performance_profiling.html">使用Profiler调试性能↗</a></li>
</ul>
<p class="caption"><span class="caption-text">应用实践</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">机器视觉</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">自然语言处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">高性能计算</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">在云上使用MindSpore</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="distributed_training.html">分布式并行总览</a> &raquo;</li>
        
      <li>分布式并行接口说明</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/auto_parallel.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="id1">
<h1>分布式并行接口说明<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">分布式并行</span></code></p>
<!-- TOC -->
<ul class="simple">
<li><p><a class="reference external" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E6%8E%A5%E5%8F%A3%E8%AF%B4%E6%98%8E">分布式并行接口说明</a></p>
<ul>
<li><p><a class="reference external" href="#%E6%A6%82%E8%BF%B0">概述</a></p></li>
<li><p><a class="reference external" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E9%85%8D%E7%BD%AE">分布式并行配置</a></p>
<ul>
<li><p><a class="reference external" href="#%E9%80%9A%E7%94%A8%E9%85%8D%E7%BD%AE">通用配置</a></p>
<ul>
<li><p><a class="reference external" href="#device_num">device_num</a></p></li>
<li><p><a class="reference external" href="#global_rank">global_rank</a></p></li>
<li><p><a class="reference external" href="#gradients_mean">gradients_mean</a></p></li>
<li><p><a class="reference external" href="#parallel_mode">parallel_mode</a></p></li>
<li><p><a class="reference external" href="#all_reduce_fusion_config">all_reduce_fusion_config</a></p></li>
<li><p><a class="reference external" href="#enable_parallel_optimizer">enable_parallel_optimizer</a></p></li>
<li><p><a class="reference external" href="#parameter_broadcast">parameter_broadcast</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#%E8%87%AA%E5%8A%A8%E5%B9%B6%E8%A1%8C%E9%85%8D%E7%BD%AE">自动并行配置</a></p>
<ul>
<li><p><a class="reference external" href="#gradient_fp32_sync">gradient_fp32_sync</a></p></li>
<li><p><a class="reference external" href="#auto_parallel_search_mode">auto_parallel_search_mode</a></p></li>
<li><p><a class="reference external" href="#strategy_ckpt_load_file">strategy_ckpt_load_file</a></p></li>
<li><p><a class="reference external" href="#strategy_ckpt_save_file">strategy_ckpt_save_file</a></p></li>
<li><p><a class="reference external" href="#full_batch">full_batch</a></p></li>
<li><p><a class="reference external" href="#pipeline_stages">pipeline_stages</a></p></li>
<li><p><a class="reference external" href="#grad_accumulation_step">grad_accumulation_step</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1%E6%8E%A5%E5%8F%A3">分布式通信接口</a></p>
<ul>
<li><p><a class="reference external" href="#init">init</a></p></li>
<li><p><a class="reference external" href="#get_group_size">get_group_size</a></p></li>
<li><p><a class="reference external" href="#get_rank">get_rank</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%B1%9E%E6%80%A7%E9%85%8D%E7%BD%AE">分布式属性配置</a></p>
<ul>
<li><p><a class="reference external" href="#cross_batch">cross_batch</a></p></li>
<li><p><a class="reference external" href="#fusion">fusion</a></p></li>
<li><p><a class="reference external" href="#layerwise_parallel">layerwise_parallel</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- /TOC -->
<p><a href="https://gitee.com/mindspore/docs/blob/r1.5/docs/mindspore/programming_guide/source_zh_cn/auto_parallel.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source.png"></a></p>
<div class="section" id="id2">
<h2>概述<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>在深度学习中，当数据集和参数量的规模越来越大，训练所需的时间和硬件资源会随之增加，最后会变成制约训练的瓶颈。分布式并行训练，可以降低对内存、计算性能等硬件的需求，是进行训练的重要优化手段。</p>
<p>MindSpore提供了分布式并行训练的功能，它支持了包括数据并行和自动并行在内的多种并行模式。</p>
</div>
<div class="section" id="id3">
<h2>分布式并行配置<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>MindSpore的分布式并行配置通过<code class="docutils literal notranslate"><span class="pre">auto_parallel_context</span></code>来进行集中管理，用户可根据自身需求和实际情况来进行个性化的配置。这些配置可分为三大类：</p>
<ul class="simple">
<li><p>通用配置：对数据并行、自动并行以及混合并行均起作用的配置，如：<code class="docutils literal notranslate"><span class="pre">device_num</span></code>、<code class="docutils literal notranslate"><span class="pre">global_rank</span></code>等。</p></li>
<li><p>自动并行配置：仅在自动并行模式下起作用的配置，如：<code class="docutils literal notranslate"><span class="pre">auto_parallel_search_mode</span></code>、<code class="docutils literal notranslate"><span class="pre">gradient_fp32_sync</span></code>等。</p></li>
</ul>
<p>用户可利用<code class="docutils literal notranslate"><span class="pre">context.set_auto_parallel_context</span></code>配置上述参数，同时可通过<code class="docutils literal notranslate"><span class="pre">context.get_auto_parallel_context</span></code>来获取上述参数。</p>
<div class="section" id="id4">
<h3>通用配置<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<div class="section" id="device-num">
<h4>device_num<a class="headerlink" href="#device-num" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">device_num</span></code>表示可用的机器数，其值为int型，默认值是0，且必须在1~4096范围内。若用户不配置，<code class="docutils literal notranslate"><span class="pre">Model</span></code>接口内部则会通过<code class="docutils literal notranslate"><span class="pre">get_group_size</span></code>方法获取，若用户进行了配置，则遵循用户的配置。这个配置可以在用户不使用<code class="docutils literal notranslate"><span class="pre">Model</span></code>接口的情况下，手动传递<code class="docutils literal notranslate"><span class="pre">device_num</span></code>。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">device_num</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">get_auto_parallel_context</span><span class="p">(</span><span class="s2">&quot;device_num&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="global-rank">
<h4>global_rank<a class="headerlink" href="#global-rank" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">global_rank</span></code>表示当前卡的逻辑序号，其值为int型，默认值是0，且必须在0~4095范围内。若用户不配置，<code class="docutils literal notranslate"><span class="pre">Model</span></code>接口内部则会通过<code class="docutils literal notranslate"><span class="pre">get_rank</span></code>方法获取，若用户进行了配置，则遵循用户的配置。这个配置可以在用户不使用<code class="docutils literal notranslate"><span class="pre">Model</span></code>接口的情况下，手动传递<code class="docutils literal notranslate"><span class="pre">global_rank</span></code>。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">global_rank</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">get_auto_parallel_context</span><span class="p">(</span><span class="s2">&quot;global_rank&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="gradients-mean">
<h4>gradients_mean<a class="headerlink" href="#gradients-mean" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">gradients_mean</span></code>表示在反向梯度进行聚合时，是否进行平均操作。其值为bool型，默认为False，即梯度聚合仅进行AllReduce的SUM操作，不做平均操作。<code class="docutils literal notranslate"><span class="pre">gradients_mean</span></code>会影响网络的收敛，不同场景，<code class="docutils literal notranslate"><span class="pre">gradients_mean</span></code>的设置可能不同。因此，MindSpore提供这个接口让用户根据实际情况来配置。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">gradients_mean</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">get_auto_parallel_context</span><span class="p">(</span><span class="s2">&quot;gradients_mean&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="parallel-mode">
<h4>parallel_mode<a class="headerlink" href="#parallel-mode" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">parallel_mode</span></code>表示并行模式，其值为字符串类型。用户可选择的模式有：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">stand_alone</span></code>：单机模式。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data_parallel</span></code>：数据并行模式。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">hybrid_parallel</span></code>：混合并行模式。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">semi_auto_parallel</span></code>：半自动并行模式，即用户可通过<code class="docutils literal notranslate"><span class="pre">shard</span></code>方法给算子配置切分策略，若不配置策略，则默认是数据并行策略。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">auto_parallel</span></code>：自动并行模式，即框架会自动建立代价模型，为用户选择最优的切分策略。</p></li>
</ul>
<p>其中<code class="docutils literal notranslate"><span class="pre">auto_parallel</span></code>和<code class="docutils literal notranslate"><span class="pre">data_parallel</span></code>在MindSpore教程中有完整样例：</p>
<p><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/distributed_training.html">https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/distributed_training.html</a>。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">parallel_mode</span><span class="o">=</span><span class="s2">&quot;semi_auto_parallel&quot;</span><span class="p">)</span>
<span class="n">mul</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Mul</span><span class="p">()</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
<span class="n">context</span><span class="o">.</span><span class="n">get_auto_parallel_context</span><span class="p">(</span><span class="s2">&quot;parallel_mode&quot;</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><p>在semi_auto_parallel模式下，如果一个Parameter被多个算子共享，则需要保证该Parameter在每个算子中的排布都一致，否则构图将会失败。比如下面这个例子中，mul1和mul2共享权重weight，但mul1对weight按行切8份，而mul2对weight按列切8份，weight在两个算子中的排布不一致，构图将会失败：</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Parameter</span>
<span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Cell</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">Cell</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Net definition&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mul1</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Mul</span><span class="p">()</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mul2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Mul</span><span class="p">()</span><span class="o">.</span><span class="n">shard</span><span class="p">(((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="s2">&quot;weight1&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mul1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mul2</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
<div class="section" id="all-reduce-fusion-config">
<h4>all_reduce_fusion_config<a class="headerlink" href="#all-reduce-fusion-config" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">all_reduce_fusion_config</span></code>可以让用户自定义梯度AllReduce融合切分策略。出于减少资源消耗及算子执行间隙的目的，框架默认将所有反向梯度聚合的AllReduce融合成一个算子运算，但当模型较大时，这会造成迭代拖尾耗时增加。用户可结合具体网络，通过设置该参数，手动调优找到性能最好的融合切分策略。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">all_reduce_fusion_config</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">35</span><span class="p">])</span>
<span class="n">context</span><span class="o">.</span><span class="n">get_auto_parallel_context</span><span class="p">(</span><span class="s2">&quot;all_reduce_fusion_config&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>样例中，<code class="docutils literal notranslate"><span class="pre">all_reduce_fusion_config</span></code>的值为[20, 35]，将前20个AllReduce融合成1个，第20～35个AllReduce融合成1个，剩下的AllReduce融合成1个。</p>
</div>
<div class="section" id="enable-parallel-optimizer">
<h4>enable_parallel_optimizer<a class="headerlink" href="#enable-parallel-optimizer" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">enable_parallel_optimizer</span></code>是一个开发中特性，参数默认值是False。数据并行时参数更新部分在各卡间存在冗余计算，优化器并行通过将优化器的计算量分散到各个卡上，在大规模网络上（比如Bert、GPT）可以有效减少内存消耗并提升网络性能。</p>
<p>在<code class="docutils literal notranslate"><span class="pre">data_parallel</span></code>模式下使能优化器并行，框架会将需要更新的参数进行分组到不同卡上，各自更新后再通过<code class="docutils literal notranslate"><span class="pre">Broadcast</span></code>算子在集群间做权重共享。需要注意的是参数量应当大于机器数，当前只支持<code class="docutils literal notranslate"><span class="pre">Lamb</span></code>和<code class="docutils literal notranslate"><span class="pre">AdamWeightDecay</span></code>优化器。</p>
<p>在<code class="docutils literal notranslate"><span class="pre">auto_parallel</span></code>或者<code class="docutils literal notranslate"><span class="pre">semi_auto_parallel</span></code>模式下使能优化器并行，如果经过策略切分后的参数在机器间存在重复切片，并且shape的最高维可以被卡数整除，框架会以最小切片的方式保存参数并在优化器中更新。该模式下支持所有优化器。</p>
<p>无论是哪种模式，优化器并行不会影响原有正反向网络的计算图，只会影响参数更新的计算量和计算逻辑。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">enable_parallel_optimizer</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">get_auto_parallel_context</span><span class="p">(</span><span class="s2">&quot;enable_parallel_optimizer&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="parameter-broadcast">
<h4>parameter_broadcast<a class="headerlink" href="#parameter-broadcast" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">parameter_broadcast</span></code>将数据并行参数在0号卡上的权值广播到其他卡上，达到同步初始化权重的目的。参数默认值是False，当前仅支持图模式。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">parameter_broadcast</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">get_auto_parallel_context</span><span class="p">(</span><span class="s2">&quot;parameter_broadcast&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id5">
<h3>自动并行配置<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<div class="section" id="gradient-fp32-sync">
<h4>gradient_fp32_sync<a class="headerlink" href="#gradient-fp32-sync" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">gradient_fp32_sync</span></code>表示梯度是否以float32类型进行聚合，其值为bool类型，默认为True，即梯度以float32类型进行聚合。由于<code class="docutils literal notranslate"><span class="pre">Ascend</span></code>AI处理器的特殊构造，float32类型的数据进行聚合的速度要高于float16，但可能会影响精度。因此，MindSpore提供<code class="docutils literal notranslate"><span class="pre">gradient_fp32_sync</span></code>接口，让用户自己根据实际情况去进行取舍。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">gradient_fp32_sync</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">get_auto_parallel_context</span><span class="p">(</span><span class="s2">&quot;gradient_fp32_sync&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="auto-parallel-search-mode">
<h4>auto_parallel_search_mode<a class="headerlink" href="#auto-parallel-search-mode" title="Permalink to this headline">¶</a></h4>
<p>MindSpore提供了<code class="docutils literal notranslate"><span class="pre">dynamic_programming</span></code>和<code class="docutils literal notranslate"><span class="pre">recursive_programming</span></code>两种搜索策略的算法，默认是<code class="docutils literal notranslate"><span class="pre">dynamic_programming</span></code>。<code class="docutils literal notranslate"><span class="pre">dynamic_programming</span></code>能够搜索出代价模型刻画的最优策略，但在搜索巨大网络模型的并行策略时耗时较长；而<code class="docutils literal notranslate"><span class="pre">recursive_programming</span></code>能瞬间搜索出并行策略，同时在已验证的常用网络中搜索出来的策略是最优策略，但在未经验证的某些特殊网络中可能找到次优策略。为此，MindSpore提供了参数，让用户自由选择搜索算法。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">auto_parallel_search_mode</span><span class="o">=</span><span class="s2">&quot;recursive_programming&quot;</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">get_auto_parallel_context</span><span class="p">(</span><span class="s2">&quot;auto_parallel_search_mode&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="strategy-ckpt-load-file">
<h4>strategy_ckpt_load_file<a class="headerlink" href="#strategy-ckpt-load-file" title="Permalink to this headline">¶</a></h4>
<p>指定加载路径，加载自动并行中所有带有权重的算子的切分信息。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">strategy_ckpt_load_file</span><span class="o">=</span><span class="s2">&quot;./&quot;</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">get_auto_parallel_context</span><span class="p">(</span><span class="s2">&quot;strategy_ckpt_load_file&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="strategy-ckpt-save-file">
<h4>strategy_ckpt_save_file<a class="headerlink" href="#strategy-ckpt-save-file" title="Permalink to this headline">¶</a></h4>
<p>指定存储路径，存储自动并行中所有带有权重的算子的切分信息。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">strategy_ckpt_save_file</span><span class="o">=</span><span class="s2">&quot;./&quot;</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">get_auto_parallel_context</span><span class="p">(</span><span class="s2">&quot;strategy_ckpt_save_file&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="full-batch">
<h4>full_batch<a class="headerlink" href="#full-batch" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">full_batch</span></code>可以让用户决定数据集是否以全量导入。默认是False。即数据集以数据并行的方式导入。在特殊场景下，数据集全量导入的性能要优于数据并行方式导入，比如WideDeep网络的非均匀切分场景。因此，MindSpore提供<code class="docutils literal notranslate"><span class="pre">full_batch</span></code>可配置接口。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">full_batch</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">get_auto_parallel_context</span><span class="p">(</span><span class="s2">&quot;full_batch&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="pipeline-stages">
<h4>pipeline_stages<a class="headerlink" href="#pipeline-stages" title="Permalink to this headline">¶</a></h4>
<p>近年来，神经网络的规模几乎是呈指数型增长。受单卡内存的限制，训练这些大模型用到的设备数量也在不断增加。受server间通信带宽低的影响，传统数据并行叠加模型并行的这种混合并行模式的性能表现欠佳，需要引入流水线并行。流水线并行能够将模型在空间上按<code class="docutils literal notranslate"><span class="pre">stage</span></code>进行切分，每个<code class="docutils literal notranslate"><span class="pre">stage</span></code>只需执行网络的一部分，大大节省了内存开销，同时缩小了通信域。MindSpore能够根据用户的配置，将单机模型自动地转换成流水线并行模式去执行。<code class="docutils literal notranslate"><span class="pre">pipeline_stages</span></code>用来设置流水线并行的<code class="docutils literal notranslate"><span class="pre">stage</span></code>个数。
代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">pipeline_stages</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">get_auto_parallel_context</span><span class="p">(</span><span class="s2">&quot;pipeline_stages&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="grad-accumulation-step">
<h4>grad_accumulation_step<a class="headerlink" href="#grad-accumulation-step" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">grad_accumulation_step</span></code>指梯度累积步数。具体用法请参考<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/apply_gradient_accumulation.html">指导教程</a></p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">grad_accumulation_step</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">get_auto_parallel_context</span><span class="p">(</span><span class="s2">&quot;grad_accumulation_step&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id6">
<h2>分布式通信接口<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">mindspore.communication.management</span></code>中封装了分布式并行用到的集合通信接口，方便用户配置分布式信息。</p>
<div class="section" id="init">
<h3>init<a class="headerlink" href="#init" title="Permalink to this headline">¶</a></h3>
<p>使能MindSpore通信，并完成分布式训练初始化操作。<code class="docutils literal notranslate"><span class="pre">init</span></code>要在<code class="docutils literal notranslate"><span class="pre">context.set_context</span></code>之后调用。用户可给<code class="docutils literal notranslate"><span class="pre">init</span></code>传入通信后端信息，<code class="docutils literal notranslate"><span class="pre">init</span></code>会根据不同的后端来进行不同初始化。</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">hccl</span></code>：全名为<code class="docutils literal notranslate"><span class="pre">Huawei</span> <span class="pre">Collective</span> <span class="pre">Communication</span> <span class="pre">Library</span></code>。用于<code class="docutils literal notranslate"><span class="pre">Ascend</span></code>处理器平台。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nccl</span></code>：全名为<code class="docutils literal notranslate"><span class="pre">NVIDIA</span> <span class="pre">Collective</span> <span class="pre">Communication</span> <span class="pre">Library</span></code>。用于<code class="docutils literal notranslate"><span class="pre">GPU</span></code>处理器平台。</p></li>
</ul>
<p>若用户不配置通信后端，MindSpore会根据<code class="docutils literal notranslate"><span class="pre">context</span></code>中的<code class="docutils literal notranslate"><span class="pre">device_target</span></code>信息进行自动配置。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="get-group-size">
<h3>get_group_size<a class="headerlink" href="#get-group-size" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">get_group_size</span></code>可让用户获取集群数量。在用<code class="docutils literal notranslate"><span class="pre">get_group_size</span></code>接口之前，要先调用<code class="docutils literal notranslate"><span class="pre">init</span></code>。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_group_size</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="n">group_size</span> <span class="o">=</span> <span class="n">get_group_size</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="get-rank">
<h3>get_rank<a class="headerlink" href="#get-rank" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">get_rank</span></code>可让用户获取当前设备在集群中的ID。在用<code class="docutils literal notranslate"><span class="pre">get_rank</span></code>接口之前，要先调用<code class="docutils literal notranslate"><span class="pre">init</span></code>。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="n">rank_id</span> <span class="o">=</span> <span class="n">get_rank</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id7">
<h2>分布式属性配置<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<div class="section" id="cross-batch">
<h3>cross_batch<a class="headerlink" href="#cross-batch" title="Permalink to this headline">¶</a></h3>
<p>在特定场景下，<code class="docutils literal notranslate"><span class="pre">data_parallel</span></code>的计算逻辑和<code class="docutils literal notranslate"><span class="pre">stand_alone</span></code>是不一样的，<code class="docutils literal notranslate"><span class="pre">auto_parallel</span></code>在任何场景下都是和<code class="docutils literal notranslate"><span class="pre">stand_alone</span></code>的计算逻辑保持一致。而<code class="docutils literal notranslate"><span class="pre">data_parallel</span></code>的收敛效果可能更好，因此MindSpore提供了<code class="docutils literal notranslate"><span class="pre">cross_batch</span></code>这个参数，可以使<code class="docutils literal notranslate"><span class="pre">auto_parallel</span></code>的计算逻辑和<code class="docutils literal notranslate"><span class="pre">data_parallel</span></code>保持一致，用户可通过<code class="docutils literal notranslate"><span class="pre">add_prim_attr</span></code>方法进行配置，默认值是False。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">mul</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Mul</span><span class="p">()</span><span class="o">.</span><span class="n">add_prim_attr</span><span class="p">(</span><span class="s2">&quot;cross_batch&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="fusion">
<h3>fusion<a class="headerlink" href="#fusion" title="Permalink to this headline">¶</a></h3>
<p>出于性能考虑，MindSpore提供了<code class="docutils literal notranslate"><span class="pre">AllGather</span></code>和<code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>算子的融合功能，<code class="docutils literal notranslate"><span class="pre">fusion</span></code>值相同的同类算子（算子类型以及通信域相同）会融合在一起，<code class="docutils literal notranslate"><span class="pre">fusion</span></code>的值必须大于等于0，且当<code class="docutils literal notranslate"><span class="pre">fusion</span></code>值为0时，表示不融合。目前只支持<code class="docutils literal notranslate"><span class="pre">Ascend</span></code>后端。</p>
<p><code class="docutils literal notranslate"><span class="pre">fusion</span></code>属性的配置有两种方式，如果是显式调用通信算子可以通过<code class="docutils literal notranslate"><span class="pre">add_prim_attr</span></code>方法直接为通信算子配置属性。代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">allreduce1</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">AllReduce</span><span class="p">()</span><span class="o">.</span><span class="n">add_prim_attr</span><span class="p">(</span><span class="s2">&quot;fusion&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">allreduce2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">AllReduce</span><span class="p">()</span><span class="o">.</span><span class="n">add_prim_attr</span><span class="p">(</span><span class="s2">&quot;fusion&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>样例中的<code class="docutils literal notranslate"><span class="pre">allreduce1</span></code>和<code class="docutils literal notranslate"><span class="pre">allreduce2</span></code>将在执行时被融合为一个算子。</p>
<p>在<code class="docutils literal notranslate"><span class="pre">AUTO_PARALLEL</span></code>和<code class="docutils literal notranslate"><span class="pre">SEMI_AUTO_PARALLEL</span></code>模式下自动插入的用于参数或者梯度聚合的通信算子，需要通过对<code class="docutils literal notranslate"><span class="pre">Cell</span></code>或者<code class="docutils literal notranslate"><span class="pre">Parameter</span></code>设置属性的方式间接添加。例如：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Parameter</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Net definition&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">MatMul</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">MatMul</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">48</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;weight1&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p1</span><span class="o">.</span><span class="n">comm_fusion</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p2</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">64</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;weight2&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="n">y</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">parallel_mode</span><span class="o">=</span><span class="s2">&quot;auto_parallel&quot;</span><span class="p">,</span> <span class="n">device_num</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span><span class="o">.</span><span class="n">set_comm_fusion</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>样例中对参数<code class="docutils literal notranslate"><span class="pre">Net.p1</span></code>设置<code class="docutils literal notranslate"><span class="pre">comm_fusion</span></code>为2，表示作用于该参数的通信算子<code class="docutils literal notranslate"><span class="pre">fusion</span></code>属性为2。当需要批量对参数进行操作时，可以调用<code class="docutils literal notranslate"><span class="pre">set_comm_fusion</span></code>方法将网络<code class="docutils literal notranslate"><span class="pre">Net</span></code>中包含的全部参数设置<code class="docutils literal notranslate"><span class="pre">comm_fusion</span></code>属性。如果多次调用的话，属性值会被覆盖。</p>
<blockquote>
<div><p>当参数被共享时，需要保证连接参数的多个算子混合精度一致，否则融合会失败。</p>
</div></blockquote>
</div>
<div class="section" id="layerwise-parallel">
<h3>layerwise_parallel<a class="headerlink" href="#layerwise-parallel" title="Permalink to this headline">¶</a></h3>
<p>在<code class="docutils literal notranslate"><span class="pre">HYBRID_PARALLEL</span></code>模式下用户需要手动切分模型，其中对于模型并行的参数用户需要手动打上标记<code class="docutils literal notranslate"><span class="pre">layerwise_parallel</span></code>，框架会根据此标记为模型并行参数过滤掉梯度聚合操作。</p>
<p>代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">Tensor</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])),</span> <span class="n">layerwise_parallel</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="distributed_training_mode.html" class="btn btn-neutral float-right" title="分布式并行训练模式" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="distributed_training.html" class="btn btn-neutral float-left" title="分布式并行总览" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>