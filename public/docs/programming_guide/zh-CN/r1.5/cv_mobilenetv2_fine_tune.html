<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>使用MobileNetV2网络实现微调（Fine Tune） &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="自然语言处理" href="nlp.html" />
    <link rel="prev" title="使用ResNet-50网络实现图像分类" href="cv_resnet50.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">整体介绍</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">MindSpore总体架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API概述</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">设计介绍</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/technical_white_paper.html">技术白皮书</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/all_scenarios_architecture.html">全场景统一架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/gradient.html">函数式可微分编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/dynamic_graph_and_static_graph.html">动态图和静态图</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/distributed_training_design.html">分布式训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/heterogeneous_training.html">异构并行训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindir.html">MindSpore IR（MindIR）</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/training_visual_design.html">可视化调试调优↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindarmour/docs/zh-CN/r1.5/design.html">安全可信↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/glossary.html">术语</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">快速入门</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/r1.5/linear_regression.html">实现简单线性函数拟合↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/r1.5/quick_start.html">实现一个图片分类应用↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">基本概念</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dtype.html">DataType</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter_introduction.html">Parameter</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators.html">算子</a></li>
<li class="toctree-l1"><a class="reference internal" href="cell.html">Cell</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_introduction.html">Dataset</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">数据加载和处理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataset_sample.html">快速入门数据加载和处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">数据集加载</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_advanced.html">数据处理高级用法</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_usage.html">数据迭代</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">网络构建</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="build_net.html">构建单算子网络和多层网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="initializer.html">Initializer初始化器</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter.html">网络参数</a></li>
<li class="toctree-l1"><a class="reference internal" href="control_flow.html">使用流程控制语句</a></li>
<li class="toctree-l1"><a class="reference internal" href="indefinite_parameter.html">参数传递</a></li>
<li class="toctree-l1"><a class="reference internal" href="constexpr.html">网络内构造常量</a></li>
<li class="toctree-l1"><a class="reference internal" href="loss.html">损失函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="grad_operation.html">求导</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypermap.html">运算重载</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">优化器</a></li>
<li class="toctree-l1"><a class="reference internal" href="train_and_eval.html">构建训练与评估网络</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型运行</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="context.html">配置运行信息</a></li>
<li class="toctree-l1"><a class="reference internal" href="run.html">运行方式</a></li>
<li class="toctree-l1"><a class="reference internal" href="ms_function.html">ms_function动静结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_and_load_models.html">模型保存与加载</a></li>
<li class="toctree-l1"><a class="reference internal" href="model.html">Model接口应用</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">推理模型总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="online_inference.html">加载Checkpoint在线推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="offline_inference.html">使用离线模型推理</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">分布式并行</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">分布式并行总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_advanced.html">分布式并行高级特性</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_example.html">分布式并行使用样例</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyNative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">PyNative模式应用</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Numpy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">MindSpore NumPy函数</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">高级特性</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="second_order_optimizer.html">二阶优化</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">应用感知量化训练</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">功能调试</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="read_ir_files.html">如何查看IR文件</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/debug_in_pynative_mode.html">使用PyNative模式调试↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">使用Dump功能在Graph模式调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">自定义调试信息</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">算子增量编译</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">精度调优</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/accuracy_problem_preliminary_location.html">精度问题初步定位指南↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/accuracy_optimization.html">精度问题详细定位和调优指南↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">性能优化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">使能混合精度</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">使能图算融合</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_tune.html">使能算子调优工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">应用梯度累积算法</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/performance_profiling.html">使用Profiler调试性能↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">应用实践</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="cv.html">机器视觉</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="cv_resnet50.html">使用ResNet-50网络实现图像分类</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">使用MobileNetV2网络实现微调（Fine Tune）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">概述</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">任务描述及准备</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id3">环境配置</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id4">下载代码</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id5">准备预训练模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id6">准备数据</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id7">预训练模型加载代码详解</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id8">参数简介</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#python">运行Python文件</a></li>
<li class="toctree-l4"><a class="reference internal" href="#shell">运行Shell脚本</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id9">加载微调训练</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#cpu">CPU加载训练</a></li>
<li class="toctree-l4"><a class="reference internal" href="#gpu">GPU加载训练</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ascend">Ascend加载训练</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id10">微调训练结果</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id11">验证微调训练模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id12">验证模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id13">验证结果</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">自然语言处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">高性能计算</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">在云上使用MindSpore</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="cv.html">机器视觉</a> &raquo;</li>
      <li>使用MobileNetV2网络实现微调（Fine Tune）</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/cv_mobilenetv2_fine_tune.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="mobilenetv2-fine-tune">
<h1>使用MobileNetV2网络实现微调（Fine Tune）<a class="headerlink" href="#mobilenetv2-fine-tune" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">全流程</span></code></p>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.5/docs/mindspore/programming_guide/source_zh_cn/cv_mobilenetv2_fine_tune.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source.png"></a>  </p>
<section id="id1">
<h2>概述<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h2>
<p>计算机视觉任务中，从头开始训练一个网络耗时巨大，需要大量计算能力。预训练模型选择的常见的OpenImage、ImageNet、VOC、COCO等公开大型数据集，规模达到几十万甚至超过上百万张。大部分任务数据规模较大，训练网络模型时，如果不使用预训练模型，从头开始训练网络，需要消耗大量的时间与计算能力，模型容易陷入局部极小值和过拟合。因此大部分任务都会选择预训练模型，在其上做微调（也称为Fine Tune）。</p>
<p>MindSpore是一个多元化的机器学习框架。既可以在手机等端侧和PC等设备上运行，也可以在云上的服务器集群上运行。目前MobileNetV2支持在Windows、EulerOS和Ubuntu系统中使用单个CPU做微调，也可以使用单个或者多个Ascend AI处理器或GPU做微调，本教程将会介绍如何在不同系统与处理器下的MindSpore框架中做微调的训练与验证。</p>
<p>目前，Window上暂只支持支持CPU，Ubuntu与EulerOS上支持CPU、GPU与Ascend AI处理器三种处理器。</p>
<blockquote>
<div><p>你可以在这里找到完整可运行的样例代码：<a class="reference external" href="https://gitee.com/mindspore/models/tree/r1.5/official/cv/mobilenetv2">https://gitee.com/mindspore/models/tree/r1.5/official/cv/mobilenetv2</a></p>
</div></blockquote>
</section>
<section id="id2">
<h2>任务描述及准备<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h2>
<section id="id3">
<h3>环境配置<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h3>
<p>若在本地环境运行，需要安装MindSpore框架，配置CPU、GPU或Ascend AI处理器。若在华为云环境上运行，不需要安装MindSpore框架，不需要配置Ascend AI处理器、CPU与GPU，可以跳过本小节。</p>
<p>Windows操作系统中使用<code class="docutils literal notranslate"><span class="pre">\</span></code>，Linux操作系统中使用<code class="docutils literal notranslate"><span class="pre">/</span></code>分割路径地址中不同层级目录，下文中默认使用<code class="docutils literal notranslate"><span class="pre">/</span></code>，若用户使用Windows操作系统，路径地址中<code class="docutils literal notranslate"><span class="pre">/</span></code>需自行更改为<code class="docutils literal notranslate"><span class="pre">\</span></code>。</p>
<ol class="arabic">
<li><p>安装MindSpore框架
在EulerOS、Ubuntu或者Windows等系统上需要根据系统和处理器架构<a class="reference external" href="https://www.mindspore.cn/install">安装对应版本MindSpore框架</a>。</p></li>
<li><p>配置CPU环境<br />
使用CPU时，在代码中，需要在调用CPU开始训练或测试前，按照如下代码设置：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s2">&quot;CPU&quot;</span><span class="p">:</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">platform</span><span class="p">,</span> \
        <span class="n">save_graphs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>配置GPU环境<br />
使用GPU时，在代码中，需要在调用GPU开始训练或测试前，按照如下代码设置：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s2">&quot;GPU&quot;</span><span class="p">:</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">platform</span><span class="p">,</span> <span class="n">save_graphs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">run_distribute</span><span class="p">:</span>
        <span class="n">init</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>
        <span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">device_num</span><span class="o">=</span><span class="n">get_group_size</span><span class="p">(),</span>
                                          <span class="n">parallel_mode</span><span class="o">=</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">DATA_PARALLEL</span><span class="p">,</span>
                                          <span class="n">gradients_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>配置Ascend环境<br />
以Ascend 910 AI处理器为例，1个8个处理器环境的json配置文件<code class="docutils literal notranslate"><span class="pre">hccl_config.json</span></code>示例如下。单/多处理器环境可以根据以下示例调整<code class="docutils literal notranslate"><span class="pre">&quot;server_count&quot;</span></code>与<code class="docutils literal notranslate"><span class="pre">device</span></code>：</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;version&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1.0&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;server_count&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;server_list&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;server_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;10.*.*.*&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.1.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.2.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.3.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;3&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.4.27.6&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;3&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;4&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.1.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;4&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;5&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.2.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;5&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;6&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.3.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;6&quot;</span><span class="p">},</span>
<span class="w">                </span><span class="p">{</span><span class="nt">&quot;device_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;7&quot;</span><span class="p">,</span><span class="nt">&quot;device_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;192.4.27.7&quot;</span><span class="p">,</span><span class="nt">&quot;rank_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;7&quot;</span><span class="p">}],</span>
<span class="w">            </span><span class="nt">&quot;host_nic_ip&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;reserve&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">],</span>
<span class="w">    </span><span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;completed&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>使用Ascend AI处理器时，在代码中，需要在调用Ascend AI处理器开始训练或测试前，按照如下代码设置：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s2">&quot;Ascend&quot;</span><span class="p">:</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">platform</span><span class="p">,</span> <span class="n">device_id</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">device_id</span><span class="p">,</span>
                        <span class="n">save_graphs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">run_distribute</span><span class="p">:</span>
        <span class="n">context</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">device_num</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">rank_size</span><span class="p">,</span>
                                          <span class="n">parallel_mode</span><span class="o">=</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">DATA_PARALLEL</span><span class="p">,</span>
                                          <span class="n">gradients_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                          <span class="n">all_reduce_fusion_config</span><span class="o">=</span><span class="p">[</span><span class="mi">140</span><span class="p">])</span>
        <span class="n">init</span><span class="p">()</span>
<span class="o">...</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="id4">
<h3>下载代码<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h3>
<p>在Gitee中克隆<a class="reference external" href="https://gitee.com/mindspore/models.git">MindSpore开源项目仓库</a>，进入<code class="docutils literal notranslate"><span class="pre">./models/official/cv/mobilenetv2/</span></code>。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://gitee.com/mindspore/models.git<span class="w"> </span>-b<span class="w"> </span>r1.5
<span class="nb">cd</span><span class="w"> </span>./models/official/cv/mobilenetv2
</pre></div>
</div>
<p>代码结构如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>├── MobileNetV2
  ├── README.md                  # MobileNetV2相关描述
  ├── ascend310_infer            # 用于310推理
  ├── scripts
  │   ├──run_train.sh            # 使用CPU、GPU或Ascend进行训练、微调或增量学习的shell脚本
  │   ├──run_eval.sh             # 使用CPU、GPU或Ascend进行评估的shell脚本
  │   ├──cache_util.sh           # 包含一些使用cache的帮助函数
  │   ├──run_train_nfs_cache.sh  # 使用NFS的数据集进行训练并利用缓存服务进行加速的shell脚本
  │   ├──run_infer_310.sh        # 使用Dvpp 或CPU算子进行推理的shell脚本
  ├── src
  │   ├──aipp.cfg                # aipp配置
  │   ├──dataset.py              # 创建数据集
  │   ├──launch.py               # 启动Python脚本
  │   ├──lr_generator.py         # 配置学习率
  │   ├──mobilenetV2.py          # MobileNetV2架构
  │   ├──models.py               # 加载define_net、Loss、及Monitor
  │   ├──utils.py                # 加载ckpt_file进行微调或增量学习
  │   └──model_utils
  │      ├──config.py            # 获取.yaml配置参数
  │      ├──device_adapter.py    # 获取云上id
  │      ├──local_adapter.py     # 获取本地id
  │      └──moxing_adapter.py    # 云上数据准备
  ├── default_config.yaml        # 训练配置参数(ascend)
  ├── default_config_cpu.yaml    # 训练配置参数(cpu)
  ├── default_config_gpu.yaml    # 训练配置参数(gpu)
  ├── train.py                   # 训练脚本
  ├── eval.py                    # 评估脚本
  ├── export.py                  # 模型导出脚本
  ├── mindspore_hub_conf.py      # MindSpore Hub接口
  ├── postprocess.py             # 推理后处理脚本
</pre></div>
</div>
<p>运行微调训练与测试时，Windows、Ubuntu与EulersOS上可以使用Python文件<code class="docutils literal notranslate"><span class="pre">train.py</span></code>与<code class="docutils literal notranslate"><span class="pre">eval.py</span></code>，Ubuntu与EulerOS上还可以使用Shell脚本文件<code class="docutils literal notranslate"><span class="pre">run_train.sh</span></code>与<code class="docutils literal notranslate"><span class="pre">run_eval.sh</span></code>。</p>
<p>使用脚本文件<code class="docutils literal notranslate"><span class="pre">run_train.sh</span></code>时，该文件会将运行<code class="docutils literal notranslate"><span class="pre">launch.py</span></code>并且将参数传入<code class="docutils literal notranslate"><span class="pre">launch.py</span></code>，<code class="docutils literal notranslate"><span class="pre">launch.py</span></code>根据分配的CPU、GPU或Ascend AI处理器数量，启动单个/多个进程运行<code class="docutils literal notranslate"><span class="pre">train.py</span></code>，每一个进程分配对应的一个处理器。</p>
</section>
<section id="id5">
<h3>准备预训练模型<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h3>
<p>用户需要根据不同处理器种类<a class="reference external" href="https://download.mindspore.cn/model_zoo/official/lite/mobilenetv2_openimage_lite/mobilenetv2_cpu_gpu.ckpt">下载CPU/GPU预训练模型</a>或<a class="reference external" href="https://download.mindspore.cn/model_zoo/r1.2/mobilenetv2_ascend_v120_imagenet2012_official_cv_bs256_acc71/mobilenetv2_ascend_v120_imagenet2012_official_cv_bs256_acc71.ckpt">下载Ascend预训练模型</a>到以下目录：<br />
<code class="docutils literal notranslate"><span class="pre">./pretrain_checkpoint/</span></code></p>
<ul>
<li><p>CPU/GPU 处理器</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>pretrain_checkpoint
wget<span class="w"> </span>-P<span class="w"> </span>./pretrain_checkpoint<span class="w"> </span>https://download.mindspore.cn/model_zoo/official/lite/mobilenetv2_openimage_lite/mobilenetv2_cpu_gpu.ckpt<span class="w"> </span>--no-check-certificate
</pre></div>
</div>
</li>
<li><p>Ascend AI处理器</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>pretrain_checkpoint
wget<span class="w"> </span>-P<span class="w"> </span>./pretrain_checkpoint<span class="w"> </span>https://download.mindspore.cn/model_zoo/r1.2/mobilenetv2_ascend_v120_imagenet2012_official_cv_bs256_acc71/mobilenetv2_ascend_v120_imagenet2012_official_cv_bs256_acc71.ckpt<span class="w"> </span>--no-check-certificate
</pre></div>
</div>
</li>
</ul>
</section>
<section id="id6">
<h3>准备数据<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h3>
<p>准备ImageFolder格式管理的数据集，运行<code class="docutils literal notranslate"><span class="pre">run_train.sh</span></code>时加入<code class="docutils literal notranslate"><span class="pre">&lt;dataset_path&gt;</span></code>参数，运行<code class="docutils literal notranslate"><span class="pre">train.py</span></code>时加入<code class="docutils literal notranslate"><span class="pre">--dataset_path</span> <span class="pre">&lt;dataset_path&gt;</span></code>参数：</p>
<p>数据集结构如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>└─ImageFolder
    ├─train
    │   class1Folder
    │   class2Folder
    │   ......
    └─eval
        class1Folder
        class2Folder
        ......
</pre></div>
</div>
<blockquote>
<div><p>运行本例时，上述结构中验证数据集文件夹名称<code class="docutils literal notranslate"><span class="pre">eval</span></code>需改为<code class="docutils literal notranslate"><span class="pre">validation_preprocess</span></code>。</p>
</div></blockquote>
</section>
</section>
<section id="id7">
<h2>预训练模型加载代码详解<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h2>
<p>在微调时，需要加载预训练模型。不同数据集和任务中特征提取层（卷积层）分布趋于一致，但是特征向量的组合（全连接层）不相同，分类数量（全连接层output_size）通常也不一致。在微调时，只加载与训练特征提取层参数，不加载与训练全连接层参数；在微调与初始训练时，加载与训练特征提取层参数与全连接层参数。</p>
<p>在训练与测试之前，首先按照代码第1行，构建MobileNetV2的backbone网络，head网络，并且构建包含这两个子网络的MobileNetV2网络。代码第3-10行展示了如何定义<code class="docutils literal notranslate"><span class="pre">backbone_net</span></code>与<code class="docutils literal notranslate"><span class="pre">head_net</span></code>，以及将两个子网络置入<code class="docutils literal notranslate"><span class="pre">mobilenet_v2</span></code>中。代码第12-27行，展示了在微调训练模式下，需要将预训练模型加载入<code class="docutils literal notranslate"><span class="pre">backbone_net</span></code>子网络，并且冻结<code class="docutils literal notranslate"><span class="pre">backbone_net</span></code>中的参数，不参与训练。代码第25-27行展示了如何冻结网络参数。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span> <span class="mi">1</span><span class="p">:</span>  <span class="n">backbone_net</span><span class="p">,</span> <span class="n">head_net</span><span class="p">,</span> <span class="n">net</span> <span class="o">=</span> <span class="n">define_net</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">is_training</span><span class="p">)</span>
 <span class="mi">2</span><span class="p">:</span>  <span class="o">...</span>
 <span class="mi">3</span><span class="p">:</span>  <span class="k">def</span> <span class="nf">define_net</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
 <span class="mi">4</span><span class="p">:</span>      <span class="n">backbone_net</span> <span class="o">=</span> <span class="n">MobileNetV2Backbone</span><span class="p">()</span>
 <span class="mi">5</span><span class="p">:</span>      <span class="n">activation</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">activation</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">is_training</span> <span class="k">else</span> <span class="s2">&quot;None&quot;</span>
 <span class="mi">6</span><span class="p">:</span>      <span class="n">head_net</span> <span class="o">=</span> <span class="n">MobileNetV2Head</span><span class="p">(</span><span class="n">input_channel</span><span class="o">=</span><span class="n">backbone_net</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span>
 <span class="mi">7</span><span class="p">:</span>                              <span class="n">num_classes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span>
 <span class="mi">8</span><span class="p">:</span>                              <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">)</span>
 <span class="mi">9</span><span class="p">:</span>      <span class="n">net</span> <span class="o">=</span> <span class="n">mobilenet_v2</span><span class="p">(</span><span class="n">backbone_net</span><span class="p">,</span> <span class="n">head_net</span><span class="p">)</span>
<span class="mi">10</span><span class="p">:</span>      <span class="k">return</span> <span class="n">backbone_net</span><span class="p">,</span> <span class="n">head_net</span><span class="p">,</span> <span class="n">net</span>
<span class="mi">11</span><span class="p">:</span>  <span class="o">...</span>
<span class="mi">12</span><span class="p">:</span>  <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">pretrain_ckpt</span><span class="p">:</span>
<span class="mi">13</span><span class="p">:</span>      <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">freeze_layer</span> <span class="o">==</span> <span class="s2">&quot;backbone&quot;</span><span class="p">:</span>
<span class="mi">14</span><span class="p">:</span>         <span class="n">load_ckpt</span><span class="p">(</span><span class="n">backbone_net</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">pretrain_ckpt</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="mi">15</span><span class="p">:</span>         <span class="n">step_size</span> <span class="o">=</span> <span class="n">extract_features</span><span class="p">(</span><span class="n">backbone_net</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<span class="mi">16</span><span class="p">:</span>      <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">filter_head</span><span class="p">:</span>
<span class="mi">17</span><span class="p">:</span>           <span class="n">load_ckpt</span><span class="p">(</span><span class="n">backbone_net</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">pretrain_ckpt</span><span class="p">)</span>
<span class="mi">18</span><span class="p">:</span>      <span class="k">else</span><span class="p">:</span>
<span class="mi">19</span><span class="p">:</span>           <span class="n">load_ckpt</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">pretrain_ckpt</span><span class="p">)</span>
<span class="mi">20</span><span class="p">:</span>  <span class="o">...</span>
<span class="mi">21</span><span class="p">:</span>  <span class="k">def</span> <span class="nf">load_ckpt</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">pretrain_ckpt_path</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="mi">22</span><span class="p">:</span>      <span class="s2">&quot;&quot;&quot; train the param weight or not &quot;&quot;&quot;</span>
<span class="mi">23</span><span class="p">:</span>      <span class="n">param_dict</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">pretrain_ckpt_path</span><span class="p">)</span>
<span class="mi">24</span><span class="p">:</span>      <span class="n">load_param_into_net</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
<span class="mi">25</span><span class="p">:</span>      <span class="k">if</span> <span class="ow">not</span> <span class="n">trainable</span><span class="p">:</span>
<span class="mi">26</span><span class="p">:</span>          <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">():</span>
<span class="mi">27</span><span class="p">:</span>              <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
</section>
<section id="id8">
<h2>参数简介<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h2>
<p>每个参数需要用户根据自己本地的处理器类型、数据地址与预训练模型地址等修改为相应的值。</p>
<section id="python">
<h3>运行Python文件<a class="headerlink" href="#python" title="Permalink to this headline"></a></h3>
<p>在Windows与Linux系统上训练时，运行<code class="docutils literal notranslate"><span class="pre">train.py</span></code>时需要传入 <code class="docutils literal notranslate"><span class="pre">config_path</span></code>、 <code class="docutils literal notranslate"><span class="pre">dataset_path</span></code>、<code class="docutils literal notranslate"><span class="pre">platform</span></code>、<code class="docutils literal notranslate"><span class="pre">pretrain_ckpt</span></code>与<code class="docutils literal notranslate"><span class="pre">freeze_layer</span></code>五个参数。验证时，运行<code class="docutils literal notranslate"><span class="pre">eval.py</span></code>并且传入<code class="docutils literal notranslate"><span class="pre">config_path</span></code>、<code class="docutils literal notranslate"><span class="pre">dataset_path</span></code>、<code class="docutils literal notranslate"><span class="pre">platform</span></code>、<code class="docutils literal notranslate"><span class="pre">pretrain_ckpt</span></code>四个参数。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Windows/Linux train with Python file</span>
python<span class="w"> </span>train.py<span class="w"> </span>--config_path<span class="w"> </span><span class="o">[</span>CONFIG_PATH<span class="o">]</span><span class="w"> </span>--platform<span class="w"> </span><span class="o">[</span>PLATFORM<span class="o">]</span><span class="w"> </span>--dataset_path<span class="w"> </span>&lt;DATASET_PATH&gt;<span class="w">  </span>--pretrain_ckpt<span class="w"> </span><span class="o">[</span>PRETRAIN_CHECKPOINT_PATH<span class="o">]</span><span class="w"> </span>--freeze_layer<span class="o">[(</span><span class="s2">&quot;none&quot;</span>,<span class="w"> </span><span class="s2">&quot;backbone&quot;</span><span class="o">)]</span>

<span class="c1"># Windows/Linux eval with Python file</span>
python<span class="w"> </span>eval.py<span class="w"> </span>--config_path<span class="w"> </span><span class="o">[</span>CONFIG_PATH<span class="o">]</span><span class="w"> </span>--platform<span class="w"> </span><span class="o">[</span>PLATFORM<span class="o">]</span><span class="w"> </span>--dataset_path<span class="w"> </span>&lt;DATASET_PATH&gt;<span class="w"> </span>--pretrain_ckpt<span class="w"> </span>&lt;PRETRAIN_CHECKPOINT_PATH&gt;
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--config_path</span></code>：训练与验证所需参数。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--dataset_path</span></code>：训练与验证数据集地址，无默认值，用户训练/验证时必须输入。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--platform</span></code>：处理器类型，默认为“Ascend”，可以设置为“CPU”或”GPU”。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--pretrain_ckpt</span></code>：增量训练或调优时，需要传入pretrain_checkpoint文件路径以加载预训练好的模型参数权重。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--freeze_layer</span></code>：冻结网络层，输入“none”、”backbone”其中一个。</p></li>
</ul>
</section>
<section id="shell">
<h3>运行Shell脚本<a class="headerlink" href="#shell" title="Permalink to this headline"></a></h3>
<p>在Linux系统上时，可以选择运行Shell脚本文件<code class="docutils literal notranslate"><span class="pre">./scripts/run_train.sh</span></code>与<code class="docutils literal notranslate"><span class="pre">./scripts/run_eval.sh</span></code>。运行时需要在交互界面中同时传入参数。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Windows doesn&#39;t support Shell</span>
<span class="c1"># Linux train with Shell script</span>
sh<span class="w"> </span>run_train.sh<span class="w"> </span><span class="o">[</span>PLATFORM<span class="o">]</span><span class="w"> </span><span class="o">[</span>DEVICE_NUM<span class="o">]</span><span class="w"> </span><span class="o">[</span>VISIABLE_DEVICES<span class="o">(</span><span class="m">0</span>,1,2,3,4,5,6,7<span class="o">)]</span><span class="w"> </span><span class="o">[</span>RANK_TABLE_FILE<span class="o">]</span><span class="w"> </span><span class="o">[</span>DATASET_PATH<span class="o">]</span><span class="w"> </span><span class="o">[</span>CKPT_PATH<span class="o">](</span>optional<span class="o">)</span><span class="w"> </span><span class="o">[</span>FREEZE_LAYER<span class="o">](</span>optional<span class="o">)</span><span class="w"> </span><span class="o">[</span>FILTER_HEAD<span class="o">](</span>optional<span class="o">)</span>

<span class="c1"># Linux eval with Shell script for fine tune</span>
sh<span class="w"> </span>run_eval.sh<span class="w"> </span><span class="o">[</span>PLATFORM<span class="o">]</span><span class="w"> </span><span class="o">[</span>DATASET_PATH<span class="o">]</span><span class="w"> </span><span class="o">[</span>PRETRAIN_CKPT_PATH<span class="o">]</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;PLATFORM&gt;</span></code>：处理器类型，默认为“Ascend”，可以设置为“GPU”。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;DEVICE_NUM&gt;</span></code>：每个节点（一台服务器/PC相当于一个节点）进程数量，建议设置为机器上Ascend AI处理器数量或GPU数量。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;VISIABLE_DEVICES(0,1,2,3,4,5,6,7)&gt;</span></code>：字符串格式的设备ID，训练将会根据<code class="docutils literal notranslate"><span class="pre">&lt;VISIABLE_DEVICES&gt;</span></code>将进程绑定到对应ID的设备上，多个设备ID之间使用’,’分隔，建议ID数量与进程数量相同。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;RANK_TABLE_FILE&gt;</span></code>：platform选择Ascend时，需要配置Ascend的配置Json文件,。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;DATASET_PATH&gt;</span></code>：训练与验证数据集地址，无默认值，用户训练/验证时必须输入。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;CKPT_PATH&gt;</span></code>：增量训练或调优时，需要传入checkpoint文件路径以加载预训练好的模型参数权重</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[FREEZE_LAYER]</span></code>：针对微调的模型做验证时，需要选择不冻结网络或者冻结backbone。</p></li>
</ul>
</section>
</section>
<section id="id9">
<h2>加载微调训练<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h2>
<p>Windows系统上，MobileNetV2做微调训练时，只能运行<code class="docutils literal notranslate"><span class="pre">train.py</span></code>。Linux系统上，使用MobileNetV2做微调训练时，可以选择运行<code class="docutils literal notranslate"><span class="pre">run_train.sh</span></code>， 并在运行Shell脚本文件时传入<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/cv_mobilenetv2_fine_tune.html#id8">参数</a>。</p>
<p>Windows系统输出信息到交互式命令行，Linux系统环境下运行<code class="docutils literal notranslate"><span class="pre">run_train.sh</span></code>时，命令行结尾使用<code class="docutils literal notranslate"><span class="pre">&amp;&gt;</span> <span class="pre">&lt;log_file_path&gt;</span></code>将标准输出与错误输出写入log文件。微调成功开始训练，<code class="docutils literal notranslate"><span class="pre">./train/rank*/log*.log</span></code>中会持续写入每一个epoch的训练时间与Loss等信息。若未成功，上述log文件会写入失败报错信息。</p>
<section id="cpu">
<h3>CPU加载训练<a class="headerlink" href="#cpu" title="Permalink to this headline"></a></h3>
<ul>
<li><p>设置节点数量</p>
<p>目前运行<code class="docutils literal notranslate"><span class="pre">train.py</span></code>时仅支持单处理器，不需要调整处理器数量。运行<code class="docutils literal notranslate"><span class="pre">run_train.sh</span></code>文件时，<code class="docutils literal notranslate"><span class="pre">CPU</span></code>设备默认为单处理器，目前暂不支持修改CPU数量。</p>
</li>
<li><p>开始增量训练</p>
<p>使用样例1：通过Python文件调用1个CPU处理器。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Windows or Linux with Python</span>
python<span class="w"> </span>train.py<span class="w"> </span>--config_path<span class="w"> </span>./default_config_cpu.yaml<span class="w"> </span>--platform<span class="w"> </span>CPU<span class="w"> </span>--dataset_path<span class="w"> </span>&lt;TRAIN_DATASET_PATH&gt;<span class="w"> </span>--pretrain_ckpt<span class="w"> </span>./pretrain_checkpoint/mobilenetv2_cpu_gpu.ckpt<span class="w"> </span>--freeze_layer<span class="w"> </span>backbone<span class="w"> </span>--filter_head<span class="w"> </span>FILTER_HEAD<span class="w"> </span><span class="p">&amp;</span>&gt;<span class="w"> </span>./train.log<span class="w"> </span><span class="p">&amp;</span>
</pre></div>
</div>
<p>使用样例2：通过Shell文件调用1个CPU处理器。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Linux with Shell</span>
sh<span class="w"> </span>run_train.sh<span class="w"> </span>CPU<span class="w"> </span><span class="o">[</span>DATASET_PATH<span class="o">]</span><span class="w"> </span><span class="o">[</span>CKPT_PATH<span class="o">](</span>optional<span class="o">)</span><span class="w"> </span><span class="o">[</span>FREEZE_LAYER<span class="o">](</span>optional<span class="o">)</span><span class="w"> </span><span class="o">[</span>FILTER_HEAD<span class="o">](</span>optional<span class="o">)</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="gpu">
<h3>GPU加载训练<a class="headerlink" href="#gpu" title="Permalink to this headline"></a></h3>
<ul>
<li><p>设置节点数量</p>
<p>目前运行<code class="docutils literal notranslate"><span class="pre">train.py</span></code>时仅支持单处理器，不需要调整节点数量。运行<code class="docutils literal notranslate"><span class="pre">run_train.sh</span></code>文件时，设置<code class="docutils literal notranslate"><span class="pre">&lt;nproc_per_node&gt;</span></code>为GPU数量， <code class="docutils literal notranslate"><span class="pre">&lt;visible_devices&gt;</span></code>为可使用的处理器编号，即GPU的ID，可以选择一个或多个设备ID，使用<code class="docutils literal notranslate"><span class="pre">,</span></code>隔开。</p>
</li>
<li><p>开始增量训练</p>
<ul>
<li><p>使用样例1：通过Python文件调用1个GPU处理器。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Windows or Linux with Python</span>
python<span class="w"> </span>train.py<span class="w">  </span>--config_path<span class="w"> </span>./default_config_gpu.yaml<span class="w"> </span>--platform<span class="w"> </span>GPU<span class="w"> </span>--dataset_path<span class="w"> </span>&lt;TRAIN_DATASET_PATH&gt;<span class="w"> </span>--pretrain_ckpt<span class="w"> </span>./pretrain_checkpoint/mobilenetv2_cpu_gpu.ckpt<span class="w"> </span>--freeze_layer<span class="w"> </span>backbone
</pre></div>
</div>
</li>
<li><p>使用样例2：通过Shell脚本调用1个GPU处理器，设备ID为<code class="docutils literal notranslate"><span class="pre">“0”</span></code>。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Linux with Shell</span>
sh<span class="w"> </span>run_train.sh<span class="w"> </span>GPU<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">[</span>DATASET_PATH<span class="o">]</span><span class="w"> </span><span class="o">[</span>CKPT_PATH<span class="o">](</span>optional<span class="o">)</span><span class="w"> </span><span class="o">[</span>FREEZE_LAYER<span class="o">](</span>optional<span class="o">)</span><span class="w"> </span><span class="o">[</span>FILTER_HEAD<span class="o">](</span>optional<span class="o">)</span>
</pre></div>
</div>
</li>
<li><p>使用样例3：通过Shell脚本调用8个GPU处理器，设备ID为<code class="docutils literal notranslate"><span class="pre">“0,1,2,3,4,5,6,7”</span></code>。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Linux with Shell</span>
sh<span class="w"> </span>run_train.sh<span class="w"> </span>GPU<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="m">0</span>,1,2,3,4,5,6,7<span class="w"> </span><span class="o">[</span>DATASET_PATH<span class="o">]</span><span class="w"> </span><span class="o">[</span>CKPT_PATH<span class="o">](</span>optional<span class="o">)</span><span class="w"> </span><span class="o">[</span>FREEZE_LAYER<span class="o">](</span>optional<span class="o">)</span><span class="w"> </span><span class="o">[</span>FILTER_HEAD<span class="o">](</span>optional<span class="o">)</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</section>
<section id="ascend">
<h3>Ascend加载训练<a class="headerlink" href="#ascend" title="Permalink to this headline"></a></h3>
<ul>
<li><p>设置节点数量</p>
<p>目前运行<code class="docutils literal notranslate"><span class="pre">train.py</span></code>时仅支持单处理器，不需要调整节点数量。运行<code class="docutils literal notranslate"><span class="pre">run_train.sh</span></code>文件时，设置<code class="docutils literal notranslate"><span class="pre">&lt;nproc_per_node&gt;</span></code>为Ascend AI处理器数量， <code class="docutils literal notranslate"><span class="pre">&lt;visible_devices&gt;</span></code>为可使用的处理器编号，即Ascend AI处理器的ID，8卡服务器可以选择0-7中一个或多个设备ID，使用<code class="docutils literal notranslate"><span class="pre">,</span></code>隔开。Ascend节点处理器数量目前只能设置为1或者8。</p>
</li>
<li><p>开始增量训练</p>
<ul>
<li><p>使用样例1：通过Python文件调用1个Ascend处理器。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Windows or Linux with Python</span>
python<span class="w"> </span>train.py<span class="w"> </span>--config_path<span class="w"> </span>./default_config.yaml<span class="w"> </span>--platform<span class="w"> </span>Ascend<span class="w"> </span>--dataset_path<span class="w"> </span>&lt;TRAIN_DATASET_PATH&gt;<span class="w">  </span>--pretrain_ckpt<span class="w">  </span>./pretrain_checkpoint/mobilenetv2_ascend_v120_imagenet2012_official_cv_bs256_acc71.ckpt<span class="w"> </span>--freeze_layer<span class="w"> </span>backbone
</pre></div>
</div>
</li>
<li><p>使用样例2：通过Shell脚本调用1个Ascend AI处理器，设备ID为“0”。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Linux with Shell</span>
sh<span class="w"> </span>run_train.sh<span class="w"> </span>Ascend<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">0</span><span class="w"> </span>~/rank_table.json<span class="w"> </span>&lt;TRAIN_DATASET_PATH&gt;<span class="w"> </span>../pretrain_checkpoint/mobilenetv2_ascend_v120_imagenet2012_official_cv_bs256_acc71.ckpt<span class="w"> </span>backbone
</pre></div>
</div>
</li>
<li><p>使用样例3：通过Shell脚本调用8个Ascend AI处理器，设备ID为”0,1,2,3,4,5,6,7“。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Linux with Shell</span>
sh<span class="w"> </span>run_train.sh<span class="w"> </span>Ascend<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="m">0</span>,1,2,3,4,5,6,7<span class="w"> </span>~/rank_table.json<span class="w"> </span>&lt;TRAIN_DATASET_PATH&gt;<span class="w"> </span>../pretrain_checkpoint/mobilenetv2_ascend_v120_imagenet2012_official_cv_bs256_acc71.ckpt<span class="w"> </span>backbone
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</section>
<section id="id10">
<h3>微调训练结果<a class="headerlink" href="#id10" title="Permalink to this headline"></a></h3>
<ul>
<li><p>查看运行结果。</p>
<ul>
<li><p>运行Python文件时在交互式命令行中查看打印信息，<code class="docutils literal notranslate"><span class="pre">Linux</span></code>上运行Shell脚本运行后使用<code class="docutils literal notranslate"><span class="pre">cat</span> <span class="pre">./train/rank0/log0.log</span></code>中查看打印信息，输出结果如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>train args: Namespace(dataset_path=&#39;./dataset/train&#39;, platform=&#39;CPU&#39;, \
pretrain_ckpt=&#39;./pretrain_checkpoint/mobilenetv2_cpu_gpu.ckpt&#39;, freeze_layer=&#39;backbone&#39;)
cfg: {&#39;num_classes&#39;: 26, &#39;image_height&#39;: 224, &#39;image_width&#39;: 224, &#39;batch_size&#39;: 150, \
&#39;epoch_size&#39;: 200, &#39;warmup_epochs&#39;: 0, &#39;lr_max&#39;: 0.03, &#39;lr_end&#39;: 0.03, &#39;momentum&#39;: 0.9, \
&#39;weight_decay&#39;: 4e-05, &#39;label_smooth&#39;: 0.1, &#39;loss_scale&#39;: 1024, &#39;save_checkpoint&#39;: True, \
&#39;save_checkpoint_epochs&#39;: 1, &#39;keep_checkpoint_max&#39;: 20, &#39;save_checkpoint_path&#39;: &#39;./&#39;, \
&#39;platform&#39;: &#39;CPU&#39;}
Processing batch: 16: 100%|███████████████████████████████████████████ █████████████████████| 16/16 [00:00&lt;?, ?it/s]
epoch[200], iter[16] cost: 256.030, per step time: 256.030, avg loss: 1.775total cos 7.2574 s
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>查看保存的checkpoint文件。</p>
<ul>
<li><p>Windows上使用<code class="docutils literal notranslate"><span class="pre">dir</span> <span class="pre">checkpoint</span></code>查看保存的模型文件：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>dir ckpt_0
2020//0814 11:20        267,727 mobilenetv2_1.ckpt
2020//0814 11:21        267,727 mobilenetv2_10.ckpt
2020//0814 11:21        267,727 mobilenetv2_11.ckpt
...
2020//0814 11:21        267,727 mobilenetv2_7.ckpt
2020//0814 11:21        267,727 mobilenetv2_8.ckpt
2020//0814 11:21        267,727 mobilenetv2_9.ckpt
</pre></div>
</div>
</li>
<li><p>Linux上使用<code class="docutils literal notranslate"><span class="pre">ls</span> <span class="pre">./checkpoint</span></code>查看保存的模型文件：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ls ./ckpt_0/
mobilenetv2_1.ckpt  mobilenetv2_2.ckpt
mobilenetv2_3.ckpt  mobilenetv2_4.ckpt
...
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</section>
</section>
<section id="id11">
<h2>验证微调训练模型<a class="headerlink" href="#id11" title="Permalink to this headline"></a></h2>
<section id="id12">
<h3>验证模型<a class="headerlink" href="#id12" title="Permalink to this headline"></a></h3>
<p>使用验证集测试模型性能，需要输入必要<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/cv_mobilenetv2_fine_tune.html#id8">参数</a>，<code class="docutils literal notranslate"><span class="pre">--platform</span></code>默认为“Ascend”，可自行设置为”CPU”或”GPU”。最终在交互式命令行中展示标准输出与错误输出，或者将其写入<code class="docutils literal notranslate"><span class="pre">eval.log</span></code>文件。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Windows/Linux with Python</span>
python<span class="w"> </span>eval.py<span class="w"> </span>--config_path<span class="w"> </span>./default_config_cpu.yaml<span class="w"> </span>--platform<span class="w"> </span>CPU<span class="w"> </span>--dataset_path<span class="w"> </span>&lt;VAL_DATASET_PATH&gt;<span class="w"> </span>--pretrain_ckpt<span class="w"> </span>./ckpt_0/mobilenetv2_15.ckpt

<span class="c1"># Linux with Shell</span>
sh<span class="w"> </span>run_eval.sh<span class="w"> </span>CPU<span class="w"> </span>&lt;VAL_DATASET_PATH&gt;<span class="w"> </span>../ckpt_0/mobilenetv2_15.ckpt
</pre></div>
</div>
</section>
<section id="id13">
<h3>验证结果<a class="headerlink" href="#id13" title="Permalink to this headline"></a></h3>
<p>运行Python文件时在交互式命令行中输出验证结果，Shell脚本将把这些信息写入<code class="docutils literal notranslate"><span class="pre">./eval.log</span></code>中，需要使用<code class="docutils literal notranslate"><span class="pre">cat</span> <span class="pre">./eval.log</span></code>查看，结果如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>result:{&#39;acc&#39;: 0.9466666666666666666667}
pretrain_ckpt = ./ckpt_0/mobilenetv2_15.ckpt
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="cv_resnet50.html" class="btn btn-neutral float-left" title="使用ResNet-50网络实现图像分类" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="nlp.html" class="btn btn-neutral float-right" title="自然语言处理" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>