

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>使用Dump功能在Graph模式调试 &mdash; MindSpore master documentation</title>
  

  
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="自定义调试信息" href="custom_debugging_info.html" />
    <link rel="prev" title="如何查看IR文件" href="read_ir_files.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">整体介绍</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">MindSpore总体架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API概述</a></li>
</ul>
<p class="caption"><span class="caption-text">设计介绍</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/technical_white_paper.html">技术白皮书</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/all_scenarios_architecture.html">全场景统一架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/gradient.html">函数式可微分编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/dynamic_graph_and_static_graph.html">动态图和静态图</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/distributed_training_design.html">分布式训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/heterogeneous_training.html">异构并行训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindir.html">MindSpore IR（MindIR）</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/training_visual_design.html">可视化调试调优↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindarmour/docs/zh-CN/r1.5/design.html">安全可信↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/glossary.html">术语</a></li>
</ul>
<p class="caption"><span class="caption-text">快速入门</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/r1.5/linear_regression.html">实现简单线性函数拟合↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/r1.5/quick_start.html">实现一个图片分类应用↗</a></li>
</ul>
<p class="caption"><span class="caption-text">基本概念</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dtype.html">DataType</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter_introduction.html">Parameter</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators.html">算子</a></li>
<li class="toctree-l1"><a class="reference internal" href="cell.html">Cell</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_introduction.html">Dataset</a></li>
</ul>
<p class="caption"><span class="caption-text">数据加载和处理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataset_sample.html">快速入门数据加载和处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">数据集加载</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_advanced.html">数据处理高级用法</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_usage.html">数据迭代</a></li>
</ul>
<p class="caption"><span class="caption-text">网络构建</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="build_net.html">构建单算子网络和多层网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="initializer.html">Initializer初始化器</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter.html">网络参数</a></li>
<li class="toctree-l1"><a class="reference internal" href="control_flow.html">使用流程控制语句</a></li>
<li class="toctree-l1"><a class="reference internal" href="indefinite_parameter.html">参数传递</a></li>
<li class="toctree-l1"><a class="reference internal" href="constexpr.html">网络内构造常量</a></li>
<li class="toctree-l1"><a class="reference internal" href="loss.html">损失函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="grad_operation.html">求导</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypermap.html">运算重载</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">优化器</a></li>
<li class="toctree-l1"><a class="reference internal" href="train_and_eval.html">构建训练与评估网络</a></li>
</ul>
<p class="caption"><span class="caption-text">模型运行</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="context.html">配置运行信息</a></li>
<li class="toctree-l1"><a class="reference internal" href="run.html">运行方式</a></li>
<li class="toctree-l1"><a class="reference internal" href="ms_function.html">ms_function动静结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_and_load_models.html">模型保存与加载</a></li>
<li class="toctree-l1"><a class="reference internal" href="model.html">Model接口应用</a></li>
</ul>
<p class="caption"><span class="caption-text">推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">推理模型总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="online_inference.html">加载Checkpoint在线推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="offline_inference.html">使用离线模型推理</a></li>
</ul>
<p class="caption"><span class="caption-text">分布式并行</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">分布式并行总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_advanced.html">分布式并行高级特性</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_example.html">分布式并行使用样例</a></li>
</ul>
<p class="caption"><span class="caption-text">PyNative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">PyNative模式应用</a></li>
</ul>
<p class="caption"><span class="caption-text">Numpy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">MindSpore NumPy函数</a></li>
</ul>
<p class="caption"><span class="caption-text">高级特性</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="second_order_optimizer.html">二阶优化</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">应用感知量化训练</a></li>
</ul>
<p class="caption"><span class="caption-text">功能调试</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="read_ir_files.html">如何查看IR文件</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/debug_in_pynative_mode.html">使用PyNative模式调试↗</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">使用Dump功能在Graph模式调试</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">概述</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">调试过程</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id3">数据准备</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id4">数据分析</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id5">适用场景</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#dump">Dump功能说明</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id6">同步Dump</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id7">同步Dump操作步骤</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id8">同步Dump数据对象目录</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id9">同步Dump数据文件介绍</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id10">同步Dump数据分析样例</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id11">异步Dump</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id12">异步Dump操作步骤</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id13">异步Dump数据对象目录</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id14">异步Dump数据文件介绍</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id15">异步Dump数据分析样例</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">自定义调试信息</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">算子增量编译</a></li>
</ul>
<p class="caption"><span class="caption-text">精度调优</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/accuracy_problem_preliminary_location.html">精度问题初步定位指南↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/accuracy_optimization.html">精度问题详细定位和调优指南↗</a></li>
</ul>
<p class="caption"><span class="caption-text">性能优化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">使能混合精度</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">使能图算融合</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_tune.html">使能算子调优工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">应用梯度累积算法</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/performance_profiling.html">使用Profiler调试性能↗</a></li>
</ul>
<p class="caption"><span class="caption-text">应用实践</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">机器视觉</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">自然语言处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">高性能计算</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">在云上使用MindSpore</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>使用Dump功能在Graph模式调试</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/dump_in_graph_mode.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="dumpgraph">
<h1>使用Dump功能在Graph模式调试<a class="headerlink" href="#dumpgraph" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">模型调优</span></code></p>
<!-- TOC -->
<ul class="simple">
<li><p><a class="reference external" href="#%E4%BD%BF%E7%94%A8dump%E5%8A%9F%E8%83%BD%E5%9C%A8graph%E6%A8%A1%E5%BC%8F%E8%B0%83%E8%AF%95">使用Dump功能在Graph模式调试</a></p>
<ul>
<li><p><a class="reference external" href="#%E6%A6%82%E8%BF%B0">概述</a></p>
<ul>
<li><p><a class="reference external" href="#%E8%B0%83%E8%AF%95%E8%BF%87%E7%A8%8B">调试过程</a></p>
<ul>
<li><p><a class="reference external" href="#%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87">数据准备</a></p></li>
<li><p><a class="reference external" href="#%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90">数据分析</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF">适用场景</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#dump%E5%8A%9F%E8%83%BD%E8%AF%B4%E6%98%8E">Dump功能说明</a></p></li>
<li><p><a class="reference external" href="#%E5%90%8C%E6%AD%A5dump">同步Dump</a></p>
<ul>
<li><p><a class="reference external" href="#%E5%90%8C%E6%AD%A5dump%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4">同步Dump操作步骤</a></p></li>
<li><p><a class="reference external" href="#%E5%90%8C%E6%AD%A5dump%E6%95%B0%E6%8D%AE%E5%AF%B9%E8%B1%A1%E7%9B%AE%E5%BD%95">同步Dump数据对象目录</a></p></li>
<li><p><a class="reference external" href="#%E5%90%8C%E6%AD%A5dump%E6%95%B0%E6%8D%AE%E6%96%87%E4%BB%B6%E4%BB%8B%E7%BB%8D">同步Dump数据文件介绍</a></p></li>
<li><p><a class="reference external" href="#%E5%90%8C%E6%AD%A5dump%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A0%B7%E4%BE%8B">同步Dump数据分析样例</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#%E5%BC%82%E6%AD%A5dump">异步Dump</a></p>
<ul>
<li><p><a class="reference external" href="#%E5%BC%82%E6%AD%A5dump%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4">异步Dump操作步骤</a></p></li>
<li><p><a class="reference external" href="#%E5%BC%82%E6%AD%A5dump%E6%95%B0%E6%8D%AE%E5%AF%B9%E8%B1%A1%E7%9B%AE%E5%BD%95">异步Dump数据对象目录</a></p></li>
<li><p><a class="reference external" href="#%E5%BC%82%E6%AD%A5dump%E6%95%B0%E6%8D%AE%E6%96%87%E4%BB%B6%E4%BB%8B%E7%BB%8D">异步Dump数据文件介绍</a></p></li>
<li><p><a class="reference external" href="#%E5%BC%82%E6%AD%A5dump%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A0%B7%E4%BE%8B">异步Dump数据分析样例</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- /TOC -->
<p><a href="https://gitee.com/mindspore/docs/blob/r1.5/docs/mindspore/programming_guide/source_zh_cn/dump_in_graph_mode.md" target="_blank"><img src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source.png"></a></p>
<div class="section" id="id1">
<h2>概述<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>为了对训练过程进行分析，用户需要感知训练过程中算子的输入和输出数据。</p>
<ul class="simple">
<li><p>对于动态图模式，MindSpore提供了Python原生执行能力，用户可以在网络脚本运行过程中查看记录相应的输入输出，详情见<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/debug_in_pynative_mode.html">使用PyNative模式调试</a> 。</p></li>
<li><p>对于静态图模式，MindSpore提供了Dump功能，用来将模型训练中的图以及算子的输入输出数据保存到磁盘文件。</p></li>
</ul>
<p>本文针对静态图模式，介绍如何基于Dump功能对网络数据进行分析对比。</p>
<div class="section" id="id2">
<h3>调试过程<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>使用Dump来帮助调试分为两个步骤：1、数据准备；2、数据分析。</p>
<div class="section" id="id3">
<h4>数据准备<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h4>
<p>数据准备阶段使用同步Dump或异步Dump来生成Dump数据。使用方法详见<a class="reference external" href="#id7">同步Dump操作步骤</a>和<a class="reference external" href="#id12">异步Dump操作步骤</a>。</p>
<p>在准备数据时，您可以参考以下最佳实践：</p>
<ol class="simple">
<li><p>设置<code class="docutils literal notranslate"><span class="pre">iteration</span></code>参数，仅保存出现问题的迭代和前一个迭代这两个迭代的数据。例如，要分析的问题会在第10个迭代（从1开始数）出现，则可以这样设置：<code class="docutils literal notranslate"><span class="pre">&quot;iteration&quot;:</span> <span class="pre">&quot;8|9&quot;</span></code>。请注意<code class="docutils literal notranslate"><span class="pre">iteration</span></code>参数从0开始计算迭代数。保存上述两个迭代的数据能够支撑大多数场景的问题分析。</p></li>
<li><p>在出现问题的迭代执行完毕后，建议您通过<a class="reference external" href="https://www.mindspore.cn/docs/api/zh-CN/r1.5/api_python/mindspore.train.html#mindspore.train.callback.RunContext.request_stop">run_context.request_stop()</a>等方法提前结束训练。</p></li>
</ol>
</div>
<div class="section" id="id4">
<h4>数据分析<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h4>
<p>如果用户已经安装了MindInsight, 可以使用MindInsight的离线调试器来分析。离线调试器的使用方法详见<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/debugger_offline.html">使用离线调试器</a> 。</p>
<p>如果没有安装MindInsight，需要通过以下步骤来分析数据。</p>
<ol>
<li><p>从脚本找到对应的算子</p>
<p>使用Dump功能将自动生成最终执行图的IR文件（IR文件中包含了算子全名，和算子在计算图中输入和输出的依赖，也包含从算子到相应脚本代码的Trace信息)，IR文件可以用<code class="docutils literal notranslate"><span class="pre">vi</span></code>命令查看，Dump功能的配置见<a class="reference external" href="#id7">同步Dump操作步骤</a>和<a class="reference external" href="#id12">异步Dump操作步骤</a>，Dump输出的目录结构见<a class="reference external" href="#id8">同步Dump数据对象目录</a>和<a class="reference external" href="#id13">异步Dump数据对象目录</a>。然后通过图文件找到脚本中代码对应的算子，参考<a class="reference external" href="#id10">同步Dump数据分析样例</a>和<a class="reference external" href="#id15">异步Dump数据数据分析样例</a>。</p>
</li>
<li><p>从算子到Dump数据</p>
<p>在了解脚本和算子的映射关系后，可以确定想要分析的算子名称，从而找到算子对应的dump文件，参考<a class="reference external" href="#id8">同步Dump数据对象目录</a>和<a class="reference external" href="#id13">异步Dump数据对象目录</a>。</p>
</li>
<li><p>分析Dump数据</p>
<p>通过解析Dump数据，可以与其他第三方框架进行对比。同步Dump数据格式参考<a class="reference external" href="#id9">同步Dump数据文件介绍</a>，异步Dump数据格式参考<a class="reference external" href="#id14">异步Dump数据文件介绍</a>。</p>
</li>
</ol>
</div>
</div>
<div class="section" id="id5">
<h3>适用场景<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<ol>
<li><p>静态图算子结果分析。</p>
<p>通过Dump功能获得的IR图，可以了解脚本代码与执行算子的映射关系（详情见<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/design/mindir.html#id1">MindSpore IR简介</a>）。结合执行算子的输入和输出数据，可以分析训练过程中可能存在的溢出、梯度爆炸与消失等问题，反向跟踪到脚本中可能存在问题的代码。</p>
</li>
<li><p>特征图分析。</p>
<p>通过获取图层的输出数据，分析特征图的信息。</p>
</li>
<li><p>模型迁移。</p>
<p>在将模型从第三方框架（TensorFlow、PyTorch）迁移到MindSpore的场景中，通过比对相同位置算子的输出数据，分析第三方框架和MindSpore对于同一模型的训练结果是否足够接近，来定位模型的精度问题。</p>
</li>
</ol>
</div>
</div>
<div class="section" id="dump">
<h2>Dump功能说明<a class="headerlink" href="#dump" title="Permalink to this headline">¶</a></h2>
<p>MindSpore提供了同步Dump与异步Dump两种模式：</p>
<ul class="simple">
<li><p>同步Dump的机制是在网络训练过程中每个step执行结束后， Host侧发起Dump动作，从Device上拷贝算子地址里面的数据到Host，并保存文件。同步Dump会默认关闭算子间的内存复用，避免读到脏数据。</p></li>
<li><p>异步Dump是专门针对Ascend整图下沉而开发的功能，可以一边执行算子一边dump数据，一个算子执行结束后立即dump数据，因此开启内存复用也可以生成正确的数据，但是相应的网络训练的速度会较慢。</p></li>
</ul>
<p>不同模式所需要的配置文件和dump出来的数据格式不同：</p>
<ul class="simple">
<li><p>在Ascend上开启同步Dump的时候，待Dump的算子会自动关闭内存复用。</p></li>
<li><p>同步Dump目前支持Ascend、GPU和CPU上的图模式，暂不支持PyNative模式。</p></li>
<li><p>异步Dump仅支持Ascend上的图模式，不支持PyNative模式。开启异步Dump的时候不会关闭内存复用。</p></li>
<li><p>默认使用用异步Dump模式，如果要使用同步Dump模式，需要在配置文件中设置”e2e_dump_settings”。</p></li>
</ul>
</div>
<div class="section" id="id6">
<h2>同步Dump<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id7">
<h3>同步Dump操作步骤<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<ol>
<li><p>创建json格式的配置文件，JSON文件的名称和位置可以自定义设置。</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;common_dump_settings&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&quot;dump_mode&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;/absolute_path&quot;</span><span class="p">,</span>
        <span class="nt">&quot;net_name&quot;</span><span class="p">:</span> <span class="s2">&quot;ResNet50&quot;</span><span class="p">,</span>
        <span class="nt">&quot;iteration&quot;</span><span class="p">:</span> <span class="s2">&quot;0|5-8|100-120&quot;</span><span class="p">,</span>
        <span class="nt">&quot;input_output&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&quot;kernels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;Default/Conv-op12&quot;</span><span class="p">],</span>
        <span class="nt">&quot;support_device&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">]</span>
    <span class="p">},</span>
    <span class="nt">&quot;e2e_dump_settings&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&quot;enable&quot;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&quot;trans_flag&quot;</span><span class="p">:</span> <span class="kc">true</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dump_mode</span></code>：设置成0，表示Dump出该网络中的所有算子数据；设置成1，表示Dump<code class="docutils literal notranslate"><span class="pre">&quot;kernels&quot;</span></code>里面指定的算子数据。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>：Dump保存数据的绝对路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>：自定义的网络名称，例如：”ResNet50”。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iteration</span></code>：指定需要Dump数据的迭代。类型为str，用“|”分离要保存的不同区间的step的数据。如”0|5-8|100-120”表示Dump第1个，第6个到第9个， 第101个到第121个step的数据。指定“all”，表示Dump所有迭代的数据。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output</span></code>：设置成0，表示Dump出算子的输入和算子的输出；设置成1，表示Dump出算子的输入；设置成2，表示Dump出算子的输出。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kernels</span></code>：算子的名称列表。开启IR保存开关<code class="docutils literal notranslate"><span class="pre">context.set_context(save_graphs=True)</span></code>并执行用例，从生成的IR文件<code class="docutils literal notranslate"><span class="pre">trace_code_graph_{graph_id}</span></code>中获取算子名称。详细说明可以参照教程：<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/read_ir_files.html#id2">如何保存IR</a>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">support_device</span></code>：支持的设备，默认设置成0到7即可；在分布式训练场景下，需要dump个别设备上的数据，可以只在<code class="docutils literal notranslate"><span class="pre">support_device</span></code>中指定需要Dump的设备Id。该配置参数在CPU上无效，因为CPU下没有device这个概念，但是在json格式的配置文件中仍需保留该字段。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">enable</span></code>：开启E2E Dump。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trans_flag</span></code>：开启格式转换。将设备上的数据格式转换成NCHW格式。若为<code class="docutils literal notranslate"><span class="pre">True</span></code>，则数据会以Host侧的4D格式（NCHW）格式保存；若为<code class="docutils literal notranslate"><span class="pre">False</span></code>，则保留Device侧的数据格式。该配置参数在CPU上无效，因为CPU上没有format转换，但是在json格式的配置文件中仍需保留该字段。</p></li>
</ul>
</li>
<li><p>设置Dump环境变量。</p>
<p>指定Dump的json配置文件。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">MINDSPORE_DUMP_CONFIG</span><span class="o">=</span><span class="si">${</span><span class="nv">xxx</span><span class="si">}</span>
</pre></div>
</div>
<p>其中”xxx”为配置文件的绝对路径，如：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">MINDSPORE_DUMP_CONFIG</span><span class="o">=</span>/path/to/data_dump.json
</pre></div>
</div>
<p>如果Dump配置文件没有设置<code class="docutils literal notranslate"><span class="pre">path</span></code>字段或者设置为空字符串，还需要配置环境变量<code class="docutils literal notranslate"><span class="pre">MS_DIAGNOSTIC_DATA_PATH</span></code>。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">MS_DIAGNOSTIC_DATA_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">yyy</span><span class="si">}</span>
</pre></div>
</div>
<p>则”$MS_DIAGNOSTIC_DATA_PATH/debug_dump”就会被当做<code class="docutils literal notranslate"><span class="pre">path</span></code>的值。若Dump配置文件中设置了<code class="docutils literal notranslate"><span class="pre">path</span></code>字段，则仍以该字段的实际取值为准。</p>
<p>注意：</p>
<ul class="simple">
<li><p>在网络脚本执行前，设置好环境变量；网络脚本执行过程中设置将会不生效。</p></li>
<li><p>在分布式场景下，Dump环境变量需要在调用<code class="docutils literal notranslate"><span class="pre">mindspore.communication.init</span></code>之前配置。</p></li>
</ul>
</li>
<li><p>启动网络训练脚本。</p>
<p>训练启动后，若正确配置了<code class="docutils literal notranslate"><span class="pre">MINDSPORE_DUMP_CONFIG</span></code>环境变量，则会读取配置文件的内容，并按照Dump配置中指定的数据保存路径保存算子数据。
同步模式下，GPU环境如果要Dump数据，必须采用非数据下沉模式（设置<code class="docutils literal notranslate"><span class="pre">model.train</span></code>或<code class="docutils literal notranslate"><span class="pre">DatasetHelper</span></code>中的<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code>参数为<code class="docutils literal notranslate"><span class="pre">False</span></code>），以保证可以获取每个step的Dump数据。
若脚本中都不调用<code class="docutils literal notranslate"><span class="pre">model.train</span></code>或<code class="docutils literal notranslate"><span class="pre">DatasetHelper</span></code>，则默认为非数据下沉模式。使用Dump功能将自动生成最终执行图的IR文件。</p>
<p>可以在训练脚本中设置<code class="docutils literal notranslate"><span class="pre">context.set_context(reserve_class_name_in_scope=False)</span></code>，避免Dump文件名称过长导致Dump数据文件生成失败。</p>
</li>
<li><p>通过<code class="docutils literal notranslate"><span class="pre">numpy.load</span></code>读取和解析同步Dump数据，参考<a class="reference external" href="#id9">同步Dump数据文件介绍</a>。</p></li>
</ol>
</div>
<div class="section" id="id8">
<h3>同步Dump数据对象目录<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>启动训练后，同步Dump保存的数据对象包括最终执行图（<code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code>文件）以及图中算子的输入和输出数据，数据目录结构如下所示：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{path}/
    - rank_{rank_id}/
        - .dump_metadata/
        - {net_name}/
            - {graph_id}/
                - {iteration_id}/
                    {op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}.{input_output_index}.{slot}.{format}.npy
            ...
        - graphs/
            ms_output_trace_code_graph_{graph_id}.pb
            ms_output_trace_code_graph_{graph_id}.ir
        - execution_order/
            ms_execution_order_graph_{graph_id}.csv
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>：<code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code>配置文件中设置的绝对路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rank_id</span></code>： 逻辑卡号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>：<code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code>配置文件中设置的网络名称。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">graph_id</span></code>：训练的图标号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iteration_id</span></code>：训练的轮次。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_type</span></code>：算子类型。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_name</span></code>：算子名称。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">task_id</span></code>：任务标号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">stream_id</span></code>：流标号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">timestamp</span></code>：时间戳。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output_index</span></code>：输入或输出标号，例如<code class="docutils literal notranslate"><span class="pre">output.0</span></code>表示该文件是该算子的第1个输出Tensor的数据。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">slot</span></code>：slot标号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">format</span></code>: 数据格式。</p></li>
</ul>
<p>对于多图网络，由于存在控制流，某些子图可能不会被执行，Dump只保存执行过的节点，所以graphs目录下<code class="docutils literal notranslate"><span class="pre">.pb</span></code>文件名中的{graph_id}并不一定在{net_name}下存在对应的{graph_id}目录。</p>
</div>
<div class="section" id="id9">
<h3>同步Dump数据文件介绍<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>同步Dump生成的数据文件是后缀名为<code class="docutils literal notranslate"><span class="pre">.npy</span></code>的文件，文件命名格式为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}.{input_output_index}.{slot}.{format}.npy
</pre></div>
</div>
<p>可以用Numpy的<code class="docutils literal notranslate"><span class="pre">numpy.load</span></code>接口读取数据。</p>
<p>同步Dump生成的最终执行图文件后缀名分别为<code class="docutils literal notranslate"><span class="pre">.pb</span></code>和<code class="docutils literal notranslate"><span class="pre">.ir</span></code>，文件命名格式为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ms_output_trace_code_graph_{graph_id}.pb
ms_output_trace_code_graph_{graph_id}.ir
</pre></div>
</div>
<p>其中以<code class="docutils literal notranslate"><span class="pre">.ir</span></code>为后缀的文件可以通过<code class="docutils literal notranslate"><span class="pre">vi</span></code>命令打开查看。</p>
<p>同步Dump生成的节点执行序文件后缀名为<code class="docutils literal notranslate"><span class="pre">.csv</span></code>，文件命名格式为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ms_execution_order_graph_{graph_id}.csv
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">.dump_metadata</span></code>记录了训练的原信息，其中<code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code>保存了用户设置的dump配置。</p>
</div>
<div class="section" id="id10">
<h3>同步Dump数据分析样例<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>对于Ascend场景，在通过Dump功能将脚本对应的图保存到磁盘上后，会产生最终执行图文件<code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code>。该文件中保存了对应的图中每个算子的堆栈信息，记录了算子对应的生成脚本。</p>
<p>以<a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.5/official/cv/alexnet/src/alexnet.py">AlexNet脚本</a>为例 ：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>


<span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                     <span class="n">has_bias</span><span class="o">=</span><span class="n">has_bias</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="n">pad_mode</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">fc_with_initialize</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="n">has_bias</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">AlexNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Alexnet</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">phase</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AlexNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">192</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv5</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">include_top</span> <span class="o">=</span> <span class="n">include_top</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">include_top</span><span class="p">:</span>
            <span class="n">dropout_ratio</span> <span class="o">=</span> <span class="mf">0.65</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;test&#39;</span><span class="p">:</span>
                <span class="n">dropout_ratio</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="mi">6</span> <span class="o">*</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_ratio</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;define network&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv5</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">include_top</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<p>如果用户想查看脚本中第58行的代码：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>执行完训练网络后，可以从最终执行图（<code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code>文件）中查找到该行代码所对应的多个算子信息，文件内容如下所示：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  %24(equivoutput) = Conv2D(%23, %21) {instance name: conv2d} primitive_attrs: {compile_info: , pri_format: NC1HWC0, stride: (1, 1, 1, 1), pad: (0, 0, 0, 0), pad_mod: same, out_channel:
192, mode: 1, dilation: (1, 1, 1, 1), output_names: [output], group: 1, format: NCHW, offset_a: 0, kernel_size: (3, 3), groups: 1, input_names: [x, w], pad_list: (1, 1, 1, 1),
IsFeatureMapOutput: true, IsFeatureMapInputList: (0)}
       : (&lt;Tensor[Float32]x[const vector][32, 128, 13, 13]&gt;, &lt;Tensor[Float16]x[const vector][192, 128, 3, 3]&gt;) -&gt; (&lt;Tensor[Float16]x[const vector][32, 192, 13, 13]&gt;)
       : (&lt;Float16xNC1HWC0[const vector][32, 8, 13, 13, 16]&gt;, &lt;Float16xFracZ[const vector][72, 12, 16, 16]&gt;) -&gt; (&lt;Float16xNC1HWC0[const vector][32, 12, 13, 13, 16]&gt;)
       : (Default/network-WithLossCell/_backbone-AlexNet/conv3-Conv2d/Conv2D-op107)
       ...
       # In file {Absolute path of model_zoo}/official/cv/alexnet/src/alexnet.py(58)/        x = self.conv3(x)/
       ...
  %25(equivoutput) = BiasAdd(%24, %22) {instance name: bias_add} primitive_attrs: {output_used_num: (1), input_names: [x, b], format: NCHW, compile_info: , output_names: [output],
IsFeatureMapOutput: true, IsFeatureMapInputList: (0), pri_format: NC1HWC0}
       : (&lt;Tensor[Float16]x[const vector][32, 192, 13, 13]&gt;) -&gt; (&lt;Tensor[Float16]x[const vector][192]&gt;) -&gt; (&lt;Tensor[Float16]x[const vector][32, 192, 13, 13]&gt;)
       : (&lt;Float16xNC1HWC0[const vector][32, 12, 13, 13, 16]&gt;) -&gt; (&lt;Float16xDefaultFormat[const vector][192]&gt;) -&gt; (&lt;Float16xNC1HWC0[const vector][32, 12, 13, 13, 16]&gt;)
       : (Default/network-WithLossCell/_backbone-AlexNet/conv3-Conv2d/BiasAdd-op105)
       ...
       # In file {Absolute path of model_zoo}/official/cv/alexnet/src/alexnet.py(58)/        x = self.conv3(x)/
       ...
</pre></div>
</div>
<p>以上所示文件内容的各行所表示的含义如下：</p>
<ul>
<li><p>算子在Host侧（第一行）和Device侧（第二行，有些算子可能不存在）的输入输出情况。从执行图可知，该算子有两个输入（箭头左侧），一个输出（箭头右侧）。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>: (&lt;Tensor[Float32]x[const vector][32, 128, 13, 13]&gt;, &lt;Tensor[Float16]x[const vector][192, 128, 3, 3]&gt;) -&gt; (&lt;Tensor[Float16]x[const vector][32, 192, 13, 13]&gt;)
: (&lt;Float16xNC1HWC0[const vector][32, 8, 13, 13, 16]&gt;, &lt;Float16xFracZ[const vector][72, 12, 16, 16]&gt;) -&gt; (&lt;Float16xNC1HWC0[const vector][32, 12, 13, 13, 16]&gt;)
</pre></div>
</div>
</li>
<li><p>算子名称。从执行图可知，该算子在最终执行图中的完整名称为<code class="docutils literal notranslate"><span class="pre">Default/network-WithLossCell/_backbone-AlexNet/conv3-Conv2d/Conv2D-op107</span></code>。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>: (Default/network-WithLossCell/_backbone-AlexNet/conv3-Conv2d/Conv2D-op107)
</pre></div>
</div>
</li>
<li><p>算子对应的训练脚本代码。通过搜索要查询的训练脚本代码，可以找到多个匹配的算子。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># In file {Absolute path of model_zoo}/official/cv/alexnet/src/alexnet.py(58)/        x = self.conv3(x)/
</pre></div>
</div>
</li>
</ul>
<p>通过算子名称和输入输出信息，可以查找到唯一对应的Tensor数据文件。比如，若要查看Conv2D-op107算子的第1个输出数据对应的Dump文件，可获取以下信息：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">operator_name</span></code>：<code class="docutils literal notranslate"><span class="pre">Conv2D-op107</span></code>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output_index</span></code>：<code class="docutils literal notranslate"><span class="pre">output.0</span></code>表示该文件是该算子的第1个输出Tensor的数据。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">slot</span></code>：0，该算子的输出只有一个slot。</p></li>
</ul>
<p>在Dump保存的数据对象文件目录下搜索到相应的文件名：
<code class="docutils literal notranslate"><span class="pre">Conv2D.Conv2D-op107.2.2.1623124369613540.output.0.DefaultFormat.npy</span></code>。</p>
<p>还原数据的时候，通过执行：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;Conv2D.Conv2D-op107.2.2.1623124369613540.output.0.DefaultFormat.npy&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>生成numpy.array数据。</p>
</div>
</div>
<div class="section" id="id11">
<h2>异步Dump<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h2>
<p>大型网络（如Bert Large）使用同步Dump时会导致内存溢出，MindSpore通过异步Dump提供了大型网络的调试能力。</p>
<div class="section" id="id12">
<h3>异步Dump操作步骤<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<ol>
<li><p>创建配置文件<code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code>。</p>
<p>JSON文件的名称和位置可以自定义设置。</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;common_dump_settings&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&quot;dump_mode&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&quot;path&quot;</span><span class="p">:</span> <span class="s2">&quot;/absolute_path&quot;</span><span class="p">,</span>
        <span class="nt">&quot;net_name&quot;</span><span class="p">:</span> <span class="s2">&quot;ResNet50&quot;</span><span class="p">,</span>
        <span class="nt">&quot;iteration&quot;</span><span class="p">:</span> <span class="s2">&quot;0|5-8|100-120&quot;</span><span class="p">,</span>
        <span class="nt">&quot;input_output&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="nt">&quot;kernels&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;Default/Conv-op12&quot;</span><span class="p">],</span>
        <span class="nt">&quot;support_device&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">],</span>
        <span class="nt">&quot;op_debug_mode&quot;</span><span class="p">:</span> <span class="mi">0</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dump_mode</span></code>：设置成0，表示Dump出该网络中的所有算子数据；设置成1，表示Dump<code class="docutils literal notranslate"><span class="pre">&quot;kernels&quot;</span></code>里面指定的算子数据。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>：Dump保存数据的绝对路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>：自定义的网络名称，例如：”ResNet50”。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iteration</span></code>：指定需要Dump的迭代。类型为str，用“|”分离要保存的不同区间的step的数据。如”0|5-8|100-120”表示Dump第1个，第6个到第9个， 第101个到第121个step的数据。指定“all”，表示Dump所有迭代的数据。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_output</span></code>：设置成0，表示Dump出算子的输入和算子的输出；设置成1，表示Dump出算子的输入；设置成2，表示Dump出算子的输出。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kernels</span></code>：算子的名称列表。开启IR保存开关<code class="docutils literal notranslate"><span class="pre">context.set_context(save_graphs=True)</span></code>并执行用例，从生成的<code class="docutils literal notranslate"><span class="pre">trace_code_graph_{graph_id}</span></code>IR文件中获取算子名称。<code class="docutils literal notranslate"><span class="pre">kernels</span></code>仅支持TBE算子、AiCPU算子、通信算子，若设置成通信算子的名称，将会Dump出通信算子的输入算子的数据。详细说明可以参照教程：<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/read_ir_files.html#id2">如何保存IR</a>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">support_device</span></code>：支持的设备，默认设置成0到7即可；在分布式训练场景下，需要dump个别设备上的数据，可以只在<code class="docutils literal notranslate"><span class="pre">support_device</span></code>中指定需要Dump的设备Id。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_debug_mode</span></code>：预留字段，设置为0。</p></li>
</ul>
</li>
<li><p>设置数据Dump的环境变量。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">MINDSPORE_DUMP_CONFIG</span><span class="o">={</span>Absolute path of data_dump.json<span class="o">}</span>
</pre></div>
</div>
<p>如果Dump配置文件没有设置<code class="docutils literal notranslate"><span class="pre">path</span></code>字段或者设置为空字符串，还需要配置环境变量<code class="docutils literal notranslate"><span class="pre">MS_DIAGNOSTIC_DATA_PATH</span></code>。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">MS_DIAGNOSTIC_DATA_PATH</span><span class="o">=</span><span class="si">${</span><span class="nv">yyy</span><span class="si">}</span>
</pre></div>
</div>
<p>则”$MS_DIAGNOSTIC_DATA_PATH/debug_dump”就会被当做’path’的值。若Dump配置文件中设置了’path’字段，则仍以该字段的实际取值为准。</p>
<ul class="simple">
<li><p>在网络脚本执行前，设置好环境变量；网络脚本执行过程中设置将会不生效。</p></li>
<li><p>在分布式场景下，Dump环境变量需要在调用<code class="docutils literal notranslate"><span class="pre">mindspore.communication.init</span></code>之前配置。</p></li>
</ul>
</li>
<li><p>执行用例Dump数据。</p>
<p>可以在训练脚本中设置<code class="docutils literal notranslate"><span class="pre">context.set_context(reserve_class_name_in_scope=False)</span></code>，避免Dump文件名称过长导致Dump数据文件生成失败。</p>
</li>
<li><p>参考<a class="reference external" href="#id15">异步Dump数据分析样例</a>解析Dump数据文件。</p></li>
</ol>
<p>注意：</p>
<ul class="simple">
<li><p>若需要dump全量或部分算子，则可以修改json配置文件中的<code class="docutils literal notranslate"><span class="pre">dump_mode</span></code>选项为0或1。</p></li>
<li><p>使用Dump功能将自动生成最终执行图的IR文件。</p></li>
</ul>
</div>
<div class="section" id="id13">
<h3>异步Dump数据对象目录<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<p>异步Dump保存的数据对象包括了最终执行图（<code class="docutils literal notranslate"><span class="pre">ms_output_trace_code_graph_{graph_id}.ir</span></code>文件）以及图中算子的输入和输出数据，目录结构如下所示：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{path}/
    - rank_{rank_id}/
        - .dump_metadata/
        - {net_name}/
            - {graph_id}/
                - {iteration_id}/
                    {op_type}.{op_name}.{task_id}.{stream_id}.{timestamp}
            ...
        - graphs/
            ms_output_trace_code_graph_{graph_id}.pb
            ms_output_trace_code_graph_{graph_id}.ir
        - execution_order/
            ms_execution_order_graph_{graph_id}.csv
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">path</span></code>：<code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code>配置文件中设置的绝对路径。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rank_id</span></code>： 逻辑卡号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">net_name</span></code>：<code class="docutils literal notranslate"><span class="pre">data_dump.json</span></code>配置文件中设置的网络名称。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">graph_id</span></code>：训练的图标号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iteration_id</span></code>：训练的轮次。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_type</span></code>：算子类型。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">op_name</span></code>：算子名称。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">task_id</span></code>：任务标号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">stream_id</span></code>：流标号。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">timestamp</span></code>：时间戳。</p></li>
</ul>
<p>由于存在控制流，某些子图可能不会被执行，Dump只保存执行过的节点，所以graphs目录下<code class="docutils literal notranslate"><span class="pre">.pb</span></code>文件名中的{graph_id}并不一定在{net_name}下存在对应的{graph_id}目录。</p>
<p>对于多图网络，例如动态shape的场景，每张图的轮次独立计数。</p>
</div>
<div class="section" id="id14">
<h3>异步Dump数据文件介绍<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<p>启动训练后，异步Dump生成的原始数据文件是protobuf格式的文件，需要用到海思Run包中自带的数据解析工具进行解析，详见<a class="reference external" href="https://support.huawei.com/enterprise/zh/doc/EDOC1100206690/640e796d">如何查看dump数据文件</a> 。</p>
<p>数据在Device侧的格式可能和Host侧计算图中的定义不同，异步Dump的数据格式为Device侧格式，如果想要转为Host侧格式，可以参考<a class="reference external" href="https://support.huawei.com/enterprise/zh/doc/EDOC1100206690/130949fb">如何进行dump数据文件Format转换</a> 。</p>
<p>异步Dump生成的数据文件命名规则如下：</p>
<ul class="simple">
<li><p>Dump路径的命名规则为：<code class="docutils literal notranslate"><span class="pre">{path}/{device_id}/{net_name}_graph_{graph_id}/{graph_id}/{iteration}</span></code>。</p></li>
<li><p>Dump文件的命名规则为：<code class="docutils literal notranslate"><span class="pre">{op_type}.{op_name}.{task_id}.{timestamp}</span></code>。</p></li>
</ul>
<p>以一个简单网络的Dump结果为例：<code class="docutils literal notranslate"><span class="pre">Add.Default_Add-op1.2.161243956333802</span></code>，其中<code class="docutils literal notranslate"><span class="pre">Add</span></code>是<code class="docutils literal notranslate"><span class="pre">{op_type}</span></code>，<code class="docutils literal notranslate"><span class="pre">Default_Add-op1</span></code>是<code class="docutils literal notranslate"><span class="pre">{op_name}</span></code>，<code class="docutils literal notranslate"><span class="pre">2</span></code>是<code class="docutils literal notranslate"><span class="pre">{task_id}</span></code>，<code class="docutils literal notranslate"><span class="pre">161243956333802</span></code>是<code class="docutils literal notranslate"><span class="pre">{timestamp}</span></code>。</p>
<p>如果<code class="docutils literal notranslate"><span class="pre">op_type</span></code>和<code class="docutils literal notranslate"><span class="pre">op_name</span></code>中出现了“.”、“/”、“\”、空格时，会转换为下划线表示。</p>
<p>Dump生成的原始数据文件也可以使用MindInsight的数据解析工具DumpParser解析，DumpParser的使用方式详见<a class="reference external" href="https://gitee.com/mindspore/mindinsight/tree/r1.5/mindinsight/parser">DumpParser介绍</a> 。MindInsight解析出来的数据格式与同步dump的数据格式完全相同。</p>
<p>异步Dump生成的最终执行图文件和节点执行序文件命名规则与同步Dump相同，可以参考<a class="reference external" href="#id9">同步Dump数据文件介绍</a>。</p>
</div>
<div class="section" id="id15">
<h3>异步Dump数据分析样例<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<p>通过异步Dump的功能，获取到算子异步Dump生成的数据文件。</p>
<ol>
<li><p>使用run包中提供的<code class="docutils literal notranslate"><span class="pre">msaccucmp.py</span></code>解析Dump出来的文件。不同的环境上<code class="docutils literal notranslate"><span class="pre">msaccucmp.py</span></code>文件所在的路径可能不同，可以通过<code class="docutils literal notranslate"><span class="pre">find</span></code>命令进行查找：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>find <span class="si">${</span><span class="nv">run_path</span><span class="si">}</span> -name <span class="s2">&quot;msaccucmp.py&quot;</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">run_path</span></code>：run包的安装路径。</p></li>
</ul>
</li>
<li><p>找到<code class="docutils literal notranslate"><span class="pre">msaccucmp.py</span></code>后，到<code class="docutils literal notranslate"><span class="pre">/absolute_path</span></code>目录下，运行如下命令解析Dump数据：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python <span class="si">${</span><span class="nv">The</span><span class="p"> absolute path of msaccucmp.py</span><span class="si">}</span> convert -d <span class="o">{</span>file path of dump<span class="o">}</span> -out <span class="o">{</span>file path of output<span class="o">}</span>
</pre></div>
</div>
<p>若需要转换数据格式，可参考使用说明链接<a class="reference external" href="https://support.huawei.com/enterprise/zh/doc/EDOC1100206690/130949fb">https://support.huawei.com/enterprise/zh/doc/EDOC1100206690/130949fb</a> 。</p>
<p>如Dump生成的数据文件为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491
</pre></div>
</div>
<p>则执行：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3.7.5 msaccucmp.py convert -d BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491 -out ./output -f NCHW -t npy
</pre></div>
</div>
<p>则可以在<code class="docutils literal notranslate"><span class="pre">./output</span></code>下生成该算子的所有输入输出数据。每个数据以<code class="docutils literal notranslate"><span class="pre">.npy</span></code>后缀的文件保存，数据格式为<code class="docutils literal notranslate"><span class="pre">NCHW</span></code>。生成结果如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>BNTrainingUpdate.   Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell _1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.0.30x1024x17x17.npy
BNTrainingUpdate.   Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell _1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.1.1x1024x1x1.npy
BNTrainingUpdate.   Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell _1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.2.1x1024x1x1.npy
BNTrainingUpdate.   Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell _1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.3.1x1024x1x1.npy
BNTrainingUpdate.   Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell _1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.4.1x1024x1x1.npy
BNTrainingUpdate.   Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell _1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.5.1x1024x1x1.npy
BNTrainingUpdate.   Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell _1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.6.1x1024x1x1.npy
BNTrainingUpdate.   Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell _1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.output.0.30x1024x17x17.npy
BNTrainingUpdate.   Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell _1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.output.1.1x1024x1x1.npy
BNTrainingUpdate.   Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell _1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.output.2.1x1024x1x1.npy
BNTrainingUpdate.   Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell _1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.output.3.1x1024x1x1.npy
BNTrainingUpdate.   Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell _1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.output.4.1x1024x1x1.npy
</pre></div>
</div>
<p>在文件名的末尾可以看到该文件是算子的第几个输入或输出，以及数据的维度信息。例如，通过第一个<code class="docutils literal notranslate"><span class="pre">.npy</span></code>文件名</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>BNTrainingUpdate.   Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell _1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.0.30x1024x17x17.npy
</pre></div>
</div>
<p>可知该文件是算子的第0个输入，数据的维度信息是<code class="docutils literal notranslate"><span class="pre">30x1024x17x17</span></code>。</p>
</li>
<li><p>通过<code class="docutils literal notranslate"><span class="pre">numpy.load(&quot;file_name&quot;)</span></code>可以读取到对应数据。例：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;BNTrainingUpdate.Default_network-YoloWithLossCell_yolo_network-YOLOV3DarkNet53_feature_map-YOLOv3_backblock0-YoloBlock_conv3-SequentialCell_1-BatchNorm2d_BNTrainingUpdate-op5489.137.1608983934774491.input.0.30x1024x17x17.npy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="custom_debugging_info.html" class="btn btn-neutral float-right" title="自定义调试信息" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="read_ir_files.html" class="btn btn-neutral float-left" title="如何查看IR文件" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>