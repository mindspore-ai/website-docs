<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>如何查看IR文件 &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="使用Dump功能在Graph模式调试" href="dump_in_graph_mode.html" />
    <link rel="prev" title="应用感知量化训练" href="apply_quantization_aware_training.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">整体介绍</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">MindSpore总体架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_structure.html">MindSpore API概述</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">设计介绍</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/technical_white_paper.html">技术白皮书</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/all_scenarios_architecture.html">全场景统一架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/gradient.html">函数式可微分编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/dynamic_graph_and_static_graph.html">动态图和静态图</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/distributed_training_design.html">分布式训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/heterogeneous_training.html">异构并行训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/mindir.html">MindSpore IR（MindIR）</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/training_visual_design.html">可视化调试调优↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindarmour/docs/zh-CN/r1.5/design.html">安全可信↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="design/glossary.html">术语</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">快速入门</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/r1.5/linear_regression.html">实现简单线性函数拟合↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/r1.5/quick_start.html">实现一个图片分类应用↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">基本概念</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dtype.html">DataType</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter_introduction.html">Parameter</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators.html">算子</a></li>
<li class="toctree-l1"><a class="reference internal" href="cell.html">Cell</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_introduction.html">Dataset</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">数据加载和处理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataset_sample.html">快速入门数据加载和处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">数据集加载</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_advanced.html">数据处理高级用法</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_usage.html">数据迭代</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">网络构建</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="build_net.html">构建单算子网络和多层网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="initializer.html">Initializer初始化器</a></li>
<li class="toctree-l1"><a class="reference internal" href="parameter.html">网络参数</a></li>
<li class="toctree-l1"><a class="reference internal" href="control_flow.html">使用流程控制语句</a></li>
<li class="toctree-l1"><a class="reference internal" href="indefinite_parameter.html">参数传递</a></li>
<li class="toctree-l1"><a class="reference internal" href="constexpr.html">网络内构造常量</a></li>
<li class="toctree-l1"><a class="reference internal" href="loss.html">损失函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="grad_operation.html">求导</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypermap.html">运算重载</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">优化器</a></li>
<li class="toctree-l1"><a class="reference internal" href="train_and_eval.html">构建训练与评估网络</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型运行</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="context.html">配置运行信息</a></li>
<li class="toctree-l1"><a class="reference internal" href="run.html">运行方式</a></li>
<li class="toctree-l1"><a class="reference internal" href="ms_function.html">ms_function动静结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="save_and_load_models.html">模型保存与加载</a></li>
<li class="toctree-l1"><a class="reference internal" href="model.html">Model接口应用</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">推理</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="multi_platform_inference.html">推理模型总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="online_inference.html">加载Checkpoint在线推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="offline_inference.html">使用离线模型推理</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">分布式并行</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="distributed_training.html">分布式并行总览</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_advanced.html">分布式并行高级特性</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_example.html">分布式并行使用样例</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyNative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debug_in_pynative_mode.html">PyNative模式应用</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Numpy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">MindSpore NumPy函数</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">高级特性</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="second_order_optimizer.html">二阶优化</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_quantization_aware_training.html">应用感知量化训练</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">功能调试</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">如何查看IR文件</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">如何保存IR</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">IR文件解读</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id4">ir文件介绍</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dat">dat文件介绍</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#analyze-fail-dat">如何根据analyze_fail.dat文件分析图推导失败的原因</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/debug_in_pynative_mode.html">使用PyNative模式调试↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_in_graph_mode.html">使用Dump功能在Graph模式调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_debugging_info.html">自定义调试信息</a></li>
<li class="toctree-l1"><a class="reference internal" href="incremental_operator_build.html">算子增量编译</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">精度调优</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/accuracy_problem_preliminary_location.html">精度问题初步定位指南↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/accuracy_optimization.html">精度问题详细定位和调优指南↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">性能优化</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enable_mixed_precision.html">使能混合精度</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_graph_kernel_fusion.html">使能图算融合</a></li>
<li class="toctree-l1"><a class="reference internal" href="enable_auto_tune.html">使能算子调优工具</a></li>
<li class="toctree-l1"><a class="reference internal" href="apply_gradient_accumulation.html">应用梯度累积算法</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/performance_profiling.html">使用Profiler调试性能↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">应用实践</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cv.html">机器视觉</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">自然语言处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="hpc.html">高性能计算</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_on_the_cloud.html">在云上使用MindSpore</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>如何查看IR文件</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/read_ir_files.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="ir">
<h1>如何查看IR文件<a class="headerlink" href="#ir" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">模型调试</span></code></p>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.5/docs/mindspore/programming_guide/source_zh_cn/read_ir_files.md"><img alt="查看源文件" src="https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source.png" /></a></p>
<section id="id1">
<h2>概述<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h2>
<p>在图模式<code class="docutils literal notranslate"><span class="pre">context.set_context(mode=context.GRAPH_MODE)</span></code>下运行用MindSpore编写的模型时，若配置中设置了<code class="docutils literal notranslate"><span class="pre">context.set_context(save_graphs=True)</span></code>，运行时会输出一些图编译过程中生成的一些中间文件，我们称为IR文件。当前主要有三种格式的IR文件：</p>
<ul class="simple">
<li><p>ir后缀结尾的IR文件：一种比较直观易懂的以文本格式描述模型结构的文件，可以直接用文本编辑软件查看。</p></li>
<li><p>dat后缀结尾的IR文件：一种相对于ir后缀结尾的文件格式定义更为严谨的描述模型结构的文件，包含的内容更为丰富，可以直接用文本编辑软件查看。</p></li>
<li><p>dot后缀结尾的IR文件：描述了不同节点间的拓扑关系，可以用<a class="reference external" href="http://graphviz.org">graphviz</a>将此文件作为输入生成图片，方便用户直观地查看模型结构。对于算子比较多的模型，推荐使用可视化组件<a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.5/dashboard.html#id5">MindInsight</a>对计算图进行可视化。</p></li>
</ul>
</section>
<section id="id2">
<h2>如何保存IR<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h2>
<p>通过<code class="docutils literal notranslate"><span class="pre">context.set_context(save_graphs=True)</span></code>来保存各个编译阶段的中间代码。被保存的中间代码有三种格式，一个是后缀名为<code class="docutils literal notranslate"><span class="pre">.ir</span></code>的文本格式，一个是后缀名为<code class="docutils literal notranslate"><span class="pre">.dat</span></code>的文本格式，一个是后缀名为<code class="docutils literal notranslate"><span class="pre">.dot</span></code>的图形化格式。当网络规模不大时，建议使用更直观的图形化格式来查看，当网络规模较大时建议使用更高效的文本格式来查看。</p>
<p>.dot文件可以通过graphviz转换为图片格式来查看，例如将dot转换为png的命令是<code class="docutils literal notranslate"><span class="pre">dot</span> <span class="pre">-Tpng</span> <span class="pre">*.dot</span> <span class="pre">-o</span> <span class="pre">*.png</span></code>。</p>
<p>在训练脚本<code class="docutils literal notranslate"><span class="pre">train.py</span></code>中，我们在<code class="docutils literal notranslate"><span class="pre">set_context</span></code>函数中添加如下代码，运行训练脚本时，MindSpore会自动将编译过程中产生的IR文件存放到指定路径。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">save_graphs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_graphs_path</span><span class="o">=</span><span class="s2">&quot;path/to/ir/files&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>执行训练命令后，在指定的路径下生成如下文件。其中以数字下划线开头的IR文件是在ME编译图过程中输出的，<code class="docutils literal notranslate"><span class="pre">pipeline</span></code>各阶段分别会保存一次计算图。下面介绍图编译过程中比较重要的阶段，例如<code class="docutils literal notranslate"><span class="pre">parse</span></code>阶段会解析入口的<code class="docutils literal notranslate"><span class="pre">construct</span></code>函数；<code class="docutils literal notranslate"><span class="pre">symbol_resolve</span></code>阶段会递归解析入口函数直接或间接引用到的其他函数和对象；<code class="docutils literal notranslate"><span class="pre">abstract_specialize</span></code>即<code class="docutils literal notranslate"><span class="pre">graph</span> <span class="pre">evaluate</span></code>阶段，会根据输入信息从而推导出所有节点的<code class="docutils literal notranslate"><span class="pre">data</span> <span class="pre">type</span></code>和<code class="docutils literal notranslate"><span class="pre">shape</span></code>信息；<code class="docutils literal notranslate"><span class="pre">optimize</span></code>阶段主要是进行和硬件无关的优化，，自动微分与自动并行功能也是在该阶段展开；<code class="docutils literal notranslate"><span class="pre">validate</span></code>阶段会校验编译出来的计算图；<code class="docutils literal notranslate"><span class="pre">task_emit</span></code>阶段将计算图传给后端进一步处理；<code class="docutils literal notranslate"><span class="pre">execute</span></code>阶段会执行该计算图。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>.
├──00_parse_0000.dot
├──00_parse_0001.ir
├──00_parse_0002.dat
├──01_symbol_resolve_0003.dot
├──01_symbol_resolve_0004.ir
├──01_symbol_resolve_0005.dat
├──02_combine_like_graphs_0006.dot
├──02_combine_like_graphs_0007.ir
├──02_combine_like_graphs_0008.dat
├──03_inference_opt_prepare_0009.dot
├──03_inference_opt_prepare_0010.ir
├──03_inference_opt_prepare_0011.dat
├──04_abstract_specialize_0012.dot
├──04_abstract_specialize_0013.ir
├──04_abstract_specialize_0014.dat
...
</pre></div>
</div>
</section>
<section id="id3">
<h2>IR文件解读<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h2>
<p>下面以一个简单的例子来说明IR文件的内容，运行该脚本：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.context</span> <span class="k">as</span> <span class="nn">context</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>

<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">save_graphs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_graphs_path</span><span class="o">=</span><span class="s2">&quot;./&quot;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Add</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sub</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sub</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mul</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Mul</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">div</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Div</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">c</span>

<span class="n">input1</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">input2</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
<section id="id4">
<h3>ir文件介绍<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h3>
<p>使用文本编辑软件（例如<code class="docutils literal notranslate"><span class="pre">vi</span></code>）打开执行完后输出的IR文件<code class="docutils literal notranslate"><span class="pre">04_abstract_specialize_0013.ir</span></code>，内容如下所示：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  1 #IR entry      : @1_construct_wrapper.21
  2 #attrs         :
  3 #Total params  : 2
  4
  5 %para1_x : &lt;Tensor[Float32]x()&gt;
  6 %para2_y : &lt;Tensor[Float32]x()&gt;
  7
  8 #Total subgraph : 3
  9
 10 subgraph attr:
 11 Undeterminate : 0
 12 subgraph @2_construct.22(%para3_x, %para4_y) {
 13   %0(a) = Sub(%para3_x, Tensor(shape=[], dtype=Float32, value= 1)) {instance name: sub} primitive_attrs: {input_names: [x, y], output_names: [output]}
 14       : (&lt;Tensor[Float32]x()&gt;, &lt;Tensor[Float32]x()&gt;) -&gt; (&lt;Tensor[Float32]x()&gt;)
 15       # In file train.py(34)/        a = self.sub(x, 1)/
 16   %1(b) = Add(%0, %para4_y) {instance name: add} primitive_attrs: {input_names: [x, y], output_names: [output]}
 17       : (&lt;Tensor[Float32]x()&gt;, &lt;Tensor[Float32]x()&gt;) -&gt; (&lt;Tensor[Float32]x()&gt;)
 18       # In file train.py(35)/        b = self.add(a, y)/
 19   %2([CNode]5) = call @3_func.23(%0, %1)
 20       : (&lt;Tensor[Float32]x()&gt;, &lt;Tensor[Float32]x()&gt;) -&gt; (&lt;Tensor[Float32]x()&gt;)
 21       # In file train.py(36)/        c = self.mul(b, self.func(a, b))/
 22   %3(c) = Mul(%1, %2) {instance name: mul} primitive_attrs: {input_names: [x, y], output_names: [output]}
 23       : (&lt;Tensor[Float32]x()&gt;, &lt;Tensor[Float32]x()&gt;) -&gt; (&lt;Tensor[Float32]x()&gt;)
 24       # In file train.py(36)/        c = self.mul(b, self.func(a, b))/
 25   Return(%3)
 26       : (&lt;Tensor[Float32]x()&gt;)
 27       # In file train.py(37)/        return c/
 28 }
 29
 30 subgraph attr:
 31 Undeterminate : 0
 32 subgraph @3_func.23(%para5_x, %para6_y) {
 33   %0([CNode]20) = Div(%para5_x, %para6_y) {instance name: div} primitive_attrs: {input_names: [x, y], output_names: [output]}
 34       : (&lt;Tensor[Float32]x()&gt;, &lt;Tensor[Float32]x()&gt;) -&gt; (&lt;Tensor[Float32]x()&gt;)
 35       # In file train.py(31)/        return self.div(x, y)/
 36   Return(%0)
 37       : (&lt;Tensor[Float32]x()&gt;)
 38       # In file train.py(31)/        return self.div(x, y)/
 39 }
 40
 41 subgraph attr:
 42 subgraph @1_construct_wrapper.21() {
 43   %0([CNode]2) = call @2_construct.22(%para1_x, %para2_y)
 44       : (&lt;Tensor[Float32]x()&gt;, &lt;Tensor[Float32]x()&gt;) -&gt; (&lt;Tensor[Float32]x()&gt;)
 45       # In file train.py(37)/        return c/
 46   Return(%0)
 47       : (&lt;Tensor[Float32]x()&gt;)
 48       # In file train.py(37)/        return c/
 49 }
</pre></div>
</div>
<p>以上内容可分为两个部分，第一部分为图的输入信息，第二部分为图的结构信息。
其中第1行告诉了我们该网络的顶图名称<code class="docutils literal notranslate"><span class="pre">1_construct_wrapper.21</span></code>，也就是入口图。
第3行告诉了我们该网络有多少个输入。
第5-6行是输入列表，遵循<code class="docutils literal notranslate"><span class="pre">%para[序号]_[name]</span> <span class="pre">:</span> <span class="pre">&lt;[data_type]x[shape]&gt;</span></code>的格式。
第8行告诉我们该网络解析出来的图的数量，该IR文件展示了三张图的信息。 分别为第42行的入口图<code class="docutils literal notranslate"><span class="pre">1_construct_wrapper.21</span></code>；第32行的图<code class="docutils literal notranslate"><span class="pre">3_func.23</span></code>，对应着网络中定义的函数<code class="docutils literal notranslate"><span class="pre">func(x,</span> <span class="pre">y)</span></code>；第12行的图<code class="docutils literal notranslate"><span class="pre">2_construct.22</span></code>，即对应<code class="docutils literal notranslate"><span class="pre">construct</span></code>函数。
对于具体的图来说（此处我们以图<code class="docutils literal notranslate"><span class="pre">2_construct.22</span></code>为例），第10-28行展示了图结构的信息，图中含有若干个节点，即<code class="docutils literal notranslate"><span class="pre">CNode</span></code>。该图包含<code class="docutils literal notranslate"><span class="pre">Sub</span></code>、<code class="docutils literal notranslate"><span class="pre">Add</span></code>、<code class="docutils literal notranslate"><span class="pre">Mul</span></code>这些已经在<code class="docutils literal notranslate"><span class="pre">__init___</span></code>函数中定义过的算子。另外还有一处（第19行）以<code class="docutils literal notranslate"><span class="pre">call</span> <span class="pre">&#64;3_func.23</span></code>的形式，调用了图<code class="docutils literal notranslate"><span class="pre">3_func.23</span></code>，对应脚本中调用函数<code class="docutils literal notranslate"><span class="pre">func</span></code>执行两数相除的行为。</p>
<p><code class="docutils literal notranslate"><span class="pre">CNode</span></code>（<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/design/mindir.html#id2">ANF-IR的设计请查看</a>）的信息遵循如下格式，从左到右分别为序号、节点名称-debug_name、算子名称-op_name、输入节点-arg、节点的属性-primitive_attrs、输入和输出的规格、源码解析调用栈等信息。
由于ANF图为单向无环图，所以此处仅根据输入关系来体现节点与节点的连接关系。源码解析调用栈则体现了<code class="docutils literal notranslate"><span class="pre">CNode</span></code>与脚本源码之间的关系，例如第15行表明该节点是由脚本中<code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">=</span> <span class="pre">self.sub(x,</span> <span class="pre">1)</span></code>这一行解析而来。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>%[序号]([debug_name]) = [op_name]([arg], ...) primitive_attrs: {[key]: [value], ...}
    : (&lt;[输入data_type]x[输入shape]&gt;, ...) -&gt; (&lt;[输出data_type]x[输出shape]&gt;, ...)
    # 源码解析调用栈
</pre></div>
</div>
<blockquote>
<div><p>需要注意的是经过编译器的若干优化处理后，节点可能经过了若干变幻（如算子拆分、算子融合等），节点的源码解析调用栈信息与脚本可能无法完全一一对应，这里仅作为辅助手段。</p>
</div></blockquote>
</section>
<section id="dat">
<h3>dat文件介绍<a class="headerlink" href="#dat" title="Permalink to this headline"></a></h3>
<p>使用文本编辑软件（例如<code class="docutils literal notranslate"><span class="pre">vi</span></code>）打开执行完后输出的IR文件<code class="docutils literal notranslate"><span class="pre">04_abstract_specialize_0014.dat</span></code>，内容如下所示：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  1 # [No.1] 1_construct_wrapper.21
  2 # In file train.py(33)/    def construct(self, x, y):/
  3 funcgraph fg_21(
  4         %para1 : Tensor(F32)[]    # x
  5         , %para2 : Tensor(F32)[]    # y
  6     ) {
  7     %1 : Tensor(F32)[] = FuncGraph::fg_22(%para1, %para2)    #(Tensor(F32)[], Tensor(F32)[])    # fg_22=2_construct.22 #scope: Default
  8       # In file train.py(37)/        return c/#[CNode]2
  9     Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[]) #scope: Default
 10       # In file train.py(37)/        return c/#[CNode]1
 11 }
 12 # order:
 13 #   1: 1_construct_wrapper.21:[CNode]2{[0]: ValueNode&lt;FuncGraph&gt; 2_construct.22, [1]: x, [2]: y}
 14 #   2: 1_construct_wrapper.21:[CNode]1{[0]: ValueNode&lt;Primitive&gt; Return, [1]: [CNode]2}
 15
 16
 17 # [No.2] 2_construct.22
 18 # In file train.py(33)/    def construct(self, x, y):/
 19 funcgraph fg_22(
 20         %para3 : Tensor(F32)[]    # x
 21         , %para4 : Tensor(F32)[]    # y
 22     ) {
 23     %1 : Tensor(F32)[] = PrimitivePy::Sub{prim_type=2}[input_names=[&quot;x&quot;, &quot;y&quot;], output_names=[&quot;output&quot;]](%para3, Tensor(43)[])    #(Tensor(F32)[], Tenso    r(F32)[]) #scope: Default
 24       # In file train.py(34)/        a = self.sub(x, 1)/#a
 25     %2 : Tensor(F32)[] = PrimitivePy::Add{prim_type=2}[input_names=[&quot;x&quot;, &quot;y&quot;], output_names=[&quot;output&quot;]](%1, %para4)    #(Tensor(F32)[], Tensor(F32)[])     #scope: Default
 26       # In file train.py(35)/        b = self.add(a, y)/#b
 27     %3 : Tensor(F32)[] = FuncGraph::fg_23(%1, %2)    #(Tensor(F32)[], Tensor(F32)[])    # fg_23=3_func.23 #scope: Default
 28       # In file train.py(36)/        c = self.mul(b, self.func(a, b))/#[CNode]5
 29     %4 : Tensor(F32)[] = PrimitivePy::Mul{prim_type=2}[input_names=[&quot;x&quot;, &quot;y&quot;], output_names=[&quot;output&quot;]](%2, %3)    #(Tensor(F32)[], Tensor(F32)[]) #sco    pe: Default
 30       # In file train.py(36)/        c = self.mul(b, self.func(a, b))/#c
 31     Primitive::Return{prim_type=1}(%4)    #(Tensor(F32)[]) #scope: Default
 32       # In file train.py(37)/        return c/#[CNode]4
 33 }
 34 # order:
 35 #   1: 2_construct.22:a{[0]: ValueNode&lt;PrimitivePy&gt; Sub, [1]: x, [2]: ValueNode&lt;Tensor&gt; Tensor(shape=[], dtype=Float32, value= 1)}
 36 #   2: 2_construct.22:b{[0]: ValueNode&lt;PrimitivePy&gt; Add, [1]: a, [2]: y}
 37 #   3: 2_construct.22:[CNode]5{[0]: ValueNode&lt;FuncGraph&gt; 3_func.23, [1]: a, [2]: b}
 38 #   4: 2_construct.22:c{[0]: ValueNode&lt;PrimitivePy&gt; Mul, [1]: b, [2]: [CNode]5}
 39 #   5: 2_construct.22:[CNode]4{[0]: ValueNode&lt;Primitive&gt; Return, [1]: c}
 40
 41
 42 # [No.3] 3_func.23
 43 # In file train.py(30)/    def func(x, y):/
 44 funcgraph fg_23(
 45         %para5 : Tensor(F32)[]    # x
 46         , %para6 : Tensor(F32)[]    # y
 47     ) {
 48     %1 : Tensor(F32)[] = PrimitivePy::Div{prim_type=2}[input_names=[&quot;x&quot;, &quot;y&quot;], output_names=[&quot;output&quot;]](%para5, %para6)    #(Tensor(F32)[], Tensor(F32)    []) #scope: Default
 49       # In file train.py(31)/        return self.div(x, y)/#[CNode]20
 50     Primitive::Return{prim_type=1}(%1)    #(Tensor(F32)[]) #scope: Default
 51       # In file train.py(31)/        return self.div(x, y)/#[CNode]19
 52 }
 53 # order:
 54 #   1: 3_func.23:[CNode]20{[0]: ValueNode&lt;PrimitivePy&gt; Div, [1]: x, [2]: y}
 55 #   2: 3_func.23:[CNode]19{[0]: ValueNode&lt;Primitive&gt; Return, [1]: [CNode]20}
 56
 57
 58 # num of total function graphs: 3
</pre></div>
</div>
<p>以上内容，从顶图开始，以顺序方式展示了所有图的信息。
其中，第1行表示序号为<code class="docutils literal notranslate"><span class="pre">No.1</span></code>，图名为<code class="docutils literal notranslate"><span class="pre">1_construct_wrapper.21</span></code>。在顶图之中，第7行调用了图<code class="docutils literal notranslate"><span class="pre">2_construct.22</span></code>。
图<code class="docutils literal notranslate"><span class="pre">2_construct.22</span></code>的信息位于第17-39行，我们以该图为例展开详细说明。
第18行表示该图对应脚本中的函数定义所在的位置。
第20-21行表示图的输入信息，格式为：<code class="docutils literal notranslate"><span class="pre">%para[序号]</span> <span class="pre">:</span> <span class="pre">[data_type][shape]</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">[name]</span></code>.
第23-32行展示了图结构的信息，图中含有若干个节点，即<code class="docutils literal notranslate"><span class="pre">CNode</span></code>。该图包含<code class="docutils literal notranslate"><span class="pre">Sub</span></code>、<code class="docutils literal notranslate"><span class="pre">Add</span></code>、<code class="docutils literal notranslate"><span class="pre">Mul</span></code>这些已经在<code class="docutils literal notranslate"><span class="pre">__init___</span></code>函数中定义过的算子，其中第27行表示对另一张图的调用。
第34-39表示图中计算节点的执行序，与代码执行的先后顺序对应。格式为：<code class="docutils literal notranslate"><span class="pre">序号:</span> <span class="pre">所属图名称:节点名称{[0]:</span> <span class="pre">第一个输入的信息,</span> <span class="pre">[1]:</span> <span class="pre">第二个输入的信息,</span> <span class="pre">...}</span></code>。 对于<code class="docutils literal notranslate"><span class="pre">CNode</span></code>而言，第一个输入表示该节点承载的计算方式。
第58行表示图的数量，此处为3。</p>
<p><code class="docutils literal notranslate"><span class="pre">CNode</span></code>（<a class="reference external" href="https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.5/design/mindir.html#id2">ANF-IR的设计请查看</a>）的信息遵循如下格式，从左到右分别为序号、输出规格、算子名称-op_name、节点的属性-attr、输入节点-arg、输入节点的规格、所在的命名空间、源码解析调用栈等信息。</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>%[序号] : [输出规格] = [op_name]{[prim_type]}[attr0, attr1, ...](arg0, arg1, ...)    #(输入参数规格)#[命名空间]
  # 源码解析调用栈/#debug_name
</pre></div>
</div>
</section>
</section>
<section id="analyze-fail-dat">
<h2>如何根据analyze_fail.dat文件分析图推导失败的原因<a class="headerlink" href="#analyze-fail-dat" title="Permalink to this headline"></a></h2>
<p>MindSpore在编译图的过程中，经常会出现<code class="docutils literal notranslate"><span class="pre">evaluate</span></code>阶段的图推导失败的报错，通常我们能根据报错信息以及analyze_fail.dat文件，来定位出脚本中存在的问题。</p>
<p>例如执行下面一段代码：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>  <span class="mi">1</span> <span class="kn">import</span> <span class="nn">mindspore.context</span> <span class="k">as</span> <span class="nn">context</span>
  <span class="mi">2</span> <span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
  <span class="mi">3</span> <span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
  <span class="mi">4</span> <span class="kn">from</span> <span class="nn">mindspore.nn</span> <span class="kn">import</span> <span class="n">Cell</span>
  <span class="mi">5</span> <span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
  <span class="mi">6</span> <span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
  <span class="mi">7</span>
  <span class="mi">8</span> <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
  <span class="mi">9</span> <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">save_graphs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
 <span class="mi">10</span>
 <span class="mi">11</span> <span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
 <span class="mi">12</span>     <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
 <span class="mi">13</span>         <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
 <span class="mi">14</span>         <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Add</span><span class="p">()</span>
 <span class="mi">15</span>         <span class="bp">self</span><span class="o">.</span><span class="n">sub</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sub</span><span class="p">()</span>
 <span class="mi">16</span>         <span class="bp">self</span><span class="o">.</span><span class="n">mul</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Mul</span><span class="p">()</span>
 <span class="mi">17</span>         <span class="bp">self</span><span class="o">.</span><span class="n">div</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Div</span><span class="p">()</span>
 <span class="mi">18</span>
 <span class="mi">19</span>     <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
 <span class="mi">20</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
 <span class="mi">21</span>
 <span class="mi">22</span>     <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
 <span class="mi">23</span>         <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
 <span class="mi">24</span>         <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
 <span class="mi">25</span>         <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
 <span class="mi">26</span>         <span class="k">return</span> <span class="n">c</span>
 <span class="mi">27</span>
 <span class="mi">28</span> <span class="n">input1</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
 <span class="mi">29</span> <span class="n">input2</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
 <span class="mi">30</span> <span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
 <span class="mi">31</span> <span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">)</span>
 <span class="mi">32</span> <span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
<p>会出现如下的报错：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  1 [EXCEPTION] ANALYZER(31946,7f6f03941740,python):2021-09-18-15:10:49.094.863 [mindspore/ccsrc/pipeline/jit/static_analysis/stack_frame.cc:85] DoJump] The parameters number of the function is 2, but the number of provided arguments is 3.
  2 FunctionGraph ID : func.18
  3 NodeInfo: In file test.py(19)
  4     def func(x, y):
  5
  6 Traceback (most recent call last):
  7   File &quot;test.py&quot;, line 31, in &lt;module&gt;
  8     out = net(input1, input2)
  9   File &quot;/home/workspace/mindspore/mindspore/nn/cell.py&quot;, line 404, in __call__
 10     out = self.compile_and_run(*inputs)
 11   File &quot;/home/workspace/mindspore/mindspore/nn/cell.py&quot;, line 682, in compile_and_run
 12     self.compile(*inputs)
 13   File &quot;/home/workspace/mindspore/mindspore/nn/cell.py&quot;, line 669, in compile
 14     _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode)
 15   File &quot;/home/workspace/mindspore/mindspore/common/api.py&quot;, line 542, in compile
 16     result = self._graph_executor.compile(obj, args_list, phase, use_vm, self.queue_name)
 17 TypeError: mindspore/ccsrc/pipeline/jit/static_analysis/stack_frame.cc:85 DoJump] The parameters number of the function is 2, but the number of provided arguments is 3.
 18 FunctionGraph ID : func.18
 19 NodeInfo: In file test.py(19)
 20     def func(x, y):
 21
 22 The function call stack (See file &#39;/home/workspace/mindspore/rank_0/om/analyze_fail.dat&#39; for more details):
 23 # 0 In file test.py(26)
 24         return c
 25         ^
 26 # 1 In file test.py(25)
 27         c = self.mul(b, self.func(a, a, b))
 28                         ^
</pre></div>
</div>
<p>以上的报错信息为：“TypeError: mindspore/ccsrc/pipeline/jit/static_analysis/stack_frame.cc:85 DoJump] The parameters number of the function is 2, but the number of provided arguments is 3…”。
表明<code class="docutils literal notranslate"><span class="pre">FunctionGraph</span> <span class="pre">ID</span> <span class="pre">:</span> <span class="pre">func.18</span></code>只需要2个参数，但是却提供了3个参数。从“The function call stack …”中，可以知道出错的代码为：“In file test.py(25) … self.func(a, a, b)”，易知是该处的函数调用传入参数的数目过多。</p>
<p>但如果报错信息不直观或者需要查看IR中已推导出的部分图信息，我们使用文本编辑软件（例如，vi）打开报错信息中的提示的文件（第22行括号中）：<code class="docutils literal notranslate"><span class="pre">/home/workspace/mindspore/rank_0/om/analyze_fail.dat</span></code>，内容如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>  1 # [No.1] construct_wrapper.0
  2 # In file test.py(22)/    def construct(self, x, y):/
  3 funcgraph fg_0(
  4         %para1 : Tensor(F32)[]    # x
  5         , %para2 : Tensor(F32)[]    # y
  6     ) {
  7
  8 #------------------------&gt; 0
  9     %1 = FuncGraph::fg_3(%para1, %para2)    #(Tensor(F32)[], Tensor(F32)[])    # fg_3=construct.3 #scope: Default
 10       # In file test.py(26)/        return c/#[CNode]2
 11     Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default
 12       # In file test.py(26)/        return c/#[CNode]1
 13 }
 14 # order:
 15 #   1: construct_wrapper.0:[CNode]2{[0]: ValueNode&lt;FuncGraph&gt; construct.3, [1]: x, [2]: y}
 16 #   2: construct_wrapper.0:[CNode]1{[0]: ValueNode&lt;Primitive&gt; Return, [1]: [CNode]2}
 17
 18
 19 # [No.2] construct.3
 20 # In file test.py(22)/    def construct(self, x, y):/
 21 funcgraph fg_3(
 22         %para3 : Tensor(F32)[]    # x
 23         , %para4 : Tensor(F32)[]    # y
 24     ) {
 25     %1 : Tensor(F32)[] = DoSignaturePrimitive::S-Prim-Sub{prim_type=1}[input_names=[&quot;x&quot;, &quot;y&quot;], output_names=[&quot;output&quot;]](%para3, I64(1))    #(Tensor(F32)[], I64) #scope: Default
 26       # In file test.py(23)/        a = self.sub(x, 1)/#a
 27     %2 : Tensor(F32)[] = DoSignaturePrimitive::S-Prim-Add{prim_type=1}[input_names=[&quot;x&quot;, &quot;y&quot;], output_names=[&quot;output&quot;]](%1, %para4)    #(Tensor(F32)[], Tensor(F32)[]) #scope: Default
 28       # In file test.py(24)/        b = self.add(a, y)/#b
 29
 30 #------------------------&gt; 1
 31     %3 = FuncGraph::fg_18(%1, %1, %2)    #(Tensor(F32)[], Tensor(F32)[], Tensor(F32)[])    # fg_18=func.18 #scope: Default
 32       # In file test.py(25)/        c = self.mul(b, self.func(a, a, b))/#[CNode]5
 33     %4 = DoSignaturePrimitive::S-Prim-Mul{prim_type=1}[input_names=[&quot;x&quot;, &quot;y&quot;], output_names=[&quot;output&quot;]](%2, %3)    #(Tensor(F32)[], Undefined) #scope: Default
 34       # In file test.py(25)/        c = self.mul(b, self.func(a, a, b))/#c
 35     Primitive::Return{prim_type=1}(%4)    #(Undefined) #scope: Default
 36       # In file test.py(26)/        return c/#[CNode]4
 37 }
 38 # order:
 39 #   1: construct.3:a{[0]: a, [1]: ValueNode&lt;Int64Imm&gt; 1, [2]: ValueNode&lt;Float&gt; Float32}
 40 #   2: construct.3:a{[0]: ValueNode&lt;DoSignaturePrimitive&gt; S-Prim-Sub, [1]: x, [2]: ValueNode&lt;Int64Imm&gt; 1}
 41 #   3: construct.3:b{[0]: ValueNode&lt;DoSignaturePrimitive&gt; S-Prim-Add, [1]: a, [2]: y}
 42 #   4: construct.3:[CNode]5{[0]: ValueNode&lt;FuncGraph&gt; func.18, [1]: a, [2]: a, [3]: b}
 43 #   5: construct.3:c{[0]: ValueNode&lt;DoSignaturePrimitive&gt; S-Prim-Mul, [1]: b, [2]: [CNode]5}
 44 #   6: construct.3:[CNode]4{[0]: ValueNode&lt;Primitive&gt; Return, [1]: c}
 45
 46
 47 #===============================================================================
 48 # num of function graphs in stack: 2
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">analyze_fail.dat</span></code>文件与前文介绍过的.dat文件格式一致，唯一有区别的地方在于<code class="docutils literal notranslate"><span class="pre">analyze_fail.dat</span></code>文件中会指出推导出错的节点所在的位置。
我们不断搜索<code class="docutils literal notranslate"><span class="pre">------------------------&gt;</span></code>并来到最后一处该箭头出现的位置，即第30行的<code class="docutils literal notranslate"><span class="pre">------------------------&gt;</span> <span class="pre">1</span></code>。该最后一处箭头指向了推导出错的节点，为<code class="docutils literal notranslate"><span class="pre">%3</span> <span class="pre">=</span> <span class="pre">FuncGraph::fg_18(%1,</span> <span class="pre">%1,</span> <span class="pre">%2)</span> <span class="pre">...</span></code>，表达了该节点在IR中的信息，如何查看dat文件前文<code class="docutils literal notranslate"><span class="pre">dat文件介绍</span></code>一节中已经介绍，此处不再赘述。
根据<code class="docutils literal notranslate"><span class="pre">(%1,</span> <span class="pre">%1,</span> <span class="pre">%2)</span></code>可知，该节点的输入参数有三个。从源码解析调用栈中可以知道实际该函数为<code class="docutils literal notranslate"><span class="pre">self.func</span></code>，在脚本中的定义为<code class="docutils literal notranslate"><span class="pre">def</span> <span class="pre">dunc(x,</span> <span class="pre">y):...</span></code>。
在函数定义中，只需要两个参数，故会在此处出现推导失败的报错，我们需要修改脚本中传入的参数个数以解决该问题。</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="apply_quantization_aware_training.html" class="btn btn-neutral float-left" title="应用感知量化训练" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="dump_in_graph_mode.html" class="btn btn-neutral float-right" title="使用Dump功能在Graph模式调试" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>