

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindspore.ops.function.sparse_func &mdash; MindSpore master 文档</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/training.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
   
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/language_data.js"></script>
        <script src="../../../../_static/js/training.js"></script>
        <script src="../../../../_static/translations.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">设计</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/overview.html">MindSpore设计概览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/programming_paradigm.html">编程范式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/auto_gradient.html">函数式微分编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/mindir.html">中间表示MindIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/all_scenarios.html">全场景统一</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/dynamic_graph_and_static_graph.html">动静态图结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/pluggable_device.html">三方硬件对接</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/distributed_training_design.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/graph_fusion_engine.html">图算融合加速引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/glossary.html">术语</a></li>
</ul>
<p class="caption"><span class="caption-text">规格</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/benchmark.html">基准性能</a></li>
<li class="toctree-l1"><a class="reference external" href="https://gitee.com/mindspore/models/blob/master/README_CN.md#目录">网络支持↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/operator_list.html">API支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/syntax_list.html">语法支持</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/master/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption"><span class="caption-text">API映射</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/api_mapping/pytorch_api_mapping.html">PyTorch与MindSpore API映射表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/api_mapping/tensorflow_api_mapping.html">TensorFlow与MindSpore API映射表</a></li>
</ul>
<p class="caption"><span class="caption-text">迁移指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/overview.html">迁移指南概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/enveriment_preparation.html">环境准备与资料获取</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/analysis_and_preparation.html">模型分析与准备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/model_development/model_development.html">MindSpore网络搭建</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/debug_and_tune.html">调试调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/sample_code.html">网络迁移调试实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/faq.html">常见问题</a></li>
</ul>
<p class="caption"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/installation.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/data_processing.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/implement_problem.html">执行问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/network_compilation.html">网络编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/usage_migrate_3rd.html">第三方框架迁移使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/distributed_parallel.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/feature_advice.html">特性咨询</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../index.html">模块代码</a> &raquo;</li>
        
      <li>mindspore.ops.function.sparse_func</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>mindspore.ops.function.sparse_func 源代码</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2022 Huawei Technologies Co., Ltd</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ============================================================================</span>

<span class="sd">&quot;&quot;&quot;Defines sparse operators with functional form.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span>
<span class="kn">from</span> <span class="nn">mindspore.ops.operations.sparse_ops</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">DenseToCSRSparseMatrix</span><span class="p">,</span>
    <span class="n">CSRSparseMatrixToSparseTensor</span><span class="p">,</span>
    <span class="n">SparseConcat</span><span class="p">,</span>
    <span class="n">SparseAdd</span><span class="p">,</span>
    <span class="n">SparseMatrixAdd</span><span class="p">,</span>
    <span class="n">SparseMatrixSoftmax</span><span class="p">,</span>
    <span class="n">SparseMatrixSparseMatMul</span><span class="p">,</span>
    <span class="n">CSRSparseMatrixToDense</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">mindspore.common</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">from</span> <span class="nn">mindspore.ops.primitive</span> <span class="kn">import</span> <span class="n">constexpr</span><span class="p">,</span> <span class="n">Primitive</span>
<span class="kn">from</span> <span class="nn">mindspore.ops.operations.array_ops</span> <span class="kn">import</span> <span class="n">GatherNd</span><span class="p">,</span> <span class="n">Coalesce</span>
<span class="kn">from</span> <span class="nn">mindspore.ops.operations</span> <span class="kn">import</span> <span class="n">_csr_ops</span>
<span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">mindspore.common</span> <span class="kn">import</span> <span class="n">CSRTensor</span><span class="p">,</span> <span class="n">COOTensor</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore.ops.composite.multitype_ops._constexpr_utils</span> <span class="kn">import</span> <span class="n">raise_value_error</span><span class="p">,</span> <span class="n">raise_type_error</span><span class="p">,</span> <span class="n">make_tensor</span><span class="p">,</span>\
    <span class="n">promote_binary_dtype</span>

<span class="c1"># utility functions and values</span>
<span class="n">gather_nd</span> <span class="o">=</span> <span class="n">GatherNd</span><span class="p">()</span>
<span class="n">dense_to_csr</span> <span class="o">=</span> <span class="n">DenseToCSRSparseMatrix</span><span class="p">()</span>
<span class="n">csr_sparse_matrix_to_sparse_tensor</span> <span class="o">=</span> <span class="n">CSRSparseMatrixToSparseTensor</span><span class="p">()</span>
<span class="n">batch_csr_pointers_empty</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">coalesce_op</span> <span class="o">=</span> <span class="n">Coalesce</span><span class="p">()</span>
<span class="n">csr_sparse_matrix_to_dense</span> <span class="o">=</span> <span class="n">CSRSparseMatrixToDense</span><span class="p">()</span>


<span class="nd">@constexpr</span>
<span class="k">def</span> <span class="nf">print_info</span><span class="p">(</span><span class="n">info</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Print given error info&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">info</span><span class="p">)</span>


<span class="nd">@constexpr</span>
<span class="k">def</span> <span class="nf">_make_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Make Tensor&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>


<span class="nd">@constexpr</span>
<span class="k">def</span> <span class="nf">_make_tensor_with_dtype</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Make Tensor with specific datatype&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_convert_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Temporary solution to get shape value, will be removed when shape op is supported.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">is_sequence_shape_unknown</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,)</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">F</span><span class="o">.</span><span class="n">isconstant</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">else</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">is_scalar</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Determine whether tensor input is a scalar tensor.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">2</span>


<span class="k">def</span> <span class="nf">promote_tensor</span><span class="p">(</span><span class="n">tensor_1</span><span class="p">,</span> <span class="n">tensor_2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;promote Tensor&quot;&quot;&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">promote_binary_dtype</span><span class="p">(</span><span class="n">tensor_1</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">tensor_2</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tensor_1</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">),</span> <span class="n">tensor_2</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">promote_csr</span><span class="p">(</span><span class="n">csr_tensor_1</span><span class="p">,</span> <span class="n">csr_tensor_2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Type promotion for CSR tensor.&quot;&quot;&quot;</span>
    <span class="n">indptr_1</span><span class="p">,</span> <span class="n">indptr_2</span> <span class="o">=</span> <span class="n">promote_tensor</span><span class="p">(</span><span class="n">csr_tensor_1</span><span class="o">.</span><span class="n">indptr</span><span class="p">,</span> <span class="n">csr_tensor_2</span><span class="o">.</span><span class="n">indptr</span><span class="p">)</span>
    <span class="n">indices_1</span><span class="p">,</span> <span class="n">indices_2</span> <span class="o">=</span> <span class="n">promote_tensor</span><span class="p">(</span><span class="n">csr_tensor_1</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">csr_tensor_2</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>
    <span class="n">values_1</span><span class="p">,</span> <span class="n">values_2</span> <span class="o">=</span> <span class="n">promote_tensor</span><span class="p">(</span><span class="n">csr_tensor_1</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">csr_tensor_2</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">csr_tensor_1</span> <span class="o">=</span> <span class="n">CSRTensor</span><span class="p">(</span><span class="n">indptr_1</span><span class="p">,</span> <span class="n">indices_1</span><span class="p">,</span> <span class="n">values_1</span><span class="p">,</span> <span class="n">csr_tensor_1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">csr_tensor_2</span> <span class="o">=</span> <span class="n">CSRTensor</span><span class="p">(</span><span class="n">indptr_2</span><span class="p">,</span> <span class="n">indices_2</span><span class="p">,</span> <span class="n">values_2</span><span class="p">,</span> <span class="n">csr_tensor_2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">csr_tensor_1</span><span class="p">,</span> <span class="n">csr_tensor_2</span>


<span class="k">def</span> <span class="nf">promote_coo</span><span class="p">(</span><span class="n">coo_tensor_1</span><span class="p">,</span> <span class="n">coo_tensor_2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;promote COO-Tensor&quot;&quot;&quot;</span>
    <span class="n">indices_1</span><span class="p">,</span> <span class="n">indices_2</span> <span class="o">=</span> <span class="n">promote_tensor</span><span class="p">(</span><span class="n">coo_tensor_1</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">coo_tensor_2</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>
    <span class="n">values_1</span><span class="p">,</span> <span class="n">values_2</span> <span class="o">=</span> <span class="n">promote_tensor</span><span class="p">(</span><span class="n">coo_tensor_1</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">coo_tensor_2</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">coo_tensor_1</span> <span class="o">=</span> <span class="n">COOTensor</span><span class="p">(</span><span class="n">indices_1</span><span class="p">,</span> <span class="n">values_1</span><span class="p">,</span> <span class="n">coo_tensor_1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">coo_tensor_2</span> <span class="o">=</span> <span class="n">COOTensor</span><span class="p">(</span><span class="n">indices_2</span><span class="p">,</span> <span class="n">values_2</span><span class="p">,</span> <span class="n">coo_tensor_2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">coo_tensor_1</span><span class="p">,</span> <span class="n">coo_tensor_2</span>


<span class="k">def</span> <span class="nf">coalesce</span><span class="p">(</span><span class="n">x_indices</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">x_values</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">x_shape</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the coalesced sparse tensor of the input.</span>

<span class="sd">    Args:</span>
<span class="sd">        - **x_indices** (Tensor) - A 2-D Tensor, represents the indices of the nonzero elements of the sparse tensor.</span>
<span class="sd">          Supported data type is int64. It&#39;s elements should be non-negative. The shape is :math:`(y, x)`.</span>
<span class="sd">        - **x_values** (Tensor) - A 1-D Tensor, represents the values corresponding to the indices in `x_indices`.</span>
<span class="sd">          Supported data types are float16 and float32. The shape is :math:`(x,)`.</span>
<span class="sd">        - **x_shape** (Tensor) - A 1-D Tensor, specifies the shape of the sparse tensor.</span>
<span class="sd">          Supported data type is int64. The shape is :math:`(y,)`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        - **y_indices** (Tensor) - A 2-D Tensor, represents the indices of the nonzero elements of the sparse tensor.</span>
<span class="sd">          Data type is int64. It&#39;s elements are non-negative. The shape is :math:`(y, z)`.</span>
<span class="sd">          `z` represents the number of different indices in `x_indices`.</span>
<span class="sd">        - **y_values** (Tensor) - A 1-D Tensor, represents the values corresponding to the indices in `y_indices`.</span>
<span class="sd">          Data type is the same as `x_values`&#39;s. The shape is :math:`(z,)`.</span>
<span class="sd">        - **y_shape** (Tensor) - A 1-D Tensor, specifies the shape of the sparse tensor.</span>
<span class="sd">          Data type is int64. The shape is :math:`(y,)`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the data type of `x_values` is neither float32 nor float16.</span>
<span class="sd">        TypeError: If any of the data types of `x_indices` and `x_shape` is not int64.</span>
<span class="sd">        ValueError: If any of `x_values` and `x_shape` is not a 1-D tensor.</span>
<span class="sd">        ValueError: If `x_indices` is not a 2-D tensor.</span>
<span class="sd">        ValueError: If sizes of second dimension of `x_indices` and first dimension of `x_values` are not the same.</span>
<span class="sd">        ValueError: If sizes of first dimension of `x_indices` and first dimension of `x_shape` are not the same.</span>
<span class="sd">        ValueError: If any of the values of elements of `x_indices` is negative.</span>
<span class="sd">        ValueError: If any of the values of elements of `x_indices` exceed the limit set by `x_shape`.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.ops as ops</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import Tensor</span>
<span class="sd">        &gt;&gt;&gt; x_indices = Tensor([[0, 0, 1], [1, 1, 2]], dtype=ms.int64)</span>
<span class="sd">        &gt;&gt;&gt; x_values = Tensor([1, 5, 4], dtype=ms.float32)</span>
<span class="sd">        &gt;&gt;&gt; x_shape = Tensor([3, 3], dtype=ms.int64)</span>
<span class="sd">        &gt;&gt;&gt; y_indices, y_values, y_shape = ops.Coalesce()(x_indices, x_values, x_shape)</span>
<span class="sd">        &gt;&gt;&gt; print(y_indices)</span>
<span class="sd">        [[0 1]</span>
<span class="sd">         [1 2]]</span>
<span class="sd">        &gt;&gt;&gt; print(y_values)</span>
<span class="sd">        [6. 4.]</span>
<span class="sd">        &gt;&gt;&gt; print(y_shape)</span>
<span class="sd">        [3 3]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">coalesce_op</span><span class="p">(</span><span class="n">x_indices</span><span class="p">,</span> <span class="n">x_values</span><span class="p">,</span> <span class="n">x_shape</span><span class="p">)</span>


<span class="n">coo2csr</span> <span class="o">=</span> <span class="n">_csr_ops</span><span class="o">.</span><span class="n">COO2CSR</span><span class="p">()</span>

<span class="n">coo_tensor_get_dense_shape</span> <span class="o">=</span> <span class="n">Primitive</span><span class="p">(</span><span class="s1">&#39;COOTensorGetDenseShape&#39;</span><span class="p">)</span>

<span class="n">coo_tensor_get_indices</span> <span class="o">=</span> <span class="n">Primitive</span><span class="p">(</span><span class="s1">&#39;COOTensorGetIndices&#39;</span><span class="p">)</span>

<span class="n">coo_tensor_get_values</span> <span class="o">=</span> <span class="n">Primitive</span><span class="p">(</span><span class="s1">&#39;COOTensorGetValues&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">csr_div</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">CSRTensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns x / y where x is CSRTensor and y is Tensor.</span>

<span class="sd">    Note:</span>
<span class="sd">        This function returns the results of dense Tensor, represents the non-zero</span>
<span class="sd">        values of the CSRTensor. If user expects a CSRTensor as output, please directly</span>
<span class="sd">        use `/` operator instead. Only support dense tensor broadcast to sparse tensor</span>
<span class="sd">        at the moment.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (CSRTensor): Sparse CSR Tensor.</span>
<span class="sd">        y (Tensor): Dense Tensor, its shape must be able to broadcast to x.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dense Tensor, represents the non-zero values of the result.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU`` ``CPU``</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">_make_tensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">is_scalar</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
            <span class="n">raise_value_error</span><span class="p">(</span><span class="s2">&quot;dense tensor cannot broadcast to the sparse tensor.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">values</span> <span class="o">/</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">x_values</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">promote_tensor</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">res_values</span> <span class="o">=</span> <span class="n">_csr_ops</span><span class="o">.</span><span class="n">CSRDiv</span><span class="p">()(</span><span class="n">x</span><span class="o">.</span><span class="n">indptr</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">x_values</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">CSRTensor</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">indptr</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">res_values</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>


<span class="n">csr_gather</span> <span class="o">=</span> <span class="n">_csr_ops</span><span class="o">.</span><span class="n">CSRGather</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">csr_mul</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">CSRTensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">CSRTensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns x * y where x is CSRTensor and y is Tensor.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (CSRTensor): Sparse CSR Tensor.</span>
<span class="sd">        y (Tensor): Dense Tensor, its shape must be able to broadcast to x.</span>

<span class="sd">    Returns:</span>
<span class="sd">        CSRTensor.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU`` ``CPU``</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">_make_tensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">is_scalar</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
            <span class="n">raise_value_error</span><span class="p">(</span><span class="s2">&quot;dense tensor cannot broadcast to the sparse tensor.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">values</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">x_values</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">promote_tensor</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">res_values</span> <span class="o">=</span> <span class="n">_csr_ops</span><span class="o">.</span><span class="n">CSRMul</span><span class="p">()(</span><span class="n">x</span><span class="o">.</span><span class="n">indptr</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">x_values</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">CSRTensor</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">indptr</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">res_values</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">csr_mv</span><span class="p">(</span><span class="n">csr_tensor</span><span class="p">:</span> <span class="n">CSRTensor</span><span class="p">,</span> <span class="n">dense</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sparse matrix-vector multiplication.</span>

<span class="sd">    Args:</span>
<span class="sd">        csr_tensor (CSRTensor): Sparse CSR Tensor.</span>
<span class="sd">        dense (Tensor): Dense Tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dense Tensor.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU`` ``CPU``</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">csr_tensor_values</span><span class="p">,</span> <span class="n">dense</span> <span class="o">=</span> <span class="n">promote_tensor</span><span class="p">(</span><span class="n">csr_tensor</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dense</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_csr_ops</span><span class="o">.</span><span class="n">CSRMV</span><span class="p">()(</span><span class="n">csr_tensor</span><span class="o">.</span><span class="n">indptr</span><span class="p">,</span> <span class="n">csr_tensor</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">csr_tensor_values</span><span class="p">,</span> <span class="n">csr_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dense</span><span class="p">)</span>


<div class="viewcode-block" id="csr_mm"><a class="viewcode-back" href="../../../../api_python/ops/mindspore.ops.csr_mm.html#mindspore.ops.csr_mm">[文档]</a><span class="k">def</span> <span class="nf">csr_mm</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">CSRTensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">CSRTensor</span><span class="p">,</span> <span class="n">trans_a</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">trans_b</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
           <span class="n">adjoint_a</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">adjoint_b</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return the matrix multiplication result of the right-multiply matrix (dense or CSRTensor) of the CSRTensor.</span>
<span class="sd">    The CSRTensor with shape `[M, N]` needs to adapt the right matrix with shape `[N, K]`</span>
<span class="sd">    to get the dense matrix or CSRTensor with result `[M, K]`.</span>

<span class="sd">    Note:</span>
<span class="sd">        If right matrix is CSRTensor, currently only supports GPU backend.</span>
<span class="sd">        If right matrix is Tensor, currently supports CPU backend with LLVM no lower than 12.0.1, and GPU backend.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (CSRTensor): Sparse CSR Tensor, rank should be 2.</span>
<span class="sd">        b (CSRTensor): Sparse CSR Tensor, rank should be 2.</span>
<span class="sd">        trans_a (bool, optional): whether to transpose CSRTensor a. Default: ``False`` .</span>
<span class="sd">        trans_b (bool, optional): whether to transpose CSRTensor b. Default: ``False`` .</span>
<span class="sd">        adjoint_a (bool, optional): whether to adjoint CSRTensor a. Default: ``False`` .</span>
<span class="sd">        adjoint_b (bool, optional): whether to adjoint CSRTensor b. Default: ``False`` .</span>

<span class="sd">    Returns:</span>
<span class="sd">        CSRTensor.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import Tensor, CSRTensor</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import dtype as mstype</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.ops as ops</span>
<span class="sd">        &gt;&gt;&gt; a_shape = (4, 5)</span>
<span class="sd">        &gt;&gt;&gt; a_indptr = Tensor([0, 1, 1, 3, 4], dtype=mstype.int32)</span>
<span class="sd">        &gt;&gt;&gt; a_indices = Tensor([0, 3, 4, 0],dtype=mstype.int32)</span>
<span class="sd">        &gt;&gt;&gt; a_values = Tensor([1.0, 5.0, -1.0, -2.0], dtype=mstype.float32)</span>
<span class="sd">        &gt;&gt;&gt; b_shape = (5, 3)</span>
<span class="sd">        &gt;&gt;&gt; b_indptr = Tensor([0, 1, 1, 3, 3, 3], dtype=mstype.int32)</span>
<span class="sd">        &gt;&gt;&gt; b_indices = Tensor([0, 0, 1],dtype=mstype.int32)</span>
<span class="sd">        &gt;&gt;&gt; b_values = Tensor([2.0, 7.0, 8.0], dtype=mstype.float32)</span>
<span class="sd">        &gt;&gt;&gt; a = CSRTensor(a_indptr, a_indices, a_values, a_shape)</span>
<span class="sd">        &gt;&gt;&gt; b = CSRTensor(b_indptr, b_indices, b_values, b_shape)</span>
<span class="sd">        &gt;&gt;&gt; c = ops.csr_mm(a, b)</span>
<span class="sd">        &gt;&gt;&gt; print(c.shape)</span>
<span class="sd">        (4, 3)</span>
<span class="sd">        &gt;&gt;&gt; print(c.values)</span>
<span class="sd">        [2. -4.]</span>
<span class="sd">        &gt;&gt;&gt; print(c.indptr)</span>
<span class="sd">        [0 1 1 1 2]</span>
<span class="sd">        &gt;&gt;&gt; print(c.indices)</span>
<span class="sd">        [0 0]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">CSRTensor</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">CSRTensor</span><span class="p">):</span>
        <span class="n">raise_type_error</span><span class="p">(</span><span class="s2">&quot;For functional operator csr_mm, inputs a and b must be type of CSRTensor currently.&quot;</span><span class="p">)</span>
    <span class="n">a_batch_pointers</span> <span class="o">=</span> <span class="n">make_tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">a</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">b_batch_pointers</span> <span class="o">=</span> <span class="n">make_tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">b</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">b</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">a_shape</span> <span class="o">=</span> <span class="n">make_tensor</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">b_shape</span> <span class="o">=</span> <span class="n">make_tensor</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">sparse_matrix_sparse_matmul</span> <span class="o">=</span> <span class="n">SparseMatrixSparseMatMul</span><span class="p">(</span><span class="n">transpose_a</span><span class="o">=</span><span class="n">trans_a</span><span class="p">,</span>
                                                           <span class="n">transpose_b</span><span class="o">=</span><span class="n">trans_b</span><span class="p">,</span>
                                                           <span class="n">adjoint_a</span><span class="o">=</span><span class="n">adjoint_a</span><span class="p">,</span>
                                                           <span class="n">adjoint_b</span><span class="o">=</span><span class="n">adjoint_b</span><span class="p">)</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">c_indptr</span><span class="p">,</span> <span class="n">c_indices</span><span class="p">,</span> <span class="n">c_values</span> <span class="o">=</span> <span class="n">sparse_matrix_sparse_matmul</span><span class="p">(</span><span class="n">a_shape</span><span class="p">,</span>
                                                                      <span class="n">a_batch_pointers</span><span class="p">,</span>
                                                                      <span class="n">a</span><span class="o">.</span><span class="n">indptr</span><span class="p">,</span>
                                                                      <span class="n">a</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span>
                                                                      <span class="n">a</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                                                                      <span class="n">b_shape</span><span class="p">,</span>
                                                                      <span class="n">b_batch_pointers</span><span class="p">,</span>
                                                                      <span class="n">b</span><span class="o">.</span><span class="n">indptr</span><span class="p">,</span>
                                                                      <span class="n">b</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span>
                                                                      <span class="n">b</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">trans_a</span> <span class="ow">or</span> <span class="n">adjoint_a</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">CSRTensor</span><span class="p">(</span><span class="n">c_indptr</span><span class="p">,</span> <span class="n">c_indices</span><span class="p">,</span> <span class="n">c_values</span><span class="p">,</span> <span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">if</span> <span class="n">trans_b</span> <span class="ow">or</span> <span class="n">adjoint_b</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">CSRTensor</span><span class="p">(</span><span class="n">c_indptr</span><span class="p">,</span> <span class="n">c_indices</span><span class="p">,</span> <span class="n">c_values</span><span class="p">,</span> <span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">CSRTensor</span><span class="p">(</span><span class="n">c_indptr</span><span class="p">,</span> <span class="n">c_indices</span><span class="p">,</span> <span class="n">c_values</span><span class="p">,</span> <span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span></div>


<span class="k">def</span> <span class="nf">csr_reduce_sum</span><span class="p">(</span><span class="n">csr_tensor</span><span class="p">:</span> <span class="n">CSRTensor</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reduces a dimension of a CSRTensor by summing all elements in the dimension.</span>

<span class="sd">    Args:</span>
<span class="sd">        csr_tensor (CSRTensor): Sparse CSR Tensor.</span>
<span class="sd">        axis (int): Axis to be reduced.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dense Tensor, represents the non-zero values of the result.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU`` ``CPU``</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_csr_ops</span><span class="o">.</span><span class="n">CSRReduceSum</span><span class="p">()(</span><span class="n">csr_tensor</span><span class="o">.</span><span class="n">indptr</span><span class="p">,</span> <span class="n">csr_tensor</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">csr_tensor</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">csr_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>


<div class="viewcode-block" id="csr_to_coo"><a class="viewcode-back" href="../../../../api_python/ops/mindspore.ops.csr_to_coo.html#mindspore.ops.csr_to_coo">[文档]</a><span class="k">def</span> <span class="nf">csr_to_coo</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">CSRTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">COOTensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts a CSRTensor to COOTensor.</span>

<span class="sd">    Note:</span>
<span class="sd">        Only 2-D CSRTensor is supported for now.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor (CSRTensor): A CSRTensor, must be 2-D.</span>

<span class="sd">    Returns:</span>
<span class="sd">        2D COOTensor, the input tensor stored in COO format.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input is not a COOTensor.</span>
<span class="sd">        ValueError: If input tensor is not 2-D.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``Ascend`` ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import Tensor, CSRTensor</span>
<span class="sd">        &gt;&gt;&gt; indptr = Tensor([0, 1, 2]).astype(&quot;int32&quot;)</span>
<span class="sd">        &gt;&gt;&gt; indices = Tensor([0, 1]).astype(&quot;int32&quot;)</span>
<span class="sd">        &gt;&gt;&gt; values = Tensor([2, 1]).astype(&quot;float32&quot;)</span>
<span class="sd">        &gt;&gt;&gt; shape = (2, 4)</span>
<span class="sd">        &gt;&gt;&gt; x = CSRTensor(indptr, indices, values, shape)</span>
<span class="sd">        &gt;&gt;&gt; output = ops.csr_to_coo(x)</span>
<span class="sd">        &gt;&gt;&gt; print(output.indices)</span>
<span class="sd">        [[0 0]</span>
<span class="sd">        [1 1]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">CSRTensor</span><span class="p">):</span>
        <span class="n">raise_type_error</span><span class="p">(</span><span class="s2">&quot;For functional operator csr_to_coo, input argument must be a CSRTensor.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">_convert_shape</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">raise_value_error</span><span class="p">(</span><span class="s2">&quot;Currently only support 2-D CSRTensor when converting to COOTensor.&quot;</span><span class="p">)</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">csr_sparse_matrix_to_sparse_tensor</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="n">batch_csr_pointers_empty</span><span class="p">,</span>
                                                            <span class="n">tensor</span><span class="o">.</span><span class="n">indptr</span><span class="p">,</span> <span class="n">tensor</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">tensor</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">COOTensor</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">_convert_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span></div>


<span class="k">def</span> <span class="nf">csr_to_dense</span><span class="p">(</span><span class="n">csr_tensor</span><span class="p">:</span> <span class="n">CSRTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts a CSRTensor to its dense form.</span>

<span class="sd">    Note:</span>
<span class="sd">        Only 2-D CSRTensor is supported for now.</span>

<span class="sd">    Args:</span>
<span class="sd">        csr_tensor (CSRTensor): A CSRTensor, must be 2-D.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input is not a CSRTensor.</span>
<span class="sd">        ValueError: If input CSRTensor is not 2-D.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import Tensor, CSRTensor, ops</span>
<span class="sd">        &gt;&gt;&gt; indptr = Tensor([0, 1, 2]).astype(&quot;int32&quot;)</span>
<span class="sd">        &gt;&gt;&gt; indices = Tensor([0, 1]).astype(&quot;int32&quot;)</span>
<span class="sd">        &gt;&gt;&gt; values = Tensor([2, 1]).astype(&quot;float32&quot;)</span>
<span class="sd">        &gt;&gt;&gt; shape = (2, 4)</span>
<span class="sd">        &gt;&gt;&gt; x = CSRTensor(indptr, indices, values, shape)</span>
<span class="sd">        &gt;&gt;&gt; output = ops.csr_to_dense(x)</span>
<span class="sd">        &gt;&gt;&gt; print(output)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">csr_tensor</span><span class="p">,</span> <span class="n">CSRTensor</span><span class="p">):</span>
        <span class="n">raise_type_error</span><span class="p">(</span><span class="s2">&quot;For functional operator csr_to_dense, input argument must be a CSRTensor.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">csr_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">raise_value_error</span><span class="p">(</span><span class="s2">&quot;Currently only support 2-D CSRTensor when converting to COOTensor.&quot;</span><span class="p">)</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="n">_convert_shape</span><span class="p">(</span><span class="n">csr_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">dense_shape</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">batch_pointers</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">make_tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">]),</span> <span class="n">ops</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">()(</span><span class="n">csr_tensor</span><span class="o">.</span><span class="n">values</span><span class="p">)))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;int32&quot;</span><span class="p">)</span>
    <span class="n">row_pointers</span> <span class="o">=</span> <span class="n">csr_tensor</span><span class="o">.</span><span class="n">indptr</span>
    <span class="n">col_indices</span> <span class="o">=</span> <span class="n">csr_tensor</span><span class="o">.</span><span class="n">indices</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">csr_tensor</span><span class="o">.</span><span class="n">values</span>

    <span class="n">valid_indices_dtype</span> <span class="o">=</span> <span class="p">[</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">row_pointers</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="n">valid_indices_dtype</span> <span class="ow">and</span> <span class="n">col_indices</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="n">valid_indices_dtype</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">row_pointers</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span> <span class="ow">or</span> <span class="n">col_indices</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">csr_sparse_matrix_to_dense</span><span class="p">(</span><span class="n">dense_shape</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">batch_pointers</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
                                              <span class="n">row_pointers</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">col_indices</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
                                              <span class="n">values</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">csr_sparse_matrix_to_dense</span><span class="p">(</span><span class="n">dense_shape</span><span class="p">,</span> <span class="n">batch_pointers</span><span class="p">,</span> <span class="n">row_pointers</span><span class="p">,</span> <span class="n">col_indices</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>


<span class="c1"># deprecated, will be removed once `csr_to_coo` supports all backends.</span>
<span class="n">csr2coo</span> <span class="o">=</span> <span class="n">_csr_ops</span><span class="o">.</span><span class="n">CSR2COO</span><span class="p">()</span>

<span class="n">csr_tensor_get_dense_shape</span> <span class="o">=</span> <span class="n">Primitive</span><span class="p">(</span><span class="s1">&#39;CSRTensorGetDenseShape&#39;</span><span class="p">)</span>

<span class="n">csr_tensor_get_indices</span> <span class="o">=</span> <span class="n">Primitive</span><span class="p">(</span><span class="s1">&#39;CSRTensorGetIndices&#39;</span><span class="p">)</span>

<span class="n">csr_tensor_get_indptr</span> <span class="o">=</span> <span class="n">Primitive</span><span class="p">(</span><span class="s1">&#39;CSRTensorGetIndptr&#39;</span><span class="p">)</span>

<span class="n">csr_tensor_get_values</span> <span class="o">=</span> <span class="n">Primitive</span><span class="p">(</span><span class="s1">&#39;CSRTensorGetValues&#39;</span><span class="p">)</span>


<div class="viewcode-block" id="dense_to_sparse_coo"><a class="viewcode-back" href="../../../../api_python/ops/mindspore.ops.dense_to_sparse_coo.html#mindspore.ops.dense_to_sparse_coo">[文档]</a><span class="k">def</span> <span class="nf">dense_to_sparse_coo</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">COOTensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a Tensor to COOTensor.</span>

<span class="sd">    Note:</span>
<span class="sd">        Only 2-D tensor is supported for now.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor (Tensor): A dense tensor, must be 2-D.</span>

<span class="sd">    Returns:</span>
<span class="sd">        COOTensor, a sparse representation of the original dense tensor, containing the following parts.</span>

<span class="sd">        - indices (Tensor): 2-D integer tensor, indicates the positions of `values` of the dense tensor.</span>
<span class="sd">        - values (Tensor): 1-D tensor, indicates the non-zero values of the dense tensor.</span>
<span class="sd">        - shape (tuple(int)): the shape of the COOTensor, is the same as the original dense tensor.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input is not a tensor.</span>
<span class="sd">        ValueError: If input tensor is not 2-D.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import Tensor, ops</span>
<span class="sd">        &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">        &gt;&gt;&gt; x = Tensor([[1, 0], [-5, 0]], ms.float32)</span>
<span class="sd">        &gt;&gt;&gt; output = ops.dense_to_sparse_coo(x)</span>
<span class="sd">        &gt;&gt;&gt; print(output.indices)</span>
<span class="sd">        [[0 0]</span>
<span class="sd">        [1 0]]</span>
<span class="sd">        &gt;&gt;&gt; print(output.values)</span>
<span class="sd">        [ 1. -5.]</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<span class="sd">        (2, 2)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">raise_type_error</span><span class="p">(</span><span class="s2">&quot;For functional operator dense_to_sparse_coo, input argument must be a Tensor.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">_convert_shape</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">raise_value_error</span><span class="p">(</span><span class="s2">&quot;Currently only support 2-D Tensor when converting to COOTensor.&quot;</span><span class="p">)</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;int32&quot;</span><span class="p">)</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">gather_nd</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">COOTensor</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">_convert_shape</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span></div>


<div class="viewcode-block" id="dense_to_sparse_csr"><a class="viewcode-back" href="../../../../api_python/ops/mindspore.ops.dense_to_sparse_csr.html#mindspore.ops.dense_to_sparse_csr">[文档]</a><span class="k">def</span> <span class="nf">dense_to_sparse_csr</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">CSRTensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a Tensor to CSRTensor.</span>

<span class="sd">    Note:</span>
<span class="sd">        Only 2-D tensor is supported for now.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor (Tensor): A dense tensor, must be 2-D.</span>

<span class="sd">    Returns:</span>
<span class="sd">        CSRTensor, a sparse representation of the original dense tensor, containing the following parts.</span>

<span class="sd">        - indptr (Tensor): 1-D integer tensor, indicates the start and end point for `values` in each row.</span>
<span class="sd">        - indices (Tensor): 1-D integer tensor, indicates the column positions of all non-zero values of the input.</span>
<span class="sd">        - values (Tensor): 1-D tensor, indicates the non-zero values of the dense tensor.</span>
<span class="sd">        - shape (tuple(int)): the shape of the CSRTensor, is the same as the original dense tensor.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If input is not a tensor.</span>
<span class="sd">        ValueError: If input tensor is not 2-D.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import Tensor, ops</span>
<span class="sd">        &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">        &gt;&gt;&gt; x = Tensor([[1, 0], [-5, 0]], ms.float32)</span>
<span class="sd">        &gt;&gt;&gt; output = ops.dense_to_sparse_csr(x)</span>
<span class="sd">        &gt;&gt;&gt; print(output.indptr)</span>
<span class="sd">        [0 1 2]</span>
<span class="sd">        &gt;&gt;&gt; print(output.indices)</span>
<span class="sd">        [0 0]</span>
<span class="sd">        &gt;&gt;&gt; print(output.shape)</span>
<span class="sd">        (2, 2)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">raise_type_error</span><span class="p">(</span><span class="s2">&quot;For functional operator dense_to_sparse_csr, input argument must be a Tensor.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">_convert_shape</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">raise_value_error</span><span class="p">(</span><span class="s2">&quot;Currently only support 2-D Tensor when converting to CSRTensor.&quot;</span><span class="p">)</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;int32&quot;</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">indptr</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="n">dense_to_csr</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">CSRTensor</span><span class="p">(</span><span class="n">indptr</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">_convert_shape</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span></div>


<span class="k">def</span> <span class="nf">make_sparse_tensor</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">dense_shape</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Call make_coo_tensor in this function.&quot;&quot;&quot;</span>
    <span class="n">print_info</span><span class="p">(</span><span class="s2">&quot;WARNING: &#39;SparseTensor&#39; is deprecated from version 1.7 and will be removed in a future version. &quot;</span> <span class="o">+</span>
               <span class="s2">&quot;Please use &#39;COOTensor&#39; instead.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">make_coo_tensor</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">dense_shape</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">make_row_tensor</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">dense_shape</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Call make_row_tensor_inner in this function.&quot;&quot;&quot;</span>
    <span class="n">print_info</span><span class="p">(</span><span class="s2">&quot;WARNING: &#39;RowTensor&#39; is deprecated from version 2.0 and will be removed in a future version.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">make_row_tensor_inner</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">dense_shape</span><span class="p">)</span>


<span class="n">make_coo_tensor</span> <span class="o">=</span> <span class="n">Primitive</span><span class="p">(</span><span class="s1">&#39;MakeCOOTensor&#39;</span><span class="p">)</span>

<span class="n">make_csr_tensor</span> <span class="o">=</span> <span class="n">Primitive</span><span class="p">(</span><span class="s1">&#39;MakeCSRTensor&#39;</span><span class="p">)</span>

<span class="n">make_row_tensor_inner</span> <span class="o">=</span> <span class="n">Primitive</span><span class="p">(</span><span class="s1">&#39;MakeRowTensor&#39;</span><span class="p">)</span>

<span class="n">make_map_parameter</span> <span class="o">=</span> <span class="n">Primitive</span><span class="p">(</span><span class="s1">&#39;MakeMapParameter&#39;</span><span class="p">)</span>

<span class="n">row_tensor_get_values</span> <span class="o">=</span> <span class="n">Primitive</span><span class="p">(</span><span class="s1">&#39;RowTensorGetValues&#39;</span><span class="p">)</span>

<span class="n">row_tensor_get_indices</span> <span class="o">=</span> <span class="n">Primitive</span><span class="p">(</span><span class="s1">&#39;RowTensorGetIndices&#39;</span><span class="p">)</span>

<span class="n">row_tensor_get_dense_shape</span> <span class="o">=</span> <span class="n">Primitive</span><span class="p">(</span><span class="s1">&#39;RowTensorGetDenseShape&#39;</span><span class="p">)</span>

<span class="n">row_tensor_add</span> <span class="o">=</span> <span class="n">Primitive</span><span class="p">(</span><span class="s1">&#39;RowTensorAdd&#39;</span><span class="p">)</span>


<span class="nd">@constexpr</span>
<span class="k">def</span> <span class="nf">_calc_out_shape</span><span class="p">(</span><span class="n">sp_input</span><span class="p">,</span> <span class="n">concat_dim</span><span class="p">):</span>
    <span class="s2">&quot;calculating the COOTensor output shape in coo_concat&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sp_input</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">out_shape_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">sp_input</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">2</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">out_shape_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">sp_input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sp_input</span><span class="p">)):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sp_input</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">out_shape_list</span><span class="p">[</span><span class="n">concat_dim</span><span class="p">]</span> <span class="o">+=</span> <span class="n">sp_input</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">][</span><span class="n">concat_dim</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">out_shape_list</span><span class="p">[</span><span class="n">concat_dim</span><span class="p">]</span> <span class="o">+=</span> <span class="n">sp_input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">concat_dim</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">out_shape_list</span><span class="p">)</span>


<span class="nd">@constexpr</span>
<span class="k">def</span> <span class="nf">_set_coo_concat_input</span><span class="p">(</span><span class="n">sp_input</span><span class="p">):</span>
    <span class="s2">&quot;split COOTensor to normal tensor&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sp_input</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">raise_value_error</span><span class="p">(</span><span class="s2">&quot;For coo_concat, not support COOTensor input number &lt; 2.&quot;</span><span class="p">)</span>
    <span class="n">in_indices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">in_values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">in_shapes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">sp_input</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">in_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">element</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">in_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">element</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">in_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">element</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">in_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">element</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>
            <span class="n">in_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">element</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
            <span class="n">in_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">element</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">in_indices</span><span class="p">,</span> <span class="n">in_values</span><span class="p">,</span> <span class="n">in_shapes</span>


<div class="viewcode-block" id="coo_concat"><a class="viewcode-back" href="../../../../api_python/ops/mindspore.ops.coo_concat.html#mindspore.ops.coo_concat">[文档]</a><span class="k">def</span> <span class="nf">coo_concat</span><span class="p">(</span><span class="n">sp_input</span><span class="p">,</span> <span class="n">concat_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    concatenates the input SparseTensor(COO format) along the specified dimension.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        This is an experimental API that is subjected to change or deletion. Only supported on CPU now.</span>

<span class="sd">    Args:</span>
<span class="sd">        sp_input (Union[list(COOTensor), tuple(COOTensor)]) - the list of SparseTensor which need to concatenates.</span>
<span class="sd">            for COOTensor input.</span>
<span class="sd">        concat_dim (scalar): decide the dimension to concatenation along.</span>
<span class="sd">            The value must be in range [-rank, rank), where rank is the number of dimensions in each input</span>
<span class="sd">            SparseTensor. Default is 0.</span>

<span class="sd">    Returns:</span>
<span class="sd">        - **output** (COOtensor) - the result of concatenates the input SparseTensor along the</span>
<span class="sd">          specified dimension. OutShape: OutShape[non concat_dim] is equal to InShape[non concat_dim] and</span>
<span class="sd">          OutShape[concat_dim] is all input concat_dim axis shape accumulate.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If only one sparse tensor input.</span>
<span class="sd">        ValueError: If Input COOTensor shape dim &gt; 3. COOtensor shape dim size must be 2 now.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; indices0 = Tensor([[0, 1], [1, 2]], dtype=mstype.int64)</span>
<span class="sd">        &gt;&gt;&gt; values0 = Tensor([1, 2], dtype=mstype.int32)</span>
<span class="sd">        &gt;&gt;&gt; shape0 = (3, 4)</span>
<span class="sd">        &gt;&gt;&gt; input0 = COOTensor(indices0, values0, shape0)</span>
<span class="sd">        &gt;&gt;&gt; indices1 = Tensor([[0, 0], [1, 1]], dtype=mstype.int64)</span>
<span class="sd">        &gt;&gt;&gt; values1 = Tensor([3, 4], dtype=mstype.int32)</span>
<span class="sd">        &gt;&gt;&gt; shape1 = (3, 4)</span>
<span class="sd">        &gt;&gt;&gt; input1 = COOTensor(indices1, values1, shape1)</span>
<span class="sd">        &gt;&gt;&gt; concat_dim = 1</span>
<span class="sd">        &gt;&gt;&gt; out = ops.coo_concat((input0, input1), concat_dim)</span>
<span class="sd">        &gt;&gt;&gt; print(out)</span>
<span class="sd">        COOTensor(shape=[3, 8], dtype=Int32, indices=Tensor(shape=[4, 2], dtype=Int64, value=</span>
<span class="sd">        [[0 1]</span>
<span class="sd">         [0 4]</span>
<span class="sd">         [1 2]</span>
<span class="sd">         [1 5]]), values=Tensor(shape=[4], dtype=Int32, value=[1 3 2 4]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">coo_concat_op</span> <span class="o">=</span> <span class="n">SparseConcat</span><span class="p">(</span><span class="n">concat_dim</span><span class="p">)</span>
    <span class="n">in_indices</span><span class="p">,</span> <span class="n">in_values</span><span class="p">,</span> <span class="n">in_shapes</span> <span class="o">=</span> <span class="n">_set_coo_concat_input</span><span class="p">(</span><span class="n">sp_input</span><span class="p">)</span>
    <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">coo_concat_op</span><span class="p">(</span><span class="n">in_indices</span><span class="p">,</span> <span class="n">in_values</span><span class="p">,</span> <span class="n">in_shapes</span><span class="p">)</span>
    <span class="n">out_shape</span> <span class="o">=</span> <span class="n">_calc_out_shape</span><span class="p">(</span><span class="n">sp_input</span><span class="p">,</span> <span class="n">concat_dim</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">COOTensor</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">out_shape</span><span class="p">)</span></div>


<div class="viewcode-block" id="coo_add"><a class="viewcode-back" href="../../../../api_python/ops/mindspore.ops.coo_add.html#mindspore.ops.coo_add">[文档]</a><span class="k">def</span> <span class="nf">coo_add</span><span class="p">(</span><span class="n">x1</span><span class="p">:</span> <span class="n">COOTensor</span><span class="p">,</span> <span class="n">x2</span><span class="p">:</span> <span class="n">COOTensor</span><span class="p">,</span> <span class="n">thresh</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">COOTensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the sum of x1(COOTensor) and x2(COOTensor), and return a new COOTensor</span>
<span class="sd">    based on the computed result and `thresh`.</span>

<span class="sd">    Args:</span>
<span class="sd">        x1 (COOTensor): the first COOTensor to sum.</span>
<span class="sd">        x2 (COOTensor): the second COOTensor to sum.</span>
<span class="sd">        thresh (Tensor): A 0-D Tensor, represents the magnitude threshold that determines</span>
<span class="sd">            if an output value/index pair take place. Its dtype</span>
<span class="sd">            should match that of the values if they are real. If output&#39;s</span>
<span class="sd">            value is less than the `thresh`, it will vanish.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A COOTensor, the result of sum.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If any input(x1/x2)&#39;s indices&#39;s dim is not equal to 2.</span>
<span class="sd">        ValueError: If any input(x1/x2)&#39;s values&#39;s dim is not equal to 1.</span>
<span class="sd">        ValueError: If any input(x1/x2)&#39;s shape&#39;s dim is not equal to 1.</span>
<span class="sd">        ValueError: If thresh&#39;s dim is not equal to 0.</span>
<span class="sd">        TypeError: If any input(x1/x2)&#39;s indices&#39;s type is not equal to int64.</span>
<span class="sd">        TypeError: If any input(x1/x2)&#39;s shape&#39;s type is not equal to int64.</span>
<span class="sd">        ValueError: If any input(x1/x2)&#39;s indices&#39;s length is not equal to</span>
<span class="sd">            its values&#39;s length.</span>
<span class="sd">        TypeError: If any input(x1/x2)&#39;s values&#39;s type is not equal to anf of</span>
<span class="sd">            (int8/int16/int32/int64/float32/float64/complex64/complex128).</span>
<span class="sd">        TypeError: If thresh&#39;s type is not equal to anf of</span>
<span class="sd">            (int8/int16/int32/int64/float32/float64).</span>
<span class="sd">        TypeError: If x1&#39;s indices&#39;s type is not equal to x2&#39;s indices&#39;s type.</span>
<span class="sd">        TypeError: If x1&#39;s values&#39;s type is not equal to x2&#39;s values&#39;s type.</span>
<span class="sd">        TypeError: If x1&#39;s shape&#39;s type is not equal to x2&#39;s shape&#39;s type.</span>
<span class="sd">        TypeError: If (x1/x2)&#39;s value&#39;s type is not matched with thresh&#39;s type.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import Tensor, COOTensor</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import dtype as mstype</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import context</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import ops</span>
<span class="sd">        &gt;&gt;&gt; indics0 = Tensor([[0, 1], [1, 2]], dtype=mstype.int64)</span>
<span class="sd">        &gt;&gt;&gt; values0 = Tensor([1, 2], dtype=mstype.int32)</span>
<span class="sd">        &gt;&gt;&gt; shape0 = (3, 4)</span>
<span class="sd">        &gt;&gt;&gt; input0 = COOTensor(indics0, values0, shape0)</span>
<span class="sd">        &gt;&gt;&gt; indics1 = Tensor([[0, 0], [1, 1]], dtype=mstype.int64)</span>
<span class="sd">        &gt;&gt;&gt; values1 = Tensor([3, 4], dtype=mstype.int32)</span>
<span class="sd">        &gt;&gt;&gt; shape1 = (3, 4)</span>
<span class="sd">        &gt;&gt;&gt; input1 = COOTensor(indics1, values1, shape1)</span>
<span class="sd">        &gt;&gt;&gt; thres = Tensor(0, dtype=mstype.int32)</span>
<span class="sd">        &gt;&gt;&gt; out = ops.coo_add(input0, input1, thres)</span>
<span class="sd">        &gt;&gt;&gt; print(out)</span>
<span class="sd">        COOTensor(shape=[3, 4], dtype=Int32, indices=Tensor(shape=[4, 2], dtype=Int64, value=</span>
<span class="sd">        [[0 0]</span>
<span class="sd">         [0 1]</span>
<span class="sd">         [1 1]</span>
<span class="sd">         [1 2]]), values=Tensor(shape=[4], dtype=Int32, value=[3 1 4 2]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span> <span class="o">=</span> <span class="n">promote_coo</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
    <span class="n">thresh</span> <span class="o">=</span> <span class="n">thresh</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">x1</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">x1_indices</span> <span class="o">=</span> <span class="n">x1</span><span class="o">.</span><span class="n">indices</span>
    <span class="n">x1_values</span> <span class="o">=</span> <span class="n">x1</span><span class="o">.</span><span class="n">values</span>
    <span class="n">x2_indices</span> <span class="o">=</span> <span class="n">x2</span><span class="o">.</span><span class="n">indices</span>
    <span class="n">x2_values</span> <span class="o">=</span> <span class="n">x2</span><span class="o">.</span><span class="n">values</span>
    <span class="n">den_shp</span> <span class="o">=</span> <span class="n">make_tensor</span><span class="p">(</span><span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x1_indices</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">add_op</span> <span class="o">=</span> <span class="n">SparseAdd</span><span class="p">()</span>
    <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">add_op</span><span class="p">(</span><span class="n">x1_indices</span><span class="p">,</span> <span class="n">x1_values</span><span class="p">,</span> <span class="n">den_shp</span><span class="p">,</span> <span class="n">x2_indices</span><span class="p">,</span> <span class="n">x2_values</span><span class="p">,</span> <span class="n">den_shp</span><span class="p">,</span> <span class="n">thresh</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">COOTensor</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span></div>


<div class="viewcode-block" id="csr_softmax"><a class="viewcode-back" href="../../../../api_python/ops/mindspore.ops.csr_softmax.html#mindspore.ops.csr_softmax">[文档]</a><span class="k">def</span> <span class="nf">csr_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">:</span> <span class="n">CSRTensor</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">mstype</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the softmax of a CSRTensorMatrix.</span>

<span class="sd">    Args:</span>
<span class="sd">        logits (CSRTensor): Input sparse CSRTensor.</span>
<span class="sd">        dtype (dtype): Input data type.</span>

<span class="sd">    Returns:</span>
<span class="sd">        CSRTensor, a CSRTensor containing</span>

<span class="sd">        - **indptr** - Indicates the start and end point for non-zero values in each row.</span>
<span class="sd">        - **indices** - The column positions of all non-zero values of the input.</span>
<span class="sd">        - **values** - The non-zero values of the dense tensor.</span>
<span class="sd">        - **shape** - The shape of the CSRTensor.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore as ms</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.ops as ops</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.common.dtype as mstype</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import Tensor, CSRTensor</span>
<span class="sd">        &gt;&gt;&gt; logits_indptr = Tensor([0, 4, 6], dtype=mstype.int32)</span>
<span class="sd">        &gt;&gt;&gt; logits_indices = Tensor([0, 2, 3, 4, 3, 4], dtype=mstype.int32)</span>
<span class="sd">        &gt;&gt;&gt; logits_values = Tensor([1, 2, 3, 4, 1, 2], dtype=mstype.float32)</span>
<span class="sd">        &gt;&gt;&gt; shape = (2, 6)</span>
<span class="sd">        &gt;&gt;&gt; logits = CSRTensor(logits_indptr, logits_indices, logits_values, shape)</span>
<span class="sd">        &gt;&gt;&gt; out = ops.csr_softmax(logits, dtype=mstype.float32)</span>
<span class="sd">        &gt;&gt;&gt; print(out)</span>
<span class="sd">        CSRTensor(shape=[2, 6], dtype=Float32, indptr=Tensor(shape=[3], dtype=Int32, value=[0 4 6]),</span>
<span class="sd">                       indices=Tensor(shape=[6], dtype=Int32, value=[0 2 3 4 3 4]),</span>
<span class="sd">                       values=Tensor(shape=[6], dtype=Float32, value=[ 3.20586003e-02  8.71443152e-02  2.36882806e-01</span>
<span class="sd">                       6.43914223e-01  2.68941432e-01  7.31058598e-01]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">CSRTensor</span><span class="p">):</span>
        <span class="n">raise_type_error</span><span class="p">(</span><span class="s2">&quot;For functional operator sparse_matrix_softmax, logits must be type of CSRTensor.&quot;</span><span class="p">)</span>
    <span class="n">sparse_matrix_softmax_op</span> <span class="o">=</span> <span class="n">SparseMatrixSoftmax</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">logits_batch_pointers</span> <span class="o">=</span> <span class="n">make_tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">logits</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">logits_shape</span> <span class="o">=</span> <span class="n">make_tensor</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">shape</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">indptr</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="n">sparse_matrix_softmax_op</span><span class="p">(</span><span class="n">logits_shape</span><span class="p">,</span> <span class="n">logits_batch_pointers</span><span class="p">,</span> <span class="n">logits</span><span class="o">.</span><span class="n">indptr</span><span class="p">,</span>
                                                                 <span class="n">logits</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">logits</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">output_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">CSRTensor</span><span class="p">(</span><span class="n">indptr</span><span class="o">=</span><span class="n">indptr</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">output_shape</span><span class="p">)</span></div>


<div class="viewcode-block" id="csr_add"><a class="viewcode-back" href="../../../../api_python/ops/mindspore.ops.csr_add.html#mindspore.ops.csr_add">[文档]</a><span class="k">def</span> <span class="nf">csr_add</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">CSRTensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">CSRTensor</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">beta</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">CSRTensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the linear combination of two input CSRTensors a and b.</span>

<span class="sd">    .. math::</span>

<span class="sd">        out = alpha * a + beta * b</span>

<span class="sd">    where both :math:`a` and :math:`b` are CSRTensor, :math:`alpha` and :math:`beta` are both Tensor</span>

<span class="sd">    Note:</span>
<span class="sd">        The user need to ensure that the input sparse matrix is legal.</span>
<span class="sd">        Otherwise, the behavior of the operator is undefined.</span>
<span class="sd">        For example, when there are multiple elements in the same position, the</span>
<span class="sd">        operator may return an error of fail execute.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (CSRTensor): Input sparse CSRTensor.</span>
<span class="sd">        b (CSRTensor): Input sparse CSRTensor.</span>
<span class="sd">        alpha(Tensor): Dense Tensor, its shape must be able to broadcast to a.</span>
<span class="sd">        beta(Tensor): Dense Tensor, its shape must be able to broadcast to b.</span>

<span class="sd">    Returns:</span>
<span class="sd">        CSRTensor, a CSRTensor containing the following parts.</span>

<span class="sd">        - **indptr** -  Indicates the start and end point for non-zero values in each row.</span>
<span class="sd">        - **indices** - The column positions of all non-zero values of the input.</span>
<span class="sd">        - **values** - The non-zero values of the dense tensor.</span>
<span class="sd">        - **shape** - The shape of the CSRTensor.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.common.dtype as mstype</span>
<span class="sd">        &gt;&gt;&gt; from mindspore import Tensor, CSRTensor</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.ops as ops</span>
<span class="sd">        &gt;&gt;&gt; a_indptr = Tensor([0, 1, 2], dtype=mstype.int32)</span>
<span class="sd">        &gt;&gt;&gt; a_indices = Tensor([0, 1], dtype=mstype.int32)</span>
<span class="sd">        &gt;&gt;&gt; a_values = Tensor([1, 2], dtype=mstype.float32)</span>
<span class="sd">        &gt;&gt;&gt; shape = (2, 6)</span>
<span class="sd">        &gt;&gt;&gt; b_indptr = Tensor([0, 1, 2], dtype=mstype.int32)</span>
<span class="sd">        &gt;&gt;&gt; b_indices = Tensor([0, 1], dtype=mstype.int32)</span>
<span class="sd">        &gt;&gt;&gt; b_values = Tensor([1, 2], dtype=mstype.float32)</span>
<span class="sd">        &gt;&gt;&gt; alpha = Tensor(1, mstype.float32)</span>
<span class="sd">        &gt;&gt;&gt; beta = Tensor(1, mstype.float32)</span>
<span class="sd">        &gt;&gt;&gt; csra = CSRTensor(a_indptr, a_indices, a_values, shape)</span>
<span class="sd">        &gt;&gt;&gt; csrb = CSRTensor(b_indptr, b_indices, b_values, shape)</span>
<span class="sd">        &gt;&gt;&gt; out = ops.csr_add(csra, csrb, alpha, beta)</span>
<span class="sd">        &gt;&gt;&gt; print(out)</span>
<span class="sd">        CSRTensor(shape=[2, 6], dtype=Float32, \</span>
<span class="sd">                  indptr=Tensor(shape=[3], dtype=Int32, value=[0 1 2]), \</span>
<span class="sd">                  indices=Tensor(shape=[2], dtype=Int32, value=[0 1]), \</span>
<span class="sd">                  values=Tensor(shape=[2], dtype=Float32, value=[ 2.00000000e+00  4.00000000e+00]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">CSRTensor</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">CSRTensor</span><span class="p">):</span>
        <span class="n">raise_type_error</span><span class="p">(</span><span class="s2">&quot;For functional operator csr_add, both inputs a and b must be type of CSRTensor.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">raise_type_error</span><span class="p">(</span><span class="s2">&quot;For functional operator csr_add, both inputs alpha and beta must be Tensor.&quot;</span><span class="p">)</span>
    <span class="n">csr_add_op</span> <span class="o">=</span> <span class="n">SparseMatrixAdd</span><span class="p">()</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">promote_csr</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">a_batch_pointers</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">make_tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">]),</span> <span class="n">ops</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">()(</span><span class="n">a</span><span class="o">.</span><span class="n">values</span><span class="p">)))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">indptr</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">b_batch_pointers</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">make_tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">]),</span> <span class="n">ops</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">()(</span><span class="n">b</span><span class="o">.</span><span class="n">values</span><span class="p">)))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">indptr</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">a_shape</span> <span class="o">=</span> <span class="n">make_tensor</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">indptr</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">b_shape</span> <span class="o">=</span> <span class="n">make_tensor</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b</span><span class="o">.</span><span class="n">indptr</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">indptr</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="n">csr_add_op</span><span class="p">(</span><span class="n">a_shape</span><span class="p">,</span> <span class="n">a_batch_pointers</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">indptr</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                                               <span class="n">b_shape</span><span class="p">,</span> <span class="n">b_batch_pointers</span><span class="p">,</span> <span class="n">b</span><span class="o">.</span><span class="n">indptr</span><span class="p">,</span> <span class="n">b</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">b</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                                               <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">CSRTensor</span><span class="p">(</span><span class="n">indptr</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span></div>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;coalesce&#39;</span><span class="p">,</span>
    <span class="s1">&#39;coo2csr&#39;</span><span class="p">,</span>
    <span class="s1">&#39;coo_tensor_get_dense_shape&#39;</span><span class="p">,</span>
    <span class="s1">&#39;coo_tensor_get_indices&#39;</span><span class="p">,</span>
    <span class="s1">&#39;coo_tensor_get_values&#39;</span><span class="p">,</span>
    <span class="s1">&#39;csr_div&#39;</span><span class="p">,</span>
    <span class="s1">&#39;csr_gather&#39;</span><span class="p">,</span>
    <span class="s1">&#39;csr_mm&#39;</span><span class="p">,</span>
    <span class="s1">&#39;csr_mul&#39;</span><span class="p">,</span>
    <span class="s1">&#39;csr_mv&#39;</span><span class="p">,</span>
    <span class="s1">&#39;csr_reduce_sum&#39;</span><span class="p">,</span>
    <span class="s1">&#39;csr_to_coo&#39;</span><span class="p">,</span>
    <span class="s1">&#39;csr2coo&#39;</span><span class="p">,</span>
    <span class="s1">&#39;csr_tensor_get_dense_shape&#39;</span><span class="p">,</span>
    <span class="s1">&#39;csr_tensor_get_indices&#39;</span><span class="p">,</span>
    <span class="s1">&#39;csr_tensor_get_indptr&#39;</span><span class="p">,</span>
    <span class="s1">&#39;csr_tensor_get_values&#39;</span><span class="p">,</span>
    <span class="s1">&#39;dense_to_sparse_coo&#39;</span><span class="p">,</span>
    <span class="s1">&#39;dense_to_sparse_csr&#39;</span><span class="p">,</span>
    <span class="s1">&#39;make_sparse_tensor&#39;</span><span class="p">,</span>
    <span class="s1">&#39;make_coo_tensor&#39;</span><span class="p">,</span>
    <span class="s1">&#39;make_csr_tensor&#39;</span><span class="p">,</span>
    <span class="s1">&#39;make_row_tensor&#39;</span><span class="p">,</span>
    <span class="s1">&#39;make_row_tensor_inner&#39;</span><span class="p">,</span>
    <span class="s1">&#39;make_map_parameter&#39;</span><span class="p">,</span>
    <span class="s1">&#39;row_tensor_get_values&#39;</span><span class="p">,</span>
    <span class="s1">&#39;row_tensor_get_indices&#39;</span><span class="p">,</span>
    <span class="s1">&#39;row_tensor_get_dense_shape&#39;</span><span class="p">,</span>
    <span class="s1">&#39;row_tensor_add&#39;</span><span class="p">,</span>
    <span class="s1">&#39;coo_add&#39;</span><span class="p">,</span>
    <span class="s1">&#39;coo_concat&#39;</span><span class="p">,</span>
    <span class="s1">&#39;csr_add&#39;</span><span class="p">,</span>
    <span class="s1">&#39;csr_softmax&#39;</span><span class="p">,</span>
    <span class="s1">&#39;csr_to_dense&#39;</span>
<span class="p">]</span>

<span class="n">__all__</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; 版权所有 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>