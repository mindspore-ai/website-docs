

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindspore.scipy.linalg &mdash; MindSpore master 文档</title>
  

  
  <link rel="stylesheet" href="../../../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/training.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/nbsphinx-code-cells.css" type="text/css" />
   
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
        <script src="../../../_static/js/training.js"></script>
        <script src="../../../_static/translations.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">设计</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../design/overview.html">MindSpore设计概览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/programming_paradigm.html">编程范式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/auto_gradient.html">函数式微分编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/mindir.html">中间表示MindIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/all_scenarios.html">全场景统一</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/dynamic_graph_and_static_graph.html">动静态图结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/pluggable_device.html">三方硬件对接</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/distributed_training_design.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/graph_fusion_engine.html">图算融合加速引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/glossary.html">术语</a></li>
</ul>
<p class="caption"><span class="caption-text">规格</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../note/benchmark.html">基准性能</a></li>
<li class="toctree-l1"><a class="reference external" href="https://gitee.com/mindspore/models/blob/master/README_CN.md#目录">网络支持↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../note/operator_list.html">API支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../note/syntax_list.html">语法支持</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/master/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption"><span class="caption-text">API映射</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../note/api_mapping/pytorch_api_mapping.html">PyTorch与MindSpore API映射表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../note/api_mapping/tensorflow_api_mapping.html">TensorFlow与MindSpore API映射表</a></li>
</ul>
<p class="caption"><span class="caption-text">迁移指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/overview.html">迁移指南概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/enveriment_preparation.html">环境准备与资料获取</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/analysis_and_preparation.html">模型分析与准备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/model_development/model_development.html">MindSpore网络搭建</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/debug_and_tune.html">调试调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/sample_code.html">网络迁移调试实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/faq.html">常见问题</a></li>
</ul>
<p class="caption"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/installation.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/data_processing.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/implement_problem.html">执行问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/network_compilation.html">网络编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/usage_migrate_3rd.html">第三方框架迁移使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/distributed_parallel.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/feature_advice.html">特性咨询</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../index.html">模块代码</a> &raquo;</li>
        
      <li>mindspore.scipy.linalg</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>mindspore.scipy.linalg 源代码</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2021 Huawei Technologies Co., Ltd</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ============================================================================</span>
<span class="sd">&quot;&quot;&quot;Linear algebra submodule&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">LU</span>
<span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">SolveTriangular</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">_nd_transpose</span><span class="p">,</span> <span class="n">_value_check</span><span class="p">,</span> <span class="n">_type_check</span><span class="p">,</span> <span class="n">_dtype_check</span><span class="p">,</span> <span class="n">_mstype_check</span><span class="p">,</span> <span class="n">_square_check</span><span class="p">,</span> <span class="n">_solve_check</span>
<span class="kn">from</span> <span class="nn">.utils_const</span> <span class="kn">import</span> <span class="n">_raise_value_error</span>
<span class="kn">from</span> <span class="nn">..</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">mnp</span>
<span class="kn">from</span> <span class="nn">..</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">..common</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="kn">from</span> <span class="nn">..ops.operations.math_ops</span> <span class="kn">import</span> <span class="n">Cholesky</span>
<span class="kn">from</span> <span class="nn">..ops.operations.linalg_ops</span> <span class="kn">import</span> <span class="n">Eigh</span>
<span class="kn">from</span> <span class="nn">..ops</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">..ops</span> <span class="kn">import</span> <span class="n">operations</span> <span class="k">as</span> <span class="n">P</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;block_diag&#39;</span><span class="p">,</span> <span class="s1">&#39;inv&#39;</span><span class="p">,</span> <span class="s1">&#39;cho_factor&#39;</span><span class="p">,</span> <span class="s1">&#39;cholesky&#39;</span><span class="p">,</span> <span class="s1">&#39;cho_solve&#39;</span><span class="p">,</span> <span class="s1">&#39;eigh&#39;</span><span class="p">,</span> <span class="s1">&#39;lu_factor&#39;</span><span class="p">,</span> <span class="s1">&#39;lu&#39;</span><span class="p">]</span>


<div class="viewcode-block" id="block_diag"><a class="viewcode-back" href="../../../api_python/scipy/mindspore.scipy.linalg.block_diag.html#mindspore.scipy.linalg.block_diag">[文档]</a><span class="k">def</span> <span class="nf">block_diag</span><span class="p">(</span><span class="o">*</span><span class="n">arrs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a block diagonal matrix from provided arrays.</span>

<span class="sd">    Given the list of Tensors `A`, `B`, and `C`, the output will have these</span>
<span class="sd">    Tensors arranged on the diagonal:</span>

<span class="sd">    .. code-block::</span>

<span class="sd">        [[A, 0, 0],</span>
<span class="sd">         [0, B, 0],</span>
<span class="sd">         [0, 0, C]]</span>

<span class="sd">    Note:</span>
<span class="sd">        `block_diag` is not supported on Windows platform yet.</span>

<span class="sd">    Args:</span>
<span class="sd">        arrs (list): up to 2-D Input Tensors.</span>
<span class="sd">            A 1-D Tensor or a 2-D Tensor with shape :math:`(1,n)`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor with `A`, `B`, `C`, ... on the diagonal which has the same dtype as `A`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If there are Tensors with dimensions higher than 2 in all arguments.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as onp</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.common import Tensor</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.scipy.linalg import block_diag</span>
<span class="sd">        &gt;&gt;&gt; A = Tensor(onp.array([[1, 0], [0, 1]]))</span>
<span class="sd">        &gt;&gt;&gt; B = Tensor(onp.array([[3, 4, 5], [6, 7, 8]]))</span>
<span class="sd">        &gt;&gt;&gt; C = Tensor(onp.array([[7]]))</span>
<span class="sd">        &gt;&gt;&gt; P = Tensor(onp.zeros((2, ), dtype=&#39;int32&#39;))</span>
<span class="sd">        &gt;&gt;&gt; print(block_diag(A, B, C))</span>
<span class="sd">        [[1 0 0 0 0 0]</span>
<span class="sd">         [0 1 0 0 0 0]</span>
<span class="sd">         [0 0 3 4 5 0]</span>
<span class="sd">         [0 0 6 7 8 0]</span>
<span class="sd">         [0 0 0 0 0 7]]</span>
<span class="sd">        &gt;&gt;&gt; print(block_diag(A, P, B, C))</span>
<span class="sd">        [[1 0 0 0 0 0 0 0]</span>
<span class="sd">         [0 1 0 0 0 0 0 0]</span>
<span class="sd">         [0 0 0 0 0 0 0 0]</span>
<span class="sd">         [0 0 0 0 3 4 5 0]</span>
<span class="sd">         [0 0 0 0 6 7 8 0]</span>
<span class="sd">         [0 0 0 0 0 0 0 7]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">arrs</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">mnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">bad_shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">arrs</span><span class="p">)</span> <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">bad_shapes</span><span class="p">:</span>
        <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;Arguments to mindspore.scipy.linalg.block_diag must have at most 2 dimensions.&quot;</span><span class="p">)</span>

    <span class="n">accum</span> <span class="o">=</span> <span class="n">mnp</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">arrs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">arr</span> <span class="ow">in</span> <span class="n">arrs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">mnp</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Pad</span><span class="p">(((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">accum</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">)))(</span><span class="n">arr</span><span class="p">)</span>
        <span class="n">accum</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Pad</span><span class="p">(((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">c</span><span class="p">)))(</span><span class="n">accum</span><span class="p">)</span>
        <span class="n">accum</span> <span class="o">=</span> <span class="n">mnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">accum</span><span class="p">,</span> <span class="n">arr</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">accum</span></div>


<div class="viewcode-block" id="inv"><a class="viewcode-back" href="../../../api_python/scipy/mindspore.scipy.linalg.inv.html#mindspore.scipy.linalg.inv">[文档]</a><span class="k">def</span> <span class="nf">inv</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">overwrite_a</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the inverse of a matrix.</span>

<span class="sd">    Note:</span>
<span class="sd">        - `inv` is not supported on Windows platform yet.</span>
<span class="sd">        - Only `float32`, `float64`, `int32`, `int64` are supported Tensor dtypes. If Tensor with dtype `int32` or</span>
<span class="sd">          `int64` is passed, it will be cast to :class:`mstype.float64`.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Tensor): Square matrix to be inverted.</span>
<span class="sd">        overwrite_a (bool, optional): Discard data in `a` (may improve performance). Default: ``False`` .</span>
<span class="sd">        check_finite (bool, optional): Whether to check that the input matrix contains only finite numbers.</span>
<span class="sd">            Disabling may give a performance gain, but may result in problems (crashes, non-termination)</span>
<span class="sd">            if the inputs do contain infinities or NaNs. Default: ``True`` .</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, inverse of the matrix `a`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        LinAlgError: If :math:`a` is singular.</span>
<span class="sd">        ValueError: If :math:`a` is not square, or not 2D.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as onp</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.common import Tensor</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as mnp</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.scipy.linalg import inv</span>
<span class="sd">        &gt;&gt;&gt; a = Tensor(onp.array([[1., 2.], [3., 4.]]))</span>
<span class="sd">        &gt;&gt;&gt; print(inv(a))</span>
<span class="sd">        [[-2.   1. ]</span>
<span class="sd">         [ 1.5 -0.5]]</span>
<span class="sd">        &gt;&gt;&gt; print(mnp.dot(a, inv(a)))</span>
<span class="sd">        [[1.0000000e+00 0.0000000e+00]</span>
<span class="sd">         [8.8817842e-16 1.0000000e+00]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">func_name</span> <span class="o">=</span> <span class="s2">&quot;inv&quot;</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">overwrite_a</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;overwrite_a&#39;</span><span class="p">)</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">check_finite</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;check_finite&#39;</span><span class="p">)</span>
    <span class="n">_mstype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">TensorType</span><span class="p">)</span>
    <span class="n">_square_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
    <span class="n">_dtype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">matrix_inverse</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">MatrixInverse</span><span class="p">(</span><span class="n">adjoint</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">matrix_inverse</span><span class="p">(</span><span class="n">a</span><span class="p">)</span></div>


<div class="viewcode-block" id="cho_factor"><a class="viewcode-back" href="../../../api_python/scipy/mindspore.scipy.linalg.cho_factor.html#mindspore.scipy.linalg.cho_factor">[文档]</a><span class="k">def</span> <span class="nf">cho_factor</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">overwrite_a</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the cholesky decomposition of a matrix, to use in :func:`mindspore.scipy.linalg.cho_solve`.</span>

<span class="sd">    Returns a matrix containing the cholesky decomposition,</span>
<span class="sd">    :math:`a = l l*` or :math:`a = u* u` of a Hermitian positive-definite matrix `a`.</span>
<span class="sd">    The return value can be directly used as the first parameter to :func:`mindspore.scipy.linalg.cho_solve`.</span>

<span class="sd">    Note:</span>
<span class="sd">        - `cho_factor` is not supported on Windows platform yet.</span>
<span class="sd">        - Only `float32`, `float64`, `int32`, `int64` are supported Tensor dtypes. If Tensor with dtype `int32` or</span>
<span class="sd">          `int64` is passed, it will be cast to :class:`mstype.float64`.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        The returned matrix also contains random data in the entries not</span>
<span class="sd">        used by the cholesky decomposition. If you need to zero these</span>
<span class="sd">        entries, use the function `cholesky` instead.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Tensor): square Matrix of (M, M) to be decomposed.</span>
<span class="sd">        lower (bool, optional): Whether to compute the upper or lower triangular cholesky factorization.</span>
<span class="sd">            Default: ``False`` .</span>
<span class="sd">        overwrite_a(bool, optional): Whether to overwrite data in a (may improve performance). Default: ``False`` .</span>
<span class="sd">            in mindspore, this arg does not work right now.</span>
<span class="sd">        check_finite(bool, optional): Whether to check that the input matrix contains only finite numbers.</span>
<span class="sd">            Disabling may give a performance gain, but may result in problems</span>
<span class="sd">            (crashes, non-termination) if the inputs do contain infinities or NaNs. Default: ``True`` .</span>
<span class="sd">            in mindspore, this arg does not work right now.</span>

<span class="sd">    Returns:</span>
<span class="sd">         - Tensor, matrix whose upper or lower triangle contains the cholesky factor of `a`.</span>
<span class="sd">           Other parts of the matrix contain random data.</span>
<span class="sd">         - bool, flag indicating whether the factor is in the lower or upper triangle</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If input a tensor is not a square matrix or it&#39;s dims not equal to 2D.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as onp</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.common import Tensor</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.scipy.linalg import cho_factor</span>
<span class="sd">        &gt;&gt;&gt; a = Tensor(onp.array([[9, 3, 1, 5], [3, 7, 5, 1], [1, 5, 9, 2], [5, 1, 2, 6]]).astype(onp.float32))</span>
<span class="sd">        &gt;&gt;&gt; c, low = cho_factor(a)</span>
<span class="sd">        &gt;&gt;&gt; print(c)</span>
<span class="sd">        [[ 3.          1.          0.33333334  1.6666666 ]</span>
<span class="sd">         [ 3.          2.4494898   1.9051585  -0.2721655 ]</span>
<span class="sd">         [ 1.          5.          2.2933078   0.8559526 ]</span>
<span class="sd">         [ 5.          1.          2.          1.5541857 ]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">func_name</span> <span class="o">=</span> <span class="s2">&quot;cho_factor&quot;</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">overwrite_a</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;overwrite_a&#39;</span><span class="p">)</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">check_finite</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;check_finite&#39;</span><span class="p">)</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;lower&#39;</span><span class="p">)</span>
    <span class="n">_mstype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">TensorType</span><span class="p">)</span>
    <span class="n">_dtype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">])</span>
    <span class="n">_square_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">cholesky_net</span> <span class="o">=</span> <span class="n">Cholesky</span><span class="p">()</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">cholesky_net</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">lower</span><span class="p">:</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">_nd_transpose</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="n">lower</span></div>


<div class="viewcode-block" id="cholesky"><a class="viewcode-back" href="../../../api_python/scipy/mindspore.scipy.linalg.cholesky.html#mindspore.scipy.linalg.cholesky">[文档]</a><span class="k">def</span> <span class="nf">cholesky</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">overwrite_a</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the cholesky decomposition of a matrix.</span>

<span class="sd">    Returns the cholesky decomposition, :math:`a = l l^*` or</span>
<span class="sd">    :math:`a = u^* u` of a Hermitian positive-definite matrix a.</span>

<span class="sd">    Note:</span>
<span class="sd">        - `cholesky` is not supported on Windows platform yet.</span>
<span class="sd">        - Only `float32`, `float64`, `int32`, `int64` are supported Tensor dtypes. If Tensor with dtype `int32` or</span>
<span class="sd">          `int64` is passed, it will be cast to :class:`mstype.float64`.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Tensor): square Matrix of (M, M) to be decomposed.</span>
<span class="sd">        lower (bool, optional): Whether to compute the upper- or lower-triangular cholesky</span>
<span class="sd">            factorization. Default: ``False`` .</span>
<span class="sd">        overwrite_a (bool, optional): Whether to overwrite data in `a` (may improve performance). Default: ``False`` .</span>
<span class="sd">            in mindspore, this arg does not work right now.</span>
<span class="sd">        check_finite (bool, optional): Whether to check that the input matrix contains only finite numbers.</span>
<span class="sd">            Disabling may give a performance gain, but may result in problems</span>
<span class="sd">            (crashes, non-termination) if the inputs do contain infinities or NaNs. Default: ``True`` .</span>
<span class="sd">            in mindspore, this arg does not work right now.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, upper- or lower-triangular cholesky factor of `a`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If input a tensor is not a square matrix or it&#39;s dims not equal to 2D.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as onp</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.common import Tensor</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.scipy.linalg import cholesky</span>
<span class="sd">        &gt;&gt;&gt; a = Tensor(onp.array([[1, 2],[2, 5]]).astype(onp.float32))</span>
<span class="sd">        &gt;&gt;&gt; L = cholesky(a, lower=True)</span>
<span class="sd">        &gt;&gt;&gt; print(L)</span>
<span class="sd">        [[1. 0.]</span>
<span class="sd">         [2. 1.]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">func_name</span> <span class="o">=</span> <span class="s2">&quot;cholesky&quot;</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">overwrite_a</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;overwrite_a&#39;</span><span class="p">)</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">check_finite</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;check_finite&#39;</span><span class="p">)</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;lower&#39;</span><span class="p">)</span>
    <span class="n">_mstype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">TensorType</span><span class="p">)</span>
    <span class="n">_dtype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">])</span>
    <span class="n">_square_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">cholesky_net</span> <span class="o">=</span> <span class="n">Cholesky</span><span class="p">()</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">cholesky_net</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">lower</span><span class="p">:</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">_nd_transpose</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">c</span></div>


<div class="viewcode-block" id="cho_solve"><a class="viewcode-back" href="../../../api_python/scipy/mindspore.scipy.linalg.cho_solve.html#mindspore.scipy.linalg.cho_solve">[文档]</a><span class="k">def</span> <span class="nf">cho_solve</span><span class="p">(</span><span class="n">c_and_lower</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">overwrite_b</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given the cholesky factorization of a, solve the linear equation</span>

<span class="sd">    .. math::</span>
<span class="sd">        a x = b</span>

<span class="sd">    Note:</span>
<span class="sd">        - `cho_solve` is not supported on Windows platform yet.</span>
<span class="sd">        - Only `float32`, `float64`, `int32`, `int64` support Tensor dtypes. If Tensor with dtype `int32` or</span>
<span class="sd">          `int64` is passed, it will be cast to :class:`mstype.float64`.</span>

<span class="sd">    Args:</span>
<span class="sd">        c_and_lower ((Tensor, bool)): cholesky factorization of :math:`a`,</span>
<span class="sd">            as given by :func:`mindspore.scipy.linalg.cho_factor`.</span>
<span class="sd">        b (Tensor): Right-hand side.</span>
<span class="sd">        overwrite_b (bool, optional): Whether to overwrite data in :math:`b` (may improve performance).</span>
<span class="sd">            Default: ``False``.</span>
<span class="sd">        check_finite (bool, optional): Whether to check that the input matrices contain only finite numbers.</span>
<span class="sd">            Disabling may give a performance gain, but may result in problems</span>
<span class="sd">            (crashes, non-termination) if the inputs do contain infinities or NaNs. Default: ``True``.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, the solution to the system a x = b.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as onp</span>
<span class="sd">        &gt;&gt;&gt; from mindspore as ms</span>
<span class="sd">        &gt;&gt;&gt; a = ms.Tensor(onp.array([[9, 3, 1, 5], [3, 7, 5, 1], [1, 5, 9, 2], [5, 1, 2, 6]]).astype(onp.float32))</span>
<span class="sd">        &gt;&gt;&gt; b = ms.Tensor(onp.array([1, 1, 1, 1]).astype(onp.float32))</span>
<span class="sd">        &gt;&gt;&gt; c, low = ms.scipy.linalg.cho_factor(a)</span>
<span class="sd">        &gt;&gt;&gt; x = ms.scipy.linalg.cho_solve((c, low), b)</span>
<span class="sd">        &gt;&gt;&gt; print(x)</span>
<span class="sd">        [-0.01749266  0.11953348  0.01166185  0.15743434]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">func_name</span> <span class="o">=</span> <span class="s2">&quot;cho_solve&quot;</span>
    <span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">lower</span><span class="p">)</span> <span class="o">=</span> <span class="n">c_and_lower</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">overwrite_b</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;overwrite_b&#39;</span><span class="p">)</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">check_finite</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;check_finite&#39;</span><span class="p">)</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;lower&#39;</span><span class="p">)</span>
    <span class="n">_mstype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">)</span>
    <span class="n">_mstype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">)</span>
    <span class="n">_dtype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="p">[</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">],</span> <span class="s1">&#39;c&#39;</span><span class="p">)</span>
    <span class="n">_dtype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="p">[</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">],</span> <span class="s1">&#39;b&#39;</span><span class="p">)</span>
    <span class="n">_solve_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="c1"># Do not support complex, so trans is chosen from (&#39;T&#39;, &#39;N&#39;)</span>
    <span class="k">if</span> <span class="n">lower</span><span class="p">:</span>
        <span class="n">l_trans</span> <span class="o">=</span> <span class="s1">&#39;N&#39;</span>
        <span class="n">l_t_trans</span> <span class="o">=</span> <span class="s1">&#39;T&#39;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">l_trans</span> <span class="o">=</span> <span class="s1">&#39;T&#39;</span>
        <span class="n">l_t_trans</span> <span class="o">=</span> <span class="s1">&#39;N&#39;</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">SolveTriangular</span><span class="p">(</span><span class="n">lower</span><span class="o">=</span><span class="n">lower</span><span class="p">,</span> <span class="n">unit_diagonal</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><span class="n">l_trans</span><span class="p">)(</span><span class="n">c</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">SolveTriangular</span><span class="p">(</span><span class="n">lower</span><span class="o">=</span><span class="n">lower</span><span class="p">,</span> <span class="n">unit_diagonal</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><span class="n">l_t_trans</span><span class="p">)(</span><span class="n">c</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">b</span></div>


<div class="viewcode-block" id="eigh"><a class="viewcode-back" href="../../../api_python/scipy/mindspore.scipy.linalg.eigh.html#mindspore.scipy.linalg.eigh">[文档]</a><span class="k">def</span> <span class="nf">eigh</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">eigvals_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">overwrite_a</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
         <span class="n">overwrite_b</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">turbo</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">eigvals</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">check_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>  <span class="c1"># pylint: disable=W0622</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Solve a standard or generalized eigenvalue problem for a complex Hermitian or real symmetric matrix.</span>

<span class="sd">    Find eigenvalues Tensor `w` and optionally eigenvectors Tensor `v` of Tensor `a`,</span>
<span class="sd">    where `b` is positive definite such that for every eigenvalue `λ` (i-th entry of w) and</span>
<span class="sd">    its eigenvector `vi` (i-th column of `v`) satisfies::</span>

<span class="sd">                      a @ vi = λ * b @ vi</span>
<span class="sd">        vi.conj().T @ a @ vi = λ</span>
<span class="sd">        vi.conj().T @ b @ vi = 1</span>

<span class="sd">    In the standard problem, `b` is assumed to be the identity matrix.</span>

<span class="sd">    Note:</span>
<span class="sd">        - `eigh` is not supported on Windows platform yet.</span>
<span class="sd">        - Only `float32`, `float64`, `int32`, `int64` are supported Tensor dtypes. If Tensor with dtype `int32` or</span>
<span class="sd">          `int64` is passed, it will be cast to `mstype.float64`.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Tensor): A :math:`(M, M)` complex Hermitian or real symmetric matrix whose eigenvalues and</span>
<span class="sd">            eigenvectors will be computed.</span>
<span class="sd">        b (Tensor, optional): A :math:`(M, M)` complex Hermitian or real symmetric definite positive matrix in.</span>
<span class="sd">            If omitted, identity matrix is assumed. Default: ``None``.</span>
<span class="sd">        lower (bool, optional): Whether the pertinent Tensor data is taken from the lower or upper</span>
<span class="sd">            triangle of `a` and, if applicable, `b`. Default: ``True``.</span>
<span class="sd">        eigvals_only (bool, optional): Whether to calculate only eigenvalues and no eigenvectors.</span>
<span class="sd">            Default: ``False`` .</span>
<span class="sd">        type (int, optional): For the generalized problems, this keyword specifies the problem type</span>
<span class="sd">            to be solved for `w` and `v` (only takes 1, 2, 3 as possible inputs)::</span>

<span class="sd">                1 =&gt;     a @ v = w @ b @ v</span>
<span class="sd">                2 =&gt; a @ b @ v = w @ v</span>
<span class="sd">                3 =&gt; b @ a @ v = w @ v</span>

<span class="sd">            This keyword is ignored for standard problems. Default: ``1`` .</span>
<span class="sd">        overwrite_a (bool, optional): Whether to overwrite data in `a` (may improve performance). Default: ``False`` .</span>
<span class="sd">        overwrite_b (bool, optional): Whether to overwrite data in `b` (may improve performance). Default: ``False`` .</span>
<span class="sd">        check_finite (bool, optional): Whether to check that the input matrices contain only finite numbers.</span>
<span class="sd">            Disabling may give a performance gain, but may result in problems (crashes, non-termination)</span>
<span class="sd">            if the inputs do contain infinities or NaNs. Default: ``True`` .</span>
<span class="sd">        turbo (bool, optional): use divide and conquer algorithm (faster but expensive in memory, only</span>
<span class="sd">            for generalized eigenvalue problem and if full set of eigenvalues are requested.).</span>
<span class="sd">            Has no significant effect if eigenvectors are not requested. Default: ``True`` .</span>
<span class="sd">        eigvals (tuple, optional): Indexes of the smallest and largest (in ascending order) eigenvalues</span>
<span class="sd">            and corresponding eigenvectors to be returned: :math:`0 &lt;= lo &lt;= hi &lt;= M-1`. If omitted, all eigenvalues</span>
<span class="sd">            and eigenvectors are returned. Default: ``None`` .</span>

<span class="sd">    Returns:</span>
<span class="sd">        - Tensor with shape :math:`(N,)`, the :math:`N (1&lt;=N&lt;=M)` selected eigenvalues, in ascending order,</span>
<span class="sd">          each repeated according to its multiplicity.</span>

<span class="sd">        - Tensor with shape :math:`(M, N)`, if `eigvals_only == False`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: If eigenvalue computation does not converge, an error occurred, or b matrix is not</span>
<span class="sd">            definite positive. Note that if input matrices are not symmetric or Hermitian, no error will</span>
<span class="sd">            be reported but results will be wrong.</span>
<span class="sd">        TypeError: If `a` is not Tensor.</span>
<span class="sd">        TypeError: If `lower` is not bool.</span>
<span class="sd">        TypeError: If `eigvals_only` is not bool.</span>
<span class="sd">        TypeError: If `overwrite_a` is not bool.</span>
<span class="sd">        TypeError: If `overwrite_b` is not bool.</span>
<span class="sd">        TypeError: If `turbo` is not bool.</span>
<span class="sd">        TypeError: If `check_finite` is not bool.</span>
<span class="sd">        ValueError: If `a` is not square matrix.</span>
<span class="sd">        ValueError: If `b` is not None.</span>
<span class="sd">        ValueError: If `eigvals` is not None.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as onp</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.numpy as mnp</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.common import Tensor, dtype</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.scipy.linalg import eigh</span>
<span class="sd">        &gt;&gt;&gt; a = Tensor([[6, 3, 1, 5], [3, 0, 5, 1], [1, 5, 6, 2], [5, 1, 2, 2]], dtype.float64)</span>
<span class="sd">        &gt;&gt;&gt; w, v = eigh(a)</span>
<span class="sd">        &gt;&gt;&gt; print(onp.allclose(mnp.dot(a, v).asnumpy(), mnp.dot(v, mnp.diag(w)).asnumpy(), 1e-5, 1e-8))</span>
<span class="sd">        True</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">func_name</span> <span class="o">=</span> <span class="s1">&#39;eigh&#39;</span>
    <span class="n">eigh_type_check</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">_type_check</span><span class="p">,</span> <span class="n">func_name</span><span class="p">)</span>
    <span class="n">eigh_value_check</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">_value_check</span><span class="p">,</span> <span class="n">func_name</span><span class="p">)</span>

    <span class="n">eigh_type_check</span><span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;lower&#39;</span><span class="p">)</span>
    <span class="n">eigh_type_check</span><span class="p">(</span><span class="n">eigvals_only</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;eigvals_only&#39;</span><span class="p">)</span>
    <span class="n">eigh_type_check</span><span class="p">(</span><span class="n">overwrite_a</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;overwrite_a&#39;</span><span class="p">)</span>
    <span class="n">eigh_type_check</span><span class="p">(</span><span class="n">overwrite_b</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;overwrite_b&#39;</span><span class="p">)</span>
    <span class="n">eigh_type_check</span><span class="p">(</span><span class="n">turbo</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;turbo&#39;</span><span class="p">)</span>
    <span class="n">eigh_type_check</span><span class="p">(</span><span class="nb">type</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">)</span>
    <span class="n">eigh_type_check</span><span class="p">(</span><span class="n">check_finite</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;check_finite&#39;</span><span class="p">)</span>
    <span class="n">_mstype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">TensorType</span><span class="p">)</span>
    <span class="n">_dtype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span>
                 <span class="p">[</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">complex64</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">complex128</span><span class="p">])</span>
    <span class="n">_square_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
    <span class="n">eigh_value_check</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;todo&#39;</span><span class="p">)</span>
    <span class="n">eigh_value_check</span><span class="p">(</span><span class="n">eigvals</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;eigvals&#39;</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;todo&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">eigh_net</span> <span class="o">=</span> <span class="n">Eigh</span><span class="p">(</span><span class="ow">not</span> <span class="n">eigvals_only</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="n">lower</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">eigh_net</span><span class="p">(</span><span class="n">a</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">lu_pivots_to_permutation</span><span class="p">(</span><span class="n">pivots</span><span class="p">,</span> <span class="n">permutation_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;transfer pivots to permutation&quot;&quot;&quot;</span>
    <span class="n">batch_dims</span> <span class="o">=</span> <span class="n">pivots</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">pivots</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">per</span> <span class="o">=</span> <span class="n">mnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">permutation_size</span><span class="p">)</span>
    <span class="n">permutation</span> <span class="o">=</span> <span class="n">mnp</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">per</span><span class="p">,</span> <span class="n">batch_dims</span> <span class="o">+</span> <span class="p">(</span><span class="n">permutation_size</span><span class="p">,))</span>
    <span class="n">permutation</span> <span class="o">=</span> <span class="n">mnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">permutation</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">permutation_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">permutation</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="n">j</span> <span class="o">=</span> <span class="n">pivots</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">mnp</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">mnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch_dims</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[</span><span class="n">loc</span> <span class="o">+</span> <span class="p">(</span><span class="n">j</span><span class="p">,)]</span>
        <span class="n">permutation</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>
        <span class="n">permutation</span><span class="p">[</span><span class="n">loc</span> <span class="o">+</span> <span class="p">(</span><span class="n">j</span><span class="p">,)]</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">return</span> <span class="n">permutation</span>


<div class="viewcode-block" id="lu_factor"><a class="viewcode-back" href="../../../api_python/scipy/mindspore.scipy.linalg.lu_factor.html#mindspore.scipy.linalg.lu_factor">[文档]</a><span class="k">def</span> <span class="nf">lu_factor</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">overwrite_a</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute pivoted LU decomposition of a square matrix,</span>
<span class="sd">    and its outputs can be directly used as the inputs of `lu_solve`.</span>
<span class="sd">    The decomposition is:</span>

<span class="sd">    .. math::</span>
<span class="sd">        a = p l u</span>

<span class="sd">    where :math:`p` is a permutation matrix, :math:`l` lower triangular with unit diagonal elements,</span>
<span class="sd">    and :math:`u` upper triangular.</span>

<span class="sd">    Note:</span>
<span class="sd">        - `lu_factor` is not supported on Windows platform yet.</span>
<span class="sd">        - Only `float32`, `float64`, `int32`, `int64` are supported Tensor dtypes. If Tensor with dtype `int32` or</span>
<span class="sd">          `int64` is passed, it will be cast to :class:`mstype.float64`.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Tensor): square matrix of :math:`(M, M)` to decompose. Note that if the input tensor is not a `float`,</span>
<span class="sd">            then it will be cast to :class:&#39;mstype.float32&#39;.</span>
<span class="sd">        overwrite_a (bool, optional): Whether to overwrite data in :math:`a` (may increase performance).</span>
<span class="sd">            Default: ``False`` .</span>
<span class="sd">        check_finite (bool, optional): Whether to check that the input matrix contains only finite numbers.</span>
<span class="sd">            Disabling may give a performance gain, but may result in problems</span>
<span class="sd">            (crashes, non-termination) if the inputs do contain infinities or NaNs. Default: ``True`` .</span>

<span class="sd">    Returns:</span>
<span class="sd">        - Tensor, a square matrix of :math:`(N, N)` containing `U` in its upper triangle, and `L` in its lower triangle.</span>
<span class="sd">          The unit diagonal elements of `L` are not stored.</span>

<span class="sd">        - Tensor, :math:`(N,)` pivot indices representing the permutation matrix `P`:</span>
<span class="sd">          the i-th element value j in the indices indicates that row i of matrix was interchanged with row j.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If :math:`a` is not square.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as onp</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.common import Tensor</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.scipy.linalg import lu_factor</span>
<span class="sd">        &gt;&gt;&gt; a = Tensor(onp.array([[2, 5, 8, 7], [5, 2, 2, 8], [7, 5, 6, 6], [5, 4, 4, 8]]).astype(onp.float64))</span>
<span class="sd">        &gt;&gt;&gt; lu, piv = lu_factor(a)</span>
<span class="sd">        &gt;&gt;&gt; print(lu)</span>
<span class="sd">        [[ 7.          5.          6.          6.        ]</span>
<span class="sd">         [ 0.28571429  3.57142857  6.28571429  5.28571429]</span>
<span class="sd">         [ 0.71428571  0.12       -1.04        3.08      ]</span>
<span class="sd">         [ 0.71428571 -0.44       -0.46153846  7.46153846]]</span>
<span class="sd">        &gt;&gt;&gt; print(piv)</span>
<span class="sd">        [2 2 3 3]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">func_name</span> <span class="o">=</span> <span class="s2">&quot;lu_factor&quot;</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">overwrite_a</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;overwrite_a&#39;</span><span class="p">)</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">check_finite</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;check_finite&#39;</span><span class="p">)</span>
    <span class="n">_mstype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">TensorType</span><span class="p">)</span>
    <span class="n">_dtype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">])</span>
    <span class="n">_square_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">msp_lu</span> <span class="o">=</span> <span class="n">LU</span><span class="p">()</span>
    <span class="n">m_lu</span><span class="p">,</span> <span class="n">pivots</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">msp_lu</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">m_lu</span><span class="p">,</span> <span class="n">pivots</span></div>


<div class="viewcode-block" id="lu"><a class="viewcode-back" href="../../../api_python/scipy/mindspore.scipy.linalg.lu.html#mindspore.scipy.linalg.lu">[文档]</a><span class="k">def</span> <span class="nf">lu</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">permute_l</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">overwrite_a</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute pivoted LU decomposition of a general matrix.</span>

<span class="sd">    The decomposition is:</span>

<span class="sd">    .. math::</span>
<span class="sd">        a = p l u</span>

<span class="sd">    where :math:`P` is a permutation matrix, :math:`L` lower triangular with unit</span>
<span class="sd">    diagonal elements, and :math:`U` upper triangular.</span>

<span class="sd">    Note:</span>
<span class="sd">        - `lu` is not supported on Windows platform yet.</span>
<span class="sd">        - Only `float32`, `float64`, `int32`, `int64` are supported Tensor dtypes. If Tensor with dtype `int32` or</span>
<span class="sd">          `int64` is passed, it will be cast to :class:`mstype.float64`.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Tensor): a :math:`(M, N)` matrix to decompose. Note that if the input tensor is not a `float`,</span>
<span class="sd">            then it will be cast to :class:&#39;mstype.float32&#39;.</span>
<span class="sd">        permute_l (bool, optional): Perform the multiplication :math:`P L` (Default: do not permute).</span>
<span class="sd">            Default: ``False`` .</span>
<span class="sd">        overwrite_a (bool, optional): Whether to overwrite data in :math:`a` (may improve performance).</span>
<span class="sd">            Default: ``False`` .</span>
<span class="sd">        check_finite (bool, optional):  Whether to check that the input matrix contains</span>
<span class="sd">            only finite numbers. Disabling may give a performance gain, but may result</span>
<span class="sd">            in problems (crashes, non-termination) if the inputs do contain infinities or NaNs. Default: ``True`` .</span>

<span class="sd">    Returns:</span>
<span class="sd">        **If permute_l == False**</span>

<span class="sd">        - Tensor, :math:`(M, M)` permutation matrix.</span>
<span class="sd">        - Tensor, :math:`(M, K)` lower triangular or trapezoidal matrix with unit diagonal. :math:`K = min(M, N)`.</span>
<span class="sd">        - Tensor, :math:`(K, N)` upper triangular or trapezoidal matrix.</span>

<span class="sd">        **If permute_l == True**</span>

<span class="sd">        - Tensor, :math:`(M, K)` permuted L matrix. :math:`K = min(M, N)`.</span>
<span class="sd">        - Tensor, :math:`(K, N)` upper triangular or trapezoidal matrix.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as onp</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.common import Tensor</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.scipy.linalg import lu</span>
<span class="sd">        &gt;&gt;&gt; a = Tensor(onp.array([[2, 5, 8, 7], [5, 2, 2, 8], [7, 5, 6, 6], [5, 4, 4, 8]]).astype(onp.float64))</span>
<span class="sd">        &gt;&gt;&gt; p, l, u = lu(a)</span>
<span class="sd">        &gt;&gt;&gt; print(p)</span>
<span class="sd">        [[0 1 0 0]</span>
<span class="sd">         [0 0 0 1]</span>
<span class="sd">         [1 0 0 0]</span>
<span class="sd">         [0 0 1 0]]</span>
<span class="sd">        &gt;&gt;&gt; print(l)</span>
<span class="sd">        [[ 1.          0.          0.          0.        ]</span>
<span class="sd">         [ 0.2857143   1.          0.          0.        ]</span>
<span class="sd">         [ 0.71428573  0.12        1.          0.        ]</span>
<span class="sd">         [ 0.71428573 -0.44       -0.46153846  1.        ]]</span>
<span class="sd">        &gt;&gt;&gt; print(u)</span>
<span class="sd">        [[ 7.          5.          6.          6.        ]</span>
<span class="sd">         [ 0.          3.57142854  6.28571415  5.28571415]</span>
<span class="sd">         [ 0.          0.         -1.03999996  3.07999992]</span>
<span class="sd">         [ 0.         -0.         -0.          7.46153831]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">func_name</span> <span class="o">=</span> <span class="s2">&quot;lu&quot;</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">permute_l</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;permute_l&#39;</span><span class="p">)</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">overwrite_a</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;overwrite_a&#39;</span><span class="p">)</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">check_finite</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;check_finite&#39;</span><span class="p">)</span>
    <span class="n">_mstype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">TensorType</span><span class="p">)</span>
    <span class="n">_dtype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">])</span>
    <span class="n">_value_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;dimension&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="n">msp_lu</span> <span class="o">=</span> <span class="n">LU</span><span class="p">()</span>
    <span class="n">m_lu</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">msp_lu</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">m</span> <span class="o">&gt;</span> <span class="n">n</span><span class="p">:</span>
        <span class="n">_raise_value_error</span><span class="p">(</span><span class="s2">&quot;last two dimensions of LU decomposition must be row less or equal to col.&quot;</span><span class="p">)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">l</span> <span class="o">=</span> <span class="n">mnp</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">m_lu</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">mnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">mnp</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">m_lu</span><span class="p">)[:</span><span class="n">k</span><span class="p">,</span> <span class="p">:]</span>
    <span class="k">if</span> <span class="n">permute_l</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">mnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">l</span><span class="p">),</span> <span class="n">u</span>
    <span class="k">return</span> <span class="n">p</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">u</span></div>


<span class="k">def</span> <span class="nf">lu_solve</span><span class="p">(</span><span class="n">lu_and_piv</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">overwrite_b</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Solve an equation system, a x = b, given the LU factorization of a</span>

<span class="sd">    Note:</span>
<span class="sd">        - `lu_solve` is not supported on Windows platform yet.</span>
<span class="sd">        - Only `float32`, `float64`, `int32`, `int64` are supported Tensor dtypes. If Tensor with dtype `int32` or</span>
<span class="sd">          `int64` is passed, it will be cast to :class:`mstype.float64`.</span>

<span class="sd">    Args:</span>
<span class="sd">        lu_and_piv (Tensor, Tensor): Factorization of the coefficient matrix a, as given by lu_factor</span>
<span class="sd">        b (Tensor): Right-hand side</span>
<span class="sd">        trans (int, optional): {0, 1, 2}</span>
<span class="sd">            Type of system to solve:</span>
<span class="sd">            =====  =========</span>
<span class="sd">            trans  system</span>
<span class="sd">            =====  =========</span>
<span class="sd">            0      a x   = b</span>
<span class="sd">            1      a^T x = b</span>
<span class="sd">            2      a^H x = b</span>
<span class="sd">            =====  =========</span>
<span class="sd">        overwrite_b (bool, optional): Whether to overwrite data in b (may increase performance)</span>
<span class="sd">        check_finite ( bool, optional): Whether to check that the input matrices contain only finite numbers.</span>
<span class="sd">            Disabling may give a performance gain, but may result in problems (crashes, non-termination)</span>
<span class="sd">            if the inputs do contain infinities or NaNs.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, solution to the system</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``GPU`` ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as onp</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.common import Tensor</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.scipy.linalg import lu_factor, lu_solve</span>
<span class="sd">        &gt;&gt;&gt; a = Tensor(onp.array([[2, 5, 8, 7], [5, 2, 2, 8], [7, 5, 6, 6], [5, 4, 4, 8]]).astype(onp.float64))</span>
<span class="sd">        &gt;&gt;&gt; b = Tensor(onp.array([1, 1, 1, 1]).astype(onp.float64))</span>
<span class="sd">        &gt;&gt;&gt; lu, piv = lu_factor(a)</span>
<span class="sd">        &gt;&gt;&gt; print(lu_solve((lu, piv), b))</span>
<span class="sd">        [ 0.05154639, -0.08247423,  0.08247423,  0.09278351]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">func_name</span> <span class="o">=</span> <span class="s2">&quot;lu_solve&quot;</span>
    <span class="n">lu_matrix</span><span class="p">,</span> <span class="n">pivot</span> <span class="o">=</span> <span class="n">lu_and_piv</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">overwrite_b</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;overwrite_b&#39;</span><span class="p">)</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">check_finite</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;check_finite&#39;</span><span class="p">)</span>
    <span class="n">_mstype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">lu_matrix</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span> <span class="s1">&#39;lu_matrix&#39;</span><span class="p">)</span>
    <span class="n">_mstype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">)</span>
    <span class="n">_mstype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">TensorType</span><span class="p">,</span> <span class="s1">&#39;pivot&#39;</span><span class="p">)</span>
    <span class="n">_dtype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">lu_matrix</span><span class="p">,</span> <span class="p">[</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">],</span> <span class="s1">&#39;lu_matrix&#39;</span><span class="p">)</span>
    <span class="n">_dtype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="p">[</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">],</span> <span class="s1">&#39;b&#39;</span><span class="p">)</span>
    <span class="n">_dtype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">pivot</span><span class="p">,</span> <span class="p">[</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">],</span> <span class="s1">&#39;pivot&#39;</span><span class="p">)</span>
    <span class="n">_solve_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">lu_matrix</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="s1">&#39;lu_matrix&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">)</span>
    <span class="n">_value_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">pivot</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;pivot&#39;</span><span class="p">,</span> <span class="s1">&#39;dimension&#39;</span><span class="p">)</span>
    <span class="n">_value_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">lu_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">pivot</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s1">&#39;lu_matrix&#39;</span><span class="p">,</span> <span class="s1">&#39;pivot&#39;</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="s1">&#39;solve&#39;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;solve&#39;</span><span class="p">)</span>
    <span class="n">_value_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">trans</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;trans&#39;</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">lu_matrix</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
        <span class="n">lu_matrix</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">lu_matrix</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="n">permutation</span> <span class="o">=</span> <span class="n">lu_pivots_to_permutation</span><span class="p">(</span><span class="n">pivot</span><span class="p">,</span> <span class="n">pivot</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
    <span class="n">rhs_vector</span> <span class="o">=</span> <span class="n">lu_matrix</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="n">b</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">permutation</span><span class="p">,</span> <span class="p">:]</span>
    <span class="k">if</span> <span class="n">trans</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">SolveTriangular</span><span class="p">(</span><span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">unit_diagonal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><span class="s1">&#39;N&#39;</span><span class="p">)(</span><span class="n">lu_matrix</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">SolveTriangular</span><span class="p">(</span><span class="n">lower</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">unit_diagonal</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><span class="s1">&#39;N&#39;</span><span class="p">)(</span><span class="n">lu_matrix</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">SolveTriangular</span><span class="p">(</span><span class="n">lower</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">unit_diagonal</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)(</span><span class="n">lu_matrix</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">SolveTriangular</span><span class="p">(</span><span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">unit_diagonal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><span class="s1">&#39;T&#39;</span><span class="p">)(</span><span class="n">lu_matrix</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">mnp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">rhs_vector</span> <span class="k">else</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">_det_2x2</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span>
            <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">_det_3x3</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">+</span>
            <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span>
            <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span>
            <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span>
            <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span>
            <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">det</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">overwrite_a</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the determinant of a matrix</span>

<span class="sd">    The determinant of a square matrix is a value derived arithmetically</span>
<span class="sd">    from the coefficients of the matrix.</span>

<span class="sd">    The determinant for a 3x3 matrix, for example, is computed as follows::</span>

<span class="sd">        a    b    c</span>
<span class="sd">        d    e    f = A</span>
<span class="sd">        g    h    i</span>

<span class="sd">        det(A) = a*e*i + b*f*g + c*d*h - c*e*g - b*d*i - a*f*h</span>

<span class="sd">    Note:</span>
<span class="sd">        - `det` is not supported on Windows platform yet.</span>
<span class="sd">        - Only `float32`, `float64`, `int32`, `int64` are supported Tensor dtypes. If Tensor with dtype `int32` or</span>
<span class="sd">          `int64` is passed, it will be cast to :class:`mstype.float64`.</span>

<span class="sd">    Args:</span>
<span class="sd">        a (Tensor): A square matrix to compute. Note that if the input tensor is not a `float`,</span>
<span class="sd">            then it will be cast to :class:`mstype.float32`.</span>
<span class="sd">        overwrite_a (bool, optional): Allow overwriting data in a (may enhance performance).</span>
<span class="sd">        check_finite (bool, optional): Whether to check that the input matrix contains</span>
<span class="sd">            only finite numbers.</span>
<span class="sd">            Disabling may give a performance gain, but may result in problems</span>
<span class="sd">            (crashes, non-termination) if the inputs do contain infinities or NaNs.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If :math:`a` is not square.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor, Determinant of `a`.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as onp</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.common import Tensor</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.scipy.linalg import det</span>
<span class="sd">        &gt;&gt;&gt; a = Tensor(onp.array([[0, 2, 3], [4, 5, 6], [7, 8, 9]])).astype(onp.float64)</span>
<span class="sd">        &gt;&gt;&gt; print(det(a))</span>
<span class="sd">        3.0</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">func_name</span> <span class="o">=</span> <span class="s2">&quot;det&quot;</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">overwrite_a</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;overwrite_a&#39;</span><span class="p">)</span>
    <span class="n">_type_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">check_finite</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="s1">&#39;check_finite&#39;</span><span class="p">)</span>
    <span class="n">_mstype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">TensorType</span><span class="p">)</span>
    <span class="n">_square_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
    <span class="n">_dtype_check</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="c1"># special case</span>
    <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_det_2x2</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_det_3x3</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="n">lu_matrix</span><span class="p">,</span> <span class="n">pivot</span> <span class="o">=</span> <span class="n">lu_factor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">diag</span> <span class="o">=</span> <span class="n">lu_matrix</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">axis1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">pivot_not_equal</span> <span class="o">=</span> <span class="p">(</span><span class="n">pivot</span> <span class="o">!=</span> <span class="n">mnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">pivot_sign</span> <span class="o">=</span> <span class="n">mnp</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">pivot_not_equal</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sign</span> <span class="o">=</span> <span class="o">-</span><span class="mf">2.</span> <span class="o">*</span> <span class="p">(</span><span class="n">pivot_sign</span> <span class="o">%</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.</span>
    <span class="k">return</span> <span class="n">sign</span> <span class="o">*</span> <span class="n">P</span><span class="o">.</span><span class="n">ReduceProd</span><span class="p">(</span><span class="n">keep_dims</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span><span class="n">diag</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; 版权所有 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>