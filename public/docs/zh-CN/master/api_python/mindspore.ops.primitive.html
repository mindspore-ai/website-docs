

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindspore.ops.primitive &mdash; MindSpore master 文档</title>
  

  
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/js/training.js"></script>
        <script src="../_static/translations.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="mindspore.ops.Primitive" href="ops/mindspore.ops.Primitive.html" />
    <link rel="prev" title="mindspore.ops.csr_tanh" href="ops/mindspore.ops.csr_tanh.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">设计</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../design/overview.html">MindSpore设计概览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/programming_paradigm.html">编程范式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/auto_gradient.html">函数式微分编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/mindir.html">中间表示MindIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/all_scenarios.html">全场景统一</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/dynamic_graph_and_static_graph.html">动静态图结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/pluggable_device.html">三方硬件对接</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/distributed_training_design.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/graph_fusion_engine.html">图算融合加速引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/glossary.html">术语</a></li>
</ul>
<p class="caption"><span class="caption-text">规格</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/benchmark.html">基准性能</a></li>
<li class="toctree-l1"><a class="reference external" href="https://gitee.com/mindspore/models/blob/master/README_CN.md#目录">网络支持↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/operator_list.html">API支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/syntax_list.html">语法支持</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindspore.ops.primitive</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#算子原语">算子原语</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.Primitive.html">mindspore.ops.Primitive</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.PrimitiveWithCheck.html">mindspore.ops.PrimitiveWithCheck</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.PrimitiveWithInfer.html">mindspore.ops.PrimitiveWithInfer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#装饰器">装饰器</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.constexpr.html">mindspore.ops.constexpr</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.custom_info_register.html">mindspore.ops.custom_info_register</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.kernel.html">mindspore.ops.kernel</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.op_info_register.html">mindspore.ops.op_info_register</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.prim_attr_register.html">mindspore.ops.prim_attr_register</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#神经网络层算子">神经网络层算子</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#神经网络">神经网络</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.AvgPool.html">mindspore.ops.AvgPool</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.AvgPool3D.html">mindspore.ops.AvgPool3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BatchNorm.html">mindspore.ops.BatchNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Conv2D.html">mindspore.ops.Conv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Conv2DTranspose.html">mindspore.ops.Conv2DTranspose</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Conv3D.html">mindspore.ops.Conv3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Conv3DTranspose.html">mindspore.ops.Conv3DTranspose</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.CTCGreedyDecoder.html">mindspore.ops.CTCGreedyDecoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Dropout.html">mindspore.ops.Dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Dropout2D.html">mindspore.ops.Dropout2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Dropout3D.html">mindspore.ops.Dropout3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.DynamicGRUV2.html">mindspore.ops.DynamicGRUV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.DynamicRNN.html">mindspore.ops.DynamicRNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.EmbeddingLookup.html">mindspore.ops.EmbeddingLookup</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Flatten.html">mindspore.ops.Flatten</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.GridSampler2D.html">mindspore.ops.GridSampler2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.GridSampler3D.html">mindspore.ops.GridSampler3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.LayerNorm.html">mindspore.ops.LayerNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.LRN.html">mindspore.ops.LRN</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.LSTM.html">mindspore.ops.LSTM</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MaxPool.html">mindspore.ops.MaxPool</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MaxPool3D.html">mindspore.ops.MaxPool3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MaxPool3DWithArgmax.html">mindspore.ops.MaxPool3DWithArgmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MaxPoolWithArgmax.html">mindspore.ops.MaxPoolWithArgmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MaxPoolWithArgmaxV2.html">mindspore.ops.MaxPoolWithArgmaxV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MaxUnpool2D.html">mindspore.ops.MaxUnpool2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MaxUnpool3D.html">mindspore.ops.MaxUnpool3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MirrorPad.html">mindspore.ops.MirrorPad</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Pad.html">mindspore.ops.Pad</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Padding.html">mindspore.ops.Padding</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ResizeBicubic.html">mindspore.ops.ResizeBicubic</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ResizeBilinear.html">mindspore.ops.ResizeBilinear</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ResizeNearestNeighbor.html">mindspore.ops.ResizeNearestNeighbor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#损失函数">损失函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BCEWithLogitsLoss.html">mindspore.ops.BCEWithLogitsLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BinaryCrossEntropy.html">mindspore.ops.BinaryCrossEntropy</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.CTCLoss.html">mindspore.ops.CTCLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.CTCLossV2.html">mindspore.ops.CTCLossV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.KLDivLoss.html">mindspore.ops.KLDivLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.L2Loss.html">mindspore.ops.L2Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MultilabelMarginLoss.html">mindspore.ops.MultilabelMarginLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MultiMarginLoss.html">mindspore.ops.MultiMarginLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.NLLLoss.html">mindspore.ops.NLLLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.RNNTLoss.html">mindspore.ops.RNNTLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SigmoidCrossEntropyWithLogits.html">mindspore.ops.SigmoidCrossEntropyWithLogits</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SmoothL1Loss.html">mindspore.ops.SmoothL1Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SoftMarginLoss.html">mindspore.ops.SoftMarginLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SoftmaxCrossEntropyWithLogits.html">mindspore.ops.SoftmaxCrossEntropyWithLogits</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SparseSoftmaxCrossEntropyWithLogits.html">mindspore.ops.SparseSoftmaxCrossEntropyWithLogits</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.TripletMarginLoss.html">mindspore.ops.TripletMarginLoss</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#激活函数">激活函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Elu.html">mindspore.ops.Elu</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.FastGeLU.html">mindspore.ops.FastGeLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.GeLU.html">mindspore.ops.GeLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.GLU.html">mindspore.ops.GLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.HShrink.html">mindspore.ops.HShrink</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.HSigmoid.html">mindspore.ops.HSigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.HSwish.html">mindspore.ops.HSwish</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.LogSoftmax.html">mindspore.ops.LogSoftmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Mish.html">mindspore.ops.Mish</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.PReLU.html">mindspore.ops.PReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ReLU.html">mindspore.ops.ReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ReLU6.html">mindspore.ops.ReLU6</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SeLU.html">mindspore.ops.SeLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Sigmoid.html">mindspore.ops.Sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Softmax.html">mindspore.ops.Softmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Softplus.html">mindspore.ops.Softplus</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SoftShrink.html">mindspore.ops.SoftShrink</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Softsign.html">mindspore.ops.Softsign</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Tanh.html">mindspore.ops.Tanh</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#优化器">优化器</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Adam.html">mindspore.ops.Adam</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.AdamWeightDecay.html">mindspore.ops.AdamWeightDecay</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.AdaptiveAvgPool2D.html">mindspore.ops.AdaptiveAvgPool2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.AdaptiveAvgPool3D.html">mindspore.ops.AdaptiveAvgPool3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ApplyAdadelta.html">mindspore.ops.ApplyAdadelta</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ApplyAdagrad.html">mindspore.ops.ApplyAdagrad</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ApplyAdagradDA.html">mindspore.ops.ApplyAdagradDA</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ApplyAdagradV2.html">mindspore.ops.ApplyAdagradV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ApplyAdaMax.html">mindspore.ops.ApplyAdaMax</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ApplyAddSign.html">mindspore.ops.ApplyAddSign</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ApplyCenteredRMSProp.html">mindspore.ops.ApplyCenteredRMSProp</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ApplyFtrl.html">mindspore.ops.ApplyFtrl</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ApplyGradientDescent.html">mindspore.ops.ApplyGradientDescent</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ApplyMomentum.html">mindspore.ops.ApplyMomentum</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ApplyPowerSign.html">mindspore.ops.ApplyPowerSign</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ApplyProximalAdagrad.html">mindspore.ops.ApplyProximalAdagrad</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ApplyProximalGradientDescent.html">mindspore.ops.ApplyProximalGradientDescent</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ApplyRMSProp.html">mindspore.ops.ApplyRMSProp</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.LARSUpdate.html">mindspore.ops.LARSUpdate</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SparseApplyAdagradV2.html">mindspore.ops.SparseApplyAdagradV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SparseApplyProximalAdagrad.html">mindspore.ops.SparseApplyProximalAdagrad</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SGD.html">mindspore.ops.SGD</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SparseApplyFtrl.html">mindspore.ops.SparseApplyFtrl</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SparseApplyFtrlV2.html">mindspore.ops.SparseApplyFtrlV2</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#距离函数">距离函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Cdist.html">mindspore.ops.Cdist</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.EditDistance.html">mindspore.ops.EditDistance</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.LpNorm.html">mindspore.ops.LpNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Pdist.html">mindspore.ops.Pdist</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#采样算子">采样算子</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ComputeAccidentalHits.html">mindspore.ops.ComputeAccidentalHits</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.LogUniformCandidateSampler.html">mindspore.ops.LogUniformCandidateSampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.UniformCandidateSampler.html">mindspore.ops.UniformCandidateSampler</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#图像处理">图像处理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BoundingBoxDecode.html">mindspore.ops.BoundingBoxDecode</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BoundingBoxEncode.html">mindspore.ops.BoundingBoxEncode</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.CheckValid.html">mindspore.ops.CheckValid</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.CropAndResize.html">mindspore.ops.CropAndResize</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ExtractVolumePatches.html">mindspore.ops.ExtractVolumePatches</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.IOU.html">mindspore.ops.IOU</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.L2Normalize.html">mindspore.ops.L2Normalize</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.NMSWithMask.html">mindspore.ops.NMSWithMask</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ResizeBilinearV2.html">mindspore.ops.ResizeBilinearV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ROIAlign.html">mindspore.ops.ROIAlign</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#文本处理">文本处理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.NoRepeatNGram.html">mindspore.ops.NoRepeatNGram</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#数学运算算子">数学运算算子</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.Bincount.html">mindspore.ops.Bincount</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.Cholesky.html">mindspore.ops.Cholesky</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.Complex.html">mindspore.ops.Complex</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.ComplexAbs.html">mindspore.ops.ComplexAbs</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.Cross.html">mindspore.ops.Cross</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.Gcd.html">mindspore.ops.Gcd</a></li>
<li class="toctree-l3"><a class="reference internal" href="#逐元素运算">逐元素运算</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Abs.html">mindspore.ops.Abs</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.AccumulateNV2.html">mindspore.ops.AccumulateNV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ACos.html">mindspore.ops.ACos</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Acosh.html">mindspore.ops.Acosh</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Add.html">mindspore.ops.Add</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Addcdiv.html">mindspore.ops.Addcdiv</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Addcmul.html">mindspore.ops.Addcmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.AddN.html">mindspore.ops.AddN</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Angle.html">mindspore.ops.Angle</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Asin.html">mindspore.ops.Asin</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Asinh.html">mindspore.ops.Asinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Atan.html">mindspore.ops.Atan</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Atan2.html">mindspore.ops.Atan2</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Atanh.html">mindspore.ops.Atanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BesselI0.html">mindspore.ops.BesselI0</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BesselI0e.html">mindspore.ops.BesselI0e</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BesselI1.html">mindspore.ops.BesselI1</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BesselI1e.html">mindspore.ops.BesselI1e</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BesselJ0.html">mindspore.ops.BesselJ0</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BesselJ1.html">mindspore.ops.BesselJ1</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BesselK0.html">mindspore.ops.BesselK0</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BesselK0e.html">mindspore.ops.BesselK0e</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BesselK1.html">mindspore.ops.BesselK1</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BesselK1e.html">mindspore.ops.BesselK1e</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BesselY0.html">mindspore.ops.BesselY0</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BesselY1.html">mindspore.ops.BesselY1</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BitwiseAnd.html">mindspore.ops.BitwiseAnd</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BitwiseOr.html">mindspore.ops.BitwiseOr</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BitwiseXor.html">mindspore.ops.BitwiseXor</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Ceil.html">mindspore.ops.Ceil</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Conj.html">mindspore.ops.Conj</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Cos.html">mindspore.ops.Cos</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Cosh.html">mindspore.ops.Cosh</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Digamma.html">mindspore.ops.Digamma</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Div.html">mindspore.ops.Div</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.DivNoNan.html">mindspore.ops.DivNoNan</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Einsum.html">mindspore.ops.Einsum</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Erf.html">mindspore.ops.Erf</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Erfc.html">mindspore.ops.Erfc</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Erfinv.html">mindspore.ops.Erfinv</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Exp.html">mindspore.ops.Exp</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Expm1.html">mindspore.ops.Expm1</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Floor.html">mindspore.ops.Floor</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.FloorDiv.html">mindspore.ops.FloorDiv</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.FloorMod.html">mindspore.ops.FloorMod</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Geqrf.html">mindspore.ops.Geqrf</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Imag.html">mindspore.ops.Imag</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Inv.html">mindspore.ops.Inv</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Invert.html">mindspore.ops.Invert</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Lerp.html">mindspore.ops.Lerp</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Log.html">mindspore.ops.Log</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Log1p.html">mindspore.ops.Log1p</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.LogicalAnd.html">mindspore.ops.LogicalAnd</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.LogicalNot.html">mindspore.ops.LogicalNot</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.LogicalOr.html">mindspore.ops.LogicalOr</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.LogicalXor.html">mindspore.ops.LogicalXor</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Logit.html">mindspore.ops.Logit</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Mod.html">mindspore.ops.Mod</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Mul.html">mindspore.ops.Mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MulNoNan.html">mindspore.ops.MulNoNan</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Neg.html">mindspore.ops.Neg</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.NextAfter.html">mindspore.ops.NextAfter</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Polar.html">mindspore.ops.Polar</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Polygamma.html">mindspore.ops.Polygamma</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Pow.html">mindspore.ops.Pow</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Real.html">mindspore.ops.Real</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.RealDiv.html">mindspore.ops.RealDiv</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Reciprocal.html">mindspore.ops.Reciprocal</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Rint.html">mindspore.ops.Rint</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Round.html">mindspore.ops.Round</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Rsqrt.html">mindspore.ops.Rsqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Sign.html">mindspore.ops.Sign</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Sin.html">mindspore.ops.Sin</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Sinc.html">mindspore.ops.Sinc</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Sinh.html">mindspore.ops.Sinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Sqrt.html">mindspore.ops.Sqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Square.html">mindspore.ops.Square</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SquaredDifference.html">mindspore.ops.SquaredDifference</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SquareSumAll.html">mindspore.ops.SquareSumAll</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Sub.html">mindspore.ops.Sub</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Tan.html">mindspore.ops.Tan</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Trunc.html">mindspore.ops.Trunc</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.TruncateDiv.html">mindspore.ops.TruncateDiv</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.TruncateMod.html">mindspore.ops.TruncateMod</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Xdivy.html">mindspore.ops.Xdivy</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Xlogy.html">mindspore.ops.Xlogy</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#reduction算子">Reduction算子</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Argmax.html">mindspore.ops.Argmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ArgMaxWithValue.html">mindspore.ops.ArgMaxWithValue</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Argmin.html">mindspore.ops.Argmin</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ArgMinWithValue.html">mindspore.ops.ArgMinWithValue</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Median.html">mindspore.ops.Median</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ReduceAll.html">mindspore.ops.ReduceAll</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ReduceAny.html">mindspore.ops.ReduceAny</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ReduceMax.html">mindspore.ops.ReduceMax</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ReduceMean.html">mindspore.ops.ReduceMean</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ReduceMin.html">mindspore.ops.ReduceMin</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ReduceProd.html">mindspore.ops.ReduceProd</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ReduceSum.html">mindspore.ops.ReduceSum</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#比较算子">比较算子</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ApproximateEqual.html">mindspore.ops.ApproximateEqual</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Equal.html">mindspore.ops.Equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.EqualCount.html">mindspore.ops.EqualCount</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Greater.html">mindspore.ops.Greater</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.GreaterEqual.html">mindspore.ops.GreaterEqual</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.InTopK.html">mindspore.ops.InTopK</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.IsFinite.html">mindspore.ops.IsFinite</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.IsInf.html">mindspore.ops.IsInf</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.IsNan.html">mindspore.ops.IsNan</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Less.html">mindspore.ops.Less</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.LessEqual.html">mindspore.ops.LessEqual</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Maximum.html">mindspore.ops.Maximum</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Minimum.html">mindspore.ops.Minimum</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.NotEqual.html">mindspore.ops.NotEqual</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.TopK.html">mindspore.ops.TopK</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#线性代数算子">线性代数算子</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BatchMatMul.html">mindspore.ops.BatchMatMul</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BiasAdd.html">mindspore.ops.BiasAdd</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Ger.html">mindspore.ops.Ger</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MatMul.html">mindspore.ops.MatMul</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MatrixInverse.html">mindspore.ops.MatrixInverse</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Orgqr.html">mindspore.ops.Orgqr</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Svd.html">mindspore.ops.Svd</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#tensor操作算子">Tensor操作算子</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#tensor创建">Tensor创建</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Eps.html">mindspore.ops.Eps</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Eye.html">mindspore.ops.Eye</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Fill.html">mindspore.ops.Fill</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.LinSpace.html">mindspore.ops.LinSpace</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.OneHot.html">mindspore.ops.OneHot</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Ones.html">mindspore.ops.Ones</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.OnesLike.html">mindspore.ops.OnesLike</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Zeros.html">mindspore.ops.Zeros</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ZerosLike.html">mindspore.ops.ZerosLike</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#随机生成算子">随机生成算子</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Bernoulli.html">mindspore.ops.Bernoulli</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Gamma.html">mindspore.ops.Gamma</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Multinomial.html">mindspore.ops.Multinomial</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MultinomialWithReplacement.html">mindspore.ops.MultinomialWithReplacement</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.RandomCategorical.html">mindspore.ops.RandomCategorical</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.RandomChoiceWithMask.html">mindspore.ops.RandomChoiceWithMask</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.RandomGamma.html">mindspore.ops.RandomGamma</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.RandomPoisson.html">mindspore.ops.RandomPoisson</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Randperm.html">mindspore.ops.Randperm</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.StandardLaplace.html">mindspore.ops.StandardLaplace</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.StandardNormal.html">mindspore.ops.StandardNormal</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.UniformInt.html">mindspore.ops.UniformInt</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.UniformReal.html">mindspore.ops.UniformReal</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#array操作">Array操作</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.AffineGrid.html">mindspore.ops.AffineGrid</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BatchToSpace.html">mindspore.ops.BatchToSpace</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BatchToSpaceND.html">mindspore.ops.BatchToSpaceND</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.BroadcastTo.html">mindspore.ops.BroadcastTo</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Cast.html">mindspore.ops.Cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ChannelShuffle.html">mindspore.ops.ChannelShuffle</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Col2Im.html">mindspore.ops.Col2Im</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Concat.html">mindspore.ops.Concat</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Cummax.html">mindspore.ops.Cummax</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Cummin.html">mindspore.ops.Cummin</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.CumProd.html">mindspore.ops.CumProd</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.CumSum.html">mindspore.ops.CumSum</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.DataFormatDimMap.html">mindspore.ops.DataFormatDimMap</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.DepthToSpace.html">mindspore.ops.DepthToSpace</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Diag.html">mindspore.ops.Diag</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.DType.html">mindspore.ops.DType</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Eig.html">mindspore.ops.Eig</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Expand.html">mindspore.ops.Expand</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ExpandDims.html">mindspore.ops.ExpandDims</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.FillV2.html">mindspore.ops.FillV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.FloatStatus.html">mindspore.ops.FloatStatus</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Fmax.html">mindspore.ops.Fmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Gather.html">mindspore.ops.Gather</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.GatherD.html">mindspore.ops.GatherD</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.GatherNd.html">mindspore.ops.GatherNd</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.HammingWindow.html">mindspore.ops.HammingWindow</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Heaviside.html">mindspore.ops.Heaviside</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.HistogramFixedWidth.html">mindspore.ops.HistogramFixedWidth</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Hypot.html">mindspore.ops.Hypot</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Identity.html">mindspore.ops.Identity</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Igamma.html">mindspore.ops.Igamma</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Im2Col.html">mindspore.ops.Im2Col</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.IndexAdd.html">mindspore.ops.IndexAdd</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.IndexFill.html">mindspore.ops.IndexFill</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.InplaceAdd.html">mindspore.ops.InplaceAdd</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.InplaceIndexAdd.html">mindspore.ops.InplaceIndexAdd</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.InplaceSub.html">mindspore.ops.InplaceSub</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.InplaceUpdate.html">mindspore.ops.InplaceUpdate</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.InplaceUpdateV2.html">mindspore.ops.InplaceUpdateV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.InvertPermutation.html">mindspore.ops.InvertPermutation</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.IsClose.html">mindspore.ops.IsClose</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Lcm.html">mindspore.ops.Lcm</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.LeftShift.html">mindspore.ops.LeftShift</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.LogSpace.html">mindspore.ops.LogSpace</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.LuUnpack.html">mindspore.ops.LuUnpack</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MaskedFill.html">mindspore.ops.MaskedFill</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MaskedSelect.html">mindspore.ops.MaskedSelect</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MatrixBandPart.html">mindspore.ops.MatrixBandPart</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MatrixDiagPartV3.html">mindspore.ops.MatrixDiagPartV3</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MatrixDiagV3.html">mindspore.ops.MatrixDiagV3</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MatrixSetDiagV3.html">mindspore.ops.MatrixSetDiagV3</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.MatrixSolve.html">mindspore.ops.MatrixSolve</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Meshgrid.html">mindspore.ops.Meshgrid</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Mvlgamma.html">mindspore.ops.Mvlgamma</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.NanToNum.html">mindspore.ops.NanToNum</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.NonZero.html">mindspore.ops.NonZero</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ParallelConcat.html">mindspore.ops.ParallelConcat</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.PopulationCount.html">mindspore.ops.PopulationCount</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Qr.html">mindspore.ops.Qr</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.RandomShuffle.html">mindspore.ops.RandomShuffle</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Range.html">mindspore.ops.Range</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Rank.html">mindspore.ops.Rank</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Renorm.html">mindspore.ops.Renorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Reshape.html">mindspore.ops.Reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ReverseSequence.html">mindspore.ops.ReverseSequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ReverseV2.html">mindspore.ops.ReverseV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.RightShift.html">mindspore.ops.RightShift</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ScatterNd.html">mindspore.ops.ScatterNd</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ScatterNdDiv.html">mindspore.ops.ScatterNdDiv</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ScatterNdMax.html">mindspore.ops.ScatterNdMax</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ScatterNdMin.html">mindspore.ops.ScatterNdMin</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ScatterNdMul.html">mindspore.ops.ScatterNdMul</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SearchSorted.html">mindspore.ops.SearchSorted</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Select.html">mindspore.ops.Select</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Shape.html">mindspore.ops.Shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Size.html">mindspore.ops.Size</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Slice.html">mindspore.ops.Slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Sort.html">mindspore.ops.Sort</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SpaceToBatchND.html">mindspore.ops.SpaceToBatchND</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SpaceToDepth.html">mindspore.ops.SpaceToDepth</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.SparseGatherV2.html">mindspore.ops.SparseGatherV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Split.html">mindspore.ops.Split</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Squeeze.html">mindspore.ops.Squeeze</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Stack.html">mindspore.ops.Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.StridedSlice.html">mindspore.ops.StridedSlice</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.TensorScatterAdd.html">mindspore.ops.TensorScatterAdd</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.TensorScatterDiv.html">mindspore.ops.TensorScatterDiv</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.TensorScatterMax.html">mindspore.ops.TensorScatterMax</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.TensorScatterMin.html">mindspore.ops.TensorScatterMin</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.TensorScatterMul.html">mindspore.ops.TensorScatterMul</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.TensorScatterSub.html">mindspore.ops.TensorScatterSub</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.TensorScatterUpdate.html">mindspore.ops.TensorScatterUpdate</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.TensorShape.html">mindspore.ops.TensorShape</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Tile.html">mindspore.ops.Tile</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Trace.html">mindspore.ops.Trace</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Transpose.html">mindspore.ops.Transpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Tril.html">mindspore.ops.Tril</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.TrilIndices.html">mindspore.ops.TrilIndices</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.TriuIndices.html">mindspore.ops.TriuIndices</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Unique.html">mindspore.ops.Unique</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.UniqueConsecutive.html">mindspore.ops.UniqueConsecutive</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.UniqueWithPad.html">mindspore.ops.UniqueWithPad</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.UnsortedSegmentMax.html">mindspore.ops.UnsortedSegmentMax</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.UnsortedSegmentMin.html">mindspore.ops.UnsortedSegmentMin</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.UnsortedSegmentProd.html">mindspore.ops.UnsortedSegmentProd</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.UnsortedSegmentSum.html">mindspore.ops.UnsortedSegmentSum</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.Unstack.html">mindspore.ops.Unstack</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#类型转换">类型转换</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ScalarCast.html">mindspore.ops.ScalarCast</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.ScalarToTensor.html">mindspore.ops.ScalarToTensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="ops/mindspore.ops.TupleToArray.html">mindspore.ops.TupleToArray</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#parameter操作算子">Parameter操作算子</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.Assign.html">mindspore.ops.Assign</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.AssignAdd.html">mindspore.ops.AssignAdd</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.AssignSub.html">mindspore.ops.AssignSub</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.ScatterAdd.html">mindspore.ops.ScatterAdd</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.ScatterDiv.html">mindspore.ops.ScatterDiv</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.ScatterMax.html">mindspore.ops.ScatterMax</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.ScatterMin.html">mindspore.ops.ScatterMin</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.ScatterMul.html">mindspore.ops.ScatterMul</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.ScatterNdAdd.html">mindspore.ops.ScatterNdAdd</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.ScatterNdSub.html">mindspore.ops.ScatterNdSub</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.ScatterNdUpdate.html">mindspore.ops.ScatterNdUpdate</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.ScatterNonAliasingAdd.html">mindspore.ops.ScatterNonAliasingAdd</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.ScatterSub.html">mindspore.ops.ScatterSub</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.ScatterUpdate.html">mindspore.ops.ScatterUpdate</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#数据操作算子">数据操作算子</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.GetNext.html">mindspore.ops.GetNext</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#通信算子">通信算子</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.AllGather.html">mindspore.ops.AllGather</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.AllReduce.html">mindspore.ops.AllReduce</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.AlltoAll.html">mindspore.ops.AlltoAll</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.Broadcast.html">mindspore.ops.Broadcast</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.NeighborExchangeV2.html">mindspore.ops.NeighborExchangeV2</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.ReduceOp.html">mindspore.ops.ReduceOp</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.ReduceScatter.html">mindspore.ops.ReduceScatter</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#调试算子">调试算子</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.HistogramSummary.html">mindspore.ops.HistogramSummary</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.ImageSummary.html">mindspore.ops.ImageSummary</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.ScalarSummary.html">mindspore.ops.ScalarSummary</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.TensorSummary.html">mindspore.ops.TensorSummary</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.Print.html">mindspore.ops.Print</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.NPUAllocFloatStatus.html">mindspore.ops.NPUAllocFloatStatus</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.NPUClearFloatStatus.html">mindspore.ops.NPUClearFloatStatus</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.NPUGetFloatStatus.html">mindspore.ops.NPUGetFloatStatus</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#稀疏算子">稀疏算子</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.SparseTensorDenseMatmul.html">mindspore.ops.SparseTensorDenseMatmul</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.SparseToDense.html">mindspore.ops.SparseToDense</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#框架算子">框架算子</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.Depend.html">mindspore.ops.Depend</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.GradOperation.html">mindspore.ops.GradOperation</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.HookBackward.html">mindspore.ops.HookBackward</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.HyperMap.html">mindspore.ops.HyperMap</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.InsertGradientOf.html">mindspore.ops.InsertGradientOf</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.Map.html">mindspore.ops.Map</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.MultitypeFuncGraph.html">mindspore.ops.MultitypeFuncGraph</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.Partial.html">mindspore.ops.Partial</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#算子信息注册">算子信息注册</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.AiCPURegOp.html">mindspore.ops.AiCPURegOp</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.CustomRegOp.html">mindspore.ops.CustomRegOp</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.DataType.html">mindspore.ops.DataType</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.TBERegOp.html">mindspore.ops.TBERegOp</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.get_vm_impl_fn.html">mindspore.ops.get_vm_impl_fn</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#自定义算子">自定义算子</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.Custom.html">mindspore.ops.Custom</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#光谱算子">光谱算子</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.BartlettWindow.html">mindspore.ops.BartlettWindow</a></li>
<li class="toctree-l3"><a class="reference internal" href="ops/mindspore.ops.BlackmanWindow.html">mindspore.ops.BlackmanWindow</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/master/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption"><span class="caption-text">API映射</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/pytorch_api_mapping.html">PyTorch与MindSpore API映射表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/tensorflow_api_mapping.html">TensorFlow与MindSpore API映射表</a></li>
</ul>
<p class="caption"><span class="caption-text">迁移指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/overview.html">迁移指南概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/enveriment_preparation.html">环境准备与资料获取</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/analysis_and_preparation.html">模型分析与准备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/model_development/model_development.html">MindSpore网络搭建</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/debug_and_tune.html">调试调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/sample_code.html">网络迁移调试实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/faq.html">常见问题</a></li>
</ul>
<p class="caption"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq/installation.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/data_processing.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/implement_problem.html">执行问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/network_compilation.html">网络编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/usage_migrate_3rd.html">第三方框架迁移使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/distributed_parallel.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/feature_advice.html">特性咨询</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>mindspore.ops.primitive</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/api_python/mindspore.ops.primitive.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="mindspore-ops-primitive">
<h1>mindspore.ops.primitive<a class="headerlink" href="#mindspore-ops-primitive" title="永久链接至标题">¶</a></h1>
<p>可用于Cell的构造函数的算子。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
</pre></div>
</div>
<p>MindSpore中 <cite>mindspore.ops.primitive</cite> 接口与上一版本相比，新增、删除和支持平台的变化信息请参考 <a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/resource/api_updates/ops_api_updates_cn.md">mindspore.ops.primitive API接口变更</a> 。</p>
<div class="section" id="算子原语">
<h2>算子原语<a class="headerlink" href="#算子原语" title="永久链接至标题">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"></tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Primitive.html#mindspore.ops.Primitive" title="mindspore.ops.Primitive"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Primitive</span></code></a></p></td>
<td><p>Primitive是Python中算子原语的基类。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.PrimitiveWithCheck.html#mindspore.ops.PrimitiveWithCheck" title="mindspore.ops.PrimitiveWithCheck"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.PrimitiveWithCheck</span></code></a></p></td>
<td><p>PrimitiveWithCheck是Python中原语的基类，定义了检查算子输入参数的函数，但是使用了C++源码中注册的推理方法。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.PrimitiveWithInfer.html#mindspore.ops.PrimitiveWithInfer" title="mindspore.ops.PrimitiveWithInfer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.PrimitiveWithInfer</span></code></a></p></td>
<td><p>PrimitiveWithInfer是Python中的原语基类，在python中定义了跟踪推理的函数。</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="装饰器">
<h2>装饰器<a class="headerlink" href="#装饰器" title="永久链接至标题">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"></tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.constexpr.html#mindspore.ops.constexpr" title="mindspore.ops.constexpr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.constexpr</span></code></a></p></td>
<td><p>创建PrimiveWithInfer算子，用于在编译时推断值。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.custom_info_register.html#mindspore.ops.custom_info_register" title="mindspore.ops.custom_info_register"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.custom_info_register</span></code></a></p></td>
<td><p>装饰器，用于将注册信息绑定到： <a class="reference internal" href="ops/mindspore.ops.Custom.html#mindspore.ops.Custom" title="mindspore.ops.Custom"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.Custom</span></code></a> 的 <cite>func</cite> 参数。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.kernel.html#mindspore.ops.kernel" title="mindspore.ops.kernel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.kernel</span></code></a></p></td>
<td><p>用于MindSpore Hybrid DSL函数书写的装饰器。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.op_info_register.html#mindspore.ops.op_info_register" title="mindspore.ops.op_info_register"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.op_info_register</span></code></a></p></td>
<td><p>用于注册算子的装饰器。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.prim_attr_register.html#mindspore.ops.prim_attr_register" title="mindspore.ops.prim_attr_register"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.prim_attr_register</span></code></a></p></td>
<td><p>Primitive属性的注册器。</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="神经网络层算子">
<h2>神经网络层算子<a class="headerlink" href="#神经网络层算子" title="永久链接至标题">¶</a></h2>
<div class="section" id="神经网络">
<h3>神经网络<a class="headerlink" href="#神经网络" title="永久链接至标题">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.AvgPool.html#mindspore.ops.AvgPool" title="mindspore.ops.AvgPool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.AvgPool</span></code></a></p></td>
<td><p>对输入的多维数据进行二维平均池化运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.AvgPool3D.html#mindspore.ops.AvgPool3D" title="mindspore.ops.AvgPool3D"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.AvgPool3D</span></code></a></p></td>
<td><p>对输入的多维数据进行三维的平均池化运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>“kernel_size”在[1, 255]范围中。”strides”在[1, 63]范围中。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.BatchNorm.html#mindspore.ops.BatchNorm" title="mindspore.ops.BatchNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BatchNorm</span></code></a></p></td>
<td><p>对输入数据进行归一化(Batch Normalization)和更新参数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>如果该运算用于推理，并且输出”reserve_space_1”和”reserve_space_2”可用，则”reserve_space_1”的值与”mean”相同，”reserve_space_2”的值与”variance”相同。 对于Ascend 310，由于平方根指令，结果精度未能达到1‰。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Conv2D.html#mindspore.ops.Conv2D" title="mindspore.ops.Conv2D"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Conv2D</span></code></a></p></td>
<td><p>二维卷积层。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Conv2DTranspose.html#mindspore.ops.Conv2DTranspose" title="mindspore.ops.Conv2DTranspose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Conv2DTranspose</span></code></a></p></td>
<td><p>计算二维转置卷积，也称为反卷积，实际不是真正的反卷积。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Conv3D.html#mindspore.ops.Conv3D" title="mindspore.ops.Conv3D"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Conv3D</span></code></a></p></td>
<td><p>对输入Tensor计算三维卷积。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Conv3DTranspose.html#mindspore.ops.Conv3DTranspose" title="mindspore.ops.Conv3DTranspose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Conv3DTranspose</span></code></a></p></td>
<td><p>计算三维转置卷积，也称为反卷积（实际不是真正的反卷积）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.CTCGreedyDecoder.html#mindspore.ops.CTCGreedyDecoder" title="mindspore.ops.CTCGreedyDecoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.CTCGreedyDecoder</span></code></a></p></td>
<td><p>对输入中给定的logits执行贪婪解码。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Dropout.html#mindspore.ops.Dropout" title="mindspore.ops.Dropout"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Dropout</span></code></a></p></td>
<td><p>Dropout是一种正则化手段，通过在训练中以 <span class="math notranslate nohighlight">\(1 - keep\_prob\)</span> 的概率随机将神经元输出设置为0，起到减少神经元相关性的作用，避免过拟合。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Dropout2D.html#mindspore.ops.Dropout2D" title="mindspore.ops.Dropout2D"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Dropout2D</span></code></a></p></td>
<td><p>在训练期间，根据概率 <span class="math notranslate nohighlight">\(1-keep\_prob\)</span> ，随机地将一些通道设置为0，且服从伯努利分布。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Dropout3D.html#mindspore.ops.Dropout3D" title="mindspore.ops.Dropout3D"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Dropout3D</span></code></a></p></td>
<td><p>在训练期间，以服从伯努利分布的概率 <span class="math notranslate nohighlight">\(1-keep\_prob\)</span> 随机将输入Tensor的某些通道归零。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.DynamicGRUV2.html#mindspore.ops.DynamicGRUV2" title="mindspore.ops.DynamicGRUV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.DynamicGRUV2</span></code></a></p></td>
<td><p>为输入序列应用一个单层GRU(gated recurrent unit)。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.DynamicRNN.html#mindspore.ops.DynamicRNN" title="mindspore.ops.DynamicRNN"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.DynamicRNN</span></code></a></p></td>
<td><p>将循环神经网络应用到输入上。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.EmbeddingLookup.html#mindspore.ops.EmbeddingLookup" title="mindspore.ops.EmbeddingLookup"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.EmbeddingLookup</span></code></a></p></td>
<td><p>根据指定的索引，返回输入Tensor的切片。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Flatten.html#mindspore.ops.Flatten" title="mindspore.ops.Flatten"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Flatten</span></code></a></p></td>
<td><p>扁平化（Flatten）输入Tensor，不改变0轴的size。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.GridSampler2D.html#mindspore.ops.GridSampler2D" title="mindspore.ops.GridSampler2D"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.GridSampler2D</span></code></a></p></td>
<td><p>此操作使用基于流场网格的插值对2D <cite>input_x</cite> 进行采样，该插值通常由 <a class="reference internal" href="ops/mindspore.ops.affine_grid.html#mindspore.ops.affine_grid" title="mindspore.ops.affine_grid"><code class="xref py py-func docutils literal notranslate"><span class="pre">mindspore.ops.affine_grid()</span></code></a> 生成。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.GridSampler3D.html#mindspore.ops.GridSampler3D" title="mindspore.ops.GridSampler3D"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.GridSampler3D</span></code></a></p></td>
<td><p>给定一个输入和一个网格，使用网格中的输入值和像素位置计算输出。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.LayerNorm.html#mindspore.ops.LayerNorm" title="mindspore.ops.LayerNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.LayerNorm</span></code></a></p></td>
<td><p>在输入Tensor上应用层归一化（Layer Normalization）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.LRN.html#mindspore.ops.LRN" title="mindspore.ops.LRN"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.LRN</span></code></a></p></td>
<td><p>局部响应归一化操作LRN(Local Response Normalization)。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.LSTM.html#mindspore.ops.LSTM" title="mindspore.ops.LSTM"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.LSTM</span></code></a></p></td>
<td><p>对输入执行长短期记忆（LSTM）网络。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.MaxPool.html#mindspore.ops.MaxPool" title="mindspore.ops.MaxPool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MaxPool</span></code></a></p></td>
<td><p>对输入的多维数据进行二维的最大池化运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.MaxPool3D.html#mindspore.ops.MaxPool3D" title="mindspore.ops.MaxPool3D"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MaxPool3D</span></code></a></p></td>
<td><p>对输入的多维数据进行三维的最大池化运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.MaxPool3DWithArgmax.html#mindspore.ops.MaxPool3DWithArgmax" title="mindspore.ops.MaxPool3DWithArgmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MaxPool3DWithArgmax</span></code></a></p></td>
<td><p>三维最大值池化，返回最大值结果及其索引值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.MaxPoolWithArgmax.html#mindspore.ops.MaxPoolWithArgmax" title="mindspore.ops.MaxPoolWithArgmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MaxPoolWithArgmax</span></code></a></p></td>
<td><p><a class="reference internal" href="ops/mindspore.ops.MaxPoolWithArgmax.html#mindspore.ops.MaxPoolWithArgmax" title="mindspore.ops.MaxPoolWithArgmax"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.MaxPoolWithArgmax</span></code></a> 从2.0版本开始已被弃用，并将在未来版本中被移除，建议使用 <a class="reference internal" href="ops/mindspore.ops.MaxPoolWithArgmaxV2.html#mindspore.ops.MaxPoolWithArgmaxV2" title="mindspore.ops.MaxPoolWithArgmaxV2"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.MaxPoolWithArgmaxV2</span></code></a> 代替。</p></td>
<td><p>Deprecated</p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.MaxPoolWithArgmaxV2.html#mindspore.ops.MaxPoolWithArgmaxV2" title="mindspore.ops.MaxPoolWithArgmaxV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MaxPoolWithArgmaxV2</span></code></a></p></td>
<td><p>对输入Tensor执行最大池化运算，并返回最大值和索引。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.MaxUnpool2D.html#mindspore.ops.MaxUnpool2D" title="mindspore.ops.MaxUnpool2D"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MaxUnpool2D</span></code></a></p></td>
<td><p>MaxPool2D的逆过程。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.MaxUnpool3D.html#mindspore.ops.MaxUnpool3D" title="mindspore.ops.MaxUnpool3D"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MaxUnpool3D</span></code></a></p></td>
<td><p><a class="reference internal" href="ops/mindspore.ops.MaxPool3D.html#mindspore.ops.MaxPool3D" title="mindspore.ops.MaxPool3D"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.MaxPool3D</span></code></a> 的逆过程。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.MirrorPad.html#mindspore.ops.MirrorPad" title="mindspore.ops.MirrorPad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MirrorPad</span></code></a></p></td>
<td><p>通过指定的填充模式和大小对输入Tensor进行填充。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Pad.html#mindspore.ops.Pad" title="mindspore.ops.Pad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Pad</span></code></a></p></td>
<td><p>根据参数 <cite>paddings</cite> 对输入进行填充。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Padding.html#mindspore.ops.Padding" title="mindspore.ops.Padding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Padding</span></code></a></p></td>
<td><p>将输入Tensor的最后一个维度从1扩展到 <cite>pad_dim_size</cite> ，其填充值为0。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ResizeBicubic.html#mindspore.ops.ResizeBicubic" title="mindspore.ops.ResizeBicubic"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ResizeBicubic</span></code></a></p></td>
<td><p>使用双三次插值调整图像大小到指定的大小。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ResizeBilinear.html#mindspore.ops.ResizeBilinear" title="mindspore.ops.ResizeBilinear"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ResizeBilinear</span></code></a></p></td>
<td><p>此接口已弃用，请使用 <a class="reference internal" href="ops/mindspore.ops.ResizeBilinearV2.html#mindspore.ops.ResizeBilinearV2" title="mindspore.ops.ResizeBilinearV2"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.ResizeBilinearV2</span></code></a> 。</p></td>
<td><p>Deprecated</p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ResizeNearestNeighbor.html#mindspore.ops.ResizeNearestNeighbor" title="mindspore.ops.ResizeNearestNeighbor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ResizeNearestNeighbor</span></code></a></p></td>
<td><p>使用最近邻插值算法调整输入Tensor为指定大小。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="损失函数">
<h3>损失函数<a class="headerlink" href="#损失函数" title="永久链接至标题">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.BCEWithLogitsLoss.html#mindspore.ops.BCEWithLogitsLoss" title="mindspore.ops.BCEWithLogitsLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BCEWithLogitsLoss</span></code></a></p></td>
<td><p>输入经过sigmoid激活函数后作为预测值，<cite>BCEWithLogitsLoss</cite> 计算预测值和目标值之间的二值交叉熵损失。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.BinaryCrossEntropy.html#mindspore.ops.BinaryCrossEntropy" title="mindspore.ops.BinaryCrossEntropy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BinaryCrossEntropy</span></code></a></p></td>
<td><p>计算目标值和预测值之间的二值交叉熵损失值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p><span class="math notranslate nohighlight">\(x\)</span> 的值必须在0到1之间。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.CTCLoss.html#mindspore.ops.CTCLoss" title="mindspore.ops.CTCLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.CTCLoss</span></code></a></p></td>
<td><p>计算CTC(Connectionist Temporal Classification)损失和梯度。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.CTCLossV2.html#mindspore.ops.CTCLossV2" title="mindspore.ops.CTCLossV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.CTCLossV2</span></code></a></p></td>
<td><p>计算CTC(Connectionist Temporal Classification)损失和梯度。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.KLDivLoss.html#mindspore.ops.KLDivLoss" title="mindspore.ops.KLDivLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.KLDivLoss</span></code></a></p></td>
<td><p>计算输入 <cite>logits</cite> 和 <cite>labels</cite> 的KL散度。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.L2Loss.html#mindspore.ops.L2Loss" title="mindspore.ops.L2Loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.L2Loss</span></code></a></p></td>
<td><p>用于计算L2范数的一半，但不对结果进行开方操作。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.MultilabelMarginLoss.html#mindspore.ops.MultilabelMarginLoss" title="mindspore.ops.MultilabelMarginLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MultilabelMarginLoss</span></code></a></p></td>
<td><p>创建一个损失函数，用于最小化多分类任务的合页损失。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.MultiMarginLoss.html#mindspore.ops.MultiMarginLoss" title="mindspore.ops.MultiMarginLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MultiMarginLoss</span></code></a></p></td>
<td><p>创建一个损失函数，用于优化输入和输出之间的多分类合页损失。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.NLLLoss.html#mindspore.ops.NLLLoss" title="mindspore.ops.NLLLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.NLLLoss</span></code></a></p></td>
<td><p>获取预测值和目标值之间的负对数似然损失。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.RNNTLoss.html#mindspore.ops.RNNTLoss" title="mindspore.ops.RNNTLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.RNNTLoss</span></code></a></p></td>
<td><p>计算相对于softmax输出的RNNTLoss及其梯度。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.SigmoidCrossEntropyWithLogits.html#mindspore.ops.SigmoidCrossEntropyWithLogits" title="mindspore.ops.SigmoidCrossEntropyWithLogits"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SigmoidCrossEntropyWithLogits</span></code></a></p></td>
<td><p>计算预测值与真实值之间的sigmoid交叉熵。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.SmoothL1Loss.html#mindspore.ops.SmoothL1Loss" title="mindspore.ops.SmoothL1Loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SmoothL1Loss</span></code></a></p></td>
<td><p>计算平滑L1损失，该L1损失函数有稳健性。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.SoftMarginLoss.html#mindspore.ops.SoftMarginLoss" title="mindspore.ops.SoftMarginLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SoftMarginLoss</span></code></a></p></td>
<td><p>SoftMarginLoss操作。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.SoftmaxCrossEntropyWithLogits.html#mindspore.ops.SoftmaxCrossEntropyWithLogits" title="mindspore.ops.SoftmaxCrossEntropyWithLogits"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SoftmaxCrossEntropyWithLogits</span></code></a></p></td>
<td><p>使用one-hot编码获取预测值和真实之间的softmax交叉熵。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.SparseSoftmaxCrossEntropyWithLogits.html#mindspore.ops.SparseSoftmaxCrossEntropyWithLogits" title="mindspore.ops.SparseSoftmaxCrossEntropyWithLogits"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SparseSoftmaxCrossEntropyWithLogits</span></code></a></p></td>
<td><p>计算预测值和标签之间的稀疏softmax交叉熵。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.TripletMarginLoss.html#mindspore.ops.TripletMarginLoss" title="mindspore.ops.TripletMarginLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.TripletMarginLoss</span></code></a></p></td>
<td><p>三元组损失函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="激活函数">
<h3>激活函数<a class="headerlink" href="#激活函数" title="永久链接至标题">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Elu.html#mindspore.ops.Elu" title="mindspore.ops.Elu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Elu</span></code></a></p></td>
<td><p>指数线性单元激活函数（Exponential Linear Unit activation function）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.FastGeLU.html#mindspore.ops.FastGeLU" title="mindspore.ops.FastGeLU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.FastGeLU</span></code></a></p></td>
<td><p>快速高斯误差线性单元激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.GeLU.html#mindspore.ops.GeLU" title="mindspore.ops.GeLU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.GeLU</span></code></a></p></td>
<td><p>高斯误差线性单元激活函数（Gaussian Error Linear Units activation function）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.GLU.html#mindspore.ops.GLU" title="mindspore.ops.GLU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.GLU</span></code></a></p></td>
<td><p>门线性单元函数（Gated Linear Unit function）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.HShrink.html#mindspore.ops.HShrink" title="mindspore.ops.HShrink"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.HShrink</span></code></a></p></td>
<td><p>Hard Shrink激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.HSigmoid.html#mindspore.ops.HSigmoid" title="mindspore.ops.HSigmoid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.HSigmoid</span></code></a></p></td>
<td><p>分段性逼近激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.HSwish.html#mindspore.ops.HSwish" title="mindspore.ops.HSwish"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.HSwish</span></code></a></p></td>
<td><p>Hard Swish激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.LogSoftmax.html#mindspore.ops.LogSoftmax" title="mindspore.ops.LogSoftmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.LogSoftmax</span></code></a></p></td>
<td><p>LogSoftmax激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Mish.html#mindspore.ops.Mish" title="mindspore.ops.Mish"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Mish</span></code></a></p></td>
<td><p>逐元素计算输入Tensor的MISH（Self Regularized Non-Monotonic Neural Activation Function 自正则化非单调神经激活函数）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.PReLU.html#mindspore.ops.PReLU" title="mindspore.ops.PReLU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.PReLU</span></code></a></p></td>
<td><p>带参数的线性修正单元激活函数（Parametric Rectified Linear Unit activation function）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ReLU.html#mindspore.ops.ReLU" title="mindspore.ops.ReLU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ReLU</span></code></a></p></td>
<td><p>线性修正单元激活函数（Rectified Linear Unit）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ReLU6.html#mindspore.ops.ReLU6" title="mindspore.ops.ReLU6"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ReLU6</span></code></a></p></td>
<td><p>计算输入Tensor的ReLU（矫正线性单元），其上限为6。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.SeLU.html#mindspore.ops.SeLU" title="mindspore.ops.SeLU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SeLU</span></code></a></p></td>
<td><p>激活函数SeLU（Scaled exponential Linear Unit）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Sigmoid.html#mindspore.ops.Sigmoid" title="mindspore.ops.Sigmoid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Sigmoid</span></code></a></p></td>
<td><p>Sigmoid激活函数，逐元素计算Sigmoid激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Softmax.html#mindspore.ops.Softmax" title="mindspore.ops.Softmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Softmax</span></code></a></p></td>
<td><p>在指定轴上使用Softmax函数做归一化操作。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Softplus.html#mindspore.ops.Softplus" title="mindspore.ops.Softplus"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Softplus</span></code></a></p></td>
<td><p>Softplus激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code>  <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.SoftShrink.html#mindspore.ops.SoftShrink" title="mindspore.ops.SoftShrink"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SoftShrink</span></code></a></p></td>
<td><p>Soft Shrink激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Softsign.html#mindspore.ops.Softsign" title="mindspore.ops.Softsign"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Softsign</span></code></a></p></td>
<td><p>Softsign激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Tanh.html#mindspore.ops.Tanh" title="mindspore.ops.Tanh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Tanh</span></code></a></p></td>
<td><p>逐元素计算输入元素的双曲正切。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code>  <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="优化器">
<h3>优化器<a class="headerlink" href="#优化器" title="永久链接至标题">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Adam.html#mindspore.ops.Adam" title="mindspore.ops.Adam"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Adam</span></code></a></p></td>
<td><p>通过Adam算法更新梯度。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.AdamWeightDecay.html#mindspore.ops.AdamWeightDecay" title="mindspore.ops.AdamWeightDecay"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.AdamWeightDecay</span></code></a></p></td>
<td><p>通过具有权重衰减的自适应矩估计算法（AdamWeightDecay）更新梯度。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.AdaptiveAvgPool2D.html#mindspore.ops.AdaptiveAvgPool2D" title="mindspore.ops.AdaptiveAvgPool2D"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.AdaptiveAvgPool2D</span></code></a></p></td>
<td><p>二维自适应平均池化。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.AdaptiveAvgPool3D.html#mindspore.ops.AdaptiveAvgPool3D" title="mindspore.ops.AdaptiveAvgPool3D"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.AdaptiveAvgPool3D</span></code></a></p></td>
<td><p>三维自适应平均池化。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ApplyAdadelta.html#mindspore.ops.ApplyAdadelta" title="mindspore.ops.ApplyAdadelta"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ApplyAdadelta</span></code></a></p></td>
<td><p>根据Adadelta算法更新相关参数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ApplyAdagrad.html#mindspore.ops.ApplyAdagrad" title="mindspore.ops.ApplyAdagrad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ApplyAdagrad</span></code></a></p></td>
<td><p>根据Adagrad算法更新相关参数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ApplyAdagradDA.html#mindspore.ops.ApplyAdagradDA" title="mindspore.ops.ApplyAdagradDA"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ApplyAdagradDA</span></code></a></p></td>
<td><p>根据Adagrad算法更新 <cite>var</cite> 。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ApplyAdagradV2.html#mindspore.ops.ApplyAdagradV2" title="mindspore.ops.ApplyAdagradV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ApplyAdagradV2</span></code></a></p></td>
<td><p>根据Adagrad算法更新相关参数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ApplyAdaMax.html#mindspore.ops.ApplyAdaMax" title="mindspore.ops.ApplyAdaMax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ApplyAdaMax</span></code></a></p></td>
<td><p>根据AdaMax算法更新相关参数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ApplyAddSign.html#mindspore.ops.ApplyAddSign" title="mindspore.ops.ApplyAddSign"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ApplyAddSign</span></code></a></p></td>
<td><p>根据AddSign算法更新相关参数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ApplyCenteredRMSProp.html#mindspore.ops.ApplyCenteredRMSProp" title="mindspore.ops.ApplyCenteredRMSProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ApplyCenteredRMSProp</span></code></a></p></td>
<td><p>居中RMSProp算法优化器。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>在此算法的密集实现中， <cite>mean_gradient</cite> 、 <cite>mean_square</cite> 和 <cite>moment</cite> 在 <cite>grad</cite> 为零时仍将被更新。但在稀疏实现中， <cite>mean_gradient</cite> 、 <cite>mean_square</cite> 和 <cite>moment</cite> 不会在 <cite>grad</cite> 为零的迭代中被更新。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ApplyFtrl.html#mindspore.ops.ApplyFtrl" title="mindspore.ops.ApplyFtrl"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ApplyFtrl</span></code></a></p></td>
<td><p>根据FTRL算法更新相关参数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ApplyGradientDescent.html#mindspore.ops.ApplyGradientDescent" title="mindspore.ops.ApplyGradientDescent"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ApplyGradientDescent</span></code></a></p></td>
<td><p>通过从 <cite>var</cite> 中减去 <cite>alpha</cite> * <cite>delta</cite> 来更新 <cite>var</cite> 。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ApplyMomentum.html#mindspore.ops.ApplyMomentum" title="mindspore.ops.ApplyMomentum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ApplyMomentum</span></code></a></p></td>
<td><p>使用动量算法的优化器。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ApplyPowerSign.html#mindspore.ops.ApplyPowerSign" title="mindspore.ops.ApplyPowerSign"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ApplyPowerSign</span></code></a></p></td>
<td><p>根据AddSign算法更新相关参数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ApplyProximalAdagrad.html#mindspore.ops.ApplyProximalAdagrad" title="mindspore.ops.ApplyProximalAdagrad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ApplyProximalAdagrad</span></code></a></p></td>
<td><p>根据Proximal Adagrad算法更新网络参数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ApplyProximalGradientDescent.html#mindspore.ops.ApplyProximalGradientDescent" title="mindspore.ops.ApplyProximalGradientDescent"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ApplyProximalGradientDescent</span></code></a></p></td>
<td><p>根据FOBOS(Forward Backward Splitting)算法更新网络参数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ApplyRMSProp.html#mindspore.ops.ApplyRMSProp" title="mindspore.ops.ApplyRMSProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ApplyRMSProp</span></code></a></p></td>
<td><p>实现均方根传播Root Mean Square prop(RMSProp)算法的优化器。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>在该算法的稠密实现版本中，”mean_square”和”momemt”即使”grad”为零将仍被更新。但在该稀疏实现版本中，在”grad”为零的迭代”mean_squre”和”moment”将不被更新。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.LARSUpdate.html#mindspore.ops.LARSUpdate" title="mindspore.ops.LARSUpdate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.LARSUpdate</span></code></a></p></td>
<td><p>对梯度的平方和应用LARS(layer-wise adaptive rate scaling)算法。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.SparseApplyAdagradV2.html#mindspore.ops.SparseApplyAdagradV2" title="mindspore.ops.SparseApplyAdagradV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SparseApplyAdagradV2</span></code></a></p></td>
<td><p>根据Adagrad算法更新相关参数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.SparseApplyProximalAdagrad.html#mindspore.ops.SparseApplyProximalAdagrad" title="mindspore.ops.SparseApplyProximalAdagrad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SparseApplyProximalAdagrad</span></code></a></p></td>
<td><p>根据Proximal Adagrad算法更新网络参数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.SGD.html#mindspore.ops.SGD" title="mindspore.ops.SGD"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SGD</span></code></a></p></td>
<td><p>计算随机梯度下降。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.SparseApplyFtrl.html#mindspore.ops.SparseApplyFtrl" title="mindspore.ops.SparseApplyFtrl"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SparseApplyFtrl</span></code></a></p></td>
<td><p>根据FTRL-proximal算法更新相关参数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.SparseApplyFtrlV2.html#mindspore.ops.SparseApplyFtrlV2" title="mindspore.ops.SparseApplyFtrlV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SparseApplyFtrlV2</span></code></a></p></td>
<td><p><a class="reference internal" href="ops/mindspore.ops.SparseApplyFtrlV2.html#mindspore.ops.SparseApplyFtrlV2" title="mindspore.ops.SparseApplyFtrlV2"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.SparseApplyFtrlV2</span></code></a> 从2.0版本开始已被弃用，并将在未来版本中被移除，建议使用 <a class="reference internal" href="ops/mindspore.ops.SparseApplyFtrl.html#mindspore.ops.SparseApplyFtrl" title="mindspore.ops.SparseApplyFtrl"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.SparseApplyFtrl</span></code></a> 代替。</p></td>
<td><p>Deprecated</p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="距离函数">
<h3>距离函数<a class="headerlink" href="#距离函数" title="永久链接至标题">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Cdist.html#mindspore.ops.Cdist" title="mindspore.ops.Cdist"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Cdist</span></code></a></p></td>
<td><p>计算两个Tensor的p-norm距离。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.EditDistance.html#mindspore.ops.EditDistance" title="mindspore.ops.EditDistance"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.EditDistance</span></code></a></p></td>
<td><p>计算Levenshtein编辑距离。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>如果输入 <cite>truth_indices</cite> 或者 <cite>hypothesis_indices</cite> 不是有序的， 可能会导致计算结果不符合预期， 建议调用该接口之前确保输入的稀疏张量 <cite>truth_indices</cite> 和 <cite>hypothesis_indices</cite> 都是升序排列的。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.LpNorm.html#mindspore.ops.LpNorm" title="mindspore.ops.LpNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.LpNorm</span></code></a></p></td>
<td><p>返回输入Tensor的矩阵范数或向量范数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Pdist.html#mindspore.ops.Pdist" title="mindspore.ops.Pdist"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Pdist</span></code></a></p></td>
<td><p>计算输入中每对行向量之间的p-范数距离。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="采样算子">
<h3>采样算子<a class="headerlink" href="#采样算子" title="永久链接至标题">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ComputeAccidentalHits.html#mindspore.ops.ComputeAccidentalHits" title="mindspore.ops.ComputeAccidentalHits"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ComputeAccidentalHits</span></code></a></p></td>
<td><p>计算与目标类完全匹配的抽样样本的位置id。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.LogUniformCandidateSampler.html#mindspore.ops.LogUniformCandidateSampler" title="mindspore.ops.LogUniformCandidateSampler"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.LogUniformCandidateSampler</span></code></a></p></td>
<td><p>使用log-uniform(Zipfian)分布对一组类别进行采样。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.UniformCandidateSampler.html#mindspore.ops.UniformCandidateSampler" title="mindspore.ops.UniformCandidateSampler"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.UniformCandidateSampler</span></code></a></p></td>
<td><p>使用均匀分布对一组类别进行采样。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="图像处理">
<h3>图像处理<a class="headerlink" href="#图像处理" title="永久链接至标题">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.BoundingBoxDecode.html#mindspore.ops.BoundingBoxDecode" title="mindspore.ops.BoundingBoxDecode"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BoundingBoxDecode</span></code></a></p></td>
<td><p>解码边界框位置信息。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.BoundingBoxEncode.html#mindspore.ops.BoundingBoxEncode" title="mindspore.ops.BoundingBoxEncode"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BoundingBoxEncode</span></code></a></p></td>
<td><p>编码边界框位置信息。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.CheckValid.html#mindspore.ops.CheckValid" title="mindspore.ops.CheckValid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.CheckValid</span></code></a></p></td>
<td><p>检查边界框。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.CropAndResize.html#mindspore.ops.CropAndResize" title="mindspore.ops.CropAndResize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.CropAndResize</span></code></a></p></td>
<td><p>从输入图像Tensor中提取切片并调整其大小。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ExtractVolumePatches.html#mindspore.ops.ExtractVolumePatches" title="mindspore.ops.ExtractVolumePatches"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ExtractVolumePatches</span></code></a></p></td>
<td><p>从输入中提取数据，并将它放入”depth”输出维度中，”depth”为输出的第二维。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.IOU.html#mindspore.ops.IOU" title="mindspore.ops.IOU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.IOU</span></code></a></p></td>
<td><p>计算矩形的IOU，即真实区域和预测区域的交并比。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.L2Normalize.html#mindspore.ops.L2Normalize" title="mindspore.ops.L2Normalize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.L2Normalize</span></code></a></p></td>
<td><p>L2范数归一化算子。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.NMSWithMask.html#mindspore.ops.NMSWithMask" title="mindspore.ops.NMSWithMask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.NMSWithMask</span></code></a></p></td>
<td><p>非极大值抑制算法（NMS, Non-maximum Suppression）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>一次最多支持2864个输入框。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ResizeBilinearV2.html#mindspore.ops.ResizeBilinearV2" title="mindspore.ops.ResizeBilinearV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ResizeBilinearV2</span></code></a></p></td>
<td><p>使用双线性插值调整图像大小到指定的大小。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ROIAlign.html#mindspore.ops.ROIAlign" title="mindspore.ops.ROIAlign"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ROIAlign</span></code></a></p></td>
<td><p>感兴趣区域对齐(RoI Align)运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="文本处理">
<h3>文本处理<a class="headerlink" href="#文本处理" title="永久链接至标题">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.NoRepeatNGram.html#mindspore.ops.NoRepeatNGram" title="mindspore.ops.NoRepeatNGram"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.NoRepeatNGram</span></code></a></p></td>
<td><p>n-grams出现重复，则更新对应n-gram词序列出现的概率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="数学运算算子">
<h2>数学运算算子<a class="headerlink" href="#数学运算算子" title="永久链接至标题">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Bincount.html#mindspore.ops.Bincount" title="mindspore.ops.Bincount"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Bincount</span></code></a></p></td>
<td><p>计算整数数组中每个值的出现次数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Cholesky.html#mindspore.ops.Cholesky" title="mindspore.ops.Cholesky"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Cholesky</span></code></a></p></td>
<td><p>计算单个或成批对称正定矩阵的Cholesky分解。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Complex.html#mindspore.ops.Complex" title="mindspore.ops.Complex"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Complex</span></code></a></p></td>
<td><p>给定复数的实部与虚部，返回一个复数的Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ComplexAbs.html#mindspore.ops.ComplexAbs" title="mindspore.ops.ComplexAbs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ComplexAbs</span></code></a></p></td>
<td><p>返回输入复数的模。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Cross.html#mindspore.ops.Cross" title="mindspore.ops.Cross"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Cross</span></code></a></p></td>
<td><p>返回 <cite>x1</cite> 和 <cite>x2</cite> 沿着维度 <cite>dim</cite> 上的向量积（叉积）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Gcd.html#mindspore.ops.Gcd" title="mindspore.ops.Gcd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Gcd</span></code></a></p></td>
<td><p>逐元素计算输入Tensor的最大公约数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
</tbody>
</table>
<div class="section" id="逐元素运算">
<h3>逐元素运算<a class="headerlink" href="#逐元素运算" title="永久链接至标题">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Abs.html#mindspore.ops.Abs" title="mindspore.ops.Abs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Abs</span></code></a></p></td>
<td><p>逐元素计算输入Tensor的绝对值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.AccumulateNV2.html#mindspore.ops.AccumulateNV2" title="mindspore.ops.AccumulateNV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.AccumulateNV2</span></code></a></p></td>
<td><p>逐元素将所有输入的Tensor相加。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ACos.html#mindspore.ops.ACos" title="mindspore.ops.ACos"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ACos</span></code></a></p></td>
<td><p>逐元素计算输入Tensor的反余弦。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Acosh.html#mindspore.ops.Acosh" title="mindspore.ops.Acosh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Acosh</span></code></a></p></td>
<td><p>逐元素计算输入Tensor的反双曲余弦。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Add.html#mindspore.ops.Add" title="mindspore.ops.Add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Add</span></code></a></p></td>
<td><p>两个输入Tensor逐元素相加。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Addcdiv.html#mindspore.ops.Addcdiv" title="mindspore.ops.Addcdiv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Addcdiv</span></code></a></p></td>
<td><p>执行Tensor <cite>x1</cite> 与Tensor <cite>x2</cite> 的逐元素除法，将结果乘以标量值 <cite>value</cite> ，并将其添加到 <cite>input_data</cite> 中。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Addcmul.html#mindspore.ops.Addcmul" title="mindspore.ops.Addcmul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Addcmul</span></code></a></p></td>
<td><p>执行Tensor <cite>x1</cite> 与Tensor <cite>x2</cite> 的逐元素乘积，将结果乘以标量值 <cite>value</cite> ，并将其添加到 <cite>input_data</cite> 中。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.AddN.html#mindspore.ops.AddN" title="mindspore.ops.AddN"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.AddN</span></code></a></p></td>
<td><p>逐元素将所有输入的Tensor相加。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Angle.html#mindspore.ops.Angle" title="mindspore.ops.Angle"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Angle</span></code></a></p></td>
<td><p>逐元素计算复数Tensor的辐角。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Asin.html#mindspore.ops.Asin" title="mindspore.ops.Asin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Asin</span></code></a></p></td>
<td><p>逐元素计算输入Tensor的反正弦值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Asinh.html#mindspore.ops.Asinh" title="mindspore.ops.Asinh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Asinh</span></code></a></p></td>
<td><p>逐元素计算输入Tensor的反双曲正弦值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Atan.html#mindspore.ops.Atan" title="mindspore.ops.Atan"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Atan</span></code></a></p></td>
<td><p>逐元素计算输入Tensor的反正切值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Atan2.html#mindspore.ops.Atan2" title="mindspore.ops.Atan2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Atan2</span></code></a></p></td>
<td><p>逐元素计算x/y的反正切值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Atanh.html#mindspore.ops.Atanh" title="mindspore.ops.Atanh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Atanh</span></code></a></p></td>
<td><p>逐元素计算输入Tensor的反双曲正切值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.BesselI0.html#mindspore.ops.BesselI0" title="mindspore.ops.BesselI0"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BesselI0</span></code></a></p></td>
<td><p>逐元素计算输入数据的BesselI0函数值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.BesselI0e.html#mindspore.ops.BesselI0e" title="mindspore.ops.BesselI0e"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BesselI0e</span></code></a></p></td>
<td><p>逐元素计算输入数据的BesselI0e函数值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.BesselI1.html#mindspore.ops.BesselI1" title="mindspore.ops.BesselI1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BesselI1</span></code></a></p></td>
<td><p>逐元素计算并返回输入Tensor的BesselI1函数值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.BesselI1e.html#mindspore.ops.BesselI1e" title="mindspore.ops.BesselI1e"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BesselI1e</span></code></a></p></td>
<td><p>逐元素计算输入数据的BesselI1e函数值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.BesselJ0.html#mindspore.ops.BesselJ0" title="mindspore.ops.BesselJ0"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BesselJ0</span></code></a></p></td>
<td><p>逐元素计算输入数据的BesselJ0函数值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.BesselJ1.html#mindspore.ops.BesselJ1" title="mindspore.ops.BesselJ1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BesselJ1</span></code></a></p></td>
<td><p>逐元素计算输入数据的BesselJ1函数值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.BesselK0.html#mindspore.ops.BesselK0" title="mindspore.ops.BesselK0"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BesselK0</span></code></a></p></td>
<td><p>逐元素计算输入数据的BesselK0函数值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.BesselK0e.html#mindspore.ops.BesselK0e" title="mindspore.ops.BesselK0e"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BesselK0e</span></code></a></p></td>
<td><p>逐元素计算输入数据的BesselK0e函数值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.BesselK1.html#mindspore.ops.BesselK1" title="mindspore.ops.BesselK1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BesselK1</span></code></a></p></td>
<td><p>逐元素计算输入数据的BesselK1函数值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.BesselK1e.html#mindspore.ops.BesselK1e" title="mindspore.ops.BesselK1e"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BesselK1e</span></code></a></p></td>
<td><p>逐元素计算输入数据的BesselK1e函数值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.BesselY0.html#mindspore.ops.BesselY0" title="mindspore.ops.BesselY0"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BesselY0</span></code></a></p></td>
<td><p>逐元素计算输入数据的BesselY0函数值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.BesselY1.html#mindspore.ops.BesselY1" title="mindspore.ops.BesselY1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BesselY1</span></code></a></p></td>
<td><p>逐元素计算输入数据的BesselY1函数值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.BitwiseAnd.html#mindspore.ops.BitwiseAnd" title="mindspore.ops.BitwiseAnd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BitwiseAnd</span></code></a></p></td>
<td><p>逐元素执行两个Tensor的与运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.BitwiseOr.html#mindspore.ops.BitwiseOr" title="mindspore.ops.BitwiseOr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BitwiseOr</span></code></a></p></td>
<td><p>逐元素执行两个Tensor的或运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.BitwiseXor.html#mindspore.ops.BitwiseXor" title="mindspore.ops.BitwiseXor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BitwiseXor</span></code></a></p></td>
<td><p>逐元素执行两个Tensor的异或运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Ceil.html#mindspore.ops.Ceil" title="mindspore.ops.Ceil"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Ceil</span></code></a></p></td>
<td><p>向上取整函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Conj.html#mindspore.ops.Conj" title="mindspore.ops.Conj"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Conj</span></code></a></p></td>
<td><p>返回输入张量的共轭。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Cos.html#mindspore.ops.Cos" title="mindspore.ops.Cos"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Cos</span></code></a></p></td>
<td><p>逐元素计算输入数据的余弦。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Cosh.html#mindspore.ops.Cosh" title="mindspore.ops.Cosh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Cosh</span></code></a></p></td>
<td><p>逐元素计算输入数据的双曲余弦。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Digamma.html#mindspore.ops.Digamma" title="mindspore.ops.Digamma"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Digamma</span></code></a></p></td>
<td><p>计算输入的lgamma函数的导数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Div.html#mindspore.ops.Div" title="mindspore.ops.Div"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Div</span></code></a></p></td>
<td><p>逐元素计算第一输入Tensor除以第二输入Tensor的商。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.DivNoNan.html#mindspore.ops.DivNoNan" title="mindspore.ops.DivNoNan"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.DivNoNan</span></code></a></p></td>
<td><p>对 <cite>x1</cite> 和 <cite>x2</cite> 逐元素执行安全除法，如果 <cite>x2</cite> 的元素为0，则返回0。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Einsum.html#mindspore.ops.Einsum" title="mindspore.ops.Einsum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Einsum</span></code></a></p></td>
<td><p>此算子使用爱因斯坦求和约定（Einsum）进行Tensor计算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Erf.html#mindspore.ops.Erf" title="mindspore.ops.Erf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Erf</span></code></a></p></td>
<td><p>逐元素计算 <cite>x</cite> 的高斯误差函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Erfc.html#mindspore.ops.Erfc" title="mindspore.ops.Erfc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Erfc</span></code></a></p></td>
<td><p>逐元素计算 <cite>x</cite> 的互补误差函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code>  <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Erfinv.html#mindspore.ops.Erfinv" title="mindspore.ops.Erfinv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Erfinv</span></code></a></p></td>
<td><p>计算输入Tensor的逆误差函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Exp.html#mindspore.ops.Exp" title="mindspore.ops.Exp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Exp</span></code></a></p></td>
<td><p>逐元素计算输入Tensor的指数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Expm1.html#mindspore.ops.Expm1" title="mindspore.ops.Expm1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Expm1</span></code></a></p></td>
<td><p>返回Tensor元素的指数，然后减去1。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Floor.html#mindspore.ops.Floor" title="mindspore.ops.Floor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Floor</span></code></a></p></td>
<td><p>向下取整函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.FloorDiv.html#mindspore.ops.FloorDiv" title="mindspore.ops.FloorDiv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.FloorDiv</span></code></a></p></td>
<td><p>将第一个输入Tensor除以第二个输入Tensor，并向下取整。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.FloorMod.html#mindspore.ops.FloorMod" title="mindspore.ops.FloorMod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.FloorMod</span></code></a></p></td>
<td><p>将第一个输入Tensor除以第二个输入Tensor，并向下取余。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Geqrf.html#mindspore.ops.Geqrf" title="mindspore.ops.Geqrf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Geqrf</span></code></a></p></td>
<td><p>将矩阵分解为正交矩阵 <cite>Q</cite> 和上三角矩阵 <cite>R</cite> 的乘积。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Imag.html#mindspore.ops.Imag" title="mindspore.ops.Imag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Imag</span></code></a></p></td>
<td><p>返回包含输入Tensor的虚部。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Inv.html#mindspore.ops.Inv" title="mindspore.ops.Inv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Inv</span></code></a></p></td>
<td><p>按元素计算输入Tensor的倒数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Invert.html#mindspore.ops.Invert" title="mindspore.ops.Invert"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Invert</span></code></a></p></td>
<td><p>翻转输入Tensor的所有元素。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Lerp.html#mindspore.ops.Lerp" title="mindspore.ops.Lerp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Lerp</span></code></a></p></td>
<td><p>基于权重参数计算两个Tensor之间的线性插值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Log.html#mindspore.ops.Log" title="mindspore.ops.Log"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Log</span></code></a></p></td>
<td><p>逐元素返回Tensor的自然对数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Log1p.html#mindspore.ops.Log1p" title="mindspore.ops.Log1p"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Log1p</span></code></a></p></td>
<td><p>对输入Tensor逐元素加一后计算自然对数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.LogicalAnd.html#mindspore.ops.LogicalAnd" title="mindspore.ops.LogicalAnd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.LogicalAnd</span></code></a></p></td>
<td><p>逐元素计算两个Tensor的逻辑与运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.LogicalNot.html#mindspore.ops.LogicalNot" title="mindspore.ops.LogicalNot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.LogicalNot</span></code></a></p></td>
<td><p>逐元素计算一个Tensor的逻辑非运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.LogicalOr.html#mindspore.ops.LogicalOr" title="mindspore.ops.LogicalOr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.LogicalOr</span></code></a></p></td>
<td><p>逐元素计算两个Tensor的逻辑或运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.LogicalXor.html#mindspore.ops.LogicalXor" title="mindspore.ops.LogicalXor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.LogicalXor</span></code></a></p></td>
<td><p>逐元素计算两个Tensor的逻辑异或运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Logit.html#mindspore.ops.Logit" title="mindspore.ops.Logit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Logit</span></code></a></p></td>
<td><p>逐元素计算Tensor的logit值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Mod.html#mindspore.ops.Mod" title="mindspore.ops.Mod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Mod</span></code></a></p></td>
<td><p>将第一个输入Tensor逐元素除以第二个输入Tensor，并取余。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>输入数据不支持0。 当输出包含的元素个数超过2048时，该算子不能保证双千分之一的精度要求。 由于架构的差异，在NPU和CPU上生成的结果可能不一致。 如果shape表示为 <span class="math notranslate nohighlight">\((D1, D2, ..., Dn)\)</span> ，则 <span class="math notranslate nohighlight">\(D1*D2... *DN&lt;=1000000,n&lt;=8\)</span> 。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Mul.html#mindspore.ops.Mul" title="mindspore.ops.Mul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Mul</span></code></a></p></td>
<td><p>两个Tensor逐元素相乘。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.MulNoNan.html#mindspore.ops.MulNoNan" title="mindspore.ops.MulNoNan"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MulNoNan</span></code></a></p></td>
<td><p>逐元素计算输入乘积。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Neg.html#mindspore.ops.Neg" title="mindspore.ops.Neg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Neg</span></code></a></p></td>
<td><p>计算输入x的相反数并返回。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.NextAfter.html#mindspore.ops.NextAfter" title="mindspore.ops.NextAfter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.NextAfter</span></code></a></p></td>
<td><p>逐元素返回 <cite>x1</cite> 指向 <cite>x2</cite> 的下一个可表示值符点值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Polar.html#mindspore.ops.Polar" title="mindspore.ops.Polar"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Polar</span></code></a></p></td>
<td><p>将极坐标转化为笛卡尔坐标。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Polygamma.html#mindspore.ops.Polygamma" title="mindspore.ops.Polygamma"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Polygamma</span></code></a></p></td>
<td><p>计算关于 <cite>x</cite> 的多伽马函数的 <span class="math notranslate nohighlight">\(a\)</span> 阶导数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Pow.html#mindspore.ops.Pow" title="mindspore.ops.Pow"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Pow</span></code></a></p></td>
<td><p>计算 <cite>x</cite> 中每个元素的 <cite>y</cite> 次幂。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Real.html#mindspore.ops.Real" title="mindspore.ops.Real"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Real</span></code></a></p></td>
<td><p>返回输入Tensor的实数部分。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.RealDiv.html#mindspore.ops.RealDiv" title="mindspore.ops.RealDiv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.RealDiv</span></code></a></p></td>
<td><p>第一个输入Tensor元素为分子，第二个输入Tensor元素为分母，逐元素进行浮点型除法运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Reciprocal.html#mindspore.ops.Reciprocal" title="mindspore.ops.Reciprocal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Reciprocal</span></code></a></p></td>
<td><p>返回输入Tensor的倒数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Rint.html#mindspore.ops.Rint" title="mindspore.ops.Rint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Rint</span></code></a></p></td>
<td><p>逐元素计算最接近输入数据的整数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Round.html#mindspore.ops.Round" title="mindspore.ops.Round"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Round</span></code></a></p></td>
<td><p>逐元素返回Tensor最接近的整数值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Rsqrt.html#mindspore.ops.Rsqrt" title="mindspore.ops.Rsqrt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Rsqrt</span></code></a></p></td>
<td><p>逐元素计算输入Tensor平方根的倒数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Sign.html#mindspore.ops.Sign" title="mindspore.ops.Sign"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Sign</span></code></a></p></td>
<td><p>符号函数，计算输入Tensor元素的执行符号。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Sin.html#mindspore.ops.Sin" title="mindspore.ops.Sin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Sin</span></code></a></p></td>
<td><p>逐元素计算输入Tensor的正弦。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Sinc.html#mindspore.ops.Sinc" title="mindspore.ops.Sinc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Sinc</span></code></a></p></td>
<td><p>逐元素计算输入Tensor的数学正弦函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Sinh.html#mindspore.ops.Sinh" title="mindspore.ops.Sinh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Sinh</span></code></a></p></td>
<td><p>逐元素计算输入Tensor的双曲正弦。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Sqrt.html#mindspore.ops.Sqrt" title="mindspore.ops.Sqrt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Sqrt</span></code></a></p></td>
<td><p>逐元素计算输入Tensor的平方根。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Square.html#mindspore.ops.Square" title="mindspore.ops.Square"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Square</span></code></a></p></td>
<td><p>计算输入Tensor的平方。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.SquaredDifference.html#mindspore.ops.SquaredDifference" title="mindspore.ops.SquaredDifference"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SquaredDifference</span></code></a></p></td>
<td><p>第一个输入Tensor元素中减去第二个输入Tensor，并返回其平方。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.SquareSumAll.html#mindspore.ops.SquareSumAll" title="mindspore.ops.SquareSumAll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SquareSumAll</span></code></a></p></td>
<td><p>计算输入Tensor的平方和。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Sub.html#mindspore.ops.Sub" title="mindspore.ops.Sub"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Sub</span></code></a></p></td>
<td><p>逐元素用第一个输入Tensor减去第二个输入Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Tan.html#mindspore.ops.Tan" title="mindspore.ops.Tan"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Tan</span></code></a></p></td>
<td><p>逐元素计算输入元素的正切值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Trunc.html#mindspore.ops.Trunc" title="mindspore.ops.Trunc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Trunc</span></code></a></p></td>
<td><p>返回一个新的张量，该张量具有输入元素的截断整数值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.TruncateDiv.html#mindspore.ops.TruncateDiv" title="mindspore.ops.TruncateDiv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.TruncateDiv</span></code></a></p></td>
<td><p>将第一个输入Tensor与第二个输入Tensor逐元素相除，结果将向0取整。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.TruncateMod.html#mindspore.ops.TruncateMod" title="mindspore.ops.TruncateMod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.TruncateMod</span></code></a></p></td>
<td><p>逐元素取模。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>输入数值不能为0。 当输入含有超过2048个元素，该操作不能保证千分之二的精度要求。 由于架构不同，该算子在NPU和CPU上的计算结果可能不一致。 若shape为（D1、D2…、Dn），则D1*D2…*DN&lt;=1000000，n&lt;=8。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Xdivy.html#mindspore.ops.Xdivy" title="mindspore.ops.Xdivy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Xdivy</span></code></a></p></td>
<td><p>将第一个输入Tensor除以第二个输入Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Xlogy.html#mindspore.ops.Xlogy" title="mindspore.ops.Xlogy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Xlogy</span></code></a></p></td>
<td><p>计算第一个输入Tensor乘以第二个输入Tensor的对数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="reduction算子">
<h3>Reduction算子<a class="headerlink" href="#reduction算子" title="永久链接至标题">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Argmax.html#mindspore.ops.Argmax" title="mindspore.ops.Argmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Argmax</span></code></a></p></td>
<td><p>返回输入Tensor在指定轴上的最大值索引。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ArgMaxWithValue.html#mindspore.ops.ArgMaxWithValue" title="mindspore.ops.ArgMaxWithValue"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ArgMaxWithValue</span></code></a></p></td>
<td><p>在给定轴上计算输入Tensor的最大值，并且返回最大值和索引。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>如果有多个最大值，则取第一个最大值的索引。 “axis”的取值范围为[-dims, dims - 1]。”dims”为”x”的维度长度。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Argmin.html#mindspore.ops.Argmin" title="mindspore.ops.Argmin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Argmin</span></code></a></p></td>
<td><p>返回输入Tensor在指定轴上的最小值索引。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ArgMinWithValue.html#mindspore.ops.ArgMinWithValue" title="mindspore.ops.ArgMinWithValue"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ArgMinWithValue</span></code></a></p></td>
<td><p>在给定轴上计算输入Tensor的最小值，并且返回最小值和索引。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>如果有多个最小值，则取第一个最小值的索引。 “axis”的取值范围为[-dims, dims - 1]。”dims”为”input_x”的维度长度。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Median.html#mindspore.ops.Median" title="mindspore.ops.Median"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Median</span></code></a></p></td>
<td><p>输出Tensor指定维度 <cite>axis</cite> 上的中值与其对应的索引。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>如果 <cite>input</cite> 的中值不唯一，则 <cite>indices</cite> 不一定包含第一个出现的中值。该算子的具体实现方式和后端类型相关，CPU和GPU的返回值可能不相同。 如果 <cite>global_median</cite> 为 <code class="docutils literal notranslate"><span class="pre">True</span></code> , 第二个输出 <cite>indices</cite> 无意义。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ReduceAll.html#mindspore.ops.ReduceAll" title="mindspore.ops.ReduceAll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ReduceAll</span></code></a></p></td>
<td><p>默认情况下，通过对指定维度所有元素进行逻辑与运算以移除该维度。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ReduceAny.html#mindspore.ops.ReduceAny" title="mindspore.ops.ReduceAny"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ReduceAny</span></code></a></p></td>
<td><p>默认情况下，通过对指定维度所有元素进行逻辑或运算来移除该维度。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ReduceMax.html#mindspore.ops.ReduceMax" title="mindspore.ops.ReduceMax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ReduceMax</span></code></a></p></td>
<td><p>默认情况下，使用指定维度的最大值代替该维度的其他元素，以移除该维度。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ReduceMean.html#mindspore.ops.ReduceMean" title="mindspore.ops.ReduceMean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ReduceMean</span></code></a></p></td>
<td><p>默认情况下，使用指定维度的平均值代替该维度的其他元素，以移除该维度。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ReduceMin.html#mindspore.ops.ReduceMin" title="mindspore.ops.ReduceMin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ReduceMin</span></code></a></p></td>
<td><p>默认情况下，使用指定维度的最小值代替该维度的其他元素，以移除该维度。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ReduceProd.html#mindspore.ops.ReduceProd" title="mindspore.ops.ReduceProd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ReduceProd</span></code></a></p></td>
<td><p>默认情况下，使用指定维度所有元素的乘积代替该维度的其他元素，以移除该维度。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ReduceSum.html#mindspore.ops.ReduceSum" title="mindspore.ops.ReduceSum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ReduceSum</span></code></a></p></td>
<td><p>默认情况下，输出Tensor各维度上的和，以达到对所有维度进行归约的目的。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="比较算子">
<h3>比较算子<a class="headerlink" href="#比较算子" title="永久链接至标题">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ApproximateEqual.html#mindspore.ops.ApproximateEqual" title="mindspore.ops.ApproximateEqual"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ApproximateEqual</span></code></a></p></td>
<td><p>逐元素计算abs(x-y)，如果小于tolerance则为True，否则为False。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Equal.html#mindspore.ops.Equal" title="mindspore.ops.Equal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Equal</span></code></a></p></td>
<td><p>逐元素比较两个输入Tensor是否相等。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.EqualCount.html#mindspore.ops.EqualCount" title="mindspore.ops.EqualCount"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.EqualCount</span></code></a></p></td>
<td><p>计算两个Tensor的相同元素的数量。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Greater.html#mindspore.ops.Greater" title="mindspore.ops.Greater"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Greater</span></code></a></p></td>
<td><p>按元素比较输入参数 <span class="math notranslate nohighlight">\(x,y\)</span> 的值，输出结果为bool值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.GreaterEqual.html#mindspore.ops.GreaterEqual" title="mindspore.ops.GreaterEqual"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.GreaterEqual</span></code></a></p></td>
<td><p>输入两个Tensor，逐元素比较第一个Tensor是否大于等于第二个Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.InTopK.html#mindspore.ops.InTopK" title="mindspore.ops.InTopK"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.InTopK</span></code></a></p></td>
<td><p>判断目标标签是否在前 <cite>k</cite> 个预测中。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.IsFinite.html#mindspore.ops.IsFinite" title="mindspore.ops.IsFinite"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.IsFinite</span></code></a></p></td>
<td><p>确定输入Tensor每个位置上的元素是否为有限数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.IsInf.html#mindspore.ops.IsInf" title="mindspore.ops.IsInf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.IsInf</span></code></a></p></td>
<td><p>确定输入Tensor每个位置上的元素是否为无穷大或无穷小。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.IsNan.html#mindspore.ops.IsNan" title="mindspore.ops.IsNan"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.IsNan</span></code></a></p></td>
<td><p>判断输入数据每个位置上的值是否是NaN。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Less.html#mindspore.ops.Less" title="mindspore.ops.Less"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Less</span></code></a></p></td>
<td><p>逐元素计算 <span class="math notranslate nohighlight">\(x &lt; y\)</span> ，返回为bool。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.LessEqual.html#mindspore.ops.LessEqual" title="mindspore.ops.LessEqual"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.LessEqual</span></code></a></p></td>
<td><p>逐元素计算 <span class="math notranslate nohighlight">\(x &lt;= y\)</span> 的bool值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Maximum.html#mindspore.ops.Maximum" title="mindspore.ops.Maximum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Maximum</span></code></a></p></td>
<td><p>逐元素计算输入Tensor的最大值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Minimum.html#mindspore.ops.Minimum" title="mindspore.ops.Minimum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Minimum</span></code></a></p></td>
<td><p>逐元素计算两个Tensor的最小值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.NotEqual.html#mindspore.ops.NotEqual" title="mindspore.ops.NotEqual"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.NotEqual</span></code></a></p></td>
<td><p>逐元素计算两个Tensor是否不相等。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.TopK.html#mindspore.ops.TopK" title="mindspore.ops.TopK"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.TopK</span></code></a></p></td>
<td><p>沿最后一个维度查找 <cite>k</cite> 个最大元素和对应的索引。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>如果 <cite>sorted</cite> 设置为 <code class="docutils literal notranslate"><span class="pre">False</span></code> ，它将使用aicpu运算符，性能可能会降低，另外，由于在不同平台上存在内存排布以及遍历方式不同等问题，<cite>sorted</cite> 设置为 <code class="docutils literal notranslate"><span class="pre">False</span></code> 时计算结果的显示顺序可能会出现不一致的情况。</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="线性代数算子">
<h3>线性代数算子<a class="headerlink" href="#线性代数算子" title="永久链接至标题">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.BatchMatMul.html#mindspore.ops.BatchMatMul" title="mindspore.ops.BatchMatMul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BatchMatMul</span></code></a></p></td>
<td><p>基于batch维度的两个Tensor的矩阵乘法。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.BiasAdd.html#mindspore.ops.BiasAdd" title="mindspore.ops.BiasAdd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BiasAdd</span></code></a></p></td>
<td><p>返回输入Tensor与偏置Tensor之和。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Ger.html#mindspore.ops.Ger" title="mindspore.ops.Ger"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Ger</span></code></a></p></td>
<td><p>计算两个一维Tensor的外积。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.MatMul.html#mindspore.ops.MatMul" title="mindspore.ops.MatMul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MatMul</span></code></a></p></td>
<td><p>将矩阵 <cite>a</cite> 和矩阵 <cite>b</cite> 相乘。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.MatrixInverse.html#mindspore.ops.MatrixInverse" title="mindspore.ops.MatrixInverse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MatrixInverse</span></code></a></p></td>
<td><p>计算输入矩阵的逆矩阵。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Orgqr.html#mindspore.ops.Orgqr" title="mindspore.ops.Orgqr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Orgqr</span></code></a></p></td>
<td><p>计算 <a class="reference internal" href="ops/mindspore.ops.Geqrf.html#mindspore.ops.Geqrf" title="mindspore.ops.Geqrf"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.Geqrf</span></code></a> 返回的正交矩阵 <span class="math notranslate nohighlight">\(Q\)</span> 的显式表示。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Svd.html#mindspore.ops.Svd" title="mindspore.ops.Svd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Svd</span></code></a></p></td>
<td><p>计算一个或多个矩阵的奇异值分解。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="tensor操作算子">
<h2>Tensor操作算子<a class="headerlink" href="#tensor操作算子" title="永久链接至标题">¶</a></h2>
<div class="section" id="tensor创建">
<h3>Tensor创建<a class="headerlink" href="#tensor创建" title="永久链接至标题">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Eps.html#mindspore.ops.Eps" title="mindspore.ops.Eps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Eps</span></code></a></p></td>
<td><p>创建一个与输入数据类型和shape都相同的Tensor，元素值为对应数据类型能表达的最小值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Eye.html#mindspore.ops.Eye" title="mindspore.ops.Eye"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Eye</span></code></a></p></td>
<td><p>创建一个主对角线上元素为1，其余元素为0的Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Fill.html#mindspore.ops.Fill" title="mindspore.ops.Fill"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Fill</span></code></a></p></td>
<td><p>Fill接口已弃用， 请使用 <a class="reference internal" href="ops/mindspore.ops.FillV2.html#mindspore.ops.FillV2" title="mindspore.ops.FillV2"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.FillV2</span></code></a> 。</p></td>
<td><p>Deprecated</p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.LinSpace.html#mindspore.ops.LinSpace" title="mindspore.ops.LinSpace"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.LinSpace</span></code></a></p></td>
<td><p>返回一个在区间 <cite>start</cite> 和 <cite>stop</cite> （包括 <cite>start</cite> 和 <cite>stop</cite> ）内均匀分布的，包含 <cite>num</cite> 个值的一维Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.OneHot.html#mindspore.ops.OneHot" title="mindspore.ops.OneHot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.OneHot</span></code></a></p></td>
<td><p>返回一个one-hot类型的Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Ones.html#mindspore.ops.Ones" title="mindspore.ops.Ones"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Ones</span></code></a></p></td>
<td><p>创建一个值全为1的Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.OnesLike.html#mindspore.ops.OnesLike" title="mindspore.ops.OnesLike"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.OnesLike</span></code></a></p></td>
<td><p>返回值为1的Tensor，shape和数据类型与输入相同。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Zeros.html#mindspore.ops.Zeros" title="mindspore.ops.Zeros"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Zeros</span></code></a></p></td>
<td><p>创建一个值全为0的Tensor。</p></td>
<td><p>Deprecated</p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ZerosLike.html#mindspore.ops.ZerosLike" title="mindspore.ops.ZerosLike"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ZerosLike</span></code></a></p></td>
<td><p>返回值为0的Tensor，其shape和数据类型与输入Tensor相同。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="随机生成算子">
<h3>随机生成算子<a class="headerlink" href="#随机生成算子" title="永久链接至标题">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Bernoulli.html#mindspore.ops.Bernoulli" title="mindspore.ops.Bernoulli"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Bernoulli</span></code></a></p></td>
<td><p>以 <cite>p</cite> 的概率随机将输出的元素设置为0或1，服从伯努利分布。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Gamma.html#mindspore.ops.Gamma" title="mindspore.ops.Gamma"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Gamma</span></code></a></p></td>
<td><p>根据概率密度函数分布生成随机正值浮点数x。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Multinomial.html#mindspore.ops.Multinomial" title="mindspore.ops.Multinomial"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Multinomial</span></code></a></p></td>
<td><p>返回从输入Tensor对应行进行多项式概率分布采样出的Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.MultinomialWithReplacement.html#mindspore.ops.MultinomialWithReplacement" title="mindspore.ops.MultinomialWithReplacement"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MultinomialWithReplacement</span></code></a></p></td>
<td><p>返回一个Tensor，其中每行包含从重复采样的多项式分布中抽取的 <cite>numsamples</cite> 个索引。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.RandomCategorical.html#mindspore.ops.RandomCategorical" title="mindspore.ops.RandomCategorical"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.RandomCategorical</span></code></a></p></td>
<td><p>从分类分布中抽取样本。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.RandomChoiceWithMask.html#mindspore.ops.RandomChoiceWithMask" title="mindspore.ops.RandomChoiceWithMask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.RandomChoiceWithMask</span></code></a></p></td>
<td><p>对输入进行随机取样，返回取样索引和掩码。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.RandomGamma.html#mindspore.ops.RandomGamma" title="mindspore.ops.RandomGamma"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.RandomGamma</span></code></a></p></td>
<td><p>根据概率密度函数分布生成随机正值浮点数x。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.RandomPoisson.html#mindspore.ops.RandomPoisson" title="mindspore.ops.RandomPoisson"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.RandomPoisson</span></code></a></p></td>
<td><p>根据离散概率密度函数分布生成随机非负数浮点数i。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Randperm.html#mindspore.ops.Randperm" title="mindspore.ops.Randperm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Randperm</span></code></a></p></td>
<td><p>生成从0到n-1不重复的n个随机样本。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.StandardLaplace.html#mindspore.ops.StandardLaplace" title="mindspore.ops.StandardLaplace"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.StandardLaplace</span></code></a></p></td>
<td><p>生成符合标准Laplace（mean=0, lambda=1）分布的随机数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.StandardNormal.html#mindspore.ops.StandardNormal" title="mindspore.ops.StandardNormal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.StandardNormal</span></code></a></p></td>
<td><p>根据标准正态（高斯）随机数分布生成随机数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.UniformInt.html#mindspore.ops.UniformInt" title="mindspore.ops.UniformInt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.UniformInt</span></code></a></p></td>
<td><p>根据均匀分布在区间 <cite>[minval, maxval)</cite> 中生成随机数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.UniformReal.html#mindspore.ops.UniformReal" title="mindspore.ops.UniformReal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.UniformReal</span></code></a></p></td>
<td><p>产生随机的浮点数，均匀分布在[0, 1)范围内。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="array操作">
<h3>Array操作<a class="headerlink" href="#array操作" title="永久链接至标题">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.AffineGrid.html#mindspore.ops.AffineGrid" title="mindspore.ops.AffineGrid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.AffineGrid</span></code></a></p></td>
<td><p>基于一批仿射矩阵 theta 生成一个2D 或 3D 的流场（采样网格）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.BatchToSpace.html#mindspore.ops.BatchToSpace" title="mindspore.ops.BatchToSpace"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BatchToSpace</span></code></a></p></td>
<td><p>将批处理数据重新排列到空间数据中。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.BatchToSpaceND.html#mindspore.ops.BatchToSpaceND" title="mindspore.ops.BatchToSpaceND"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BatchToSpaceND</span></code></a></p></td>
<td><p><a class="reference internal" href="ops/mindspore.ops.BatchToSpaceND.html#mindspore.ops.BatchToSpaceND" title="mindspore.ops.BatchToSpaceND"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.BatchToSpaceND</span></code></a> 从2.0版本开始已被弃用，并将在未来版本中被移除，建议使用 <a class="reference internal" href="ops/mindspore.ops.batch_to_space_nd.html#mindspore.ops.batch_to_space_nd" title="mindspore.ops.batch_to_space_nd"><code class="xref py py-func docutils literal notranslate"><span class="pre">mindspore.ops.batch_to_space_nd()</span></code></a> 代替。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.BroadcastTo.html#mindspore.ops.BroadcastTo" title="mindspore.ops.BroadcastTo"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BroadcastTo</span></code></a></p></td>
<td><p>将输入shape广播到目标shape。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Cast.html#mindspore.ops.Cast" title="mindspore.ops.Cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Cast</span></code></a></p></td>
<td><p>转换输入Tensor的数据类型。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ChannelShuffle.html#mindspore.ops.ChannelShuffle" title="mindspore.ops.ChannelShuffle"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ChannelShuffle</span></code></a></p></td>
<td><p>将shape为 <span class="math notranslate nohighlight">\((*, C, H, W)\)</span> 的Tensor的通道划分成 <span class="math notranslate nohighlight">\(g\)</span> 组，并按如下方式重新排列 <span class="math notranslate nohighlight">\((*, \frac C g, g, H*W)\)</span> ，同时保持原始Tensor的shape不变。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Col2Im.html#mindspore.ops.Col2Im" title="mindspore.ops.Col2Im"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Col2Im</span></code></a></p></td>
<td><p>将一组通过滑窗获得的数组组合成一个大的Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Concat.html#mindspore.ops.Concat" title="mindspore.ops.Concat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Concat</span></code></a></p></td>
<td><p>在指定轴上拼接输入Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Cummax.html#mindspore.ops.Cummax" title="mindspore.ops.Cummax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Cummax</span></code></a></p></td>
<td><p>返回输入Tensor在指定轴上的累计最大值与其对应的索引。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Cummin.html#mindspore.ops.Cummin" title="mindspore.ops.Cummin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Cummin</span></code></a></p></td>
<td><p>返回输入Tensor在指定轴上的累计最小值与其对应的索引。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.CumProd.html#mindspore.ops.CumProd" title="mindspore.ops.CumProd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.CumProd</span></code></a></p></td>
<td><p>计算 <cite>x</cite> 沿着指定axis的元素累计积。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.CumSum.html#mindspore.ops.CumSum" title="mindspore.ops.CumSum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.CumSum</span></code></a></p></td>
<td><p>计算输入Tensor在指定轴上的累加和。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.DataFormatDimMap.html#mindspore.ops.DataFormatDimMap" title="mindspore.ops.DataFormatDimMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.DataFormatDimMap</span></code></a></p></td>
<td><p>返回源数据格式中的目标数据格式的维度索引。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.DepthToSpace.html#mindspore.ops.DepthToSpace" title="mindspore.ops.DepthToSpace"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.DepthToSpace</span></code></a></p></td>
<td><p>将深度数据重新排列到空间维度中。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Diag.html#mindspore.ops.Diag" title="mindspore.ops.Diag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Diag</span></code></a></p></td>
<td><p>用给定的对角线值构造对角线Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.DType.html#mindspore.ops.DType" title="mindspore.ops.DType"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.DType</span></code></a></p></td>
<td><p>计算输入Tensor的数据类型，且返回的数据类型为 <cite>mindspore.dtype</cite> 。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Eig.html#mindspore.ops.Eig" title="mindspore.ops.Eig"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Eig</span></code></a></p></td>
<td><p>计算输入方阵（batch方阵）的特征值和特征向量。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Expand.html#mindspore.ops.Expand" title="mindspore.ops.Expand"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Expand</span></code></a></p></td>
<td><p>将输入Tensor的单例维度（维度size为1）进行扩展，以匹配给定的目标shape。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ExpandDims.html#mindspore.ops.ExpandDims" title="mindspore.ops.ExpandDims"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ExpandDims</span></code></a></p></td>
<td><p>对输入 <cite>input_x</cite> 在给定的轴上添加额外维度。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.FillV2.html#mindspore.ops.FillV2" title="mindspore.ops.FillV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.FillV2</span></code></a></p></td>
<td><p>创建一个Tensor，其shape由 <cite>shape</cite> 指定，其值则由 <cite>value</cite> 进行填充。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.FloatStatus.html#mindspore.ops.FloatStatus" title="mindspore.ops.FloatStatus"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.FloatStatus</span></code></a></p></td>
<td><p>确定元素是否包含非数字（NaN）、正无穷还是负无穷。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Fmax.html#mindspore.ops.Fmax" title="mindspore.ops.Fmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Fmax</span></code></a></p></td>
<td><p>逐元素计算输入Tensor的最大值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Gather.html#mindspore.ops.Gather" title="mindspore.ops.Gather"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Gather</span></code></a></p></td>
<td><p>返回输入Tensor在指定 <cite>axis</cite> 上 <cite>input_indices</cite> 索引对应的元素组成的切片。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.GatherD.html#mindspore.ops.GatherD" title="mindspore.ops.GatherD"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.GatherD</span></code></a></p></td>
<td><p>获取指定轴的元素。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.GatherNd.html#mindspore.ops.GatherNd" title="mindspore.ops.GatherNd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.GatherNd</span></code></a></p></td>
<td><p>根据索引获取输入Tensor指定位置上的元素。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.HammingWindow.html#mindspore.ops.HammingWindow" title="mindspore.ops.HammingWindow"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.HammingWindow</span></code></a></p></td>
<td><p>使用输入窗口长度计算汉明窗口函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Heaviside.html#mindspore.ops.Heaviside" title="mindspore.ops.Heaviside"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Heaviside</span></code></a></p></td>
<td><p>计算输入中每个元素的Heaviside步长函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.HistogramFixedWidth.html#mindspore.ops.HistogramFixedWidth" title="mindspore.ops.HistogramFixedWidth"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.HistogramFixedWidth</span></code></a></p></td>
<td><p>返回一个rank为1的直方图，该直方图中的每个组的值表示数量。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Hypot.html#mindspore.ops.Hypot" title="mindspore.ops.Hypot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Hypot</span></code></a></p></td>
<td><p>将输入Tensor的逐个元素作为直角三角形的直角边，并计算其斜边的值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Identity.html#mindspore.ops.Identity" title="mindspore.ops.Identity"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Identity</span></code></a></p></td>
<td><p><a class="reference internal" href="ops/mindspore.ops.Identity.html#mindspore.ops.Identity" title="mindspore.ops.Identity"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.Identity</span></code></a> 接口将废弃，请使用 <a class="reference internal" href="ops/mindspore.ops.deepcopy.html#mindspore.ops.deepcopy" title="mindspore.ops.deepcopy"><code class="xref py py-func docutils literal notranslate"><span class="pre">mindspore.ops.deepcopy()</span></code></a> 替代。</p></td>
<td><p>Deprecated</p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Igamma.html#mindspore.ops.Igamma" title="mindspore.ops.Igamma"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Igamma</span></code></a></p></td>
<td><p>计算正则化的下层不完全伽马函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Im2Col.html#mindspore.ops.Im2Col" title="mindspore.ops.Im2Col"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Im2Col</span></code></a></p></td>
<td><p>从一个batch的输入Tensor中提取滑动局部块。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.IndexAdd.html#mindspore.ops.IndexAdd" title="mindspore.ops.IndexAdd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.IndexAdd</span></code></a></p></td>
<td><p>将Tensor <cite>y</cite> 加到Tensor <cite>x</cite> 的指定 <cite>axis</cite> 和 <cite>indices</cite> 。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.IndexFill.html#mindspore.ops.IndexFill" title="mindspore.ops.IndexFill"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.IndexFill</span></code></a></p></td>
<td><p>按 <cite>index</cite> 中给定的顺序选择索引，将输入Tensor <cite>x</cite> 的 <cite>dim</cite> 维度下的元素用 <cite>value</cite> 的值填充。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.InplaceAdd.html#mindspore.ops.InplaceAdd" title="mindspore.ops.InplaceAdd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.InplaceAdd</span></code></a></p></td>
<td><p>将 <cite>input_v</cite> 添加到 <cite>x</cite> 的特定行。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.InplaceIndexAdd.html#mindspore.ops.InplaceIndexAdd" title="mindspore.ops.InplaceIndexAdd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.InplaceIndexAdd</span></code></a></p></td>
<td><p>逐元素将一个Tensor <cite>updates</cite> 添加到原Tensor <cite>var</cite> 的指定轴和索引处。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.InplaceSub.html#mindspore.ops.InplaceSub" title="mindspore.ops.InplaceSub"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.InplaceSub</span></code></a></p></td>
<td><p>从 <cite>x</cite> 的特定行减去 <cite>input_v</cite> 。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.InplaceUpdate.html#mindspore.ops.InplaceUpdate" title="mindspore.ops.InplaceUpdate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.InplaceUpdate</span></code></a></p></td>
<td><p>InplaceUpdate接口已废弃，请使用接口 <a class="reference internal" href="ops/mindspore.ops.InplaceUpdateV2.html#mindspore.ops.InplaceUpdateV2" title="mindspore.ops.InplaceUpdateV2"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.InplaceUpdateV2</span></code></a> 替换，废弃版本2.0。</p></td>
<td><p>Deprecated</p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.InplaceUpdateV2.html#mindspore.ops.InplaceUpdateV2" title="mindspore.ops.InplaceUpdateV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.InplaceUpdateV2</span></code></a></p></td>
<td><p>根据 <cite>indices</cite>，将 <cite>x</cite> 中的某些值更新为 <cite>v</cite>。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.InvertPermutation.html#mindspore.ops.InvertPermutation" title="mindspore.ops.InvertPermutation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.InvertPermutation</span></code></a></p></td>
<td><p>计算索引的逆置换。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.IsClose.html#mindspore.ops.IsClose" title="mindspore.ops.IsClose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.IsClose</span></code></a></p></td>
<td><p>返回一个bool型Tensor，表示 <cite>x1</cite> 的每个元素与 <cite>x2</cite> 的每个元素在给定容忍度内是否“接近”。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Lcm.html#mindspore.ops.Lcm" title="mindspore.ops.Lcm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Lcm</span></code></a></p></td>
<td><p>逐个元素计算输入Tensor的最小公倍数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.LeftShift.html#mindspore.ops.LeftShift" title="mindspore.ops.LeftShift"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.LeftShift</span></code></a></p></td>
<td><p>将Tensor每个位置的值向左移动若干个比特位。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.LogSpace.html#mindspore.ops.LogSpace" title="mindspore.ops.LogSpace"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.LogSpace</span></code></a></p></td>
<td><p>返回一个大小为 <cite>steps</cite> 的1-D Tensor，其值从 <span class="math notranslate nohighlight">\(base^{start}\)</span> 到 <span class="math notranslate nohighlight">\(base^{end}\)</span> ，以 <cite>base</cite> 为底数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.LuUnpack.html#mindspore.ops.LuUnpack" title="mindspore.ops.LuUnpack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.LuUnpack</span></code></a></p></td>
<td><p>将 <cite>LU_data</cite> 和 <cite>LU_pivots</cite> 还原为为P, L, U矩阵，其中P为置换矩阵，L为下三角矩阵，U为上三角矩阵。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.MaskedFill.html#mindspore.ops.MaskedFill" title="mindspore.ops.MaskedFill"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MaskedFill</span></code></a></p></td>
<td><p>将掩码位置为True的位置填充指定的值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.MaskedSelect.html#mindspore.ops.MaskedSelect" title="mindspore.ops.MaskedSelect"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MaskedSelect</span></code></a></p></td>
<td><p>返回一个一维张量，其中的内容是 <cite>x</cite> 张量中对应于 <cite>mask</cite> 张量中True位置的值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.MatrixBandPart.html#mindspore.ops.MatrixBandPart" title="mindspore.ops.MatrixBandPart"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MatrixBandPart</span></code></a></p></td>
<td><p>提取一个Tensor中每个矩阵的中心带，中心带之外的所有值都设置为零。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.MatrixDiagPartV3.html#mindspore.ops.MatrixDiagPartV3" title="mindspore.ops.MatrixDiagPartV3"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MatrixDiagPartV3</span></code></a></p></td>
<td><p>返回Tensor的对角线部分。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.MatrixDiagV3.html#mindspore.ops.MatrixDiagV3" title="mindspore.ops.MatrixDiagV3"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MatrixDiagV3</span></code></a></p></td>
<td><p>构造以输入Tensor为对角线的矩阵。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.MatrixSetDiagV3.html#mindspore.ops.MatrixSetDiagV3" title="mindspore.ops.MatrixSetDiagV3"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MatrixSetDiagV3</span></code></a></p></td>
<td><p>更新批处理矩阵对角线的值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.MatrixSolve.html#mindspore.ops.MatrixSolve" title="mindspore.ops.MatrixSolve"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MatrixSolve</span></code></a></p></td>
<td><p>求解线性方程组。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Meshgrid.html#mindspore.ops.Meshgrid" title="mindspore.ops.Meshgrid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Meshgrid</span></code></a></p></td>
<td><p>从给定的Tensor生成网格矩阵。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Mvlgamma.html#mindspore.ops.Mvlgamma" title="mindspore.ops.Mvlgamma"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Mvlgamma</span></code></a></p></td>
<td><p>逐元素计算 <cite>p</cite> 维多元对数伽马函数值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.NanToNum.html#mindspore.ops.NanToNum" title="mindspore.ops.NanToNum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.NanToNum</span></code></a></p></td>
<td><p>将输入中的 <cite>NaN</cite> 、正无穷大和负无穷大值分别替换为 <cite>nan</cite> 、 <cite>posinf</cite> 和 <cite>neginf</cite> 指定的值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.NonZero.html#mindspore.ops.NonZero" title="mindspore.ops.NonZero"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.NonZero</span></code></a></p></td>
<td><p>计算输入Tensor中所有非零元素的索引位置。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ParallelConcat.html#mindspore.ops.ParallelConcat" title="mindspore.ops.ParallelConcat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ParallelConcat</span></code></a></p></td>
<td><p>根据第一个维度连接输入Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.PopulationCount.html#mindspore.ops.PopulationCount" title="mindspore.ops.PopulationCount"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.PopulationCount</span></code></a></p></td>
<td><p>计算二进制数中1的个数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Qr.html#mindspore.ops.Qr" title="mindspore.ops.Qr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Qr</span></code></a></p></td>
<td><p>返回一个或多个矩阵的QR（正交三角）分解。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.RandomShuffle.html#mindspore.ops.RandomShuffle" title="mindspore.ops.RandomShuffle"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.RandomShuffle</span></code></a></p></td>
<td><p>沿着Tensor的第一个维度进行随机打乱操作。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Range.html#mindspore.ops.Range" title="mindspore.ops.Range"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Range</span></code></a></p></td>
<td><p>返回从 <cite>start</cite> 开始，步长为 <cite>delta</cite> ，且不超过 <cite>limit</cite> （不包括 <cite>limit</cite> ）的序列。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Rank.html#mindspore.ops.Rank" title="mindspore.ops.Rank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Rank</span></code></a></p></td>
<td><p>返回输入Tensor的秩。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Renorm.html#mindspore.ops.Renorm" title="mindspore.ops.Renorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Renorm</span></code></a></p></td>
<td><p>对Tensor沿着指定维度 <cite>dim</cite> 进行重新规范化，要求每个子Tensor的 <cite>p</cite> 范数不超过 <cite>maxnorm</cite> 。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Reshape.html#mindspore.ops.Reshape" title="mindspore.ops.Reshape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Reshape</span></code></a></p></td>
<td><p>基于给定的shape，对输入Tensor进行重新排列。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ReverseSequence.html#mindspore.ops.ReverseSequence" title="mindspore.ops.ReverseSequence"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ReverseSequence</span></code></a></p></td>
<td><p>对输入序列进行部分反转。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ReverseV2.html#mindspore.ops.ReverseV2" title="mindspore.ops.ReverseV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ReverseV2</span></code></a></p></td>
<td><p>对输入Tensor按指定维度反转。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>“axis”的取值范围为[-dims, dims - 1]，”dims”表示”input_x”的维度长度。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.RightShift.html#mindspore.ops.RightShift" title="mindspore.ops.RightShift"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.RightShift</span></code></a></p></td>
<td><p>将Tensor <cite>input_x</cite> 的每个元素右移 Tensor <cite>input_y</cite> 中对应位数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ScatterNd.html#mindspore.ops.ScatterNd" title="mindspore.ops.ScatterNd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScatterNd</span></code></a></p></td>
<td><p>根据指定的索引将更新值散布到新Tensor上。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ScatterNdDiv.html#mindspore.ops.ScatterNdDiv" title="mindspore.ops.ScatterNdDiv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScatterNdDiv</span></code></a></p></td>
<td><p>将sparse division应用于张量中的单个值或切片。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ScatterNdMax.html#mindspore.ops.ScatterNdMax" title="mindspore.ops.ScatterNdMax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScatterNdMax</span></code></a></p></td>
<td><p>对张量中的单个值或切片应用sparse maximum。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ScatterNdMin.html#mindspore.ops.ScatterNdMin" title="mindspore.ops.ScatterNdMin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScatterNdMin</span></code></a></p></td>
<td><p>对张量中的单个值或切片应用sparse minimum。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ScatterNdMul.html#mindspore.ops.ScatterNdMul" title="mindspore.ops.ScatterNdMul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScatterNdMul</span></code></a></p></td>
<td><p>对张量中的单个值或切片应用sparse multiplication。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.SearchSorted.html#mindspore.ops.SearchSorted" title="mindspore.ops.SearchSorted"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SearchSorted</span></code></a></p></td>
<td><p>返回位置索引，根据这个索引将 <cite>values</cite> 插入 <cite>sorted_sequence</cite> 后，<cite>sorted_sequence</cite> 的元素大小顺序保持不变。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Select.html#mindspore.ops.Select" title="mindspore.ops.Select"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Select</span></code></a></p></td>
<td><p>根据条件判断Tensor中的元素的值，决定输出中的相应元素是从 <cite>x</cite> （如果元素值为True）还是从 <cite>y</cite> （如果元素值为False）中选择。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Shape.html#mindspore.ops.Shape" title="mindspore.ops.Shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Shape</span></code></a></p></td>
<td><p>返回输入Tensor的shape。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Size.html#mindspore.ops.Size" title="mindspore.ops.Size"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Size</span></code></a></p></td>
<td><p>返回一个Scalar，类型为整数，表示输入Tensor的大小，即Tensor中元素的总数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Slice.html#mindspore.ops.Slice" title="mindspore.ops.Slice"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Slice</span></code></a></p></td>
<td><p>根据指定shape对输入Tensor进行切片。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Sort.html#mindspore.ops.Sort" title="mindspore.ops.Sort"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Sort</span></code></a></p></td>
<td><p>根据指定的轴对输入Tensor的元素进行排序，默认为升序排序。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>目前仅支持float16数据类型。如果使用float32类型可能导致数据精度损失。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.SpaceToBatchND.html#mindspore.ops.SpaceToBatchND" title="mindspore.ops.SpaceToBatchND"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SpaceToBatchND</span></code></a></p></td>
<td><p>将空间维度划分为对应大小的块，并在批次维度重排张量。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.SpaceToDepth.html#mindspore.ops.SpaceToDepth" title="mindspore.ops.SpaceToDepth"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SpaceToDepth</span></code></a></p></td>
<td><p>将空间维度分块，增加Tensor深度。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.SparseGatherV2.html#mindspore.ops.SparseGatherV2" title="mindspore.ops.SparseGatherV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SparseGatherV2</span></code></a></p></td>
<td><p>基于指定的索引和axis返回输入Tensor的切片。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Split.html#mindspore.ops.Split" title="mindspore.ops.Split"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Split</span></code></a></p></td>
<td><p>根据指定的轴和分割数量对输入Tensor进行分割。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Squeeze.html#mindspore.ops.Squeeze" title="mindspore.ops.Squeeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Squeeze</span></code></a></p></td>
<td><p>返回删除指定 <cite>axis</cite> 中大小为1的维度后的Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Stack.html#mindspore.ops.Stack" title="mindspore.ops.Stack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Stack</span></code></a></p></td>
<td><p>在指定轴上对输入Tensor序列进行堆叠。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.StridedSlice.html#mindspore.ops.StridedSlice" title="mindspore.ops.StridedSlice"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.StridedSlice</span></code></a></p></td>
<td><p>对输入Tensor根据步长和索引进行切片提取。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.TensorScatterAdd.html#mindspore.ops.TensorScatterAdd" title="mindspore.ops.TensorScatterAdd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.TensorScatterAdd</span></code></a></p></td>
<td><p>根据指定的更新值和输入索引，进行加法运算更新输入Tensor的值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.TensorScatterDiv.html#mindspore.ops.TensorScatterDiv" title="mindspore.ops.TensorScatterDiv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.TensorScatterDiv</span></code></a></p></td>
<td><p>根据指定的更新值和输入索引，进行除法运算更新输入Tensor的值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.TensorScatterMax.html#mindspore.ops.TensorScatterMax" title="mindspore.ops.TensorScatterMax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.TensorScatterMax</span></code></a></p></td>
<td><p>根据指定的更新值和输入索引，通过最大值运算将结果赋值到输出Tensor中。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.TensorScatterMin.html#mindspore.ops.TensorScatterMin" title="mindspore.ops.TensorScatterMin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.TensorScatterMin</span></code></a></p></td>
<td><p>根据指定的更新值和输入索引，计算原值与更新值的较小值并更新原值，返回更新后的Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.TensorScatterMul.html#mindspore.ops.TensorScatterMul" title="mindspore.ops.TensorScatterMul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.TensorScatterMul</span></code></a></p></td>
<td><p>根据指定的更新值和输入索引，进行乘法运算更新输入Tensor的值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.TensorScatterSub.html#mindspore.ops.TensorScatterSub" title="mindspore.ops.TensorScatterSub"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.TensorScatterSub</span></code></a></p></td>
<td><p>根据指定的更新值和输入索引，进行减法运算更新输入Tensor的值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.TensorScatterUpdate.html#mindspore.ops.TensorScatterUpdate" title="mindspore.ops.TensorScatterUpdate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.TensorScatterUpdate</span></code></a></p></td>
<td><p>根据指定的更新值和输入索引，通过更新操作更新输入Tensor的值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.TensorShape.html#mindspore.ops.TensorShape" title="mindspore.ops.TensorShape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.TensorShape</span></code></a></p></td>
<td><p>返回输入Tensor的Shape。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Tile.html#mindspore.ops.Tile" title="mindspore.ops.Tile"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Tile</span></code></a></p></td>
<td><p>按照给定的次数复制输入Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Trace.html#mindspore.ops.Trace" title="mindspore.ops.Trace"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Trace</span></code></a></p></td>
<td><p>返回在Tensor的对角线方向上的总和。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Transpose.html#mindspore.ops.Transpose" title="mindspore.ops.Transpose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Transpose</span></code></a></p></td>
<td><p>根据指定的排列对输入的Tensor进行数据重排。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Tril.html#mindspore.ops.Tril" title="mindspore.ops.Tril"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Tril</span></code></a></p></td>
<td><p>返回单个或一批二维矩阵下三角形部分，其他位置的元素将被置零。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.TrilIndices.html#mindspore.ops.TrilIndices" title="mindspore.ops.TrilIndices"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.TrilIndices</span></code></a></p></td>
<td><p>计算 <cite>row</cite> * <cite>col</cite> 行列矩阵的下三角元素的索引，并将它们作为一个 2xN 的Tensor返回。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.TriuIndices.html#mindspore.ops.TriuIndices" title="mindspore.ops.TriuIndices"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.TriuIndices</span></code></a></p></td>
<td><p>计算 <cite>row</cite> * <cite>col</cite> 行列矩阵的上三角元素的索引，并将它们作为一个 2xN 的Tensor返回。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Unique.html#mindspore.ops.Unique" title="mindspore.ops.Unique"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Unique</span></code></a></p></td>
<td><p>返回输入Tensor的唯一元素以及其对应的每个值的索引。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.UniqueConsecutive.html#mindspore.ops.UniqueConsecutive" title="mindspore.ops.UniqueConsecutive"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.UniqueConsecutive</span></code></a></p></td>
<td><p>对输入张量中连续且重复的元素去重。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.UniqueWithPad.html#mindspore.ops.UniqueWithPad" title="mindspore.ops.UniqueWithPad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.UniqueWithPad</span></code></a></p></td>
<td><p>对输入一维张量中元素去重，返回一维张量中的唯一元素（使用pad_num填充）和相对索引。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.UnsortedSegmentMax.html#mindspore.ops.UnsortedSegmentMax" title="mindspore.ops.UnsortedSegmentMax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.UnsortedSegmentMax</span></code></a></p></td>
<td><p>沿分段计算输入Tensor的最大值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.UnsortedSegmentMin.html#mindspore.ops.UnsortedSegmentMin" title="mindspore.ops.UnsortedSegmentMin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.UnsortedSegmentMin</span></code></a></p></td>
<td><p>沿分段计算输入Tensor的最小值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.UnsortedSegmentProd.html#mindspore.ops.UnsortedSegmentProd" title="mindspore.ops.UnsortedSegmentProd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.UnsortedSegmentProd</span></code></a></p></td>
<td><p>沿分段计算输入Tensor元素的乘积。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.UnsortedSegmentSum.html#mindspore.ops.UnsortedSegmentSum" title="mindspore.ops.UnsortedSegmentSum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.UnsortedSegmentSum</span></code></a></p></td>
<td><p>沿分段计算输入Tensor元素的和。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Unstack.html#mindspore.ops.Unstack" title="mindspore.ops.Unstack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Unstack</span></code></a></p></td>
<td><p>根据指定轴对输入矩阵进行分解。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="类型转换">
<h3>类型转换<a class="headerlink" href="#类型转换" title="永久链接至标题">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ScalarCast.html#mindspore.ops.ScalarCast" title="mindspore.ops.ScalarCast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScalarCast</span></code></a></p></td>
<td><p>将输入Scalar转换为其他类型。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ScalarToTensor.html#mindspore.ops.ScalarToTensor" title="mindspore.ops.ScalarToTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScalarToTensor</span></code></a></p></td>
<td><p>将Scalar转换为指定数据类型的 <cite>Tensor</cite> 。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.TupleToArray.html#mindspore.ops.TupleToArray" title="mindspore.ops.TupleToArray"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.TupleToArray</span></code></a></p></td>
<td><p>将tuple转换为Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="parameter操作算子">
<h2>Parameter操作算子<a class="headerlink" href="#parameter操作算子" title="永久链接至标题">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Assign.html#mindspore.ops.Assign" title="mindspore.ops.Assign"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Assign</span></code></a></p></td>
<td><p>为网络参数赋值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.AssignAdd.html#mindspore.ops.AssignAdd" title="mindspore.ops.AssignAdd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.AssignAdd</span></code></a></p></td>
<td><p>进行加法运算更新网络参数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.AssignSub.html#mindspore.ops.AssignSub" title="mindspore.ops.AssignSub"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.AssignSub</span></code></a></p></td>
<td><p>从网络参数减去特定数值来更新网络参数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ScatterAdd.html#mindspore.ops.ScatterAdd" title="mindspore.ops.ScatterAdd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScatterAdd</span></code></a></p></td>
<td><p>根据指定更新值和输入索引通过加法运算更新输入数据的值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ScatterDiv.html#mindspore.ops.ScatterDiv" title="mindspore.ops.ScatterDiv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScatterDiv</span></code></a></p></td>
<td><p>通过除法操作更新输入张量的值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ScatterMax.html#mindspore.ops.ScatterMax" title="mindspore.ops.ScatterMax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScatterMax</span></code></a></p></td>
<td><p>通过最大操作更新输入张量的值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ScatterMin.html#mindspore.ops.ScatterMin" title="mindspore.ops.ScatterMin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScatterMin</span></code></a></p></td>
<td><p>通过最小操作更新输入张量的值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ScatterMul.html#mindspore.ops.ScatterMul" title="mindspore.ops.ScatterMul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScatterMul</span></code></a></p></td>
<td><p>根据指定更新值和输入索引通过乘法运算更新输入数据的值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ScatterNdAdd.html#mindspore.ops.ScatterNdAdd" title="mindspore.ops.ScatterNdAdd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScatterNdAdd</span></code></a></p></td>
<td><p>使用给定值通过加法运算和输入索引更新Tensor值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ScatterNdSub.html#mindspore.ops.ScatterNdSub" title="mindspore.ops.ScatterNdSub"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScatterNdSub</span></code></a></p></td>
<td><p>使用给定值通过减法运算和输入索引更新Tensor值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ScatterNdUpdate.html#mindspore.ops.ScatterNdUpdate" title="mindspore.ops.ScatterNdUpdate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScatterNdUpdate</span></code></a></p></td>
<td><p>使用给定值以及输入索引更新输入数据的值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ScatterNonAliasingAdd.html#mindspore.ops.ScatterNonAliasingAdd" title="mindspore.ops.ScatterNonAliasingAdd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScatterNonAliasingAdd</span></code></a></p></td>
<td><p>使用给定值通过加法操作和输入索引来更新Tensor值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ScatterSub.html#mindspore.ops.ScatterSub" title="mindspore.ops.ScatterSub"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScatterSub</span></code></a></p></td>
<td><p>使用给定更新值通过减法操作和输入索引来更新Tensor值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ScatterUpdate.html#mindspore.ops.ScatterUpdate" title="mindspore.ops.ScatterUpdate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScatterUpdate</span></code></a></p></td>
<td><p>使用给定的更新值和输入索引更新输入Tensor的值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="数据操作算子">
<h2>数据操作算子<a class="headerlink" href="#数据操作算子" title="永久链接至标题">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.GetNext.html#mindspore.ops.GetNext" title="mindspore.ops.GetNext"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.GetNext</span></code></a></p></td>
<td><p>返回数据集队列中的下一个元素。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="通信算子">
<h2>通信算子<a class="headerlink" href="#通信算子" title="永久链接至标题">¶</a></h2>
<p>注意，以下列表中的接口需要先配置好通信环境变量。</p>
<p>针对Ascend设备，用户需要准备rank表，设置rank_id和device_id，详见 <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/master/parallel/train_ascend.html#准备环节">Ascend指导文档 </a> 。</p>
<p>针对GPU设备，用户需要准备host文件和mpi，详见 <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/master/parallel/train_gpu.html#准备环节">GPU指导文档 </a> 。</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.AllGather.html#mindspore.ops.AllGather" title="mindspore.ops.AllGather"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.AllGather</span></code></a></p></td>
<td><p>在指定的通信组中汇聚Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.AllReduce.html#mindspore.ops.AllReduce" title="mindspore.ops.AllReduce"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.AllReduce</span></code></a></p></td>
<td><p>使用指定方式对通信组内的所有设备的Tensor数据进行规约操作，所有设备都得到相同的结果。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.AlltoAll.html#mindspore.ops.AlltoAll" title="mindspore.ops.AlltoAll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.AlltoAll</span></code></a></p></td>
<td><p>AlltoAll是一个集合通信函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Broadcast.html#mindspore.ops.Broadcast" title="mindspore.ops.Broadcast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Broadcast</span></code></a></p></td>
<td><p>对输入数据整组广播。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.NeighborExchangeV2.html#mindspore.ops.NeighborExchangeV2" title="mindspore.ops.NeighborExchangeV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.NeighborExchangeV2</span></code></a></p></td>
<td><p>NeighborExchangeV2是一个集合通讯操作。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ReduceOp.html#mindspore.ops.ReduceOp" title="mindspore.ops.ReduceOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ReduceOp</span></code></a></p></td>
<td><p>规约张量的操作选项。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ReduceScatter.html#mindspore.ops.ReduceScatter" title="mindspore.ops.ReduceScatter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ReduceScatter</span></code></a></p></td>
<td><p>规约并且分发指定通信组中的张量。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="调试算子">
<h2>调试算子<a class="headerlink" href="#调试算子" title="永久链接至标题">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.HistogramSummary.html#mindspore.ops.HistogramSummary" title="mindspore.ops.HistogramSummary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.HistogramSummary</span></code></a></p></td>
<td><p>计算Tensor的直方图并保存到Summary文件。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.ImageSummary.html#mindspore.ops.ImageSummary" title="mindspore.ops.ImageSummary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ImageSummary</span></code></a></p></td>
<td><p>将图像保存到Summary文件。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.ScalarSummary.html#mindspore.ops.ScalarSummary" title="mindspore.ops.ScalarSummary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.ScalarSummary</span></code></a></p></td>
<td><p>将标量数据保存到Summary文件。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.TensorSummary.html#mindspore.ops.TensorSummary" title="mindspore.ops.TensorSummary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.TensorSummary</span></code></a></p></td>
<td><p>将Tensor保存到Summary文件。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Print.html#mindspore.ops.Print" title="mindspore.ops.Print"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Print</span></code></a></p></td>
<td><p>将输入数据进行打印输出。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.NPUAllocFloatStatus.html#mindspore.ops.NPUAllocFloatStatus" title="mindspore.ops.NPUAllocFloatStatus"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.NPUAllocFloatStatus</span></code></a></p></td>
<td><p>分配一个标志来存储溢出状态。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.NPUClearFloatStatus.html#mindspore.ops.NPUClearFloatStatus" title="mindspore.ops.NPUClearFloatStatus"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.NPUClearFloatStatus</span></code></a></p></td>
<td><p>清除存储溢出状态的标识。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.NPUGetFloatStatus.html#mindspore.ops.NPUGetFloatStatus" title="mindspore.ops.NPUGetFloatStatus"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.NPUGetFloatStatus</span></code></a></p></td>
<td><p>在执行 <a class="reference internal" href="ops/mindspore.ops.NPUAllocFloatStatus.html#mindspore.ops.NPUAllocFloatStatus" title="mindspore.ops.NPUAllocFloatStatus"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.NPUAllocFloatStatus</span></code></a> 后， <cite>NPUGetFloatStatus</cite>  获取最新溢出状态并更新标识。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="稀疏算子">
<h2>稀疏算子<a class="headerlink" href="#稀疏算子" title="永久链接至标题">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.SparseTensorDenseMatmul.html#mindspore.ops.SparseTensorDenseMatmul" title="mindspore.ops.SparseTensorDenseMatmul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SparseTensorDenseMatmul</span></code></a></p></td>
<td><p>稀疏矩阵 <cite>A</cite> 乘以稠密矩阵 <cite>B</cite> 。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.SparseToDense.html#mindspore.ops.SparseToDense" title="mindspore.ops.SparseToDense"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.SparseToDense</span></code></a></p></td>
<td><p>将稀疏Tensor转换为密集Tensor。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="框架算子">
<h2>框架算子<a class="headerlink" href="#框架算子" title="永久链接至标题">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Depend.html#mindspore.ops.Depend" title="mindspore.ops.Depend"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Depend</span></code></a></p></td>
<td><p>用来处理操作间的依赖关系。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.GradOperation.html#mindspore.ops.GradOperation" title="mindspore.ops.GradOperation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.GradOperation</span></code></a></p></td>
<td><p>一个高阶函数，为输入函数生成梯度函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.HookBackward.html#mindspore.ops.HookBackward" title="mindspore.ops.HookBackward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.HookBackward</span></code></a></p></td>
<td><p>用来导出中间变量中的梯度。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.HyperMap.html#mindspore.ops.HyperMap" title="mindspore.ops.HyperMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.HyperMap</span></code></a></p></td>
<td><p>对输入序列做集合运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.InsertGradientOf.html#mindspore.ops.InsertGradientOf" title="mindspore.ops.InsertGradientOf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.InsertGradientOf</span></code></a></p></td>
<td><p>为图节点附加回调函数，将在梯度计算时被调用。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Map.html#mindspore.ops.Map" title="mindspore.ops.Map"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Map</span></code></a></p></td>
<td><p>Map将对输入序列应用设置的函数操作。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.MultitypeFuncGraph.html#mindspore.ops.MultitypeFuncGraph" title="mindspore.ops.MultitypeFuncGraph"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.MultitypeFuncGraph</span></code></a></p></td>
<td><p>MultitypeFuncGraph是一个用于生成重载函数的类，使用不同类型作为输入。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.Partial.html#mindspore.ops.Partial" title="mindspore.ops.Partial"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Partial</span></code></a></p></td>
<td><p>生成偏函数的实例。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>无</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="算子信息注册">
<h2>算子信息注册<a class="headerlink" href="#算子信息注册" title="永久链接至标题">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"></tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.AiCPURegOp.html#mindspore.ops.AiCPURegOp" title="mindspore.ops.AiCPURegOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.AiCPURegOp</span></code></a></p></td>
<td><p>AiCPU算子信息注册类。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.CustomRegOp.html#mindspore.ops.CustomRegOp" title="mindspore.ops.CustomRegOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.CustomRegOp</span></code></a></p></td>
<td><p>用于为 <a class="reference internal" href="ops/mindspore.ops.Custom.html#mindspore.ops.Custom" title="mindspore.ops.Custom"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.Custom</span></code></a> 的 <cite>func</cite> 参数生成算子注册信息的类。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.DataType.html#mindspore.ops.DataType" title="mindspore.ops.DataType"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.DataType</span></code></a></p></td>
<td><p>Ascend算子的dtype和format的多种组合。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.TBERegOp.html#mindspore.ops.TBERegOp" title="mindspore.ops.TBERegOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.TBERegOp</span></code></a></p></td>
<td><p>注册TBE算子信息的类。</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.get_vm_impl_fn.html#mindspore.ops.get_vm_impl_fn" title="mindspore.ops.get_vm_impl_fn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.get_vm_impl_fn</span></code></a></p></td>
<td><p>通过Primitive对象或Primitive名称，获取虚拟实现函数。</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="自定义算子">
<h2>自定义算子<a class="headerlink" href="#自定义算子" title="永久链接至标题">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.Custom.html#mindspore.ops.Custom" title="mindspore.ops.Custom"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.Custom</span></code></a></p></td>
<td><p><cite>Custom</cite> 算子是MindSpore自定义算子的统一接口。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="光谱算子">
<h2>光谱算子<a class="headerlink" href="#光谱算子" title="永久链接至标题">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 45%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>接口名</strong></p></td>
<td><p><strong>概述</strong></p></td>
<td><p><strong>支持平台</strong></p></td>
<td><p><strong>警告</strong></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="ops/mindspore.ops.BartlettWindow.html#mindspore.ops.BartlettWindow" title="mindspore.ops.BartlettWindow"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BartlettWindow</span></code></a></p></td>
<td><p>巴特利特窗口函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="ops/mindspore.ops.BlackmanWindow.html#mindspore.ops.BlackmanWindow" title="mindspore.ops.BlackmanWindow"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.ops.BlackmanWindow</span></code></a></p></td>
<td><p>布莱克曼窗口函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
<td><p>这是一个实验性API，后续可能修改或删除。</p></td>
</tr>
</tbody>
</table>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="ops/mindspore.ops.Primitive.html" class="btn btn-neutral float-right" title="mindspore.ops.Primitive" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="ops/mindspore.ops.csr_tanh.html" class="btn btn-neutral float-left" title="mindspore.ops.csr_tanh" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; 版权所有 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>