

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>数据处理 &mdash; MindSpore master 文档</title>
  

  
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/training.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/js/training.js"></script>
        <script src="../_static/translations.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="执行问题" href="implement_problem.html" />
    <link rel="prev" title="安装" href="installation.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">设计</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../design/overview.html">MindSpore设计概览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/programming_paradigm.html">编程范式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/auto_gradient.html">函数式微分编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/mindir.html">中间表示MindIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/all_scenarios.html">全场景统一</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/dynamic_graph_and_static_graph.html">动静态图结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/pluggable_device.html">三方硬件对接</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/distributed_training_design.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/graph_fusion_engine.html">图算融合加速引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/glossary.html">术语</a></li>
</ul>
<p class="caption"><span class="caption-text">模型库</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/official_models.html">官方模型库</a></li>
</ul>
<p class="caption"><span class="caption-text">语法支持</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/static_graph_syntax_support.html">静态图语法支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/index_support.html">Tensor索引支持</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/master/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption"><span class="caption-text">API映射</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/pytorch_api_mapping.html">PyTorch与MindSpore API映射表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/tensorflow_api_mapping.html">TensorFlow与MindSpore API映射表</a></li>
</ul>
<p class="caption"><span class="caption-text">迁移指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/overview.html">迁移指南概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/enveriment_preparation.html">环境准备与资料获取</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/analysis_and_preparation.html">模型分析与准备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/model_development/model_development.html">MindSpore网络搭建</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/debug_and_tune.html">调试调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/sample_code.html">网络迁移调试实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/faq.html">常见问题</a></li>
</ul>
<p class="caption"><span class="caption-text">FAQ</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">安装</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="implement_problem.html">执行问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="network_compilation.html">网络编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage_migrate_3rd.html">第三方框架迁移使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_parallel.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_advice.html">特性咨询</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>数据处理</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/faq/data_processing.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="数据处理">
<h1>数据处理<a class="headerlink" href="#数据处理" title="永久链接至标题">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/master/docs/mindspore/source_zh_cn/faq/data_processing.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source.png"></a></p>
<p><font size=3><strong>Q: 请问如果不使用高阶API，怎么实现数据下沉？</strong></font></p>
<p>A: 可以参考此手动下沉方式的<a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/master/tests/st/data_transfer/test_tdt_data_transfer.py">test_tdt_data_transfer.py</a>示例实现，不用借助<code class="docutils literal notranslate"><span class="pre">model.train</span></code>接口，目前支持：GPU和Ascend硬件使用。</p>
<br/>
<p><font size=3><strong>Q: 在使用<code class="docutils literal notranslate"><span class="pre">Dataset</span></code>处理数据过程中内存占用高，怎么优化？</strong></font></p>
<p>A: 可以参考如下几个步骤来降低内存占用，同时也可能会降低数据处理的效率。</p>
<ol class="simple">
<li><p>在定义数据集<code class="docutils literal notranslate"><span class="pre">**Dataset</span></code>对象前，设置<code class="docutils literal notranslate"><span class="pre">Dataset</span></code>数据处理预取的大小，<code class="docutils literal notranslate"><span class="pre">ds.config.set_prefetch_size(2)</span></code>。</p></li>
<li><p>在定义<code class="docutils literal notranslate"><span class="pre">**Dataset</span></code>对象时，设置其参数<code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>为1。</p></li>
<li><p>如果对<code class="docutils literal notranslate"><span class="pre">**Dataset</span></code>对象进一步使用了<code class="docutils literal notranslate"><span class="pre">.map(...)</span></code>操作，可以设置<code class="docutils literal notranslate"><span class="pre">.map(...)</span></code>的参数<code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>为1。</p></li>
<li><p>如果对<code class="docutils literal notranslate"><span class="pre">**Dataset</span></code>对象进一步使用了<code class="docutils literal notranslate"><span class="pre">.batch(...)</span></code>操作，可以设置<code class="docutils literal notranslate"><span class="pre">.batch(...)</span></code>的参数<code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>为1。</p></li>
<li><p>如果对<code class="docutils literal notranslate"><span class="pre">**Dataset</span></code>对象进一步使用了<code class="docutils literal notranslate"><span class="pre">.shuffle(...)</span></code>操作，可以把参数<code class="docutils literal notranslate"><span class="pre">buffer_size</span></code>设置减少。</p></li>
</ol>
<br/>
<p><font size=3><strong>Q: 在使用<code class="docutils literal notranslate"><span class="pre">Dataset</span></code>处理数据过程中CPU占用高，表现为sy占用高而us占用低，怎么优化？</strong></font></p>
<p>A: 可以参考如下几个步骤来降低CPU占用，进一步提升性能，其主要原因是三方库多线程与数据处理多线程存在资源竞争。</p>
<ol class="simple">
<li><p>如果数据处理阶段有opencv的<code class="docutils literal notranslate"><span class="pre">cv2</span></code>操作，那么通过<code class="docutils literal notranslate"><span class="pre">cv2.setNumThreads(2)</span></code>设置<code class="docutils literal notranslate"><span class="pre">cv2</span></code>全局线程数。</p></li>
<li><p>如果数据处理阶段有<code class="docutils literal notranslate"><span class="pre">numpy</span></code>操作，那么通过<code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">OPENBLAS_NUM_THREADS=1</span></code>设置<code class="docutils literal notranslate"><span class="pre">OPENBLAS</span></code>线程数。</p></li>
<li><p>如果数据处理阶段有<code class="docutils literal notranslate"><span class="pre">numba</span></code>操作，那么通过<code class="docutils literal notranslate"><span class="pre">numba.set_num_threads(1)</span></code>设置并行度来减少线程竞争。</p></li>
</ol>
<br/>
<p><font size=3><strong>Q: 在<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>中，看到有参数<code class="docutils literal notranslate"><span class="pre">shuffle</span></code>，在跑任务时发现<code class="docutils literal notranslate"><span class="pre">shuffle=True</span></code>和<code class="docutils literal notranslate"><span class="pre">shuffle=False</span></code>，两者没有区别，这是为什么？</strong></font></p>
<p>A: 开启<code class="docutils literal notranslate"><span class="pre">shuffle</span></code>,需要传入的<code class="docutils literal notranslate"><span class="pre">Dataset</span></code>是支持随机访问的（例如自定义的<code class="docutils literal notranslate"><span class="pre">Dataset</span></code>有<code class="docutils literal notranslate"><span class="pre">getitem</span></code>方法），如果是在自定义的<code class="docutils literal notranslate"><span class="pre">Dataset</span></code>里面通过<code class="docutils literal notranslate"><span class="pre">yeild</span></code>方式返回回来的数据，是不支持随机访问的，具体可查看教程中的<a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/master/beginner/dataset.html#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86">自定义数据集</a>章节。</p>
<br/>
<p><font size=3><strong>Q: 请问<code class="docutils literal notranslate"><span class="pre">Dataset</span></code>如何把两个<code class="docutils literal notranslate"><span class="pre">columns</span></code>合并成一个<code class="docutils literal notranslate"><span class="pre">column</span></code>？</strong></font></p>
<p>A: 可以添加如下操作把 两个字段合成一个。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">combine</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">combine</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;data2&quot;</span><span class="p">],</span> <span class="n">output_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>注：因为两个<code class="docutils literal notranslate"><span class="pre">columns</span></code>是不同的<code class="docutils literal notranslate"><span class="pre">shape</span></code>，需要先<code class="docutils literal notranslate"><span class="pre">flatten</span></code>下，然后再合并。</p>
<br/>
<p><font size=3><strong>Q: 请问<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>支持<code class="docutils literal notranslate"><span class="pre">ds.PKSampler</span></code>采样吗？</strong></font></p>
<p>A: 自定义数据集<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>不支持<code class="docutils literal notranslate"><span class="pre">PKSampler</span></code>采样逻辑。主要原因是自定义数据操作灵活度太大了，内置的<code class="docutils literal notranslate"><span class="pre">PKSampler</span></code>难以做到通用性，所以选择在接口层面直接提示不支持。但是对于<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>，可以方便的定义自己需要的<code class="docutils literal notranslate"><span class="pre">Sampler</span></code>逻辑，即在<code class="docutils literal notranslate"><span class="pre">ImageDataset</span></code>类的<code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>函数中定义具体的<code class="docutils literal notranslate"><span class="pre">sampler</span></code>规则，返回自己需要的数据即可。</p>
<br/>
<p><font size=3><strong>Q: MindSpore如何加载已有的预训练词向量？</strong></font></p>
<p>A: 可以在定义EmbedingLookup或者Embedding时候，把预训练的词向量传进来，把预训练的词向量封装成一个Tensor作为EmbeddingLookup初始值。</p>
<br/>
<p><font size=3><strong>Q: 请问<code class="docutils literal notranslate"><span class="pre">c_transforms</span></code>和<code class="docutils literal notranslate"><span class="pre">py_transforms</span></code>有什么区别，比较推荐使用哪个？</strong></font></p>
<p>A: 推荐使用<code class="docutils literal notranslate"><span class="pre">c_transforms</span></code>，因为纯C层执行，所以性能会更好。</p>
<p>原理:<code class="docutils literal notranslate"><span class="pre">c_transform</span></code>底层使用的是C版本<code class="docutils literal notranslate"><span class="pre">opencv/jpeg-turbo</span></code>进行的数据处理，<code class="docutils literal notranslate"><span class="pre">py_transform</span></code>使用的是Python版本的<code class="docutils literal notranslate"><span class="pre">Pillow</span></code>进行数据处理。</p>
<p>在MindSpore1.8开始，数据增强API进行了合并，用户无需显式感知<code class="docutils literal notranslate"><span class="pre">c_transforms</span></code>和<code class="docutils literal notranslate"><span class="pre">py_transforms</span></code>，MindSpore将根据传入数据增强API的数据类型决定使用何种后端，默认使用<code class="docutils literal notranslate"><span class="pre">c_transforms</span></code>，因其性能更佳。详细可以参考<a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/master/docs/api/api_python/mindspore.dataset.transforms.rst#%E8%A7%86%E8%A7%89">最新API文档与import说明</a>。</p>
<br/>
<p><font size=3><strong>Q: 由于我一条数据包含多个图像，并且每个图像的宽高都不一致，需要对转成mindrecord格式的数据进行<code class="docutils literal notranslate"><span class="pre">map</span></code>操作。可是我从<code class="docutils literal notranslate"><span class="pre">record</span></code>读取的数据是<code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code>格式的数据，我的数据处理的<code class="docutils literal notranslate"><span class="pre">operations</span></code>是针对图像格式的。我应该怎么样才能对所生成的mindrecord的格式的数据进行预处理呢？</strong></font></p>
<p>A: 建议你按照如下操作进行:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#1 The defined schema is as follows: Among them, data1, data2, data3, ... These fields store your image, and only the binary of the image is stored here.</span>

<span class="n">cv_schema_json</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;int32&quot;</span><span class="p">},</span> <span class="s2">&quot;data1&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;bytes&quot;</span><span class="p">},</span> <span class="s2">&quot;data2&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;bytes&quot;</span><span class="p">},</span> <span class="s2">&quot;data3&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;bytes&quot;</span><span class="p">}}</span>

<span class="c1">#2 The organized data can be as follows, and then this data_list can be written by FileWriter.write_raw_data(...).</span>

<span class="n">data_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;1.jpg&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
<span class="n">image_bytes</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span>

<span class="n">data</span><span class="p">[</span><span class="s1">&#39;data1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_bytes</span>

<span class="n">f2</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;2.jpg&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
<span class="n">image_bytes2</span> <span class="o">=</span> <span class="n">f2</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">f2</span><span class="o">.</span><span class="n">close</span>

<span class="n">data</span><span class="p">[</span><span class="s1">&#39;data2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_bytes2</span>

<span class="n">f3</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;3.jpg&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
<span class="n">image_bytes3</span> <span class="o">=</span> <span class="n">f3</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">f3</span><span class="o">.</span><span class="n">close</span>

<span class="n">data</span><span class="p">[</span><span class="s1">&#39;data3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_bytes3</span>

<span class="n">data_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1">#3 Use MindDataset to load, then use the decode operation we provide to decode, and then perform subsequent processing.</span>

<span class="n">data_set</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">MindDataset</span><span class="p">(</span><span class="s2">&quot;mindrecord_file_name&quot;</span><span class="p">)</span>
<span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data1&quot;</span><span class="p">],</span> <span class="n">operations</span><span class="o">=</span><span class="n">vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data2&quot;</span><span class="p">],</span> <span class="n">operations</span><span class="o">=</span><span class="n">vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data3&quot;</span><span class="p">],</span> <span class="n">operations</span><span class="o">=</span><span class="n">vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">resize_op</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">)</span>
<span class="n">data_set</span> <span class="o">=</span> <span class="n">data_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">resize_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data1&quot;</span><span class="p">],</span> <span class="n">num_parallel_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data_set</span><span class="o">.</span><span class="n">create_dict_iterator</span><span class="p">(</span><span class="n">output_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: 我的自定义图像数据集转为mindrecord格式时，我的数据是<code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>格式的，且<code class="docutils literal notranslate"><span class="pre">shape</span></code>为[4,100,132,3]，这个<code class="docutils literal notranslate"><span class="pre">shape</span></code>的含义是四幅三通道的帧，且每个值都在0~255。可是当我查看转化成mindrecord的格式的数据时，发现是<code class="docutils literal notranslate"><span class="pre">[19800]</span></code>的<code class="docutils literal notranslate"><span class="pre">shape</span></code>，我原数据的维度全部展开有<code class="docutils literal notranslate"><span class="pre">[158400]</span></code>，请问这是为什么？</strong></font></p>
<p>A: 可能是你数据中<code class="docutils literal notranslate"><span class="pre">ndarray</span></code>的<code class="docutils literal notranslate"><span class="pre">dtype</span></code>是<code class="docutils literal notranslate"><span class="pre">int8</span></code>，因为<code class="docutils literal notranslate"><span class="pre">[158400]</span></code>和<code class="docutils literal notranslate"><span class="pre">[19800]</span></code>刚好相差了8倍，建议将数据中<code class="docutils literal notranslate"><span class="pre">ndarray</span></code>的<code class="docutils literal notranslate"><span class="pre">dtype</span></code>指定为<code class="docutils literal notranslate"><span class="pre">float64</span></code>。</p>
<br/>
<p><font size=3><strong>Q: 想要保存生成的图片，代码运行完毕以后在相应目录找不到图片。相似的，在JupyterLab中生成数据集用于训练，训练时可以在相应路径读取到数据，但是自己却无法在路径中找到图片或数据集？</strong></font></p>
<p>A: 可能是JumperLab生成的图片或者数据集都是在Docker内，<code class="docutils literal notranslate"><span class="pre">moxing</span></code>下载的数据只能训练进程的Docker内看见，训练完成后这些数据就随着Docker释放了。 可以试试在训练任务中将需要<code class="docutils literal notranslate"><span class="pre">download</span></code>的数据再通过<code class="docutils literal notranslate"><span class="pre">moxing</span></code>传回<code class="docutils literal notranslate"><span class="pre">obs</span></code>，然后再在<code class="docutils literal notranslate"><span class="pre">obs</span></code>里面下载到你本地。</p>
<br/>
<p><font size=3><strong>Q: MindSpore中<code class="docutils literal notranslate"><span class="pre">model.train</span></code>的<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode</span></code>参数该如何理解？</strong></font></p>
<p>A: 当<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode=True</span></code>时，数据处理会和网络计算构成Pipeline方式，即: 数据处理在逐步处理数据时，处理完一个<code class="docutils literal notranslate"><span class="pre">batch</span></code>的数据，会把数据放到一个队列里，这个队列用于缓存已经处理好的数据，然后网络计算从这个队列里面取数据用于训练，那么此时数据处理与网络计算就<code class="docutils literal notranslate"><span class="pre">Pipeline</span></code>起来了，整个训练耗时就是数据处理/网络计算耗时最长的那个。</p>
<p>当<code class="docutils literal notranslate"><span class="pre">dataset_sink_mode=False</span></code>时，数据处理会和网络计算构成串行的过程，即: 数据处理在处理完一个<code class="docutils literal notranslate"><span class="pre">batch</span></code>后，把这个<code class="docutils literal notranslate"><span class="pre">batch</span></code>的数据传递给网络用于计算，在计算完成后，数据处理再处理下一个<code class="docutils literal notranslate"><span class="pre">batch</span></code>，然后把这个新的<code class="docutils literal notranslate"><span class="pre">batch</span></code>数据传递给网络用于计算，如此的循环往复，直到训练完。该方法的总耗时是数据处理的耗时+网络计算的耗时=训练总耗时。</p>
<br/>
<p><font size=3><strong>Q: MindSpore能否支持按批次对不同尺寸的图片数据进行训练？</strong></font></p>
<p>A: 你可以参考yolov3对于此场景的使用，里面有对于图像的不同缩放,脚本见<a class="reference external" href="https://gitee.com/mindspore/models/blob/master/official/cv/YOLOv3/src/yolo_dataset.py">yolo_dataset</a>。</p>
<br/>
<p><font size=3><strong>Q: 使用MindSpore做分割训练，必须将数据转为MindRecord吗？</strong></font></p>
<p>A: <a class="reference external" href="https://gitee.com/mindspore/models/blob/master/research/cv/FCN8s/src/data/build_seg_data.py">build_seg_data.py</a>是将数据集生成MindRecord的脚本，可以直接使用/适配下你的数据集。或者如果你想尝试自己实现数据集的读取，可以使用<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>自定义数据集加载。</p>
<p><a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/master/beginner/dataset.html#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86">GenratorDataset 示例</a></p>
<p><a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/api_python/dataset/mindspore.dataset.GeneratorDataset.html#mindspore.dataset.GeneratorDataset">GenratorDataset API说明</a></p>
<br/>
<p><font size=3><strong>Q: MindSpore在Ascend硬件平台进行多卡训练，自定义数据集如何给不同卡传递不同数据？</strong></font></p>
<p>A: 使用<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>的时候，可以使用<code class="docutils literal notranslate"><span class="pre">num_shards=num_shards</span></code>,<code class="docutils literal notranslate"><span class="pre">shard_id=device_id</span></code>参数来控制不同卡读取哪个分片的数据，<code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>和<code class="docutils literal notranslate"><span class="pre">__len__</span></code>按全量数据集处理即可。</p>
<p>举例:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 卡0:</span>
<span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="c1"># 卡1:</span>
<span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="c1"># 卡2:</span>
<span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="o">...</span>
<span class="c1"># 卡7:</span>
<span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shard_id</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: 如何构建图像的多标签MindRecord格式数据集？</strong></font></p>
<p>A: 数据Schema可以按如下方式定义: <code class="docutils literal notranslate"><span class="pre">cv_schema_json</span> <span class="pre">=</span> <span class="pre">{&quot;label&quot;:</span> <span class="pre">{&quot;type&quot;:</span> <span class="pre">&quot;int32&quot;,</span> <span class="pre">&quot;shape&quot;:</span> <span class="pre">[-1]},</span> <span class="pre">&quot;data&quot;:</span> <span class="pre">{&quot;type&quot;:</span> <span class="pre">&quot;bytes&quot;}}</span></code></p>
<p>说明: label是一个数组，numpy类型，这里面可以存 1， 1，0，1， 0， 1 这么多label值，这些label值对应同一个data，即: 同一个图像的二进制值。
可以参考<a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/master/advanced/dataset/record.html#%E8%BD%AC%E6%8D%A2%E6%88%90record%E6%A0%BC%E5%BC%8F">将数据集转换为MindRecord</a>教程。</p>
<br/>
<p><font size=3><strong>Q: 请问自己制作的黑底白字<code class="docutils literal notranslate"><span class="pre">28*28</span></code>的数字图片，使用MindSpore训练出来的模型做预测，报错提示<code class="docutils literal notranslate"><span class="pre">wrong</span> <span class="pre">shape</span> <span class="pre">of</span> <span class="pre">image</span></code>是怎么回事？</strong></font></p>
<p>A: 首先MindSpore训练使用的灰度图MNIST数据集。所以模型使用时对数据是有要求的，需要设置为<code class="docutils literal notranslate"><span class="pre">28*28</span></code>的灰度图，就是单通道才可以。</p>
<br/>
<p><font size=3><strong>Q: MindSpore设计了专门用于数据处理的框架，有相关的设计和用法介绍？</strong></font></p>
<p>A: MindSpore Dataset模块使得用户很简便地定义数据预处理Pipeline，并以高效（多进程/多线程）的方式处理数据集中样本，同时MindSpore Dataset也提供了多样化的API加载和处理数据集，详细介绍请参阅<a class="reference external" href="https://mindspore.cn/docs/zh-CN/master/api_python/mindspore.dataset.html#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86pipeline%E4%BB%8B%E7%BB%8D">数据处理Pipeline介绍</a>。如果想进一步对数据处理Pipeline进行性能调优，请参阅<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/master/dataset/optimize.html">数据处理性能优化</a>。</p>
<br/>
<p><font size=3><strong>Q: 网络训练时出现报错提示数据下发失败“TDT Push data into device Failed”，如何定位原因？</strong></font></p>
<p>A: 首先上述报错指的是通过训练数据下发通道（TDT，train data transfer)发送数据到卡（device）上失败，导致这一报错的原因可能有多种，因此日志中给出了相应的检查建议，具体而言:</p>
<ol>
<li><p>通常我们会找到日志中最先抛出的错误（第一个ERROR级别的错误）或报错堆栈（TraceBack)，并尝试从中找到有助于定位错误原因的信息。</p></li>
<li><p><strong>在图编译阶段，训练还没开始报错时</strong>（例如日志中还没打印loss)，请先检查下报错（ERROR）日志中是否有网络中涉及的相关算子报错或涉及环境没配置好导致的报错（如hccl.json不对导致多卡通信初始化异常）。</p></li>
<li><p><strong>在中间训练过程中报错时</strong>，通常为下发的数据量（batch数）与网络训练需要的数据量（step数）不匹配导致的，可以通过<code class="docutils literal notranslate"><span class="pre">get_dataset_size</span></code>接口打印一个epoch中包含的batch数，导致异常的部分可能原因如下：</p>
<ul>
<li><p>通过查看打印loss次数的等方式判断如果数据量（step数）刚好为一个epoch中batch数的整数倍，则可能是数据处理部分涉及epoch的处理存在问题，如下面这场景:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">create_tuple_iteator</span><span class="p">(</span><span class="n">num_epochs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 此处如果要返回一个迭代器则num_epochs应该给1, 但建议直接返回dataset</span>
<span class="k">return</span> <span class="n">dataset</span>
</pre></div>
</div>
</li>
<li><p>考虑是否是数据处理性能较慢，跟不上网络训练的速度，针对这一场景，可借助profiler工具和MindSpore Insight看一下是否存在明显的迭代间隙，或手动遍历一下dataset，并打印计算下平均单batch的耗时，是否比网络正反向加起来的时间更长，如果是则大概率需要对数据处理部分进行性能优化。</p></li>
<li><p>训练过程中出现异常数据抛出异常导致下发数据失败，通常这种情况会有其他报错（ERROR）日志会提示数据处理哪个环节出现了异常及检查建议。如果不明显，也可以通过遍历dataset每条数据的方式尝试找出异常的数据（如关闭shuffle, 然后进行二分法）。</p></li>
</ul>
</li>
<li><p>如果<strong>在训练结束后</strong>打印这条日志（大抵是强制释放资源导致），可忽略这个报错。</p></li>
<li><p>如果仍不能定位具体原因，请通过提issue或论坛提问等方式找模块开发人员协助定位。</p></li>
</ol>
<br/>
<p><font size=3><strong>Q: py_transforms 和 c_transforms 增强操作能否混合使用，如果混合使用具体需要怎么使用？</strong></font></p>
<p>A: 出于高性能考虑，通常不建议将py_transforms 与 c_transforms增强操作混合使用，但若不追求极致的性能，主要考虑打通流程，在无法全部使用c_transforms增强模块（缺少对应的c_transforms增强操作）的情况下，可使用py_transforms模块中的增强操作替代，此时即存在混合使用。
对此我们需要注意c_transforms 增强模块的输出通常是numpy array，py_transforms增强模块的输出是PIL Image，具体可查看对应的模块说明，为此通常的混合使用方法为：</p>
<ul class="simple">
<li><p>c_transforms 增强操作 + ToPIL操作 + py_transforms 增强操作 + ToNumpy操作</p></li>
<li><p>py_transforms 增强操作 + ToNumpy操作 + c_transforms 增强操作</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># example that using c_transforms and py_transforms operations together</span>
<span class="c1"># in following case: c_vision refers to c_transforms, py_vision refer to py_transforms</span>
<span class="kn">import</span> <span class="nn">mindspore.vision.c_transforms</span> <span class="k">as</span> <span class="nn">c_vision</span>
<span class="kn">import</span> <span class="nn">mindspore.vision.py_transforms</span> <span class="k">as</span> <span class="nn">py_vision</span>

<span class="n">decode_op</span> <span class="o">=</span> <span class="n">c_vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">()</span>

<span class="c1"># If input type is not PIL, then add ToPIL operation.</span>
<span class="n">transforms</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">py_vision</span><span class="o">.</span><span class="n">ToPIL</span><span class="p">(),</span>
    <span class="n">py_vision</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">375</span><span class="p">),</span>
    <span class="n">py_vision</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">]</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span><span class="n">transforms</span><span class="p">)</span>
<span class="n">data1</span> <span class="o">=</span> <span class="n">data1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">decode_op</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>
<span class="n">data1</span> <span class="o">=</span> <span class="n">data1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>在MindSpore1.8之后，由于数据增强API的合并，写作上会更简洁，如：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.vision</span> <span class="k">as</span> <span class="nn">vision</span>

<span class="n">transforms</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">(),</span>         <span class="c1"># c_transforms 数据增强</span>
    <span class="n">vision</span><span class="o">.</span><span class="n">ToPIL</span><span class="p">(),</span>          <span class="c1"># 切换下一个增强输入为PIL</span>
    <span class="n">vision</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">375</span><span class="p">),</span>  <span class="c1"># py_transforms 数据增强</span>
<span class="p">]</span>

<span class="n">data1</span> <span class="o">=</span> <span class="n">data1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="n">transforms</span><span class="p">,</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">])</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: 当错误提示 “The data pipeline is not a tree (i.e., one node has 2 consumers)” 应该怎么检查？</strong></font></p>
<p>A: 上述错误通常是脚本书写错误导致。正常情况下数据处理pipeline中的操作是依次串联的，如下列定义：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pipeline结构：</span>
<span class="c1"># dataset1 -&gt; map -&gt; shuffle -&gt; batch</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">XXDataset</span><span class="p">()</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>然而在下列异常场景中，假如dataset1有两个分叉节点，即dataset2和dataset3，就会出现上述错误。
因为dataset1节点产生了分支，其数据流向是未定义的，所以不允许出现此种情况。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pipeline结构：</span>
<span class="c1"># dataset1 -&gt; dataset2 -&gt; map</span>
<span class="c1">#          |</span>
<span class="c1">#          --&gt; dataset3 -&gt; map</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">XXDataset</span><span class="p">()</span>
<span class="n">dataset2</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">***</span><span class="p">)</span>
<span class="n">dataset3</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">***</span><span class="p">)</span>
</pre></div>
</div>
<p>正确的写法如下所示，dataset3是由dataset2进性数据增强得到的，而不是在dataset1基础上进行数据增强操作得到。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset2</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">***</span><span class="p">)</span>
<span class="n">dataset3</span> <span class="o">=</span> <span class="n">dataset2</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">***</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: MindSpore中和DataLoader对应的接口是什么？</strong></font></p>
<p>A：如果将DataLoader考虑为接收自定义Dataset的API接口，MindSpore数据处理API中和Dataloader较为相似的是GeneratorDataset，可接收用户自定义的Dataset，具体使用方式参考<a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/master/beginner/dataset.html#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86">GeneratorDataset 文档</a>，差异对比也可查看<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/master/note/api_mapping/pytorch_api_mapping.html">API算子映射表</a>。</p>
<br/>
<p><font size=3><strong>Q: 自定义的Dataset出现错误时，应该如何调试？</strong></font></p>
<p>A：自定义的Dataset通常会传入到GeneratorDataset，在使用过程中错误指向了自定义的Dataset时，可通过一些方式进行调试（如增加打印信息，打印返回值的shape、dtype等），自定义Dataset通常要保持中间处理结果为numpy array，且不建议与MindSpore网络计算的算子混合使用。此外针对自定义的Dataset如下面的MyDataset，初始化后也可直接进行如下遍历（主要为简化调试，分析原始Dataset中的问题，可不传入GeneratorDataset)，调试遵循常规的Python语法规则。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Dataset</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">()</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">Dataset</span><span class="p">:</span>
   <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;item:&quot;</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: 数据处理操作与网络计算算子能否混合使用？</strong></font></p>
<p>A：通常数据处理操作与网络计算算子混合使用会导致性能有所降低，在缺少对应的数据处理操作且自定义Python操作不合适时可进行尝试。需要注意的是，因为二者需要的输入不一致，数据处理操作通常输入为numpy array 或 PIL Image，但网络计算算子输入需要是MindSpore.Tensor;
将二者混合使用需要使上一个的输出格式和下一个所需的输入格式一致。数据处理操作指的是官网API文档中mindspore.dataset模块下的接口，如 mindspore.dataset.vision.CenterCrop，网络计算算子包含 mindspore.nn、 mindspore.ops等模块下的算子。</p>
<br/>
<p><font size=3><strong>Q: MindRecord为何会生成.db文件？ 缺少.db文件时加载数据集会有什么报错？</strong></font></p>
<p>A：.db文件为MindRecord文件对应的索引文件，缺少.db文件通常会在获取数据集总的数据量时报错，错误提示如：<code class="docutils literal notranslate"><span class="pre">MindRecordOp</span> <span class="pre">Count</span> <span class="pre">total</span> <span class="pre">rows</span> <span class="pre">failed</span></code>。</p>
<br/>
<p><font size=3><strong>Q: 自定义Dataset中如何进行图像读取并进行Decode操作？</strong></font></p>
<p>A：传入GeneratorDataset的自定义Dataset，在接口内部（如<code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>函数）进行图像读取后可以直接返回bytes类型的数据、numpy array类型的数组或已经做了解码操作的numpy array, 具体如下所示：</p>
<ul>
<li><p>读取图像后直接返回bytes类型的数据</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ImageDataset</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_path</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data_path</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="c1"># use file open and read method</span>
        <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span>
        <span class="n">img_bytes</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="c1"># return bytes directly</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">img_bytes</span><span class="p">,</span> <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># data_path is a list of image file name</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">ImageDataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">),</span> <span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
<span class="n">decode_op</span> <span class="o">=</span> <span class="n">py_vision</span><span class="o">.</span><span class="n">Decode</span><span class="p">()</span>
<span class="n">to_tensor</span> <span class="o">=</span> <span class="n">py_vision</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(</span><span class="n">output_type</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">dataset1</span> <span class="o">=</span> <span class="n">dataset1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">operations</span><span class="o">=</span><span class="p">[</span><span class="n">decode_op</span><span class="p">,</span> <span class="n">to_tensor</span><span class="p">],</span> <span class="n">input_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
</pre></div>
</div>
</li>
<li><p>读取图像后返回numpy array</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 在上面的用例中，对__getitem__函数可进行如下修改, Decode操作同上述用例一致</span>
<span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
    <span class="c1"># use np.fromfile to read image</span>
    <span class="n">img_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromfile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>

    <span class="c1"># return Numpy array directly</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">img_np</span><span class="p">,</span> <span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>读取图像后直接进行Decode操作</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 依据上面的用例，对__getitem__函数可进行如下修改, 直接返回Decode之后的数据，此后可以不需要通过map执行Decode操作</span>
<span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
    <span class="c1"># use Image.Open to open file, and convert to RGC</span>
    <span class="n">img_rgb</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">Open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">index</span><span class="p">])</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">img_rgb</span><span class="p">,</span> <span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
<br/>
<p><font size=3><strong>Q: 在使用<code class="docutils literal notranslate"><span class="pre">Dataset</span></code>处理数据过程中，报错<code class="docutils literal notranslate"><span class="pre">RuntimeError:</span> <span class="pre">can't</span> <span class="pre">start</span> <span class="pre">new</span> <span class="pre">thread</span></code>，怎么解决？</strong></font></p>
<p>A: 主要原因是在使用<code class="docutils literal notranslate"><span class="pre">**Dataset</span></code>、<code class="docutils literal notranslate"><span class="pre">.map(...)</span></code>和<code class="docutils literal notranslate"><span class="pre">.batch(...)</span></code>时，参数<code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>配置过大，用户进程数达到最大，可以通过<code class="docutils literal notranslate"><span class="pre">ulimit</span> <span class="pre">-u</span> <span class="pre">最大进程数</span></code>来增加用户最大进程数范围，或者将<code class="docutils literal notranslate"><span class="pre">num_parallel_workers</span></code>配置减小。</p>
<p><font size=3><strong>Q: 在使用<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>加载数据时，报错<code class="docutils literal notranslate"><span class="pre">RuntimeError:</span> <span class="pre">Failed</span> <span class="pre">to</span> <span class="pre">copy</span> <span class="pre">data</span> <span class="pre">into</span> <span class="pre">tensor.</span></code>，怎么解决？</strong></font></p>
<p>A: 在使用<code class="docutils literal notranslate"><span class="pre">GeneratorDataset</span></code>加载Pyfunc返回的Numpy array时，MindSpore框架将执行Numpy array到MindSpore Tensor的转换，假设Numpy array所指向的内存被释放，可能会发生内存拷贝的错误。举例如下：</p>
<ul>
<li><p>在<code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>函数中执行Numpy array - MindSpore Tensor - Numpy array的就地转换。其中Tensor <code class="docutils literal notranslate"><span class="pre">tensor</span></code>和Numpy array <code class="docutils literal notranslate"><span class="pre">ndarray_1</span></code>共享同一块内存，Tensor <code class="docutils literal notranslate"><span class="pre">tensor</span></code>在<code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>函数退出时超出作用域，其所指向的内存将被释放。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RandomAccessDataset</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="n">ndarray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">544</span><span class="p">,</span> <span class="mi">1056</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">ndarray</span><span class="p">)</span>
        <span class="n">ndarray_1</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">ndarray_1</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">8</span>

<span class="n">data1</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">RandomAccessDataset</span><span class="p">(),</span> <span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
</pre></div>
</div>
</li>
<li><p>忽略上面例子中的循环转换，在<code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>函数退出时，Tensor对象<code class="docutils literal notranslate"><span class="pre">tensor</span></code>被释放，和其共享同一块内存的Numpy array对象<code class="docutils literal notranslate"><span class="pre">ndarray_1</span></code>变成未知状态，为了规避此问题可以直接使用<code class="docutils literal notranslate"><span class="pre">deepcopy</span></code>函数为将返回的Numpy array对象<code class="docutils literal notranslate"><span class="pre">ndarray_2</span></code>申请独立的内存。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RandomAccessDataset</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="n">ndarray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">544</span><span class="p">,</span> <span class="mi">1056</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">ndarray</span><span class="p">)</span>
        <span class="n">ndarray_1</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
        <span class="n">ndarray_2</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">ndarray_1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ndarray_2</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">8</span>

<span class="n">data1</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">GeneratorDataset</span><span class="p">(</span><span class="n">RandomAccessDataset</span><span class="p">(),</span> <span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">])</span>
</pre></div>
</div>
</li>
</ul>
<br/>
<p><font size=3><strong>Q: 如何根据数据预处理退出状态判断GetNext超时原因？</strong></font></p>
<p>A: 在使用数据下沉模式（此时 <code class="docutils literal notranslate"><span class="pre">数据预处理</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">发送队列</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">网络计算</span></code> 三者构成Pipeline模式）进行训练时，当出现GetNext超时报错，数据预处理模块会输出状态信息，帮助用户分析出错原因。用户可以在日志中看到如下几种情况，具体原因及改进方法可参考：</p>
<ol>
<li><p>当日志输出类似如下时，表示数据预处理没有产生任何可用于训练的数据。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">preprocess_batch</span><span class="p">:</span> <span class="mi">0</span><span class="p">;</span>
<span class="n">batch_queue</span><span class="p">:</span> <span class="p">;</span>
            <span class="n">push_start_time</span> <span class="o">-&gt;</span> <span class="n">push_end_time</span>
</pre></div>
</div>
<p>改进方法：可以先循环数据集对象，确认数据集预处理是否正常。</p>
</li>
<li><p>当日志输出类似如下时，表示数据预处理产生了一条数据，但是仍未发送到设备侧。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">preprocess_batch</span><span class="p">:</span> <span class="mi">0</span><span class="p">;</span>
<span class="n">batch_queue</span><span class="p">:</span> <span class="mi">1</span><span class="p">;</span>
            <span class="n">push_start_time</span> <span class="o">-&gt;</span> <span class="n">push_end_time</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">11</span><span class="p">:</span><span class="mi">36</span><span class="p">:</span><span class="mf">00.521.386</span> <span class="o">-&gt;</span>
</pre></div>
</div>
<p>改进方法：可以查看设备plog是否有报错信息。</p>
</li>
<li><p>当日志输出类似如下时，表示数据预处理产生了三条数据，并且都已经发送到设备侧，同时正在预处理第4条数据。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">preprocess_batch</span><span class="p">:</span> <span class="mi">3</span><span class="p">;</span>
<span class="n">batch_queue</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">;</span>
            <span class="n">push_start_time</span> <span class="o">-&gt;</span> <span class="n">push_end_time</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">11</span><span class="p">:</span><span class="mi">36</span><span class="p">:</span><span class="mf">00.521.386</span> <span class="o">-&gt;</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">11</span><span class="p">:</span><span class="mi">36</span><span class="p">:</span><span class="mf">00.782.215</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">11</span><span class="p">:</span><span class="mi">36</span><span class="p">:</span><span class="mf">01.212.621</span> <span class="o">-&gt;</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">11</span><span class="p">:</span><span class="mi">36</span><span class="p">:</span><span class="mf">01.490.139</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">11</span><span class="p">:</span><span class="mi">36</span><span class="p">:</span><span class="mf">01.893.412</span> <span class="o">-&gt;</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">11</span><span class="p">:</span><span class="mi">36</span><span class="p">:</span><span class="mf">02.006.771</span>
</pre></div>
</div>
<p>改进方法：查看最后一条 <code class="docutils literal notranslate"><span class="pre">push_end_time</span></code> 时间 与 GetNext报错时间，如果超过默认GetNext超时时间（默认：1900s，且可通过 <code class="docutils literal notranslate"><span class="pre">mindspore.set_context(op_timeout=xx)</span></code> 来进行修改），说明数据预处理性能差，可参考 <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/master/dataset/optimize.html">数据处理性能优化</a> 对数据预处理部分进行优化。</p>
</li>
<li><p>当日志输出类似如下时，表示数据预处理产生了182条数据，正在向设备发送第183条数据。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">preprocess_batch</span><span class="p">:</span> <span class="mi">182</span><span class="p">;</span>
<span class="n">batch_queue</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">;</span>
            <span class="n">push_start_time</span> <span class="o">-&gt;</span> <span class="n">push_end_time</span>
                            <span class="o">-&gt;</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">00.603.866</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">00.621.146</span> <span class="o">-&gt;</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">01.018.964</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">01.043.705</span> <span class="o">-&gt;</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">01.396.650</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">01.421.501</span> <span class="o">-&gt;</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">01.807.671</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">01.828.931</span> <span class="o">-&gt;</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">02.179.945</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">02.201.960</span> <span class="o">-&gt;</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">02.555.941</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">02.584.413</span> <span class="o">-&gt;</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">02.943.839</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">02.969.583</span> <span class="o">-&gt;</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">03.309.299</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">03.337.607</span> <span class="o">-&gt;</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">03.684.034</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">03.717.230</span> <span class="o">-&gt;</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">04.038.521</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mf">04.064.571</span> <span class="o">-&gt;</span>
</pre></div>
</div>
<p>改进方法：可以查看设备plog是否有报错信息。</p>
</li>
</ol>
<br/>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="implement_problem.html" class="btn btn-neutral float-right" title="执行问题" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="installation.html" class="btn btn-neutral float-left" title="安装" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; 版权所有 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>