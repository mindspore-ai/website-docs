<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.nn.Cell &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script><script src="../../_static/jquery.js"></script>
        <script src="../../_static/js/theme.js"></script><script src="../../_static/underscore.js"></script><script src="../../_static/doctools.js"></script><script src="../../_static/js/training.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="mindspore.nn.GraphCell" href="mindspore.nn.GraphCell.html" />
    <link rel="prev" title="mindspore.nn" href="../mindspore.nn.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">设计</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../design/overview.html">MindSpore设计概览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/auto_gradient.html">函数式微分编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/mindir.html">中间表示MindIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/all_scenarios.html">全场景统一</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/dynamic_graph_and_static_graph.html">动静态图结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/distributed_training_design.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/graph_fusion_engine.html">图算融合加速引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/glossary.html">术语</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">规格</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/benchmark.html">基准性能</a></li>
<li class="toctree-l1"><a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.10/README_CN.md#目录">网络支持↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/operator_list.html">API支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/syntax_list.html">语法支持</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.audio.html">mindspore.dataset.audio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../mindspore.nn.html">mindspore.nn</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../mindspore.nn.html#基本构成单元">基本构成单元</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">mindspore.nn.Cell</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.GraphCell.html">mindspore.nn.GraphCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.LossBase.html">mindspore.nn.LossBase</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.nn.Optimizer.html">mindspore.nn.Optimizer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#容器">容器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#封装层">封装层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#卷积神经网络层">卷积神经网络层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#循环神经网络层">循环神经网络层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#嵌入层">嵌入层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#非线性激活函数层">非线性激活函数层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#线性层">线性层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#dropout层">Dropout层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#归一化层">归一化层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#池化层">池化层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#填充层">填充层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#损失函数">损失函数</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#优化器">优化器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#评价指标">评价指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#动态学习率">动态学习率</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#图像处理层">图像处理层</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#矩阵处理">矩阵处理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#工具">工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.nn.html#数学运算">数学运算</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.transformer.html">mindspore.nn.transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.function.html">mindspore.ops.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.10/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API映射</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/pytorch_api_mapping.html">PyTorch与MindSpore API映射表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/tensorflow_api_mapping.html">TensorFlow与MindSpore API映射表</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">迁移指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/overview.html">概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/enveriment_preparation.html">环境准备与资料获取</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/analysis_and_preparation.html">模型分析与准备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/model_development/model_development.html">MindSpore网络搭建</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/debug_and_tune.html">调试调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/sample_code.html">网络迁移调试实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/faq.html">常见问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/typical_api_comparision.html">与PyTorch典型区别</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/use_third_party_op.html">基于自定义算子接口调用第三方算子库</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq/installation.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/data_processing.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/implement_problem.html">执行问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/network_compilation.html">网络编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/usage_migrate_3rd.html">第三方框架迁移使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/distributed_configure.html">分布式配置</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/feature_advice.html">特性咨询</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../mindspore.nn.html">mindspore.nn</a> &raquo;</li>
      <li>mindspore.nn.Cell</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/api_python/nn/mindspore.nn.Cell.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mindspore-nn-cell">
<h1>mindspore.nn.Cell<a class="headerlink" href="#mindspore-nn-cell" title="Permalink to this headline"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.nn.Cell">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.nn.</span></span><span class="sig-name descname"><span class="pre">Cell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">auto_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flags</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell" title="Permalink to this definition"></a></dt>
<dd><p>MindSpore中神经网络的基本构成单元。模型或神经网络层应当继承该基类。</p>
<p><cite>mindspore.nn</cite> 中神经网络层也是Cell的子类，如 <a class="reference internal" href="mindspore.nn.Conv2d.html#mindspore.nn.Conv2d" title="mindspore.nn.Conv2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.nn.Conv2d</span></code></a> 、 <a class="reference internal" href="mindspore.nn.ReLU.html#mindspore.nn.ReLU" title="mindspore.nn.ReLU"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.nn.ReLU</span></code></a> 等。Cell在GRAPH_MODE(静态图模式)下将编译为一张计算图，在PYNATIVE_MODE(动态图模式)下作为神经网络的基础模块。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>auto_prefix</strong> (bool) - 是否自动为Cell及其子Cell生成NameSpace。<cite>auto_prefix</cite> 的设置影响网络参数的命名，如果设置为True，则自动给网络参数的名称添加前缀，否则不添加前缀。默认值：True。</p></li>
<li><p><strong>flags</strong> (dict) - Cell的配置信息，目前用于绑定Cell和数据集。用户也通过该参数自定义Cell属性。默认值：None。</p></li>
</ul>
</dd>
<dt>支持平台：</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">MyCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">forward_net</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">MyCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">forward_net</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inner_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_net</span> <span class="o">=</span> <span class="n">MyCell</span><span class="p">(</span><span class="n">inner_net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">my_net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
<span class="gp">... </span><span class="c1"># If the &#39;auto_prefix&#39; set to True or not set when call the &#39;__init__&#39; method of the parent class,</span>
<span class="gp">... </span><span class="c1"># the parameter&#39;s name will be &#39;net.weight&#39;.</span>
<span class="go">[Parameter (name=weight, shape=(240, 120, 4, 4), dtype=Float32, requires_grad=True)]</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.add_flags">
<span class="sig-name descname"><span class="pre">add_flags</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">flags</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.add_flags"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.add_flags" title="Permalink to this definition"></a></dt>
<dd><p>为Cell添加自定义属性。</p>
<p>在实例化Cell类时，如果入参flags不为空，会调用此方法。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>flags</strong> (dict) - Cell的配置信息，目前用于绑定Cell和数据集。用户也通过该参数自定义Cell属性。默认值：None。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.add_flags_recursive">
<span class="sig-name descname"><span class="pre">add_flags_recursive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">flags</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.add_flags_recursive"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.add_flags_recursive" title="Permalink to this definition"></a></dt>
<dd><p>如果Cell含有多个子Cell，此方法会递归得给所有子Cell添加自定义属性。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>flags</strong> (dict) - Cell的配置信息，目前用于绑定Cell和数据集。用户也通过该参数自定义Cell属性。默认值：None。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.auto_cast_inputs">
<span class="sig-name descname"><span class="pre">auto_cast_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.auto_cast_inputs"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.auto_cast_inputs" title="Permalink to this definition"></a></dt>
<dd><p>在混合精度下，自动对输入进行类型转换。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (tuple) - construct方法的输入。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>Tuple类型，经过类型转换后的输入。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.auto_parallel_compile_and_run">
<span class="sig-name descname"><span class="pre">auto_parallel_compile_and_run</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.auto_parallel_compile_and_run"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.auto_parallel_compile_and_run" title="Permalink to this definition"></a></dt>
<dd><p>是否在‘AUTO_PARALLEL’或‘SEMI_AUTO_PARALLEL’模式下执行编译流程。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>bool，<cite>_auto_parallel_compile_and_run</cite> 的值。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.bprop_debug">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">bprop_debug</span></span><a class="headerlink" href="#mindspore.nn.Cell.bprop_debug" title="Permalink to this definition"></a></dt>
<dd><p>在图模式下使用，用于标识是否使用自定义的反向传播函数。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.cast_inputs">
<span class="sig-name descname"><span class="pre">cast_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dst_type</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.cast_inputs"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.cast_inputs" title="Permalink to this definition"></a></dt>
<dd><p>将输入转换为指定类型。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (tuple[Tensor]) - 输入。</p></li>
<li><p><strong>dst_type</strong> (mindspore.dtype) - 指定的数据类型。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>tuple[Tensor]类型，转换类型后的结果。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.cast_param">
<span class="sig-name descname"><span class="pre">cast_param</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">param</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.cast_param"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.cast_param" title="Permalink to this definition"></a></dt>
<dd><p>在PyNative模式下，根据自动混合精度的精度设置转换Cell中参数的类型。</p>
<p>该接口目前在自动混合精度场景下使用。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>param</strong> (Parameter) - 需要被转换类型的输入参数。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>Parameter类型，转换类型后的参数。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.cells">
<span class="sig-name descname"><span class="pre">cells</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.cells"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.cells" title="Permalink to this definition"></a></dt>
<dd><p>返回当前Cell的子Cell的迭代器。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>Iteration类型，Cell的子Cell。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.cells_and_names">
<span class="sig-name descname"><span class="pre">cells_and_names</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cells</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.cells_and_names"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.cells_and_names" title="Permalink to this definition"></a></dt>
<dd><p>递归地获取当前Cell及输入 <cite>cells</cite> 的所有子Cell的迭代器，包括Cell的名称及其本身。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>cells</strong> (str) - 需要进行迭代的Cell。默认值：None。</p></li>
<li><p><strong>name_prefix</strong> (str) - 作用域。默认值：’’。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>Iteration类型，当前Cell及输入 <cite>cells</cite> 的所有子Cell和相对应的名称。</p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">names</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">n</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">():</span>
<span class="gp">... </span>    <span class="k">if</span> <span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
<span class="gp">... </span>        <span class="n">names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.check_names">
<span class="sig-name descname"><span class="pre">check_names</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.check_names"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.check_names" title="Permalink to this definition"></a></dt>
<dd><p>检查Cell中的网络参数名称是否重复。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.compile"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.compile" title="Permalink to this definition"></a></dt>
<dd><p>编译Cell为计算图，输入需与construct中定义的输入一致。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (tuple) - Cell的输入。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.compile_and_run">
<span class="sig-name descname"><span class="pre">compile_and_run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.compile_and_run"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.compile_and_run" title="Permalink to this definition"></a></dt>
<dd><p>编译并运行Cell，输入需与construct中定义的输入一致。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>不推荐使用该函数，建议直接调用Cell实例。</p>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (tuple) - Cell的输入。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>Object类型，执行的结果。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.construct">
<span class="sig-name descname"><span class="pre">construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.construct"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.construct" title="Permalink to this definition"></a></dt>
<dd><p>定义要执行的计算逻辑。所有子类都必须重写此方法。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>当前不支持inputs同时输入tuple类型和非tuple类型。</p>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (tuple) - 可变参数列表，默认值：()。</p></li>
<li><p><strong>kwargs</strong> (dict) - 可变的关键字参数的字典，默认值：{}。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>Tensor类型，返回计算结果。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.exec_checkpoint_graph">
<span class="sig-name descname"><span class="pre">exec_checkpoint_graph</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.exec_checkpoint_graph"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.exec_checkpoint_graph" title="Permalink to this definition"></a></dt>
<dd><p>保存checkpoint图。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.extend_repr">
<span class="sig-name descname"><span class="pre">extend_repr</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.extend_repr"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.extend_repr" title="Permalink to this definition"></a></dt>
<dd><p>在原有描述基础上扩展Cell的描述。</p>
<p>若需要在print时输出个性化的扩展信息，请在您的网络中重新实现此方法。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.flatten_weights">
<span class="sig-name descname"><span class="pre">flatten_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fusion_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.flatten_weights"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.flatten_weights" title="Permalink to this definition"></a></dt>
<dd><p>重置权重参数（即可训练参数）使用的数据内存，让这些参数按数据类型分组使用连续内存块。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>默认情况下，具有相同数据类型的参数会使用同一个连续内存块。但对于某些具有大量参数的模型，
将一个大的连续内存块分为多个小一点的内存块有可能提升性能，对于这种情况，
可以通过 <cite>fusion_size</cite> 参数来限制最大连续内存块的的大小。</p>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>fusion_size</strong> (int) - 最大连续内存块的大小（以字节为单位），0表示不限制大小。默认值：0。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.generate_scope">
<span class="sig-name descname"><span class="pre">generate_scope</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.generate_scope"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.generate_scope" title="Permalink to this definition"></a></dt>
<dd><p>为网络中的每个Cell对象生成NameSpace。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.get_flags">
<span class="sig-name descname"><span class="pre">get_flags</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.get_flags"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.get_flags" title="Permalink to this definition"></a></dt>
<dd><p>获取该Cell的自定义属性，自定义属性通过 <cite>add_flags</cite> 方法添加。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.get_func_graph_proto">
<span class="sig-name descname"><span class="pre">get_func_graph_proto</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.get_func_graph_proto"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.get_func_graph_proto" title="Permalink to this definition"></a></dt>
<dd><p>返回图的二进制原型。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.get_inputs">
<span class="sig-name descname"><span class="pre">get_inputs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.get_inputs"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.get_inputs" title="Permalink to this definition"></a></dt>
<dd><p>返回编译计算图所设置的输入。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>Tuple类型，编译计算图所设置的输入。</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>这是一个实验接口，可能会被更改或者删除。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.get_parameters">
<span class="sig-name descname"><span class="pre">get_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">expand</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.get_parameters"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.get_parameters" title="Permalink to this definition"></a></dt>
<dd><p>返回Cell中parameter的迭代器。</p>
<p>获取Cell的参数。如果 <cite>expand</cite> 为true，获取此cell和所有subcells的参数。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>expand</strong> (bool) - 如果为True，则递归地获取当前Cell和所有子Cell的parameter。否则，只生成当前Cell的子Cell的parameter。默认值：True。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>Iteration类型，Cell的parameter。</p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parameters</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">():</span>
<span class="gp">... </span>    <span class="n">parameters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.get_scope">
<span class="sig-name descname"><span class="pre">get_scope</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.get_scope"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.get_scope" title="Permalink to this definition"></a></dt>
<dd><p>返回Cell的作用域。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>String类型，网络的作用域。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.infer_param_pipeline_stage">
<span class="sig-name descname"><span class="pre">infer_param_pipeline_stage</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.infer_param_pipeline_stage"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.infer_param_pipeline_stage" title="Permalink to this definition"></a></dt>
<dd><p>推导Cell中当前 <cite>pipeline_stage</cite> 的参数。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>如果某参数不属于任何已被设置 <cite>pipeline_stage</cite> 的Cell，此参数应使用 <cite>add_pipeline_stage</cite> 方法来添加它的 <cite>pipeline_stage</cite> 信息。</p></li>
<li><p>如果某参数P被stageA和stageB两个不同stage的算子使用，那么参数P在使用 <cite>infer_param_pipeline_stage</cite> 之前，应使用 <cite>P.add_pipeline_stage(stageA)</cite> 和 <cite>P.add_pipeline_stage(stageB)</cite> 添加它的stage信息。</p></li>
</ul>
</div>
<dl class="simple">
<dt>返回：</dt><dd><p>属于当前 <cite>pipeline_stage</cite> 的参数。</p>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>RuntimeError</strong> - 如果参数不属于任何stage。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.init_parameters_data">
<span class="sig-name descname"><span class="pre">init_parameters_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">auto_parallel_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.init_parameters_data"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.init_parameters_data" title="Permalink to this definition"></a></dt>
<dd><p>初始化并替换Cell中所有的parameter的值。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>在调用 <cite>init_parameters_data</cite> 后，<cite>trainable_params()</cite> 或其他相似的接口可能返回不同的参数对象，不要保存这些结果。</p>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>auto_parallel_mode</strong> (bool) - 是否在自动并行模式下执行。默认值：False。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>Dict[Parameter, Parameter]，返回一个原始参数和替换参数的字典。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.insert_child_to_cell">
<span class="sig-name descname"><span class="pre">insert_child_to_cell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">child_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">child_cell</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.insert_child_to_cell"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.insert_child_to_cell" title="Permalink to this definition"></a></dt>
<dd><p>将一个给定名称的子Cell添加到当前Cell。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>child_name</strong> (str) - 子Cell名称。</p></li>
<li><p><strong>child_cell</strong> (Cell) - 要插入的子Cell。</p></li>
</ul>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>KeyError</strong> - 如果子Cell的名称不正确或与其他子Cell名称重复。</p></li>
<li><p><strong>TypeError</strong> - 如果子Cell的类型不正确。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.insert_param_to_cell">
<span class="sig-name descname"><span class="pre">insert_param_to_cell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">param_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_name_contain_dot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.insert_param_to_cell"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.insert_param_to_cell" title="Permalink to this definition"></a></dt>
<dd><p>向当前Cell添加参数。</p>
<p>将指定名称的参数添加到Cell中。目前在 <cite>mindspore.nn.Cell.__setattr__</cite> 中使用。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>param_name</strong> (str) - 参数名称。</p></li>
<li><p><strong>param</strong> (Parameter) - 要插入到Cell的参数。</p></li>
<li><p><strong>check_name_contain_dot</strong> (bool) - 是否对 <cite>param_name</cite> 中的”.”进行检查。默认值：True。</p></li>
</ul>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>KeyError</strong> - 如果参数名称为空或包含”.”。</p></li>
<li><p><strong>TypeError</strong> - 如果参数的类型不是Parameter。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.load_parameter_slice">
<span class="sig-name descname"><span class="pre">load_parameter_slice</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.load_parameter_slice"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.load_parameter_slice" title="Permalink to this definition"></a></dt>
<dd><p>根据并行策略获取Tensor分片并替换原始参数。</p>
<p>请参考 <cite>mindspore.common._Executor.compile</cite> 源代码中的用法。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>params</strong> (dict) - 用于初始化数据图的参数字典。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.name_cells">
<span class="sig-name descname"><span class="pre">name_cells</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.name_cells"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.name_cells" title="Permalink to this definition"></a></dt>
<dd><p>递归地获取一个Cell中所有子Cell的迭代器。</p>
<p>包括Cell名称和Cell本身。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>Dict[String, Cell]，Cell中的所有子Cell及其名称。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.param_prefix">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">param_prefix</span></span><a class="headerlink" href="#mindspore.nn.Cell.param_prefix" title="Permalink to this definition"></a></dt>
<dd><p>当前Cell的子Cell的参数名前缀。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.parameter_layout_dict">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">parameter_layout_dict</span></span><a class="headerlink" href="#mindspore.nn.Cell.parameter_layout_dict" title="Permalink to this definition"></a></dt>
<dd><p><cite>parameter_layout_dict</cite> 表示一个参数的张量layout，这种张量layout是由分片策略和分布式算子信息推断出来的。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.parameters_and_names">
<span class="sig-name descname"><span class="pre">parameters_and_names</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expand</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.parameters_and_names"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.parameters_and_names" title="Permalink to this definition"></a></dt>
<dd><p>返回Cell中parameter的迭代器。</p>
<p>包含参数名称和参数本身。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>name_prefix</strong> (str) - 作用域。默认值： ‘’。</p></li>
<li><p><strong>expand</strong> (bool) - 如果为True，则递归地获取当前Cell和所有子Cell的参数及名称；如果为False，只生成当前Cell的子Cell的参数及名称。默认值：True。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>迭代器，Cell的名称和Cell本身。</p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">names</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">n</span><span class="o">.</span><span class="n">parameters_and_names</span><span class="p">():</span>
<span class="gp">... </span>    <span class="k">if</span> <span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
<span class="gp">... </span>        <span class="n">names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.parameters_broadcast_dict">
<span class="sig-name descname"><span class="pre">parameters_broadcast_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.parameters_broadcast_dict"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.parameters_broadcast_dict" title="Permalink to this definition"></a></dt>
<dd><p>获取这个Cell的参数广播字典。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>recurse</strong> (bool) - 是否包含子Cell的参数。默认值：True。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>OrderedDict，返回参数广播字典。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.parameters_dict">
<span class="sig-name descname"><span class="pre">parameters_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.parameters_dict"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.parameters_dict" title="Permalink to this definition"></a></dt>
<dd><p>获取此Cell的parameter字典。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>recurse</strong> (bool) - 是否递归得包含所有子Cell的parameter。默认值：True。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>OrderedDict类型，返回参数字典。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.recompute">
<span class="sig-name descname"><span class="pre">recompute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.recompute"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.recompute" title="Permalink to this definition"></a></dt>
<dd><p>设置Cell重计算。Cell中输出算子以外的所有算子将被设置为重计算。如果一个算子的计算结果被输出到一些反向节点来进行梯度计算，且被设置成重计算，那么我们会在反向传播中重新计算它，而不去存储在前向传播中的中间激活层的计算结果。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>如果计算涉及到诸如随机化或全局变量之类的操作，那么目前还不能保证等价。</p></li>
<li><p>如果该Cell中算子的重计算API也被调用，则该算子的重计算模式以算子的重计算API的设置为准。</p></li>
<li><p>该接口仅配置一次，即当父Cell配置了，子Cell不需再配置。</p></li>
<li><p>Cell的输出算子默认不做重计算，这一点是基于我们减少内存占用的配置经验。如果一个Cell里面只有一个算子而且想要把这个算子设置为重计算的，那么请使用算子的重计算API。</p></li>
<li><p>当应用了重计算且内存充足时，可以配置’mp_comm_recompute=False’来提升性能。</p></li>
<li><p>当应用了重计算但内存不足时，可以配置’parallel_optimizer_comm_recompute=True’来节省内存。有相同融合group的Cell应该配置相同的parallel_optimizer_comm_recompute。</p></li>
</ul>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>mp_comm_recompute</strong> (bool) - 表示在自动并行或半自动并行模式下，指定Cell内部由模型并行引入的通信操作是否重计算。默认值：True。</p></li>
<li><p><strong>parallel_optimizer_comm_recompute</strong> (bool) - 表示在自动并行或半自动并行模式下，指定Cell内部由优化器并行引入的AllGather通信是否重计算。默认值：False。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.register_backward_hook">
<span class="sig-name descname"><span class="pre">register_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook_fn</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.register_backward_hook"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.register_backward_hook" title="Permalink to this definition"></a></dt>
<dd><p>设置Cell对象的反向hook函数。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p><cite>register_backward_hook(hook_fn)</cite> 在图模式下，或者在PyNative模式下使用 <cite>ms_function</cite> 功能时不起作用。</p></li>
<li><p>hook_fn必须有如下代码定义。 <cite>cell_id</cite> 是已注册Cell对象的信息，包括名称和ID。 <cite>grad_input</cite> 是反向传递给Cell对象的梯度。 <cite>grad_output</cite> 是Cell对象的反向输出梯度。用户可以在hook_fn中打印梯度数据或者返回新的输出梯度。</p></li>
<li><p>hook_fn返回新的输出梯度或者None：hook_fn(cell_id, grad_input, grad_output) -&gt; New grad_output or None。</p></li>
<li><p>为了避免脚本在切换到图模式时运行失败，不建议在Cell对象的 <cite>construct</cite> 函数中调用 <cite>register_backward_hook(hook_fn)</cite> 。</p></li>
<li><p>PyNative模式下，如果在Cell对象的 <cite>construct</cite> 函数中调用 <cite>register_backward_hook(hook_fn)</cite> ，那么Cell对象每次运行都将增加一个 <cite>hook_fn</cite> 。</p></li>
</ul>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>hook_fn</strong> (function) - 捕获Cell对象信息和反向输入，输出梯度的hook_fn函数。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p><cite>mindspore.common.hook_handle.HookHandle</cite> 类型，与 <cite>hook_fn</cite> 函数对应的 <cite>handle</cite> 对象。可通过调用 <cite>handle.remove()</cite> 来删除添加的 <cite>hook_fn</cite> 函数。</p>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>TypeError</strong> - 如果 <cite>hook_fn</cite> 不是Python函数。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">GradOperation</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">backward_hook_fn</span><span class="p">(</span><span class="n">cell_id</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;backward input: &quot;</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">)</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;backward output: &quot;</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">handle</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="o">.</span><span class="n">register_backward_hook</span><span class="p">(</span><span class="n">backward_hook_fn</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">x</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad</span> <span class="o">=</span> <span class="n">GradOperation</span><span class="p">(</span><span class="n">get_all</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">net</span><span class="p">)(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="go">backward input: (Tensor(shape=[1], dtype=Float32, value= [ 1.00000000e+00]),)</span>
<span class="go">backward output: (Tensor(shape=[1], dtype=Float32, value= [ 1.00000000e+00]),)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">(Tensor(shape=[1], dtype=Float32, value= [ 2.00000000e+00]),)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.register_forward_hook">
<span class="sig-name descname"><span class="pre">register_forward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook_fn</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.register_forward_hook"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.register_forward_hook" title="Permalink to this definition"></a></dt>
<dd><p>设置Cell对象的正向hook函数。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p><cite>register_forward_hook(hook_fn)</cite> 在图模式下，或者在PyNative模式下使用 <cite>ms_function</cite> 功能时不起作用。</p></li>
<li><p>hook_fn必须有如下代码定义。 <cite>cell_id</cite> 是已注册Cell对象的信息，包括名称和ID。 <cite>inputs</cite> 是网络正向传播时Cell对象的输入数据。 <cite>outputs</cite> 是网络正向传播时Cell对象的输出数据。用户可以在hook_fn中打印数据或者返回新的输出数据。</p></li>
<li><p>hook_fn返回新的输出数据或者None：hook_fn(cell_id, inputs, outputs) -&gt; New outputs or None。</p></li>
<li><p>为了避免脚本在切换到图模式时运行失败，不建议在Cell对象的 <cite>construct</cite> 函数中调用 <cite>register_forward_hook(hook_fn)</cite> 。</p></li>
<li><p>PyNative模式下，如果在Cell对象的 <cite>construct</cite> 函数中调用 <cite>register_forward_hook(hook_fn)</cite> ，那么Cell对象每次运行都将增加一个 <cite>hook_fn</cite> 。</p></li>
</ul>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>hook_fn</strong> (function) - 捕获Cell对象信息和正向输入，输出数据的hook_fn函数。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p><cite>mindspore.common.hook_handle.HookHandle</cite> 类型，与 <cite>hook_fn</cite> 函数对应的 <cite>handle</cite> 对象。可通过调用 <cite>handle.remove()</cite> 来删除添加的 <cite>hook_fn</cite> 函数。</p>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>TypeError</strong> - 如果 <cite>hook_fn</cite> 不是Python函数。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">GradOperation</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">forward_hook_fn</span><span class="p">(</span><span class="n">cell_id</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;forward inputs: &quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;forward output: &quot;</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">mul</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MatMul</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">handle</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mul</span><span class="o">.</span><span class="n">register_forward_hook</span><span class="p">(</span><span class="n">forward_hook_fn</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">x</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad</span> <span class="o">=</span> <span class="n">GradOperation</span><span class="p">(</span><span class="n">get_all</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">net</span><span class="p">)(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)),</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="go">forward inputs: (Tensor(shape=[1], dtype=Float32, value= [ 2.00000000e+00]), Tensor(shape=[1],</span>
<span class="go">                dtype=Float32, value= [ 1.00000000e+00]))</span>
<span class="go">forward output: 2.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">(Tensor(shape=[1], dtype=Float32, value= [ 2.00000000e+00]), Tensor(shape=[1], dtype=Float32,</span>
<span class="go">value= [ 2.00000000e+00]))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.register_forward_pre_hook">
<span class="sig-name descname"><span class="pre">register_forward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook_fn</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.register_forward_pre_hook"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.register_forward_pre_hook" title="Permalink to this definition"></a></dt>
<dd><p>设置Cell对象的正向pre_hook函数。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p><cite>register_forward_pre_hook(hook_fn)</cite> 在图模式下，或者在PyNative模式下使用 <cite>ms_function</cite> 功能时不起作用。</p></li>
<li><p>hook_fn必须有如下代码定义。 <cite>cell_id</cite> 是已注册Cell对象的信息，包括名称和ID。 <cite>inputs</cite> 是网络正向传播时Cell对象的输入数据。用户可以在hook_fn中打印输入数据或者返回新的输入数据。</p></li>
<li><p>hook_fn返回新的输入数据或者None：hook_fn(cell_id, inputs) -&gt; New inputs or None。</p></li>
<li><p>为了避免脚本在切换到图模式时运行失败，不建议在Cell对象的 <cite>construct</cite> 函数中调用 <cite>register_forward_pre_hook(hook_fn)</cite> 。</p></li>
<li><p>PyNative模式下，如果在Cell对象的 <cite>construct</cite> 函数中调用 <cite>register_forward_pre_hook(hook_fn)</cite> ，那么Cell对象每次运行都将增加一个 <cite>hook_fn</cite> 。</p></li>
</ul>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>hook_fn</strong> (function) - 捕获Cell对象信息和正向输入数据的hook_fn函数。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p><cite>mindspore.common.hook_handle.HookHandle</cite> 类型，与 <cite>hook_fn</cite> 函数对应的 <cite>handle</cite> 对象。可通过调用 <cite>handle.remove()</cite> 来删除添加的 <cite>hook_fn</cite> 函数。</p>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>TypeError</strong> - 如果 <cite>hook_fn</cite> 不是Python函数。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.ops</span> <span class="kn">import</span> <span class="n">GradOperation</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">forward_pre_hook_fn</span><span class="p">(</span><span class="n">cell_id</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;forward inputs: &quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">mul</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MatMul</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">handle</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mul</span><span class="o">.</span><span class="n">register_forward_pre_hook</span><span class="p">(</span><span class="n">forward_pre_hook_fn</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">x</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad</span> <span class="o">=</span> <span class="n">GradOperation</span><span class="p">(</span><span class="n">get_all</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">net</span><span class="p">)(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)),</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="go">forward inputs: (Tensor(shape=[1], dtype=Float32, value= [ 2.00000000e+00]), Tensor(shape=[1],</span>
<span class="go">                dtype=Float32, value= [ 1.00000000e+00]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">(Tensor(shape=[1], dtype=Float32, value= [ 2.00000000e+00]), Tensor(shape=[1], dtype=Float32,</span>
<span class="go">value= [ 2.00000000e+00]))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.remove_redundant_parameters">
<span class="sig-name descname"><span class="pre">remove_redundant_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.remove_redundant_parameters"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.remove_redundant_parameters" title="Permalink to this definition"></a></dt>
<dd><p>删除冗余参数。</p>
<p>这个接口通常不需要显式调用。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.run_construct">
<span class="sig-name descname"><span class="pre">run_construct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cast_inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.run_construct"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.run_construct" title="Permalink to this definition"></a></dt>
<dd><p>运行construct方法。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>该函数已经弃用，将会在未来版本中删除。不推荐使用此函数。</p>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>cast_inputs</strong> (tuple) - Cell的输入。</p></li>
<li><p><strong>kwargs</strong> (dict) - 关键字参数。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>Cell的输出。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.set_auto_parallel">
<span class="sig-name descname"><span class="pre">set_auto_parallel</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.set_auto_parallel"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.set_auto_parallel" title="Permalink to this definition"></a></dt>
<dd><p>将Cell设置为自动并行模式。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>如果一个Cell需要使用自动并行或半自动并行模式来进行训练、评估或预测，则该Cell需要调用此接口。</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.set_boost">
<span class="sig-name descname"><span class="pre">set_boost</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">boost_type</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.set_boost"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.set_boost" title="Permalink to this definition"></a></dt>
<dd><p>为了提升网络性能，可以配置boost内的算法让框架自动使能该算法来加速网络训练。</p>
<p>请确保 <cite>boost_type</cite> 所选择的算法在
<a class="reference external" href="https://gitee.com/mindspore/mindspore/tree/r1.10/mindspore/python/mindspore/boost">algorithm library</a> 算法库中。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>部分加速算法可能影响网络精度，请谨慎选择。</p>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>boost_type</strong> (str) - 加速算法。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>Cell类型，Cell本身。</p>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>ValueError</strong> - 如果 <cite>boost_type</cite> 不在boost算法库内。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.set_broadcast_flag">
<span class="sig-name descname"><span class="pre">set_broadcast_flag</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.set_broadcast_flag"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.set_broadcast_flag" title="Permalink to this definition"></a></dt>
<dd><p>设置该Cell的参数广播模式。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>mode</strong> (bool) - 指定当前模式是否进行参数广播。默认值：True。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.set_comm_fusion">
<span class="sig-name descname"><span class="pre">set_comm_fusion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fusion_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.set_comm_fusion"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.set_comm_fusion" title="Permalink to this definition"></a></dt>
<dd><p>为Cell中的参数设置融合类型。请参考 <a class="reference internal" href="../mindspore/mindspore.Parameter.html#mindspore.Parameter.comm_fusion" title="mindspore.Parameter.comm_fusion"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.Parameter.comm_fusion</span></code></a> 的描述。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>当函数被多次调用时，此属性值将被重写。</p>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>fusion_type</strong> (int) - Parameter的 <cite>comm_fusion</cite> 属性的设置值。</p></li>
<li><p><strong>recurse</strong> (bool) - 是否递归地设置子Cell的可训练参数。默认值：True。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.set_data_parallel">
<span class="sig-name descname"><span class="pre">set_data_parallel</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.set_data_parallel"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.set_data_parallel" title="Permalink to this definition"></a></dt>
<dd><p>递归设置该Cell中的所有算子的并行策略为数据并行。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>仅在图模式，使用auto_parallel_context = ParallelMode.AUTO_PARALLEL生效。</p>
</div>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">set_data_parallel</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.set_grad">
<span class="sig-name descname"><span class="pre">set_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.set_grad"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.set_grad" title="Permalink to this definition"></a></dt>
<dd><p>Cell的梯度设置。在PyNative模式下，该参数指定Cell是否需要梯度。如果为True，则在执行正向网络时，将生成需要计算梯度的反向网络。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>requires_grad</strong> (bool) - 指定网络是否需要梯度，如果为True，PyNative模式下Cell将构建反向网络。默认值：True。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>Cell类型，Cell本身。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.set_inputs">
<span class="sig-name descname"><span class="pre">set_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.set_inputs"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.set_inputs" title="Permalink to this definition"></a></dt>
<dd><p>设置编译计算图所需的输入。输入数量需与数据集数量一致。若使用Model接口，请确保所有传入Model的网络和损失函数都配置了set_inputs。
输入可以为动态或静态的Tensor。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (tuple) - Cell的输入。</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>这是一个实验接口，可能会被更改或者删除。</p>
</div>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">context</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">reluNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">reluNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">reluNet</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_dyn</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">set_inputs</span><span class="p">(</span><span class="n">input_dyn</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input1</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input1</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.set_jit_config">
<span class="sig-name descname"><span class="pre">set_jit_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">jit_config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.set_jit_config"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.set_jit_config" title="Permalink to this definition"></a></dt>
<dd><p>为Cell设置编译时所使用的JitConfig配置项。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>jit_config</strong> (JitConfig) - Cell的Jit配置信息。目前支持下面两个配置项。</p>
<ul>
<li><p><strong>jit_level</strong> (str) - 用于设置优化图的’level’参数。取值范围[‘O0’、’O1’、’O2’]。默认值：’O1’。</p>
<ul>
<li><p>O0：基本优化。</p></li>
<li><p>O1：手动优化。</p></li>
<li><p>O2：手动优化和图算融合。</p></li>
</ul>
</li>
<li><p><strong>task_sink</strong> (bool) - 是否通过数据集方式传递数据。默认值：True。</p></li>
</ul>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.set_parallel_input_with_inputs">
<span class="sig-name descname"><span class="pre">set_parallel_input_with_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.set_parallel_input_with_inputs"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.set_parallel_input_with_inputs" title="Permalink to this definition"></a></dt>
<dd><p>通过并行策略对输入张量进行切分。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>inputs</strong> (tuple) - construct方法的输入。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.set_param_fl">
<span class="sig-name descname"><span class="pre">set_param_fl</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">push_to_server</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pull_from_server</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_aggr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.set_param_fl"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.set_param_fl" title="Permalink to this definition"></a></dt>
<dd><p>设置参数与服务器交互的方式。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>push_to_server</strong> (bool) - 是否将参数推送到服务器。默认值：False。</p></li>
<li><p><strong>pull_from_server</strong> (bool) - 是否从服务器提取参数。默认值：False。</p></li>
<li><p><strong>requires_aggr</strong> (bool) - 是否在服务器中聚合参数。默认值：True。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.set_param_ps">
<span class="sig-name descname"><span class="pre">set_param_ps</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_in_server</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.set_param_ps"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.set_param_ps" title="Permalink to this definition"></a></dt>
<dd><p>设置可训练参数是否由参数服务器更新，以及是否在服务器上初始化可训练参数。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>只在运行的任务处于参数服务器模式时有效。</p>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>recurse</strong> (bool) - 是否设置子网络的可训练参数。默认值：True。</p></li>
<li><p><strong>init_in_server</strong> (bool) - 是否在服务器上初始化由参数服务器更新的可训练参数。默认值：False。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.set_train">
<span class="sig-name descname"><span class="pre">set_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.set_train"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.set_train" title="Permalink to this definition"></a></dt>
<dd><p>将Cell设置为训练模式。</p>
<p>设置当前Cell和所有子Cell的训练模式。对于训练和预测具有不同结构的网络层(如 <cite>BatchNorm</cite>)，将通过这个属性区分分支。如果设置为True，则执行训练分支，否则执行另一个分支。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>mode</strong> (bool) - 指定模型是否为训练模式。默认值：True。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>Cell类型，Cell本身。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.shard">
<span class="sig-name descname"><span class="pre">shard</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_strategy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_strategy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameter_plan</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Ascend'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.shard"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.shard" title="Permalink to this definition"></a></dt>
<dd><p>指定输入/输出Tensor的分布策略，其余算子的策略推导得到。在PyNative模式下，可以利用此方法指定某个Cell以图模式进行分布式执行。 in_strategy/out_strategy需要为元组类型，
其中的每一个元素指定对应的输入/输出的Tensor分布策略，可参考： <cite>mindspore.ops.Primitive.shard</cite> 的描述。也可以设置为None，会默认以数据并行执行。
其余算子的并行策略由输入输出指定的策略推导得到。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>需设置为PyNative模式，并且ParallelMode.AUTO_PARALLEL，同时设置 <cite>set_auto_parallel_context</cite> 中的搜索模式(search mode)为”sharding_propagation”。</p>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>in_strategy</strong> (tuple) - 指定各输入的切分策略，输入元组的每个元素可以为元组或None，元组即具体指定输入每一维的切分策略，None则会默认以数据并行执行。</p></li>
<li><p><strong>out_strategy</strong> (tuple) - 指定各输出的切分策略，用法同in_strategy。</p></li>
<li><p><strong>parameter_plan</strong> (Union[dict, None]) - 指定各参数的切分策略，传入字典时，键是str类型的参数名，值是1维整数tuple表示相应的切分策略，
如果参数名错误或对应参数已经设置了切分策略，该参数的设置会被跳过。默认值：None。</p></li>
<li><p><strong>device</strong> (string) - 指定执行设备，可以为[“CPU”, “GPU”, “Ascend”]中任意一个，默认值：”Ascend”。目前尚未使能。</p></li>
<li><p><strong>level</strong> (int) - 指定搜索切分策略的目标函数，即是最大化计算通信比、最小化内存消耗、最大化执行速度等。可以为[0, 1, 2]中任意一个，默认值：0。目前仅支持最大化计算通信比，其余模式尚未使能。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>Cell类型，Cell本身。</p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Block</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>    <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">... </span>    <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="gp">... </span>    <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense2</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">... </span>  <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dense2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">(</span><span class="n">x</span><span class="p">))))</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">x</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">example</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
<span class="gp">... </span>  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>    <span class="bp">self</span><span class="o">.</span><span class="n">block1</span> <span class="o">=</span> <span class="n">Block</span><span class="p">()</span>
<span class="gp">... </span>    <span class="bp">self</span><span class="o">.</span><span class="n">block2</span> <span class="o">=</span> <span class="n">Block</span><span class="p">()</span>
<span class="gp">... </span>    <span class="bp">self</span><span class="o">.</span><span class="n">block2</span><span class="o">.</span><span class="n">shard</span><span class="p">(</span><span class="n">in_strategy</span><span class="o">=</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),),</span> <span class="n">out_strategy</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,),</span>
<span class="gp">... </span>                      <span class="n">parameter_plan</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;self.block2.shard.dense1.weight&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)})</span>
<span class="gp">... </span>  <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.to_float">
<span class="sig-name descname"><span class="pre">to_float</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dst_type</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.to_float"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.to_float" title="Permalink to this definition"></a></dt>
<dd><p>在Cell和所有子Cell的输入上添加类型转换，以使用特定的浮点类型运行。</p>
<p>如果 <cite>dst_type</cite> 是 <cite>mindspore.dtype.float16</cite> ，Cell的所有输入(包括作为常量的input，Parameter，Tensor)都会被转换为float16。请参考 <cite>mindspore.build_train_network</cite> 的源代码中的用法。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>多次调用将产生覆盖。</p>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>dst_type</strong> (mindspore.dtype) - Cell转换为 <cite>dst_type</cite> 类型运行。 <cite>dst_type</cite> 可以是 <cite>mindspore.dtype.float16</cite> 或者  <cite>mindspore.dtype.float32</cite> 。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>Cell类型，Cell本身。</p>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>ValueError</strong> - 如果 <cite>dst_type</cite> 不是 <cite>mindspore.dtype.float32</cite> ，也不是 <cite>mindspore.dtype.float16</cite>。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">weight_init</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">mstype</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="go">Conv2d&lt;input_channels=120, output_channels=240, kernel_size=(4, 4), stride=(1, 1), pad_mode=same,</span>
<span class="go">padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW&gt;</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.trainable_params">
<span class="sig-name descname"><span class="pre">trainable_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.trainable_params"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.trainable_params" title="Permalink to this definition"></a></dt>
<dd><p>返回Cell的可训练参数。</p>
<p>返回一个可训练参数的列表。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>recurse</strong> (bool) - 是否递归地包含当前Cell的所有子Cell的可训练参数。默认值：True。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>List类型，可训练参数列表。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.untrainable_params">
<span class="sig-name descname"><span class="pre">untrainable_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.untrainable_params"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.untrainable_params" title="Permalink to this definition"></a></dt>
<dd><p>返回Cell的不可训练参数。</p>
<p>返回一个不可训练参数的列表。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>recurse</strong> (bool) - 是否递归地包含当前Cell的所有子Cell的不可训练参数。默认值：True。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>List类型，不可训练参数列表。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.update_cell_prefix">
<span class="sig-name descname"><span class="pre">update_cell_prefix</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.update_cell_prefix"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.update_cell_prefix" title="Permalink to this definition"></a></dt>
<dd><p>递归地更新所有子Cell的 <cite>param_prefix</cite> 。</p>
<p>在调用此方法后，可以通过Cell的 <cite>param_prefix</cite> 属性获取该Cell的所有子Cell的名称前缀。</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.update_cell_type">
<span class="sig-name descname"><span class="pre">update_cell_type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cell_type</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.update_cell_type"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.update_cell_type" title="Permalink to this definition"></a></dt>
<dd><p>量化感知训练网络场景下，更新当前Cell的类型。</p>
<p>此方法将Cell类型设置为 <cite>cell_type</cite> 。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>cell_type</strong> (str) - 被更新的类型，<cite>cell_type</cite> 可以是”quant”或”second-order”。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.nn.Cell.update_parameters_name">
<span class="sig-name descname"><span class="pre">update_parameters_name</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/nn/cell.html#Cell.update_parameters_name"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.nn.Cell.update_parameters_name" title="Permalink to this definition"></a></dt>
<dd><p>给网络参数名称添加 <cite>prefix</cite> 前缀字符串。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>prefix</strong> (str) - 前缀字符串。默认值：’’。</p></li>
<li><p><strong>recurse</strong> (bool) - 是否递归地包含所有子Cell的参数。默认值：True。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../mindspore.nn.html" class="btn btn-neutral float-left" title="mindspore.nn" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mindspore.nn.GraphCell.html" class="btn btn-neutral float-right" title="mindspore.nn.GraphCell" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>