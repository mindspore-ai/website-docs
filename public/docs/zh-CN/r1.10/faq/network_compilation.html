

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>网络编译 &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/js/training.js"></script>
        
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="算子编译" href="operators_compile.html" />
    <link rel="prev" title="执行问题" href="implement_problem.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">设计</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../design/overview.html">MindSpore设计概览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/auto_gradient.html">函数式微分编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/mindir.html">中间表示MindIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/all_scenarios.html">全场景统一</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/dynamic_graph_and_static_graph.html">动静态图结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/distributed_training_design.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/graph_fusion_engine.html">图算融合加速引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/glossary.html">术语</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">规格</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/benchmark.html">基准性能</a></li>
<li class="toctree-l1"><a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.10/README_CN.md#目录">网络支持↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/operator_list.html">API支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/syntax_list.html">语法支持</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.audio.html">mindspore.dataset.audio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.nn.transformer.html">mindspore.nn.transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.ops.function.html">mindspore.ops.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.10/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API映射</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/pytorch_api_mapping.html">PyTorch与MindSpore API映射表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/tensorflow_api_mapping.html">TensorFlow与MindSpore API映射表</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">迁移指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/overview.html">概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/enveriment_preparation.html">环境准备与资料获取</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/analysis_and_preparation.html">模型分析与准备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/model_development/model_development.html">MindSpore网络搭建</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/debug_and_tune.html">调试调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/sample_code.html">网络迁移调试实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/faq.html">常见问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/typical_api_comparision.html">与PyTorch典型区别</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/use_third_party_op.html">基于自定义算子接口调用第三方算子库</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_processing.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="implement_problem.html">执行问题</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">网络编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage_migrate_3rd.html">第三方框架迁移使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_configure.html">分布式配置</a></li>
<li class="toctree-l1"><a class="reference internal" href="inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_advice.html">特性咨询</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>网络编译</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/faq/network_compilation.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="网络编译">
<h1>网络编译<a class="headerlink" href="#网络编译" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r1.10/docs/mindspore/source_zh_cn/faq/network_compilation.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.10/resource/_static/logo_source.png"></a></p>
<p><font size=3><strong>Q: 编译时报错“’self.xx’ should be initialized as a ‘Parameter’ type in the ‘<code class="docutils literal notranslate"><span class="pre">__init__</span></code>’ function”怎么办？</strong></font></p>
<p>A: 在 <code class="docutils literal notranslate"><span class="pre">construct</span></code> 函数内，如果想对类成员 <code class="docutils literal notranslate"><span class="pre">self.xx</span></code> 赋值，那么 <code class="docutils literal notranslate"><span class="pre">self.xx</span></code> 必须已经在 <code class="docutils literal notranslate"><span class="pre">__init__</span></code> 函数中被定义为 <a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.10/api_python/mindspore/mindspore.Parameter.html">Parameter</a> 类型，其他类型则不支持。局部变量 <code class="docutils literal notranslate"><span class="pre">xx</span></code> 不受这个限制。</p>
<br/>
<p><font size=3><strong>Q: 编译时报错“For syntax like ‘a is not b’, b supports True, False and None”怎么办？</strong></font></p>
<p>A: 对于语法 <code class="docutils literal notranslate"><span class="pre">is</span></code> 或 <code class="docutils literal notranslate"><span class="pre">is</span> <span class="pre">not</span></code> 而言，当前 <code class="docutils literal notranslate"><span class="pre">MindSpore</span></code> 仅支持与 <code class="docutils literal notranslate"><span class="pre">True</span></code>、<code class="docutils literal notranslate"><span class="pre">False</span></code> 和 <code class="docutils literal notranslate"><span class="pre">None</span></code> 的比较。暂不支持其他类型，如字符串等。</p>
<br/>
<p><font size=3><strong>Q: 编译时报错“Only support comparison with 1 operator, but got 2”怎么办？</strong></font></p>
<p>A: 对于比较语句，<code class="docutils literal notranslate"><span class="pre">MindSpore</span></code> 最多支持一个操作数。例如不支持语句 <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">&lt;</span> <span class="pre">x</span> <span class="pre">&lt;</span> <span class="pre">3</span></code>，请使用 <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">&lt;</span> <span class="pre">x</span> <span class="pre">and</span> <span class="pre">x</span> <span class="pre">&lt;</span> <span class="pre">3</span></code> 的方式代替。</p>
<br/>
<p><font size=3><strong>Q: 编译时报错“TypeError: For ‘Cell’, the function construct requires 1 positional argument and 0 default argument, total 1, but got 2”怎么办？</strong></font></p>
<p>A: 网络的实例被调用时，会执行 <code class="docutils literal notranslate"><span class="pre">construct</span></code> 方法，然后会检查 <code class="docutils literal notranslate"><span class="pre">construct</span></code> 方法需要的参数个数和实际传入的参数个数，如果不一致则会抛出以上异常。
请检查脚本中调用网络实例时传入的参数个数，和定义的网络中 <code class="docutils literal notranslate"><span class="pre">construct</span></code> 函数需要的参数个数是否一致。</p>
<br/>
<p><font size=3><strong>Q: 编译时报错“Unsupported expression ‘Yield’”怎么办？</strong></font></p>
<p>A: MindSpore在静态图模式下不支持 <code class="docutils literal notranslate"><span class="pre">yield</span></code> 语法。另外，在静态图模式下，如果代码中错误使用了 <code class="docutils literal notranslate"><span class="pre">net.trainable_params()</span></code> 不支持语法，也会触发该报错，因为其内部实现使用了 <code class="docutils literal notranslate"><span class="pre">list(filter(iterator))</span></code> 语法，隐式调用了 <code class="docutils literal notranslate"><span class="pre">yield</span></code> 语法。代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">set_context</span><span class="p">,</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">True</span>

<span class="k">class</span> <span class="nc">TestNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TestNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">()</span>

<span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">TestNet</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">()</span>
</pre></div>
</div>
<p>执行结果如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>RuntimeError: Unsupported expression &#39;Yield&#39;.
More details please refer to syntax support at https://www.mindspore.cn

----------------------------------------------------
- The Traceback of Net Construct Code:
----------------------------------------------------
The function call stack (See file &#39;analyze_fail.dat&#39; for more details. Get instructions about `analyze_fail.dat` at https://www.mindspore.cn/search?inputValue=analyze_fail.dat):
# 0 In file test.py:13
        return net.trainable_params()
               ^
# 1 In file /home/workspace/mindspore/build/package/mindspore/nn/cell.py:1257
        return list(filter(lambda x: x.requires_grad, self.get_parameters(expand=recurse)))
                                                      ^
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: 编译时报错“Type Join Failed”或“Shape Join Failed”怎么办？</strong></font></p>
<p>A: 在前端编译的推理阶段，会对节点的抽象类型(包含 <code class="docutils literal notranslate"><span class="pre">type</span></code>、<code class="docutils literal notranslate"><span class="pre">shape</span></code> 等)进行推导，常见抽象类型包括 <code class="docutils literal notranslate"><span class="pre">AbstractScalar</span></code>、<code class="docutils literal notranslate"><span class="pre">AbstractTensor</span></code>、<code class="docutils literal notranslate"><span class="pre">AbstractFunction</span></code>、<code class="docutils literal notranslate"><span class="pre">AbstractTuple</span></code>、<code class="docutils literal notranslate"><span class="pre">AbstractList</span></code> 等。在一些场景比如多分支场景，会对不同分支返回值的抽象类型进行 <code class="docutils literal notranslate"><span class="pre">join</span></code> 合并，推导出返回结果的抽象类型。如果抽象类型不匹配，或者 <code class="docutils literal notranslate"><span class="pre">type</span></code>/<code class="docutils literal notranslate"><span class="pre">shape</span></code> 不一致，则会抛出以上异常。</p>
<p>当出现类似“Type Join Failed: dtype1 = Float32, dtype2 = Float16”的报错时，说明数据类型不一致，导致抽象类型合并失败。根据提供的数据类型和代码行信息，可以快速定位出错范围。此外，报错信息中提供了具体的抽象类型信息、节点信息，可以通过 <code class="docutils literal notranslate"><span class="pre">analyze_fail.dat</span></code> 文件查看MindIR信息，定位解决问题。关于MindIR的具体介绍，可以参考<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.10/design/mindir.html">MindSpore IR（MindIR）</a>。代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cast</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Cast</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="n">b</span><span class="p">:</span>    <span class="c1"># if的两个分支返回值的type不一致</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>    <span class="c1"># shape: (2, 3, 4, 5), dtype:Float32</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>    <span class="c1"># shape: (2, 3, 4, 5)， dtype:Float16</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">input_a</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">input_b</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">out_me</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_a</span><span class="p">,</span> <span class="n">input_b</span><span class="p">)</span>
</pre></div>
</div>
<p>执行结果如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>TypeError: Cannot join the return values of different branches, perhaps you need to make them equal.
Type Join Failed: dtype1 = Float32, dtype2 = Float16.
For more details, please refer to https://www.mindspore.cn/search?inputValue=Type%20Join%20Failed.

Inner Message:
The abstract type of the return value of the current branch is AbstractTensor(shape: (2, 3, 4, 5), element: AbstractScalar(Type: Float16, Value: AnyValue, Shape: NoShape), value_ptr: 0x55b9f289d090, value: AnyValue), and that of the previous branch is AbstractTensor(shape: (2, 3, 4, 5), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0x55b9f289d090, value: AnyValue).
The node is construct.6:[CNode]13{[0]: construct.6:[CNode]12{[0]: ValueNode&lt;Primitive&gt; Switch, [1]: [CNode]11, [2]: ValueNode&lt;FuncGraph&gt; ✓construct.4, [3]: ValueNode&lt;FuncGraph&gt; ✗construct.5}}, true branch: ✓construct.4, false branch: ✗construct.5

The function call stack (See file &#39;analyze_fail.dat&#39; for more details. Get instructions about `analyze_fail.dat` at https://www.mindspore.cn/search?inputValue=analyze_fail.dat):
# 0 In file test.py(14)
        if a &gt; b:
        ^
</pre></div>
</div>
<p>当出现类似“Shape Join Failed: shape1 = (2, 3, 4, 5), shape2 = ()”的报错时，说明 <code class="docutils literal notranslate"><span class="pre">shape</span></code> 不一致，导致抽象类型合并失败。代码样例如下:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reducesum</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="n">b</span><span class="p">:</span>    <span class="c1"># if的两个分支返回值的shape不一致</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>    <span class="c1"># shape: (2, 3, 4, 5), dtype:Float32</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reducesum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>    <span class="c1"># shape:(), dype: Float32</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">input_a</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">input_b</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_a</span><span class="p">,</span> <span class="n">input_b</span><span class="p">)</span>
</pre></div>
</div>
<p>执行结果如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ValueError: Cannot join the return values of different branches, perhaps you need to make them equal.
Shape Join Failed: shape1 = (2, 3, 4, 5), shape2 = ().
For more details, please refer to https://www.mindspore.cn/search?inputValue=Type%20Join%20Failed.

Inner Message:
The abstract type of the return value of the current branch is AbstractTensor(shape: (), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0x55658aa9b090, value: AnyValue), and that of the previous branch is AbstractTensor(shape: (2, 3, 4, 5), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0x55658aa9b090, value: AnyValue).
The node is construct.6:[CNode]13{[0]: construct.6:[CNode]12{[0]: ValueNode&lt;Primitive&gt; Switch, [1]: [CNode]11, [2]: ValueNode&lt;FuncGraph&gt; ✓construct.4, [3]: ValueNode&lt;FuncGraph&gt; ✗construct.5}}, true branch: ✓construct.4, false branch: ✗construct.5

The function call stack (See file &#39;analyze_fail.dat&#39; for more details. Get instructions about `analyze_fail.dat` at https://www.mindspore.cn/search?inputValue=analyze_fail.dat):
# 0 In file test.py(14)
        if a &gt; b:
        ^
</pre></div>
</div>
<p>当出现如“Type Join Failed: abstract type AbstractTensor can not join with AbstractTuple”的报错时，说明抽象类型不匹配，导致抽象类型合并失败，代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ms_function</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">])</span>
<span class="n">grad</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">GradOperation</span><span class="p">(</span><span class="n">get_by_list</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sens_param</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">sens</span> <span class="o">=</span> <span class="mf">1.0</span>

<span class="k">def</span> <span class="nf">test_net</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span>

<span class="nd">@ms_function</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">join_fail</span><span class="p">():</span>
    <span class="n">sens_i</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Fill</span><span class="p">()(</span><span class="n">ops</span><span class="o">.</span><span class="n">DType</span><span class="p">()(</span><span class="n">x</span><span class="p">),</span> <span class="n">ops</span><span class="o">.</span><span class="n">Shape</span><span class="p">()(</span><span class="n">x</span><span class="p">),</span> <span class="n">sens</span><span class="p">)</span>    <span class="c1"># sens_i 是一个标量shape: (1), dtype:Float64, value:1.0</span>
    <span class="c1"># sens_i = (sens_i, sens_i)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">test_net</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sens_i</span><span class="p">)</span>    <span class="c1"># 对输出类型为tuple(Tensor, Tensor)的test_net求梯度需要sens_i的类型同输出保持一致，但sens_i是个Tensor; 在grad前设置sens_i = (sens_i, sens_i)可以修复问题。</span>
    <span class="k">return</span> <span class="n">a</span>

<span class="n">join_fail</span><span class="p">()</span>
</pre></div>
</div>
<p>执行结果如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>TypeError: Type Join Failed: abstract type AbstractTensor cannot join with AbstractTuple.
For more details, please refer to https://www.mindspore.cn/search?inputValue=Type%20Join%20Failed.

Inner Message:
This: AbstractTensor(shape: (1), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0x55c969c44c60, value: Tensor(shape=[1], dtype=Float32, value=[ 1.00000000e+00])), other: AbstractTuple{element[0]: AbstractTensor(shape: (1), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0x55c96a9a3bd0, value: Tensor(shape=[1], dtype=Float32, value=[ 1.00000000e+00])), element[1]: AbstractTensor(shape: (1), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0x55c96a5f06a0, value: Tensor(shape=[1], dtype=Float32, value=[ 2.00000000e+00])), sequence_nodes: {test_net.3:[CNode]4{[0]: ValueNode&lt;PrimitivePy&gt; MakeTuple, [1]: a, [2]: b}, elements_use_flags: {ptr: 0x55c96ae83400, value: [const vector][1, 1]}}}. Please check the node: test_net.5:a{[0]: a, [1]: test_net}

The function call stack (See file &#39;analyze_fail.dat&#39; for more details. Get instructions about `analyze_fail.dat` at https://www.mindspore.cn/search?inputValue=analyze_fail.dat):

The function call stack:
# 0 In file test.py(17)
    a = grad(test_net)(x, y, sens_i)
        ^
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: 编译时报错“The params of function ‘bprop’ of Primitive or Cell requires the forward inputs as well as the ‘out’ and ‘dout’”怎么办？</strong></font></p>
<p>A: 用户自定义的Cell的反向传播函数 <code class="docutils literal notranslate"><span class="pre">bprop</span></code>，它的输入需要包含正向网络的输入，以及 <code class="docutils literal notranslate"><span class="pre">out</span></code> 和 <code class="docutils literal notranslate"><span class="pre">dout</span></code>，代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">ops</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>

<span class="k">class</span> <span class="nc">BpropUserDefinedNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">BpropUserDefinedNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">zeros_like</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ZerosLike</span><span class="p">()</span>

        <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>

        <span class="c1"># def bprop(self, x, y, out, dout):    # 正确写法</span>
        <span class="k">def</span> <span class="nf">bprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">out</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">out</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

<span class="n">grad_fn</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">GradOperation</span><span class="p">(</span><span class="n">get_all</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">BpropUserDefinedNet</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">grad_fn</span><span class="p">(</span><span class="n">net</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>执行结果如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>TypeError: The params of function &#39;bprop&#39; of Primitive or Cell requires the forward inputs as well as the &#39;out&#39; and &#39;dout&#39;.
In file test.py(13)
        def bprop(self, x, y, out):
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: 编译时报错“There isn’t any branch that can be evaluated”怎么办？</strong></font></p>
<p>A: 当出现There isn’t any branch that can be evaluated 时，说明代码中可能出现了无穷递归或者时死循环，导致if条件的每一个分支都无法推导出正确的类型和维度信息。代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ms_function</span>

<span class="n">ZERO</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">ONE</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="nd">@ms_function</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">ZERO</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">z</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">5</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<br/>
<p><font size=3><strong>Q: 编译时报错”Exceed function call depth limit 1000”怎么办？</strong></font></p>
<p>A: 当出现Exceed function call depth limit 1000 时，说明代码中出现了无穷递归死循环，或者是代码过于复杂，类型推导过程中导致栈深度超过设置的最大深度。
此时可以通过设置 <code class="docutils literal notranslate"><span class="pre">set_context(max_call_depth</span> <span class="pre">=</span> <span class="pre">value)</span></code> 更改栈的最大深度，并考虑简化代码逻辑或者检查代码中是否存在无穷递归或死循环。
需要注意的是，设置max_call_depth虽然可以改变MindSpore的递归深度，但是可能会超过系统栈的最大深度，进而出现段错误。此时可能还需要设置系统栈深度。</p>
<br/>
<p><font size=3><strong>Q: 编译时报错“could not get source code”以及“Mindspore can not compile temporary source code in terminal. Please write source code to a python file and run the file.”是什么原因？</strong></font></p>
<p>A: MindSpore编译网络时通过 <code class="docutils literal notranslate"><span class="pre">inspect.getsourcelines(self.fn)</span></code> 获取网络代码所在的文件，如果网络是编辑在命令行中的临时代码，那么会出现如标题所示的报错，需要将网络写在Python文件中去执行才能避免该错误。</p>
<br/>
<p><font size=3><strong>Q: 报错提示中的“Corresponding forward node candidate:”或“Corresponding code candidate:”是什么意思？</strong></font></p>
<p>A: “Corresponding forward node candidate:”为关联的正向网络中的代码，表示该反向传播算子与该正向代码对应。“Corresponding code candidate:”表示该算子是由这些代码融合而来，其中分符“-”用以区分不同的代码。</p>
<p>例如：</p>
<ul>
<li><p>算子FusionOp_BNTrainingUpdate_ReLUV2报错，打印了如下的代码行：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Corresponding code candidate:
 - In file /home/workspace/mindspore/build/package/mindspore/nn/layer/normalization.py(212)/                return self.bn_train(x,/
   In file /home/workspace/mindspore/tests/st/tbe_networks/resnet.py(265)/        x = self.bn1(x)/
   In file /home/workspace/mindspore/build/package/mindspore/nn/wrap/cell_wrapper.py(109)/        out = self._backbone(data)/
   In file /home/workspace/mindspore/build/package/mindspore/nn/wrap/cell_wrapper.py(356)/        loss = self.network(*inputs)/
   In file /home/workspace/mindspore/build/package/mindspore/train/dataset_helper.py(98)/        return self.network(*outputs)/
 - In file /home/workspace/mindspore/tests/st/tbe_networks/resnet.py(266)/        x = self.relu(x)/
   In file /home/workspace/mindspore/build/package/mindspore/nn/wrap/cell_wrapper.py(109)/        out = self._backbone(data)/
   In file /home/workspace/mindspore/build/package/mindspore/nn/wrap/cell_wrapper.py(356)/        loss = self.network(*inputs)/
   In file /home/workspace/mindspore/build/package/mindspore/train/dataset_helper.py(98)/        return self.network(*outputs)/
</pre></div>
</div>
<p>第一个分隔符的代码调用栈指向了网络脚本文件中第265行的“x = self.bn1(x)”，第二个分隔符的代码调用栈指向了网络脚本文件中第266行的“x = self.relu(x)”。可知，该算子FusionOp_BNTrainingUpdate_ReLUV2由这两行代码融合而来。</p>
</li>
<li><p>算子Conv2DBackpropFilter报错，打印了如下的代码行：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>In file /home/workspace/mindspore/build/package/mindspore/ops/_grad/grad_nn_ops.py(65)/        dw = filter_grad(dout, x, w_shape)/
Corresponding forward node candidate:
 - In file /home/workspace/mindspore/build/package/mindspore/nn/layer/conv.py(266)/        output = self.conv2d(x, self.weight)/
   In file /home/workspace/mindspore/tests/st/tbe_networks/resnet.py(149)/        out = self.conv1(x)/
   In file /home/workspace/mindspore/tests/st/tbe_networks/resnet.py(195)/        x = self.a(x)/
   In file /home/workspace/mindspore/tests/st/tbe_networks/resnet.py(270)/        x = self.layer2(x)/
   In file /home/workspace/mindspore/build/package/mindspore/nn/wrap/cell_wrapper.py(109)/        out = self._backbone(data)/
   In file /home/workspace/mindspore/build/package/mindspore/nn/wrap/cell_wrapper.py(356)/        loss = self.network(*inputs)/
   In file /home/workspace/mindspore/build/package/mindspore/train/dataset_helper.py(98)/        return self.network(*outputs)/
</pre></div>
</div>
<p>第一行是该算子的相应源码，该算子是反向算子，故由MindSpore实现。第二行提示此算子有关联的正向节点，第四行则指向了网络脚本文件第149行的“out = self.conv1(x)”。综上可知，算子Conv2DBackpropFilter是一个反向算子，相应的正向节点是一个卷积算子。</p>
</li>
</ul>
<br/>
<p><font size=3><strong>Q: 什么是“JIT Fallback”？编译时报错“Should not use Python object in runtime”怎么办？</strong></font></p>
<p>A: JIT Fallback从静态图的角度出发考虑静态图和动态图的统一。通过JIT Fallback特性，静态图可以支持尽量多的动态图语法，使得静态图提供接近动态图的语法使用体验。JIT Fallback的环境变量开关是 <code class="docutils literal notranslate"><span class="pre">DEV_ENV_ENABLE_FALLBACK</span></code>，默认使用JIT Fallback。</p>
<p>当出现“Should not use Python object in runtime”和“We suppose all nodes generated by JIT Fallback would not return to outside of graph”的报错信息时，说明静态图模式代码中出现了错误使用语法。JIT Fallback处理不支持的语法表达式时，将会生成相应的节点，并在编译时阶段完成推导和执行，否则这些节点传递到运行时后会引发报错。当前JIT Fallback有条件地支持Graph模式的部分常量场景，编写代码时请参考<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.10/note/static_graph_syntax_support.html">静态图语法支持</a>和<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.10/design/jit_fallback.html">JIT Fallback</a>。</p>
<p>例如，在调用第三方库NumPy时，JIT Fallback支持使用 <code class="docutils literal notranslate"><span class="pre">np.add(x,</span> <span class="pre">y)</span></code> 和 <code class="docutils literal notranslate"><span class="pre">Tensor(np.add(x,</span> <span class="pre">y))</span></code> 语法，但MindSpore不支持NumPy类型作为返回值，否则将会出现报错。代码样例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">()</span>
</pre></div>
</div>
<p>执行结果如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>RuntimeError: Should not use Python object in runtime, node: ValueNode&lt;InterpretedObject&gt; InterpretedObject: &#39;[4 6]&#39;.
Line: In file test.py(11)
        return np.add(x, y)
        ^

We suppose all nodes generated by JIT Fallback not return to outside of graph. For more information about JIT Fallback, please refer to https://www.mindspore.cn/search?inputValue=JIT%20Fallback
</pre></div>
</div>
<p>出现JIT Fallback相关的报错时，请根据<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.10/note/static_graph_syntax_support.html">静态图语法支持</a>以及报错代码行，重新检视代码语法并修改。如果需要关闭JIT Fallback，可以设置 <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">DEV_ENV_ENABLE_FALLBACK=0</span></code>。</p>
<br/>
<p><font size=3><strong>Q: 为什么运行代码时屏幕中会出现“Start compiling and it will take a while. Please wait…”和“End compiling.”的打印？</strong></font></p>
<p>A: 当需要加速执行时，MindSpore会将Python源码转换成一种基于图表示的函数式IR，并进行相关的优化。这个过程也被称为编译流程。
当出现“Start compiling and it will take a while. Please wait…”的打印时，MindSpore开始了图编译流程；当出现“End compiling.”则表明图编译流程结束。</p>
<p>当前主要有以下两种场景会有该打印：</p>
<ul class="simple">
<li><p>静态图模式下运行网络。</p></li>
<li><p>动态图下执行被<code class="docutils literal notranslate"><span class="pre">&#64;ms_function</span></code>装饰的函数（例如优化器<code class="docutils literal notranslate"><span class="pre">nn.Momentum</span></code>）。</p></li>
</ul>
<blockquote>
<div><p>一次任务中有可能会触发多次编译流程。</p>
</div></blockquote>
<p><font size=3><strong>Q: 编译时报出告警:“On the Ascend platform, when the return value of the control flow subgraph is parameter, the performance may be degraded. The value of the parameter can be returned to improve the performance. ”，是什么意思？</strong></font></p>
<p>A: 由于Ascend平台不能真正返回一个内存地址，导致在整图下沉模式下，对于控制流场景中返回值存在参数的情况，会存在一些问题。为了避免出现问题，会对这种场景切换到统一运行时模式，从整图下沉模式切换到统一运行时模式，网络性能可能会劣化。如果控制流子图的返回值仅使用参数的值，可以通过参数的value接口获取参数的值，从而避免模式切换导致的性能劣化。</p>
<p>例如下面的用例，在网络“Net”中仅使用“InnerNet”中的“self.param1”和“self.param2”的值，没有使用参数的属性，所以可以使用value接口来避免模式切换导致的性能劣化。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Parameter</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">InnerNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param1</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;param1&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param2</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;param2&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
           <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">param1</span><span class="o">.</span><span class="n">value</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">param2</span><span class="o">.</span><span class="n">value</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">param2</span><span class="o">.</span><span class="n">value</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">param1</span><span class="o">.</span><span class="n">value</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inner_net</span> <span class="o">=</span> <span class="n">InnerNet</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">addn</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">AddN</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">inner_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner_net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out_res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">addn</span><span class="p">(</span><span class="n">inner_params</span><span class="p">)</span> <span class="o">+</span> <span class="n">y</span>
        <span class="k">return</span> <span class="n">out_res</span><span class="p">,</span> <span class="n">inner_params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">inner_params</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">input_y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;out:&quot;</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
<p>执行结果如下：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>out: (Tensor(shape=[], dtype=Int64, value=8), Tensor(shape=[], dtype=Int64, value=3))
</pre></div>
</div>
<br/>
</section>


           </div>
           
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="implement_problem.html" class="btn btn-neutral float-left" title="执行问题" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="operators_compile.html" class="btn btn-neutral float-right" title="算子编译" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
</body>
</html>