

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindspore.dataset.vision.py_transforms &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/language_data.js"></script>
        <script src="../../../../_static/js/training.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">设计</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/technical_white_paper.html">技术白皮书</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/all_scenarios_architecture.html">全场景统一</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/gradient.html">函数式微分编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/dynamic_graph_and_static_graph.html">动静态图结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/heterogeneous_training.html">异构并行训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/distributed_training_design.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/mindir.html">中间表达MindIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/graph_kernel_fusion.html">图算融合加速引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/second_order_optimizer.html">二阶优化</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.7/training_visual_design.html">可视化调试调优↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindarmour/docs/zh-CN/r1.7/design.html">安全可信↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/glossary.html">术语</a></li>
</ul>
<p class="caption"><span class="caption-text">参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/benchmark.html">基准性能</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/network_list.html">网络支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/operator_list.html">算子支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/env_var_list.html">环境变量</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/syntax_list.html">语法支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/api_mapping.html">API映射</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.context.html">mindspore.context</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.audio.html">mindspore.dataset.audio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.nn.transformer.html">mindspore.nn.transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.ops.functional.html">mindspore.ops.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.parallel.html">mindspore.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.parallel.nn.html">mindspore.parallel.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.profiler.html">mindspore.Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.7/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption"><span class="caption-text">迁移指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/overview.html">概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/preparation.html">准备工作</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/script_analysis.html">网络脚本分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/script_development.html">网络脚本开发</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/neural_network_debug.html">网络调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/accuracy_optimization.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/performance_optimization.html">性能调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/inference.html">推理执行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/sample_code.html">网络迁移调试实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/faq.html">常见问题</a></li>
</ul>
<p class="caption"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/installation.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/data_processing.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/implement_problem.html">执行问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/network_compilation.html">网络编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/usage_migrate_3rd.html">第三方框架迁移使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/distributed_configure.html">分布式配置</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/feature_advice.html">特性咨询</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
      <li>mindspore.dataset.vision.py_transforms</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for mindspore.dataset.vision.py_transforms</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2019-2022 Huawei Technologies Co., Ltd</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">The module vision.py_transforms is mainly implemented based on Python PIL, which</span>
<span class="sd">provides many kinds of image augmentation methods and conversion methods between</span>
<span class="sd">PIL.Image.Image and numpy.ndarray. For users who prefer using Python PIL in computer vision</span>
<span class="sd">tasks, this module is a good choice to process images. Users can also self-define</span>
<span class="sd">their own augmentation methods with Python PIL.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numbers</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="kn">import</span> <span class="nn">mindspore.dataset.transforms.py_transforms</span> <span class="k">as</span> <span class="nn">py_transforms</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">py_transforms_util</span> <span class="k">as</span> <span class="n">util</span>
<span class="kn">from</span> <span class="nn">.c_transforms</span> <span class="kn">import</span> <span class="n">parse_padding</span>
<span class="kn">from</span> <span class="nn">.py_transforms_util</span> <span class="kn">import</span> <span class="n">is_pil</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">Border</span><span class="p">,</span> <span class="n">Inter</span>
<span class="kn">from</span> <span class="nn">.validators</span> <span class="kn">import</span> <span class="n">check_adjust_gamma</span><span class="p">,</span> <span class="n">check_alpha</span><span class="p">,</span> <span class="n">check_auto_contrast</span><span class="p">,</span> <span class="n">check_center_crop</span><span class="p">,</span> <span class="n">check_cutout</span><span class="p">,</span> \
    <span class="n">check_five_crop</span><span class="p">,</span> <span class="n">check_hsv_to_rgb</span><span class="p">,</span> <span class="n">check_linear_transform</span><span class="p">,</span> <span class="n">check_mix_up</span><span class="p">,</span> <span class="n">check_normalize_py</span><span class="p">,</span> \
    <span class="n">check_normalizepad_py</span><span class="p">,</span> <span class="n">check_num_channels</span><span class="p">,</span> <span class="n">check_pad</span><span class="p">,</span> <span class="n">check_positive_degrees</span><span class="p">,</span> <span class="n">check_prob</span><span class="p">,</span> <span class="n">check_random_affine</span><span class="p">,</span> \
    <span class="n">check_random_color_adjust</span><span class="p">,</span> <span class="n">check_random_crop</span><span class="p">,</span> <span class="n">check_random_erasing</span><span class="p">,</span> <span class="n">check_random_perspective</span><span class="p">,</span> \
    <span class="n">check_random_resize_crop</span><span class="p">,</span> <span class="n">check_random_rotation</span><span class="p">,</span> <span class="n">check_resize_interpolation</span><span class="p">,</span> <span class="n">check_rgb_to_bgr</span><span class="p">,</span> <span class="n">check_rgb_to_hsv</span><span class="p">,</span> \
    <span class="n">check_ten_crop</span><span class="p">,</span> <span class="n">check_uniform_augment_py</span>

<span class="n">DE_PY_BORDER_TYPE</span> <span class="o">=</span> <span class="p">{</span><span class="n">Border</span><span class="o">.</span><span class="n">CONSTANT</span><span class="p">:</span> <span class="s1">&#39;constant&#39;</span><span class="p">,</span>
                     <span class="n">Border</span><span class="o">.</span><span class="n">EDGE</span><span class="p">:</span> <span class="s1">&#39;edge&#39;</span><span class="p">,</span>
                     <span class="n">Border</span><span class="o">.</span><span class="n">REFLECT</span><span class="p">:</span> <span class="s1">&#39;reflect&#39;</span><span class="p">,</span>
                     <span class="n">Border</span><span class="o">.</span><span class="n">SYMMETRIC</span><span class="p">:</span> <span class="s1">&#39;symmetric&#39;</span><span class="p">}</span>

<span class="n">DE_PY_INTER_MODE</span> <span class="o">=</span> <span class="p">{</span><span class="n">Inter</span><span class="o">.</span><span class="n">NEAREST</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">NEAREST</span><span class="p">,</span>
                    <span class="n">Inter</span><span class="o">.</span><span class="n">ANTIALIAS</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">ANTIALIAS</span><span class="p">,</span>
                    <span class="n">Inter</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">,</span>
                    <span class="n">Inter</span><span class="o">.</span><span class="n">CUBIC</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">CUBIC</span><span class="p">}</span>


<span class="k">class</span> <span class="nc">AdjustGamma</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform gamma correction on the input PIL Image.</span>

<span class="sd">    Args:</span>
<span class="sd">        gamma (float): The gamma parameter in correction equation, must be non negative.</span>
<span class="sd">        gain (float, optional): The constant multiplier. Default: 1.0.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `gain` is not of type float.</span>
<span class="sd">        TypeError: If `gamma` is not of type float.</span>
<span class="sd">        ValueError: If `gamma` is less than 0.</span>
<span class="sd">        RuntimeError: If shape of the input image is not &lt;H, W&gt; or &lt;H, W, C&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.AdjustGamma(gamma=10.0),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_adjust_gamma</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gain</span> <span class="o">=</span> <span class="n">gain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be gamma adjusted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, gamma adjusted image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">adjust_gamma</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gain</span><span class="p">)</span>


<div class="viewcode-block" id="AutoContrast"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.AutoContrast.html#mindspore.dataset.vision.py_transforms.AutoContrast">[文档]</a><span class="k">class</span> <span class="nc">AutoContrast</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Maximize (normalize) contrast of the input PIL Image.</span>

<span class="sd">    It will first calculate a histogram of the input image, remove `cutoff` percent of the</span>
<span class="sd">    lightest and darkest pixels from the histogram, then remap the pixel value to [0, 255],</span>
<span class="sd">    making the darkest pixel black and the lightest pixel white.</span>

<span class="sd">    Args:</span>
<span class="sd">        cutoff (float, optional): Percent to cut off from the histogram on the low and</span>
<span class="sd">            high ends, must be in range of [0.0, 50.0). Default: 0.0.</span>
<span class="sd">        ignore (Union[int, Sequence[int]], optional): Background pixel value, which will be</span>
<span class="sd">            directly remapped to white. Default: None, means no background.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `cutoff` is not of type float.</span>
<span class="sd">        TypeError: If `ignore` is not of type int or sequence.</span>
<span class="sd">        ValueError: If `cutoff` is not in range [0, 50.0).</span>
<span class="sd">        ValueError: If `ignore` is not in range [0, 255].</span>
<span class="sd">        RuntimeError: If shape of the input image is not &lt;H, W&gt; or &lt;H, W, C&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.AutoContrast(),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_auto_contrast</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cutoff</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">ignore</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span> <span class="o">=</span> <span class="n">cutoff</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignore</span> <span class="o">=</span> <span class="n">ignore</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be automatically contrasted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, automatically contrasted image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">auto_contrast</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore</span><span class="p">)</span></div>


<div class="viewcode-block" id="CenterCrop"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.CenterCrop.html#mindspore.dataset.vision.py_transforms.CenterCrop">[文档]</a><span class="k">class</span> <span class="nc">CenterCrop</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Crop the central region of the input PIL Image with the given size.</span>

<span class="sd">    Args:</span>
<span class="sd">        size (Union[int, Sequence[int, int]]): The size of the cropped image.</span>
<span class="sd">            If int is provided, a square of size (`size`, `size`) will be cropped with this value.</span>
<span class="sd">            If Sequence[int, int] is provided, its two elements will be taken as the cropped height and width.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `size` is not of type int or Sequence[int, int].</span>
<span class="sd">        ValueError: If `size` is not positive.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.CenterCrop(64),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_center_crop</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be center cropped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, cropped image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">center_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">)</span></div>


<div class="viewcode-block" id="Cutout"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Cutout.html#mindspore.dataset.vision.py_transforms.Cutout">[文档]</a><span class="k">class</span> <span class="nc">Cutout</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly cut out a certain number of square patches on the input numpy.ndarray image,</span>
<span class="sd">    setting the pixel values in the patch to zero.</span>

<span class="sd">    See `Improved Regularization of Convolutional Neural Networks with Cutout &lt;https://arxiv.org/pdf/1708.04552.pdf&gt;`_.</span>

<span class="sd">    Args:</span>
<span class="sd">        length (int): The side length of square patches to be cut out.</span>
<span class="sd">        num_patches (int, optional): The number of patches to be cut out. Default: 1.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `length` is not of type int.</span>
<span class="sd">        TypeError: If `num_patches` is not of type int.</span>
<span class="sd">        ValueError: If `length` is less than or equal 0.</span>
<span class="sd">        ValueError: If `num_patches` is less than or equal 0.</span>
<span class="sd">        RuntimeError: If shape of the input image is not &lt;H, W, C&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.Cutout(80)])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_cutout</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">num_patches</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">length</span> <span class="o">=</span> <span class="n">length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_patches</span> <span class="o">=</span> <span class="n">num_patches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">np_img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            np_img (numpy.ndarray): Image in shape of (C, H, W) to be cut out.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, image cut out.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;img should be NumPy array. Got </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">np_img</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">np_img</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s1">&#39;img dimension should be 3. Got </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np_img</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">image_h</span><span class="p">,</span> <span class="n">image_w</span> <span class="o">=</span> <span class="n">np_img</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">length</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">length</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">image_h</span> <span class="o">*</span> <span class="n">image_w</span><span class="p">)</span>
        <span class="n">bounded</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_patches</span><span class="p">):</span>
            <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">erase_h</span><span class="p">,</span> <span class="n">erase_w</span><span class="p">,</span> <span class="n">erase_value</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">get_erase_params</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">scale</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">bounded</span><span class="p">,</span>
                                                                        <span class="mi">1</span><span class="p">)</span>
            <span class="n">np_img</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">erase</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">erase_h</span><span class="p">,</span> <span class="n">erase_w</span><span class="p">,</span> <span class="n">erase_value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np_img</span></div>


<div class="viewcode-block" id="Decode"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Decode.html#mindspore.dataset.vision.py_transforms.Decode">[文档]</a><span class="k">class</span> <span class="nc">Decode</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Decode the input raw image bytes to PIL Image format in RGB mode.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If the input is not raw image bytes.</span>
<span class="sd">        ValueError: If the input image is already decoded.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (Bytes-like Object): Raw image data to be decoded.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, decoded PIL Image in RGB mode.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">img</span><span class="p">)</span></div>


<div class="viewcode-block" id="Equalize"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Equalize.html#mindspore.dataset.vision.py_transforms.Equalize">[文档]</a><span class="k">class</span> <span class="nc">Equalize</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Equalize the histogram of the input PIL Image.</span>

<span class="sd">    By applying a non-linear mapping to the input image, it creates a uniform</span>
<span class="sd">    distribution of grayscale values in the output.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.Equalize(),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be equalized.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, equalized image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">equalize</span><span class="p">(</span><span class="n">img</span><span class="p">)</span></div>


<div class="viewcode-block" id="FiveCrop"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.FiveCrop.html#mindspore.dataset.vision.py_transforms.FiveCrop">[文档]</a><span class="k">class</span> <span class="nc">FiveCrop</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Crop the given image into one central crop and four corners.</span>

<span class="sd">    Args:</span>
<span class="sd">        size (Union[int, Sequence[int, int]]): The size of the cropped image.</span>
<span class="sd">            If int is provided, a square of size (`size`, `size`) will be cropped with this value.</span>
<span class="sd">            If Sequence[int, int] is provided, its two elements will be taken as the cropped height and width.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `size` is not of type int or Sequence[int, int].</span>
<span class="sd">        ValueError: If `size` is not positive.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.FiveCrop(size=200),</span>
<span class="sd">        ...                            # 4D stack of 5 images</span>
<span class="sd">        ...                            lambda *images: numpy.stack([py_vision.ToTensor()(image) for image in images])])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_five_crop</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be cropped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple[PIL.Image.Image], five cropped images in order of top_left, top_right, bottom_left,</span>
<span class="sd">            bottom_right and center.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">five_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">)</span></div>


<div class="viewcode-block" id="Grayscale"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Grayscale.html#mindspore.dataset.vision.py_transforms.Grayscale">[文档]</a><span class="k">class</span> <span class="nc">Grayscale</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert the input PIL Image to grayscale.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_output_channels (int): The number of channels desired for the output image, must be 1 or 3.</span>
<span class="sd">            If 3 is provided, the returned image will have 3 identical RGB channels. Default: 1.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `num_output_channels` is not of type int.</span>
<span class="sd">        ValueError: If `num_output_channels` is not 1 or 3.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.Grayscale(3),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_num_channels</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_output_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_output_channels</span> <span class="o">=</span> <span class="n">num_output_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be converted to grayscale.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, converted grayscale image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">grayscale</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">num_output_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_output_channels</span><span class="p">)</span></div>


<div class="viewcode-block" id="HsvToRgb"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.HsvToRgb.html#mindspore.dataset.vision.py_transforms.HsvToRgb">[文档]</a><span class="k">class</span> <span class="nc">HsvToRgb</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert the input numpy.ndarray images from HSV to RGB.</span>

<span class="sd">    Args:</span>
<span class="sd">        is_hwc (bool): If True, means the input image is in shape of (H, W, C) or (N, H, W, C).</span>
<span class="sd">            Otherwise, it is in shape of (C, H, W) or (N, C, H, W). Default: False.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `is_hwc` is not of type bool.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.CenterCrop(20),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.HsvToRgb()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_hsv_to_rgb</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">is_hwc</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span> <span class="o">=</span> <span class="n">is_hwc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hsv_imgs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            hsv_imgs (numpy.ndarray): HSV images to be converted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, converted RGB images.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">hsv_to_rgbs</span><span class="p">(</span><span class="n">hsv_imgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span><span class="p">)</span></div>


<div class="viewcode-block" id="HWC2CHW"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.HWC2CHW.html#mindspore.dataset.vision.py_transforms.HWC2CHW">[文档]</a><span class="k">class</span> <span class="nc">HWC2CHW</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transpose the input numpy.ndarray image of shape (H, W, C) to (C, H, W).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input image is not of type :class:`numpy.ndarray`.</span>
<span class="sd">        TypeError: If dimension of the input image is not 3.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.HWC2CHW()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (numpy.ndarray): numpy.ndarray of shape (H, W, C) to be transposed.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, transposed numpy.ndarray of shape (C, H, W).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">hwc_to_chw</span><span class="p">(</span><span class="n">img</span><span class="p">)</span></div>


<div class="viewcode-block" id="Invert"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Invert.html#mindspore.dataset.vision.py_transforms.Invert">[文档]</a><span class="k">class</span> <span class="nc">Invert</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Invert the colors of the input PIL Image.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.Invert(),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be color inverted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, color inverted image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">invert_color</span><span class="p">(</span><span class="n">img</span><span class="p">)</span></div>


<div class="viewcode-block" id="LinearTransformation"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.LinearTransformation.html#mindspore.dataset.vision.py_transforms.LinearTransformation">[文档]</a><span class="k">class</span> <span class="nc">LinearTransformation</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Linearly transform the input numpy.ndarray image with a square transformation matrix and a mean vector.</span>

<span class="sd">    It will first flatten the input image and subtract the mean vector from it, then compute the dot</span>
<span class="sd">    product with the transformation matrix, finally reshape it back to its original shape.</span>

<span class="sd">    Args:</span>
<span class="sd">        transformation_matrix (numpy.ndarray): A square transformation matrix in shape of (D, D), where</span>
<span class="sd">            :math:`D = C \times H \times W`.</span>
<span class="sd">        mean_vector (numpy.ndarray): A mean vector in shape of (D,), where :math:`D = C \times H \times W`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `transformation_matrix` is not of type :class:`numpy.ndarray`.</span>
<span class="sd">        TypeError: If `mean_vector` is not of type :class:`numpy.ndarray`.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; height, width = 32, 32</span>
<span class="sd">        &gt;&gt;&gt; dim = 3 * height * width</span>
<span class="sd">        &gt;&gt;&gt; transformation_matrix = np.ones([dim, dim])</span>
<span class="sd">        &gt;&gt;&gt; mean_vector = np.zeros(dim)</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.Resize((height,width)),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.LinearTransformation(transformation_matrix, mean_vector)])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_linear_transform</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transformation_matrix</span><span class="p">,</span> <span class="n">mean_vector</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformation_matrix</span> <span class="o">=</span> <span class="n">transformation_matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_vector</span> <span class="o">=</span> <span class="n">mean_vector</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">np_img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            np_img (numpy.ndarray): Image in shape of (C, H, W) to be linearly transformed.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, linearly transformed image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">linear_transform</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformation_matrix</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_vector</span><span class="p">)</span></div>


<div class="viewcode-block" id="MixUp"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.MixUp.html#mindspore.dataset.vision.py_transforms.MixUp">[文档]</a><span class="k">class</span> <span class="nc">MixUp</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly mix up a batch of images together with its labels.</span>

<span class="sd">    Each image will be multiplied by a random weight :math:`lambda` generated from the Beta distribution and then added</span>
<span class="sd">    to another image multiplied by :math:`1 - lambda`. The same transformation will be applied to their labels with the</span>
<span class="sd">    same value of :math:`lambda`. Make sure that the labels are one-hot encoded in advance.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch_size (int): The number of images in a batch.</span>
<span class="sd">        alpha (float): The alpha and beta parameter for the Beta distribution.</span>
<span class="sd">        is_single (bool, optional): If True, it will randomly mix up [img0, ..., img(n-1), img(n)] with</span>
<span class="sd">            [img1, ..., img(n), img0] in each batch. Otherwise, it will randomly mix up images with the</span>
<span class="sd">            output of the previous batch. Default: True.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `batch_size` is not of type int.</span>
<span class="sd">        TypeError: If `alpha` is not of type float.</span>
<span class="sd">        TypeError: If `is_single` is not of type bool.</span>
<span class="sd">        ValueError: If `batch_size` is not positive.</span>
<span class="sd">        ValueError: If `alpha` is not positive.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; # Setup multi-batch mixup transformation</span>
<span class="sd">        &gt;&gt;&gt; transform = [py_vision.MixUp(batch_size=16, alpha=0.2, is_single=False)]</span>
<span class="sd">        &gt;&gt;&gt; # Apply the transform to the dataset through dataset.map()</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(input_columns=&quot;image&quot;,</span>
<span class="sd">        ...                                                 operations=transform)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_mix_up</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">is_single</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_first</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_single</span> <span class="o">=</span> <span class="n">is_single</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            image (numpy.ndarray): Images to be mixed up.</span>
<span class="sd">            label (numpy.ndarray): Labels to be mixed up.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, images after mixing up.</span>
<span class="sd">            numpy.ndarray, labels after mixing up.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_single</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">mix_up_single</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">mix_up_muti</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span></div>


<div class="viewcode-block" id="Normalize"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Normalize.html#mindspore.dataset.vision.py_transforms.Normalize">[文档]</a><span class="k">class</span> <span class="nc">Normalize</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Normalize the input numpy.ndarray image of shape (C, H, W) with the specified mean and standard deviation.</span>

<span class="sd">    .. math::</span>

<span class="sd">        output_{c} = \frac{input_{c} - mean_{c}}{std_{c}}</span>

<span class="sd">    Note:</span>
<span class="sd">        The pixel values of the input image need to be in range of [0.0, 1.0].</span>
<span class="sd">        If not so, please call :class:`mindspore.dataset.vision.py_transforms.ToTensor` first.</span>

<span class="sd">    Args:</span>
<span class="sd">        mean (Union[float, Sequence[float]]): Mean pixel values for each channel,</span>
<span class="sd">            must be in range of [0.0, 1.0].</span>
<span class="sd">            If float is provided, it will be applied to each channel.</span>
<span class="sd">            If Sequence[float] is provided, it should have the same length with channel</span>
<span class="sd">            and be arranged in channel order.</span>
<span class="sd">        std (Union[float, Sequence[float]]): Standard deviation values for each channel, must be in range of (0.0, 1.0].</span>
<span class="sd">            If float is provided, it will be applied to each channel.</span>
<span class="sd">            If Sequence[float] is provided, it should have the same length with channel</span>
<span class="sd">            and be arranged in channel order.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input image is not of type :class:`numpy.ndarray`.</span>
<span class="sd">        TypeError: If dimension of the input image is not 3.</span>
<span class="sd">        NotImplementedError: If dtype of the input image is int.</span>
<span class="sd">        ValueError: If lengths of `mean` and `std` are not equal.</span>
<span class="sd">        ValueError: If length of `mean` or `std` is neither equal to 1 nor equal to the length of channel.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.Normalize((0.491, 0.482, 0.447), (0.247, 0.243, 0.262))])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_normalize_py</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (numpy.ndarray): numpy.ndarray to be normalized.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, normalized numpy.ndarray.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="p">)</span></div>


<div class="viewcode-block" id="NormalizePad"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.NormalizePad.html#mindspore.dataset.vision.py_transforms.NormalizePad">[文档]</a><span class="k">class</span> <span class="nc">NormalizePad</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Normalize the input numpy.ndarray image of shape (C, H, W) with the specified mean and standard deviation,</span>
<span class="sd">    then pad an extra channel filled with zeros.</span>

<span class="sd">    .. math::</span>
<span class="sd">        output_{c} = \begin{cases}</span>
<span class="sd">        \frac{input_{c} - mean_{c}}{std_{c}}, &amp; \text{if} \quad 0 \le c &lt; 3 \text{;}\\</span>
<span class="sd">        0, &amp; \text{if} \quad c = 3 \text{.}</span>
<span class="sd">        \end{cases}</span>

<span class="sd">    Note:</span>
<span class="sd">        The pixel values of the input image need to be in range of [0.0, 1.0].</span>
<span class="sd">        If not so, please call :class:`mindspore.dataset.vision.py_transforms.ToTensor` first.</span>

<span class="sd">    Args:</span>
<span class="sd">        mean (Union[float, Sequence[float]]): Mean pixel values for each channel, must be in range of [0.0, 1.0].</span>
<span class="sd">            If float is provided, it will be applied to each channel.</span>
<span class="sd">            If Sequence[float] is provided, it should have the same length with channel</span>
<span class="sd">            and be arranged in channel order.</span>
<span class="sd">        std (Union[float, Sequence[float]]): Standard deviation values for each channel, must be in range of (0.0, 1.0].</span>
<span class="sd">            If float is provided, it will be applied to each channel.</span>
<span class="sd">            If Sequence[float] is provided, it should have the same length with channel</span>
<span class="sd">            and be arranged in channel order.</span>
<span class="sd">        dtype (str): The dtype of the output image. Only &quot;float32&quot; and &quot;float16&quot; are supported. Default: &quot;float32&quot;.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input image is not of type :class:`numpy.ndarray`.</span>
<span class="sd">        TypeError: If dimension of the input image is not 3.</span>
<span class="sd">        NotImplementedError: If dtype of the input image is int.</span>
<span class="sd">        ValueError: If lengths of `mean` and `std` are not equal.</span>
<span class="sd">        ValueError: If length of `mean` or `std` is neither equal to 1 nor equal to the length of channel.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.NormalizePad((0.491, 0.482, 0.447), (0.247, 0.243, 0.262), &quot;float32&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_normalizepad_py</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (numpy.ndarray): numpy.ndarray to be normalized and padded.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, normalized and padded numpy.ndarray.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="p">,</span> <span class="n">pad_channel</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="Pad"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Pad.html#mindspore.dataset.vision.py_transforms.Pad">[文档]</a><span class="k">class</span> <span class="nc">Pad</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Pad the input PIL Image on all sides.</span>

<span class="sd">    Args:</span>
<span class="sd">        padding (Union[int, Sequence[int, int], Sequence[int, int, int, int]]): The number of pixels to pad</span>
<span class="sd">            on each border.</span>
<span class="sd">            If int is provided, pad all borders with this value.</span>
<span class="sd">            If Sequence[int, int] is provided, pad the left and top borders with the</span>
<span class="sd">            first value and the right and bottom borders with the second value.</span>
<span class="sd">            If Sequence[int, int, int, int] is provided, pad the left, top, right and bottom borders respectively.</span>
<span class="sd">        fill_value (Union[int, tuple[int, int, int]], optional): Pixel value used to pad the borders,</span>
<span class="sd">            only valid when `padding_mode` is Border.CONSTANT.</span>
<span class="sd">            If int is provided, it will be used for all RGB channels.</span>
<span class="sd">            If tuple[int, int, int] is provided, it will be used for R, G, B channels respectively. Default: 0.</span>
<span class="sd">        padding_mode (Border, optional): Method of padding. It can be Border.CONSTANT, Border.EDGE, Border.REFLECT</span>
<span class="sd">            or Border.SYMMETRIC. Default: Border.CONSTANT. Default: Border.CONSTANT.</span>

<span class="sd">            - Border.CONSTANT, pads with a constant value.</span>
<span class="sd">            - Border.EDGE, pads with the last value at the edge of the image.</span>
<span class="sd">            - Border.REFLECT, pads with reflection of the image omitting the last value on the edge.</span>
<span class="sd">            - Border.SYMMETRIC, pads with reflection of the image repeating the last value on the edge.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `padding` is not of type int or Sequence[int, int].</span>
<span class="sd">        TypeError: If `fill_value` is not of type int or tuple[int, int, int].</span>
<span class="sd">        TypeError: If `padding_mode` is not of type :class:`mindspore.dataset.vision.Border`.</span>
<span class="sd">        ValueError: If `padding` is negative.</span>
<span class="sd">        ValueError: If `fill_value` is not in range of [0, 255].</span>
<span class="sd">        RuntimeError: If shape of the input image is not &lt;H, W&gt; or &lt;H, W, C&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            # adds 10 pixels (default black) to each border of the image</span>
<span class="sd">        ...                            py_vision.Pad(padding=10),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_pad</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="n">Border</span><span class="o">.</span><span class="n">CONSTANT</span><span class="p">):</span>
        <span class="n">parse_padding</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span> <span class="o">=</span> <span class="n">fill_value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span> <span class="o">=</span> <span class="n">DE_PY_BORDER_TYPE</span><span class="p">[</span><span class="n">padding_mode</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be padded.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, padded image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomAffine"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomAffine.html#mindspore.dataset.vision.py_transforms.RandomAffine">[文档]</a><span class="k">class</span> <span class="nc">RandomAffine</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply random affine transformation to the input PIL Image.</span>

<span class="sd">    Args:</span>
<span class="sd">        degrees (Union[float, Sequence[float, float]]): Range of degrees to select from.</span>
<span class="sd">            If float is provided, the degree will be randomly selected from (-`degrees`, `degrees`).</span>
<span class="sd">            If Sequence[float, float] is provided, it needs to be arranged in order of (min, max).</span>
<span class="sd">        translate (Sequence[float, float], optional): Maximum absolute fraction sequence in shape of (tx, ty)</span>
<span class="sd">            for horizontal and vertical translations. The horizontal and vertical shifts are randomly</span>
<span class="sd">            selected from (-tx * width, tx * width) and (-ty * height, ty * height) respectively.</span>
<span class="sd">            Default: None, means no translation.</span>
<span class="sd">        scale (Sequence[float, float], optional): Range of scaling factor to select from.</span>
<span class="sd">            Default: None, means to keep the original scale.</span>
<span class="sd">        shear (Union[float, Sequence[float, float], Sequence[float, float, float, float]], optional):</span>
<span class="sd">            Range of shear factor to select from.</span>
<span class="sd">            If float is provided, a shearing parallel to X axis with a factor selected from</span>
<span class="sd">            (- `shear` , `shear` ) will be applied.</span>
<span class="sd">            If Sequence[float, float] is provided, a shearing parallel to X axis with a factor selected</span>
<span class="sd">            from ( `shear` [0], `shear` [1]) will be applied.</span>
<span class="sd">            If Sequence[float, float, float, float] is provided, a shearing parallel to X axis with a factor selected</span>
<span class="sd">            from ( `shear` [0], `shear` [1]) and a shearing parallel to Y axis with a factor selected from</span>
<span class="sd">            ( `shear` [2], `shear` [3]) will be applied. Default: None, means no shearing.</span>
<span class="sd">        resample (Inter, optional): Method of interpolation. It can be Inter.BILINEAR, Inter.NEAREST</span>
<span class="sd">            or Inter.BICUBIC. If the input PIL Image is in mode of &quot;1&quot; or &quot;P&quot;, Inter.NEAREST will be</span>
<span class="sd">            used directly. Default: Inter.NEAREST.</span>

<span class="sd">            - Inter.BILINEAR, bilinear interpolation.</span>
<span class="sd">            - Inter.NEAREST, nearest-neighbor interpolation.</span>
<span class="sd">            - Inter.BICUBIC, bicubic interpolation.</span>

<span class="sd">        fill_value (Union[int, tuple[int, int, int]], optional): Pixel value for areas outside the transform image.</span>
<span class="sd">            If int is provided, it will be used for all RGB channels.</span>
<span class="sd">            If tuple[int, int, int] is provided, it will be used for R, G, B channels respectively.</span>
<span class="sd">            Only supported with Pillow 5.0.0 and above. Default: 0.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `degrees` is not of type float or Sequence[float, float].</span>
<span class="sd">        TypeError: If `translate` is not of type Sequence[float, float].</span>
<span class="sd">        TypeError: If `scale` is not of type Sequence[float, float].</span>
<span class="sd">        TypeError: If `shear` is not of type float or Sequence[float, float].</span>
<span class="sd">        TypeError: If `resample` is not of type :class:`mindspore.dataset.vision.Inter`.</span>
<span class="sd">        TypeError: If `fill_value` is not of type int or tuple[int, int, int].</span>
<span class="sd">        ValueError: If `degrees` is negative.</span>
<span class="sd">        ValueError: If `translate` is not in range of [-1.0, 1.0].</span>
<span class="sd">        ValueError: If `scale` is negative.</span>
<span class="sd">        ValueError: If `shear` is not positive.</span>
<span class="sd">        RuntimeError: If shape of the input image is not &lt;H, W&gt; or &lt;H, W, C&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_affine</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degrees</span><span class="p">,</span> <span class="n">translate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shear</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">NEAREST</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">shear</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shear</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">):</span>
                <span class="n">shear</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">shear</span><span class="p">,</span> <span class="n">shear</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shear</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="n">shear</span> <span class="o">=</span> <span class="p">[</span><span class="n">shear</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shear</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]</span>
                <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shear</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                    <span class="n">shear</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">shear</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">degrees</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">):</span>
            <span class="n">degrees</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">degrees</span><span class="p">,</span> <span class="n">degrees</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">=</span> <span class="n">degrees</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">translate</span> <span class="o">=</span> <span class="n">translate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_ranges</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shear</span> <span class="o">=</span> <span class="n">shear</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resample</span> <span class="o">=</span> <span class="n">DE_PY_INTER_MODE</span><span class="p">[</span><span class="n">resample</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span> <span class="o">=</span> <span class="n">fill_value</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be randomly affine transformed.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, randomly affine transformed image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_affine</span><span class="p">(</span><span class="n">img</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">translate</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">scale_ranges</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">shear</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">resample</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomColor"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomColor.html#mindspore.dataset.vision.py_transforms.RandomColor">[文档]</a><span class="k">class</span> <span class="nc">RandomColor</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Adjust the color balance of the input PIL Image by a random degree.</span>

<span class="sd">    Args:</span>
<span class="sd">        degrees (Sequence[float, float]): Range of color adjustment degree to select from,</span>
<span class="sd">            must be a Sequence of length 2, arranged in order of (min, max).</span>
<span class="sd">            A degree of 1.0 gives the original image, a degree of 0.0 gives a black and white image</span>
<span class="sd">            and higher degrees mean more brightness, contrast, etc. Default: (0.1, 1.9).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `degrees` is not of type Sequence[float, float].</span>
<span class="sd">        ValueError: If `degrees` is negative.</span>
<span class="sd">        RuntimeError: If shape of the input image is not &lt;H, W, C&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomColor((0.5, 2.0)),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_positive_degrees</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degrees</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">=</span> <span class="n">degrees</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be color adjusted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, color adjusted image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_color</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomColorAdjust"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomColorAdjust.html#mindspore.dataset.vision.py_transforms.RandomColorAdjust">[文档]</a><span class="k">class</span> <span class="nc">RandomColorAdjust</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly adjust the brightness, contrast, saturation, and hue of the input PIL Image.</span>

<span class="sd">    Args:</span>
<span class="sd">        brightness (Union[float, Sequence[float, float]], optional): Range of brightness adjustment factor</span>
<span class="sd">            to select from, must be non negative.</span>
<span class="sd">            If float is provided, the factor will be uniformly selected from</span>
<span class="sd">            [max(0, 1 - `brightness`), 1 + `brightness`).</span>
<span class="sd">            If Sequence[float, float] is provided, it should be arranged in order of (min, max). Default: (1, 1).</span>
<span class="sd">        contrast (Union[float, Sequence[float, float]], optional): Range of contrast adjustment factor</span>
<span class="sd">            to select from, must be non negative.</span>
<span class="sd">            If float is provided, the factor will be uniformly selected from [max(0, 1 - `contrast`), 1 + `contrast`).</span>
<span class="sd">            If Sequence[float, float] is provided, it should be arranged in order of (min, max). Default: (1, 1).</span>
<span class="sd">        saturation (Union[float, Sequence[float, float]], optional): Range of saturation adjustment factor</span>
<span class="sd">            to select from, must be non negative.</span>
<span class="sd">            If float is provided, the factor will be uniformly selected from</span>
<span class="sd">            [max(0, 1 - `saturation`), 1 + `saturation`).</span>
<span class="sd">            If Sequence[float, float] is provided, it should be arranged in order of (min, max). Default: (1, 1).</span>
<span class="sd">        hue (Union[float, Sequence[float, float]], optional): Range of hue adjustment factor to select from.</span>
<span class="sd">            If float is provided, it must be in range of [0, 0.5], and the factor will be uniformly</span>
<span class="sd">            selected from [-`hue`, `hue`).</span>
<span class="sd">            If Sequence[float, float] is provided, the elements must be in range of [-0.5, 0.5] and arranged in</span>
<span class="sd">            order of (min, max). Default: (0, 0).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `brightness` is not of type float or Sequence[float, float].</span>
<span class="sd">        TypeError: If `contrast` is not of type float or Sequence[float, float].</span>
<span class="sd">        TypeError: If `saturation` is not of type float or Sequence[float, float].</span>
<span class="sd">        TypeError: If `hue` is not of type float or Sequence[float, float].</span>
<span class="sd">        ValueError: If `brightness` is negative.</span>
<span class="sd">        ValueError: If `contrast` is negative.</span>
<span class="sd">        ValueError: If `saturation` is negative.</span>
<span class="sd">        ValueError: If `hue` is not in range of [-0.5, 0.5].</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomColorAdjust(0.4, 0.4, 0.4, 0.1),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_color_adjust</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">brightness</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">contrast</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">saturation</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">hue</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">brightness</span> <span class="o">=</span> <span class="n">brightness</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">contrast</span> <span class="o">=</span> <span class="n">contrast</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">saturation</span> <span class="o">=</span> <span class="n">saturation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hue</span> <span class="o">=</span> <span class="n">hue</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be randomly color adjusted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, randomly color adjusted image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_color_adjust</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">brightness</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">contrast</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">saturation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hue</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomCrop"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomCrop.html#mindspore.dataset.vision.py_transforms.RandomCrop">[文档]</a><span class="k">class</span> <span class="nc">RandomCrop</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Crop the input PIL Image at a random location with the specified size.</span>

<span class="sd">    Args:</span>
<span class="sd">        size (Union[int, Sequence[int, int]]): The size of the cropped image.</span>
<span class="sd">            If int is provided, a square of size (`size`, `size`) will be cropped with this value.</span>
<span class="sd">            If Sequence[int, int] is provided, its two elements will be taken as the cropped height and width.</span>
<span class="sd">        padding (Union[int, Sequence[int, int], Sequence[int, int, int, int]], optional): The number of pixels to pad</span>
<span class="sd">            on each border. When specified, it will pad the image before random cropping.</span>
<span class="sd">            If int is provided, pad all borders with this value.</span>
<span class="sd">            If Sequence[int, int] is provided, pad the left and top borders with the</span>
<span class="sd">            first value and the right and bottom borders with the second value.</span>
<span class="sd">            If Sequence[int, int, int, int] is provided, pad the left, top, right and bottom borders respectively.</span>
<span class="sd">            Default: None, means not to pad.</span>
<span class="sd">        pad_if_needed (bool, optional): Whether to pad the image if either side is shorter than</span>
<span class="sd">            the given cropping size. Default: False, means not to pad.</span>
<span class="sd">        fill_value (Union[int, tuple[int, int, int]], optional): Pixel value used to pad the borders,</span>
<span class="sd">            only valid when `padding_mode` is Border.CONSTANT.</span>
<span class="sd">            If int is provided, it will be used for all RGB channels.</span>
<span class="sd">            If tuple[int, int, int] is provided, it will be used for R, G, B channels respectively. Default: 0.</span>
<span class="sd">        padding_mode (Border, optional): Method of padding. It can be Border.CONSTANT, Border.EDGE, Border.REFLECT</span>
<span class="sd">            or Border.SYMMETRIC. Default: Border.CONSTANT.</span>

<span class="sd">            - Border.CONSTANT, pads with a constant value.</span>
<span class="sd">            - Border.EDGE, pads with the last value at the edge of the image.</span>
<span class="sd">            - Border.REFLECT, pads with reflection of the image omitting the last value on the edge.</span>
<span class="sd">            - Border.SYMMETRIC, pads with reflection of the image repeating the last value on the edge.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `size` is not of type int or Sequence[int, int].</span>
<span class="sd">        TypeError: If `padding` is not of type int, Sequence[int, int] or Sequence[int, int, int, int].</span>
<span class="sd">        TypeError: If `pad_if_needed` is not of type bool.</span>
<span class="sd">        TypeError: If `fill_value` is not of type int or tuple[int, int, int].</span>
<span class="sd">        TypeError: If `padding_mode` is not of type :class:`mindspore.dataset.vision.Border`.</span>
<span class="sd">        ValueError: If `size` is not positive.</span>
<span class="sd">        ValueError: If `padding` is negative.</span>
<span class="sd">        ValueError: If `fill_value` is not in range of [0, 255].</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomCrop(224),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_crop</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pad_if_needed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="n">Border</span><span class="o">.</span><span class="n">CONSTANT</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">padding</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="n">parse_padding</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_if_needed</span> <span class="o">=</span> <span class="n">pad_if_needed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span> <span class="o">=</span> <span class="n">fill_value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span> <span class="o">=</span> <span class="n">DE_PY_BORDER_TYPE</span><span class="p">[</span><span class="n">padding_mode</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be randomly cropped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, cropped image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_if_needed</span><span class="p">,</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_mode</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomErasing"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomErasing.html#mindspore.dataset.vision.py_transforms.RandomErasing">[文档]</a><span class="k">class</span> <span class="nc">RandomErasing</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly erase pixels within a random selected rectangle erea on the input numpy.ndarray image.</span>

<span class="sd">    See `Random Erasing Data Augmentation &lt;https://arxiv.org/pdf/1708.04896.pdf&gt;`_.</span>

<span class="sd">    Args:</span>
<span class="sd">        prob (float, optional): Probability of performing erasing. Default: 0.5.</span>
<span class="sd">        scale (Sequence[float, float], optional): Range of area scale of the erased area relative</span>
<span class="sd">            to the original image to select from, arranged in order of (min, max).</span>
<span class="sd">            Default: (0.02, 0.33).</span>
<span class="sd">        ratio (Sequence[float, float], optional): Range of aspect ratio of the erased area to select</span>
<span class="sd">            from, arraged in order of (min, max). Default: (0.3, 3.3).</span>
<span class="sd">        value (Union[int, str, Sequence[int, int, int]]): Pixel value used to pad the erased area.</span>
<span class="sd">            If int is provided, it will be used for all RGB channels.</span>
<span class="sd">            If Sequence[int, int, int] is provided, it will be used for R, G, B channels respectively.</span>
<span class="sd">            If a string of &#39;random&#39; is provided, each pixel will be erased with a random value obtained</span>
<span class="sd">            from a standard normal distribution. Default: 0.</span>
<span class="sd">        inplace (bool, optional): Whether to apply erasing inplace. Default: False.</span>
<span class="sd">        max_attempts (int, optional): The maximum number of attempts to propose a valid</span>
<span class="sd">            erased area, beyond which the original image will be returned. Default: 10.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `prob` is not of type float.</span>
<span class="sd">        TypeError: If `scale` is not of type Sequence[float, float].</span>
<span class="sd">        TypeError: If `ratio` is not of type Sequence[float, float].</span>
<span class="sd">        TypeError: If `value` is not of type int, str, or Sequence[int, int, int].</span>
<span class="sd">        TypeError: If `inplace` is not of type bool.</span>
<span class="sd">        TypeError: If `max_attempts` is not of type int.</span>
<span class="sd">        ValueError: If `prob` is not in range of [0, 1].</span>
<span class="sd">        ValueError: If `scale` is negative.</span>
<span class="sd">        ValueError: If `ratio` is negative.</span>
<span class="sd">        ValueError: If `value` is not in range of [0, 255].</span>
<span class="sd">        ValueError: If `max_attempts` is not positive.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.RandomErasing(value=&#39;random&#39;)])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_erasing</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">),</span> <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.3</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_attempts</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span> <span class="o">=</span> <span class="n">ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span> <span class="o">=</span> <span class="n">inplace</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_attempts</span> <span class="o">=</span> <span class="n">max_attempts</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">np_img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            np_img (numpy.ndarray): image in shape of (C, H, W) to be randomly erased.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, erased image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">bounded</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">&gt;</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">():</span>
            <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">erase_h</span><span class="p">,</span> <span class="n">erase_w</span><span class="p">,</span> <span class="n">erase_value</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">get_erase_params</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span><span class="p">,</span>
                                                                        <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">bounded</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_attempts</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">erase</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">erase_h</span><span class="p">,</span> <span class="n">erase_w</span><span class="p">,</span> <span class="n">erase_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np_img</span></div>


<div class="viewcode-block" id="RandomGrayscale"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomGrayscale.html#mindspore.dataset.vision.py_transforms.RandomGrayscale">[文档]</a><span class="k">class</span> <span class="nc">RandomGrayscale</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly convert the input PIL Image to grayscale.</span>

<span class="sd">    Args:</span>
<span class="sd">        prob (float, optional): Probability of performing grayscale conversion. Default: 0.1.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `prob` is not of type float.</span>
<span class="sd">        ValueError: If `prob` is not in range of [0, 1].</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomGrayscale(0.3),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_prob</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be randomly converted to grayscale.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, randomly converted grayscale image, which has the same number of channels</span>
<span class="sd">                as the input image.</span>
<span class="sd">                If input image has 1 channel, the output grayscale image will have 1 channel.</span>
<span class="sd">                If input image has 3 channels, the output grayscale image will have 3 identical channels.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">img</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;L&#39;</span><span class="p">:</span>
            <span class="n">num_output_channels</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">num_output_channels</span> <span class="o">=</span> <span class="mi">3</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">&gt;</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">grayscale</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">num_output_channels</span><span class="o">=</span><span class="n">num_output_channels</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span></div>


<div class="viewcode-block" id="RandomHorizontalFlip"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomHorizontalFlip.html#mindspore.dataset.vision.py_transforms.RandomHorizontalFlip">[文档]</a><span class="k">class</span> <span class="nc">RandomHorizontalFlip</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly flip the input PIL Image horizontally with a given probability.</span>

<span class="sd">    Args:</span>
<span class="sd">        prob (float, optional): Probability of performing horizontally flip. Default: 0.5.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `prob` is not of type float.</span>
<span class="sd">        ValueError: If `prob` is not in range of [0, 1].</span>
<span class="sd">        RuntimeError: If shape of the input image is not &lt;H, W&gt; or &lt;H, W, C&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_prob</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be horizontally flipped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, randomly horizontally flipped image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_horizontal_flip</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob</span><span class="p">)</span></div>


<span class="k">class</span> <span class="nc">RandomLighting</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Add AlexNet-style PCA-based noise to the input PIL Image.</span>

<span class="sd">    Args:</span>
<span class="sd">        alpha (float, optional): Intensity of the noise. Default: 0.05.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `alpha` is not of type float.</span>
<span class="sd">        ValueError: If `alpha` is negative.</span>
<span class="sd">        RuntimeError: If shape of input image is not &lt;H, W, C&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomLighting(0.1),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_alpha</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be added AlexNet-style PCA-based noise.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, image with noise added.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_lighting</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>


<div class="viewcode-block" id="RandomPerspective"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomPerspective.html#mindspore.dataset.vision.py_transforms.RandomPerspective">[文档]</a><span class="k">class</span> <span class="nc">RandomPerspective</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly apply perspective transformation to the input PIL Image with a given probability.</span>

<span class="sd">    Args:</span>
<span class="sd">        distortion_scale (float, optional): Scale of distortion, in range of [0, 1]. Default: 0.5.</span>
<span class="sd">        prob (float, optional): Probability of performing perspective transformation. Default: 0.5.</span>
<span class="sd">        interpolation (Inter, optional): Method of interpolation. It can be Inter.BILINEAR,</span>
<span class="sd">            Inter.NEAREST or Inter.BICUBIC. Default: Inter.BICUBIC.</span>

<span class="sd">            - Inter.BILINEAR, bilinear interpolation.</span>
<span class="sd">            - Inter.NEAREST, nearest-neighbor interpolation.</span>
<span class="sd">            - Inter.BICUBIC, bicubic interpolation.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `distortion_scale` is not of type float.</span>
<span class="sd">        TypeError: If `prob` is not of type float.</span>
<span class="sd">        TypeError: If `interpolation` is not of type :class:`mindspore.dataset.vision.Inter`.</span>
<span class="sd">        ValueError: If `distortion_scale` is not in range of [0, 1].</span>
<span class="sd">        ValueError: If `prob` is not in range of [0, 1].</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomPerspective(prob=0.1),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_perspective</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">distortion_scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distortion_scale</span> <span class="o">=</span> <span class="n">distortion_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span> <span class="o">=</span> <span class="n">DE_PY_INTER_MODE</span><span class="p">[</span><span class="n">interpolation</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be applied randomly perspective transformation.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, image applied randomly perspective transformation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_pil</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input image should be a Pillow image.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">&gt;</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">():</span>
            <span class="n">start_points</span><span class="p">,</span> <span class="n">end_points</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">get_perspective_params</span><span class="p">(</span>
                <span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">distortion_scale</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">perspective</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">start_points</span><span class="p">,</span> <span class="n">end_points</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span></div>


<div class="viewcode-block" id="RandomResizedCrop"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomResizedCrop.html#mindspore.dataset.vision.py_transforms.RandomResizedCrop">[文档]</a><span class="k">class</span> <span class="nc">RandomResizedCrop</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly crop the input PIL Image and resize it to a given size.</span>

<span class="sd">    Args:</span>
<span class="sd">        size (Union[int, Sequence[int, int]]): The size of the cropped image.</span>
<span class="sd">            If int is provided, a square of size (`size`, `size`) will be cropped with this value.</span>
<span class="sd">            If Sequence[int, int] is provided, its two elements will be taken as the cropped height and width.</span>
<span class="sd">        scale (Sequence[float, float], optional): Range of area scale of the cropped area relative</span>
<span class="sd">            to the original image to select from, arraged in order or (min, max). Default: (0.08, 1.0).</span>
<span class="sd">        ratio (Sequence[float, float], optional): Range of aspect ratio of the cropped area to select</span>
<span class="sd">            from, arraged in order of (min, max). Default: (3./4., 4./3.).</span>
<span class="sd">        interpolation (Inter, optional): Method of interpolation. It can be Inter.NEAREST,</span>
<span class="sd">            Inter.ANTIALIAS, Inter.BILINEAR or Inter.BICUBIC. Default: Inter.BILINEAR.</span>

<span class="sd">            - Inter.NEAREST, nearest-neighbor interpolation.</span>
<span class="sd">            - Inter.ANTIALIAS, antialias interpolation.</span>
<span class="sd">            - Inter.BILINEAR, bilinear interpolation.</span>
<span class="sd">            - Inter.BICUBIC, bicubic interpolation.</span>

<span class="sd">        max_attempts (int, optional): The maximum number of attempts to propose a valid</span>
<span class="sd">            crop area, beyond which it will fall back to use center crop instead. Default: 10.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `size` is not of type int or Sequence[int, int].</span>
<span class="sd">        TypeError: If `scale` is not of type Sequence[float, float].</span>
<span class="sd">        TypeError: If `ratio` is not of type Sequence[float, float].</span>
<span class="sd">        TypeError: If `interpolation` is not of type :class:`mindspore.dataset.vision.Inter`.</span>
<span class="sd">        TypeError: If `max_attempts` is not of type int.</span>
<span class="sd">        ValueError: If `size` is not positive.</span>
<span class="sd">        ValueError: If `scale` is negative.</span>
<span class="sd">        ValueError: If `ratio` is negative.</span>
<span class="sd">        ValueError: If `max_attempts` is not positive.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomResizedCrop(224),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_resize_crop</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.08</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="mf">3.</span> <span class="o">/</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">4.</span> <span class="o">/</span> <span class="mf">3.</span><span class="p">),</span>
                 <span class="n">interpolation</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">BILINEAR</span><span class="p">,</span> <span class="n">max_attempts</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span> <span class="o">=</span> <span class="n">ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span> <span class="o">=</span> <span class="n">DE_PY_INTER_MODE</span><span class="p">[</span><span class="n">interpolation</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_attempts</span> <span class="o">=</span> <span class="n">max_attempts</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be randomly cropped and resized.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, randomly cropped and resized image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_resize_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_attempts</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomRotation"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomRotation.html#mindspore.dataset.vision.py_transforms.RandomRotation">[文档]</a><span class="k">class</span> <span class="nc">RandomRotation</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rotate the input PIL Image by a random angle.</span>

<span class="sd">    Args:</span>
<span class="sd">        degrees (Union[float, Sequence[float, float]]): Range of rotation degree to select from.</span>
<span class="sd">            If int is provided, the rotation degree will be randomly selected from (-`degrees`, `degrees`).</span>
<span class="sd">            If Sequence[float, float] is provided, it should be arranged in order of (min, max).</span>
<span class="sd">        resample (Inter, optional): Method of interpolation. It can be Inter.NEAREST, Inter.ANTIALIAS,</span>
<span class="sd">            Inter.BILINEAR or Inter.BICUBIC. If the input PIL Image is in mode of &quot;1&quot; or &quot;P&quot;,</span>
<span class="sd">            Inter.NEAREST will be used directly. Default: Inter.NEAREST.</span>

<span class="sd">            - Inter.NEAREST, nearest-neighbor interpolation.</span>
<span class="sd">            - Inter.ANTIALIAS, antialias interpolation.</span>
<span class="sd">            - Inter.BILINEAR, bilinear interpolation.</span>
<span class="sd">            - Inter.BICUBIC, bicubic interpolation.</span>

<span class="sd">        expand (bool, optional): If True, it will expand the image to make it large enough to hold the entire</span>
<span class="sd">            rotated image. If False, keep the image the same size as the input. Please note that the expansion</span>
<span class="sd">            assumes rotation around the center and no translation. Default: False.</span>
<span class="sd">        center (Sequence[int, int], optional): The position of the rotation center, taking the upper left corner</span>
<span class="sd">            as the origin. It should be arranged in order of (width, height). Default: None, means to set the</span>
<span class="sd">            center of the image.</span>
<span class="sd">        fill_value (Union[int, tuple[int, int, int]], optional): Pixel value for areas outside the rotated image.</span>
<span class="sd">            If int is provided, it will be used for all RGB channels.</span>
<span class="sd">            If tuple[int, int, int] is provided, it will be used for R, G, B channels respectively. Default: 0.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `degrees` is not of type float or Sequence[float, float].</span>
<span class="sd">        TypeError: If `resample` is not of type :class:`mindspore.dataset.vision.Inter`.</span>
<span class="sd">        TypeError: If `expand` is not of type bool.</span>
<span class="sd">        TypeError: If `center` is not of type Sequence[int, int].</span>
<span class="sd">        TypeError: If `fill_value` is not of type int or tuple[int, int, int].</span>
<span class="sd">        ValueError: If `fill_value` is not in range of [0, 255].</span>
<span class="sd">        RuntimeError: If shape of the input image is not &lt;H, W&gt; or &lt;H, W, C&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomRotation(30),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_random_rotation</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degrees</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">NEAREST</span><span class="p">,</span> <span class="n">expand</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">=</span> <span class="n">degrees</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resample</span> <span class="o">=</span> <span class="n">DE_PY_INTER_MODE</span><span class="p">[</span><span class="n">resample</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">expand</span> <span class="o">=</span> <span class="n">expand</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">center</span> <span class="o">=</span> <span class="n">center</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span> <span class="o">=</span> <span class="n">fill_value</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be randomly rotated.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, randomly rotated image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_rotation</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">resample</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">expand</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">center</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fill_value</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomSharpness"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomSharpness.html#mindspore.dataset.vision.py_transforms.RandomSharpness">[文档]</a><span class="k">class</span> <span class="nc">RandomSharpness</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Adjust the sharpness of the input PIL Image by a random degree.</span>

<span class="sd">    Args:</span>
<span class="sd">        degrees (Sequence[float, float], optional): Range of sharpness adjustment degree to select from, arranged</span>
<span class="sd">            in order of (min, max). A degree of 0.0 gives a blurred image, a degree of 1.0</span>
<span class="sd">            gives the original image and a degree of 2.0 gives a sharpened image.</span>
<span class="sd">            Default: (0.1, 1.9).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError : If `degrees` is not of type Sequence[float, float].</span>
<span class="sd">        ValueError: If `degrees` is negative.</span>
<span class="sd">        ValueError: If `degrees` is not in order of (min, max).</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomSharpness((0.5, 1.5)),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_positive_degrees</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degrees</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span> <span class="o">=</span> <span class="n">degrees</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be sharpness adjusted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, sharpness adjusted image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_sharpness</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degrees</span><span class="p">)</span></div>


<div class="viewcode-block" id="RandomVerticalFlip"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RandomVerticalFlip.html#mindspore.dataset.vision.py_transforms.RandomVerticalFlip">[文档]</a><span class="k">class</span> <span class="nc">RandomVerticalFlip</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Randomly flip the input PIL Image vertically with a given probability.</span>

<span class="sd">    Args:</span>
<span class="sd">        prob (float, optional): Probability of performing vertically flip. Default: 0.5.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `prob` is not of type float.</span>
<span class="sd">        ValueError: If `prob` is not in range of [0, 1].</span>
<span class="sd">        RuntimeError: If shape of input image is not &lt;H, W&gt; or &lt;H, W, C&gt;.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomVerticalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_prob</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be vertically flipped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, randomly vertically flipped image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">random_vertical_flip</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob</span><span class="p">)</span></div>


<div class="viewcode-block" id="Resize"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.Resize.html#mindspore.dataset.vision.py_transforms.Resize">[文档]</a><span class="k">class</span> <span class="nc">Resize</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Resize the input PIL Image to the given size.</span>

<span class="sd">    Args:</span>
<span class="sd">        size (Union[int, Sequence[int, int]]): The size of the resized image.</span>
<span class="sd">            If int is provided, resize the smaller edge of the image to this</span>
<span class="sd">            value, keeping the image aspect ratio the same.</span>
<span class="sd">            If Sequence[int, int] is provided, its two elements will be taken as the resized height and width.</span>
<span class="sd">        interpolation (Inter, optional): Method of interpolation. It can be Inter.NEAREST,</span>
<span class="sd">            Inter.ANTIALIAS, Inter.BILINEAR or Inter.BICUBIC. Default: Inter.BILINEAR.</span>

<span class="sd">            - Inter.NEAREST, nearest-neighbor interpolation.</span>
<span class="sd">            - Inter.ANTIALIAS, antialias interpolation.</span>
<span class="sd">            - Inter.BILINEAR, bilinear interpolation.</span>
<span class="sd">            - Inter.BICUBIC, bicubic interpolation.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `size` is not of type int or Sequence[int, int].</span>
<span class="sd">        TypeError: If `interpolation` is not of type :class:`mindspore.dataset.vision.Inter`.</span>
<span class="sd">        ValueError: If `size` is not positive.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.Resize(256),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_resize_interpolation</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">Inter</span><span class="o">.</span><span class="n">BILINEAR</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span> <span class="o">=</span> <span class="n">DE_PY_INTER_MODE</span><span class="p">[</span><span class="n">interpolation</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be resized.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, resized image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span><span class="p">)</span></div>


<span class="k">class</span> <span class="nc">RgbToBgr</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert the input numpy.ndarray images from RGB to BGR.</span>

<span class="sd">    Args:</span>
<span class="sd">        is_hwc (bool): If True, means the input image is in shape of (H, W, C) or (N, H, W, C).</span>
<span class="sd">            Otherwise, it is in shape of (C, H, W) or (N, C, H, W). Default: False.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `is_hwc` is not of type bool.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.CenterCrop(20),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.RgbToBgr()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_rgb_to_bgr</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">is_hwc</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span> <span class="o">=</span> <span class="n">is_hwc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rgb_imgs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            rgb_imgs (numpy.ndarray): RGB images to be converted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, converted BGR images.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">rgb_to_bgrs</span><span class="p">(</span><span class="n">rgb_imgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span><span class="p">)</span>


<div class="viewcode-block" id="RgbToHsv"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.RgbToHsv.html#mindspore.dataset.vision.py_transforms.RgbToHsv">[文档]</a><span class="k">class</span> <span class="nc">RgbToHsv</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert the input numpy.ndarray images from RGB to HSV.</span>

<span class="sd">    Args:</span>
<span class="sd">        is_hwc (bool): If True, means the input image is in shape of (H, W, C) or (N, H, W, C).</span>
<span class="sd">            Otherwise, it is in shape of (C, H, W) or (N, C, H, W). Default: False.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `is_hwc` is not of type bool.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.CenterCrop(20),</span>
<span class="sd">        ...                            py_vision.ToTensor(),</span>
<span class="sd">        ...                            py_vision.RgbToHsv()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_rgb_to_hsv</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">is_hwc</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span> <span class="o">=</span> <span class="n">is_hwc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rgb_imgs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            rgb_imgs (numpy.ndarray): RGB images to be converted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, converted HSV images.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">rgb_to_hsvs</span><span class="p">(</span><span class="n">rgb_imgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_hwc</span><span class="p">)</span></div>


<div class="viewcode-block" id="TenCrop"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.TenCrop.html#mindspore.dataset.vision.py_transforms.TenCrop">[文档]</a><span class="k">class</span> <span class="nc">TenCrop</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Crop the given image into one central crop and four corners with the flipped version of these.</span>

<span class="sd">    Args:</span>
<span class="sd">        size (Union[int, Sequence[int, int]]): The size of the cropped image.</span>
<span class="sd">            If int is provided, a square of size (`size`, `size`) will be cropped with this value.</span>
<span class="sd">            If Sequence[int, int] is provided, its two elements will be taken as the cropped height and width.</span>
<span class="sd">        use_vertical_flip (bool, optional): If True, flip the images vertically. Otherwise, flip them</span>
<span class="sd">            horizontally. Default: False.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `size` is not of type int or Sequence[int, int].</span>
<span class="sd">        TypeError: If `use_vertical_flip` is not of type bool.</span>
<span class="sd">        ValueError: If `size` is not positive.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.TenCrop(size=200),</span>
<span class="sd">        ...                            # 4D stack of 10 images</span>
<span class="sd">        ...                            lambda *images: numpy.stack([py_vision.ToTensor()(image) for image in images])])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_ten_crop</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">use_vertical_flip</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_vertical_flip</span> <span class="o">=</span> <span class="n">use_vertical_flip</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be cropped.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple, 10 cropped PIL.Image.Image, in order of top_left, top_right, bottom_left, bottom_right, center</span>
<span class="sd">                of the original image and top_left, top_right, bottom_left, bottom_right, center of the flipped image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">ten_crop</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_vertical_flip</span><span class="p">)</span></div>


<div class="viewcode-block" id="ToPIL"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.ToPIL.html#mindspore.dataset.vision.py_transforms.ToPIL">[文档]</a><span class="k">class</span> <span class="nc">ToPIL</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert the input decoded numpy.ndarray image to PIL Image.</span>

<span class="sd">    Note:</span>
<span class="sd">        The conversion mode will be determined by the data type using :class:`PIL.Image.fromarray`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input image is not of type :class:`numpy.ndarray` or :class:`PIL.Image.Image`.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # data is already decoded, but not in PIL Image format</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.ToPIL(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (numpy.ndarray): Decoded numpy.ndarray image to be converted to PIL.Image.Image.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, converted PIL Image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">to_pil</span><span class="p">(</span><span class="n">img</span><span class="p">)</span></div>


<div class="viewcode-block" id="ToTensor"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.ToTensor.html#mindspore.dataset.vision.py_transforms.ToTensor">[文档]</a><span class="k">class</span> <span class="nc">ToTensor</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert the input PIL Image or numpy.ndarray to numpy.ndarray of the desired dtype. At the same time,</span>
<span class="sd">    the range of pixel value will be changed from [0, 255] to [0.0, 1.0] and the shape will be changed</span>
<span class="sd">    from (H, W, C) to (C, H, W).</span>

<span class="sd">    Args:</span>
<span class="sd">        output_type (numpy.dtype, optional): The desired dtype of the output image. Default: :class:`numpy.float32`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input image is not of type :class:`PIL.Image.Image` or :class:`numpy.ndarray`.</span>
<span class="sd">        TypeError: If dimension of the input image is not 2 or 3.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # create a list of transformations to be applied to the &quot;image&quot; column of each data row</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_type</span> <span class="o">=</span> <span class="n">output_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (Union[PIL.Image.Image, numpy.ndarray]): PIL.Image.Image or numpy.ndarray to be type converted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, converted numpy.ndarray with desired type.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_type</span><span class="p">)</span></div>


<div class="viewcode-block" id="ToType"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.ToType.html#mindspore.dataset.vision.py_transforms.ToType">[文档]</a><span class="k">class</span> <span class="nc">ToType</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert the input numpy.ndarray image to the desired dtype.</span>

<span class="sd">    Args:</span>
<span class="sd">        output_type (numpy.dtype): The desired dtype of the output image, e.g. :class:`numpy.float32`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input image is not of type :class:`numpy.ndarray`.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms_list =Compose([py_vision.Decode(),</span>
<span class="sd">        ...                           py_vision.RandomHorizontalFlip(0.5),</span>
<span class="sd">        ...                           py_vision.ToTensor(),</span>
<span class="sd">        ...                           py_vision.ToType(np.float32)])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_type</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_type</span> <span class="o">=</span> <span class="n">output_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (numpy.ndarray): numpy.ndarray to be dtype converted.</span>

<span class="sd">        Returns:</span>
<span class="sd">            numpy.ndarray, converted numpy.ndarray with desired dtype.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">to_type</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_type</span><span class="p">)</span></div>


<div class="viewcode-block" id="UniformAugment"><a class="viewcode-back" href="../../../../api_python/dataset_vision/mindspore.dataset.vision.py_transforms.UniformAugment.html#mindspore.dataset.vision.py_transforms.UniformAugment">[文档]</a><span class="k">class</span> <span class="nc">UniformAugment</span><span class="p">(</span><span class="n">py_transforms</span><span class="o">.</span><span class="n">PyTensorOperation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Uniformly select a number of transformations from a sequence and apply them</span>
<span class="sd">    sequentially and randomly, which means that there is a chance that a chosen</span>
<span class="sd">    transformation will not be applied.</span>

<span class="sd">    All transformations in the sequence require the output type to be the same as</span>
<span class="sd">    the input. Thus, the latter one can deal with the output of the previous one.</span>

<span class="sd">    Args:</span>
<span class="sd">         transforms (Sequence): Sequence of transformations to select from.</span>
<span class="sd">         num_ops (int, optional): Number of transformations to be sequentially and randomly applied. Default: 2.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If `transforms` is not a sequence of data processing operations.</span>
<span class="sd">        TypeError: If `num_ops` is not of type int.</span>
<span class="sd">        ValueError: If `num_ops` is not positive.</span>

<span class="sd">    Supported Platforms:</span>
<span class="sd">        ``CPU``</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from mindspore.dataset.transforms.py_transforms import Compose</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; transforms = [py_vision.CenterCrop(64),</span>
<span class="sd">        ...               py_vision.RandomColor(),</span>
<span class="sd">        ...               py_vision.RandomSharpness(),</span>
<span class="sd">        ...               py_vision.RandomRotation(30)]</span>
<span class="sd">        &gt;&gt;&gt; transforms_list = Compose([py_vision.Decode(),</span>
<span class="sd">        ...                            py_vision.UniformAugment(transforms),</span>
<span class="sd">        ...                            py_vision.ToTensor()])</span>
<span class="sd">        &gt;&gt;&gt; # apply the transform to dataset through map function</span>
<span class="sd">        &gt;&gt;&gt; image_folder_dataset = image_folder_dataset.map(operations=transforms_list,</span>
<span class="sd">        ...                                                 input_columns=&quot;image&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@check_uniform_augment_py</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">num_ops</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">transforms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_ops</span> <span class="o">=</span> <span class="n">num_ops</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call method.</span>

<span class="sd">        Args:</span>
<span class="sd">            img (PIL.Image.Image): Image to be transformed.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PIL.Image.Image, transformed image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">util</span><span class="o">.</span><span class="n">uniform_augment</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_ops</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">not_random</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Specify the function as &quot;not random&quot;, i.e., it produces deterministic result.</span>
<span class="sd">    A Python function can only be cached after it is specified as &quot;not random&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">func</span><span class="o">.</span><span class="n">random</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="n">func</span>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>