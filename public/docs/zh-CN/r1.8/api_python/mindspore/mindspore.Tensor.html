

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindspore.Tensor &mdash; MindSpore master documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script src="../../_static/js/training.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="mindspore.COOTensor" href="mindspore.COOTensor.html" />
    <link rel="prev" title="mindspore" href="../mindspore.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">设计</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../design/all_scenarios.html">全场景统一</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/auto_gradient.html">函数式微分编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/dynamic_graph_and_static_graph.html">动静态图结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/heterogeneous_training.html">异构并行训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/distributed_training_design.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/mindir.html">中间表达MindIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/graph_fusion_engine.html">图算融合加速引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/thor.html">二阶优化</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindinsight/docs/zh-CN/r1.8/training_visual_design.html">可视化调试调优↗</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/mindarmour/docs/zh-CN/r1.8/design.html">安全可信↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/glossary.html">术语</a></li>
</ul>
<p class="caption"><span class="caption-text">规格</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/benchmark.html">基准性能</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/network_list.html">网络支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/operator_list.html">算子支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/syntax_list.html">语法支持</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../mindspore.html">mindspore</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../mindspore.html#张量">张量</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">mindspore.Tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.COOTensor.html">mindspore.COOTensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.CSRTensor.html">mindspore.CSRTensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.RowTensor.html">mindspore.RowTensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.SparseTensor.html">mindspore.SparseTensor</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#参数">参数</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#数据类型">数据类型</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#随机种子">随机种子</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#运行环境">运行环境</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#模型">模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#回调函数">回调函数</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#数据处理工具">数据处理工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#序列化">序列化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#调试调优">调试调优</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#即时编译">即时编译</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#日志">日志</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#安装验证">安装验证</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#内存回收">内存回收</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#二阶优化">二阶优化</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.audio.html">mindspore.dataset.audio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.transformer.html">mindspore.nn.transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.functional.html">mindspore.ops.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.parallel.nn.html">mindspore.parallel.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.8/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption"><span class="caption-text">API映射</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/pytorch_api_mapping.html">PyTorch与MindSpore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/tensorflow_api_mapping.html">TensorFlow与MindSpore</a></li>
</ul>
<p class="caption"><span class="caption-text">迁移指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/overview.html">概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/preparation.html">准备工作</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/script_analysis.html">网络脚本分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/script_development.html">网络脚本开发</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/neural_network_debug.html">网络调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/accuracy_optimization.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/performance_optimization.html">性能调试</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/inference.html">推理执行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/sample_code.html">网络迁移调试实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/faq.html">常见问题</a></li>
</ul>
<p class="caption"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq/installation.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/data_processing.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/implement_problem.html">执行问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/network_compilation.html">网络编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/usage_migrate_3rd.html">第三方框架迁移使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/distributed_configure.html">分布式配置</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/feature_advice.html">特性咨询</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../mindspore.html">mindspore</a> &raquo;</li>
        
      <li>mindspore.Tensor</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/api_python/mindspore/mindspore.Tensor.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="mindspore-tensor">
<h1>mindspore.Tensor<a class="headerlink" href="#mindspore-tensor" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="mindspore.Tensor">
<em class="property">class </em><code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">Tensor</code><span class="sig-paren">(</span><em class="sig-param">input_data=None</em>, <em class="sig-param">dtype=None</em>, <em class="sig-param">shape=None</em>, <em class="sig-param">init=None</em>, <em class="sig-param">internal=False</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>张量，即存储多维数组（n-dimensional array）的数据结构。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>input_data</strong> (Union[Tensor, float, int, bool, tuple, list, numpy.ndarray]) - 被存储的数据，可以是其它Tensor，也可以是Python基本数据（如int，float，bool等），或是一个NumPy对象。默认值：None。</p></li>
<li><p><strong>dtype</strong> (<a class="reference internal" href="mindspore.dtype.html#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>) - 用于定义该Tensor的数据类型，必须是 <em>mindspore.dtype</em> 中定义的类型。如果该参数为None，则数据类型与 <cite>input_data</cite> 一致，默认值：None。</p></li>
<li><p><strong>shape</strong> (Union[tuple, list, int]) - 用于定义该Tensor的形状。如果指定了 <cite>input_data</cite> ，则无需设置该参数。默认值：None。</p></li>
<li><p><strong>init</strong> (Initializer) - 用于在并行模式中延迟Tensor的数据的初始化，如果指定该参数，则 <cite>dtype</cite> 和 <cite>shape</cite> 也必须被指定。不推荐在非自动并行之外的场景下使用该接口。只有当调用 <cite>Tensor.init_data</cite> 时，才会使用指定的 <cite>init</cite> 来初始化Tensor数据。默认值：None。</p></li>
<li><p><strong>internal</strong> (bool) - Tensor是否由框架创建。如果为True，表示Tensor是由框架创建的，如果为False，表示Tensor是由用户创建的。默认值：False。</p></li>
</ul>
<p><strong>输出：</strong></p>
<p>Tensor。</p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">One</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize a tensor with numpy.ndarray</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t1</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">t1</span><span class="p">)</span>
<span class="go">[[[0. 0. 0.]</span>
<span class="go">[0. 0. 0.]]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">t1</span><span class="p">))</span>
<span class="go">&lt;class &#39;mindspore.common.tensor.Tensor&#39;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">t1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(1, 2, 3)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">t1</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="go">Float32</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize a tensor with a float scalar</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t2</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">t2</span><span class="p">)</span>
<span class="go">0.1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">t2</span><span class="p">))</span>
<span class="go">&lt;class &#39;mindspore.common.tensor.Tensor&#39;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">t2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">t2</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="go">Float32</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize a tensor with a tuple</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t3</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">t3</span><span class="p">)</span>
<span class="go">[1 2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">t3</span><span class="p">))</span>
<span class="go">&lt;class &#39;mindspore.common.tensor.Tensor&#39;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">t3</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(2,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">t3</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="go">Int64</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># initialize a tensor with init</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t4</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="n">One</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">t4</span><span class="p">)</span>
<span class="go">[[1. 1. 1.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">t4</span><span class="p">))</span>
<span class="go">&lt;class &#39;mindspore.common.tensor.Tensor&#39;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">t4</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(1, 3)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">t4</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="go">Float32</span>
</pre></div>
</div>
<dl class="method">
<dt id="mindspore.Tensor.T">
<em class="property">property </em><code class="sig-name descname">T</code><a class="headerlink" href="#mindspore.Tensor.T" title="Permalink to this definition">¶</a></dt>
<dd><p>返回转置后的Tensor。</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.abs">
<code class="sig-name descname">abs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.abs"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.abs" title="Permalink to this definition">¶</a></dt>
<dd><p>返回每个元素的绝对值。</p>
<p><strong>返回：</strong></p>
<p>Tensor。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">1.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[1.1 2.1]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.all">
<code class="sig-name descname">all</code><span class="sig-paren">(</span><em class="sig-param">axis=()</em>, <em class="sig-param">keep_dims=False</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.all"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.all" title="Permalink to this definition">¶</a></dt>
<dd><p>检查在指定轴上所有元素是否均为True。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (Union[None, int, tuple(int)]) - 计算all的维度。当 <cite>axis</cite> 为None或者空元组的时候，计算所有维度。当 <cite>axis</cite> 为int或tuple(int)时，记Tensor的维度为dim，则其取值范围为[-dim, dim)。默认值：()。</p></li>
<li><p><strong>keep_dims</strong> (bool) - 计算结果是否保留维度。默认值：False。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor。如果在指定轴方向上所有数组元素都为True，则其值为True，否则其值为False。如果轴为None或空元组，则默认降维。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">False</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.any">
<code class="sig-name descname">any</code><span class="sig-paren">(</span><em class="sig-param">axis=()</em>, <em class="sig-param">keep_dims=False</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.any"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.any" title="Permalink to this definition">¶</a></dt>
<dd><p>检查在指定轴方向上是否存在任意为True的Tensor元素。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (Union[None, int, tuple(int)]) - 计算any的维度。当 <cite>axis</cite> 为None或空元组时，计算所有维度。当 <cite>axis</cite> 为int或tuple(int)时，记Tensor的维度为dim，则其取值范围为[-dim, dim)。默认值：()。</p></li>
<li><p><strong>keep_dims</strong> (bool) - 计算结果是否保留维度。默认值：False。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor。如果在指定轴方向上所有Tensor元素都为True，则其值为True，否则其值为False。如果轴为None或空元组，则默认降维。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.col2im">
<code class="sig-name descname">col2im</code><span class="sig-paren">(</span><em class="sig-param">output_size</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">dilation</em>, <em class="sig-param">padding_value</em>, <em class="sig-param">stride</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.col2im"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.col2im" title="Permalink to this definition">¶</a></dt>
<dd><p>将一组滑动的局部块组合成一个大张量。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>output_size</strong> (Tensor) - 输出张量的后两维的shape。</p></li>
<li><p><strong>kernel_size</strong> (Union[int, tuple[int], list[int]]) - 滑动窗口的大小。</p></li>
<li><p><strong>dilation</strong> (Union[int, tuple[int], list[int]]) - 滑动窗口扩张的大小。</p></li>
<li><p><strong>padding_value</strong> (Union[int, tuple[int], list[int]]) - 填充的大小。</p></li>
<li><p><strong>stride</strong> (Union[int, tuple[int], list[int]]) - 步长的大小。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，输出的张量，维度和类型和输入一致。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 如果 <cite>kernel_size</cite>，<cite>dilation</cite>，<cite>padding_value</cite>，<cite>stride</cite> 不属于 Union[int, tuple[int], list[int]]。</p></li>
<li><p><strong>ValueError</strong> - 如果 <cite>kernel_size</cite>，<cite>dilation</cite>，<cite>stride</cite> 值小于等于0或者个数大于2。</p></li>
<li><p><strong>ValueError</strong> - 如果 <cite>padding_value</cite> 值小于0或者个数大于2。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output_size</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">col2im</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dilation</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">padding_value</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(16, 16, 8, 8)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.argmax">
<code class="sig-name descname">argmax</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.argmax"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.argmax" title="Permalink to this definition">¶</a></dt>
<dd><p>返回指定轴上最大值的索引。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (int, optional) - 默认情况下，返回扁平化Tensor的最大值序号，否则返回指定轴方向上。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，最大值的索引。它与原始Tensor具有相同的shape，但移除了轴方向上的维度。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>ValueError</strong> - 入参axis的设定值超出了范围。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">argmax</span><span class="p">())</span>
<span class="go">5</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.argmin">
<code class="sig-name descname">argmin</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.argmin"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.argmin" title="Permalink to this definition">¶</a></dt>
<dd><p>返回指定轴上最小值的索引。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (int, optional) - 返回扁平化Tensor的最小值序号，否则返回指定轴方向上的最小值序号。默认值: None。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，最小Tensor的索引。它与原始Tensor具有相同的shape，但移除了轴方向上的维度。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>ValueError</strong> - 入参axis的设定值超出了范围。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">argmin</span><span class="p">())</span>
<span class="go">0</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.asnumpy">
<code class="sig-name descname">asnumpy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.asnumpy"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.asnumpy" title="Permalink to this definition">¶</a></dt>
<dd><p>将张量转换为NumPy数组。该方法会将Tensor本身转换为NumPy的ndarray。这个Tensor和函数返回的ndarray共享内存地址。对Tensor本身的修改会反映到相应的ndarray上。</p>
<p><strong>返回：</strong></p>
<p>NumPy的ndarray，该ndarray与Tensor共享内存地址。</p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">11</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">[11.  2.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">[11.  2.]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.assign_value">
<code class="sig-name descname">assign_value</code><span class="sig-paren">(</span><em class="sig-param">value</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.assign_value"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.assign_value" title="Permalink to this definition">¶</a></dt>
<dd><p>将另一个Tensor的值赋给当前Tensor。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>value</strong> (Tensor) - 用于赋值的Tensor。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，赋值后的Tensor。</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.astype">
<code class="sig-name descname">astype</code><span class="sig-paren">(</span><em class="sig-param">dtype</em>, <em class="sig-param">copy=True</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.astype"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.astype" title="Permalink to this definition">¶</a></dt>
<dd><p>将Tensor转为指定数据类型，可指定是否返回副本。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>dtype</strong> (Union[<cite>mindspore.dtype</cite> , <cite>numpy.dtype</cite> , str]) - 指定的Tensor数据类型，可以是: <cite>mindspore.dtype.float32</cite> , <cite>numpy.float32</cite> 或 <cite>float32</cite> 的格式。默认值：<cite>mindspore.dtype.float32</cite> 。</p></li>
<li><p><strong>copy</strong> (bool, optional) - 默认情况下，astype返回新拷贝的Tensor。如果该参数设为False，则返回输入Tensor而不是副本。默认值：True。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，指定数据类型的Tensor。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 指定了无法解析的类型。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;int32&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="go">Int32</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.atan2">
<code class="sig-name descname">atan2</code><span class="sig-paren">(</span><em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.atan2"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.atan2" title="Permalink to this definition">¶</a></dt>
<dd><p>逐元素计算x/y的反正切值。</p>
<p><cite>x</cite> 指的当前 Tensor。</p>
<p>返回 <span class="math notranslate nohighlight">\(\theta\ \in\ [-\pi, \pi]\)</span> ，使得 <span class="math notranslate nohighlight">\(x = r*\sin(\theta), y = r*\cos(\theta)\)</span> ，其中 <span class="math notranslate nohighlight">\(r = \sqrt{x^2 + y^2}\)</span> 。
输入 <cite>x</cite> 和 <cite>y</cite> 会通过隐式数据类型转换使数据类型保持一致。如果数据类型不同，低精度的数据类型会被转换到高精度的数据类型。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>y</strong> (Tensor) - 输入Tensor。shape应能在广播后与 <cite>x</cite> 相同，或 <cite>x</cite> 的shape在广播后与 <cite>y</cite> 相同。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，与广播后的输入shape相同，和 <cite>x</cite> 数据类型相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>x</cite> 或 <cite>y</cite> 不是Tensor。</p></li>
<li><p><strong>RuntimeError</strong> - <cite>x</cite> 与 <cite>y</cite> 之间的数据类型转换不被支持。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">atan2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[0.        0.7853982]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.bernoulli">
<code class="sig-name descname">bernoulli</code><span class="sig-paren">(</span><em class="sig-param">p=0.5</em>, <em class="sig-param">seed=-1</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.bernoulli"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.bernoulli" title="Permalink to this definition">¶</a></dt>
<dd><p>以p的概率随机将输出的元素设置为0或1，服从伯努利分布。</p>
<div class="math notranslate nohighlight">
\[out_{i} \sim Bernoulli(p_{i})\]</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>p</strong> (Union[Tensor, float], 可选) - shape需要可以被广播到当前Tensor。其数据类型为float32或float64。<cite>p</cite> 中每个值代表输出Tensor中对应广播位置为1的概率，数值范围在0到1之间。默认值：0.5。</p></li>
<li><p><strong>seed</strong> (int, 可选) - 随机种子，用于生成随机数，数值范围是-1或正整数。默认值：-1，代表取当前时间戳。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，shape和数据类型与当前Tensor相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 当前Tensor的数据类型不在int8, uint8, int16, int32, int64, bool, float32和float64中。</p></li>
<li><p><strong>TypeError</strong> - <cite>p</cite> 的数据类型既不是float32也不是float64。</p></li>
<li><p><strong>TypeError</strong> - <cite>seed</cite> 不是int。</p></li>
<li><p><strong>ValueError</strong> - <cite>seed</cite> 是负数且不为-1。</p></li>
<li><p><strong>ValueError</strong> - <cite>p</cite> 数值范围不在0到1之间。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[1 1 1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_p</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">input_p</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[0 1 1]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.bitwise_and">
<code class="sig-name descname">bitwise_and</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.bitwise_and"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.bitwise_and" title="Permalink to this definition">¶</a></dt>
<dd><p>逐元素执行两个Tensor的与运算。</p>
<p>更多细节参考 <a class="reference internal" href="../ops/mindspore.ops.bitwise_and.html#mindspore.ops.bitwise_and" title="mindspore.ops.bitwise_and"><code class="xref py py-func docutils literal notranslate"><span class="pre">mindspore.ops.bitwise_and()</span></code></a>。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>x</strong> (Tensor) - 输入Tensor，是一个数据类型为uint16、int16或int32的Tensor。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，是一个与 <cite>x</cite> 相同类型的Tensor。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">bitwise_and</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[ 0  0  1 -1  1  0  1]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.bitwise_or">
<code class="sig-name descname">bitwise_or</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.bitwise_or"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.bitwise_or" title="Permalink to this definition">¶</a></dt>
<dd><p>逐元素执行两个Tensor的或运算。</p>
<p>更多细节参考 <a class="reference internal" href="../ops/mindspore.ops.bitwise_or.html#mindspore.ops.bitwise_or" title="mindspore.ops.bitwise_or"><code class="xref py py-func docutils literal notranslate"><span class="pre">mindspore.ops.bitwise_or()</span></code></a>。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>x</strong> (Tensor) - 输入Tensor，是一个数据类型为uint16、int16或int32的Tensor。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，是一个与 <cite>x</cite> 相同类型的Tensor。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">bitwise_or</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[ 0  1  1 -1 -1  3  3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.bitwise_xor">
<code class="sig-name descname">bitwise_xor</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.bitwise_xor"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.bitwise_xor" title="Permalink to this definition">¶</a></dt>
<dd><p>逐元素执行两个Tensor的异或运算。</p>
<p>更多细节参考 <a class="reference internal" href="../ops/mindspore.ops.bitwise_xor.html#mindspore.ops.bitwise_xor" title="mindspore.ops.bitwise_xor"><code class="xref py py-func docutils literal notranslate"><span class="pre">mindspore.ops.bitwise_xor()</span></code></a>。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>x</strong> (Tensor) - 输入Tensor，是一个数据类型为uint16、int16或int32的Tensor。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，是一个与 <cite>x</cite> 相同类型的Tensor。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">bitwise_xor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[ 0  1  0  0 -2  3  2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.broadcast_to">
<code class="sig-name descname">broadcast_to</code><span class="sig-paren">(</span><em class="sig-param">shape</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.broadcast_to"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.broadcast_to" title="Permalink to this definition">¶</a></dt>
<dd><p>将输入shape广播到目标shape。</p>
<p>更多细节请参考 <a class="reference internal" href="../ops/mindspore.ops.broadcast_to.html#mindspore.ops.broadcast_to" title="mindspore.ops.broadcast_to"><code class="xref py py-func docutils literal notranslate"><span class="pre">mindspore.ops.broadcast_to()</span></code></a>。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>shape</strong> (tuple) - 要广播的目标形状。可以由用户指定，或在要广播的维度上指定-1，它将被该位置的输入张量形状替换。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，形状为用户指定的 <cite>shape</cite>，类型和 <cite>self</cite> 相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 如果输入的 <cite>shape</cite> 参数不是tuple类型。</p></li>
<li><p><strong>ValueError</strong> - 如果输入的 <cite>shape</cite> 与 <cite>self</cite> 的形状不兼容，或者目标 <cite>shape</cite> 中的-1位于无效位置。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[1. 2. 3.]</span>
<span class="go">[1. 2. 3.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[1. 1.]</span>
<span class="go">[2. 2.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.ceil">
<code class="sig-name descname">ceil</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.ceil"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.ceil" title="Permalink to this definition">¶</a></dt>
<dd><p>向上取整。</p>
<p><strong>返回：</strong></p>
<p>Tensor。向上取整的结果。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 如果当前Tensor的数据类型不是float16或者float32。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">ceil</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[ 2.  3. -1.]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.choose">
<code class="sig-name descname">choose</code><span class="sig-paren">(</span><em class="sig-param">choices</em>, <em class="sig-param">mode='clip'</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.choose"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.choose" title="Permalink to this definition">¶</a></dt>
<dd><p>根据原始Tensor数组和一个索引数组构造一个新的Tensor。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>choices</strong> (Union[tuple, list, Tensor]) - 索引选择数组。原始输入Tensor和 <cite>choices</cite> 的广播维度必须相同。如果 <cite>choices</cite> 本身是一个Tensor，则其最外层的维度（即，对应于第0维的维度）被用来定义 <cite>choices</cite> 数组。</p></li>
<li><p><strong>mode</strong> (‘raise’, ‘wrap’, ‘clip’, optional) - 指定如何处理 <cite>[0, n-1]</cite> 外部的索引：</p>
<ul>
<li><p><strong>raise</strong> - 引发异常（默认）；</p></li>
<li><p><strong>wrap</strong> - 原值映射为对n取余后的值；</p></li>
<li><p><strong>clip</strong> - 大于n-1的值会被映射为n-1。该模式下禁用负数索引。</p></li>
</ul>
</li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，合并后的结果。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>ValueError</strong> - 输入Tensor和任一 <cite>choices</cite> 无法广播。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">choices</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">],</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">23</span><span class="p">],</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">33</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">choose</span><span class="p">(</span><span class="n">choices</span><span class="p">))</span>
<span class="go">[20 31 12  3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.clip">
<code class="sig-name descname">clip</code><span class="sig-paren">(</span><em class="sig-param">xmin</em>, <em class="sig-param">xmax</em>, <em class="sig-param">dtype=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.clip"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.clip" title="Permalink to this definition">¶</a></dt>
<dd><p>裁剪Tensor中的值。</p>
<p>给定一个区间，区间外的值将被裁剪到区间边缘。
例如，如果指定的间隔为 <span class="math notranslate nohighlight">\([0, 1]\)</span> ，则小于0的值将变为0，大于1的值将变为1。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>目前不支持裁剪 <cite>xmin=nan</cite> 或 <cite>xmax=nan</cite> 。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>xmin</strong> (Tensor, scalar, None) - 最小值。如果值为None，则不在间隔的下边缘执行裁剪操作。<cite>xmin</cite> 或 <cite>xmax</cite> 只能有一个为None。</p></li>
<li><p><strong>xmax</strong> (Tensor, scalar, None) - 最大值。如果值为None，则不在间隔的上边缘执行裁剪操作。<cite>xmin</cite> 或 <cite>xmax</cite> 只能有一个为None。如果 <cite>xmin</cite> 或 <cite>xmax</cite> 是Tensor，则三个Tensor将被广播进行shape匹配。</p></li>
<li><p><strong>dtype</strong> (<cite>mindspore.dtype</cite> , optional) - 覆盖输出Tensor的dtype。默认值为None。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，含有输入Tensor的元素，其中values &lt; <cite>xmin</cite> 被替换为 <cite>xmin</cite> ，values &gt; <cite>xmax</cite> 被替换为 <cite>xmax</cite> 。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 输入的类型与Tensor不一致。</p></li>
<li><p><strong>ValueError</strong> - 输入与Tensor的shape不能广播，或者 <cite>xmin</cite> 和 <cite>xmax</cite> 都是 <cite>None</cite> 。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">[1. 2. 2. 0. 0. 2. 2. 0.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">[1. 2. 2. 1. 1. 2. 2. 1.]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.copy">
<code class="sig-name descname">copy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.copy"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.copy" title="Permalink to this definition">¶</a></dt>
<dd><p>复制一个Tensor并返回。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>当前实现不支持类似NumPy的 <cite>order</cite> 参数。</p>
</div>
<p><strong>返回：</strong></p>
<p>复制的Tensor。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[1. 1. 1.]</span>
<span class="go">[1. 1. 1.]</span>
<span class="go">[1. 1. 1.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.cosh">
<code class="sig-name descname">cosh</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.cosh"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.cosh" title="Permalink to this definition">¶</a></dt>
<dd><p>逐元素计算双曲余弦值。</p>
<div class="math notranslate nohighlight">
\[out_i = cosh(x_i)\]</div>
<p><strong>返回：</strong></p>
<p>Tensor，数据类型和shape与 <cite>x</cite> 相同。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.24</span><span class="p">,</span> <span class="mf">0.83</span><span class="p">,</span> <span class="mf">0.31</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">cosh</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[1.0289385 1.364684 1.048436 1.0040528]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.cummax">
<code class="sig-name descname">cummax</code><span class="sig-paren">(</span><em class="sig-param">axis</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.cummax"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.cummax" title="Permalink to this definition">¶</a></dt>
<dd><p>返回一个元组（最值、索引），其中最值是输入张量 <cite>x</cite> 沿维度 <cite>axis</cite> 的累积最大值，索引是每个最大值的索引位置。</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll} \\
    y{i} = max(x{1}, x{2}, ... , x{i})
\end{array}\end{split}\]</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (int) - 算子操作的维度，维度的大小范围是[-x.ndim, x.ndim - 1]。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>一个包含两个Tensor的元组，分别表示累积最大值和对应索引。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 如果 <cite>axis</cite> 不是int。</p></li>
<li><p><strong>ValueError</strong> - 如果 <cite>axis</cite> 不在范围[-x.ndim, x.ndim - 1]内。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">cummax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="go">[[ 3.  4.  6. 10.]</span>
<span class="go">[ 3.  6.  7. 10.]</span>
<span class="go">[ 4.  6.  8. 10.]</span>
<span class="go">[ 4.  6.  8. 10.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="go">[[0 0 0 0]</span>
<span class="go">[0 1 1 0]</span>
<span class="go">[2 1 2 0]</span>
<span class="go">[2 1 2 0]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.cummin">
<code class="sig-name descname">cummin</code><span class="sig-paren">(</span><em class="sig-param">axis</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.cummin"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.cummin" title="Permalink to this definition">¶</a></dt>
<dd><p>返回一个元组（最值、索引），其中最值是输入张量 <cite>x</cite> 沿维度 <cite>axis</cite> 的累积最小值，索引是每个最小值的索引位置。</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll} \\
    y{i} = min(x{1}, x{2}, ... , x{i})
\end{array}\end{split}\]</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (int) - 算子操作的维度，维度的大小范围是[-x.ndim, x.ndim - 1]。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>一个包含两个Tensor的元组，分别表示累积最小值和对应索引。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 如果 <cite>axis</cite> 不是int。</p></li>
<li><p><strong>ValueError</strong> - 如果 <cite>axis</cite> 不在范围[-x.ndim, x.ndim - 1]内。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">ops</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.2284</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6628</span><span class="p">,</span>  <span class="mf">0.0975</span><span class="p">,</span>  <span class="mf">0.2680</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3298</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4220</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">cummin</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="go">[-0.2284 -0.6628 -0.6628 -0.6628 -1.3298 -1.3298]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="go">[0 1 1 1 4 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.cumsum">
<code class="sig-name descname">cumsum</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em>, <em class="sig-param">dtype=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.cumsum"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.cumsum" title="Permalink to this definition">¶</a></dt>
<dd><p>返回指定轴方向上元素的累加值。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>如果 <cite>dtype</cite> 为 <cite>int8</cite> , <cite>int16</cite> 或 <cite>bool</cite> ，则结果 <cite>dtype</cite> 将提升为 <cite>int32</cite> ，不支持 <cite>int64</cite> 。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (int, optional) - 轴，在该轴方向上的累积和。默认情况下，计算所有元素的累加和。</p></li>
<li><p><strong>dtype</strong> (<cite>mindspore.dtype</cite> , optional) - 如果未指定参数值，则保持与原始Tensor相同，除非参数值是一个精度小于 <cite>float32</cite> 的整数。在这种情况下，使用 <cite>float32</cite> 。默认值：None。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>ValueError</strong> - 轴超出范围。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[1. 1. 1.]</span>
<span class="go">[2. 2. 2.]</span>
<span class="go">[3. 3. 3.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.diag">
<code class="sig-name descname">diag</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.diag"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.diag" title="Permalink to this definition">¶</a></dt>
<dd><p>用给定的对角线值构造对角线张量。</p>
<p>假设输入Tensor维度为 <span class="math notranslate nohighlight">\([D_1,... D_k]\)</span> ，则输出是一个rank为2k的tensor，其维度为 <span class="math notranslate nohighlight">\([D_1,..., D_k, D_1,..., D_k]\)</span> ，其中 <span class="math notranslate nohighlight">\(output[i_1,..., i_k, i_1,..., i_k] = self[i_1,..., i_k]\)</span> 并且其他位置的值为0。</p>
<p><strong>返回：</strong></p>
<p>Tensor，具有与输入Tensor相同的数据类型。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>ValueError</strong> - 输入Tensor的rank小于1。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">diag</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[1, 0, 0, 0]</span>
<span class="go">[0, 2, 0, 0]</span>
<span class="go">[0, 0, 3, 0]</span>
<span class="go">[0, 0, 0, 4]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.diagonal">
<code class="sig-name descname">diagonal</code><span class="sig-paren">(</span><em class="sig-param">offset=0</em>, <em class="sig-param">axis1=0</em>, <em class="sig-param">axis2=1</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.diagonal"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.diagonal" title="Permalink to this definition">¶</a></dt>
<dd><p>返回指定的对角线。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>offset</strong> (int, optional) - 对角线与主对角线的偏移。可以是正值或负值。默认为主对角线。</p></li>
<li><p><strong>axis1</strong> (int, optional) - 二维子数组的第一轴，对角线应该从这里开始。默认为第一轴(0)。</p></li>
<li><p><strong>axis2</strong> (int, optional) - 二维子数组的第二轴，对角线应该从这里开始。默认为第二轴。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，如果Tensor是二维，则返回值是一维数组。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>ValueError</strong> - 输入Tensor的维度少于2。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">[[0 1]</span>
<span class="go">[2 3]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[0 3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.dtype">
<em class="property">property </em><code class="sig-name descname">dtype</code><a class="headerlink" href="#mindspore.Tensor.dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>返回张量的数据类型（<a class="reference internal" href="mindspore.dtype.html#mindspore.dtype" title="mindspore.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.dtype</span></code></a>）。</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.expand_as">
<code class="sig-name descname">expand_as</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.expand_as"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.expand_as" title="Permalink to this definition">¶</a></dt>
<dd><p>将目标张量的维度扩展为输入张量的维度。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>x</strong> (Tensor) - 输入的张量。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>维度与输入张量的相同的Tensor。输出张量的维度必须遵守广播规则。广播规则指输出张量的维度需要扩展为输入张量的维度，如果目标张量的维度大于输入张量的维度，则不满足广播规则。</p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[1. 2. 3.]</span>
<span class="go">[1. 2. 3.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.expand_dims">
<code class="sig-name descname">expand_dims</code><span class="sig-paren">(</span><em class="sig-param">axis</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.expand_dims"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.expand_dims" title="Permalink to this definition">¶</a></dt>
<dd><p>沿指定轴扩展Tensor维度。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (int) - 扩展维度指定的轴。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，指定轴上扩展的维度为1。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - axis不是int类型。</p></li>
<li><p><strong>ValueError</strong> - axis的取值不在[-self.ndim - 1, self.ndim + 1)范围内。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">[[1. 1.]</span>
<span class="go">[1. 1.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(2, 2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">[[[1. 1.]</span>
<span class="go">[1. 1.]]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(1, 2, 2)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.erf">
<code class="sig-name descname">erf</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.erf"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.erf" title="Permalink to this definition">¶</a></dt>
<dd><p>逐元素计算原Tensor的高斯误差函数。
更多细节参考 <a class="reference internal" href="../ops/mindspore.ops.erf.html#mindspore.ops.erf" title="mindspore.ops.erf"><code class="xref py py-func docutils literal notranslate"><span class="pre">mindspore.ops.erf()</span></code></a>。</p>
<p><strong>返回：</strong></p>
<p>Tensor，具有与原Tensor相同的数据类型和shape。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 原Tensor的数据类型既不是float16也不是float32。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code>  <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">erf</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[-0.8427168   0.          0.8427168   0.99530876  0.99997765]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.erfc">
<code class="sig-name descname">erfc</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.erfc"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.erfc" title="Permalink to this definition">¶</a></dt>
<dd><p>逐元素计算原Tensor的互补误差函数。
更多细节参考 <a class="reference internal" href="../ops/mindspore.ops.erfc.html#mindspore.ops.erfc" title="mindspore.ops.erfc"><code class="xref py py-func docutils literal notranslate"><span class="pre">mindspore.ops.erfc()</span></code></a>。</p>
<p><strong>返回：</strong></p>
<p>Tensor，具有与原Tensor相同的数据类型和shape。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 原Tensor的数据类型既不是float16也不是float32。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code>  <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">erfc</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[1.8427168e+00 1.0000000e+00 1.5728319e-01 4.6912432e-03 2.2351742e-05]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.fill">
<code class="sig-name descname">fill</code><span class="sig-paren">(</span><em class="sig-param">value</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.fill"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.fill" title="Permalink to this definition">¶</a></dt>
<dd><p>用标量值填充数组。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>与NumPy不同，Tensor.fill()将始终返回一个新的Tensor，而不是填充原来的Tensor。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>value</strong> (Union[None, int, float, bool]) - 所有元素都被赋予这个值。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，与原来的dtype和shape相同的Tensor。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 输入参数具有前面未指定的类型。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
<span class="go">[[1. 1.]</span>
<span class="go">[1. 1.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.flatten">
<code class="sig-name descname">flatten</code><span class="sig-paren">(</span><em class="sig-param">order='C'</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.flatten"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.flatten" title="Permalink to this definition">¶</a></dt>
<dd><p>返回展开成一维的Tensor的副本。</p>
<p><strong>参数：</strong></p>
<p><strong>order</strong> (str, optional) - 可以在’C’和’F’之间进行选择。’C’表示按行优先（C风格）顺序展开。’F’表示按列优先顺序（Fortran风格）进行扁平化。仅支持’C’和’F’。默认值：’C’。</p>
<p><strong>返回：</strong></p>
<p>Tensor，具有与输入相同的数据类型。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>order</cite> 不是字符串类型。</p></li>
<li><p><strong>ValueError</strong> - <cite>order</cite> 是字符串类型，但不是’C’或’F’。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(24,)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.flush_from_cache">
<code class="sig-name descname">flush_from_cache</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.flush_from_cache"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.flush_from_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>如果Tensor开启缓存作用，则将缓存数据刷新到host侧。</p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flush_from_cache</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">None</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.from_numpy">
<em class="property">static </em><code class="sig-name descname">from_numpy</code><span class="sig-paren">(</span><em class="sig-param">array</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.from_numpy"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.from_numpy" title="Permalink to this definition">¶</a></dt>
<dd><p>通过不复制数据的方式将Numpy数组转换为张量。</p>
<p><strong>参数：</strong></p>
<p><strong>array</strong> (numpy.array) - 输入数组。</p>
<p><strong>返回：</strong></p>
<p>与输入的张量具有相同的数据类型的Tensor。</p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[1 2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.gather_elements">
<code class="sig-name descname">gather_elements</code><span class="sig-paren">(</span><em class="sig-param">dim</em>, <em class="sig-param">index</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.gather_elements"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.gather_elements" title="Permalink to this definition">¶</a></dt>
<dd><p>获取指定轴的元素。</p>
<p>对于三维Tensor，输出为：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if dim == 0</span>

<span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if dim == 1</span>

<span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]]</span>  <span class="c1"># if dim == 2</span>
</pre></div>
</div>
<p><cite>index</cite> 与当前Tensor拥有一样的维度长度，且除 <cite>dim</cite> 维外其他维度一致。如果维度 <cite>dim</cite> 为i，当前Tensor是shape为 <span class="math notranslate nohighlight">\((z_0, z_1, ..., z_i, ..., z_{n-1})\)</span> 的n维Tensor，则 <cite>index</cite> 必须是shape为 <span class="math notranslate nohighlight">\((z_0, z_1, ..., y, ..., z_{n-1})\)</span> 的n维Tensor，其中 <cite>y</cite> 大于等于1。输出的shape与 <cite>index</cite> 相同。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>dim</strong> (int) - 获取元素的轴。数据类型为int32或int64。取值范围为[-self.ndim, self.ndim)。</p></li>
<li><p><strong>index</strong> (Tensor) - 获取收集元素的索引。支持的数据类型包括：int32，int64。每个索引元素的取值范围为[-self.shape(dim), self.shape(dim))。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，shape与 <cite>index</cite> 相同，即其shape为 <span class="math notranslate nohighlight">\((z_0, z_1, ..., y, ..., z_{n-1})\)</span>，数据类型与 <cite>self.dtype</cite> 相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>dim</cite> 或 <cite>index</cite> 的数据类型既不是int32，也不是int64。</p></li>
<li><p><strong>ValueError</strong> - <cite>self</cite> 和 <cite>index</cite> 的维度长度不一致。</p></li>
<li><p><strong>ValueError</strong> - <cite>self</cite> 和 <cite>index</cite> 除 <cite>dim</cite> 维外的维度不一致。</p></li>
<li><p><strong>ValueError</strong> - <cite>dim</cite> 的值不在合理范围内。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">index</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">gather_elements</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[1 1]</span>
<span class="go">[4 3]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.gather_nd">
<code class="sig-name descname">gather_nd</code><span class="sig-paren">(</span><em class="sig-param">indices</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.gather_nd"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.gather_nd" title="Permalink to this definition">¶</a></dt>
<dd><p>按索引从输入Tensor中获取切片。
使用给定的索引从具有指定形状的输入Tensor中搜集切片。
输入Tensor的shape是 <span class="math notranslate nohighlight">\((N,*)\)</span> ，其中 <span class="math notranslate nohighlight">\(*\)</span> 表示任意数量的附加维度。下文中的 <cite>input_x</cite> 代指输入Tensor本身。
<cite>indices</cite> 是一个K维的整数张量，假定它的K-1维张量中的每一个元素是输入Tensor的切片，那么有：</p>
<div class="math notranslate nohighlight">
\[output[(i_0, ..., i_{K-2})] = input\_x[indices[(i_0, ..., i_{K-2})]]\]</div>
<p><cite>indices</cite> 的最后一维不能超过输入Tensor的秩：
<span class="math notranslate nohighlight">\(indices.shape[-1] &lt;= input\_x.rank\)</span>。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>indices</strong> (Tensor) - 获取收集元素的索引张量，其数据类型包括：int32，int64。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，具有与输入Tensor相同的数据类型，shape维度为 <span class="math notranslate nohighlight">\(indices\_shape[:-1] + input\_x\_shape[indices\_shape[-1]:]\)</span>。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>ValueError</strong> - 如果输入Tensor的shape长度小于 <cite>indices</cite> 的最后一个维度。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[-0.1  0.5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.gather">
<code class="sig-name descname">gather</code><span class="sig-paren">(</span><em class="sig-param">input_indices</em>, <em class="sig-param">axis</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.gather"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.gather" title="Permalink to this definition">¶</a></dt>
<dd><p>返回指定 <cite>axis</cite> 上 <cite>input_indices</cite> 的元素对应的输入Tensor切片。为了方便描述，对于输入Tensor记为 <cite>input_params</cite>。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ol class="arabic simple">
<li><p>input_indices 的值必须在 <cite>[0, input_params.shape[axis])</cite> 的范围内，结果未定义超出范围。</p></li>
<li><p>当前在Ascend平台，input_params的值不能是 <a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/mindspore/mindspore.dtype.html#mindspore.dtype">bool_</a> 类型。</p></li>
</ol>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>input_indices</strong> (Tensor) - 待切片的索引张量，其形状为 <span class="math notranslate nohighlight">\((y_1, y_2, ..., y_S)\)</span>，代表指定原始张量元素的索引，其数据类型包括：int32，int64。</p></li>
<li><p><strong>axis</strong> (int) - 指定维度索引的轴以搜集切片。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor,其中shape维度为 <span class="math notranslate nohighlight">\(input\_params.shape[:axis] + input\_indices.shape + input\_params.shape[axis + 1:]\)</span>。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 如果 <cite>axis</cite> 不是一个整数。</p></li>
<li><p><strong>TypeError</strong> - 如果 <cite>input_indices</cite> 不是一个整数类型的Tensor。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># case1: input_indices is a Tensor with shape (5, ).</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_params</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_params</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">input_indices</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[1. 3. 5. 3. 7.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># case2: input_indices is a Tensor with shape (2, 2). When the input_params has one dimension,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># the output shape is equal to the input_indices shape.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_params</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">input_indices</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[ 1. 3.]</span>
<span class="go">[ 3. 7.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># case3: input_indices is a Tensor with shape (2, ) and</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># input_params is a Tensor with shape (3, 4) and axis is 0.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_params</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_params</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">input_indices</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[1.  2.  3.  4.]</span>
<span class="go">[9. 10. 11. 12.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># case4: input_indices is a Tensor with shape (2, ) and</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># input_params is a Tensor with shape (3, 4) and axis is 1.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_params</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_params</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">input_indices</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[1.  3.]</span>
<span class="go">[5.  7.]</span>
<span class="go">[9. 11.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.ger">
<code class="sig-name descname">ger</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.ger"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.ger" title="Permalink to this definition">¶</a></dt>
<dd><p>计算两个Tensor的外积，即计算此Tensor 和 <cite>x</cite> 的外积。如果此Tensor shape为 <span class="math notranslate nohighlight">\((m,)\)</span> ，<cite>x</cite> shape为 <span class="math notranslate nohighlight">\((n,)\)</span> ，
那么输出就是一个shape为 <span class="math notranslate nohighlight">\((m, n)\)</span> 的Tensor。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Ascend平台暂不支持float64数据格式的输入。</p>
</div>
<p>更多参考详见 <a class="reference internal" href="../ops/mindspore.ops.ger.html#mindspore.ops.ger" title="mindspore.ops.ger"><code class="xref py py-func docutils literal notranslate"><span class="pre">mindspore.ops.ger()</span></code></a>。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>x</strong> (Tensor) - 输入Tensor，数据类型为float16、float32或者float64。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，是一个与此Tensor相同数据类型的输出矩阵。当此Tensor shape为 <span class="math notranslate nohighlight">\((m,)\)</span> ， <cite>x</cite> shape为 <span class="math notranslate nohighlight">\((n,)\)</span> ，
那么输出shape为 <span class="math notranslate nohighlight">\((m, n)\)</span> 。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x1</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x2</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x1</span><span class="o">.</span><span class="n">ger</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[ 1.  2.  3.]</span>
<span class="go">[ 2.  4.  6.]</span>
<span class="go">[ 3.  6.  9.]</span>
<span class="go">[ 4.  8. 12.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.hardshrink">
<code class="sig-name descname">hardshrink</code><span class="sig-paren">(</span><em class="sig-param">lambd=0.5</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.hardshrink"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.hardshrink" title="Permalink to this definition">¶</a></dt>
<dd><p>Hard Shrink激活函数，按输入元素计算输出，公式定义如下：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\text{HardShrink}(x) =
\begin{cases}
x, &amp; \text{ if } x &gt; \lambda \\
x, &amp; \text{ if } x &lt; -\lambda \\
0, &amp; \text{ otherwise }
\end{cases}\end{split}\]</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>lambd</strong> (float) - Hard Shrink公式定义的阈值 <span class="math notranslate nohighlight">\(\lambda\)</span> 。默认值：0.5。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，shape和数据类型与输入相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>lambd</cite> 不是float。</p></li>
<li><p><strong>TypeError</strong> - 原始Tensor的dtype既不是float16也不是float32。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0533</span><span class="p">,</span> <span class="mf">0.0776</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.1233</span><span class="p">]]),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">hardshrink</span><span class="p">())</span>
<span class="go">[[ 0.      1.      2.    ]</span>
<span class="go">[ 0.      0.     -2.1233]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.has_init">
<em class="property">property </em><code class="sig-name descname">has_init</code><a class="headerlink" href="#mindspore.Tensor.has_init" title="Permalink to this definition">¶</a></dt>
<dd><p>Tensor是否已经初始化。</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.index_fill">
<code class="sig-name descname">index_fill</code><span class="sig-paren">(</span><em class="sig-param">dim</em>, <em class="sig-param">index</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.index_fill"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.index_fill" title="Permalink to this definition">¶</a></dt>
<dd><p>按 <cite>index</cite> 中给定的顺序选择索引，将输入 <cite>value</cite> 值填充到当前Tensor的所有 <cite>dim</cite> 维元素。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>dim</strong> (Union[int, Tensor]) - 填充输入Tensor的维度，要求是一个int或者数据类型为int32或int64的0维Tensor。</p></li>
<li><p><strong>index</strong> (Tensor) - 填充输入Tensor的索引，数据类型为int32。</p></li>
<li><p><strong>value</strong> (Union[bool, int, float, Tensor]) - 填充输入Tensor的值。如果 <cite>value</cite> 是Tensor，那么 <cite>value</cite> 要求是数据类型与当前Tensor相同的0维Tensor。否则，该值会自动转化为一个数据类型与当前Tensor相同的0维Tensor。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>填充后的Tensor。shape和数据类型与当前Tensor相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>dim</cite> 的类型不是int或者Tensor。</p></li>
<li><p><strong>TypeError</strong> - 当 <cite>dim</cite> 是Tensor时， <cite>dim</cite> 的数据类型不是int32或者int64。</p></li>
<li><p><strong>TypeError</strong> - <cite>index</cite> 的类型不是Tensor。</p></li>
<li><p><strong>TypeError</strong> - <cite>index</cite> 的数据类型不是int32。</p></li>
<li><p><strong>TypeError</strong> - <cite>value</cite> 的类型不是bool、int、float或者Tensor。</p></li>
<li><p><strong>TypeError</strong> - 当 <cite>value</cite> 是Tensor时， <cite>value</cite> 的数据类型和当前Tensor的数据类型不相同。</p></li>
<li><p><strong>ValueError</strong> - 当 <cite>dim</cite> 是Tensor时， <cite>dim</cite> 的维度不等于0。</p></li>
<li><p><strong>ValueError</strong> - <cite>index</cite> 的维度大于1。</p></li>
<li><p><strong>ValueError</strong> - 当 <cite>value</cite> 是Tensor时， <cite>value</cite> 的维度不等于0。</p></li>
<li><p><strong>RuntimeError</strong> - <cite>dim</cite> 值超出范围[-self.ndim, self.ndim - 1]。</p></li>
<li><p><strong>RuntimeError</strong> - <cite>index</cite> 存在值超出范围[-self.shape[dim], self.shape[dim]-1]。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">index</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">index_fill</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">[[-2. 2. -2.]</span>
<span class="go">[-2. 5. -2.]</span>
<span class="go">[-2. 8. -2.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.init_data">
<code class="sig-name descname">init_data</code><span class="sig-paren">(</span><em class="sig-param">slice_index=None</em>, <em class="sig-param">shape=None</em>, <em class="sig-param">opt_shard_group=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.init_data"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.init_data" title="Permalink to this definition">¶</a></dt>
<dd><p>获取此Tensor的数据。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>对于同一个Tensor，只可以调用一次 <cite>init_data</cite> 函数。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>slice_index</strong> (int) - 参数切片的索引。在初始化参数切片的时候使用，保证使用相同切片的设备可以生成相同的Tensor。默认值：None。</p></li>
<li><p><strong>shape</strong> (list[int]) - 切片的shape，在初始化参数切片时使用。默认值：None。</p></li>
<li><p><strong>opt_shard_group</strong> (str) - 优化器分片组，在自动或半自动并行模式下用于获取参数的切片。默认值：None。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>初始化的Tensor。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">Constant</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">initializer</span><span class="p">(</span><span class="n">Constant</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">init_data</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">[[1. 1.]</span>
<span class="go">[1. 1.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.soft_shrink">
<code class="sig-name descname">soft_shrink</code><span class="sig-paren">(</span><em class="sig-param">lambd=0.5</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.soft_shrink"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.soft_shrink" title="Permalink to this definition">¶</a></dt>
<dd><p>Soft Shrink激活函数，按输入元素计算输出，公式定义如下：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\text{SoftShrink}(x) =
\begin{cases}
x - \lambda, &amp; \text{ if } x &gt; \lambda \\
x + \lambda, &amp; \text{ if } x &lt; -\lambda \\
0, &amp; \text{ otherwise }
\end{cases}\end{split}\]</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>lambd</strong> (float) - <span class="math notranslate nohighlight">\(\lambda\)</span> 应大于等于0。默认值：0.5。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，shape和数据类型与输入相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>lambd</cite> 不是float。</p></li>
<li><p><strong>TypeError</strong> - <cite>x</cite> 不是Tensor。</p></li>
<li><p><strong>TypeError</strong> - 原始Tensor的dtype既不是float16也不是float32。</p></li>
<li><p><strong>ValueError</strong> - <cite>lambd</cite> 小于0。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span> <span class="mf">0.5297</span><span class="p">,</span>  <span class="mf">0.7871</span><span class="p">,</span>  <span class="mf">1.1754</span><span class="p">],</span> <span class="p">[</span> <span class="mf">0.7836</span><span class="p">,</span>  <span class="mf">0.6218</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1542</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">soft_shrink</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[ 0.02979  0.287    0.676  ]</span>
<span class="go">[ 0.2837   0.1216  -0.6543 ]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.inplace_update">
<code class="sig-name descname">inplace_update</code><span class="sig-paren">(</span><em class="sig-param">v</em>, <em class="sig-param">indices</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.inplace_update"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.inplace_update" title="Permalink to this definition">¶</a></dt>
<dd><p>根据 <cite>indices</cite> 以 <cite>v</cite> 来更新Tensor中的值。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><cite>indices</cite> 只能沿着最高轴进行索引。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>v</strong> (Tensor) - 用来更新的值。</p></li>
<li><p><strong>indices</strong> (Union[int, tuple]) - 待更新值在原Tensor中的索引。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，更新后的Tensor。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>indices</cite> 不是int或tuple。</p></li>
<li><p><strong>TypeError</strong> - <cite>indices</cite> 是元组，但是其中的元素不是int。</p></li>
<li><p><strong>ValueError</strong> - Tensor的shape与 <cite>v</cite> 的shape不同。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">inplace_update</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[0.1 0.2]</span>
<span class="go">[0.3 0.4]</span>
<span class="go">[5.  6. ]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.isclose">
<code class="sig-name descname">isclose</code><span class="sig-paren">(</span><em class="sig-param">x2</em>, <em class="sig-param">rtol=1e-05</em>, <em class="sig-param">atol=1e-08</em>, <em class="sig-param">equal_nan=False</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.isclose"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.isclose" title="Permalink to this definition">¶</a></dt>
<dd><p>返回一个布尔型Tensor，表示当前Tensor与 <cite>x2</cite> 的对应元素的差异是否在容忍度内相等。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>x2</strong> (Tensor) - 对比的第二个输入，支持的类型有float32，float16，int32。</p></li>
<li><p><strong>rtol</strong> (float, optional) - 相对容忍度。默认值：1e-05。</p></li>
<li><p><strong>atol</strong> (float, optional) - 绝对容忍度。默认值：1e-08。</p></li>
<li><p><strong>equal_nan</strong> (bool, optional) - IsNan的输入，任意维度的Tensor。默认值：False。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，shape与广播后的shape相同，数据类型是布尔型。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 当前Tensor和 <cite>x2</cite> 中的任何一个不是Tensor。</p></li>
<li><p><strong>TypeError</strong> - 当前Tensor和 <cite>x2</cite> 的数据类型不是float16、float32或int32之一。</p></li>
<li><p><strong>TypeError</strong> - <cite>atol</cite> 和 <cite>rtol</cite> 中的任何一个不是float。</p></li>
<li><p><strong>TypeError</strong> - <cite>equal_nan</cite>  不是bool。</p></li>
<li><p><strong>TypeError</strong> - 当前Tensor和 <cite>x2</cite> 的数据类型不同。</p></li>
<li><p><strong>ValueError</strong> - 当前Tensor和 <cite>x2</cite> 无法广播。</p></li>
<li><p><strong>ValueError</strong> - <cite>atol</cite> 和 <cite>rtol</cite> 中的任何一个小于零。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.3</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">,</span> <span class="mf">4.1</span><span class="p">,</span> <span class="mf">5.1</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">other</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.3</span><span class="p">,</span> <span class="mf">3.3</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">,</span> <span class="mf">5.1</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[ True False False False  True]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.isfinite">
<code class="sig-name descname">isfinite</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.isfinite"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.isfinite" title="Permalink to this definition">¶</a></dt>
<dd><p>判断输入数据每个位置上的值是否是有限数。</p>
<p><strong>返回：</strong></p>
<p>Tensor，输出的shape与输入相同，数据类型为bool。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 如果当前Tensor不是Tensor。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">0</span><span class="p">)]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">isfinite</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[False True False]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.item">
<code class="sig-name descname">item</code><span class="sig-paren">(</span><em class="sig-param">index=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.item"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.item" title="Permalink to this definition">¶</a></dt>
<dd><p>获取Tensor中指定索引的元素。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Tensor.item返回的是Tensor标量，而不是Python标量。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>index</strong> (Union[None, int, tuple(int)]) - Tensor的索引。默认值：None。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor标量，dtype与原始Tensor的相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>ValueError</strong> - <cite>index</cite> 的长度不等于Tensor的ndim。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">2.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.itemset">
<code class="sig-name descname">itemset</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.itemset"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.itemset" title="Permalink to this definition">¶</a></dt>
<dd><p>将标量插入到Tensor（并将标量转换为Tensor的数据类型）。</p>
<p>至少有1个参数，并且最后一个参数被定义为设定值。
Tensor.itemset(*args)等同于 <span class="math notranslate nohighlight">\(Tensor[args] = item\)</span> 。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>args</strong> (Union[(numbers.Number), (int/tuple(int), numbers.Number)]) - 指定索引和值的参数。如果 <cite>args</cite> 包含一个参数（标量），则其仅在Tensor大小为1的情况下使用。如果 <cite>args</cite> 包含两个参数，则最后一个参数是要设置的值且必须是标量，而第一个参数指定单个Tensor元素的位置。参数值是整数或者元组。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>一个新的Tensor，其值为 <span class="math notranslate nohighlight">\(Tensor[args] = item\)</span> 。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>ValueError</strong> - 第一个参数的长度不等于Tensor的ndim。</p></li>
<li><p><strong>IndexError</strong> - 只提供了一个参数，并且原来的Tensor不是标量。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">itemset</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="mi">4</span><span class="p">))</span>
<span class="go">[[1. 4. 3.]</span>
<span class="go">[4. 5. 6.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">[[1. 2. 3.]</span>
<span class="go">[4. 5. 6.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.itemsize">
<em class="property">property </em><code class="sig-name descname">itemsize</code><a class="headerlink" href="#mindspore.Tensor.itemsize" title="Permalink to this definition">¶</a></dt>
<dd><p>返回一个Tensor元素的长度（以字节为单位）。</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.lerp">
<code class="sig-name descname">lerp</code><span class="sig-paren">(</span><em class="sig-param">end</em>, <em class="sig-param">weight</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.lerp"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.lerp" title="Permalink to this definition">¶</a></dt>
<dd><p>基于某个浮点数Scalar或权重Tensor的值， 计算当前Tensor和 <cite>end</cite> Tensor之间的线性插值。</p>
<p>如果参数 <cite>weight</cite> 是一个Tensor，那么另两个输入的维度信息可以被广播到当前Tensor。
如果参数 <cite>weight</cite> 是一个Scalar， 那么 <cite>end</cite> 的维度信息可以被广播到当前Tensor。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>end</strong> (Tensor) - 进行线性插值的Tensor结束点，其数据类型必须为float16或者float32。</p></li>
<li><p><strong>weight</strong> (Union[float, Tensor]) - 线性插值公式的权重参数。当为Scalar时，其数据类型为float，当为Tensor时，其数据类型为float16或者float32。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>返回新的Tensor，其数据类型和维度必须和输入中的当前Tensor保持一致。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 如果 <cite>end</cite> 不是Tensor。</p></li>
<li><p><strong>TypeError</strong> - 如果 <cite>weight</cite> 不是float类型Scalar或者Tensor。</p></li>
<li><p><strong>TypeError</strong> - 如果 <cite>end</cite> 的数据类型不是float16或者float32。</p></li>
<li><p><strong>TypeError</strong> - 如果 <cite>weight</cite> 为Tensor且 <cite>weight</cite> 不是float16或者float32。</p></li>
<li><p><strong>TypeError</strong> - 如果当前Tensor和 <cite>end</cite> 的数据类型不一致。</p></li>
<li><p><strong>TypeError</strong> - 如果 <cite>weight</cite> 为Tensor且 <cite>end</cite> 、 <cite>weight</cite> 和当前Tensor数据类型不一致。</p></li>
<li><p><strong>ValueError</strong> - 如果 <cite>end</cite> 的维度信息无法相互广播到当前Tensor。</p></li>
<li><p><strong>ValueError</strong> - 如果 <cite>weight</cite> 为Tensor且 <cite>weight</cite> 的维度信息无法广播到当前Tensor。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">start</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">end</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">start</span><span class="o">.</span><span class="n">lerp</span><span class="p">(</span> <span class="n">end</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[5.5 6. 6.5 7. ]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.log1p">
<code class="sig-name descname">log1p</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.log1p"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.log1p" title="Permalink to this definition">¶</a></dt>
<dd><p>对当前Tensor逐元素加一后计算自然对数。</p>
<div class="math notranslate nohighlight">
\[out_i = {log_e}(x_i + 1)\]</div>
<p><strong>返回：</strong></p>
<p>Tensor，与 <cite>x</cite> 的shape相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>x</cite> 不是Tensor。</p></li>
<li><p><strong>TypeError</strong> - <cite>x</cite> 的数据类型非float16或float32。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">log1p</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[0.6931472 1.0986123 1.609438 ]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.norm">
<code class="sig-name descname">norm</code><span class="sig-paren">(</span><em class="sig-param">axis</em>, <em class="sig-param">p=2</em>, <em class="sig-param">keep_dims=False</em>, <em class="sig-param">epsilon=1e-12</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.norm"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.norm" title="Permalink to this definition">¶</a></dt>
<dd><p>返回给定Tensor的矩阵范数或向量范数。</p>
<div class="math notranslate nohighlight">
\[output = sum(abs(input)**p)**(1/p)\]</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (Union[int, list, tuple]) - 指定要计算范数的输入维度。</p></li>
<li><p><strong>p</strong> (int) - 范数的值。默认值：2。 <cite>p</cite> 大于等于0。</p></li>
<li><p><strong>keep_dims</strong> (bool) - 输出Tensor是否保留原有的维度。默认值：False。</p></li>
<li><p><strong>epsilon</strong> (float) - 用于保持数据稳定性的常量。默认值：1e-12。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，其数据类型与当前Tensor相同，其维度信息取决于 <cite>axis</cite> 轴以及参数 <cite>keep_dims</cite> 。例如如果输入的大小为 <cite>(2,3,4)</cite> 轴为 <cite>[0,1]</cite> ，输出的维度为 <cite>(4，)</cite> 。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 当前Tensor的数据类型不是float16或者float32。</p></li>
<li><p><strong>TypeError</strong> - <cite>axis</cite> 不是int，tuple或者list。</p></li>
<li><p><strong>TypeError</strong> - <cite>p</cite> 不是int。</p></li>
<li><p><strong>TypeError</strong> - <cite>axis</cite> 是tuple或者list但其元素不是int。</p></li>
<li><p><strong>TypeError</strong> - <cite>keep_dims</cite> 不是bool。</p></li>
<li><p><strong>TypeError</strong> - <cite>epsilon</cite> 不是float。</p></li>
<li><p><strong>ValueError</strong> - <cite>axis</cite> 的元素超出范围 <cite>(-len(input_x.shape), len(input_x.shape))</cite> ，其中 <cite>input_x</cite> 指当前Tensor。</p></li>
<li><p><strong>ValueError</strong> - <cite>axis</cite> 的维度rank大于当前Tensor的维度rank。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]],</span> <span class="p">[[</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">norm</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[ 9.165152 10.954452]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.masked_fill">
<code class="sig-name descname">masked_fill</code><span class="sig-paren">(</span><em class="sig-param">mask</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.masked_fill"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.masked_fill" title="Permalink to this definition">¶</a></dt>
<dd><p>将掩码位置为True的位置填充指定的值。该Tensor和 <cite>mask</cite> 的shape需相同或可广播。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>mask</strong> (Tensor[bool]) - mask矩阵，值为bool类型的Tensor。</p></li>
<li><p><strong>value</strong> (Union[float, Tensor]) - 填充值，其数据类型与该Tensor相同。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，shape和dtype与该Tensor相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>mask</cite> 不是Tensor。</p></li>
<li><p><strong>TypeError</strong> - <cite>mask</cite> 的数据类型不是bool。</p></li>
<li><p><strong>ValueError</strong> - 该Tensor和 <cite>mask</cite> 的shape不可广播。</p></li>
<li><p><strong>TypeError</strong> - 该Tensor 或 <cite>value</cite> 的数据类型不是float16、float32、int8、或int32。</p></li>
<li><p><strong>TypeError</strong> - <cite>value</cite> 的数据类型与该Tensor不同。</p></li>
<li><p><strong>TypeError</strong> - <cite>value</cite> 既不是float也不是Tensor。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">[0. 1. 2. 3.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">))</span>
<span class="go">[0. 1. 0. 0.]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.masked_select">
<code class="sig-name descname">masked_select</code><span class="sig-paren">(</span><em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.masked_select"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.masked_select" title="Permalink to this definition">¶</a></dt>
<dd><p>返回一个一维张量，其中的内容是此张量中对应于 <cite>mask</cite> 张量中True位置的值。<cite>mask</cite> 张量的shape与此张量的shape不需要一样，但必须符合广播规则。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>mask</strong> (Tensor[bool]) - 值为bool类型的张量。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>一个一维张量，类型与此张量相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>mask</cite> 不是bool类型的Tensor。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[1 3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.inv">
<code class="sig-name descname">inv</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.inv"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.inv" title="Permalink to this definition">¶</a></dt>
<dd><p>计算当前Tensor的倒数。</p>
<div class="math notranslate nohighlight">
\[out_i = \frac{1}{x_{i} }\]</div>
<p>其中 <cite>x</cite> 表示当前Tensor。</p>
<p><strong>返回：</strong></p>
<p>Tensor，shape和类型与当前Tensor相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 当前Tensor的数据类型不为float16、float32或int32。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.31</span><span class="p">,</span> <span class="mf">0.52</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">inv</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[4.        2.5       3.2258065 1.923077 ]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.invert">
<code class="sig-name descname">invert</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.invert"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.invert" title="Permalink to this definition">¶</a></dt>
<dd><p>按位翻转当前Tensor。</p>
<div class="math notranslate nohighlight">
\[out_i = \sim x_{i}\]</div>
<p>其中 <cite>x</cite> 表示当前Tensor。</p>
<p><strong>返回：</strong></p>
<p>Tensor，shape和类型与当前Tensor相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 当前Tensor的数据类型不为int16或uint16。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">25</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">9</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">invert</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[-26 -5 -14 -10]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.max">
<code class="sig-name descname">max</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em>, <em class="sig-param">keepdims=False</em>, <em class="sig-param">initial=None</em>, <em class="sig-param">where=True</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.max"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.max" title="Permalink to this definition">¶</a></dt>
<dd><p>返回Tensor的最大值或轴方向上的最大值。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (Union[None, int, list, tuple of ints], optional) - 轴，在该轴方向上进行操作。默认情况下，使用扁平输入。如果该参数为整数元组，则在多个轴上选择最大值，而不是在单个轴或所有轴上进行选择。默认值：None。</p></li>
<li><p><strong>keepdims</strong> (bool, optional) - 如果这个参数为True，被删去的维度保留在结果中，且维度大小设为1。有了这个选项，结果就可以与输入数组进行正确的广播运算。默认值：False。</p></li>
<li><p><strong>initial</strong> (scalar, optional) - 输出元素的最小值。如果对空切片进行计算，则该参数必须设置。默认值：None。</p></li>
<li><p><strong>where</strong> (bool Tensor, optional) - 一个bool数组，被广播以匹配数组维度和选择包含在降维中的元素。如果传递了一个非默认值，则还必须提供初始值。默认值：True。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor或标量，输入Tensor的最大值。如果 <cite>axis</cite> 为None，则结果是一个标量值。如果提供了 <cite>axis</cite> ，则结果是Tensor ndim - 1维度的一个数组。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 参数具有前面未指定的类型。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">3.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.mean">
<code class="sig-name descname">mean</code><span class="sig-paren">(</span><em class="sig-param">axis=()</em>, <em class="sig-param">keep_dims=False</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.mean"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.mean" title="Permalink to this definition">¶</a></dt>
<dd><p>返回指定维度上所有元素的均值，并降维。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (Union[None, int, tuple(int), list(int)]) - 要减少的维度。默认值: ()，缩小所有维度。当 <cite>axis</cite> 为int、tuple(int)或list(int)时，记Tensor的维度为dim，则其取值范围为[-dim, dim)。</p></li>
<li><p><strong>keep_dims</strong> (bool) - 计算结果是否保留维度。默认值：False。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>与输入的张量具有相同的数据类型的Tensor。</p>
<ul class="simple">
<li><p>如果 <cite>axis</cite> 为()，且 <cite>keep_dims</cite> 为False，则输出一个0维Tensor，表示输入Tensor中所有元素的均值。</p></li>
<li><p>如果 <cite>axis</cite> 为int，取值为1，并且 <cite>keep_dims</cite> 为False，则输出的shape为 <span class="math notranslate nohighlight">\((x_0, x_2, ..., x_R)\)</span> 。</p></li>
<li><p>如果 <cite>axis</cite> 为tuple(int)或list(int)，取值为(1, 2)，并且 <cite>keep_dims</cite> 为False，则输出Tensor的shape为 <span class="math notranslate nohighlight">\((x_0, x_3, ..., x_R)\)</span> 。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 如果 <cite>axis</cite> 不是以下数据类型之一：int、tuple 或 list。</p></li>
<li><p><strong>TypeError</strong> - 如果 <cite>keep_dims</cite> 不是bool类型。</p></li>
<li><p><strong>ValueError</strong> - 如果 <cite>axis</cite> 超出范围。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">2.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.amin">
<code class="sig-name descname">amin</code><span class="sig-paren">(</span><em class="sig-param">axis=()</em>, <em class="sig-param">keep_dims=False</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.amin"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.amin" title="Permalink to this definition">¶</a></dt>
<dd><p>默认情况下，使用指定维度的最小值代替该维度的其他元素，以移除该维度。也可仅缩小该维度大小至1。 <cite>keep_dims</cite> 控制输出和输入的维度是否相同。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (Union[None, int, tuple(int), list(int)]) - 要减少的维度。默认值: ()，缩小所有维度。只允许常量值。当 <cite>axis</cite> 为int、tuple(int)或list(int)时，记Tensor的维度为dim，则其取值范围为[-dim, dim)。</p></li>
<li><p><strong>keep_dims</strong> (bool) - 如果为True，则保留缩小的维度，大小为1。否则移除维度。默认值：False。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>与输入的张量具有相同的数据类型的Tensor。</p>
<ul class="simple">
<li><p>如果 <cite>axis</cite> 为()，且 <cite>keep_dims</cite> 为False，则输出一个0维Tensor，表示输入Tensor中所有元素的最小值。</p></li>
<li><p>如果 <cite>axis</cite> 为int，取值为1，并且 <cite>keep_dims</cite> 为False，则输出的shape为 <span class="math notranslate nohighlight">\((x_0, x_2, ..., x_R)\)</span> 。</p></li>
<li><p>如果 <cite>axis</cite> 为tuple(int)或list(int)，取值为(1, 2)，并且 <cite>keep_dims</cite> 为False，则输出Tensor的shape为 <span class="math notranslate nohighlight">\((x_0, x_3, ..., x_R)\)</span> 。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 如果 <cite>axis</cite> 不是以下数据类型之一：int、tuple 或 list。</p></li>
<li><p><strong>TypeError</strong> - 如果 <cite>keep_dims</cite> 不是bool类型。</p></li>
<li><p><strong>ValueError</strong> - 如果 <cite>axis</cite> 超出范围。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">amin</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">1.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.amax">
<code class="sig-name descname">amax</code><span class="sig-paren">(</span><em class="sig-param">axis=()</em>, <em class="sig-param">keep_dims=False</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.amax"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.amax" title="Permalink to this definition">¶</a></dt>
<dd><p>默认情况下，使用指定维度的最大值代替该维度的其他元素，以移除该维度。也可仅缩小该维度大小至1。 <cite>keep_dims</cite> 控制输出和输入的维度是否相同。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (Union[None, int, tuple(int), list(int)]) - 要减少的维度。默认值: ()，缩小所有维度。只允许常量值。当 <cite>axis</cite> 为int、tuple(int)或list(int)时，记Tensor的维度为dim，则其取值范围为[-dim, dim)。</p></li>
<li><p><strong>keep_dims</strong> (bool) - 如果为True，则保留缩小的维度，大小为1。否则移除维度。默认值：False。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>与输入的张量具有相同的数据类型的Tensor。</p>
<ul class="simple">
<li><p>如果 <cite>axis</cite> 为()，且 <cite>keep_dims</cite> 为False，则输出一个0维Tensor，表示输入Tensor中所有元素的最大值。</p></li>
<li><p>如果 <cite>axis</cite> 为int，取值为1，并且 <cite>keep_dims</cite> 为False，则输出的shape为 <span class="math notranslate nohighlight">\((x_0, x_2, ..., x_R)\)</span> 。</p></li>
<li><p>如果 <cite>axis</cite> 为tuple(int)或list(int)，取值为(1, 2)，并且 <cite>keep_dims</cite> 为False，则输出Tensor的shape为 <span class="math notranslate nohighlight">\((x_0, x_3, ..., x_R)\)</span> 。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 如果 <cite>axis</cite> 不是以下数据类型之一：int、tuple 或 list。</p></li>
<li><p><strong>TypeError</strong> - 如果 <cite>keep_dims</cite> 不是bool类型。</p></li>
<li><p><strong>ValueError</strong> - 如果 <cite>axis</cite> 超出范围。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">amax</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">3.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.prod">
<code class="sig-name descname">prod</code><span class="sig-paren">(</span><em class="sig-param">axis=()</em>, <em class="sig-param">keep_dims=False</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.prod"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.prod" title="Permalink to this definition">¶</a></dt>
<dd><p>默认情况下，通过将维度中的所有元素相乘来减少张量的维度。并且还可以沿轴减小“x”的维度。通过控制 <cite>keep_dims</cite> 判断输出和输入的维度是否相同。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (Union[None, int, tuple(int), list(int)]) - 计算prod的维度。当 <cite>axis</cite> 为None或空元组时，计算所有维度。当 <cite>axis</cite> 为int、tuple(int)或list(int)时，记Tensor的维度为dim，则其取值范围为[-dim, dim)。默认值：()。</p></li>
<li><p><strong>keep_dims</strong> (bool) - 计算结果是否保留维度。默认值：False。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>与输入的张量具有相同的数据类型的Tensor。</p>
<ul class="simple">
<li><p>如果 <cite>axis</cite> 为()，且 <cite>keep_dims</cite> 为False，则输出一个0维Tensor，表示输入Tensor中所有元素的乘积。</p></li>
<li><p>如果 <cite>axis</cite> 为int，取值为1，并且 <cite>keep_dims</cite> 为False，则输出的shape为 <span class="math notranslate nohighlight">\((x_0, x_2, ..., x_R)\)</span> 。</p></li>
<li><p>如果 <cite>axis</cite> 为tuple(int)或list(int)，取值为(1, 2)，并且 <cite>keep_dims</cite> 为False，则输出Tensor的shape为 <span class="math notranslate nohighlight">\((x_0, x_3, ..., x_R)\)</span> 。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 如果 <cite>axis</cite> 不是以下数据类型之一：int、tuple 或 list。</p></li>
<li><p><strong>TypeError</strong> - 如果 <cite>keep_dims</cite> 不是bool类型。</p></li>
<li><p><strong>ValueError</strong> - 如果 <cite>axis</cite> 超出范围。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">6.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.min">
<code class="sig-name descname">min</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em>, <em class="sig-param">keepdims=False</em>, <em class="sig-param">initial=None</em>, <em class="sig-param">where=True</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.min"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.min" title="Permalink to this definition">¶</a></dt>
<dd><p>返回Tensor的最小值或轴方向上的最小值。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (Union[None, int, list, tuple of ints], optional) - 轴，在该轴方向上进行操作。默认情况下，使用扁平输入。如果该参数为整数元组，则在多个轴上选择最小值，而不是在单个轴或所有轴上进行选择。默认值：None。</p></li>
<li><p><strong>keepdims</strong> (bool, optional) - 如果这个参数为True，被删去的维度保留在结果中，且维度大小设为1。有了这个选项，结果就可以与输入数组进行正确的广播运算。默认值：False。</p></li>
<li><p><strong>initial</strong> (scalar, optional) - 输出元素的最大值。如果对空切片进行计算，则该参数必须设置。默认值：None。</p></li>
<li><p><strong>where</strong> (bool Tensor, optional) - 一个布尔数组，被广播以匹配数组维度和选择包含在降维中的元素。如果传递了一个非默认值，则还必须提供初始值。默认值：True。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor或标量，输入Tensor的最小值。如果轴为None，则结果为一个标量值。如果提供了 <cite>axis</cite> ，则结果是Tensor.ndim - 1维度的一个数组。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 参数具有前面未指定的类型。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore.numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.narrow">
<code class="sig-name descname">narrow</code><span class="sig-paren">(</span><em class="sig-param">axis</em>, <em class="sig-param">start</em>, <em class="sig-param">length</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.narrow"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.narrow" title="Permalink to this definition">¶</a></dt>
<dd><p>沿指定轴，指定起始位置获取指定长度的Tensor。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (int) - 指定的轴。</p></li>
<li><p><strong>start</strong> (int) - 指定的起始位置。</p></li>
<li><p><strong>length</strong> (int) - 指定的长度。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - axis不是int类型。</p></li>
<li><p><strong>TypeError</strong> - start不是int类型。</p></li>
<li><p><strong>TypeError</strong> - length不是int类型。</p></li>
<li><p><strong>ValueError</strong> - axis取值不在[0, ndim-1]范围内。</p></li>
<li><p><strong>ValueError</strong> - start取值不在[0, shape[axis]-1]范围内。</p></li>
<li><p><strong>ValueError</strong> - start+length超出Tensor的维度范围shape[axis]-1。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[ 1 2 3]</span>
<span class="go">[ 4 5 6]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[ 2 3]</span>
<span class="go">[ 5 6]</span>
<span class="go">[ 8 9]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.nbytes">
<em class="property">property </em><code class="sig-name descname">nbytes</code><a class="headerlink" href="#mindspore.Tensor.nbytes" title="Permalink to this definition">¶</a></dt>
<dd><p>返回Tensor占用的总字节数。</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.ndim">
<em class="property">property </em><code class="sig-name descname">ndim</code><a class="headerlink" href="#mindspore.Tensor.ndim" title="Permalink to this definition">¶</a></dt>
<dd><p>返回Tensor维度的数量。</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.nonzero">
<code class="sig-name descname">nonzero</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.nonzero"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.nonzero" title="Permalink to this definition">¶</a></dt>
<dd><p>计算x中非零元素的下标。</p>
<p><strong>返回：</strong></p>
<p>Tensor，维度为2，类型为int64，表示输入中所有非零元素的下标。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[0 0 0]</span>
<span class="go">[0 1 0]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.pow">
<code class="sig-name descname">pow</code><span class="sig-paren">(</span><em class="sig-param">power</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.pow"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.pow" title="Permalink to this definition">¶</a></dt>
<dd><p>计算Tensor中每个元素的 <cite>power</cite> 次幂。</p>
<div class="math notranslate nohighlight">
\[out_{i} = x_{i} ^{ y_{i}}\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Tensor和 <cite>power</cite> 遵循 <a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/note/operator_list_implicit.html">隐式类型转换规则</a> ，使数据类型保持一致。</p></li>
<li><p>当前的Tensor和 <cite>power</cite> 的数据类型不能同时是bool，并保证其shape可以广播。</p></li>
</ul>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>power</strong> (Union[Tensor, number.Number, bool]) - 幂值，是一个number.Number或bool值，或数据类型为number或bool_的Tensor。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，shape与广播后的shape相同，数据类型为 <cite>Tensor</cite> 与 <cite>power</cite> 中精度较高的类型。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>power</cite> 不是Tensor、number.Number或bool。</p></li>
<li><p><strong>ValueError</strong> - 当Tensor和 <cite>power</cite> 都为Tensor时，它们的shape不相同。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="mf">3.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[ 1.  8. 64.]</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[ 1. 16. 64.]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.ptp">
<code class="sig-name descname">ptp</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em>, <em class="sig-param">keepdims=False</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.ptp"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.ptp" title="Permalink to this definition">¶</a></dt>
<dd><p>该函数名称是”peak to peak”的缩写。计算沿着axis的最大值与最小值的差值。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>不支持NumPy参数 <cite>dtype</cite> 和 <cite>out</cite> 。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (Union[None, int, tuple(int)]) - 轴，在轴方向上可以计算范围。默认计算扁平数组的方差。默认值：None。</p></li>
<li><p><strong>keepdims</strong> (bool) - 如果设为True，被删去的维度保留在结果中，且维度大小设为1。有了这个选项，结果将针对输入数组正确传递。默认值为False。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>self</cite> 不是Tensor，或者 <cite>axis</cite> 和 <cite>keepdims</cite> 具有前面未指定的类型。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ptp</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="go">[8. 6.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ptp</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="go">[2. 0. 5. 2.]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.ravel">
<code class="sig-name descname">ravel</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.ravel"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.ravel" title="Permalink to this definition">¶</a></dt>
<dd><p>返回一个展开的一维Tensor。</p>
<p><strong>返回：</strong></p>
<p>一维Tensor，含有与输入相同的元素。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(24,)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.renorm">
<code class="sig-name descname">renorm</code><span class="sig-paren">(</span><em class="sig-param">p</em>, <em class="sig-param">dim</em>, <em class="sig-param">maxnorm</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.renorm"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.renorm" title="Permalink to this definition">¶</a></dt>
<dd><p>沿维度 <cite>dim</cite> 重新规范Tensor的子张量，并且每个子张量的p范数不超过给定的最大范数 <cite>maxnorm</cite> 。 如果子张量的p范数小于 <cite>maxnorm</cite> ，则当前子张量不需要修改；否则该子张量需要修改为对应位置的原值除以该子张量的p范数，然后再乘上 <cite>maxnorm</cite> 。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>p</strong> (int) - 范数计算的幂。</p></li>
<li><p><strong>dim</strong> (int) - 获得子张量的维度。</p></li>
<li><p><strong>maxnorm</strong> (float32) - 给定的最大范数。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，shape和type与输入Tensor一致。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>p</cite> 不是int类型。</p></li>
<li><p><strong>TypeError</strong> - <cite>dim</cite> 不是int类型。</p></li>
<li><p><strong>TypeError</strong> - <cite>maxnorm</cite> 不是float32类型。</p></li>
<li><p><strong>ValueError</strong> - <cite>p</cite> 小于等于0。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">renorm</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">maxnorm</span><span class="o">=</span><span class="mf">5.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">[[1.       1.        1.        ]</span>
<span class="go">[1.6666666 1.6666666 1.6666666 ]</span>
<span class="go">[1.6666667 1.6666667 1.6666667 ]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.repeat">
<code class="sig-name descname">repeat</code><span class="sig-paren">(</span><em class="sig-param">repeats</em>, <em class="sig-param">axis=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.repeat"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.repeat" title="Permalink to this definition">¶</a></dt>
<dd><p>对数组中的元素进行重复复制。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>repeats</strong> (Union[int, tuple, list]) - 每个元素的重复次数，<cite>repeats</cite> 被广播以适应指定轴的shape。</p></li>
<li><p><strong>axis</strong> (int, optional) - 轴方向上的重复值。默认情况下，使用展开的输入Tensor，并返回一个展开的输出Tensor。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，除了维度外，与输入Tensor具有相同的shape。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>ValueError</strong> - 维度超出范围。</p></li>
<li><p><strong>TypeError</strong> - 参数类型不匹配。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
<span class="go">[3 3 3 3]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="go">[1 1 2 2 3 3 4 4]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="go">[[1 1 1 2 2 2]</span>
<span class="go">[3 3 3 4 4 4]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">repeat</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="go">[[1 2]</span>
<span class="go">[3 4]</span>
<span class="go">[3 4]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.reshape">
<code class="sig-name descname">reshape</code><span class="sig-paren">(</span><em class="sig-param">*shape</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.reshape"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.reshape" title="Permalink to this definition">¶</a></dt>
<dd><p>不改变数据的情况下，将Tensor的shape改为输入的新shape。</p>
<p><strong>参数：</strong></p>
<p><strong>shape</strong> (Union[int, tuple(int), list(int)]) - 新的shape应与原来的shape兼容。如果参数值为整数，则结果是该长度的一维数组。shape的维度可以为-1。在这种情况下，将根据数组的长度和剩下的维度计算出该值。</p>
<p><strong>返回：</strong></p>
<p>Tensor，具有新shape的Tensor。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 新shape不是整数、列表或元组。</p></li>
<li><p><strong>ValueError</strong> - 新shape与原来Tensor的shape不兼容。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mstype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[-0.1  0.3]</span>
<span class="go">[ 3.6  0.4]</span>
<span class="go">[ 0.5 -3.2]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.resize">
<code class="sig-name descname">resize</code><span class="sig-paren">(</span><em class="sig-param">*new_shape</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.resize"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.resize" title="Permalink to this definition">¶</a></dt>
<dd><p>将Tensor改为输入的新shape, 并将不足的元素补0。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>此方法不更改输入数组的大小，也不返回NumPy中的任何内容，而是返回一个具有输入大小的新Tensor。不支持Numpy参数 <cite>refcheck</cite> 。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>new_shape</strong> (Union[ints, tuple of ints]) - 指定Tensor的新shape。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">[[1. 2. 3.]</span>
<span class="go">[4. 5. 6.]</span>
<span class="go">[0. 0. 0.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">[[1. 2.]</span>
<span class="go">[3. 4.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.round">
<code class="sig-name descname">round</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.round"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.round" title="Permalink to this definition">¶</a></dt>
<dd><p>将Tensor进行四舍五入到最接近的整数数值。</p>
<p><strong>返回：</strong></p>
<p>Tensor，shape和数据类型与原Tensor相同。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.5</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[ 1.  2.  2.  2. -4.]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.select">
<code class="sig-name descname">select</code><span class="sig-paren">(</span><em class="sig-param">condition</em>, <em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.select"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.select" title="Permalink to this definition">¶</a></dt>
<dd><p>根据条件判断Tensor中的元素的值，来决定输出中的相应元素是从当前Tensor（如果元素值为True）还是从 <cite>y</cite> （如果元素值为False）中选择。</p>
<p>该算法可以被定义为：</p>
<div class="math notranslate nohighlight">
\[\begin{split}out_i = \begin{cases}
tensor_i, &amp; \text{if } condition_i \\
y_i, &amp; \text{otherwise}
\end{cases}\end{split}\]</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>condition</strong> (Tensor[bool]) - 条件Tensor，决定选择哪一个元素。shape与当前的Tensor相同。</p></li>
<li><p><strong>y</strong> (Union[Tensor, int, float]) - 如果y是一个Tensor，那么shape与当前Tensor相同。如果y是int或者float， 那么将会被转化为int32或者float32类型，并且被广播为与当前Tensor相同的shape。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，与当前Tensor的shape相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>y</cite> 不是Tensor、int或者float。</p></li>
<li><p><strong>ValueError</strong> - 输入的shape不相同。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># 1) y is Tensor</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cond</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[2. 2.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 2) y is a float</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cond</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="mf">2.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[2. 2.]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.shape">
<em class="property">property </em><code class="sig-name descname">shape</code><a class="headerlink" href="#mindspore.Tensor.shape" title="Permalink to this definition">¶</a></dt>
<dd><p>返回Tensor的shape。</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.size">
<em class="property">property </em><code class="sig-name descname">size</code><a class="headerlink" href="#mindspore.Tensor.size" title="Permalink to this definition">¶</a></dt>
<dd><p>返回Tensor中的元素总数。</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.squeeze">
<code class="sig-name descname">squeeze</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.squeeze"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.squeeze" title="Permalink to this definition">¶</a></dt>
<dd><p>从Tensor中删除shape为1的维度。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (Union[None, int, list(int), tuple(int)], optional) - 选择shape中长度为1的条目的子集。如果选择shape条目长度大于1的轴，则报错。默认值为None。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，删除了长度为1的维度的全部子集或一个子集。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 输入的参数类型有误。</p></li>
<li><p><strong>ValueError</strong> - 指定维度的shape大于1。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">[[[1. 1.]</span>
<span class="go">[1. 1.]]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(1, 2, 2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">[[1. 1.]</span>
<span class="go">[1. 1.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(2, 2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">[[1. 1.]</span>
<span class="go">[1. 1.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(2, 2)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.std">
<code class="sig-name descname">std</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em>, <em class="sig-param">ddof=0</em>, <em class="sig-param">keepdims=False</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.std"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.std" title="Permalink to this definition">¶</a></dt>
<dd><p>计算指定维度的标准差。
标准差是方差的算术平方根，如：<span class="math notranslate nohighlight">\(std = sqrt(mean(abs(x - x.mean())**2))\)</span> 。</p>
<p>返回标准差。默认情况下计算展开数组的标准差，否则在指定维度上计算。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>不支持NumPy参数 <cite>dtype</cite> 、 <cite>out</cite> 和 <cite>where</cite> 。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (Union[None, int, tuple(int)]) - 在该维度上计算标准差。默认值：<cite>None</cite> 。如果为 <cite>None</cite> ，则计算展开数组的标准偏差。</p></li>
<li><p><strong>ddof</strong> (int) - δ自由度。计算中使用的除数是 <span class="math notranslate nohighlight">\(N - ddof\)</span> ，其中 <span class="math notranslate nohighlight">\(N\)</span> 表示元素的数量。默认值：0。</p></li>
<li><p><strong>keepdims</strong> - 默认值：<cite>False</cite>。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>含有标准差数值的Tensor。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">1.118034</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.strides">
<em class="property">property </em><code class="sig-name descname">strides</code><a class="headerlink" href="#mindspore.Tensor.strides" title="Permalink to this definition">¶</a></dt>
<dd><p>Tensor上每个维度跨度的字节元组。</p>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.sum">
<code class="sig-name descname">sum</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em>, <em class="sig-param">dtype=None</em>, <em class="sig-param">keepdims=False</em>, <em class="sig-param">initial=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.sum"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.sum" title="Permalink to this definition">¶</a></dt>
<dd><p>返回指定维度上数组元素的总和。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>不支持NumPy参数 <cite>out</cite> 、 <cite>where</cite> 、 <cite>casting</cite> 、 <cite>order</cite> 、 <cite>subok</cite> 、 <cite>signature</cite> 和 <cite>extobj</cite> 。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (Union[None, int, tuple(int)]) - 指定维度，在该维度方向上进行求和运算。默认值：None。如果参数值为None，会计算输入数组中所有元素的和。如果axis为负数，则从最后一维开始往第一维计算。如果axis为整数元组，会对该元组指定的所有轴方向上的元素进行求和。</p></li>
<li><p><strong>dtype</strong> (<cite>mindspore.dtype</cite>, optional) - 默认值为None。会覆盖输出Tensor的dtype。</p></li>
<li><p><strong>keepdims</strong> (bool) - 如果这个参数为True，被删去的维度保留在结果中，且维度大小设为1。有了这个选项，结果就可以与输入数组进行正确的广播运算。如果设为默认值，那么 <cite>keepdims</cite> 不会被传递给ndarray子类的sum方法。但是任何非默认值都会被传递。如果子类的方法未实现 <cite>keepdims</cite> ，则引发异常。默认值：False。</p></li>
<li><p><strong>initial</strong> (scalar) - 初始化的起始值。默认值：None。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor。具有与输入相同shape的Tensor，删除了指定的轴。如果输入Tensor是0维数组，或axis为None时，返回一个标量。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - input不是Tensor，<cite>axis</cite> 不是整数或整数元组，<cite>keepdims</cite> 不是整数，或者 <cite>initial</cite> 不是标量。</p></li>
<li><p><strong>ValueError</strong> - 任意轴超出范围或存在重复的轴。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">input_x</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">input_x</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="go">[10. 35.]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.swapaxes">
<code class="sig-name descname">swapaxes</code><span class="sig-paren">(</span><em class="sig-param">axis1</em>, <em class="sig-param">axis2</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.swapaxes"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.swapaxes" title="Permalink to this definition">¶</a></dt>
<dd><p>交换Tensor的两个维度。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis1</strong> (int) - 第一个维度。</p></li>
<li><p><strong>axis2</strong> (int) - 第二个维度。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>转化后的Tensor，与输入具有相同的数据类型。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>axis1</cite> 或 <cite>axis2</cite> 不是整数。</p></li>
<li><p><strong>ValueError</strong> - <cite>axis1</cite> 或 <cite>axis2</cite> 不在 <cite>[-ndim, ndim-1]</cite> 范围内。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(4,3,2)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.take">
<code class="sig-name descname">take</code><span class="sig-paren">(</span><em class="sig-param">indices</em>, <em class="sig-param">axis=None</em>, <em class="sig-param">mode='clip'</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.take"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.take" title="Permalink to this definition">¶</a></dt>
<dd><p>在指定维度上获取Tensor中的元素。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>indices</strong> (Tensor) - 待提取的值的shape为 <cite>(Nj…)</cite> 的索引。</p></li>
<li><p><strong>axis</strong> (int, optional) - 在指定维度上选择值。默认情况下，使用展开的输入数组。默认值：None。</p></li>
<li><p><strong>mode</strong> (‘raise’, ‘wrap’, ‘clip’, optional)</p>
<ul>
<li><p>raise：抛出错误。</p></li>
<li><p>wrap：绕接。</p></li>
<li><p>clip：裁剪到范围。 <cite>clip</cite> 模式意味着所有过大的索引都会被在指定轴方向上指向最后一个元素的索引替换。注：这将禁用具有负数的索引。默认值：<cite>clip</cite> 。</p></li>
</ul>
</li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，索引的结果。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>ValueError</strong> - <cite>axis</cite> 超出范围，或 <cite>mode</cite> 被设置为’raise’、’wrap’和’clip’以外的值。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[4 3 6]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.tan">
<code class="sig-name descname">tan</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.tan"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.tan" title="Permalink to this definition">¶</a></dt>
<dd><p>返回每个元素的正切值。</p>
<div class="math notranslate nohighlight">
\[out_i = tan(x_i)\]</div>
<p><strong>返回：</strong></p>
<p>Tensor。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 当前输入不是Tensor。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">tan</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[-1.5574081 0. 1.5574081]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.scatter_add">
<code class="sig-name descname">scatter_add</code><span class="sig-paren">(</span><em class="sig-param">indices</em>, <em class="sig-param">updates</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.scatter_add"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.scatter_add" title="Permalink to this definition">¶</a></dt>
<dd><p>根据指定的更新值和输入索引，通过加法进行运算，将结果赋值到输出Tensor中。当同一索引有不同值时，更新的结果将是所有值的总和。此操作几乎等同于使用 <a class="reference internal" href="../ops/mindspore.ops.ScatterNdAdd.html#mindspore.ops.ScatterNdAdd" title="mindspore.ops.ScatterNdAdd"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.ScatterNdAdd</span></code></a> ，只是更新后的结果是通过算子output返回，而不是直接原地更新input。</p>
<p><cite>indices</cite> 的最后一个轴是每个索引向量的深度。对于每个索引向量， <cite>updates</cite> 中必须有相应的值。<cite>updates</cite> 的shape应该等于 <cite>input_x[indices]</cite> 的shape，其中 <cite>input_x</cite> 指当前Tensor。有关更多详细信息，请参见使用用例。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>GPU平台上，如果 <cite>indices</cite> 的某些值超出范围，则相应的 <cite>updates</cite> 不会更新到 <cite>input_x</cite> ，而不是抛出索引错误；CPU平台上直接抛出索引错误；Ascend平台不支持越界检查，若越界可能会造成未知错误。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>indices</strong> (Tensor) - Tensor的索引，数据类型为int32或int64。其rank至少为2。</p></li>
<li><p><strong>updates</strong> (Tensor) - 指定与本Tensor相加操作的Tensor，其数据类型与该Tensor相同。 <cite>updates.shape</cite> 应等于 <cite>indices.shape[:-1] + self.shape[indices.shape[-1]:]</cite> 。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，shape和数据类型与原Tensor相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>indices</cite> 的数据类型既不是int32，也不是int64。</p></li>
<li><p><strong>ValueError</strong> - Tensor的shape长度小于 <cite>indices</cite> 的shape的最后一个维度。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">updates</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">scatter_add</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[ 3.1  0.3  3.6]</span>
<span class="go">[ 0.4  0.5 -3.2]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.scatter_div">
<code class="sig-name descname">scatter_div</code><span class="sig-paren">(</span><em class="sig-param">indices</em>, <em class="sig-param">updates</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.scatter_div"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.scatter_div" title="Permalink to this definition">¶</a></dt>
<dd><p>根据索引，通过相除运算得到输出Tensor的值。更新后的结果是通过算子output返回，而不是直接原地更新当前Tensor。</p>
<p><cite>indices</cite> 的最后一个轴是每个索引向量的深度。对于每个索引向量， <cite>updates</cite> 中必须有相应的值。 <cite>updates</cite> 的shape应该等于 <cite>input_x[indices]</cite> 的shape。其中 <cite>input_x</cite> 指当前Tensor。 有关更多详细信息，请参见使用用例。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>如果 <cite>indices</cite> 的某些值超出范围，则相应的 <cite>updates</cite> 不会更新为当前Tensor，而不是抛出索引错误。</p></li>
<li><p>算子无法处理除0异常，用户需保证 <cite>updates</cite> 中没有0值。</p></li>
</ul>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>indices</strong> (Tensor) - 该Tensor的索引，数据类型为int32或int64。其rank至少为2。</p></li>
<li><p><strong>updates</strong> (Tensor) - 指定与当前Tensor相加操作的Tensor，其数据类型与输入相同。 <cite>updates.shape</cite> 应等于 <cite>indices.shape[:-1] + input_x.shape[indices.shape[-1]:]</cite> ，其中 <cite>input_x</cite> 指当前Tensor。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，shape和数据类型与该Tensor相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>indices</cite> 的数据类型不是int32，也不是int64。</p></li>
<li><p><strong>ValueError</strong> - Tensor的shape长度小于 <cite>indices</cite> 的shape的最后一个维度。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">updates</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">scatter_div</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[-0.05  0.3  3.6  ]</span>
<span class="go">[ 0.4   0.5  -3.2 ]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.scatter_min">
<code class="sig-name descname">scatter_min</code><span class="sig-paren">(</span><em class="sig-param">indices</em>, <em class="sig-param">updates</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.scatter_min"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.scatter_min" title="Permalink to this definition">¶</a></dt>
<dd><p>根据指定的更新值和输入索引，通过最小值运算，将结果赋值到输出Tensor中。</p>
<p>索引的最后一个轴是每个索引向量的深度。对于每个索引向量， <cite>updates</cite> 中必须有相应的值。 <cite>updates</cite> 的shape应该等于 <cite>input_x[indices]</cite> 的shape。有关更多详细信息，请参见下方样例。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>如果 <cite>indices</cite> 的某些值超出范围，则相应的 <cite>updates</cite> 不会更新到 <cite>input_x</cite> ，而不是抛出索引错误。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>indices</strong> (Tensor) - Tensor的索引，数据类型为int32或int64。其rank至少为2。</p></li>
<li><p><strong>updates</strong> (Tensor) - 指定与本Tensor做最小值运算的Tensor，其数据类型与该Tensor相同。 <cite>updates.shape</cite> 应等于 <cite>indices.shape[:-1] + self.shape[indices.shape[-1]:]</cite> 。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，shape和数据类型与原Tensor相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>indices</cite> 的数据类型既不是int32，也不是int64。</p></li>
<li><p><strong>ValueError</strong> - Tensor的shape长度小于 <cite>indices</cite> 的shape的最后一个维度。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">updates</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">scatter_min</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[ -0.1  0.3  3.6]</span>
<span class="go">[ 0.4  0.5 -3.2]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.scatter_max">
<code class="sig-name descname">scatter_max</code><span class="sig-paren">(</span><em class="sig-param">indices</em>, <em class="sig-param">updates</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.scatter_max"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.scatter_max" title="Permalink to this definition">¶</a></dt>
<dd><p>根据指定的更新值和输入索引，通过最大值运算，输出结果以Tensor形式返回。</p>
<p>索引的最后一个轴是每个索引向量的深度。对于每个索引向量， <cite>updates</cite> 中必须有相应的值。 <cite>updates</cite> 的shape应该等于 <cite>input_x[indices]</cite> 的shape。有关更多详细信息，请参见下方样例。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>如果 <cite>indices</cite> 的某些值超出范围，则不会更新相应的 <cite>updates</cite>，同时也不会抛出索引错误。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>indices</strong> (Tensor) - Tensor的索引，数据类型为int32或int64的。其rank必须至少为2。</p></li>
<li><p><strong>updates</strong> (Tensor) - 指定与本Tensor做最大值运算的Tensor，其数据类型与该Tensor相同。 <cite>updates.shape</cite> 应等于 <cite>indices.shape[:-1] + self.shape[indices.shape[-1]:]</cite>。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，shape和数据类型与原Tensor相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>indices</cite> 的数据类型既不是int32，也不是int64。</p></li>
<li><p><strong>ValueError</strong> - Tensor的shape长度小于 <cite>indices</cite> 的shape的最后一个维度。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">updates</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Next, demonstrate the approximate operation process of this operator:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 1, indices[0] = [0, 0], indices[1] = [0, 0]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 2, And input_x[0, 0] = -0.1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 3, So input_x[indices] = [-0.1, -0.1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 4, Satisfy the above formula: input_x[indices].shape=(2) == updates.shape=(2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">TensorScatterMax</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 5, Perform the max operation for the first time:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#      first_input_x = Max(input_x[0][0], updates[0]) = [[1.0, 0.3, 3.6], [0.4, 0.5, -3.2]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 6, Perform the max operation for the second time:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#      second_input_x = Max(input_x[0][0], updates[1]) = [[2.2, 0.3, 3.6], [0.4, 0.5, -3.2]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[ 2.2  0.3  3.6]</span>
<span class="go">[ 0.4  0.5 -3.2]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.scatter_mul">
<code class="sig-name descname">scatter_mul</code><span class="sig-paren">(</span><em class="sig-param">indices</em>, <em class="sig-param">updates</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.scatter_mul"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.scatter_mul" title="Permalink to this definition">¶</a></dt>
<dd><p>根据指定的索引，通过乘法进行计算，将结果赋值到输出Tensor中。更新后的结果是通过算子output返回，而不是直接原地更新当前Tensor。</p>
<p><cite>indices</cite> 的最后一个轴是每个索引向量的深度。对于每个索引向量， <cite>updates</cite> 中必须有相应的值。 <cite>updates</cite> 的shape应该等于 <cite>input_x[indices]</cite> 的shape。其中 <cite>input_x</cite> 指当前Tensor。 有关更多详细信息，请参见使用用例。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>如果 <cite>indices</cite> 的某些值超出范围，则相应的 <cite>updates</cite> 不会更新为当前Tensor，而不是抛出索引错误。</p></li>
</ul>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>indices</strong> (Tensor) - 该Tensor的索引，数据类型为int32或int64的。其rank必须至少为2。</p></li>
<li><p><strong>updates</strong> (Tensor) - 指定与当前Tensor相加操作的Tensor，其数据类型与输入相同。updates.shape应等于 <cite>indices.shape[:-1] + input_x.shape[indices.shape[-1]:]</cite>， 其中 <cite>input_x</cite> 代指当前Tensor本身。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，shape和数据类型与该Tensor相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>indices</cite> 的数据类型不是int32，也不是int64。</p></li>
<li><p><strong>ValueError</strong> - Tensor的shape长度小于 <cite>indices</cite> 的shape的最后一个维度。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">updates</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Next, demonstrate the approximate operation process of this operator:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 1, indices[0] = [0, 0], indices[1] = [0, 0]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 2, And input_x[0, 0] = -0.1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 3, So input_x[indices] = [-0.1, -0.1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 4, Satisfy the above formula: input_x[indices].shape=(2) == updates.shape=(2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 5, Perform the multiply operation for the first time:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#      first_input_x = input_x[0][0] * updates[0] = [[-0.1, 0.3, 3.6], [0.4, 0.5, -3.2]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 6, Perform the multiply operation for the second time:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#      second_input_x = input_x[0][0] * updates[1] = [[-0.22, 0.3, 3.6], [0.4, 0.5, -3.2]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">scatter_mul</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[-0.22  0.3   3.6  ]</span>
<span class="go">[ 0.4   0.5   -3.2 ]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.scatter_sub">
<code class="sig-name descname">scatter_sub</code><span class="sig-paren">(</span><em class="sig-param">indices</em>, <em class="sig-param">updates</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.scatter_sub"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.scatter_sub" title="Permalink to this definition">¶</a></dt>
<dd><p>根据指定的更新值和输入索引，通过减法进行运算，将结果赋值到输出Tensor中。当同一索引有不同值时，更新的结果将分别减去这些值。此操作几乎等同于使用 <a class="reference internal" href="../ops/mindspore.ops.ScatterNdSub.html#mindspore.ops.ScatterNdSub" title="mindspore.ops.ScatterNdSub"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.ScatterNdSub</span></code></a> ，只是更新后的结果是通过算子output返回，而不是直接原地更新input。</p>
<p><cite>indices</cite> 的最后一个轴是每个索引向量的深度。对于每个索引向量， <cite>updates</cite> 中必须有相应的值。<cite>updates</cite> 的shape应该等于 <cite>input_x[indices]</cite> 的shape，其中 <cite>input_x</cite> 指当前Tensor。有关更多详细信息，请参见使用用例。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>GPU平台上，如果 <cite>indices</cite> 的某些值超出范围，则相应的 <cite>updates</cite> 不会更新到 <cite>input_x</cite> ，而不是抛出索引错误；CPU平台上直接抛出索引错误；Ascend平台不支持越界检查，若越界可能会造成未知错误。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>indices</strong> (Tensor) - Tensor的索引，数据类型为int32或int64。其rank至少为2。</p></li>
<li><p><strong>updates</strong> (Tensor) - 指定与本Tensor相减操作的Tensor，其数据类型与该Tensor相同。 <cite>updates.shape</cite> 应等于 <cite>indices.shape[:-1] + self.shape[indices.shape[-1]:]</cite> 。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，shape和数据类型与原Tensor相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>indices</cite> 的数据类型既不是int32，也不是int64。</p></li>
<li><p><strong>ValueError</strong> - Tensor的shape长度小于 <cite>indices</cite> 的shape的最后一个维度。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">3.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">updates</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">scatter_sub</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[-3.3000002  0.3        3.6      ]</span>
<span class="go">[ 0.4        0.5       -3.2      ]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.split">
<code class="sig-name descname">split</code><span class="sig-paren">(</span><em class="sig-param">axis=0</em>, <em class="sig-param">output_num=1</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.split"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.split" title="Permalink to this definition">¶</a></dt>
<dd><p>根据指定的轴和分割数量对Tensor进行分割。</p>
<p>Tensor将被分割为相同shape的子Tensor，且要求 <cite>self.shape(axis)</cite> 可被 <cite>output_num</cite> 整除。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (int) - 指定分割轴。默认值：0。</p></li>
<li><p><strong>output_num</strong> (int) - 指定分割数量。其值为正整数。默认值：1。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>tuple[Tensor]，每个输出Tensor的shape相同，即 <span class="math notranslate nohighlight">\((y_1, y_2, ..., y_S)\)</span> 。数据类型与Tensor相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>axis</cite> 或 <cite>output_num</cite> 不是int。</p></li>
<li><p><strong>ValueError</strong> - <cite>axis</cite> 超出[-len(<cite>self.shape</cite>), len(<cite>self.shape</cite>))范围。或 <cite>output_num</cite> 小于或等于0。</p></li>
<li><p><strong>ValueError</strong> - <cite>self.shape(axis)</cite> 不可被 <cite>output_num</cite> 整除。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">[[1 1 1 1]</span>
<span class="go">[2 2 2 2]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">(Tensor(shape=[2, 2], dtype=Int32, value=</span>
<span class="go">[[1, 1],</span>
<span class="go">[2, 2]]), Tensor(shape=[2, 2], dtype=Int32, value=</span>
<span class="go">[[1, 1],</span>
<span class="go">[2, 2]]))</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.to_coo">
<code class="sig-name descname">to_coo</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.to_coo"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.to_coo" title="Permalink to this definition">¶</a></dt>
<dd><p>将常规Tensor转为稀疏化的COOTensor。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>现在只支持2维Tensor。</p>
</div>
<p><strong>返回：</strong></p>
<p>返回一个2维的COOTensor，是原稠密Tensor的稀疏化表示。其中数据分别为：</p>
<ul class="simple">
<li><p><strong>indices</strong> (Tensor) - 二维整数张量，其中N和ndims分别表示稀疏张量中 <cite>values</cite> 的数量和COOTensor维度的数量。</p></li>
<li><p><strong>values</strong> (Tensor) - 一维张量，用来给 <cite>indices</cite> 中的每个元素提供数值。</p></li>
<li><p><strong>shape</strong> (tuple(int)) - 整数元组，用来指定稀疏矩阵的稠密形状。目前只支持2维Tensor输入，所以 <cite>shape</cite> 长度只能为2。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>ValueError</strong> - Tensor的shape不是2维。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to_coo</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">[[0 0]</span>
<span class="go">[1 0]] [ 1. -5.] (2, 2)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.to_csr">
<code class="sig-name descname">to_csr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.to_csr"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.to_csr" title="Permalink to this definition">¶</a></dt>
<dd><p>将常规Tensor转为稀疏化的CSRTensor。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>现在只支持2维Tensor。</p>
</div>
<p><strong>返回：</strong></p>
<p>返回一个2维的CSRTensor，是原稠密Tensor的稀疏化表示。其中数据分别为：</p>
<ul class="simple">
<li><p><strong>indptr</strong> (Tensor) - 一维整数张量，其中M等于 <cite>shape[0] + 1</cite> , 表示每行非零元素的在 <cite>values</cite> 中存储的起止位置。</p></li>
<li><p><strong>indices</strong> (Tensor) - 一维整数张量，其中N等于非零元素数量，表示每个元素的列索引值。</p></li>
<li><p><strong>values</strong> (Tensor) - 一维张量，用来表示索引对应的数值。</p></li>
<li><p><strong>shape</strong> (tuple(int)) - 整数元组，用来指定稀疏矩阵的稠密形状。目前只支持2维Tensor输入，所以 <cite>shape</cite> 长度只能为2。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>ValueError</strong> - Tensor的shape不是2维。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to_csr</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">indptr</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">[0 1 2] [0 0] [ 1. -5.] (2, 2)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.to_tensor">
<code class="sig-name descname">to_tensor</code><span class="sig-paren">(</span><em class="sig-param">slice_index=None</em>, <em class="sig-param">shape=None</em>, <em class="sig-param">opt_shard_group=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.to_tensor"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.to_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>返回init_data()的结果，并获取此Tensor的数据。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>不建议使用 <cite>to_tensor</cite>。请使用 <cite>init_data</cite> 。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>slice_index</strong> (int) - 参数切片的索引。在初始化参数切片的时候使用，保证使用相同切片的设备可以生成相同的Tensor。默认值：None。</p></li>
<li><p><strong>shape</strong> (list[int]) - 切片的shape，在初始化参数切片时使用。默认值：None。</p></li>
<li><p><strong>opt_shard_group</strong> (str) - 优化器分片组，在自动或半自动并行模式下用于获取参数切片的分片。默认值：None。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>初始化的Tensor。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - <cite>indices</cite> 的数据类型既不是int32，也不是int64。</p></li>
<li><p><strong>ValueError</strong> - Tensor的shape长度小于 <cite>indices</cite> 的shape的最后一个维度。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">Constant</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">initializer</span><span class="p">(</span><span class="n">Constant</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">[[1. 1.]</span>
<span class="go">[1. 1.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.top_k">
<code class="sig-name descname">top_k</code><span class="sig-paren">(</span><em class="sig-param">k</em>, <em class="sig-param">sorted=True</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.top_k"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.top_k" title="Permalink to this definition">¶</a></dt>
<dd><p>沿最后一个维度查找 <cite>k</cite> 个最大元素和对应的索引。</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>如果 <cite>sorted</cite> 设置为’False’，它将使用aicpu运算符，性能可能会降低。</p></li>
</ul>
</div>
<p><cite>x</cite> 指的当前 Tensor。</p>
<p>如果 <cite>input_x</cite> 是一维Tensor，则查找Tensor中 <cite>k</cite> 个最大元素，并将其值和索引输出为Tensor。因此， <cite>values[k]</cite> 是 <cite>input_x</cite> 中 <cite>k</cite> 个最大元素，其索引是 <cite>indices[k]</cite> 。</p>
<p>对于多维矩阵，计算每行中最大的 <cite>k</cite> 个元素（沿最后一个维度的相应向量），因此：</p>
<div class="math notranslate nohighlight">
\[values.shape = indices.shape = input\_x.shape[:-1] + [k].\]</div>
<p>如果两个比较的元素相同，则优先返回索引值较小的元素。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>k</strong> (int) - 指定计算最大元素的数量，需要是常量。</p></li>
<li><p><strong>sorted</strong> (bool, optional) - 如果为True，则获取的元素将按值降序排序。默认值：True。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>2个Tensor组成的tuple， <cite>values</cite> 和 <cite>indices</cite> 。</p>
<ul class="simple">
<li><p><strong>values</strong> (Tensor) - 最后一个维度的每个切片中的 <cite>k</cite> 最大元素。</p></li>
<li><p><strong>indices</strong> (Tensor) - <cite>k</cite> 最大元素的对应索引。</p></li>
</ul>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 如果 <cite>k</cite> 不是int。</p></li>
<li><p><strong>TypeError</strong> - 如果 <cite>sorted</cite> 不是bool。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code>  <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">values</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="nb">sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">((</span><span class="n">values</span><span class="p">,</span> <span class="n">indices</span><span class="p">))</span>
<span class="go">(Tensor(shape=[3], dtype=Float16, value= [ 5.0000e+00,  4.0000e+00,  3.0000e+00]), Tensor(shape=[3],</span>
<span class="go">dtype=Int32, value= [4, 3, 2]))</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.trace">
<code class="sig-name descname">trace</code><span class="sig-paren">(</span><em class="sig-param">offset=0</em>, <em class="sig-param">axis1=0</em>, <em class="sig-param">axis2=1</em>, <em class="sig-param">dtype=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.trace"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.trace" title="Permalink to this definition">¶</a></dt>
<dd><p>在Tensor的对角线方向上的总和。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>offset</strong> (int, optional) - 对角线与主对角线的偏移。可以是正值或负值。默认为主对角线。</p></li>
<li><p><strong>axis1</strong> (int, optional) - 二维子数组的第一轴，对角线应该从这里开始。默认为第一轴(0)。</p></li>
<li><p><strong>axis2</strong> (int, optional) - 二维子数组的第二轴，对角线应该从这里开始。默认为第二轴。</p></li>
<li><p><strong>dtype</strong> (<cite>mindspore.dtype</cite> , optional) - 默认值为None。覆盖输出Tensor的dtype。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，对角线方向上的总和。</p>
<p><strong>异常：</strong></p>
<p><strong>ValueError</strong> - 输入Tensor的维度少于2。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">trace</span><span class="p">())</span>
<span class="go">3.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.unique_with_pad">
<code class="sig-name descname">unique_with_pad</code><span class="sig-paren">(</span><em class="sig-param">pad_num</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.unique_with_pad"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.unique_with_pad" title="Permalink to this definition">¶</a></dt>
<dd><p>对当前一维张量中元素去重，返回一维张量中的唯一元素（使用pad_num填充）和相对索引。</p>
<p>基本操作与unique相同，但unique_with_pad多了pad操作。
unique运算符对张量处理后所返回的元组（ <cite>y</cite> ， <cite>idx</cite> ）， <cite>y</cite> 与 <cite>idx</cite> 的shape通常会有差别，因此，为了解决上述情况，
unique_with_pad操作符将用用户指定的 <cite>pad_num</cite> 填充 <cite>y</cite> 张量，使其具有与张量 <cite>idx</cite> 相同的形状。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>pad_num</strong> (int) - 填充值。数据类型为int32或int64。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tuple， <cite>(y, idx)</cite> 。 <cite>y</cite> 是与当前张量形状和数据类型相同的Tensor，包含当前张量中去重后的元素，并用 <cite>pad_num</cite> 填充。 <cite>idx</cite> 为索引Tensor，包含当前张量中的元素在 <cite>y</cite> 中的索引，与当前张量的shape相同。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 当前张量的数据类型既不是int32也不是int64。</p></li>
<li><p><strong>ValueError</strong> - 当前张量不是一维张量。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unique_with_pad</span><span class="p">(</span><span class="n">pad_num</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[1 2 3 0 0 0]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
<span class="go">[0 0 1 1 2 0]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.transpose">
<code class="sig-name descname">transpose</code><span class="sig-paren">(</span><em class="sig-param">*axes</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.transpose"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.transpose" title="Permalink to this definition">¶</a></dt>
<dd><p>返回被转置后的Tensor。</p>
<ul class="simple">
<li><p>对于一维Tensor，这没有影响，因为转置后的向量是相同的。</p></li>
<li><p>对于二维Tensor，是标准的矩阵转置。</p></li>
<li><p>对于n维Tensor，如果提供了维度，则它们的顺序代表维度的置换方式。</p></li>
</ul>
<p>如果未提供轴，且Tensor.shape等于(i[0], i[1],…i[n-2], i[n-1])，则Tensor.transpose().shape等于(i[n-1], i[n-2], … i[1], i[0])。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axes</strong> (Union[None, tuple(int), list(int), int], optional) - 如果 <cite>axes</cite> 为None或未设置，则该方法将反转维度。如果 <cite>axes</cite> 为tuple(int)或list(int)，则Tensor.transpose()把Tensor转置为新的维度。如果 <cite>axes</cite> 为整数，则此表单仅作为元组/列表表单的备选。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，具有与输入Tensor相同的维度，其中维度被准确的排列。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 输入参数类型有误。</p></li>
<li><p><strong>ValueError</strong> - <cite>axes</cite> 的数量不等于Tensor.ndim。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(3, 2, 1)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.unique_consecutive">
<code class="sig-name descname">unique_consecutive</code><span class="sig-paren">(</span><em class="sig-param">return_idx=False</em>, <em class="sig-param">return_counts=False</em>, <em class="sig-param">axis=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.unique_consecutive"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.unique_consecutive" title="Permalink to this definition">¶</a></dt>
<dd><p>返回输入张量中每个连续等效元素组中唯一的元素。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>return_idx</strong> (bool, optional) - 是否返回原始输入中，各元素在返回的唯一列表中的结束位置的索引。默认值：False。</p></li>
<li><p><strong>return_counts</strong> (bool, optional) - 是否返回每个唯一元素的计数。默认值：False。</p></li>
<li><p><strong>axis</strong> (int, optional) - 维度。如果为None，对输入进行展平操作，返回其唯一性。如果指定，必须是int32或int64类型。默认值：None。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor或包含Tensor对象的元组（ <cite>output</cite> 、 <cite>idx</cite> 、 <cite>counts</cite> ）。 <cite>output</cite> 与输入张量具有相同的类型，用于表示唯一标量元素的输出列表。
如果 <cite>return_idx</cite> 为 True，则会有一个额外的返回张量 <cite>idx</cite>，它的形状与输入张量相同，表示原始输入中的元素映射到输出中的位置的索引。如果
<cite>return_idx</cite> 为 True，则会有一个额外的返回张量 <cite>counts</cite>，表示每个唯一值或张量的出现次数。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>RuntimeError</strong> - <cite>axis</cite> 不在 <cite>[-ndim, ndim-1]</cite> 范围内。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">dtype</span> <span class="k">as</span> <span class="n">mstype</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">mstype</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unique_consecutive</span><span class="p">(</span><span class="n">return_idx</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[1 2 3 1 2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
<span class="go">[0 0 1 1 2 3 3 4]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>
<span class="go">[2 2 1 2 1]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.var">
<code class="sig-name descname">var</code><span class="sig-paren">(</span><em class="sig-param">axis=None</em>, <em class="sig-param">ddof=0</em>, <em class="sig-param">keepdims=False</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.var"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.var" title="Permalink to this definition">¶</a></dt>
<dd><p>在指定维度上的方差。</p>
<p>方差是平均值的平方偏差的平均值，即：<span class="math notranslate nohighlight">\(var = mean(abs(x - x.mean())**2)\)</span> 。</p>
<p>返回方差值。默认情况下计算展开Tensor的方差，否则在指定维度上计算。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>不支持NumPy参数 <cite>dtype</cite> 、 <cite>out</cite> 和 <cite>where</cite> 。</p>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>axis</strong> (Union[None, int, tuple(int)]) - 维度，在指定维度上计算方差。其默认值是展开Tensor的方差。默认值：None。</p></li>
<li><p><strong>ddof</strong> (int) - δ自由度。默认值：0。计算中使用的除数是 <span class="math notranslate nohighlight">\(N - ddof\)</span> ，其中 <span class="math notranslate nohighlight">\(N\)</span> 表示元素的数量。</p></li>
<li><p><strong>keepdims</strong> (bool) - 默认值：False。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>含有方差值的Tensor。</p>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">input_x</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">1.25</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.view">
<code class="sig-name descname">view</code><span class="sig-paren">(</span><em class="sig-param">*shape</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.view"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.view" title="Permalink to this definition">¶</a></dt>
<dd><p>根据输入shape重新创建一个Tensor，与原Tensor数据相同。该方法与reshape方法相同，都是依靠底层reshape算子实现的。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>shape</strong> (Union[tuple(int), int]) - 输出Tensor的维度。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，具有与入参 <cite>shape</cite> 相同的维度。</p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">view</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[[1. 2.]</span>
<span class="go">[3. 2.]</span>
<span class="go">[3. 4.]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.xdivy">
<code class="sig-name descname">xdivy</code><span class="sig-paren">(</span><em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.xdivy"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.xdivy" title="Permalink to this definition">¶</a></dt>
<dd><p>计算原Tensor除以输入的Tensor。当原Tensor为零时，则返回零。原Tensor的数据类型需要是float，complex或bool。
后面为了使表达清晰，使用 <cite>x</cite> 代替原Tensor。</p>
<div class="math notranslate nohighlight">
\[out_i = x_{i}\y_{i}\]</div>
<p><cite>x</cite> 和 <cite>y</cite> 的输入遵循隐式类型转换规则使数据类型一致。y必须是一个Tensor或Scalar，当y是Tensor时，x和y的数据类型不能同时是bool类型，它们的shape可以广播。当y是Scalar时，只能是一个常量。</p>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>y</strong> (Union[Tensor, number.Number, bool]) - 当第一个输入x为Tensor的时候， 第二个输入y可以是Number类型、bool类型或者数据类型为float16、float32、float64、complex64、complex128、bool的Tensor。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，shape与广播后的shape相同，数据类型为两个输入中精度较高或数数值较高的类型。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 如果 <cite>y</cite> 不是以下之一：Tensor、Number、bool。</p></li>
<li><p><strong>TypeError</strong> - 如果 <cite>x</cite> 和 <cite>y</cite> 的数据类型不是float16、float32、float64、complex64、complex128、bool。</p></li>
<li><p><strong>ValueError</strong> - 如果 <cite>x</cite> 不能广播至 <cite>y</cite> 的shape。</p></li>
<li><p><strong>RuntimeError</strong> - 如果Parameter的 <cite>x</cite> , <cite>y</cite> 需要进行数据类型转换，但是Parameter是不支持数据类型转换。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">xdivy</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="go">[ 1.   2.  -0.5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="mindspore.Tensor.xlogy">
<code class="sig-name descname">xlogy</code><span class="sig-paren">(</span><em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/common/tensor.html#Tensor.xlogy"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.Tensor.xlogy" title="Permalink to this definition">¶</a></dt>
<dd><p>计算原Tensor乘以输入Tensor的对数。当原Tensor为零时，则返回零。原Tensor的数据类型需要是
<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/mindspore/mindspore.dtype.html#mindspore.dtype">number</a> 或
<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/mindspore/mindspore.dtype.html#mindspore.dtype">bool_</a>。
后面为了使表达清晰，使用 <cite>x</cite> 代替原Tensor。</p>
<div class="math notranslate nohighlight">
\[out_i = x_{i}\ln{y_{i}}\]</div>
<p><cite>x</cite> 和 <cite>y</cite> 的输入遵循隐式类型转换规则，使数据类型一致。输入必须是两个Tensor或一个Tensor和一个Scalar。当输入是两个Tensor时，它们的数据类型不能同时是bool的，它们的shape可以广播。当输入是一个Tensor和一个Scalar时，Scalar只能是一个常量。</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>在Ascend上， <cite>x</cite> 和 <cite>y</cite> 必须为float16或float32。</p></li>
</ul>
</div>
<p><strong>参数：</strong></p>
<ul class="simple">
<li><p><strong>y</strong> (Union[Tensor, number.Number, bool]) - 第二个输入为数值型。当第一个输入是Tensor或数据类型为数值型或bool的Tensor时，则第二个输入是数值型或bool。当第一个输入是Scalar时，则第二个输入必须是数据类型为数值型或bool的Tensor。</p></li>
</ul>
<p><strong>返回：</strong></p>
<p>Tensor，shape与广播后的shape相同，数据类型为两个输入中精度较高或数数值较高的类型。</p>
<p><strong>异常：</strong></p>
<ul class="simple">
<li><p><strong>TypeError</strong> - 如果 <cite>x</cite> 和 <cite>y</cite> 不是数值型、bool或Tensor。</p></li>
<li><p><strong>TypeError</strong> - 如果 <cite>x</cite> 和 <cite>y</cite> 的数据类型不是float16、float32、float64、complex64或complex128。</p></li>
<li><p><strong>ValueError</strong> - 如果 <cite>x</cite> 不能广播到与 <cite>y</cite> 的shape一致。</p></li>
</ul>
<p><strong>支持平台：</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">xlogy</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="go">[-3.465736   0.        2.7725887]</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="mindspore.COOTensor.html" class="btn btn-neutral float-right" title="mindspore.COOTensor" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="../mindspore.html" class="btn btn-neutral float-left" title="mindspore" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>