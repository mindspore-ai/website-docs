<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.nn &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      <link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script><script src="../_static/jquery.js"></script>
        <script src="../_static/js/theme.js"></script><script src="../_static/underscore.js"></script><script src="../_static/doctools.js"></script><script src="../_static/js/training.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script><script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script><script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="mindspore.nn.Cell" href="nn/mindspore.nn.Cell.html" />
    <link rel="prev" title="mindspore.mindrecord" href="mindspore.mindrecord.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">设计</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../design/overview.html">MindSpore设计概览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/auto_gradient.html">函数式微分编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/mindir.html">中间表示MindIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/all_scenarios.html">全场景统一</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/dynamic_graph_and_static_graph.html">动静态图结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/distributed_training_design.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/graph_fusion_engine.html">图算融合加速引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../design/glossary.html">术语</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">规格</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/benchmark.html">基准性能</a></li>
<li class="toctree-l1"><a class="reference external" href="https://gitee.com/mindspore/models/blob/r1.9/README_CN.md#目录">网络支持↗</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/operator_list.html">API支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/syntax_list.html">语法支持</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.audio.html">mindspore.dataset.audio</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.config.html">mindspore.dataset.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.text.html">mindspore.dataset.text</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.dataset.vision.html">mindspore.dataset.vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">mindspore.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#基本构成单元">基本构成单元</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Cell.html">mindspore.nn.Cell</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.GraphCell.html">mindspore.nn.GraphCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.LossBase.html">mindspore.nn.LossBase</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Optimizer.html">mindspore.nn.Optimizer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#容器">容器</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.CellList.html">mindspore.nn.CellList</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.SequentialCell.html">mindspore.nn.SequentialCell</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#封装层">封装层</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.DistributedGradReducer.html">mindspore.nn.DistributedGradReducer</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.DynamicLossScaleUpdateCell.html">mindspore.nn.DynamicLossScaleUpdateCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.FixedLossScaleUpdateCell.html">mindspore.nn.FixedLossScaleUpdateCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ForwardValueAndGrad.html">mindspore.nn.ForwardValueAndGrad</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.GetNextSingleOp.html">mindspore.nn.GetNextSingleOp</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.MicroBatchInterleaved.html">mindspore.nn.MicroBatchInterleaved</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ParameterUpdate.html">mindspore.nn.ParameterUpdate</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.PipelineCell.html">mindspore.nn.PipelineCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.TimeDistributed.html">mindspore.nn.TimeDistributed</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.TrainOneStepCell.html">mindspore.nn.TrainOneStepCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.TrainOneStepWithLossScaleCell.html">mindspore.nn.TrainOneStepWithLossScaleCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.WithEvalCell.html">mindspore.nn.WithEvalCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.WithGradCell.html">mindspore.nn.WithGradCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.WithLossCell.html">mindspore.nn.WithLossCell</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#卷积神经网络层">卷积神经网络层</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Conv1d.html">mindspore.nn.Conv1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Conv1dTranspose.html">mindspore.nn.Conv1dTranspose</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Conv2d.html">mindspore.nn.Conv2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Conv2dTranspose.html">mindspore.nn.Conv2dTranspose</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Conv3d.html">mindspore.nn.Conv3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Conv3dTranspose.html">mindspore.nn.Conv3dTranspose</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Unfold.html">mindspore.nn.Unfold</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#循环神经网络层">循环神经网络层</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.RNN.html">mindspore.nn.RNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.RNNCell.html">mindspore.nn.RNNCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.GRU.html">mindspore.nn.GRU</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.GRUCell.html">mindspore.nn.GRUCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.LSTM.html">mindspore.nn.LSTM</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.LSTMCell.html">mindspore.nn.LSTMCell</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#嵌入层">嵌入层</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Embedding.html">mindspore.nn.Embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.EmbeddingLookup.html">mindspore.nn.EmbeddingLookup</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.MultiFieldEmbeddingLookup.html">mindspore.nn.MultiFieldEmbeddingLookup</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#非线性激活函数层">非线性激活函数层</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.CELU.html">mindspore.nn.CELU</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ELU.html">mindspore.nn.ELU</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.FastGelu.html">mindspore.nn.FastGelu</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.GELU.html">mindspore.nn.GELU</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.get_activation.html">mindspore.nn.get_activation</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Hardtanh.html">mindspore.nn.Hardtanh</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.HShrink.html">mindspore.nn.HShrink</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.HSigmoid.html">mindspore.nn.HSigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.HSwish.html">mindspore.nn.HSwish</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.LeakyReLU.html">mindspore.nn.LeakyReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.LogSigmoid.html">mindspore.nn.LogSigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.LogSoftmax.html">mindspore.nn.LogSoftmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.LRN.html">mindspore.nn.LRN</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Mish.html">mindspore.nn.Mish</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Softsign.html">mindspore.nn.Softsign</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.PReLU.html">mindspore.nn.PReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ReLU.html">mindspore.nn.ReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ReLU6.html">mindspore.nn.ReLU6</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.RReLU.html">mindspore.nn.RReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.SeLU.html">mindspore.nn.SeLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.SiLU.html">mindspore.nn.SiLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Sigmoid.html">mindspore.nn.Sigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Softmin.html">mindspore.nn.Softmin</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Softmax.html">mindspore.nn.Softmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.SoftShrink.html">mindspore.nn.SoftShrink</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Tanh.html">mindspore.nn.Tanh</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Tanhshrink.html">mindspore.nn.Tanhshrink</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Threshold.html">mindspore.nn.Threshold</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#线性层">线性层</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Dense.html">mindspore.nn.Dense</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.BiDense.html">mindspore.nn.BiDense</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#dropout层">Dropout层</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Dropout.html">mindspore.nn.Dropout</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Dropout2d.html">mindspore.nn.Dropout2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Dropout3d.html">mindspore.nn.Dropout3d</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#归一化层">归一化层</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.BatchNorm1d.html">mindspore.nn.BatchNorm1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.BatchNorm2d.html">mindspore.nn.BatchNorm2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.BatchNorm3d.html">mindspore.nn.BatchNorm3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.GroupNorm.html">mindspore.nn.GroupNorm</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.InstanceNorm1d.html">mindspore.nn.InstanceNorm1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.InstanceNorm2d.html">mindspore.nn.InstanceNorm2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.InstanceNorm3d.html">mindspore.nn.InstanceNorm3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.LayerNorm.html">mindspore.nn.LayerNorm</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.SyncBatchNorm.html">mindspore.nn.SyncBatchNorm</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#池化层">池化层</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.AdaptiveAvgPool1d.html">mindspore.nn.AdaptiveAvgPool1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.AdaptiveAvgPool2d.html">mindspore.nn.AdaptiveAvgPool2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.AdaptiveAvgPool3d.html">mindspore.nn.AdaptiveAvgPool3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.AdaptiveMaxPool1d.html">mindspore.nn.AdaptiveMaxPool1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.AdaptiveMaxPool2d.html">mindspore.nn.AdaptiveMaxPool2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.AvgPool1d.html">mindspore.nn.AvgPool1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.AvgPool2d.html">mindspore.nn.AvgPool2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.MaxPool1d.html">mindspore.nn.MaxPool1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.MaxPool2d.html">mindspore.nn.MaxPool2d</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#填充层">填充层</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Pad.html">mindspore.nn.Pad</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ConstantPad1d.html">mindspore.nn.ConstantPad1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ConstantPad2d.html">mindspore.nn.ConstantPad2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ConstantPad3d.html">mindspore.nn.ConstantPad3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ReflectionPad1d.html">mindspore.nn.ReflectionPad1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ReflectionPad2d.html">mindspore.nn.ReflectionPad2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ZeroPad2d.html">mindspore.nn.ZeroPad2d</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#损失函数">损失函数</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.BCELoss.html">mindspore.nn.BCELoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.BCEWithLogitsLoss.html">mindspore.nn.BCEWithLogitsLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.CosineEmbeddingLoss.html">mindspore.nn.CosineEmbeddingLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.CrossEntropyLoss.html">mindspore.nn.CrossEntropyLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.DiceLoss.html">mindspore.nn.DiceLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.FocalLoss.html">mindspore.nn.FocalLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.HuberLoss.html">mindspore.nn.HuberLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.L1Loss.html">mindspore.nn.L1Loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.MSELoss.html">mindspore.nn.MSELoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.MultiClassDiceLoss.html">mindspore.nn.MultiClassDiceLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.NLLLoss.html">mindspore.nn.NLLLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.RMSELoss.html">mindspore.nn.RMSELoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.SampledSoftmaxLoss.html">mindspore.nn.SampledSoftmaxLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.SmoothL1Loss.html">mindspore.nn.SmoothL1Loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.SoftMarginLoss.html">mindspore.nn.SoftMarginLoss</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.SoftmaxCrossEntropyWithLogits.html">mindspore.nn.SoftmaxCrossEntropyWithLogits</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#优化器">优化器</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Adadelta.html">mindspore.nn.Adadelta</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Adagrad.html">mindspore.nn.Adagrad</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Adam.html">mindspore.nn.Adam</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.AdaMax.html">mindspore.nn.AdaMax</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.AdamOffload.html">mindspore.nn.AdamOffload</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.AdamWeightDecay.html">mindspore.nn.AdamWeightDecay</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.AdaSumByDeltaWeightWrapCell.html">mindspore.nn.AdaSumByDeltaWeightWrapCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.AdaSumByGradWrapCell.html">mindspore.nn.AdaSumByGradWrapCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ASGD.html">mindspore.nn.ASGD</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.FTRL.html">mindspore.nn.FTRL</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Lamb.html">mindspore.nn.Lamb</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.LARS.html">mindspore.nn.LARS</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.LazyAdam.html">mindspore.nn.LazyAdam</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Momentum.html">mindspore.nn.Momentum</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ProximalAdagrad.html">mindspore.nn.ProximalAdagrad</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.RMSProp.html">mindspore.nn.RMSProp</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Rprop.html">mindspore.nn.Rprop</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.SGD.html">mindspore.nn.SGD</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.thor.html">mindspore.nn.thor</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#评价指标">评价指标</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Accuracy.html">mindspore.nn.Accuracy</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.auc.html">mindspore.nn.auc</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.BleuScore.html">mindspore.nn.BleuScore</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ConfusionMatrix.html">mindspore.nn.ConfusionMatrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ConfusionMatrixMetric.html">mindspore.nn.ConfusionMatrixMetric</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.CosineSimilarity.html">mindspore.nn.CosineSimilarity</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Dice.html">mindspore.nn.Dice</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.F1.html">mindspore.nn.F1</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Fbeta.html">mindspore.nn.Fbeta</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.HausdorffDistance.html">mindspore.nn.HausdorffDistance</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.get_metric_fn.html">mindspore.nn.get_metric_fn</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Loss.html">mindspore.nn.Loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.MAE.html">mindspore.nn.MAE</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.MeanSurfaceDistance.html">mindspore.nn.MeanSurfaceDistance</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Metric.html">mindspore.nn.Metric</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.MSE.html">mindspore.nn.MSE</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.names.html">mindspore.nn.names</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.OcclusionSensitivity.html">mindspore.nn.OcclusionSensitivity</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Perplexity.html">mindspore.nn.Perplexity</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Precision.html">mindspore.nn.Precision</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Recall.html">mindspore.nn.Recall</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ROC.html">mindspore.nn.ROC</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.RootMeanSquareDistance.html">mindspore.nn.RootMeanSquareDistance</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.rearrange_inputs.html">mindspore.nn.rearrange_inputs</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Top1CategoricalAccuracy.html">mindspore.nn.Top1CategoricalAccuracy</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Top5CategoricalAccuracy.html">mindspore.nn.Top5CategoricalAccuracy</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.TopKCategoricalAccuracy.html">mindspore.nn.TopKCategoricalAccuracy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#动态学习率">动态学习率</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#learningrateschedule类">LearningRateSchedule类</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nn/mindspore.nn.CosineDecayLR.html">mindspore.nn.CosineDecayLR</a></li>
<li class="toctree-l4"><a class="reference internal" href="nn/mindspore.nn.ExponentialDecayLR.html">mindspore.nn.ExponentialDecayLR</a></li>
<li class="toctree-l4"><a class="reference internal" href="nn/mindspore.nn.InverseDecayLR.html">mindspore.nn.InverseDecayLR</a></li>
<li class="toctree-l4"><a class="reference internal" href="nn/mindspore.nn.NaturalExpDecayLR.html">mindspore.nn.NaturalExpDecayLR</a></li>
<li class="toctree-l4"><a class="reference internal" href="nn/mindspore.nn.PolynomialDecayLR.html">mindspore.nn.PolynomialDecayLR</a></li>
<li class="toctree-l4"><a class="reference internal" href="nn/mindspore.nn.WarmUpLR.html">mindspore.nn.WarmUpLR</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#dynamic-lr函数">Dynamic LR函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nn/mindspore.nn.cosine_decay_lr.html">mindspore.nn.cosine_decay_lr</a></li>
<li class="toctree-l4"><a class="reference internal" href="nn/mindspore.nn.exponential_decay_lr.html">mindspore.nn.exponential_decay_lr</a></li>
<li class="toctree-l4"><a class="reference internal" href="nn/mindspore.nn.inverse_decay_lr.html">mindspore.nn.inverse_decay_lr</a></li>
<li class="toctree-l4"><a class="reference internal" href="nn/mindspore.nn.natural_exp_decay_lr.html">mindspore.nn.natural_exp_decay_lr</a></li>
<li class="toctree-l4"><a class="reference internal" href="nn/mindspore.nn.piecewise_constant_lr.html">mindspore.nn.piecewise_constant_lr</a></li>
<li class="toctree-l4"><a class="reference internal" href="nn/mindspore.nn.polynomial_decay_lr.html">mindspore.nn.polynomial_decay_lr</a></li>
<li class="toctree-l4"><a class="reference internal" href="nn/mindspore.nn.warmup_lr.html">mindspore.nn.warmup_lr</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#图像处理层">图像处理层</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.CentralCrop.html">mindspore.nn.CentralCrop</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ImageGradients.html">mindspore.nn.ImageGradients</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.MSSSIM.html">mindspore.nn.MSSSIM</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.PSNR.html">mindspore.nn.PSNR</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ResizeBilinear.html">mindspore.nn.ResizeBilinear</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.SSIM.html">mindspore.nn.SSIM</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#矩阵处理">矩阵处理</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.MatrixDiag.html">mindspore.nn.MatrixDiag</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.MatrixDiagPart.html">mindspore.nn.MatrixDiagPart</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.MatrixSetDiag.html">mindspore.nn.MatrixSetDiag</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#工具">工具</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.ClipByNorm.html">mindspore.nn.ClipByNorm</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Flatten.html">mindspore.nn.Flatten</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.L1Regularizer.html">mindspore.nn.L1Regularizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Norm.html">mindspore.nn.Norm</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.OneHot.html">mindspore.nn.OneHot</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Range.html">mindspore.nn.Range</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Roll.html">mindspore.nn.Roll</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Tril.html">mindspore.nn.Tril</a></li>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Triu.html">mindspore.nn.Triu</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#数学运算">数学运算</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn/mindspore.nn.Moments.html">mindspore.nn.Moments</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.nn.transformer.html">mindspore.nn.transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.ops.function.html">mindspore.ops.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r1.9/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API映射</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/pytorch_api_mapping.html">PyTorch与MindSpore API映射表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../note/api_mapping/tensorflow_api_mapping.html">TensorFlow与MindSpore API映射表</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">迁移指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/overview.html">概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/enveriment_preparation.html">环境准备与资料获取</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/analysis_and_preparation.html">模型分析与准备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/model_development/model_development.html">MindSpore网络搭建</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/debug_and_tune.html">调试调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/sample_code.html">网络迁移调试实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/faq.html">常见问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/typical_api_comparision.html">与PyTorch典型区别</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration_guide/use_third_party_op.html">基于自定义算子接口调用第三方算子库</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq/installation.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/data_processing.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/implement_problem.html">执行问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/network_compilation.html">网络编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/usage_migrate_3rd.html">第三方框架迁移使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/distributed_configure.html">分布式配置</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/feature_advice.html">特性咨询</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>mindspore.nn</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api_python/mindspore.nn.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="mindspore-nn">
<h1>mindspore.nn<a class="headerlink" href="#mindspore-nn" title="Permalink to this headline"></a></h1>
<p>神经网络Cell。</p>
<p>用于构建神经网络中的预定义构建块或计算单元。</p>
<p>MindSpore中 <cite>mindspore.nn</cite> 接口与上一版本相比，新增、删除和支持平台的变化信息请参考 <a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.9/resource/api_updates/ops_api_updates.md">API Updates</a> 。</p>
<section id="基本构成单元">
<h2>基本构成单元<a class="headerlink" href="#基本构成单元" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Cell.html#mindspore.nn.Cell" title="mindspore.nn.Cell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Cell</span></code></a></p></td>
<td><p>MindSpore中神经网络的基本构成单元。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.GraphCell.html#mindspore.nn.GraphCell" title="mindspore.nn.GraphCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.GraphCell</span></code></a></p></td>
<td><p>运行从MindIR加载的计算图。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.LossBase.html#mindspore.nn.LossBase" title="mindspore.nn.LossBase"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.LossBase</span></code></a></p></td>
<td><p>损失函数的基类。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Optimizer.html#mindspore.nn.Optimizer" title="mindspore.nn.Optimizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Optimizer</span></code></a></p></td>
<td><p>用于参数更新的优化器基类。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="容器">
<h2>容器<a class="headerlink" href="#容器" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.CellList.html#mindspore.nn.CellList" title="mindspore.nn.CellList"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.CellList</span></code></a></p></td>
<td><p>构造Cell列表。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.SequentialCell.html#mindspore.nn.SequentialCell" title="mindspore.nn.SequentialCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.SequentialCell</span></code></a></p></td>
<td><p>构造Cell顺序容器。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="封装层">
<h2>封装层<a class="headerlink" href="#封装层" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.DistributedGradReducer.html#mindspore.nn.DistributedGradReducer" title="mindspore.nn.DistributedGradReducer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.DistributedGradReducer</span></code></a></p></td>
<td><p>分布式优化器。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.DynamicLossScaleUpdateCell.html#mindspore.nn.DynamicLossScaleUpdateCell" title="mindspore.nn.DynamicLossScaleUpdateCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.DynamicLossScaleUpdateCell</span></code></a></p></td>
<td><p>用于动态更新损失缩放系数(loss scale)的神经元。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.FixedLossScaleUpdateCell.html#mindspore.nn.FixedLossScaleUpdateCell" title="mindspore.nn.FixedLossScaleUpdateCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.FixedLossScaleUpdateCell</span></code></a></p></td>
<td><p>固定损失缩放系数的神经元。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.ForwardValueAndGrad.html#mindspore.nn.ForwardValueAndGrad" title="mindspore.nn.ForwardValueAndGrad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ForwardValueAndGrad</span></code></a></p></td>
<td><p>训练网络的封装。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.GetNextSingleOp.html#mindspore.nn.GetNextSingleOp" title="mindspore.nn.GetNextSingleOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.GetNextSingleOp</span></code></a></p></td>
<td><p>用于获取下一条数据的Cell。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.MicroBatchInterleaved.html#mindspore.nn.MicroBatchInterleaved" title="mindspore.nn.MicroBatchInterleaved"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.MicroBatchInterleaved</span></code></a></p></td>
<td><p>Wrap the network with Batch Size.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.ParameterUpdate.html#mindspore.nn.ParameterUpdate" title="mindspore.nn.ParameterUpdate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ParameterUpdate</span></code></a></p></td>
<td><p>更新参数的Cell。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.PipelineCell.html#mindspore.nn.PipelineCell" title="mindspore.nn.PipelineCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.PipelineCell</span></code></a></p></td>
<td><p>将MiniBatch切分成更细粒度的MicroBatch，用于流水线并行的训练中。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.TimeDistributed.html#mindspore.nn.TimeDistributed" title="mindspore.nn.TimeDistributed"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.TimeDistributed</span></code></a></p></td>
<td><p>时间序列封装层。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.TrainOneStepCell.html#mindspore.nn.TrainOneStepCell" title="mindspore.nn.TrainOneStepCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.TrainOneStepCell</span></code></a></p></td>
<td><p>训练网络封装类。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.TrainOneStepWithLossScaleCell.html#mindspore.nn.TrainOneStepWithLossScaleCell" title="mindspore.nn.TrainOneStepWithLossScaleCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.TrainOneStepWithLossScaleCell</span></code></a></p></td>
<td><p>使用混合精度功能的训练网络。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.WithEvalCell.html#mindspore.nn.WithEvalCell" title="mindspore.nn.WithEvalCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.WithEvalCell</span></code></a></p></td>
<td><p>封装前向网络和损失函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.WithGradCell.html#mindspore.nn.WithGradCell" title="mindspore.nn.WithGradCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.WithGradCell</span></code></a></p></td>
<td><p>Cell that returns the gradients.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.WithLossCell.html#mindspore.nn.WithLossCell" title="mindspore.nn.WithLossCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.WithLossCell</span></code></a></p></td>
<td><p>包含损失函数的Cell。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="卷积神经网络层">
<h2>卷积神经网络层<a class="headerlink" href="#卷积神经网络层" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Conv1d.html#mindspore.nn.Conv1d" title="mindspore.nn.Conv1d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Conv1d</span></code></a></p></td>
<td><p>一维卷积层。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Conv1dTranspose.html#mindspore.nn.Conv1dTranspose" title="mindspore.nn.Conv1dTranspose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Conv1dTranspose</span></code></a></p></td>
<td><p>一维转置卷积层。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Conv2d.html#mindspore.nn.Conv2d" title="mindspore.nn.Conv2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Conv2d</span></code></a></p></td>
<td><p>二维卷积层。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Conv2dTranspose.html#mindspore.nn.Conv2dTranspose" title="mindspore.nn.Conv2dTranspose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Conv2dTranspose</span></code></a></p></td>
<td><p>二维转置卷积层。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Conv3d.html#mindspore.nn.Conv3d" title="mindspore.nn.Conv3d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Conv3d</span></code></a></p></td>
<td><p>三维卷积层。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Conv3dTranspose.html#mindspore.nn.Conv3dTranspose" title="mindspore.nn.Conv3dTranspose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Conv3dTranspose</span></code></a></p></td>
<td><p>三维转置卷积层。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Unfold.html#mindspore.nn.Unfold" title="mindspore.nn.Unfold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Unfold</span></code></a></p></td>
<td><p>从图像中提取滑窗的区域块。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="循环神经网络层">
<h2>循环神经网络层<a class="headerlink" href="#循环神经网络层" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.RNN.html#mindspore.nn.RNN" title="mindspore.nn.RNN"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.RNN</span></code></a></p></td>
<td><p>循环神经网络（RNN）层，其使用的激活函数为tanh或relu。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.RNNCell.html#mindspore.nn.RNNCell" title="mindspore.nn.RNNCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.RNNCell</span></code></a></p></td>
<td><p>循环神经网络单元，激活函数是tanh或relu。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.GRU.html#mindspore.nn.GRU" title="mindspore.nn.GRU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.GRU</span></code></a></p></td>
<td><p>GRU（Gate Recurrent Unit）称为门控循环单元网络，是循环神经网络（Recurrent Neural Network, RNN）的一种。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.GRUCell.html#mindspore.nn.GRUCell" title="mindspore.nn.GRUCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.GRUCell</span></code></a></p></td>
<td><p>GRU（Gate Recurrent Unit）称为门控循环单元。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.LSTM.html#mindspore.nn.LSTM" title="mindspore.nn.LSTM"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.LSTM</span></code></a></p></td>
<td><p>长短期记忆（LSTM）网络，根据输出序列和给定的初始状态计算输出序列和最终状态。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.LSTMCell.html#mindspore.nn.LSTMCell" title="mindspore.nn.LSTMCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.LSTMCell</span></code></a></p></td>
<td><p>长短期记忆网络单元（LSTMCell）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="嵌入层">
<h2>嵌入层<a class="headerlink" href="#嵌入层" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Embedding.html#mindspore.nn.Embedding" title="mindspore.nn.Embedding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Embedding</span></code></a></p></td>
<td><p>嵌入层。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.EmbeddingLookup.html#mindspore.nn.EmbeddingLookup" title="mindspore.nn.EmbeddingLookup"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.EmbeddingLookup</span></code></a></p></td>
<td><p>嵌入查找层。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.MultiFieldEmbeddingLookup.html#mindspore.nn.MultiFieldEmbeddingLookup" title="mindspore.nn.MultiFieldEmbeddingLookup"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.MultiFieldEmbeddingLookup</span></code></a></p></td>
<td><p>根据指定的索引和字段ID，返回输入Tensor的切片。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="非线性激活函数层">
<h2>非线性激活函数层<a class="headerlink" href="#非线性激活函数层" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.CELU.html#mindspore.nn.CELU" title="mindspore.nn.CELU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.CELU</span></code></a></p></td>
<td><p>Continuously differentiable exponential linear units activation function.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.ELU.html#mindspore.nn.ELU" title="mindspore.nn.ELU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ELU</span></code></a></p></td>
<td><p>指数线性单元激活函数（Exponential Linear Unit activation function）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.FastGelu.html#mindspore.nn.FastGelu" title="mindspore.nn.FastGelu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.FastGelu</span></code></a></p></td>
<td><p>快速高斯误差线性单元激活函数（Fast Gaussian Error Linear Units activation function）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.GELU.html#mindspore.nn.GELU" title="mindspore.nn.GELU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.GELU</span></code></a></p></td>
<td><p>高斯误差线性单元激活函数（Gaussian error linear unit activation function）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.get_activation.html#mindspore.nn.get_activation" title="mindspore.nn.get_activation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.get_activation</span></code></a></p></td>
<td><p>获取激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Hardtanh.html#mindspore.nn.Hardtanh" title="mindspore.nn.Hardtanh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Hardtanh</span></code></a></p></td>
<td><p>Hardtanh激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.HShrink.html#mindspore.nn.HShrink" title="mindspore.nn.HShrink"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.HShrink</span></code></a></p></td>
<td><p>Hard Shrink激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.HSigmoid.html#mindspore.nn.HSigmoid" title="mindspore.nn.HSigmoid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.HSigmoid</span></code></a></p></td>
<td><p>Hard Sigmoid激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.HSwish.html#mindspore.nn.HSwish" title="mindspore.nn.HSwish"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.HSwish</span></code></a></p></td>
<td><p>Hard Swish激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.LeakyReLU.html#mindspore.nn.LeakyReLU" title="mindspore.nn.LeakyReLU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.LeakyReLU</span></code></a></p></td>
<td><p>Leaky ReLU激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.LogSigmoid.html#mindspore.nn.LogSigmoid" title="mindspore.nn.LogSigmoid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.LogSigmoid</span></code></a></p></td>
<td><p>Log Sigmoid激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.LogSoftmax.html#mindspore.nn.LogSoftmax" title="mindspore.nn.LogSoftmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.LogSoftmax</span></code></a></p></td>
<td><p>Log Softmax激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.LRN.html#mindspore.nn.LRN" title="mindspore.nn.LRN"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.LRN</span></code></a></p></td>
<td><p>局部响应归一化操作LRN(Local Response Normalization)。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Mish.html#mindspore.nn.Mish" title="mindspore.nn.Mish"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Mish</span></code></a></p></td>
<td><p>逐元素计算输入Tensor的MISH（Self Regularized Non-Monotonic Neural Activation Function 自正则化非单调神经激活函数）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Softsign.html#mindspore.nn.Softsign" title="mindspore.nn.Softsign"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Softsign</span></code></a></p></td>
<td><p>Softsign激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.PReLU.html#mindspore.nn.PReLU" title="mindspore.nn.PReLU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.PReLU</span></code></a></p></td>
<td><p>PReLU激活层（PReLU Activation Operator）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.ReLU.html#mindspore.nn.ReLU" title="mindspore.nn.ReLU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ReLU</span></code></a></p></td>
<td><p>修正线性单元激活函数（Rectified Linear Unit activation function）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.ReLU6.html#mindspore.nn.ReLU6" title="mindspore.nn.ReLU6"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ReLU6</span></code></a></p></td>
<td><p>ReLU6激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.RReLU.html#mindspore.nn.RReLU" title="mindspore.nn.RReLU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.RReLU</span></code></a></p></td>
<td><p>Randomized Leaky ReLU激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.SeLU.html#mindspore.nn.SeLU" title="mindspore.nn.SeLU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.SeLU</span></code></a></p></td>
<td><p>激活函数selu（Scaled exponential Linear Unit）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.SiLU.html#mindspore.nn.SiLU" title="mindspore.nn.SiLU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.SiLU</span></code></a></p></td>
<td><p>SiLU激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Sigmoid.html#mindspore.nn.Sigmoid" title="mindspore.nn.Sigmoid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Sigmoid</span></code></a></p></td>
<td><p>Sigmoid激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Softmin.html#mindspore.nn.Softmin" title="mindspore.nn.Softmin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Softmin</span></code></a></p></td>
<td><p>Softmin函数，它是二分类函数 <a class="reference internal" href="nn/mindspore.nn.Sigmoid.html#mindspore.nn.Sigmoid" title="mindspore.nn.Sigmoid"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.nn.Sigmoid</span></code></a> 在多分类上的推广，目的是将多分类的结果以概率的形式展现出来。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Softmax.html#mindspore.nn.Softmax" title="mindspore.nn.Softmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Softmax</span></code></a></p></td>
<td><p>Softmax函数，它是二分类函数 <a class="reference internal" href="nn/mindspore.nn.Sigmoid.html#mindspore.nn.Sigmoid" title="mindspore.nn.Sigmoid"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.nn.Sigmoid</span></code></a> 在多分类上的推广，目的是将多分类的结果以概率的形式展现出来。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.SoftShrink.html#mindspore.nn.SoftShrink" title="mindspore.nn.SoftShrink"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.SoftShrink</span></code></a></p></td>
<td><p>SoftShrink激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Tanh.html#mindspore.nn.Tanh" title="mindspore.nn.Tanh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Tanh</span></code></a></p></td>
<td><p>Tanh激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Tanhshrink.html#mindspore.nn.Tanhshrink" title="mindspore.nn.Tanhshrink"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Tanhshrink</span></code></a></p></td>
<td><p>Tanhshrink激活函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Threshold.html#mindspore.nn.Threshold" title="mindspore.nn.Threshold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Threshold</span></code></a></p></td>
<td><p>Threshold激活函数，按元素计算输出。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="线性层">
<h2>线性层<a class="headerlink" href="#线性层" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Dense.html#mindspore.nn.Dense" title="mindspore.nn.Dense"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Dense</span></code></a></p></td>
<td><p>全连接层。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.BiDense.html#mindspore.nn.BiDense" title="mindspore.nn.BiDense"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.BiDense</span></code></a></p></td>
<td><p>双线性全连接层。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="dropout层">
<h2>Dropout层<a class="headerlink" href="#dropout层" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Dropout.html#mindspore.nn.Dropout" title="mindspore.nn.Dropout"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Dropout</span></code></a></p></td>
<td><p>随机丢弃层。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Dropout2d.html#mindspore.nn.Dropout2d" title="mindspore.nn.Dropout2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Dropout2d</span></code></a></p></td>
<td><p>在训练期间，以服从伯努利分布的概率 <cite>p</cite> 随机将输入Tensor的某些通道归零（对于格式为 <cite>NCHW</cite> 的四维Tensor，其通道特征图指的是后两维 <cite>HW</cite> 格式的二维特征图）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Dropout3d.html#mindspore.nn.Dropout3d" title="mindspore.nn.Dropout3d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Dropout3d</span></code></a></p></td>
<td><p>在训练期间，以服从伯努利分布的概率 <cite>p</cite> 随机将输入Tensor的某些通道归零（对于形状为 <cite>NCDHW</cite> 的 <cite>5D</cite> Tensor，其通道特征图指的是后三维 <cite>DHW</cite> 形状的三维特征图）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="归一化层">
<h2>归一化层<a class="headerlink" href="#归一化层" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.BatchNorm1d.html#mindspore.nn.BatchNorm1d" title="mindspore.nn.BatchNorm1d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.BatchNorm1d</span></code></a></p></td>
<td><p>对输入的二维数据进行批归一化(Batch Normalization Layer)。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.BatchNorm2d.html#mindspore.nn.BatchNorm2d" title="mindspore.nn.BatchNorm2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.BatchNorm2d</span></code></a></p></td>
<td><p>对输入的四维数据进行批归一化(Batch Normalization Layer)。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.BatchNorm3d.html#mindspore.nn.BatchNorm3d" title="mindspore.nn.BatchNorm3d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.BatchNorm3d</span></code></a></p></td>
<td><p>对输入的五维数据进行批归一化(Batch Normalization Layer)。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.GroupNorm.html#mindspore.nn.GroupNorm" title="mindspore.nn.GroupNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.GroupNorm</span></code></a></p></td>
<td><p>在mini-batch输入上进行组归一化。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.InstanceNorm1d.html#mindspore.nn.InstanceNorm1d" title="mindspore.nn.InstanceNorm1d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.InstanceNorm1d</span></code></a></p></td>
<td><p>对三维输入实现实例归一化（Instance Normalization Layer）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.InstanceNorm2d.html#mindspore.nn.InstanceNorm2d" title="mindspore.nn.InstanceNorm2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.InstanceNorm2d</span></code></a></p></td>
<td><p>对四维输入实现实例归一化（Instance Normalization Layer）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.InstanceNorm3d.html#mindspore.nn.InstanceNorm3d" title="mindspore.nn.InstanceNorm3d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.InstanceNorm3d</span></code></a></p></td>
<td><p>对五维输入实现实例归一化（Instance Normalization Layer）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.LayerNorm.html#mindspore.nn.LayerNorm" title="mindspore.nn.LayerNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.LayerNorm</span></code></a></p></td>
<td><p>在mini-batch输入上应用层归一化（Layer Normalization）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.SyncBatchNorm.html#mindspore.nn.SyncBatchNorm" title="mindspore.nn.SyncBatchNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.SyncBatchNorm</span></code></a></p></td>
<td><p>在N维输入上进行跨设备同步批归一化（Batch Normalization，BN）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="池化层">
<h2>池化层<a class="headerlink" href="#池化层" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.AdaptiveAvgPool1d.html#mindspore.nn.AdaptiveAvgPool1d" title="mindspore.nn.AdaptiveAvgPool1d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.AdaptiveAvgPool1d</span></code></a></p></td>
<td><p>对输入的多维数据进行一维平面上的自适应平均池化运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.AdaptiveAvgPool2d.html#mindspore.nn.AdaptiveAvgPool2d" title="mindspore.nn.AdaptiveAvgPool2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.AdaptiveAvgPool2d</span></code></a></p></td>
<td><p>二维自适应平均池化。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.AdaptiveAvgPool3d.html#mindspore.nn.AdaptiveAvgPool3d" title="mindspore.nn.AdaptiveAvgPool3d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.AdaptiveAvgPool3d</span></code></a></p></td>
<td><p>三维自适应平均池化。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.AdaptiveMaxPool1d.html#mindspore.nn.AdaptiveMaxPool1d" title="mindspore.nn.AdaptiveMaxPool1d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.AdaptiveMaxPool1d</span></code></a></p></td>
<td><p>对输入的多维数据进行一维平面上的自适应最大池化运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.AdaptiveMaxPool2d.html#mindspore.nn.AdaptiveMaxPool2d" title="mindspore.nn.AdaptiveMaxPool2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.AdaptiveMaxPool2d</span></code></a></p></td>
<td><p>二维自适应最大池化运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.AvgPool1d.html#mindspore.nn.AvgPool1d" title="mindspore.nn.AvgPool1d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.AvgPool1d</span></code></a></p></td>
<td><p>对输入的多维数据进行一维平面上的平均池化运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.AvgPool2d.html#mindspore.nn.AvgPool2d" title="mindspore.nn.AvgPool2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.AvgPool2d</span></code></a></p></td>
<td><p>对输入的多维数据进行二维的平均池化运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.MaxPool1d.html#mindspore.nn.MaxPool1d" title="mindspore.nn.MaxPool1d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.MaxPool1d</span></code></a></p></td>
<td><p>对时间数据进行最大池化运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.MaxPool2d.html#mindspore.nn.MaxPool2d" title="mindspore.nn.MaxPool2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.MaxPool2d</span></code></a></p></td>
<td><p>对输入的多维数据进行二维的最大池化运算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="填充层">
<h2>填充层<a class="headerlink" href="#填充层" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Pad.html#mindspore.nn.Pad" title="mindspore.nn.Pad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Pad</span></code></a></p></td>
<td><p>根据 <cite>paddings</cite> 和 <cite>mode</cite> 对输入进行填充。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.ConstantPad1d.html#mindspore.nn.ConstantPad1d" title="mindspore.nn.ConstantPad1d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ConstantPad1d</span></code></a></p></td>
<td><p>将给定的常量填充到多维输入数据的最后一维。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.ConstantPad2d.html#mindspore.nn.ConstantPad2d" title="mindspore.nn.ConstantPad2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ConstantPad2d</span></code></a></p></td>
<td><p>将给定的常量填充到多维输入数据的最后两维。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.ConstantPad3d.html#mindspore.nn.ConstantPad3d" title="mindspore.nn.ConstantPad3d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ConstantPad3d</span></code></a></p></td>
<td><p>将给定的常量填充到多维输入数据的最后三维。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.ReflectionPad1d.html#mindspore.nn.ReflectionPad1d" title="mindspore.nn.ReflectionPad1d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ReflectionPad1d</span></code></a></p></td>
<td><p>根据 <cite>padding</cite> 对输入 <cite>x</cite> 进行填充。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.ReflectionPad2d.html#mindspore.nn.ReflectionPad2d" title="mindspore.nn.ReflectionPad2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ReflectionPad2d</span></code></a></p></td>
<td><p>根据 <cite>padding</cite> 对输入 <cite>x</cite> 进行填充。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.ZeroPad2d.html#mindspore.nn.ZeroPad2d" title="mindspore.nn.ZeroPad2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ZeroPad2d</span></code></a></p></td>
<td><p>将零填充到多维输入数据的最后两维。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="损失函数">
<h2>损失函数<a class="headerlink" href="#损失函数" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.BCELoss.html#mindspore.nn.BCELoss" title="mindspore.nn.BCELoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.BCELoss</span></code></a></p></td>
<td><p>计算目标值和预测值之间的二值交叉熵损失值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.BCEWithLogitsLoss.html#mindspore.nn.BCEWithLogitsLoss" title="mindspore.nn.BCEWithLogitsLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.BCEWithLogitsLoss</span></code></a></p></td>
<td><p>输入经过sigmoid激活函数后作为预测值，<cite>BCEWithLogitsLoss</cite> 计算预测值和目标值之间的二值交叉熵损失。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code>  <code class="docutils literal notranslate"><span class="pre">GPU</span></code>  <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.CosineEmbeddingLoss.html#mindspore.nn.CosineEmbeddingLoss" title="mindspore.nn.CosineEmbeddingLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.CosineEmbeddingLoss</span></code></a></p></td>
<td><p>余弦相似度损失函数，用于测量两个Tensor之间的相似性。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.CrossEntropyLoss.html#mindspore.nn.CrossEntropyLoss" title="mindspore.nn.CrossEntropyLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.CrossEntropyLoss</span></code></a></p></td>
<td><p>计算预测值和目标值之间的交叉熵损失。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.DiceLoss.html#mindspore.nn.DiceLoss" title="mindspore.nn.DiceLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.DiceLoss</span></code></a></p></td>
<td><p>Dice系数是一个集合相似性loss，用于计算两个样本之间的相似性。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.FocalLoss.html#mindspore.nn.FocalLoss" title="mindspore.nn.FocalLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.FocalLoss</span></code></a></p></td>
<td><p>FocalLoss函数解决了类别不平衡的问题。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.HuberLoss.html#mindspore.nn.HuberLoss" title="mindspore.nn.HuberLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.HuberLoss</span></code></a></p></td>
<td><p>HuberLoss计算预测值和目标值之间的误差。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.L1Loss.html#mindspore.nn.L1Loss" title="mindspore.nn.L1Loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.L1Loss</span></code></a></p></td>
<td><p>L1Loss用于计算预测值和目标值之间的平均绝对误差。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.MSELoss.html#mindspore.nn.MSELoss" title="mindspore.nn.MSELoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.MSELoss</span></code></a></p></td>
<td><p>用于计算预测值与标签值之间的均方误差。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.MultiClassDiceLoss.html#mindspore.nn.MultiClassDiceLoss" title="mindspore.nn.MultiClassDiceLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.MultiClassDiceLoss</span></code></a></p></td>
<td><p>对于多标签问题，可以将标签通过one-hot编码转换为多个二分类标签。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.NLLLoss.html#mindspore.nn.NLLLoss" title="mindspore.nn.NLLLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.NLLLoss</span></code></a></p></td>
<td><p>计算预测值和目标值之间的负对数似然损失。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.RMSELoss.html#mindspore.nn.RMSELoss" title="mindspore.nn.RMSELoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.RMSELoss</span></code></a></p></td>
<td><p>RMSELoss用来测量 <span class="math notranslate nohighlight">\(x\)</span> 和 <span class="math notranslate nohighlight">\(y\)</span> 元素之间的均方根误差，其中 <span class="math notranslate nohighlight">\(x\)</span> 是输入Tensor， <span class="math notranslate nohighlight">\(y\)</span> 是目标值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.SampledSoftmaxLoss.html#mindspore.nn.SampledSoftmaxLoss" title="mindspore.nn.SampledSoftmaxLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.SampledSoftmaxLoss</span></code></a></p></td>
<td><p>抽样交叉熵损失函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.SmoothL1Loss.html#mindspore.nn.SmoothL1Loss" title="mindspore.nn.SmoothL1Loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.SmoothL1Loss</span></code></a></p></td>
<td><p>SmoothL1损失函数，如果预测值和目标值的逐个元素绝对误差小于设定阈值 <cite>beta</cite> 则用平方项，否则用绝对误差项。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.SoftMarginLoss.html#mindspore.nn.SoftMarginLoss" title="mindspore.nn.SoftMarginLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.SoftMarginLoss</span></code></a></p></td>
<td><p>针对二分类问题的损失函数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.SoftmaxCrossEntropyWithLogits.html#mindspore.nn.SoftmaxCrossEntropyWithLogits" title="mindspore.nn.SoftmaxCrossEntropyWithLogits"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.SoftmaxCrossEntropyWithLogits</span></code></a></p></td>
<td><p>计算预测值与真实值之间的交叉熵。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="优化器">
<h2>优化器<a class="headerlink" href="#优化器" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Adadelta.html#mindspore.nn.Adadelta" title="mindspore.nn.Adadelta"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Adadelta</span></code></a></p></td>
<td><p>Adadelta算法的实现。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Adagrad.html#mindspore.nn.Adagrad" title="mindspore.nn.Adagrad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Adagrad</span></code></a></p></td>
<td><p>Adagrad算法的实现。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Adam.html#mindspore.nn.Adam" title="mindspore.nn.Adam"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Adam</span></code></a></p></td>
<td><p>Adaptive Moment Estimation (Adam)算法的实现。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code>  <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.AdaMax.html#mindspore.nn.AdaMax" title="mindspore.nn.AdaMax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.AdaMax</span></code></a></p></td>
<td><p>AdaMax算法是基于无穷范数的Adam的一种变体。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.AdamOffload.html#mindspore.nn.AdamOffload" title="mindspore.nn.AdamOffload"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.AdamOffload</span></code></a></p></td>
<td><p>此优化器在主机CPU上运行Adam优化算法，设备上仅执行网络参数的更新，最大限度地降低内存成本。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.AdamWeightDecay.html#mindspore.nn.AdamWeightDecay" title="mindspore.nn.AdamWeightDecay"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.AdamWeightDecay</span></code></a></p></td>
<td><p>权重衰减Adam算法的实现。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.AdaSumByDeltaWeightWrapCell.html#mindspore.nn.AdaSumByDeltaWeightWrapCell" title="mindspore.nn.AdaSumByDeltaWeightWrapCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.AdaSumByDeltaWeightWrapCell</span></code></a></p></td>
<td><p>Adaptive Summation (AdaSum)算法的实现，根据更新前后的参数差计算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.AdaSumByGradWrapCell.html#mindspore.nn.AdaSumByGradWrapCell" title="mindspore.nn.AdaSumByGradWrapCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.AdaSumByGradWrapCell</span></code></a></p></td>
<td><p>Adaptive Summation (AdaSum)算法的实现，根据梯度计算。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.ASGD.html#mindspore.nn.ASGD" title="mindspore.nn.ASGD"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ASGD</span></code></a></p></td>
<td><p>Implements Average Stochastic Gradient Descent.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.FTRL.html#mindspore.nn.FTRL" title="mindspore.nn.FTRL"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.FTRL</span></code></a></p></td>
<td><p>FTRL算法实现。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Lamb.html#mindspore.nn.Lamb" title="mindspore.nn.Lamb"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Lamb</span></code></a></p></td>
<td><p>LAMB（Layer-wise Adaptive Moments optimizer for Batching training，用于批训练的分层自适应矩优化器）算法的实现。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.LARS.html#mindspore.nn.LARS" title="mindspore.nn.LARS"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.LARS</span></code></a></p></td>
<td><p>LARS算法的实现。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.LazyAdam.html#mindspore.nn.LazyAdam" title="mindspore.nn.LazyAdam"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.LazyAdam</span></code></a></p></td>
<td><p>Adaptive Moment Estimation (Adam)算法的实现。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Momentum.html#mindspore.nn.Momentum" title="mindspore.nn.Momentum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Momentum</span></code></a></p></td>
<td><p>Momentum算法的实现。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.ProximalAdagrad.html#mindspore.nn.ProximalAdagrad" title="mindspore.nn.ProximalAdagrad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ProximalAdagrad</span></code></a></p></td>
<td><p>ProximalAdagrad算法的实现。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code>  <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.RMSProp.html#mindspore.nn.RMSProp" title="mindspore.nn.RMSProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.RMSProp</span></code></a></p></td>
<td><p>均方根传播（RMSProp）算法的实现。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Rprop.html#mindspore.nn.Rprop" title="mindspore.nn.Rprop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Rprop</span></code></a></p></td>
<td><p>Implements Resilient backpropagation.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.SGD.html#mindspore.nn.SGD" title="mindspore.nn.SGD"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.SGD</span></code></a></p></td>
<td><p>随机梯度下降的实现。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.thor.html#mindspore.nn.thor" title="mindspore.nn.thor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.thor</span></code></a></p></td>
<td><p>通过二阶算法THOR更新参数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="评价指标">
<h2>评价指标<a class="headerlink" href="#评价指标" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Accuracy.html#mindspore.nn.Accuracy" title="mindspore.nn.Accuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Accuracy</span></code></a></p></td>
<td><p>计算数据分类的正确率，包括二分类和多分类。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.auc.html#mindspore.nn.auc" title="mindspore.nn.auc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.auc</span></code></a></p></td>
<td><p>使用梯形法则计算曲线下面积AUC（Area Under the Curve，AUC）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.BleuScore.html#mindspore.nn.BleuScore" title="mindspore.nn.BleuScore"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.BleuScore</span></code></a></p></td>
<td><p>计算BLEU分数。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.ConfusionMatrix.html#mindspore.nn.ConfusionMatrix" title="mindspore.nn.ConfusionMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ConfusionMatrix</span></code></a></p></td>
<td><p>计算混淆矩阵(confusion matrix)，通常用于评估分类模型的性能，包括二分类和多分类场景。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.ConfusionMatrixMetric.html#mindspore.nn.ConfusionMatrixMetric" title="mindspore.nn.ConfusionMatrixMetric"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ConfusionMatrixMetric</span></code></a></p></td>
<td><p>计算与混淆矩阵相关的度量。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.CosineSimilarity.html#mindspore.nn.CosineSimilarity" title="mindspore.nn.CosineSimilarity"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.CosineSimilarity</span></code></a></p></td>
<td><p>计算余弦相似度。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Dice.html#mindspore.nn.Dice" title="mindspore.nn.Dice"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Dice</span></code></a></p></td>
<td><p>集合相似性度量。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.F1.html#mindspore.nn.F1" title="mindspore.nn.F1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.F1</span></code></a></p></td>
<td><p>计算F1 score。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Fbeta.html#mindspore.nn.Fbeta" title="mindspore.nn.Fbeta"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Fbeta</span></code></a></p></td>
<td><p>计算Fbeta评分。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.HausdorffDistance.html#mindspore.nn.HausdorffDistance" title="mindspore.nn.HausdorffDistance"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.HausdorffDistance</span></code></a></p></td>
<td><p>计算Hausdorff距离。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.get_metric_fn.html#mindspore.nn.get_metric_fn" title="mindspore.nn.get_metric_fn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.get_metric_fn</span></code></a></p></td>
<td><p>根据输入的 <cite>name</cite> 获取metric的方法。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Loss.html#mindspore.nn.Loss" title="mindspore.nn.Loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Loss</span></code></a></p></td>
<td><p>计算loss的平均值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.MAE.html#mindspore.nn.MAE" title="mindspore.nn.MAE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.MAE</span></code></a></p></td>
<td><p>计算平均绝对误差MAE（Mean Absolute Error）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.MeanSurfaceDistance.html#mindspore.nn.MeanSurfaceDistance" title="mindspore.nn.MeanSurfaceDistance"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.MeanSurfaceDistance</span></code></a></p></td>
<td><p>计算从 <cite>y_pred</cite> 到 <cite>y</cite> 的平均表面距离。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Metric.html#mindspore.nn.Metric" title="mindspore.nn.Metric"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Metric</span></code></a></p></td>
<td><p>用于计算评估指标的基类。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.MSE.html#mindspore.nn.MSE" title="mindspore.nn.MSE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.MSE</span></code></a></p></td>
<td><p>测量均方差MSE（Mean Squared Error）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.names.html#mindspore.nn.names" title="mindspore.nn.names"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.names</span></code></a></p></td>
<td><p>获取所有metric的名称。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.OcclusionSensitivity.html#mindspore.nn.OcclusionSensitivity" title="mindspore.nn.OcclusionSensitivity"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.OcclusionSensitivity</span></code></a></p></td>
<td><p>用于计算神经网络对给定图像的遮挡灵敏度（Occlusion Sensitivity），表示了图像的哪些部分对神经网络的分类决策最重要。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Perplexity.html#mindspore.nn.Perplexity" title="mindspore.nn.Perplexity"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Perplexity</span></code></a></p></td>
<td><p>计算困惑度（perplexity）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Precision.html#mindspore.nn.Precision" title="mindspore.nn.Precision"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Precision</span></code></a></p></td>
<td><p>计算数据分类的精度，包括单标签场景和多标签场景。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Recall.html#mindspore.nn.Recall" title="mindspore.nn.Recall"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Recall</span></code></a></p></td>
<td><p>计算数据分类的召回率，包括单标签场景和多标签场景。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.ROC.html#mindspore.nn.ROC" title="mindspore.nn.ROC"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ROC</span></code></a></p></td>
<td><p>计算ROC曲线。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.RootMeanSquareDistance.html#mindspore.nn.RootMeanSquareDistance" title="mindspore.nn.RootMeanSquareDistance"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.RootMeanSquareDistance</span></code></a></p></td>
<td><p>计算从 <cite>y_pred</cite> 到 <cite>y</cite> 的均方根表面距离。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.rearrange_inputs.html#mindspore.nn.rearrange_inputs" title="mindspore.nn.rearrange_inputs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.rearrange_inputs</span></code></a></p></td>
<td><p>此装饰器用于根据类的 <cite>indexes</cite> 属性对输入重新排列。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Top1CategoricalAccuracy.html#mindspore.nn.Top1CategoricalAccuracy" title="mindspore.nn.Top1CategoricalAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Top1CategoricalAccuracy</span></code></a></p></td>
<td><p>计算top-1分类正确率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Top5CategoricalAccuracy.html#mindspore.nn.Top5CategoricalAccuracy" title="mindspore.nn.Top5CategoricalAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Top5CategoricalAccuracy</span></code></a></p></td>
<td><p>计算top-5分类正确率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.TopKCategoricalAccuracy.html#mindspore.nn.TopKCategoricalAccuracy" title="mindspore.nn.TopKCategoricalAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.TopKCategoricalAccuracy</span></code></a></p></td>
<td><p>计算top-k分类正确率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="动态学习率">
<h2>动态学习率<a class="headerlink" href="#动态学习率" title="Permalink to this headline"></a></h2>
<section id="learningrateschedule类">
<h3>LearningRateSchedule类<a class="headerlink" href="#learningrateschedule类" title="Permalink to this headline"></a></h3>
<p>本模块中的动态学习率都是LearningRateSchedule的子类，将LearningRateSchedule的实例传递给优化器。在训练过程中，优化器以当前step为输入调用该实例，得到当前的学习率。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="n">min_lr</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">max_lr</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">decay_steps</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">cosine_decay_lr</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CosineDecayLR</span><span class="p">(</span><span class="n">min_lr</span><span class="p">,</span> <span class="n">max_lr</span><span class="p">,</span> <span class="n">decay_steps</span><span class="p">)</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">cosine_decay_lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.CosineDecayLR.html#mindspore.nn.CosineDecayLR" title="mindspore.nn.CosineDecayLR"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.CosineDecayLR</span></code></a></p></td>
<td><p>基于余弦衰减函数计算学习率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.ExponentialDecayLR.html#mindspore.nn.ExponentialDecayLR" title="mindspore.nn.ExponentialDecayLR"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ExponentialDecayLR</span></code></a></p></td>
<td><p>基于指数衰减函数计算学习率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.InverseDecayLR.html#mindspore.nn.InverseDecayLR" title="mindspore.nn.InverseDecayLR"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.InverseDecayLR</span></code></a></p></td>
<td><p>基于逆时衰减函数计算学习率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.NaturalExpDecayLR.html#mindspore.nn.NaturalExpDecayLR" title="mindspore.nn.NaturalExpDecayLR"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.NaturalExpDecayLR</span></code></a></p></td>
<td><p>基于自然指数衰减函数计算学习率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.PolynomialDecayLR.html#mindspore.nn.PolynomialDecayLR" title="mindspore.nn.PolynomialDecayLR"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.PolynomialDecayLR</span></code></a></p></td>
<td><p>基于多项式衰减函数计算学习率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.WarmUpLR.html#mindspore.nn.WarmUpLR" title="mindspore.nn.WarmUpLR"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.WarmUpLR</span></code></a></p></td>
<td><p>预热学习率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="dynamic-lr函数">
<h3>Dynamic LR函数<a class="headerlink" href="#dynamic-lr函数" title="Permalink to this headline"></a></h3>
<p>本模块中的动态学习率都是function，调用function并将结果传递给优化器。在训练过程中，优化器将result[current step]作为当前学习率。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="n">min_lr</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">max_lr</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">total_step</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">step_per_epoch</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">decay_epoch</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">lr</span><span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">cosine_decay_lr</span><span class="p">(</span><span class="n">min_lr</span><span class="p">,</span> <span class="n">max_lr</span><span class="p">,</span> <span class="n">total_step</span><span class="p">,</span> <span class="n">step_per_epoch</span><span class="p">,</span> <span class="n">decay_epoch</span><span class="p">)</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.cosine_decay_lr.html#mindspore.nn.cosine_decay_lr" title="mindspore.nn.cosine_decay_lr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.cosine_decay_lr</span></code></a></p></td>
<td><p>基于余弦衰减函数计算学习率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.exponential_decay_lr.html#mindspore.nn.exponential_decay_lr" title="mindspore.nn.exponential_decay_lr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.exponential_decay_lr</span></code></a></p></td>
<td><p>基于指数衰减函数计算学习率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.inverse_decay_lr.html#mindspore.nn.inverse_decay_lr" title="mindspore.nn.inverse_decay_lr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.inverse_decay_lr</span></code></a></p></td>
<td><p>基于逆时衰减函数计算学习率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.natural_exp_decay_lr.html#mindspore.nn.natural_exp_decay_lr" title="mindspore.nn.natural_exp_decay_lr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.natural_exp_decay_lr</span></code></a></p></td>
<td><p>基于自然指数衰减函数计算学习率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.piecewise_constant_lr.html#mindspore.nn.piecewise_constant_lr" title="mindspore.nn.piecewise_constant_lr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.piecewise_constant_lr</span></code></a></p></td>
<td><p>获取分段常量学习率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.polynomial_decay_lr.html#mindspore.nn.polynomial_decay_lr" title="mindspore.nn.polynomial_decay_lr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.polynomial_decay_lr</span></code></a></p></td>
<td><p>基于多项式衰减函数计算学习率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.warmup_lr.html#mindspore.nn.warmup_lr" title="mindspore.nn.warmup_lr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.warmup_lr</span></code></a></p></td>
<td><p>预热学习率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="图像处理层">
<h2>图像处理层<a class="headerlink" href="#图像处理层" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.CentralCrop.html#mindspore.nn.CentralCrop" title="mindspore.nn.CentralCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.CentralCrop</span></code></a></p></td>
<td><p>根据指定比例裁剪出图像的中心区域。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.ImageGradients.html#mindspore.nn.ImageGradients" title="mindspore.nn.ImageGradients"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ImageGradients</span></code></a></p></td>
<td><p>计算每个颜色通道的图像渐变，返回为两个Tensor，分别表示高和宽方向上的变化率。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.MSSSIM.html#mindspore.nn.MSSSIM" title="mindspore.nn.MSSSIM"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.MSSSIM</span></code></a></p></td>
<td><p>多尺度计算两个图像之间的结构相似性（SSIM）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.PSNR.html#mindspore.nn.PSNR" title="mindspore.nn.PSNR"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.PSNR</span></code></a></p></td>
<td><p>在批处理中计算两个图像的峰值信噪比（PSNR）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.ResizeBilinear.html#mindspore.nn.ResizeBilinear" title="mindspore.nn.ResizeBilinear"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ResizeBilinear</span></code></a></p></td>
<td><p>使用双线性插值调整输入Tensor为指定的大小。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.SSIM.html#mindspore.nn.SSIM" title="mindspore.nn.SSIM"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.SSIM</span></code></a></p></td>
<td><p>计算两个图像之间的结构相似性（SSIM）。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="矩阵处理">
<h2>矩阵处理<a class="headerlink" href="#矩阵处理" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.MatrixDiag.html#mindspore.nn.MatrixDiag" title="mindspore.nn.MatrixDiag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.MatrixDiag</span></code></a></p></td>
<td><p>根据对角线值返回一批对角矩阵。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.MatrixDiagPart.html#mindspore.nn.MatrixDiagPart" title="mindspore.nn.MatrixDiagPart"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.MatrixDiagPart</span></code></a></p></td>
<td><p>返回批对角矩阵的对角线部分。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.MatrixSetDiag.html#mindspore.nn.MatrixSetDiag" title="mindspore.nn.MatrixSetDiag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.MatrixSetDiag</span></code></a></p></td>
<td><p>将输入的对角矩阵的对角线值置换为输入的对角线值。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="工具">
<h2>工具<a class="headerlink" href="#工具" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.ClipByNorm.html#mindspore.nn.ClipByNorm" title="mindspore.nn.ClipByNorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.ClipByNorm</span></code></a></p></td>
<td><p>对输入Tensor的值进行裁剪，使用 <span class="math notranslate nohighlight">\(L_2\)</span> 范数控制梯度。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Flatten.html#mindspore.nn.Flatten" title="mindspore.nn.Flatten"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Flatten</span></code></a></p></td>
<td><p>对输入Tensor的第0维之外的维度进行展平操作。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.L1Regularizer.html#mindspore.nn.L1Regularizer" title="mindspore.nn.L1Regularizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.L1Regularizer</span></code></a></p></td>
<td><p>对权重计算L1正则化。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Norm.html#mindspore.nn.Norm" title="mindspore.nn.Norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Norm</span></code></a></p></td>
<td><p>计算向量的范数，目前包括欧几里得范数，即 <span class="math notranslate nohighlight">\(L_2\)</span>-norm。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.OneHot.html#mindspore.nn.OneHot" title="mindspore.nn.OneHot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.OneHot</span></code></a></p></td>
<td><p>对输入进行one-hot编码并返回。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Range.html#mindspore.nn.Range" title="mindspore.nn.Range"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Range</span></code></a></p></td>
<td><p>根据指定步长在范围[start, limit)中创建数字序列。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Roll.html#mindspore.nn.Roll" title="mindspore.nn.Roll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Roll</span></code></a></p></td>
<td><p>沿轴移动Tensor的元素。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="nn/mindspore.nn.Tril.html#mindspore.nn.Tril" title="mindspore.nn.Tril"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Tril</span></code></a></p></td>
<td><p>返回一个Tensor，指定主对角线以上的元素被置为零。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Triu.html#mindspore.nn.Triu" title="mindspore.nn.Triu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Triu</span></code></a></p></td>
<td><p>返回一个Tensor，指定主对角线以下的元素被置为0。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="数学运算">
<h2>数学运算<a class="headerlink" href="#数学运算" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 60%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>接口名</p></td>
<td><p>概述</p></td>
<td><p>支持平台</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="nn/mindspore.nn.Moments.html#mindspore.nn.Moments" title="mindspore.nn.Moments"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mindspore.nn.Moments</span></code></a></p></td>
<td><p>沿指定轴 <cite>axis</cite> 计算输入 <cite>x</cite> 的均值和方差。</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p></td>
</tr>
</tbody>
</table>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindspore.mindrecord.html" class="btn btn-neutral float-left" title="mindspore.mindrecord" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="nn/mindspore.nn.Cell.html" class="btn btn-neutral float-right" title="mindspore.nn.Cell" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>