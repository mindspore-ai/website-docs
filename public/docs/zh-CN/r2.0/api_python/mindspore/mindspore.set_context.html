

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mindspore.set_context &mdash; MindSpore master 文档</title>
  

  
  <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/training.css" type="text/css" />
   
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script src="../../_static/js/training.js"></script>
        <script src="../../_static/translations.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="mindspore.get_context" href="mindspore.get_context.html" />
    <link rel="prev" title="mindspore.QuantDtype" href="mindspore.QuantDtype.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">设计</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../design/overview.html">MindSpore设计概览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/programming_paradigm.html">编程范式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/auto_gradient.html">函数式微分编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/mindir.html">中间表示MindIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/all_scenarios.html">全场景统一</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/dynamic_graph_and_static_graph.html">动静态图结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/pluggable_device.html">三方硬件对接</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/distributed_training_design.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/graph_fusion_engine.html">图算融合加速引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/glossary.html">术语</a></li>
</ul>
<p class="caption"><span class="caption-text">模型库</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/official_models.html">官方模型库</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../mindspore.html">mindspore</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#数据表达">数据表达</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../mindspore.html#运行环境">运行环境</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">mindspore.set_context</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.get_context.html">mindspore.get_context</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.set_auto_parallel_context.html">mindspore.set_auto_parallel_context</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.get_auto_parallel_context.html">mindspore.get_auto_parallel_context</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.reset_auto_parallel_context.html">mindspore.reset_auto_parallel_context</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.ParallelMode.html">mindspore.ParallelMode</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.set_ps_context.html">mindspore.set_ps_context</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.get_ps_context.html">mindspore.get_ps_context</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.reset_ps_context.html">mindspore.reset_ps_context</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.set_algo_parameters.html">mindspore.set_algo_parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.get_algo_parameters.html">mindspore.get_algo_parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.reset_algo_parameters.html">mindspore.reset_algo_parameters</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#随机种子">随机种子</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#序列化">序列化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#自动微分">自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#并行优化">并行优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#即时编译">即时编译</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#工具">工具</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r2.0/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption"><span class="caption-text">API映射</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/pytorch_api_mapping.html">PyTorch与MindSpore API映射表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/tensorflow_api_mapping.html">TensorFlow与MindSpore API映射表</a></li>
</ul>
<p class="caption"><span class="caption-text">迁移指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/overview.html">迁移指南概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/enveriment_preparation.html">环境准备与资料获取</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/analysis_and_preparation.html">模型分析与准备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/model_development/model_development.html">MindSpore网络搭建</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/debug_and_tune.html">调试调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/sample_code.html">网络迁移调试实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/faq.html">常见问题</a></li>
</ul>
<p class="caption"><span class="caption-text">语法支持</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax_support.html">静态图语法支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/index_support.html">Tensor索引支持</a></li>
</ul>
<p class="caption"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq/installation.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/data_processing.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/implement_problem.html">执行问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/network_compilation.html">网络编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/usage_migrate_3rd.html">第三方框架迁移使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/distributed_parallel.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/feature_advice.html">特性咨询</a></li>
</ul>
<p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../RELEASE.html">Release Notes</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../mindspore.html">mindspore</a> &raquo;</li>
        
      <li>mindspore.set_context</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/api_python/mindspore/mindspore.set_context.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="mindspore-set-context">
<h1>mindspore.set_context<a class="headerlink" href="#mindspore-set-context" title="永久链接至标题">¶</a></h1>
<dl class="function">
<dt id="mindspore.set_context">
<code class="sig-prename descclassname">mindspore.</code><code class="sig-name descname">set_context</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/context.html#set_context"><span class="viewcode-link">[源代码]</span></a><a class="headerlink" href="#mindspore.set_context" title="打开链接">¶</a></dt>
<dd><p>设置运行环境的context。</p>
<p>在运行程序之前，应配置context。如果没有配置，默认情况下将根据设备目标进行自动设置。</p>
<div class="admonition note">
<p class="admonition-title">说明</p>
<p>设置属性时，必须输入属性名称。net初始化后不建议更改模式，因为一些操作的实现在Graph模式和PyNative模式下是不同的。默认值：PYNATIVE_MODE。</p>
</div>
<p>某些配置适用于特定的设备，有关详细信息，请参见下表：</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 30%" />
<col style="width: 36%" />
<col style="width: 34%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>功能分类</p></th>
<th class="head"><p>配置参数</p></th>
<th class="head"><p>硬件平台支持</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td rowspan="6"><p>系统配置</p></td>
<td><p>device_id</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>device_target</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-even"><td><p>max_device_memory</p></td>
<td><p>GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>variable_memory_max_size</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-even"><td><p>mempool_block_size</p></td>
<td><p>GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>op_timeout</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-even"><td rowspan="10"><p>调试配置</p></td>
<td><p>save_graphs</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>save_graphs_path</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-even"><td><p>enable_dump</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>save_dump_path</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-even"><td><p>deterministic</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>print_file_path</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-even"><td><p>env_config_path</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>precompile_only</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-even"><td><p>reserve_class_name_in_scope</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>pynative_synchronize</p></td>
<td><p>GPU/Ascend</p></td>
</tr>
<tr class="row-even"><td rowspan="16"><p>执行控制</p></td>
<td><p>mode</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>enable_graph_kernel</p></td>
<td><p>Ascend/GPU</p></td>
</tr>
<tr class="row-even"><td><p>graph_kernel_flags</p></td>
<td><p>Ascend/GPU</p></td>
</tr>
<tr class="row-odd"><td><p>enable_reduce_precision</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-even"><td><p>check_bprop</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>max_call_depth</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-even"><td><p>grad_for_scalar</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>enable_compile_cache</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-even"><td><p>inter_op_parallel_num</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>runtime_num_threads</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-even"><td><p>compile_cache_path</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>disable_format_transform</p></td>
<td><p>GPU</p></td>
</tr>
<tr class="row-even"><td><p>support_binary</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>memory_optimize_level</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-even"><td><p>memory_offload</p></td>
<td><p>GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>ascend_config</p></td>
<td><p>Ascend</p></td>
</tr>
</tbody>
</table>
<dl class="simple">
<dt>参数：</dt><dd><ul>
<li><p><strong>device_id</strong> (int) - 表示目标设备的ID，其值必须在[0, device_num_per_host-1]范围中，且 <cite>device_num_per_host</cite> 的值不应超过4096。默认值：0。</p></li>
<li><p><strong>device_target</strong> (str) - 表示待运行的目标设备，支持 ‘Ascend’、 ‘GPU’和 ‘CPU’。如果未设置此参数，则使用MindSpore包对应的后端设备。</p></li>
<li><p><strong>max_device_memory</strong> (str) - 设置设备可用的最大内存。格式为”xxGB”。默认值：1024GB。实际使用的内存大小是设备的可用内存和 <cite>max_device_memory</cite> 值中的最小值。</p></li>
<li><p><strong>variable_memory_max_size</strong> (str) - 此参数已弃用，将被删除。请使用 <cite>max_device_memory</cite> 。</p></li>
<li><p><strong>mempool_block_size</strong> (str) - 设置设备内存池的块大小。格式为”xxGB”。默认值：1GB。最小值是1GB。实际使用的内存池块大小是设备的可用内存和 <cite>mempool_block_size</cite> 值中的最小值。</p></li>
<li><p><strong>op_timeout</strong> (int) - 设置一个算子的最大执行时间，以秒为单位。如果执行时间超过这个值，系统将终止该任务。0意味着无限等待。默认值：1900。</p></li>
<li><p><strong>save_graphs</strong> (bool 或 int) - 表示是否保存中间编译图。默认值：0。可用的选项为：</p>
<ul class="simple">
<li><p>False或0：不保存中间编译图。</p></li>
<li><p>1：运行时会输出图编译过程中生成的一些中间文件。</p></li>
<li><p>True或2：生成更多后端流程相关的ir文件。</p></li>
<li><p>3：生成可视化计算图和更多详细的前端ir图。</p></li>
</ul>
<p>当 <cite>save_graphs</cite> 属性设为1、2、3或者True时， <cite>save_graphs_path</cite> 属性用于设置中间编译图的存储路径。默认情况下，计算图保存在当前目录下。</p>
</li>
<li><p><strong>save_graphs_path</strong> (str) - 表示保存计算图的路径。默认值：”.”。如果指定的目录不存在，系统将自动创建该目录。在分布式训练中，图形将被保存到 <cite>save_graphs_path/rank_${rank_id}/</cite> 目录下。 <cite>rank_id</cite> 为集群中当前设备的ID。</p></li>
<li><p><strong>enable_dump</strong> (bool) - 此参数已弃用，将在下一版本中删除。</p></li>
<li><p><strong>save_dump_path</strong> (str) - 此参数已弃用，将在下一版本中删除。</p></li>
<li><p><strong>deterministic</strong> (str) - 表示是否使能算子确定性运行模式。值必须在[‘ON’,’OFF’]范围内，默认值：’OFF’。</p>
<ul class="simple">
<li><p>ON：开启算子确定性运行模式。</p></li>
<li><p>OFF：关闭算子确定性运行模式。</p></li>
</ul>
<p>当确定性开启时，模型中的算子将在Ascend中具有确定性。这意味着，如果算子在同一硬件上使用相同的输入运行多次，则每次都会有完全相同的输出。这对于调试模型很有用。</p>
</li>
<li><p><strong>print_file_path</strong> (str) - 该路径用于保存打印数据。使用时 <a class="reference internal" href="../ops/mindspore.ops.Print.html#mindspore.ops.Print" title="mindspore.ops.Print"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.Print</span></code></a> 可以打印输入的张量或字符串信息，使用方法 <a class="reference internal" href="mindspore.parse_print.html#mindspore.parse_print" title="mindspore.parse_print"><code class="xref py py-func docutils literal notranslate"><span class="pre">mindspore.parse_print()</span></code></a> 解析保存的文件。如果设置了此参数，打印数据保存到文件，未设置将显示到屏幕。如果保存的文件已经存在，则将添加时间戳后缀到文件中。将数据保存到文件解决了屏幕打印中的数据丢失问题，如果未设置，将报告错误:”prompt to set the upper absolute path”。</p></li>
<li><p><strong>env_config_path</strong> (str) - 通过 <cite>mindspore.set_context(env_config_path=”./mindspore_config.json”)</cite> 来设置MindSpore环境配置文件路径。</p>
<p>配置Running Data Recorder：</p>
<ul class="simple">
<li><p><strong>enable</strong>：表示在发生故障时是否启用Running Data Recorder去收集和保存训练中的关键数据。设置为True时，将打开Running Data Recorder。设置为False时，将关闭Running Data Recorder。</p></li>
<li><p><strong>mode</strong>：设置导出数据时的RDR模式。当设置为1时，RDR只在故障情况下输出数据。当设置为2时，RDR在故障情况和正常结束情况下输出数据。默认值：1。</p></li>
<li><p><strong>path</strong>：设置Running Data Recorder保存数据的路径。当前路径必须是一个绝对路径。</p></li>
</ul>
<p>内存重用：</p>
<ul class="simple">
<li><p><strong>mem_Reuse</strong>：表示内存复用功能是否打开。设置为True时，将打开内存复用功能。设置为False时，将关闭内存复用功能。
有关running data recoder和内存复用配置详细信息，请查看 <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r2.0/debug/custom_debug.html">配置RDR和内存复用</a>。</p></li>
</ul>
</li>
<li><p><strong>precompile_only</strong> (bool) - 表示是否仅预编译网络。默认值：False。设置为True时，仅编译网络，而不执行网络。</p></li>
<li><p><strong>reserve_class_name_in_scope</strong> (bool) - 表示是否将网络类名称保存到所属ScopeName中。默认值：True。每个节点都有一个ScopeName。子节点的ScopeName是其父节点。如果 <cite>reserve_class_name_in_scope</cite> 设置为True，则类名将保存在ScopeName中的关键字”net-“之后。例如：</p>
<p>Default/net-Net1/net-Net2 (reserve_class_name_in_scope=True)</p>
<p>Default/net/net (reserve_class_name_in_scope=False)</p>
</li>
<li><p><strong>pynative_synchronize</strong> (bool) - 表示是否在PyNative模式下启动设备同步执行。默认值：False。设置为False时，将在设备上异步执行算子。当算子执行出错时，将无法定位特定错误脚本代码的位置。当设置为True时，将在设备上同步执行算子。这将降低程序的执行性能。此时，当算子执行出错时，可以根据错误的调用栈来定位错误脚本代码的位置。</p></li>
<li><p><strong>mode</strong> (int) - 表示在GRAPH_MODE(0)或PYNATIVE_MODE(1)模式中运行，两种模式都支持所有后端。默认值：PYNATIVE_MODE。</p></li>
<li><p><strong>enable_graph_kernel</strong> (bool) - 表示开启图算融合去优化网络执行性能。默认值：False。如果 <cite>enable_graph_kernel</cite> 设置为True，则可以启用加速。有关图算融合的详细信息，请查看 <a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r2.0/design/graph_fusion_engine.html">使能图算融合</a> 。</p></li>
<li><p><strong>graph_kernel_flags</strong> (str) - 图算融合的优化选项，当与enable_graph_kernel冲突时，它的优先级更高。其仅适用于有经验的用户。例如，mindspore.set_context(graph_kernel_flags=”–opt_level=2 –dump_as_text”)。一些常用选项：</p>
<ul>
<li><p><strong>opt_level</strong>：设置优化级别。默认值：2。当opt_level的值大于0时，启动图算融合。可选值包括：</p>
<ul class="simple">
<li><p>0：关闭图算融合。</p></li>
<li><p>1：启动算子的基本融合。</p></li>
<li><p>2：包括级别1的所有优化，并打开更多的优化，如CSE优化算法、算术简化等。</p></li>
<li><p>3：包括级别2的所有优化，并打开更多的优化，如SitchingFusion、ParallelFusion等。在某些场景下，该级别的优化激进且不稳定。使用此级别时要小心。</p></li>
</ul>
</li>
<li><p><strong>dump_as_text</strong>：将关键过程的详细信息生成文本文件保存到”graph_kernel_dump”目录里。默认值：False。</p>
<p>有关更多选项，可以参考实现代码。</p>
</li>
</ul>
</li>
<li><p><strong>enable_reduce_precision</strong> (bool) - 表示是否开启降低精度计算。默认值：True。设置为True时，不支持用户指定的精度，且精度将自动更改。设置为False时，如果未指定用例的精度，则会报错并退出。</p></li>
<li><p><strong>check_bprop</strong> (bool) - 表示是否检查反向传播节点，以确保反向传播节点输出的形状(shape)和数据类型与输入参数相同。默认值：False。</p></li>
<li><p><strong>max_call_depth</strong> (int) - 指定函数调用的最大深度。其值必须为正整数。默认值：1000。当嵌套Cell太深或子图数量太多时，需要设置 <cite>max_call_depth</cite> 参数。系统最大堆栈深度应随着 <cite>max_call_depth</cite> 的调整而设置为更大的值，否则可能会因为系统堆栈溢出而引发 “core dumped” 异常。</p></li>
<li><p><strong>grad_for_scalar</strong> (bool) - 表示是否获取标量梯度。默认值：False。当 <cite>grad_for_scalar</cite> 设置为True时，则可以导出函数的标量输入。由于后端目前不支持伸缩操作，所以该接口只支持在前端可推演的简单操作。</p></li>
<li><p><strong>enable_compile_cache</strong> (bool) - 表示是否加载或者保存前端编译的图。当 <cite>enable_compile_cache</cite> 被设置为True时，在第一次执行的过程中，一个硬件无关的编译缓存会被生成并且导出为一个MINDIR文件。当该网络被再次执行时，如果 <cite>enable_compile_cache</cite> 仍然为True并且网络脚本没有被更改，那么这个编译缓存会被加载。注意目前只支持有限的Python脚本更改的自动检测，这意味着可能有正确性风险。默认值：False。这是一个实验特性，可能会被更改或者删除。</p></li>
<li><p><strong>compile_cache_path</strong> (str) - 保存编译缓存的路径。默认值：”.”。如果目录不存在，系统会自动创建这个目录。缓存会被保存到如下目录： <cite>compile_cache_path/rank_${rank_id}/</cite> 。 <cite>rank_id</cite> 是集群上当前设备的ID。</p></li>
<li><p><strong>inter_op_parallel_num</strong> (int) - 算子间并行数控制。 默认值为0，表示由框架默认指定。</p></li>
<li><p><strong>runtime_num_threads</strong> (int) - 运行时actor和CPU算子核使用的线程池线程数，必须大于等于0。默认值为30，如果同时运行多个进程，应将该值设置得小一些，以避免线程争用。</p></li>
<li><p><strong>disable_format_transform</strong> (bool) - 表示是否取消NCHW到NHWC的自动格式转换功能。当fp16的网络性能不如fp32的时，可以设置 <cite>disable_format_transform</cite> 为True，以尝试提高训练性能。默认值：False。</p></li>
<li><p><strong>support_binary</strong> (bool) - 是否支持在图形模式下运行.pyc或.so。如果要支持在图形模式下运行.so或.pyc，可将 <cite>support_binary</cite> 置为True，并运行一次.py文件，从而将接口源码保存到接口定义.py文件中，因此要保证该文件可写。然后将.py文件编译成.pyc或.so文件，即可在图模式下运行。</p></li>
<li><p><strong>memory_optimize_level</strong> (str) - 内存优化级别，默认值：O0。其值必须在 [‘O0’, ‘O1’] 范围中。</p>
<ul class="simple">
<li><p>O0: 执行性能优先，关闭 SOMAS (Safe Optimized Memory Allocation Solver)。</p></li>
<li><p>O1: 内存性能优先，使能 SOMAS。</p></li>
</ul>
</li>
<li><p><strong>memory_offload</strong> (str) - 是否开启Offload功能，在内存不足场景下将空闲数据临时拷贝至Host侧内存。其值必须在[‘ON’, ‘OFF’]范围中，默认值为 ‘OFF’。</p>
<ul class="simple">
<li><p>ON：开启memory offload功能。在Ascend硬件平台，未设置环境变量“GRAPH_OP_RUN=1”时本参数不生效；设置memory_optimize_level=’O1’时本参数不生效。</p></li>
<li><p>OFF：关闭memory offload功能。</p></li>
</ul>
</li>
<li><p><strong>ascend_config</strong> (dict) - 设置Ascend硬件平台专用的参数，默认不设置。其中precision_mode和jit_compile当前只仅支持在Ascend910B硬件平台设置，其他平台不生效。
precision_mode和jit_compile参数的默认值属于实验性质参数，将来可能会发生变化。</p>
<ul class="simple">
<li><p><strong>precision_mode</strong> (str): 混合精度模式设置，Ascend910B硬件平台训练默认值：以CANN设置的默认值为准。推理网络默认值：force_fp16。其值范围如下：</p>
<ul>
<li><p>force_fp16: 当算子既支持float16，又支持float32时，直接选择float16。</p></li>
<li><p>allow_fp32_to_fp16: 当算子不支持float32数据类型时，直接降低精度float16。</p></li>
<li><p>allow_mix_precision: 自动混合精度，针对全网算子，按照内置的优化策略，自动将部分算子的精度降低到float16或bfloat16。</p></li>
<li><p>must_keep_origin_dtype: 保持原图精度。</p></li>
<li><p>force_fp32: 当矩阵计算的算子输入为float16，输出既支持float16又支持float32时，强制转换成float32输出。</p></li>
<li><p>force_lowerprecision: 当算子支持float16或者bfloat16，又支持float32时，直接选择float16或者bfloat16。</p></li>
<li><p>allow_fp32_to_bf16: 当算子不支持float32数据类型时，直接降低精度到bfloat16。</p></li>
<li><p>allow_fp32_to_lowprecision: 当算子不支持float32数据类型时，直接降低精度到float16或者bfloat16。</p></li>
<li><p>allow_mix_precision_fp16: 自动混合精度，针对全网算子，按照内置的优化策略，自动将部分算子的精度降低到float16。</p></li>
<li><p>allow_mix_precision_bf16: 自动混合精度，针对全网算子，按照内置的优化策略，自动将部分算子的精度降低到bfloat16。</p></li>
</ul>
</li>
<li><p><strong>jit_compile</strong> (bool): 表示是否选择在线编译。默认值：以CANN设置的默认值为准。当设置为False时，优先选择系统中已经编译好的算子二进制文件，提升编译性能。</p></li>
<li><p><strong>parallel_speed_up_json_path</strong> (Union[str, None]): 并行加速配置文件，配置项可以参考 <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r2.0/config/parallel_speed_up.json">parallel_speed_up.json</a> 。
当设置为None时，表示不启用。</p>
<ul>
<li><p><strong>recompute_comm_overlap</strong> (bool): 为True时表示开启反向重计算和通信掩盖。默认值：False。</p></li>
<li><p><strong>matmul_grad_comm_overlap</strong> (bool): 为True时表示开启反向Matmul和通信掩盖。默认值：False。</p></li>
<li><p><strong>enable_task_opt</strong> (bool): 为True时表示开启通信算子task数量优化。默认值：False。</p></li>
<li><p><strong>interleaved_matmul_comm</strong> (bool): 为True时表示开启Matmul-Comm的细粒度双副本优化。默认值：False。</p></li>
<li><p><strong>interleaved_layernorm_comm</strong> (bool): 为True时表示开启LayerNorm-Comm细粒度双副本优化。默认值：False。</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>ValueError</strong> - 输入key不是上下文中的属性。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">precompile_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_id</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">save_graphs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_graphs_path</span><span class="o">=</span><span class="s2">&quot;./model.ms&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">enable_reduce_precision</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">enable_graph_kernel</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">graph_kernel_flags</span><span class="o">=</span><span class="s2">&quot;--opt_level=2 --dump_as_text&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">reserve_class_name_in_scope</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">variable_memory_max_size</span><span class="o">=</span><span class="s2">&quot;6GB&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">check_bprop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">max_device_memory</span><span class="o">=</span><span class="s2">&quot;3.5GB&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mempool_block_size</span><span class="o">=</span><span class="s2">&quot;1GB&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">print_file_path</span><span class="o">=</span><span class="s2">&quot;print.pb&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">max_call_depth</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">env_config_path</span><span class="o">=</span><span class="s2">&quot;./env_config.json&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">grad_for_scalar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">enable_compile_cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">compile_cache_path</span><span class="o">=</span><span class="s2">&quot;./cache.ms&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">pynative_synchronize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">runtime_num_threads</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">inter_op_parallel_num</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">disable_format_transform</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">memory_optimize_level</span><span class="o">=</span><span class="s1">&#39;O0&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">memory_offload</span><span class="o">=</span><span class="s1">&#39;ON&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">deterministic</span><span class="o">=</span><span class="s1">&#39;ON&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">ascend_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;precision_mode&quot;</span><span class="p">:</span> <span class="s2">&quot;force_fp16&quot;</span><span class="p">,</span> <span class="s2">&quot;jit_compile&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
</pre></div>
</div>
</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="mindspore.get_context.html" class="btn btn-neutral float-right" title="mindspore.get_context" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="mindspore.QuantDtype.html" class="btn btn-neutral float-left" title="mindspore.QuantDtype" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; 版权所有 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>