<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.ops.Conv3D &mdash; MindSpore master 文档</title>
      <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/js/training.js"></script>
        <script src="../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="mindspore.ops.Conv3DTranspose" href="mindspore.ops.Conv3DTranspose.html" />
    <link rel="prev" title="mindspore.ops.Conv2DTranspose" href="mindspore.ops.Conv2DTranspose.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">设计</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../design/overview.html">MindSpore设计概览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/programming_paradigm.html">编程范式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/auto_gradient.html">函数式微分编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/mindir.html">中间表示MindIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/all_scenarios.html">全场景统一</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/dynamic_graph_and_static_graph.html">动静态图结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/pluggable_device.html">三方硬件对接</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/distributed_training_design.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/graph_fusion_engine.html">图算融合加速引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/glossary.html">术语</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型库</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/official_models.html">官方模型库</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../mindspore.ops.primitive.html">mindspore.ops.primitive</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.primitive.html#算子原语">算子原语</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.primitive.html#装饰器">装饰器</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../mindspore.ops.primitive.html#神经网络层算子">神经网络层算子</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../mindspore.ops.primitive.html#神经网络">神经网络</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.AvgPool.html">mindspore.ops.AvgPool</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.AvgPool3D.html">mindspore.ops.AvgPool3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.BatchNorm.html">mindspore.ops.BatchNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.Conv2D.html">mindspore.ops.Conv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.Conv2DTranspose.html">mindspore.ops.Conv2DTranspose</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">mindspore.ops.Conv3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.Conv3DTranspose.html">mindspore.ops.Conv3DTranspose</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.CTCGreedyDecoder.html">mindspore.ops.CTCGreedyDecoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.Dropout.html">mindspore.ops.Dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.Dropout2D.html">mindspore.ops.Dropout2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.Dropout3D.html">mindspore.ops.Dropout3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.DynamicGRUV2.html">mindspore.ops.DynamicGRUV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.DynamicRNN.html">mindspore.ops.DynamicRNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.EmbeddingLookup.html">mindspore.ops.EmbeddingLookup</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.Flatten.html">mindspore.ops.Flatten</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.FractionalMaxPool3DWithFixedKsize.html">mindspore.ops.FractionalMaxPool3DWithFixedKsize</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.GridSampler2D.html">mindspore.ops.GridSampler2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.GridSampler3D.html">mindspore.ops.GridSampler3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.LayerNorm.html">mindspore.ops.LayerNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.LRN.html">mindspore.ops.LRN</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.LSTM.html">mindspore.ops.LSTM</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.MaxPool.html">mindspore.ops.MaxPool</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.MaxPool3D.html">mindspore.ops.MaxPool3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.MaxPool3DWithArgmax.html">mindspore.ops.MaxPool3DWithArgmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.MaxPoolWithArgmax.html">mindspore.ops.MaxPoolWithArgmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.MaxPoolWithArgmaxV2.html">mindspore.ops.MaxPoolWithArgmaxV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.MaxUnpool2D.html">mindspore.ops.MaxUnpool2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.MaxUnpool3D.html">mindspore.ops.MaxUnpool3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.MirrorPad.html">mindspore.ops.MirrorPad</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.Pad.html">mindspore.ops.Pad</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.Padding.html">mindspore.ops.Padding</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.ResizeBicubic.html">mindspore.ops.ResizeBicubic</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.ResizeBilinear.html">mindspore.ops.ResizeBilinear</a></li>
<li class="toctree-l4"><a class="reference internal" href="mindspore.ops.ResizeNearestNeighbor.html">mindspore.ops.ResizeNearestNeighbor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../mindspore.ops.primitive.html#损失函数">损失函数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mindspore.ops.primitive.html#激活函数">激活函数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mindspore.ops.primitive.html#优化器">优化器</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mindspore.ops.primitive.html#距离函数">距离函数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mindspore.ops.primitive.html#采样算子">采样算子</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mindspore.ops.primitive.html#图像处理">图像处理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mindspore.ops.primitive.html#文本处理">文本处理</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.primitive.html#数学运算算子">数学运算算子</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.primitive.html#tensor操作算子">Tensor操作算子</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.primitive.html#parameter操作算子">Parameter操作算子</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.primitive.html#数据操作算子">数据操作算子</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.primitive.html#通信算子">通信算子</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.primitive.html#调试算子">调试算子</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.primitive.html#稀疏算子">稀疏算子</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.primitive.html#框架算子">框架算子</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.primitive.html#算子信息注册">算子信息注册</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.primitive.html#自定义算子">自定义算子</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.ops.primitive.html#光谱算子">光谱算子</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.mindspore.cn/lite/api/zh-CN/r2.0/api_cpp/mindspore.html">C++ API↗</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API映射</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/pytorch_api_mapping.html">PyTorch与MindSpore API映射表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/tensorflow_api_mapping.html">TensorFlow与MindSpore API映射表</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">迁移指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/overview.html">迁移指南概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/enveriment_preparation.html">环境准备与资料获取</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/analysis_and_preparation.html">模型分析与准备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/model_development/model_development.html">MindSpore网络搭建</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/debug_and_tune.html">调试调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/sample_code.html">网络迁移调试实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/faq.html">常见问题</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">语法支持</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax_support.html">静态图语法支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/index_support.html">Tensor索引支持</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq/installation.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/data_processing.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/implement_problem.html">执行问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/network_compilation.html">网络编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/usage_migrate_3rd.html">第三方框架迁移使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/distributed_parallel.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/feature_advice.html">特性咨询</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../mindspore.ops.primitive.html">mindspore.ops.primitive</a> &raquo;</li>
      <li>mindspore.ops.Conv3D</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/api_python/ops/mindspore.ops.Conv3D.rst.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="mindspore-ops-conv3d">
<h1>mindspore.ops.Conv3D<a class="headerlink" href="#mindspore-ops-conv3d" title="永久链接至标题"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.ops.Conv3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.ops.</span></span><span class="sig-name descname"><span class="pre">Conv3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">out_channel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'valid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'NCDHW'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/ops/operations/nn_ops.html#Conv3D"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.ops.Conv3D" title="打开链接"></a></dt>
<dd><p>3D convolution layer.</p>
<p>Applies a 3D convolution over an input tensor which is typically of shape
<span class="math notranslate nohighlight">\((N, C_{in}, D_{in}, H_{in}, W_{in})\)</span> and output shape
<span class="math notranslate nohighlight">\((N, C_{out}, D_{out}, H_{out}, W_{out})\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is batch size, <span class="math notranslate nohighlight">\(C\)</span> is channel number,
<span class="math notranslate nohighlight">\(D\)</span> is depth, <span class="math notranslate nohighlight">\(H, W\)</span> is feature height and width respectively.
the output value of a layer is calculated as:</p>
<div class="math notranslate nohighlight">
\[\operatorname{out}\left(N_{i}, C_{\text {out}_j}\right)=\operatorname{bias}\left(C_{\text {out}_j}\right)+
\sum_{k=0}^{C_{in}-1} ccor(\text {weight}\left(C_{\text {out}_j}, k\right),
\operatorname{input}\left(N_{i}, k\right))\]</div>
<p>where <span class="math notranslate nohighlight">\(k\)</span> is kernel,
<span class="math notranslate nohighlight">\(ccor\)</span> is the <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a> ,
<span class="math notranslate nohighlight">\(C_{in}\)</span> is the channel number of the input, <span class="math notranslate nohighlight">\(out_{j}\)</span> corresponds to the <span class="math notranslate nohighlight">\(j\)</span>-th channel of
the output and <span class="math notranslate nohighlight">\(j\)</span> is in the range of <span class="math notranslate nohighlight">\([0, C_{out} - 1]\)</span>. <span class="math notranslate nohighlight">\(\text{weight}(C_{\text{out}_j}, k)\)</span>
is a convolution kernel slice with shape
<span class="math notranslate nohighlight">\((\text{kernel_size[0]}, \text{kernel_size[1]}, \text{kernel_size[2]})\)</span>,
where <span class="math notranslate nohighlight">\(\text{kernel_size[0]}\)</span>, <span class="math notranslate nohighlight">\(\text{kernel_size[1]}\)</span> and <span class="math notranslate nohighlight">\(\text{kernel_size[2]}\)</span> are
the depth, height and width of the convolution kernel respectively. <span class="math notranslate nohighlight">\(\text{bias}\)</span> is the bias parameter
and <span class="math notranslate nohighlight">\(\text{X}\)</span> is the input tensor.
The shape of full convolution kernel is
<span class="math notranslate nohighlight">\((C_{out}, C_{in} / \text{groups}, \text{kernel_size[0]}, \text{kernel_size[1]}, \text{kernel_size[2]})\)</span>,
where <cite>groups</cite> is the number of groups to split <cite>input</cite> in the channel dimension.</p>
<p>For more details, please refer to the paper <a class="reference external" href="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf">Gradient Based Learning Applied to Document
Recognition</a> .</p>
<p>If the ‘pad_mode’ is set to be “valid”, the output depth, height and width will be
<span class="math notranslate nohighlight">\(\left \lfloor{1 + \frac{D_{in} + 2 \times \text{padding} - \text{ks_d} -
(\text{ks_d} - 1) \times (\text{dilation} - 1) }{\text{stride}}} \right \rfloor\)</span> and
<span class="math notranslate nohighlight">\(\left \lfloor{1 + \frac{H_{in} + 2 \times \text{padding} - \text{ks_h} -
(\text{ks_h} - 1) \times (\text{dilation} - 1) }{\text{stride}}} \right \rfloor\)</span> and
<span class="math notranslate nohighlight">\(\left \lfloor{1 + \frac{W_{in} + 2 \times \text{padding} - \text{ks_w} -
(\text{ks_w} - 1) \times (\text{dilation} - 1) }{\text{stride}}} \right \rfloor\)</span> respectively. Where
<span class="math notranslate nohighlight">\(dilation\)</span> is Spacing between kernel elements, <span class="math notranslate nohighlight">\(stride\)</span> is The step length of each step,
<span class="math notranslate nohighlight">\(padding\)</span> is zero-padding added to both sides of the input.</p>
<dl class="field-list simple">
<dt class="field-odd">参数</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>out_channel</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(在 Python v3.8)"><em>int</em></a>) – The number of output channel <span class="math notranslate nohighlight">\(C_{out}\)</span>.</p></li>
<li><p><strong>kernel_size</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(在 Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(在 Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(在 Python v3.8)"><em>int</em></a><em>]</em><em>]</em>) – Specifies the depth, height
and width of the 3D convolution window. It can be a single int or a tuple of 3 integers.
Single int means the value is for the depth, height and width
of the kernel. A tuple of 3 ints corresponds to the depth, height and width of the kernel respectively.</p></li>
<li><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(在 Python v3.8)"><em>int</em></a>) – Modes for different convolutions. It is currently not used. Default: 1.</p></li>
<li><p><strong>stride</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(在 Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(在 Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(在 Python v3.8)"><em>int</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – The distance of kernel moving, it can be an int number
that represents the depth, height and width of movement or a tuple of three int numbers that
represent depth, height and width movement respectively. Default: 1.</p></li>
<li><p><strong>pad_mode</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(在 Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – <p>Specifies padding mode. The optional values are
“same”, “valid” and “pad”. Default: “valid”.</p>
<ul>
<li><p>same: Adopts the way of completion. The depth, height and width of the output will be equal to
the input <cite>x</cite> divided by stride. The padding will be evenly calculated in head and tail, top and bottom,
left and right directions possiblily.
Otherwise, the last extra padding will be calculated from the tail, bottom and the right side.
If this mode is set, <cite>pad</cite> must be 0.</p></li>
<li><p>valid: Adopts the way of discarding. The possible largest depth, height and width of output
will be returned without padding. Extra pixels will be discarded. If this mode is set, <cite>pad</cite>
must be 0.</p></li>
<li><p>pad: Implicit paddings on both sides of the input in depth, height and width. The number of <cite>pad</cite> will
be padded to the input Tensor borders. <cite>pad</cite> must be greater than or equal to 0.</p></li>
</ul>
</p></li>
<li><p><strong>pad</strong> (<em>Union</em><em>(</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(在 Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(在 Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(在 Python v3.8)"><em>int</em></a><em>]</em><em>)</em>) – The pad value to be filled. Default: 0. If <cite>pad</cite> is an integer, the paddings of
head, tail, top, bottom, left and right are the same, equal to pad. If <cite>pad</cite> is a tuple of six
integers, the padding of head, tail, top, bottom, left and right equal to pad[0], pad[1], pad[2],
pad[3], pad[4] and pad[5] correspondingly.</p></li>
<li><p><strong>dilation</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(在 Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/library/stdtypes.html#tuple" title="(在 Python v3.8)"><em>tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(在 Python v3.8)"><em>int</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – The data type is int or a tuple of 3 integers
<span class="math notranslate nohighlight">\((dilation_d, dilation_h, dilation_w)\)</span>. Currently, dilation on depth only supports the case of 1
on Ascend backend. Specifies the dilation rate to use for dilated convolution. If set <span class="math notranslate nohighlight">\(k &gt; 1\)</span>,
there will be <span class="math notranslate nohighlight">\(k - 1\)</span> pixels skipped for each sampling location.
The value ranges for the depth, height, and width dimensions are [1, D], [1, H], and [1, W],
respectively. Default: 1.</p></li>
<li><p><strong>group</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(在 Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The number of groups into which the filter is divided. <cite>in_channels</cite>
and <cite>out_channels</cite> must be divisible by <cite>group</cite>. Default: 1.</p></li>
<li><p><strong>data_format</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(在 Python v3.8)"><em>str</em></a>) – The optional value for data format. Currently only support “NCDHW”.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>x</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\((N, C_{in}, D_{in}, H_{in}, W_{in})\)</span>.
Currently input data type only support float16 and float32.</p></li>
<li><p><strong>weight</strong> (Tensor) - Set size of kernel is <span class="math notranslate nohighlight">\((k_d, K_h, K_w)\)</span>, then the shape is
<span class="math notranslate nohighlight">\((C_{out}, C_{in}/groups, k_d, K_h, K_w)\)</span>.
Currently weight data type only support float16 and float32.</p></li>
<li><p><strong>bias</strong> (Tensor) - Tensor of shape <span class="math notranslate nohighlight">\(C_{in}\)</span>. Currently, only support none.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><p>Tensor, the value that applied 3D convolution. The shape is <span class="math notranslate nohighlight">\((N, C_{out}, D_{out}, H_{out}, W_{out})\)</span>.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">异常</dt>
<dd class="field-odd"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(在 Python v3.8)"><strong>TypeError</strong></a> – If <cite>out_channel</cite> or <cite>group</cite> is not an int.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#TypeError" title="(在 Python v3.8)"><strong>TypeError</strong></a> – If <cite>kernel_size</cite>, <cite>stride</cite>, <cite>pad</cite> or <cite>dilation</cite> is neither an int nor a tuple.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(在 Python v3.8)"><strong>ValueError</strong></a> – If <cite>out_channel</cite>, <cite>kernel_size</cite>, <cite>stride</cite> or <cite>dilation</cite> is less than 1.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(在 Python v3.8)"><strong>ValueError</strong></a> – If <cite>pad</cite> is less than 0.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(在 Python v3.8)"><strong>ValueError</strong></a> – If <cite>pad_mode</cite> is not one of ‘same’, ‘valid’ or ‘pad’.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(在 Python v3.8)"><strong>ValueError</strong></a> – If <cite>pad</cite> is a tuple whose length is not equal to 6.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(在 Python v3.8)"><strong>ValueError</strong></a> – If <cite>pad_mode</cite> is not equal to ‘pad’ and <cite>pad</cite> is not equal to (0, 0, 0, 0, 0, 0).</p></li>
<li><p><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(在 Python v3.8)"><strong>ValueError</strong></a> – If <cite>data_format</cite> is not ‘NCDHW’.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Supported Platforms:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Ascend</span></code> <code class="docutils literal notranslate"><span class="pre">GPU</span></code> <code class="docutils literal notranslate"><span class="pre">CPU</span></code></p>
</dd>
</dl>
<p class="rubric">样例</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">weight</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">conv3d</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Conv3D</span><span class="p">(</span><span class="n">out_channel</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">conv3d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(16, 32, 7, 30, 30)</span>
</pre></div>
</div>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindspore.ops.Conv2DTranspose.html" class="btn btn-neutral float-left" title="mindspore.ops.Conv2DTranspose" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="mindspore.ops.Conv3DTranspose.html" class="btn btn-neutral float-right" title="mindspore.ops.Conv3DTranspose" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2022, MindSpore.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
        <script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>