<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.train.Model &mdash; MindSpore master 文档</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script><script src="../../_static/jquery.js"></script>
        <script src="../../_static/js/theme.js"></script><script src="../../_static/underscore.js"></script><script src="../../_static/doctools.js"></script><script src="../../_static/js/training.js"></script><script src="../../_static/translations.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="mindspore.train.BackupAndRestore" href="mindspore.train.BackupAndRestore.html" />
    <link rel="prev" title="mindspore.train" href="../mindspore.train.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">设计</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../design/overview.html">MindSpore设计概览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/programming_paradigm.html">编程范式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/auto_gradient.html">函数式微分编程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/mindir.html">中间表示MindIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/all_scenarios.html">全场景统一</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/dynamic_graph_and_static_graph.html">动静态图结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/pluggable_device.html">三方硬件对接</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/distributed_training_design.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/graph_fusion_engine.html">图算融合加速引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/glossary.html">术语</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型库</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/official_models.html">官方模型库</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../mindspore.train.html">mindspore.train</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../mindspore.train.html#模型">模型</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">mindspore.train.Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.train.html#回调函数">回调函数</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.train.html#评价指标">评价指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.train.html#工具">工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.train.html#二阶优化">二阶优化</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.scipy.html">mindspore.scipy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API映射</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/pytorch_api_mapping.html">PyTorch与MindSpore API映射表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/tensorflow_api_mapping.html">TensorFlow与MindSpore API映射表</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">迁移指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/overview.html">迁移指南概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/enveriment_preparation.html">环境准备与资料获取</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/analysis_and_preparation.html">模型分析与准备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/model_development/model_development.html">MindSpore网络搭建</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/debug_and_tune.html">调试调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/sample_code.html">网络迁移调试实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/faq.html">常见问题</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">语法支持</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax_support.html">静态图语法支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/index_support.html">Tensor索引支持</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq/installation.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/data_processing.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/implement_problem.html">执行问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/network_compilation.html">网络编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/usage_migrate_3rd.html">第三方框架迁移使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/distributed_parallel.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/feature_advice.html">特性咨询</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../mindspore.train.html">mindspore.train</a> &raquo;</li>
      <li>mindspore.train.Model</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/api_python/train/mindspore.train.Model.rst.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="mindspore-train-model">
<h1>mindspore.train.Model<a class="headerlink" href="#mindspore-train-model" title="永久链接至标题"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="mindspore.train.Model">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mindspore.train.</span></span><span class="sig-name descname"><span class="pre">Model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_network</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_indexes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amp_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'O0'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boost_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'O0'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/train/model.html#Model"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.train.Model" title="打开链接"></a></dt>
<dd><p>模型训练或推理的高阶接口。 <cite>Model</cite> 会根据用户传入的参数封装可训练或推理的实例。</p>
<div class="admonition note">
<p class="admonition-title">说明</p>
<p>如果使用混合精度功能，需要同时设置 <cite>optimizer</cite> 参数，否则混合精度功能不生效。
当使用混合精度时，优化器中的 <cite>global_step</cite> 可能与模型中的 <cite>cur_step_num</cite> 不同。</p>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul>
<li><p><strong>network</strong> (Cell) - 用于训练或推理的神经网络。</p></li>
<li><p><strong>loss_fn</strong> (Cell) - 损失函数。如果 <cite>loss_fn</cite> 为None，<cite>network</cite> 中需要进行损失函数计算，必要时也需要进行并行计算。默认值：None。</p></li>
<li><p><strong>optimizer</strong> (Cell) - 用于更新网络权重的优化器。如果 <cite>optimizer</cite> 为None， <cite>network</cite> 中需要进行反向传播和网络权重更新。默认值：None。</p></li>
<li><p><strong>metrics</strong> (Union[dict, set]) - 用于模型评估的一组评价函数。例如：{‘accuracy’, ‘recall’}。默认值：None。</p></li>
<li><p><strong>eval_network</strong> (Cell) - 用于评估的神经网络。未定义情况下，<cite>Model</cite> 会使用 <cite>network</cite> 和 <cite>loss_fn</cite> 封装一个 <cite>eval_network</cite> 。默认值：None。</p></li>
<li><p><strong>eval_indexes</strong> (list) - 在定义 <cite>eval_network</cite> 的情况下使用。如果 <cite>eval_indexes</cite> 为默认值None，<cite>Model</cite> 会将 <cite>eval_network</cite> 的所有输出传给 <cite>metrics</cite> 。如果配置 <cite>eval_indexes</cite> ，必须包含三个元素，分别为损失值、预测值和标签在 <cite>eval_network</cite> 输出中的位置，此时，损失值将传给损失评价函数，预测值和标签将传给其他评价函数。推荐使用评价函数的 <a class="reference internal" href="mindspore.train.Metric.html#mindspore.train.Metric.set_indexes" title="mindspore.train.Metric.set_indexes"><code class="xref py py-func docutils literal notranslate"><span class="pre">mindspore.train.Metric.set_indexes()</span></code></a> 代替 <cite>eval_indexes</cite> 。默认值：None。</p></li>
<li><p><strong>amp_level</strong> (str) - <cite>mindspore.amp.build_train_network</cite> 的可选参数 <cite>level</cite> ， <cite>level</cite> 为混合精度等级，该参数支持[“O0”, “O1”, “O2”, “O3”, “auto”]。默认值：”O0”。</p>
<ul class="simple">
<li><p>“O0”: 不变化。</p></li>
<li><p>“O1”: 将白名单中的算子转为float16，剩余算子保持float32。白名单中的算子如下列表：[Conv1d, Conv2d, Conv3d, Conv1dTranspose, Conv2dTranspose, Conv3dTranspose, Dense, LSTMCell, RNNCell, GRUCell, MatMul, BatchMatMul, PReLU, ReLU, Ger]。</p></li>
<li><p>“O2”: 将网络精度转为float16，BatchNorm保持float32精度，使用动态调整损失缩放系数（loss scale）的策略。</p></li>
<li><p>“O3”: 将网络精度（包括BatchNorm）转为float16，不使用损失缩放策略。</p></li>
<li><p>“auto”: 为不同处理器设置专家推荐的混合精度等级，如在GPU上设为”O2”，在Ascend上设为”O3”。该设置方式可能在部分场景下不适用，建议用户根据具体的网络模型自定义设置 <cite>amp_level</cite> 。</p></li>
</ul>
<p>在GPU上建议使用”O2”，在Ascend上建议使用”O3”。
通过 <cite>kwargs</cite> 设置 <cite>keep_batchnorm_fp32</cite> ，可修改BatchNorm的精度策略， <cite>keep_batchnorm_fp32</cite> 必须为bool类型；通过 <cite>kwargs</cite> 设置 <cite>loss_scale_manager</cite> 可修改损失缩放策略，<cite>loss_scale_manager</cite> 必须为 <a class="reference internal" href="../amp/mindspore.amp.LossScaleManager.html#mindspore.amp.LossScaleManager" title="mindspore.amp.LossScaleManager"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.amp.LossScaleManager</span></code></a> 的子类，
关于 <cite>amp_level</cite> 详见 <cite>mindpore.amp.build_train_network</cite> 。</p>
</li>
<li><p><strong>boost_level</strong> (str) - <cite>mindspore.boost</cite> 的可选参数，为boost模式训练等级。支持[“O0”, “O1”, “O2”]. 默认值：”O0”。</p>
<ul class="simple">
<li><p>“O0”: 不变化。</p></li>
<li><p>“O1”: 启用boost模式，性能将提升约20%，准确率保持不变。</p></li>
<li><p>“O2”: 启用boost模式，性能将提升约30%，准确率下降小于3%。</p></li>
</ul>
<p>如果想自行配置boost模式，可以将 <cite>boost_config_dict</cite> 设置为 <cite>boost.py</cite>。
为使功能生效，需要同时设置optimizer、eval_network或metric参数。
注意：当前默认开启的优化仅适用部分网络，并非所有网络都能获得相同收益。建议在图模式+Ascend平台下开启该模式，同时为了获取更好的加速效果，请参考文档配置boost_config_dict。</p>
</li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Define the network structure of LeNet5. Refer to</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># https://gitee.com/mindspore/docs/blob/r2.0/docs/mindspore/code/lenet.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create the dataset taking MNIST as an example. Refer to</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># https://gitee.com/mindspore/docs/blob/r2.0/docs/mindspore/code/mnist.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.Model.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sink_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/train/model.html#Model.build"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.train.Model.build" title="打开链接"></a></dt>
<dd><p>数据下沉模式下构建计算图和数据图。</p>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>这是一个实验性API，后续可能修改或删除。</p>
</div>
<div class="admonition note">
<p class="admonition-title">说明</p>
<p>如果预先调用该接口构建计算图，那么 <cite>Model.train</cite> 会直接执行计算图。预构建计算图目前仅支持GRAPH_MODE模式和Ascend处理器。仅支持数据下沉模式。</p>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>train_dataset</strong> (Dataset) - 一个训练集迭代器。如果定义了 <cite>train_dataset</cite> ，将会构建训练计算图。默认值：None。</p></li>
<li><p><strong>valid_dataset</strong> (Dataset) - 一个验证集迭代器。如果定义了 <cite>valid_dataset</cite> ，将会构建验证计算图，此时 <cite>Model</cite> 中的 <cite>metrics</cite> 不能为None。默认值：None。</p></li>
<li><p><strong>sink_size</strong> (int) - 控制每次数据下沉的数据量。默认值：-1。</p></li>
<li><p><strong>epoch</strong> (int) - 控制训练轮次。默认值：1。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.amp</span> <span class="kn">import</span> <span class="n">FixedLossScaleManager</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create the dataset taking MNIST as an example. Refer to</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># https://gitee.com/mindspore/docs/blob/r2.0/docs/mindspore/code/mnist.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Define the network structure of LeNet5. Refer to</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># https://gitee.com/mindspore/docs/blob/r2.0/docs/mindspore/code/lenet.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="gp">... </span>                 <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.Model.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">valid_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_sink_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/train/model.html#Model.eval"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.train.Model.eval" title="打开链接"></a></dt>
<dd><p>模型评估接口。</p>
<p>使用PyNative模式或CPU处理器时，模型评估流程将以非下沉模式执行。</p>
<div class="admonition note">
<p class="admonition-title">说明</p>
<p>如果 <cite>dataset_sink_mode</cite> 配置为True，数据将被发送到处理器中。此时数据集与模型绑定，数据集仅能在当前模型中使用。如果处理器是Ascend，数据特征将被逐一传输。每次数据传输的上限是256M。
该接口会构建并执行计算图。如果使用前先执行了 <cite>Model.build</cite> ，那么它会直接执行计算图而不构建。</p>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>valid_dataset</strong> (Dataset) - 评估模型的数据集。</p></li>
<li><p><strong>callbacks</strong> (Optional[list(Callback), Callback]) - 评估过程中需要执行的回调对象或回调对象列表。默认值：None。</p></li>
<li><p><strong>dataset_sink_mode</strong> (bool) - 数据是否直接下沉至处理器进行处理。默认值：False。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>Dict，key是用户定义的评价指标名称，value是以推理模式运行的评估结果。</p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create the dataset taking MNIST as an example. Refer to</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># https://gitee.com/mindspore/docs/blob/r2.0/docs/mindspore/code/mnist.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Define the network structure of LeNet5. Refer to</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># https://gitee.com/mindspore/docs/blob/r2.0/docs/mindspore/code/lenet.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.Model.eval_network">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">eval_network</span></span><a class="headerlink" href="#mindspore.train.Model.eval_network" title="打开链接"></a></dt>
<dd><p>获取该模型的评价网络。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>评估网络实例。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.Model.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_dataset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_frequency</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_sink_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_dataset_sink_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sink_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/train/model.html#Model.fit"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.train.Model.fit" title="打开链接"></a></dt>
<dd><p>模型边训练边推理接口。</p>
<p>如果 <cite>valid_dataset</cite> 不为None，在训练过程中同时执行推理。</p>
<p>更多详细信息请参考 <a class="reference internal" href="#mindspore.train.Model.train" title="mindspore.train.Model.train"><code class="xref py py-func docutils literal notranslate"><span class="pre">mindspore.train.Model.train()</span></code></a> 和 <a class="reference internal" href="#mindspore.train.Model.eval" title="mindspore.train.Model.eval"><code class="xref py py-func docutils literal notranslate"><span class="pre">mindspore.train.Model.eval()</span></code></a>。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>epoch</strong> (int) - 训练执行轮次。通常每个epoch都会使用全量数据集进行训练。当 <cite>dataset_sink_mode</cite> 设置为True且 <cite>sink_size</cite> 大于零时，则每个epoch训练次数为 <cite>sink_size</cite> 而不是数据集的总步数。如果 <cite>epoch</cite> 与 <cite>initial_epoch</cite> 一起使用，它表示训练的最后一个 <cite>epoch</cite> 是多少。</p></li>
<li><p><strong>train_dataset</strong> (Dataset) - 训练数据集迭代器。如果定义了 <cite>loss_fn</cite> ，则数据和标签会被分别传给 <cite>network</cite> 和 <cite>loss_fn</cite> ，此时数据集需要返回一个元组（data, label）。如果数据集中有多个数据或者标签，可以设置 <cite>loss_fn</cite> 为None，并在 <cite>network</cite> 中实现损失函数计算，此时数据集返回的所有数据组成的元组（data1, data2, data3, …）会传给 <cite>network</cite> 。</p></li>
<li><p><strong>valid_dataset</strong> (Dataset) - 评估模型的数据集迭代器。默认值：None。</p></li>
<li><p><strong>valid_frequency</strong> (int, list) - 此参数只有在valid_dataset不为None时生效。如果为int类型，表示执行推理的频率，例如 <cite>valid_frequency=2</cite>，则每2个训练epoch执行一次推理；如果为list类型，指明在哪几个epoch时执行推理，例如 <cite>valid_frequency=[1, 5]</cite>，则在第1个和第5个epoch执行推理。默认值：1。</p></li>
<li><p><strong>callbacks</strong> (Optional[list[Callback], Callback]) - 训练过程中需要执行的回调对象或者回调对象列表。默认值：None。</p></li>
<li><p><strong>dataset_sink_mode</strong> (bool) - 训练数据是否直接下沉至处理器进行处理。使用PYNATIVE_MODE模式或CPU处理器时，模型训练流程将以非下沉模式执行。默认值：False。</p></li>
<li><p><strong>valid_dataset_sink_mode</strong> (bool) - 推理数据是否直接下沉至处理器进行处理。默认值：False。</p></li>
<li><p><strong>sink_size</strong> (int) - 控制每次数据下沉的数据量。<cite>dataset_sink_mode</cite> 为False时 <cite>sink_size</cite> 无效。如果sink_size=-1，则每一次epoch下沉完整数据集。如果sink_size&gt;0，则每一次epoch下沉数据量为sink_size的数据集。默认值：-1。</p></li>
<li><p><strong>initial_epoch</strong> (int) - 从哪个epoch开始训练，一般用于中断恢复训练场景。默认值：0。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create the dataset taking MNIST as an example. Refer to</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># https://gitee.com/mindspore/docs/blob/r2.0/docs/mindspore/code/mnist.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Define the network structure of LeNet5. Refer to</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># https://gitee.com/mindspore/docs/blob/r2.0/docs/mindspore/code/lenet.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;accuracy&quot;</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.Model.infer_predict_layout">
<span class="sig-name descname"><span class="pre">infer_predict_layout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">predict_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_backend_compile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/train/model.html#Model.infer_predict_layout"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.train.Model.infer_predict_layout" title="打开链接"></a></dt>
<dd><p>在 <cite>AUTO_PARALLEL</cite> 或 <cite>SEMI_AUTO_PARALLEL</cite> 模式下为预测网络生成参数layout。数据可以是单个或多个张量。</p>
<div class="admonition note">
<p class="admonition-title">说明</p>
<p>同一批次数据应放在一个张量中。</p>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>predict_data</strong> (Union[Tensor, list[Tensor], tuple[Tensor]], 可选) - 预测样本，数据可以是单个张量、张量列表或张量元组。</p></li>
<li><p><strong>skip_backend_compile</strong> (bool) - 生成参数layout时跳过后端编译流程。一般用于后端编译模型大小超过卡上内存的场景，其它场景不建议开启，开启时本次编译的缓存无法在二次编译时被使用。默认值： <code class="docutils literal notranslate"><span class="pre">False</span></code>。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>Dict，用于加载分布式checkpoint的参数layout字典。它总是作为 <cite>load_distributed_checkpoint()</cite> 函数的一个入参。</p>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>RuntimeError</strong> - 非图模式（GRAPH_MODE）将会抛出该异常。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># This example should be run with multiple devices. Refer to the tutorial &gt; Distributed Training on</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.cn.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">full_batch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parallel_mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">SEMI_AUTO_PARALLEL</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">Net</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">predict_map</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">infer_predict_layout</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.Model.infer_train_layout">
<span class="sig-name descname"><span class="pre">infer_train_layout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_sink_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sink_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/train/model.html#Model.infer_train_layout"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.train.Model.infer_train_layout" title="打开链接"></a></dt>
<dd><p>在 <cite>AUTO_PARALLEL</cite> 或 <cite>SEMI_AUTO_PARALLEL</cite> 模式下为训练网络生成参数layout。当前仅支持在数据下沉模式下使用。</p>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>这是一个实验性API，后续可能修改或删除。</p>
</div>
<div class="admonition note">
<p class="admonition-title">说明</p>
<p>这是一个预编译函数。参数必须与Model.train()函数相同。</p>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>train_dataset</strong> (Dataset) - 一个训练数据集迭代器。如果没有损失函数（loss_fn），返回一个包含多个数据的元组（data1, data2, data3, …）并传递给网络。否则，返回一个元组（data, label），数据和标签将被分别传递给网络和损失函数。</p></li>
<li><p><strong>dataset_sink_mode</strong> (bool) - 决定是否以数据集下沉模式进行训练。默认值：True。PyNative模式下或处理器为CPU时，训练模型流程使用的是数据不下沉（non-sink）模式。默认值：True。</p></li>
<li><p><strong>sink_size</strong> (int) - 控制每次数据下沉的数据量，如果 <cite>sink_size</cite> =-1，则每一次epoch下沉完整数据集。如果 <cite>sink_size</cite> &gt;0，则每一次epoch下沉数据量为 <cite>sink_size</cite> 的数据集。如果 <cite>dataset_sink_mode</cite> 为False，则设置 <cite>sink_size</cite> 为无效。默认值：-1。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>Dict，用于加载分布式checkpoint的参数layout字典。</p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># This example should be run with multiple devices. Refer to the tutorial &gt; Distributed Training on</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># mindspore.cn.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_auto_parallel_context</span><span class="p">(</span><span class="n">parallel_mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">ParallelMode</span><span class="o">.</span><span class="n">SEMI_AUTO_PARALLEL</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create the dataset taking MNIST as an example. Refer to</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># https://gitee.com/mindspore/docs/blob/r2.0/docs/mindspore/code/mnist.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Define the network structure of LeNet5. Refer to</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># https://gitee.com/mindspore/docs/blob/r2.0/docs/mindspore/code/lenet.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">FixedLossScaleManager</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="gp">... </span>                 <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">layout_dict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">infer_train_layout</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.Model.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">predict_data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/train/model.html#Model.predict"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.train.Model.predict" title="打开链接"></a></dt>
<dd><p>输入样本得到预测结果。</p>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>predict_data</strong> (Union[Tensor, list[Tensor], tuple[Tensor]], 可选) - 预测样本，数据可以是单个张量、张量列表或张量元组。</p></li>
</ul>
</dd>
<dt>返回：</dt><dd><p>返回预测结果，类型是Tensor或Tensor元组。</p>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_data</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">Net</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.Model.predict_network">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">predict_network</span></span><a class="headerlink" href="#mindspore.train.Model.predict_network" title="打开链接"></a></dt>
<dd><p>获得该模型的预测网络。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>预测网络实例。</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.Model.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_sink_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sink_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/train/model.html#Model.train"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.train.Model.train" title="打开链接"></a></dt>
<dd><p>模型训练接口。</p>
<p>使用PYNATIVE_MODE模式或CPU处理器时，模型训练流程将以非下沉模式执行。</p>
<div class="admonition note">
<p class="admonition-title">说明</p>
<ul class="simple">
<li><p>如果 <cite>dataset_sink_mode</cite> 配置为True，数据将被送到处理器中。如果处理器是Ascend，数据特征将被逐一传输，每次数据传输的上限是256M。</p></li>
<li><p>如果 <cite>dataset_sink_mode</cite> 配置为True，仅在每个epoch结束时调用Callback实例的step_end方法。</p></li>
<li><p>如果 <cite>dataset_sink_mode</cite> 配置为True，数据集仅能在当前模型中使用。</p></li>
<li><p>如果 <cite>sink_size</cite> 大于零，每次epoch可以无限次遍历数据集，直到遍历数据量等于 <cite>sink_size</cite> 为止。</p></li>
<li><p>每次epoch将从上一次遍历的最后位置继续开始遍历。该接口会构建并执行计算图，如果使用前先执行了 <cite>Model.build</cite> ，那么它会直接执行计算图而不构建。</p></li>
</ul>
</div>
<dl class="simple">
<dt>参数：</dt><dd><ul class="simple">
<li><p><strong>epoch</strong> (int) - 训练执行轮次。通常每个epoch都会使用全量数据集进行训练。当 <cite>dataset_sink_mode</cite> 设置为True且 <cite>sink_size</cite> 大于零时，则每个epoch训练次数为 <cite>sink_size</cite> 而不是数据集的总步数。如果 <cite>epoch</cite> 与 <cite>initial_epoch</cite> 一起使用，它表示训练的最后一个 <cite>epoch</cite> 是多少。</p></li>
<li><p><strong>train_dataset</strong> (Dataset) - 一个训练数据集迭代器。如果定义了 <cite>loss_fn</cite> ，则数据和标签会被分别传给 <cite>network</cite> 和 <cite>loss_fn</cite> ，此时数据集需要返回一个元组（data, label）。如果数据集中有多个数据或者标签，可以设置 <cite>loss_fn</cite> 为None，并在 <cite>network</cite> 中实现损失函数计算，此时数据集返回的所有数据组成的元组（data1, data2, data3, …）会传给 <cite>network</cite> 。</p></li>
<li><p><strong>callbacks</strong> (Optional[list[Callback], Callback]) - 训练过程中需要执行的回调对象或者回调对象列表。默认值：None。</p></li>
<li><p><strong>dataset_sink_mode</strong> (bool) - 数据是否直接下沉至处理器进行处理。使用PYNATIVE_MODE模式或CPU处理器时，模型训练流程将以非下沉模式执行。默认值：False。</p></li>
<li><p><strong>sink_size</strong> (int) - 控制每次数据下沉的数据量。<cite>dataset_sink_mode</cite> 为False时 <cite>sink_size</cite> 无效。如果sink_size=-1，则每一次epoch下沉完整数据集。如果sink_size&gt;0，则每一次epoch下沉数据量为sink_size的数据集。默认值：-1。</p></li>
<li><p><strong>initial_epoch</strong> (int) - 从哪个epoch开始训练，一般用于中断恢复训练场景。默认值：0。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mindspore.train</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create the dataset taking MNIST as an example. Refer to</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># https://gitee.com/mindspore/docs/blob/r2.0/docs/mindspore/code/mnist.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Define the network structure of LeNet5. Refer to</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># https://gitee.com/mindspore/docs/blob/r2.0/docs/mindspore/code/lenet.py</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">FixedLossScaleManager</span><span class="p">(</span><span class="mf">1024.</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="gp">... </span>                 <span class="n">loss_scale_manager</span><span class="o">=</span><span class="n">loss_scale_manager</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mindspore.train.Model.train_network">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">train_network</span></span><a class="headerlink" href="#mindspore.train.Model.train_network" title="打开链接"></a></dt>
<dd><p>获得该模型的训练网络。</p>
<dl class="simple">
<dt>返回：</dt><dd><p>训练网络实例。</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../mindspore.train.html" class="btn btn-neutral float-left" title="mindspore.train" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="mindspore.train.BackupAndRestore.html" class="btn btn-neutral float-right" title="mindspore.train.BackupAndRestore" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2022, MindSpore.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>