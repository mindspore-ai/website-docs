<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>分布式集合通信原语 &mdash; MindSpore master 文档</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script>
      <link rel="stylesheet" href="../../../_static/css/bootstrap.min.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/training.css" type="text/css" /><link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script><script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/js/theme.js"></script><script src="../../../_static/underscore.js"></script><script src="../../../_static/doctools.js"></script><script src="../../../_static/js/training.js"></script><script src="../../../_static/translations.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> MindSpore
          </a>
              <div class="version">
                1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">设计</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../design/overview.html">MindSpore设计概览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/programming_paradigm.html">函数式和对象式融合编程范式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/all_scenarios.html">全场景统一架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/dynamic_graph_and_static_graph.html">动静态图结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/pluggable_device.html">三方硬件对接</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/distributed_training_design.html">原生分布式并行架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/graph_fusion_engine.html">图算融合加速引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../design/glossary.html">术语</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型库</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../note/official_models.html">官方模型库</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mindspore.scipy.html">mindspore.scipy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API映射</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../note/api_mapping/pytorch_api_mapping.html">PyTorch与MindSpore API映射表</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../note/api_mapping/tensorflow_api_mapping.html">TensorFlow与MindSpore API映射表</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">迁移指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/overview.html">迁移指南概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/enveriment_preparation.html">环境准备与资料获取</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/analysis_and_preparation.html">模型分析与准备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/typical_api_comparision.html">与PyTorch典型区别</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/model_development/model_development.html">MindSpore网络搭建</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/debug_and_tune.html">调试调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/sample_code.html">网络迁移调试实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/migrator_with_tools.html">网络迁移工具应用实践指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../migration_guide/faq.html">常见问题</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">语法支持</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../note/static_graph_syntax_support.html">静态图语法支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../note/static_graph_syntax/operators.html">静态图语法——运算符</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../note/static_graph_syntax/statements.html">静态图语法——Python语句</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../note/static_graph_syntax/python_builtin_functions.html">静态图语法——Python内置函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../note/index_support.html">Tensor索引支持</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">环境变量</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../note/env_var_list.html">环境变量</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/installation.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/data_processing.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/implement_problem.html">执行问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/network_compilation.html">网络编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/usage_migrate_3rd.html">第三方框架迁移使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/distributed_parallel.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/feature_advice.html">特性咨询</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>分布式集合通信原语</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/api_python/samples/ops/communicate_ops.md.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="分布式集合通信原语">
<h1>分布式集合通信原语<a class="headerlink" href="#分布式集合通信原语" title="永久链接至标题"></a></h1>
<p><a href="https://gitee.com/mindspore/mindspore/blob/r2.1/docs/api/api_python/samples/ops/communicate_ops.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.1/resource/_static/logo_source.svg"></a></p>
<p>在分布式训练中涉及例如<code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>、<code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code>、<code class="docutils literal notranslate"><span class="pre">AllGather</span></code>和<code class="docutils literal notranslate"><span class="pre">Broadcast</span></code>等通信操作进行数据传输，我们将在下述的章节分别阐述其含义和示例代码。</p>
<p>下述每个章节中给出了使用4张GPU进行不同通信操作的示例。示例中的输出来自于0号卡<code class="docutils literal notranslate"><span class="pre">rank0</span></code>程序的结果。用户需要将下述每个章节代码另存为communication.py。因为涉及到多卡程序，用户需要通过<code class="docutils literal notranslate"><span class="pre">mpirun</span></code>命令去启动communication.py。其中<code class="docutils literal notranslate"><span class="pre">mpirun</span></code>命令需要安装OpenMPI以及NCCL，对应的安装请参考<a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r2.1/parallel/train_gpu.html">此处</a>。准备好communication.py后，在命令行中输入如下启动命令，即可启动多卡程序：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mpirun<span class="w"> </span>-output-filename<span class="w"> </span>log<span class="w"> </span>-merge-stderr-to-stdout<span class="w"> </span>-np<span class="w"> </span><span class="m">4</span><span class="w"> </span>python<span class="w"> </span>communication.py
</pre></div>
</div>
<p>上述代码中的<code class="docutils literal notranslate"><span class="pre">-np</span></code>表示将启动4个进程任务，分别占用0，1，2，3号卡，并且将输出日志保存在<code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>目录下面。用户可以在此查看程序的输出结果。<code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">communication.py</span></code>表示启动脚本。</p>
<section id="allreduce">
<h2>AllReduce<a class="headerlink" href="#allreduce" title="永久链接至标题"></a></h2>
<p><img alt="image" src="../../../_images/allreduce.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>操作会将每卡中<code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>算子的输入Tensor进行求和操作，最终每卡的<code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>算子输出是相同的数值。例如上图所示，每张卡AllReduce算子输入分别为<code class="docutils literal notranslate"><span class="pre">0,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">3</span></code>。经过<code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>之后，每张卡输出的结果为所有卡输入之和为6(0+1+2+3)。</p>
<p>示例代码如下：我们根据rank号(每张卡所属通信编号)初始化每个进程中<code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>算子输入的数值，例如卡0，我们申请了一个1x1大小，数值为0的输入。然后调用<code class="docutils literal notranslate"><span class="pre">AllReduce</span></code>算子，在通信域为<code class="docutils literal notranslate"><span class="pre">0-1-2-3</span></code>的卡(所有卡的通信范围即nccl_world_group)中进行通信，并且打印输出结果。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">init</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_reduce_sum</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">AllReduce</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s2">&quot;nccl_world_group&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">value</span> <span class="o">=</span> <span class="n">get_rank</span><span class="p">()</span>
<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">value</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>其中0卡的运行结果如下，输出日志路径为<code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[6.]]
</pre></div>
</div>
</section>
<section id="allgather">
<h2>AllGather<a class="headerlink" href="#allgather" title="永久链接至标题"></a></h2>
<p><img alt="image" src="../../../_images/allgather.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">AllGather</span></code>操作会将每张卡的输入Tensor的第零维度上进行拼接，最终每张卡输出是相同的数值。例如上图所示，每卡的输入是大小为1x1的Tensor，经过<code class="docutils literal notranslate"><span class="pre">AllGather</span></code>操作之后，每卡<code class="docutils literal notranslate"><span class="pre">AllGather</span></code>算子的输出shape为[4,1]。其中索引为[0,0]的元素值来自于0号卡<code class="docutils literal notranslate"><span class="pre">AllGather</span></code>的输入[[0.0]]，索引为[1,0]的元素值来自于1号卡<code class="docutils literal notranslate"><span class="pre">AllGather</span></code>的输入[[1.0]]。</p>
<p>示例代码如下：我们根据rank号(每张卡所属通信编号)初始化每个进程中<code class="docutils literal notranslate"><span class="pre">AllGather</span></code>算子输入的数值，例如卡0，我们申请了一个1x1大小，数值为0的输入。然后调用<code class="docutils literal notranslate"><span class="pre">AllGather</span></code>算子，在通信域为<code class="docutils literal notranslate"><span class="pre">0-1-2-3</span></code>的卡(所有卡的通信范围即nccl_world_group)中进行通信，并且打印输出结果。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_gather</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">AllGather</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">value</span> <span class="o">=</span> <span class="n">get_rank</span><span class="p">()</span>
<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">value</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果如下，输出日志路径为<code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[0.],
 [1.],
 [2.],
 [3.]]
</pre></div>
</div>
</section>
<section id="reducescatter">
<h2>ReduceScatter<a class="headerlink" href="#reducescatter" title="永久链接至标题"></a></h2>
<p><img alt="image" src="../../../_images/reducescatter.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code>操作会将每张卡的输入先进行求和，然后在第零维度按卡数切分，将数据分发到对应的卡上。例如上图所示，每卡的输入均为4x1的Tensor。<code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code>先对输入求和得到[0, 4, 8, 12]的Tensor，然后进行分发，每卡获得1x1大小的Tensor。例如卡0对应的输出结果为[[0.0]]，卡1对应的输出结果为[[4.0]]。</p>
<p>示例代码如下：我们根据rank号(每张卡所属通信编号)初始化每个进程中<code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code>算子输入的数值，例如卡0，我们申请了一个4x1大小，数值为0的输入。然后调用<code class="docutils literal notranslate"><span class="pre">ReduceScatter</span></code>算子，在通信域为<code class="docutils literal notranslate"><span class="pre">0-1-2-3</span></code>的卡(所有卡的通信范围即nccl_world_group)中进行通信，并且打印输出结果。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span><span class="p">,</span> <span class="n">get_rank</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduce_scatter</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReduceScatter</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduce_scatter</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果如下，输出日志路径为<code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[0.]]
</pre></div>
</div>
</section>
<section id="broadcast">
<h2>Broadcast<a class="headerlink" href="#broadcast" title="永久链接至标题"></a></h2>
<p><img alt="image" src="../../../_images/broadcast.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">Broadcast</span></code>操作是将某张卡的输入广播到其他卡上，常见于参数的初始化。例如上图中，将0卡大小为1x1的Tensor进行广播，最终每张卡输出均为[[0]]。</p>
<p>示例代码如下：我们将<code class="docutils literal notranslate"><span class="pre">Broadcast</span></code>算子的根节点设置为0号卡，表示将从0号卡广播数据到其他卡上。同时申请了一个1x1大小，数值为0的输入。然后调用<code class="docutils literal notranslate"><span class="pre">Broadcast</span></code>算子，在通信域为<code class="docutils literal notranslate"><span class="pre">0-1-2-3</span></code>的卡(所有卡的通信范围即nccl_world_group)中进行通信，最终每张卡的输出数值来自卡0。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">broadcast</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Broadcast</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">broadcast</span><span class="p">((</span><span class="n">x</span><span class="p">,))</span>

<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果如下，输出日志路径为<code class="docutils literal notranslate"><span class="pre">log/1/rank.0</span></code>：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[0]]
</pre></div>
</div>
</section>
<section id="neighborexchange">
<h2>NeighborExchange<a class="headerlink" href="#neighborexchange" title="永久链接至标题"></a></h2>
<p><img alt="image" src="../../../_images/NeighborExchange.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">NeighborExchange</span></code>操作会将提供一组数据分别发往其它特定的卡上，同时从特定的卡接收数据。例如上图中，rank 0 向rank 1发送shape为[16,16]的Tensor，并接收rank 1发送的shape为[32,32]的Tensor；rank 1 向rank 0发送shape为[32,32]的Tensor，并接收rank 0发送的shape为[16,16]的Tensor。最终rank 0输出了接收到的shape为[32,32]的Tensor，rank 1输出接收到的[16,16]的Tensor。</p>
<p>示例代码如下：我们使用<code class="docutils literal notranslate"><span class="pre">NeighborExchange</span></code>算子进行0号卡和1号卡之间的数据交换，将0号卡的数据发送到1号卡，并接收来自1号卡的数据；1号卡将数据发送到0号卡，并接收来自0号卡的数据；最终每张卡输出接收到的数据。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">Net0</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net0</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchange</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NeighborExchange</span><span class="p">(</span><span class="n">send_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">recv_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">recv_shapes</span><span class="o">=</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],),</span> <span class="n">send_shapes</span><span class="o">=</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],),</span> <span class="n">recv_type</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchange</span><span class="p">((</span><span class="n">x</span><span class="p">,))</span>
        <span class="k">return</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">Net1</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net1</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchange</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NeighborExchange</span><span class="p">(</span><span class="n">send_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">recv_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">recv_shapes</span><span class="o">=</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],),</span> <span class="n">send_shapes</span><span class="o">=</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],),</span> <span class="n">recv_type</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchange</span><span class="p">((</span><span class="n">x</span><span class="p">,))</span>
        <span class="k">return</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="n">rank_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;RANK_ID&quot;</span><span class="p">))</span>
<span class="k">if</span> <span class="p">(</span><span class="n">rank_id</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
    <span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net0</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net1</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>使用shell脚本启动2卡脚本，下述中的<code class="docutils literal notranslate"><span class="pre">rank_table_file</span></code>文件可以使用<a class="reference external" href="https://gitee.com/mindspore/models">models</a>下面的hccl_tools.py生成，对应的目录文件为<code class="docutils literal notranslate"><span class="pre">models/utils/hccl_tools</span></code>。示例shell脚本如下：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_HCCL_CONFIG_PATH</span><span class="o">=</span>rank_table_file
<span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_NUM</span><span class="o">=</span><span class="m">2</span>
<span class="nv">BASE_PATH</span><span class="o">=</span><span class="k">$(</span><span class="nb">cd</span><span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>dirname<span class="w"> </span><span class="nv">$0</span><span class="k">)</span><span class="s2">&quot;</span><span class="p">;</span><span class="w"> </span><span class="nb">pwd</span><span class="k">)</span>
<span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i&lt;<span class="nv">$DEVICE_NUM</span><span class="p">;</span><span class="w"> </span>i++<span class="o">))</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>mkdir<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>cp<span class="w"> </span>-r<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/neighborexchange.py<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>/
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">RANK_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;start training for device </span><span class="nv">$i</span><span class="s2">&quot;</span>
<span class="w">    </span>python<span class="w"> </span>neighborexchange.py<span class="w"> </span>&gt;<span class="w"> </span>log.txt<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
<span class="k">done</span>
</pre></div>
</div>
<p>rank0的结果为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[2. 2.]
 [2. 2.]]
</pre></div>
</div>
<p>rank1的结果为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[1. 1. 1.]
 [1. 1. 1.]
 [1. 1. 1.]]
</pre></div>
</div>
</section>
<section id="neighborexchangev2">
<h2>NeighborExchangeV2<a class="headerlink" href="#neighborexchangev2" title="永久链接至标题"></a></h2>
<p><img alt="image" src="../../../_images/neighborexchangev2.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">NeighborExchangeV2</span></code>操作会将Tensor中按照属性设置将部分数据发送给周边的8张卡，且从周边的8张卡中接收数据并拼接成新的Tensor，常用于将大Tensor切分在多卡上进行分布式卷积运算的场景。其中，属性send_rank_ids和recv_rank_ids分别为8个数字，表示8个方向上发送/接收的rank_id，填-1表示不发送/不接收，如上图图二表示对应8个方向上的顺序；属性send_lens和recv_lens分别为4个数字，表示[top, bottom, left, right] 四个方向上的发送/接收长度。例如上图图一中为一个16卡的示例，以图中rank 10为例，设定send_rank_ids=[6,7,11,15,14,13,9,5]，将rank10的数据进行切分后分别向rank 5、6、7、11、15、14、13、9发送了对应部分的数据，例如图中红色发给rank5，红色、黄色和蓝色发给rank6，蓝色发给rank7等；设定recv_rank_ids=[6,7,11,15,14,13,9,5]，则同时rank10从这些卡分别接收了一些数据拼接到对应方向上，组成了新的Tensor输出，例如图中的rank10和浅绿色部分所示。</p>
<p>示例代码如下：我们使用<code class="docutils literal notranslate"><span class="pre">NeighborExchangeV2</span></code>算子进行0号卡和1号卡之间的数据交换，将0号卡的下方的数据发送到1号卡，并接收来自1号卡的数据拼接在下方；1号卡将上方部分数据发送到0号卡，并接收来自0号卡的数据拼接在上方；最终每张卡输出接收到的数据。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">Net0</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net0</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchangev2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NeighborExchangeV2</span><span class="p">(</span><span class="n">send_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">send_lens</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">recv_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">recv_lens</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data_format</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchangev2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="k">class</span> <span class="nc">Net1</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net1</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchangev2</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">NeighborExchangeV2</span><span class="p">(</span><span class="n">send_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">send_lens</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">recv_rank_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">recv_lens</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data_format</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbor_exchangev2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="n">rank_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;RANK_ID&quot;</span><span class="p">))</span>
<span class="k">if</span> <span class="p">(</span><span class="n">rank_id</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
    <span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net0</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net1</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>使用shell脚本启动2卡脚本，下述中的<code class="docutils literal notranslate"><span class="pre">rank_table_file</span></code>文件可以使用<a class="reference external" href="https://gitee.com/mindspore/models">models</a>下面的hccl_tools.py生成，对应的目录文件为<code class="docutils literal notranslate"><span class="pre">models/utils/hccl_tools</span></code>。示例shell脚本如下：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_HCCL_CONFIG_PATH</span><span class="o">=</span>rank_table_file
<span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_NUM</span><span class="o">=</span><span class="m">2</span>
<span class="nv">BASE_PATH</span><span class="o">=</span><span class="k">$(</span><span class="nb">cd</span><span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>dirname<span class="w"> </span><span class="nv">$0</span><span class="k">)</span><span class="s2">&quot;</span><span class="p">;</span><span class="w"> </span><span class="nb">pwd</span><span class="k">)</span>
<span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i&lt;<span class="nv">$DEVICE_NUM</span><span class="p">;</span><span class="w"> </span>i++<span class="o">))</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>mkdir<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>cp<span class="w"> </span>-r<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/neighborexchangev2.py<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>/
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">RANK_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;start training for device </span><span class="nv">$i</span><span class="s2">&quot;</span>
<span class="w">    </span>python<span class="w"> </span>neighborexchangev2.py<span class="w"> </span>&gt;<span class="w"> </span>log.txt<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
<span class="k">done</span>
</pre></div>
</div>
<p>rank 0结果为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[1. 1.]
   [1. 1.]
   [2. 2.]]]]
</pre></div>
</div>
<p>rank 1结果为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[1. 1.]
   [2. 2.]
   [2. 2.]]]]
</pre></div>
</div>
</section>
<section id="alltoall">
<h2>AlltoAll<a class="headerlink" href="#alltoall" title="永久链接至标题"></a></h2>
<p><img alt="image" src="../../../_images/alltoall.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">AlltoAll</span></code>操作会将输入数据在特定的维度切分成特定的块数，并按顺序发送给其他rank，同时从其他rank接收输入，按顺序在特定的维度拼接数据。例如上图中，将Tensor在零维切分成5块，同时接收其它rank的数据，并在一维进行拼接，最后输出拼接后的数据。</p>
<p>示例代码如下：我们使用<code class="docutils literal notranslate"><span class="pre">AlltoAll</span></code>算子进行8卡的数据交换，把每张卡在第-2维进行切分，并按顺序把切分的数据发送给其它卡，同时接收其它卡的数据，在-1维进行拼接；最终每张卡输出拼接后的数据。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore.communication</span> <span class="kn">import</span> <span class="n">init</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_to_all</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">AlltoAll</span><span class="p">(</span><span class="n">split_count</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">split_dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="n">concat_dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_to_all</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="s1">&#39;Ascend&#39;</span><span class="p">)</span>
<span class="n">init</span><span class="p">()</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">rank_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;RANK_ID&quot;</span><span class="p">))</span>
<span class="n">input_x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">rank_id</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<p>使用shell脚本启动8卡脚本，下述中的<code class="docutils literal notranslate"><span class="pre">rank_table_file</span></code>文件可以使用<a class="reference external" href="https://gitee.com/mindspore/models">models</a>下面的hccl_tools.py生成，对应的目录文件为<code class="docutils literal notranslate"><span class="pre">models/utils/hccl_tools</span></code>。示例shell脚本如下：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">MINDSPORE_HCCL_CONFIG_PATH</span><span class="o">=</span>rank_table_file
<span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_NUM</span><span class="o">=</span><span class="m">8</span>
<span class="nv">BASE_PATH</span><span class="o">=</span><span class="k">$(</span><span class="nb">cd</span><span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>dirname<span class="w"> </span><span class="nv">$0</span><span class="k">)</span><span class="s2">&quot;</span><span class="p">;</span><span class="w"> </span><span class="nb">pwd</span><span class="k">)</span>
<span class="k">for</span><span class="o">((</span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i&lt;<span class="nv">$DEVICE_NUM</span><span class="p">;</span><span class="w"> </span>i++<span class="o">))</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span>rm<span class="w"> </span>-rf<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>mkdir<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span>cp<span class="w"> </span>-r<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/alltoall.py<span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>/
<span class="w">    </span><span class="nb">cd</span><span class="w"> </span><span class="si">${</span><span class="nv">BASE_PATH</span><span class="si">}</span>/rank<span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">RANK_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">export</span><span class="w"> </span><span class="nv">DEVICE_ID</span><span class="o">=</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;start training for device </span><span class="nv">$i</span><span class="s2">&quot;</span>
<span class="w">    </span>python<span class="w"> </span>alltoall.py<span class="w"> </span>&gt;<span class="w"> </span>log.txt<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">&amp;</span>
<span class="k">done</span>
</pre></div>
</div>
<p>rank0~rank7的结果为：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[[[0. 1. 2. 3. 4. 5. 6. 7.]]]]
</pre></div>
</div>
</section>
<section id="注意事项">
<h2>注意事项<a class="headerlink" href="#注意事项" title="永久链接至标题"></a></h2>
<p>在昇腾芯片上，NeighborExchange、NeighborExchangeV2、AlltoAll这三个算子需要进行全连接配网。</p>
<p>全连接配网支持任意卡之间进行通信，没有数量限制。全连接配网方式可参考<a class="reference external" href="https://support.huawei.com/enterprise/zh/ascend-computing/a300t-9000-pid-250702906?category=developer-documents">HCCN Tool 接口参考</a>进行配置。全连接配网时，所有卡需要VLan ID相同、IP在同一网段，配置到其他卡的静态路由表和ARP。其中，<strong>VLan ID需要在交换机上进行配置</strong>，其他IP等改动的单机8卡配置参考样例如下：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># 配置IP到同一网段</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-ip<span class="w"> </span>-s<span class="w"> </span>address<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>netmask<span class="w"> </span><span class="m">255</span>.255.255.0

<span class="c1"># 策略路由</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>table<span class="w"> </span><span class="m">100</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>table<span class="w"> </span><span class="m">101</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>table<span class="w"> </span><span class="m">102</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>table<span class="w"> </span><span class="m">103</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>table<span class="w"> </span><span class="m">104</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>table<span class="w"> </span><span class="m">105</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>table<span class="w"> </span><span class="m">106</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-ip_rule<span class="w"> </span>-a<span class="w"> </span>dir<span class="w"> </span>from<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>table<span class="w"> </span><span class="m">107</span>

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>table<span class="w"> </span><span class="m">100</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>dev<span class="w"> </span>eth1<span class="w"> </span>table<span class="w"> </span><span class="m">101</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>dev<span class="w"> </span>eth2<span class="w"> </span>table<span class="w"> </span><span class="m">102</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>dev<span class="w"> </span>eth3<span class="w"> </span>table<span class="w"> </span><span class="m">103</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>dev<span class="w"> </span>eth4<span class="w"> </span>table<span class="w"> </span><span class="m">104</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>dev<span class="w"> </span>eth5<span class="w"> </span>table<span class="w"> </span><span class="m">105</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>dev<span class="w"> </span>eth6<span class="w"> </span>table<span class="w"> </span><span class="m">106</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-ip_route<span class="w"> </span>-a<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.0<span class="w"> </span>ip_mask<span class="w"> </span><span class="m">24</span><span class="w"> </span>via<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>dev<span class="w"> </span>eth7<span class="w"> </span>table<span class="w"> </span><span class="m">107</span>

<span class="c1"># 静态ARP</span>
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:16
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:15
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">0</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:14

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth1<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:17
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth1<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:15
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">1</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth1<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:14

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth2<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:17
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth2<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:16
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">2</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth2<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.103<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:14

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth3<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.100<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:17
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth3<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.101<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:16
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">3</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth3<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.102<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:15

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth4<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0e
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth4<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0d
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">4</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth4<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0c

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth5<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0f
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth5<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0d
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">5</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth5<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0c

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth6<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0f
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth6<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0e
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">6</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth6<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.107<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0c

hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth7<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.104<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0f
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth7<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.105<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0e
hccn_tool<span class="w"> </span>-i<span class="w"> </span><span class="m">7</span><span class="w"> </span>-arp<span class="w"> </span>-a<span class="w"> </span>dev<span class="w"> </span>eth7<span class="w"> </span>ip<span class="w"> </span><span class="m">192</span>.98.92.106<span class="w"> </span>mac<span class="w"> </span><span class="m">78</span>:b4:6a:f4:4c:0d
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 MindSpore.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>