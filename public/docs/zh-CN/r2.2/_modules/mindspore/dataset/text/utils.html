<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.dataset.text.utils &mdash; MindSpore master 文档</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script><script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/js/theme.js"></script><script src="../../../../_static/underscore.js"></script><script src="../../../../_static/doctools.js"></script><script src="../../../../_static/translations.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="索引" href="../../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">设计</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/overview.html">MindSpore设计概览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/programming_paradigm.html">函数式和对象式融合编程范式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/dynamic_graph_and_static_graph.html">动静态图结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/distributed_training_design.html">分布式并行原生</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/all_scenarios.html">全场景统一架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/graph_fusion_engine.html">图算融合加速引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/pluggable_device.html">三方硬件对接</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design/glossary.html">术语</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型库</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/official_models.html">官方模型库</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api_python/mindspore.experimental.html">mindspore.experimental</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API映射</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/api_mapping/pytorch_api_mapping.html">PyTorch与MindSpore API映射表</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">迁移指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/overview.html">迁移指南概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/enveriment_preparation.html">环境准备与资料获取</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/analysis_and_preparation.html">模型分析与准备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/typical_api_comparision.html">PyTorch对比</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/model_development/model_development.html">MindSpore网络搭建</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/debug_and_tune.html">调试调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/sample_code.html">网络迁移调试实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/migrator_with_tools.html">网络迁移工具应用实践指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../migration_guide/faq.html">常见问题</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">语法支持</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/static_graph_syntax_support.html">静态图语法支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/static_graph_syntax/operators.html">静态图语法-运算符</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/static_graph_syntax/statements.html">静态图语法-Python语句</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/static_graph_syntax/python_builtin_functions.html">静态图语法-Python内置函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/index_support.html">Tensor索引支持</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">环境变量</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../note/env_var_list.html">环境变量</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/installation.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/data_processing.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/implement_problem.html">执行问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/network_compilation.html">网络编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/usage_migrate_3rd.html">第三方框架迁移使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/distributed_parallel.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq/feature_advice.html">特性咨询</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../index.html">模块代码</a> &raquo;</li>
      <li>mindspore.dataset.text.utils</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>mindspore.dataset.text.utils 源代码</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2020-2021 Huawei Technologies Co., Ltd</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1"># http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">The module text.utils provides some general methods for NLP text processing.</span>
<span class="sd">For example, you can use Vocab to build a dictionary,</span>
<span class="sd">use to_bytes and to_str to encode and decode strings into a specified format.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">IntEnum</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">mindspore._c_dataengine</span> <span class="k">as</span> <span class="nn">cde</span>
<span class="kn">from</span> <span class="nn">.validators</span> <span class="kn">import</span> <span class="n">check_vocab</span><span class="p">,</span> <span class="n">check_from_file</span><span class="p">,</span> <span class="n">check_from_list</span><span class="p">,</span> <span class="n">check_from_dict</span><span class="p">,</span> <span class="n">check_from_dataset</span><span class="p">,</span> \
    <span class="n">check_from_dataset_sentencepiece</span><span class="p">,</span> <span class="n">check_from_file_sentencepiece</span><span class="p">,</span> <span class="n">check_save_model</span><span class="p">,</span> \
    <span class="n">check_from_file_vectors</span><span class="p">,</span> <span class="n">check_tokens_to_ids</span><span class="p">,</span> <span class="n">check_ids_to_tokens</span>


<div class="viewcode-block" id="CharNGram"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.CharNGram.html#mindspore.dataset.text.CharNGram">[文档]</a><span class="k">class</span> <span class="nc">CharNGram</span><span class="p">(</span><span class="n">cde</span><span class="o">.</span><span class="n">CharNGram</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    CharNGram pre-trained word embeddings.</span>

<span class="sd">    A word or sentence is represented using a character n-gram count vector, followed by a single</span>
<span class="sd">    nonlinear transformation to yield a low-dimensional embedding.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="CharNGram.from_file"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.CharNGram.html#mindspore.dataset.text.CharNGram.from_file">[文档]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@check_from_file_vectors</span>
    <span class="k">def</span> <span class="nf">from_file</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">file_path</span><span class="p">,</span> <span class="n">max_vectors</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load the CharNGram pre-training vector set file.</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): Path to the CharNGram pre-training vector set file.</span>
<span class="sd">            max_vectors (int, optional): The upper limit on the number of pre-trained vectors to load.</span>
<span class="sd">                Most pre-trained vector sets are sorted in the descending order of word frequency. Thus, in</span>
<span class="sd">                situations where the entire set doesn&#39;t fit in memory, or is not needed for another reason,</span>
<span class="sd">                this value can limit the size of the loaded set. Default: ``None``, no upper limit.</span>

<span class="sd">        Returns:</span>
<span class="sd">            CharNGram, CharNGram pre-training vectors.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `file_path` is not of type str.</span>
<span class="sd">            RuntimeError: If `file_path` does not exist or is not accessible.</span>
<span class="sd">            TypeError: If `max_vectors` is not of type int.</span>
<span class="sd">            ValueError: If `max_vectors` is negative.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset.text as text</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; char_n_gram = text.CharNGram.from_file(&quot;/path/to/char_n_gram/file&quot;, max_vectors=None)</span>
<span class="sd">            &gt;&gt;&gt; to_vectors = text.ToVectors(char_n_gram)</span>
<span class="sd">            &gt;&gt;&gt; # Look up a token into vectors according CharNGram model.</span>
<span class="sd">            &gt;&gt;&gt; word_vector = to_vectors([&quot;word1&quot;, &quot;word2&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">max_vectors</span> <span class="o">=</span> <span class="n">max_vectors</span> <span class="k">if</span> <span class="n">max_vectors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">max_vectors</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="FastText"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.FastText.html#mindspore.dataset.text.FastText">[文档]</a><span class="k">class</span> <span class="nc">FastText</span><span class="p">(</span><span class="n">cde</span><span class="o">.</span><span class="n">FastText</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    FastText pre-trained word embeddings.</span>

<span class="sd">    FastText allows one to create an unsupervised learning or supervised learning algorithm vector</span>
<span class="sd">    representations for words.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="FastText.from_file"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.FastText.html#mindspore.dataset.text.FastText.from_file">[文档]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@check_from_file_vectors</span>
    <span class="k">def</span> <span class="nf">from_file</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">file_path</span><span class="p">,</span> <span class="n">max_vectors</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load the FastText pre-training vector set file.</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): Path to the FastText pre-trained vector set file. File suffix should be `*.vec`.</span>
<span class="sd">            max_vectors (int, optional): The upper limit on the number of pre-trained vectors to load.</span>
<span class="sd">                Most pre-trained vector sets are sorted in the descending order of word frequency. Thus, in</span>
<span class="sd">                situations where the entire set doesn&#39;t fit in memory, or is not needed for another reason,</span>
<span class="sd">                this value can limit the size of the loaded set. Default: ``None``, no upper limit.</span>

<span class="sd">        Returns:</span>
<span class="sd">            FastText, FastText pre-training vectors.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `file_path` is not of type str.</span>
<span class="sd">            RuntimeError: If `file_path` does not exist or is not accessible.</span>
<span class="sd">            TypeError: If `max_vectors` is not of type int.</span>
<span class="sd">            ValueError: If `max_vectors` is negative.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset.text as text</span>
<span class="sd">            &gt;&gt;&gt; fast_text = text.FastText.from_file(&quot;/path/to/fast_text/file&quot;, max_vectors=None)</span>
<span class="sd">            &gt;&gt;&gt; to_vectors = text.ToVectors(fast_text)</span>
<span class="sd">            &gt;&gt;&gt; # Look up a token into vectors according FastText model.</span>
<span class="sd">            &gt;&gt;&gt; word_vector = to_vectors([&quot;word1&quot;, &quot;word2&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">max_vectors</span> <span class="o">=</span> <span class="n">max_vectors</span> <span class="k">if</span> <span class="n">max_vectors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">max_vectors</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="GloVe"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.GloVe.html#mindspore.dataset.text.GloVe">[文档]</a><span class="k">class</span> <span class="nc">GloVe</span><span class="p">(</span><span class="n">cde</span><span class="o">.</span><span class="n">GloVe</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Global Vectors (GloVe) pre-trained word embeddings.</span>

<span class="sd">    GloVe is an unsupervised learning algorithm for obtaining vector representations for word.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="GloVe.from_file"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.GloVe.html#mindspore.dataset.text.GloVe.from_file">[文档]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@check_from_file_vectors</span>
    <span class="k">def</span> <span class="nf">from_file</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">file_path</span><span class="p">,</span> <span class="n">max_vectors</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load the GloVe pre-training vector set file.</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): Path to the GloVe pre-training vector set file. File name is similar to `glove.*.txt`.</span>
<span class="sd">            max_vectors (int, optional): The upper limit on the number of pre-trained vectors to load.</span>
<span class="sd">                Most pre-trained vector sets are sorted in the descending order of word frequency. Thus, in</span>
<span class="sd">                situations where the entire set doesn&#39;t fit in memory, or is not needed for another reason,</span>
<span class="sd">                this value can limit the size of the loaded set. Default: ``None``, no upper limit.</span>

<span class="sd">        Returns:</span>
<span class="sd">            GloVe, GloVe pre-training vectors.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `file_path` is not of type str.</span>
<span class="sd">            RuntimeError: If `file_path` does not exist or is not accessible.</span>
<span class="sd">            TypeError: If `max_vectors` is not of type int.</span>
<span class="sd">            ValueError: If `max_vectors` is negative.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset.text as text</span>
<span class="sd">            &gt;&gt;&gt; glove = text.GloVe.from_file(&quot;/path/to/glove/file&quot;, max_vectors=None)</span>
<span class="sd">            &gt;&gt;&gt; to_vectors = text.ToVectors(glove)</span>
<span class="sd">            &gt;&gt;&gt; # Look up a token into vectors according GloVe model.</span>
<span class="sd">            &gt;&gt;&gt; word_vector = to_vectors([&quot;word1&quot;, &quot;word2&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">max_vectors</span> <span class="o">=</span> <span class="n">max_vectors</span> <span class="k">if</span> <span class="n">max_vectors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">max_vectors</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="JiebaMode"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.JiebaMode.html#mindspore.dataset.text.JiebaMode">[文档]</a><span class="k">class</span> <span class="nc">JiebaMode</span><span class="p">(</span><span class="n">IntEnum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    An enumeration for :class:`mindspore.dataset.text.JiebaTokenizer` .</span>

<span class="sd">    Possible enumeration values are: ``JiebaMode.MIX``, ``JiebaMode.MP``, ``JiebaMode.HMM``.</span>

<span class="sd">    - JiebaMode.MIX: tokenize with a mix of MPSegment and HMMSegment algorithm.</span>
<span class="sd">    - JiebaMode.MP: tokenize with MPSegment algorithm.</span>
<span class="sd">    - JiebaMode.HMM: tokenize with Hidden Markov Model Segment algorithm.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">MIX</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">MP</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">HMM</span> <span class="o">=</span> <span class="mi">2</span></div>


<div class="viewcode-block" id="NormalizeForm"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.NormalizeForm.html#mindspore.dataset.text.NormalizeForm">[文档]</a><span class="k">class</span> <span class="nc">NormalizeForm</span><span class="p">(</span><span class="n">IntEnum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    `Unicode normalization forms &lt;http://unicode.org/reports/tr15/&gt;`_ .</span>

<span class="sd">    Available values are as follows:</span>

<span class="sd">    - NormalizeForm.NONE: No normalization.</span>
<span class="sd">    - NormalizeForm.NFC: Canonical Decomposition, followed by Canonical Composition.</span>
<span class="sd">    - NormalizeForm.NFKC: Compatibility Decomposition, followed by Canonical Composition.</span>
<span class="sd">    - NormalizeForm.NFD: Canonical Decomposition.</span>
<span class="sd">    - NormalizeForm.NFKD: Compatibility Decomposition.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">NONE</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">NFC</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">NFKC</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">NFD</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">NFKD</span> <span class="o">=</span> <span class="mi">4</span></div>


<div class="viewcode-block" id="SentencePieceModel"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.SentencePieceModel.html#mindspore.dataset.text.SentencePieceModel">[文档]</a><span class="k">class</span> <span class="nc">SentencePieceModel</span><span class="p">(</span><span class="n">IntEnum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Subword algorithms for SentencePiece.</span>

<span class="sd">    Available values are as follows:</span>

<span class="sd">    - SentencePieceModel.UNIGRAM: `Unigram Language Model &lt;https://arxiv.org/abs/1804.10959&gt;`_ subword algorithm.</span>
<span class="sd">    - SentencePieceModel.BPE: `Byte-Pair-Encoding &lt;https://arxiv.org/abs/1508.07909&gt;`_ subword algorithm.</span>
<span class="sd">    - SentencePieceModel.CHAR: Character-based subword algorithm.</span>
<span class="sd">    - SentencePieceModel.WORD: Word-based subword algorithm.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">UNIGRAM</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">BPE</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">CHAR</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">WORD</span> <span class="o">=</span> <span class="mi">3</span></div>


<span class="n">DE_C_INTER_SENTENCEPIECE_MODE</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">SentencePieceModel</span><span class="o">.</span><span class="n">UNIGRAM</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">SentencePieceModel</span><span class="o">.</span><span class="n">DE_SENTENCE_PIECE_UNIGRAM</span><span class="p">,</span>
    <span class="n">SentencePieceModel</span><span class="o">.</span><span class="n">BPE</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">SentencePieceModel</span><span class="o">.</span><span class="n">DE_SENTENCE_PIECE_BPE</span><span class="p">,</span>
    <span class="n">SentencePieceModel</span><span class="o">.</span><span class="n">CHAR</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">SentencePieceModel</span><span class="o">.</span><span class="n">DE_SENTENCE_PIECE_CHAR</span><span class="p">,</span>
    <span class="n">SentencePieceModel</span><span class="o">.</span><span class="n">WORD</span><span class="p">:</span> <span class="n">cde</span><span class="o">.</span><span class="n">SentencePieceModel</span><span class="o">.</span><span class="n">DE_SENTENCE_PIECE_WORD</span>
<span class="p">}</span>


<div class="viewcode-block" id="SentencePieceVocab"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.SentencePieceVocab.html#mindspore.dataset.text.SentencePieceVocab">[文档]</a><span class="k">class</span> <span class="nc">SentencePieceVocab</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    SentencePiece object that is used to do words segmentation.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c_sentence_piece_vocab</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="SentencePieceVocab.from_dataset"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.SentencePieceVocab.html#mindspore.dataset.text.SentencePieceVocab.from_dataset">[文档]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@check_from_dataset_sentencepiece</span>
    <span class="k">def</span> <span class="nf">from_dataset</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">col_names</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">character_coverage</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build a SentencePiece from a dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset (Dataset): Dataset to build SentencePiece.</span>
<span class="sd">            col_names (list): The list of the col name.</span>
<span class="sd">            vocab_size (int): Vocabulary size.</span>
<span class="sd">            character_coverage (float): Amount of characters covered by the model. Recommend ``0.9995`` for</span>
<span class="sd">                languages with rich character set like Japanese or Chinese and ``1.0`` for other languages with small</span>
<span class="sd">                character set.</span>
<span class="sd">            model_type (SentencePieceModel): The desired subword algorithm. See :class:`~.text.SentencePieceModel`</span>
<span class="sd">                for details on optional values.</span>
<span class="sd">            params (dict): A dictionary with no incoming parameters.</span>

<span class="sd">        Returns:</span>
<span class="sd">            SentencePieceVocab, vocab built from the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset.text as text</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; from mindspore.dataset.text import SentencePieceVocab, SentencePieceModel</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.TextFileDataset(&quot;/path/to/sentence/piece/vocab/file&quot;, shuffle=False)</span>
<span class="sd">            &gt;&gt;&gt; vocab = SentencePieceVocab.from_dataset(dataset, [&quot;text&quot;], 5000, 0.9995,</span>
<span class="sd">            ...                                         SentencePieceModel.UNIGRAM, {})</span>
<span class="sd">            &gt;&gt;&gt; # Build tokenizer based on vocab</span>
<span class="sd">            &gt;&gt;&gt; tokenizer = text.SentencePieceTokenizer(vocab, out_type=text.SPieceTokenizerOutType.STRING)</span>
<span class="sd">            &gt;&gt;&gt; txt = &quot;Today is Tuesday.&quot;</span>
<span class="sd">            &gt;&gt;&gt; token = tokenizer(txt)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">sentence_piece_vocab</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">()</span>
        <span class="c1"># pylint: disable=protected-access</span>
        <span class="n">sentence_piece_vocab</span><span class="o">.</span><span class="n">c_sentence_piece_vocab</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_build_sentencepiece_vocab</span><span class="p">(</span><span class="n">col_names</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span>
                                                                                         <span class="n">character_coverage</span><span class="p">,</span>
                                                                                         <span class="n">model_type</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">sentence_piece_vocab</span></div>

<div class="viewcode-block" id="SentencePieceVocab.from_file"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.SentencePieceVocab.html#mindspore.dataset.text.SentencePieceVocab.from_file">[文档]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@check_from_file_sentencepiece</span>
    <span class="k">def</span> <span class="nf">from_file</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">file_path</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">character_coverage</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build a SentencePiece object from a file.</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (list): Path to the file which contains the SentencePiece list.</span>
<span class="sd">            vocab_size (int): Vocabulary size.</span>
<span class="sd">            character_coverage (float): Amount of characters covered by the model. Recommend ``0.9995`` for</span>
<span class="sd">                languages with rich character set like Japanese or Chinese and ``1.0`` for other languages with small</span>
<span class="sd">                character set.</span>
<span class="sd">            model_type (SentencePieceModel): The desired subword algorithm. See :class:`~.text.SentencePieceModel`</span>
<span class="sd">                for details on optional values.</span>
<span class="sd">            params (dict): A dictionary with no incoming parameters(The parameters are derived from SentencePiece</span>
<span class="sd">                library).</span>

<span class="sd">        Returns:</span>
<span class="sd">            SentencePieceVocab, vocab built from the file.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from mindspore.dataset.text import SentencePieceVocab, SentencePieceModel</span>
<span class="sd">            &gt;&gt;&gt; vocab = SentencePieceVocab.from_file([&quot;/path/to/sentence/piece/vocab/file&quot;], 5000, 0.9995,</span>
<span class="sd">            ...                                      SentencePieceModel.UNIGRAM, {})</span>
<span class="sd">            &gt;&gt;&gt; # Build tokenizer based on vocab model</span>
<span class="sd">            &gt;&gt;&gt; tokenizer = text.SentencePieceTokenizer(vocab, out_type=text.SPieceTokenizerOutType.STRING)</span>
<span class="sd">            &gt;&gt;&gt; txt = &quot;Today is Friday.&quot;</span>
<span class="sd">            &gt;&gt;&gt; token = tokenizer(txt)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">sentence_piece_vocab</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">()</span>
        <span class="n">sentence_piece_vocab</span><span class="o">.</span><span class="n">c_sentence_piece_vocab</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">SentencePieceVocab</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span>
            <span class="n">file_path</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">character_coverage</span><span class="p">,</span> <span class="n">DE_C_INTER_SENTENCEPIECE_MODE</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">model_type</span><span class="p">),</span> <span class="n">params</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">sentence_piece_vocab</span></div>

<div class="viewcode-block" id="SentencePieceVocab.save_model"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.SentencePieceVocab.html#mindspore.dataset.text.SentencePieceVocab.save_model">[文档]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@check_save_model</span>
    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save model into given filepath.</span>

<span class="sd">        Args:</span>
<span class="sd">            vocab (SentencePieceVocab): A SentencePiece object.</span>
<span class="sd">            path (str): Path to store model.</span>
<span class="sd">            filename (str): The name of the file.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; from mindspore.dataset.text import SentencePieceVocab, SentencePieceModel</span>
<span class="sd">            &gt;&gt;&gt; vocab = SentencePieceVocab.from_file([&quot;/path/to/sentence/piece/vocab/file&quot;], 5000, 0.9995,</span>
<span class="sd">            ...                                      SentencePieceModel.UNIGRAM, {})</span>
<span class="sd">            &gt;&gt;&gt; SentencePieceVocab.save_model(vocab, &quot;./&quot;, &quot;m.model&quot;)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">cde</span><span class="o">.</span><span class="n">SentencePieceVocab</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">c_sentence_piece_vocab</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="SPieceTokenizerLoadType"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.SPieceTokenizerLoadType.html#mindspore.dataset.text.SPieceTokenizerLoadType">[文档]</a><span class="k">class</span> <span class="nc">SPieceTokenizerLoadType</span><span class="p">(</span><span class="n">IntEnum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Model input type for the SentencePiece tokenizer.</span>

<span class="sd">    Available values are as follows:</span>

<span class="sd">    - SPieceTokenizerLoadType.FILE: Load model from specified file path.</span>
<span class="sd">    - SPieceTokenizerLoadType.MODEL: Load model from specified vocab object.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">FILE</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">MODEL</span> <span class="o">=</span> <span class="mi">1</span></div>


<div class="viewcode-block" id="SPieceTokenizerOutType"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.SPieceTokenizerOutType.html#mindspore.dataset.text.SPieceTokenizerOutType">[文档]</a><span class="k">class</span> <span class="nc">SPieceTokenizerOutType</span><span class="p">(</span><span class="n">IntEnum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    An enumeration for :class:`mindspore.dataset.text.SentencePieceTokenizer` .</span>

<span class="sd">    Possible enumeration values are: ``SPieceTokenizerOutType.STRING``, ``SPieceTokenizerOutType.INT``.</span>

<span class="sd">    - SPieceTokenizerOutType.STRING: means output type of SentencePiece Tokenizer is string.</span>
<span class="sd">    - SPieceTokenizerOutType.INT: means output type of SentencePiece Tokenizer is int.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">STRING</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">INT</span> <span class="o">=</span> <span class="mi">1</span></div>


<div class="viewcode-block" id="Vectors"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.Vectors.html#mindspore.dataset.text.Vectors">[文档]</a><span class="k">class</span> <span class="nc">Vectors</span><span class="p">(</span><span class="n">cde</span><span class="o">.</span><span class="n">Vectors</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Pre-trained word embeddings.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Vectors.from_file"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.Vectors.html#mindspore.dataset.text.Vectors.from_file">[文档]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@check_from_file_vectors</span>
    <span class="k">def</span> <span class="nf">from_file</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">file_path</span><span class="p">,</span> <span class="n">max_vectors</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load a pre-training vector set file.</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): Path to the pre-training vector set file.</span>
<span class="sd">            max_vectors (int, optional): The upper limit on the number of pre-trained vectors to load.</span>
<span class="sd">                Most pre-trained vector sets are sorted in the descending order of word frequency. Thus, in</span>
<span class="sd">                situations where the entire set doesn&#39;t fit in memory, or is not needed for another reason,</span>
<span class="sd">                this value can limit the size of the loaded set. Default: ``None``, no upper limit.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Vectors, pre-training vectors.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `file_path` is not of type str.</span>
<span class="sd">            RuntimeError: If `file_path` does not exist or is not accessible.</span>
<span class="sd">            TypeError: If `max_vectors` is not of type int.</span>
<span class="sd">            ValueError: If `max_vectors` is negative.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset.text as text</span>
<span class="sd">            &gt;&gt;&gt; vector = text.Vectors.from_file(&quot;/path/to/vectors/file&quot;, max_vectors=None)</span>
<span class="sd">            &gt;&gt;&gt; to_vectors = text.ToVectors(vector)</span>
<span class="sd">            &gt;&gt;&gt; # Look up a token into vectors according Vector model.</span>
<span class="sd">            &gt;&gt;&gt; word_vector = to_vectors([&quot;word1&quot;, &quot;word2&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">max_vectors</span> <span class="o">=</span> <span class="n">max_vectors</span> <span class="k">if</span> <span class="n">max_vectors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">max_vectors</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="Vocab"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.Vocab.html#mindspore.dataset.text.Vocab">[文档]</a><span class="k">class</span> <span class="nc">Vocab</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create Vocab for training NLP models.</span>

<span class="sd">    Vocab is a collection of all possible Tokens in the data, preserving the mapping between each Token and its ID.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c_vocab</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="Vocab.from_dataset"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.Vocab.html#mindspore.dataset.text.Vocab.from_dataset">[文档]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@check_from_dataset</span>
    <span class="k">def</span> <span class="nf">from_dataset</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">freq_range</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">special_tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">special_first</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build a Vocab from a given dataset.</span>

<span class="sd">        The samples in the dataset are used as a corpus to create Vocab, in which the Token is arranged in ascending</span>
<span class="sd">        order of Token frequency, and Tokens with the same frequency are arranged in alphabetical order.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset (Dataset): The dataset to build the Vocab from.</span>
<span class="sd">            columns (list[str], optional): The name of the data columns used to create the Vocab.</span>
<span class="sd">                Default: ``None`` , use all columns.</span>
<span class="sd">            freq_range (tuple[int, int], optional): The Token frequency range used to create the Vocab. Must contain</span>
<span class="sd">                two elements representing the minimum and maximum frequencies, within which the Token will be retained.</span>
<span class="sd">                When the minimum or maximum frequency is None, it means there is no minimum or maximum frequency limit.</span>
<span class="sd">                Default: ``None`` , no Token frequency range restriction.</span>
<span class="sd">            top_k (int, optional): Only the first specified number of Tokens with the highest Token frequency are</span>
<span class="sd">                selected to build the Vocab. This operation will be performed after Token frequency filtering. If</span>
<span class="sd">                the value is greater than the total number of Tokens, all Tokens will be retained. Default: ``None`` ,</span>
<span class="sd">                there is no limit to the number of Tokens.</span>
<span class="sd">            special_tokens (list[str], optional):  A list of special Token to append to the Vocab. Default: ``None`` ,</span>
<span class="sd">                no special Token is appended.</span>
<span class="sd">            special_first (bool, optional): Whether to add the special Token to the top of the Vocab, otherwise to</span>
<span class="sd">                the bottom of the Vocab. Default: ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Vocab, Vocab built from the dataset.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `columns` is not of type list[str].</span>
<span class="sd">            TypeError: If `freq_range` is not of type tuple[int, int]l.</span>
<span class="sd">            ValueError: If element of `freq_range` is negative.</span>
<span class="sd">            TypeError: If `top_k` is not of type int.</span>
<span class="sd">            ValueError: If `top_k` is not positive.</span>
<span class="sd">            TypeError: If `special_tokens` is not of type list[str].</span>
<span class="sd">            ValueError: If there are duplicate elements in `special_tokens`.</span>
<span class="sd">            TypeError: If `special_first` is not of type bool.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset.text as text</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; dataset = ds.TextFileDataset(&quot;/path/to/sentence/piece/vocab/file&quot;, shuffle=False)</span>
<span class="sd">            &gt;&gt;&gt; vocab = text.Vocab.from_dataset(dataset, &quot;text&quot;, freq_range=None, top_k=None,</span>
<span class="sd">            ...                                 special_tokens=[&quot;&lt;pad&gt;&quot;, &quot;&lt;unk&gt;&quot;],</span>
<span class="sd">            ...                                 special_first=True)</span>
<span class="sd">            &gt;&gt;&gt; # Use the vocab to look up string to id</span>
<span class="sd">            &gt;&gt;&gt; lookup = text.Lookup(vocab, &quot;&lt;unk&gt;&quot;)</span>
<span class="sd">            &gt;&gt;&gt; id = lookup(&quot;text1&quot;)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">vocab</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">()</span>
        <span class="c1"># pylint: disable=protected-access</span>
        <span class="n">vocab</span><span class="o">.</span><span class="n">c_vocab</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">_build_vocab</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="n">freq_range</span><span class="p">,</span> <span class="n">top_k</span><span class="p">,</span> <span class="n">special_tokens</span><span class="p">,</span> <span class="n">special_first</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">vocab</span></div>

<div class="viewcode-block" id="Vocab.from_list"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.Vocab.html#mindspore.dataset.text.Vocab.from_list">[文档]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@check_from_list</span>
    <span class="k">def</span> <span class="nf">from_list</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">word_list</span><span class="p">,</span> <span class="n">special_tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">special_first</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build a Vocab from a given Token list.</span>

<span class="sd">        Args:</span>
<span class="sd">            word_list (list[str]): The Token list to build the Vocab from.</span>
<span class="sd">            special_tokens (list[str], optional):  A list of special Token to append to the Vocab. Default: ``None`` ,</span>
<span class="sd">                no special Token is appended.</span>
<span class="sd">            special_first (bool, optional): Whether to add the special Token to the top of the Vocab, otherwise to</span>
<span class="sd">                the bottom of the Vocab. Default: ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Vocab, Vocab built from the list.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `word_list` is not of type list[str].</span>
<span class="sd">            ValueError: If there are duplicate elements in `word_list`.</span>
<span class="sd">            TypeError: If `special_tokens` is not of type list[str].</span>
<span class="sd">            ValueError: If there are duplicate elements in `special_tokens`.</span>
<span class="sd">            TypeError: If `special_first` is not of type bool.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset.text as text</span>
<span class="sd">            &gt;&gt;&gt; vocab = text.Vocab.from_list([&quot;w1&quot;, &quot;w2&quot;, &quot;w3&quot;], special_tokens=[&quot;&lt;unk&gt;&quot;], special_first=True)</span>
<span class="sd">            &gt;&gt;&gt; # look up strings to ids</span>
<span class="sd">            &gt;&gt;&gt; ids = vocab.tokens_to_ids([&quot;w1&quot;, &quot;w3&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">special_tokens</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">special_tokens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="n">Vocab</span><span class="p">()</span>
        <span class="n">vocab</span><span class="o">.</span><span class="n">c_vocab</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">Vocab</span><span class="o">.</span><span class="n">from_list</span><span class="p">(</span><span class="n">word_list</span><span class="p">,</span> <span class="n">special_tokens</span><span class="p">,</span> <span class="n">special_first</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">vocab</span></div>

<div class="viewcode-block" id="Vocab.from_file"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.Vocab.html#mindspore.dataset.text.Vocab.from_file">[文档]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@check_from_file</span>
    <span class="k">def</span> <span class="nf">from_file</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">file_path</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">special_tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">special_first</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build a Vocab from a file.</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): The path of the file to build the Vocab from.</span>
<span class="sd">            delimiter (str, optional): The separator for the Token in the file line. The string before the separator</span>
<span class="sd">                will be treated as a Token. Default: ``&#39;&#39;``, the whole line will be treated as a Token.</span>
<span class="sd">            vocab_size (int, optional): The upper limit on the number of Tokens that Vocab can contain.</span>
<span class="sd">                Default: ``None`` , no upper limit on the number of Token.</span>
<span class="sd">            special_tokens (list[str], optional):  A list of special Token to append to the Vocab. Default: ``None`` ,</span>
<span class="sd">                no special Token is appended.</span>
<span class="sd">            special_first (bool, optional): Whether to add the special Token to the top of the Vocab, otherwise to</span>
<span class="sd">                the bottom of the Vocab. Default: ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Vocab, Vocab built from the file.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `file_path` is not of type str.</span>
<span class="sd">            TypeError: If `delimiter` is not of type str.</span>
<span class="sd">            ValueError: If `vocab_size` is not positive.</span>
<span class="sd">            TypeError: If `special_tokens` is not of type list[str].</span>
<span class="sd">            ValueError: If there are duplicate elements in `special_tokens`.</span>
<span class="sd">            TypeError: If `special_first` is not of type bool.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset.text as text</span>
<span class="sd">            &gt;&gt;&gt; # Assume vocab file contains the following content:</span>
<span class="sd">            &gt;&gt;&gt; # --- begin of file ---</span>
<span class="sd">            &gt;&gt;&gt; # apple,apple2</span>
<span class="sd">            &gt;&gt;&gt; # banana, 333</span>
<span class="sd">            &gt;&gt;&gt; # cat,00</span>
<span class="sd">            &gt;&gt;&gt; # --- end of file ---</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Read file through this API and specify &quot;,&quot; as delimiter.</span>
<span class="sd">            &gt;&gt;&gt; # The delimiter will break up each line in file, then the first element is taken to be the word.</span>
<span class="sd">            &gt;&gt;&gt; vocab = text.Vocab.from_file(&quot;/path/to/simple/vocab/file&quot;, &quot;,&quot;, None, [&quot;&lt;pad&gt;&quot;, &quot;&lt;unk&gt;&quot;], True)</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Finally, there are 5 words in the vocab: &quot;&lt;pad&gt;&quot;, &quot;&lt;unk&gt;&quot;, &quot;apple&quot;, &quot;banana&quot;, &quot;cat&quot;.</span>
<span class="sd">            &gt;&gt;&gt; vocabulary = vocab.vocab()</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # look up strings to ids</span>
<span class="sd">            &gt;&gt;&gt; ids = vocab.tokens_to_ids([&quot;apple&quot;, &quot;banana&quot;])</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">vocab_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">vocab_size</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">special_tokens</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">special_tokens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">()</span>
        <span class="n">vocab</span><span class="o">.</span><span class="n">c_vocab</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">Vocab</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">delimiter</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">special_tokens</span><span class="p">,</span> <span class="n">special_first</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">vocab</span></div>

<div class="viewcode-block" id="Vocab.from_dict"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.Vocab.html#mindspore.dataset.text.Vocab.from_dict">[文档]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@check_from_dict</span>
    <span class="k">def</span> <span class="nf">from_dict</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">word_dict</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build a Vocab from a given dictionary.</span>

<span class="sd">        Args:</span>
<span class="sd">            word_dict (dict[str, int]): A dictionary storing the mappings between each Token and its ID.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Vocab, Vocab built from the dictionary.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `word_dict` is not of type dict[str, int].</span>
<span class="sd">            ValueError: If key value of `word_dict` is negative.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset.text as text</span>
<span class="sd">            &gt;&gt;&gt; vocab = text.Vocab.from_dict({&quot;home&quot;: 3, &quot;behind&quot;: 2, &quot;the&quot;: 4, &quot;world&quot;: 5, &quot;&lt;unk&gt;&quot;: 6})</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # look up ids to string</span>
<span class="sd">            &gt;&gt;&gt; tokens = vocab.ids_to_tokens([3, 4, 5])</span>
<span class="sd">            &gt;&gt;&gt; print(tokens)</span>
<span class="sd">            [&#39;home&#39;, &#39;the&#39;, &#39;world&#39;]</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">vocab</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">()</span>
        <span class="n">vocab</span><span class="o">.</span><span class="n">c_vocab</span> <span class="o">=</span> <span class="n">cde</span><span class="o">.</span><span class="n">Vocab</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">word_dict</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">vocab</span></div>

<div class="viewcode-block" id="Vocab.vocab"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.Vocab.html#mindspore.dataset.text.Vocab.vocab">[文档]</a>    <span class="k">def</span> <span class="nf">vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the dictionary of the mappings between Tokens and its IDs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict[str, int], the dictionary of mappings between Tokens and IDs.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset.text as text</span>
<span class="sd">            &gt;&gt;&gt; vocab = text.Vocab.from_list([&quot;word_1&quot;, &quot;word_2&quot;, &quot;word_3&quot;, &quot;word_4&quot;])</span>
<span class="sd">            &gt;&gt;&gt; vocabory_dict = vocab.vocab()</span>
<span class="sd">            &gt;&gt;&gt; print(sorted(vocabory_dict.items()))</span>
<span class="sd">            [(&#39;word_1&#39;, 0), (&#39;word_2&#39;, 1), (&#39;word_3&#39;, 2), (&#39;word_4&#39;, 3)]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_vocab</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">c_vocab</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">c_vocab</span><span class="o">.</span><span class="n">vocab</span><span class="p">()</span></div>

<div class="viewcode-block" id="Vocab.tokens_to_ids"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.Vocab.html#mindspore.dataset.text.Vocab.tokens_to_ids">[文档]</a>    <span class="nd">@check_tokens_to_ids</span>
    <span class="k">def</span> <span class="nf">tokens_to_ids</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Look up the ID corresponding to the specified Token.</span>

<span class="sd">        Args:</span>
<span class="sd">            tokens (Union[str, list[str], numpy.ndarray]): The Token or list of Tokens to be looked up.</span>
<span class="sd">                If the Token does not exist, -1 is returned.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[int, list[int]], the ID(s) corresponding to the Token(s).</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `tokens` is not of type Union[str, list[str], numpy.ndarray].</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset.text as text</span>
<span class="sd">            &gt;&gt;&gt; vocab = text.Vocab.from_list([&quot;w1&quot;, &quot;w2&quot;, &quot;w3&quot;], special_tokens=[&quot;&lt;unk&gt;&quot;], special_first=True)</span>
<span class="sd">            &gt;&gt;&gt; ids = vocab.tokens_to_ids([&quot;w1&quot;, &quot;w3&quot;])</span>
<span class="sd">            &gt;&gt;&gt; print(ids)</span>
<span class="sd">            [1, 3]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_vocab</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">c_vocab</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokens</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokens</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">c_vocab</span><span class="o">.</span><span class="n">tokens_to_ids</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span></div>

<div class="viewcode-block" id="Vocab.ids_to_tokens"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.Vocab.html#mindspore.dataset.text.Vocab.ids_to_tokens">[文档]</a>    <span class="nd">@check_ids_to_tokens</span>
    <span class="k">def</span> <span class="nf">ids_to_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ids</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Look up the Token corresponding to the specified ID.</span>

<span class="sd">        Args:</span>
<span class="sd">            ids (Union[int, list[int], numpy.ndarray]): The ID or list of IDs to be looked up.</span>
<span class="sd">                If the ID does not exist, an empty string is returned.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[str, list[str]], the Token(s) corresponding to the ID(s).</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If `ids` is not of type Union[int, list[int], numpy.ndarray].</span>
<span class="sd">            ValueError: If element of `ids` is negative.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import mindspore.dataset.text as text</span>
<span class="sd">            &gt;&gt;&gt; vocab = text.Vocab.from_list([&quot;w1&quot;, &quot;w2&quot;, &quot;w3&quot;], special_tokens=[&quot;&lt;unk&gt;&quot;], special_first=True)</span>
<span class="sd">            &gt;&gt;&gt; token = vocab.ids_to_tokens(1)</span>
<span class="sd">            &gt;&gt;&gt; print(token)</span>
<span class="sd">            w1</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_vocab</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">c_vocab</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">ids</span> <span class="o">=</span> <span class="n">ids</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">ids</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">c_vocab</span><span class="o">.</span><span class="n">ids_to_tokens</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="to_bytes"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.to_bytes.html#mindspore.dataset.text.to_bytes">[文档]</a><span class="k">def</span> <span class="nf">to_bytes</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf8&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert NumPy array of `str` to array of `bytes` by encoding each element based on charset `encoding` .</span>

<span class="sd">    Args:</span>
<span class="sd">        array (numpy.ndarray): Array of `str` type representing strings.</span>
<span class="sd">        encoding (str): Indicating the charset for encoding. Default: ``&#39;utf8&#39;``.</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray, NumPy array of `bytes` .</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.text as text</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; data = np.array([[&quot;1&quot;, &quot;2&quot;, &quot;3&quot;]], dtype=np.str_)</span>
<span class="sd">        &gt;&gt;&gt; dataset = ds.NumpySlicesDataset(data, column_names=[&quot;text&quot;])</span>
<span class="sd">        &gt;&gt;&gt; result = []</span>
<span class="sd">        &gt;&gt;&gt; for item in dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     result.append(text.to_bytes(item[&quot;text&quot;]))</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        [array([b&#39;1&#39;, b&#39;2&#39;, b&#39;3&#39;], dtype=&#39;|S1&#39;)]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;input should be a NumPy array.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">char</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">encoding</span><span class="p">)</span></div>


<div class="viewcode-block" id="to_str"><a class="viewcode-back" href="../../../../api_python/dataset_text/mindspore.dataset.text.to_str.html#mindspore.dataset.text.to_str">[文档]</a><span class="k">def</span> <span class="nf">to_str</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf8&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert NumPy array of `bytes` to array of `str` by decoding each element based on charset `encoding` .</span>

<span class="sd">    Args:</span>
<span class="sd">        array (numpy.ndarray): Array of `bytes` type representing strings.</span>
<span class="sd">        encoding (str): Indicating the charset for decoding. Default: ``&#39;utf8&#39;``.</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray, NumPy array of `str` .</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset as ds</span>
<span class="sd">        &gt;&gt;&gt; import mindspore.dataset.text as text</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; data = np.array([[&quot;1&quot;, &quot;2&quot;, &quot;3&quot;]], dtype=np.bytes_)</span>
<span class="sd">        &gt;&gt;&gt; dataset = ds.NumpySlicesDataset(data, column_names=[&quot;text&quot;])</span>
<span class="sd">        &gt;&gt;&gt; result = []</span>
<span class="sd">        &gt;&gt;&gt; for item in dataset.create_dict_iterator(num_epochs=1, output_numpy=True):</span>
<span class="sd">        ...     result.append(text.to_str(item[&quot;text&quot;]))</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        [array([&#39;1&#39;, &#39;2&#39;, &#39;3&#39;], dtype=&#39;&lt;U1&#39;)]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;input should be a NumPy array.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">char</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">encoding</span><span class="p">)</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 MindSpore.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>