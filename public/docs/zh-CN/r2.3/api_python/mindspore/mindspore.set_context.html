<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mindspore.set_context &mdash; MindSpore master 文档</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script><script src="../../_static/jquery.js"></script>
        <script src="../../_static/js/theme.js"></script><script src="../../_static/underscore.js"></script><script src="../../_static/doctools.js"></script><script src="../../_static/js/mermaid-9.3.0.js"></script><script src="../../_static/translations.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="mindspore.get_context" href="mindspore.get_context.html" />
    <link rel="prev" title="mindspore.QuantDtype" href="mindspore.QuantDtype.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">设计</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../design/overview.html">MindSpore设计概览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/programming_paradigm.html">函数式和对象式融合编程范式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/dynamic_graph_and_static_graph.html">动静态图结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/distributed_training_design.html">分布式并行原生</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/all_scenarios.html">全场景统一架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/graph_fusion_engine.html">图算融合加速引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/pluggable_device.html">三方硬件对接</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/glossary.html">术语</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型库</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/official_models.html">官方模型库</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../mindspore.html">mindspore</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#数据表达">数据表达</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../mindspore.html#运行环境">运行环境</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">mindspore.set_context</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.get_context.html">mindspore.get_context</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.set_auto_parallel_context.html">mindspore.set_auto_parallel_context</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.get_auto_parallel_context.html">mindspore.get_auto_parallel_context</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.reset_auto_parallel_context.html">mindspore.reset_auto_parallel_context</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.ParallelMode.html">mindspore.ParallelMode</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.set_ps_context.html">mindspore.set_ps_context</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.get_ps_context.html">mindspore.get_ps_context</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.reset_ps_context.html">mindspore.reset_ps_context</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.set_algo_parameters.html">mindspore.set_algo_parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.get_algo_parameters.html">mindspore.get_algo_parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.reset_algo_parameters.html">mindspore.reset_algo_parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.set_offload_context.html">mindspore.set_offload_context</a></li>
<li class="toctree-l3"><a class="reference internal" href="mindspore.get_offload_context.html">mindspore.get_offload_context</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#随机种子">随机种子</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#序列化">序列化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#自动微分">自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#并行优化">并行优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#即时编译">即时编译</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mindspore.html#工具">工具</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.multiprocessing.html">mindspore.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mindspore.experimental.html">mindspore.experimental</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API映射</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/pytorch_api_mapping.html">PyTorch与MindSpore API映射表</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">迁移指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/overview.html">迁移指南概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/enveriment_preparation.html">环境准备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/analysis_and_preparation.html">模型分析与准备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/model_development/model_development.html">网络搭建对比</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/debug_and_tune.html">调试调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/sample_code.html">网络迁移调试实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration_guide/faq.html">常见问题</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">语法支持</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax_support.html">静态图语法支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax/operators.html">静态图语法-运算符</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax/statements.html">静态图语法-Python语句</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax/python_builtin_functions.html">静态图语法-Python内置函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/index_support.html">Tensor索引支持</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">环境变量</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/env_var_list.html">环境变量</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq/installation.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/data_processing.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/implement_problem.html">执行问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/network_compilation.html">网络编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/usage_migrate_3rd.html">第三方框架迁移使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/distributed_parallel.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/feature_advice.html">特性咨询</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../mindspore.html">mindspore</a> &raquo;</li>
      <li>mindspore.set_context</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/api_python/mindspore/mindspore.set_context.rst.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="mindspore-set-context">
<h1>mindspore.set_context<a class="headerlink" href="#mindspore-set-context" title="永久链接至标题"></a></h1>
<a class="reference external image-reference" href="https://gitee.com/mindspore/mindspore/blob/r2.3/docs/api/api_python/mindspore/mindspore.set_context.rst"><img alt="查看源文件" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3/resource/_static/logo_source.svg" /></a>
<dl class="py function">
<dt class="sig sig-object py" id="mindspore.set_context">
<span class="sig-prename descclassname"><span class="pre">mindspore.</span></span><span class="sig-name descname"><span class="pre">set_context</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/mindspore/context.html#set_context"><span class="viewcode-link"><span class="pre">[源代码]</span></span></a><a class="headerlink" href="#mindspore.set_context" title="打开链接"></a></dt>
<dd><p>设置运行环境的context。</p>
<p>在运行程序之前，应配置context。如果没有配置，默认情况下将根据设备目标进行自动设置。</p>
<div class="admonition note">
<p class="admonition-title">说明</p>
<p>设置属性时，必须输入属性名称。net初始化后不建议更改模式，因为一些操作的实现在Graph模式和PyNative模式下是不同的。默认值： <code class="docutils literal notranslate"><span class="pre">PYNATIVE_MODE</span></code> 。</p>
</div>
<p>某些配置适用于特定的设备，有关详细信息，请参见下表：</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 30%" />
<col style="width: 36%" />
<col style="width: 34%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>功能分类</p></th>
<th class="head"><p>配置参数</p></th>
<th class="head"><p>硬件平台支持</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td rowspan="6"><p>系统配置</p></td>
<td><p>device_id</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>device_target</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-even"><td><p>max_device_memory</p></td>
<td><p>GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>variable_memory_max_size</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-even"><td><p>mempool_block_size</p></td>
<td><p>GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>op_timeout</p></td>
<td><p>GPU/Ascend</p></td>
</tr>
<tr class="row-even"><td rowspan="10"><p>调试配置</p></td>
<td><p>save_graphs</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>save_graphs_path</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-even"><td><p>enable_dump</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>save_dump_path</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-even"><td><p>deterministic</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>print_file_path</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-even"><td><p>env_config_path</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>precompile_only</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-even"><td><p>reserve_class_name_in_scope</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>pynative_synchronize</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-even"><td rowspan="20"><p>执行控制</p></td>
<td><p>mode</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>enable_graph_kernel</p></td>
<td><p>Ascend/GPU</p></td>
</tr>
<tr class="row-even"><td><p>graph_kernel_flags</p></td>
<td><p>Ascend/GPU</p></td>
</tr>
<tr class="row-odd"><td><p>enable_reduce_precision</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-even"><td><p>aoe_tune_mode</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>aoe_config</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-even"><td><p>check_bprop</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>max_call_depth</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-even"><td><p>grad_for_scalar</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>enable_compile_cache</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-even"><td><p>inter_op_parallel_num</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>runtime_num_threads</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-even"><td><p>compile_cache_path</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>disable_format_transform</p></td>
<td><p>GPU</p></td>
</tr>
<tr class="row-even"><td><p>support_binary</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>memory_optimize_level</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-even"><td><p>memory_offload</p></td>
<td><p>GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>ascend_config</p></td>
<td><p>Ascend</p></td>
</tr>
<tr class="row-even"><td><p>jit_syntax_level</p></td>
<td><p>CPU/GPU/Ascend</p></td>
</tr>
<tr class="row-odd"><td><p>gpu_config</p></td>
<td><p>GPU</p></td>
</tr>
</tbody>
</table>
<dl class="simple">
<dt>参数：</dt><dd><ul>
<li><p><strong>device_id</strong> (int) - 表示目标设备的ID，其值必须在[0, device_num_per_host-1]范围中，且 <cite>device_num_per_host</cite> 的值不应超过4096。默认值： <code class="docutils literal notranslate"><span class="pre">0</span></code> 。</p></li>
<li><p><strong>device_target</strong> (str) - 表示待运行的目标设备，支持 ‘Ascend’、 ‘GPU’和 ‘CPU’。如果未设置此参数，则使用MindSpore包对应的后端设备。</p></li>
<li><p><strong>max_device_memory</strong> (str) - 设置设备可用的最大内存。格式为”xxGB”。默认值： <code class="docutils literal notranslate"><span class="pre">1024GB</span></code> 。实际使用的内存大小是设备的可用内存和 <cite>max_device_memory</cite> 值中的最小值。 <cite>max_device_memory</cite> 需要在程序运行之前设置。</p></li>
<li><p><strong>variable_memory_max_size</strong> (str) - 此参数已弃用，将被删除。请使用 <cite>max_device_memory</cite> 。</p></li>
<li><p><strong>mempool_block_size</strong> (str) - 设置设备内存池的块大小。格式为”xxGB”。默认值： <code class="docutils literal notranslate"><span class="pre">1GB</span></code> 。最小值是1GB。实际使用的内存池块大小是设备的可用内存和 <cite>mempool_block_size</cite> 值中的最小值。</p></li>
<li><p><strong>op_timeout</strong> (int) - 设置一个算子的最大执行时间，以秒为单位。如果执行时间超过这个值，系统将终止该任务。0意味着使用默认值， AI Core和AICPU算子在不同硬件上的默认值有差异， 详细信息请查看 <cite>昇腾社区 &lt;https://hiascend.com/document/detail/zh/CANNCommunityEdition/70RC1alpha003/infacldevg/aclcppdevg/aclcppdevg_03_0606.html&gt;</cite>。MindSpore默认设置值： <code class="docutils literal notranslate"><span class="pre">900</span></code> 。</p></li>
<li><p><strong>save_graphs</strong> (bool 或 int) - 表示是否保存中间编译图。默认值： <code class="docutils literal notranslate"><span class="pre">0</span></code> 。可用的选项为：</p>
<ul class="simple">
<li><p>False或0：不保存中间编译图。</p></li>
<li><p>1：运行时会输出图编译过程中生成的一些中间文件。</p></li>
<li><p>True或2：生成更多后端流程相关的ir文件。</p></li>
<li><p>3：生成可视化计算图和更多详细的前端ir图。</p></li>
</ul>
<p>当 <cite>save_graphs</cite> 属性设为 <code class="docutils literal notranslate"><span class="pre">1</span></code> 、 <code class="docutils literal notranslate"><span class="pre">2</span></code> 、 <code class="docutils literal notranslate"><span class="pre">3</span></code> 或者 <code class="docutils literal notranslate"><span class="pre">True</span></code> 时， <cite>save_graphs_path</cite> 属性用于设置中间编译图的存储路径。默认情况下，计算图保存在当前目录下。</p>
</li>
<li><p><strong>save_graphs_path</strong> (str) - 表示保存计算图的路径。默认值：”.”。如果指定的目录不存在，系统将自动创建该目录。在分布式训练中，图形将被保存到 <cite>save_graphs_path/rank_${rank_id}/</cite> 目录下。 <cite>rank_id</cite> 为集群中当前设备的ID。</p></li>
<li><p><strong>deterministic</strong> (str) - 表示是否使能算子确定性运行模式。值必须在[‘ON’,’OFF’]范围内，默认值： <code class="docutils literal notranslate"><span class="pre">'OFF'</span></code> 。</p>
<ul class="simple">
<li><p>ON：开启算子确定性运行模式。</p></li>
<li><p>OFF：关闭算子确定性运行模式。</p></li>
</ul>
<p>当确定性开启时，模型中的算子将在Ascend中具有确定性。这意味着，如果算子在同一硬件上使用相同的输入运行多次，则每次都会有完全相同的输出。这对于调试模型很有用。</p>
</li>
<li><p><strong>enable_dump</strong> (bool) - 此参数已弃用，将在下一版本中删除。</p></li>
<li><p><strong>save_dump_path</strong> (str) - 此参数已弃用，将在下一版本中删除。</p></li>
<li><p><strong>print_file_path</strong> (str) - 该路径用于保存打印数据。使用时 <a class="reference internal" href="../ops/mindspore.ops.Print.html#mindspore.ops.Print" title="mindspore.ops.Print"><code class="xref py py-class docutils literal notranslate"><span class="pre">mindspore.ops.Print</span></code></a> 可以打印输入的张量或字符串信息，使用方法 <a class="reference internal" href="mindspore.parse_print.html#mindspore.parse_print" title="mindspore.parse_print"><code class="xref py py-func docutils literal notranslate"><span class="pre">mindspore.parse_print()</span></code></a> 解析保存的文件。如果设置了此参数，打印数据保存到文件，未设置将显示到屏幕。如果保存的文件已经存在，则将添加时间戳后缀到文件中。将数据保存到文件解决了屏幕打印中的数据丢失问题，如果未设置，将报告错误:”prompt to set the upper absolute path”。</p></li>
<li><p><strong>env_config_path</strong> (str) - 通过 <cite>mindspore.set_context(env_config_path=”./mindspore_config.json”)</cite> 来设置MindSpore环境配置文件路径。</p>
<p>配置Running Data Recorder：</p>
<ul class="simple">
<li><p><strong>enable</strong>：表示在发生故障时是否启用Running Data Recorder去收集和保存训练中的关键数据。设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 时，将打开Running Data Recorder。设置为 <code class="docutils literal notranslate"><span class="pre">False</span></code> 时，将关闭Running Data Recorder。</p></li>
<li><p><strong>mode</strong>：设置导出数据时的RDR模式。当设置为 <code class="docutils literal notranslate"><span class="pre">1</span></code> 时，RDR只在故障情况下输出数据。当设置为 <code class="docutils literal notranslate"><span class="pre">2</span></code> 时，RDR在故障情况和正常结束情况下输出数据。默认值： <code class="docutils literal notranslate"><span class="pre">1</span></code> 。</p></li>
<li><p><strong>path</strong>：设置Running Data Recorder保存数据的路径。当前路径必须是一个绝对路径。</p></li>
</ul>
<p>内存重用：</p>
<ul class="simple">
<li><p><strong>mem_Reuse</strong>：表示内存复用功能是否打开。设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 时，将打开内存复用功能。设置为 <code class="docutils literal notranslate"><span class="pre">False</span></code> 时，将关闭内存复用功能。</p></li>
</ul>
<p>配置详细信息，请查看 <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r2.3/debug/rdr.html">Running Data Recorder</a> 和 <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r2.3/optimize/mem_reuse.html">内存复用</a> 。</p>
</li>
<li><p><strong>precompile_only</strong> (bool) - 表示是否仅预编译网络。默认值： <code class="docutils literal notranslate"><span class="pre">False</span></code> 。设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 时，仅编译网络，而不执行网络。</p></li>
<li><p><strong>reserve_class_name_in_scope</strong> (bool) - 表示是否将网络类名称保存到所属ScopeName中。默认值： <code class="docutils literal notranslate"><span class="pre">True</span></code> 。每个节点都有一个ScopeName。子节点的ScopeName是其父节点。如果 <cite>reserve_class_name_in_scope</cite> 设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> ，则类名将保存在ScopeName中的关键字”net-“之后。例如：</p>
<p>Default/net-Net1/net-Net2 (reserve_class_name_in_scope=True)</p>
<p>Default/net/net (reserve_class_name_in_scope=False)</p>
</li>
<li><p><strong>pynative_synchronize</strong> (bool) - 表示是否在PyNative模式下启动设备同步执行。默认值： <code class="docutils literal notranslate"><span class="pre">False</span></code> 。设置为 <code class="docutils literal notranslate"><span class="pre">False</span></code> 时，将在设备上异步执行算子。当算子执行出错时，将无法定位特定错误脚本代码的位置。当设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 时，将在设备上同步执行算子。这将降低程序的执行性能。此时，当算子执行出错时，可以根据错误的调用栈来定位错误脚本代码的位置。</p></li>
<li><p><strong>mode</strong> (int) - 表示在GRAPH_MODE(0)或PYNATIVE_MODE(1)模式中运行，两种模式都支持所有后端。默认值： <code class="docutils literal notranslate"><span class="pre">PYNATIVE_MODE</span></code> 。</p></li>
<li><p><strong>enable_graph_kernel</strong> (bool) - 表示开启图算融合去优化网络执行性能。默认值： <code class="docutils literal notranslate"><span class="pre">False</span></code> 。如果 <cite>enable_graph_kernel</cite> 设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> ，则可以启用加速。有关图算融合的详细信息，请查看 <a class="reference external" href="https://www.mindspore.cn/tutorials/experts/zh-CN/r2.3/optimize/graph_fusion_engine.html">使能图算融合</a> 。</p></li>
<li><p><strong>graph_kernel_flags</strong> (str) - 图算融合的优化选项，当与enable_graph_kernel冲突时，它的优先级更高。其仅适用于有经验的用户。例如：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mindspore</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">graph_kernel_flags</span><span class="o">=</span><span class="s2">&quot;--opt_level=2 --dump_as_text&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>一些常用选项：</p>
<ul class="simple">
<li><p><strong>opt_level</strong>：设置优化级别。默认值：2。当opt_level的值大于0时，启动图算融合。可选值包括：</p>
<ul>
<li><p>0：关闭图算融合。</p></li>
<li><p>1：启动算子的基本融合。</p></li>
<li><p>2：包括级别1的所有优化，并打开更多的优化，如CSE优化算法、算术简化等。</p></li>
<li><p>3：包括级别2的所有优化，并打开更多的优化，如SitchingFusion、ParallelFusion等。在某些场景下，该级别的优化激进且不稳定。使用此级别时要小心。</p></li>
</ul>
</li>
<li><p><strong>dump_as_text</strong>：将关键过程的详细信息生成文本文件保存到”graph_kernel_dump”目录里。默认值： <code class="docutils literal notranslate"><span class="pre">False</span></code> 。</p></li>
</ul>
</li>
<li><p><strong>enable_reduce_precision</strong> (bool) - 表示是否开启降低精度计算。默认值： <code class="docutils literal notranslate"><span class="pre">True</span></code> 。设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 时，不支持用户指定的精度，且精度将自动更改。设置为 <code class="docutils literal notranslate"><span class="pre">False</span></code> 时，如果未指定用例的精度，则会报错并退出。</p></li>
<li><p><strong>aoe_tune_mode</strong> (str) - 表示启动AOE调优，默认不设置。设置为 <code class="docutils literal notranslate"><span class="pre">online</span></code> 时，将启动在线调优，设置为 <code class="docutils literal notranslate"><span class="pre">offline</span></code> 时，将为离线调优保存GE图 。</p></li>
<li><p><strong>aoe_config</strong> (dict) - 设置aoe工具专用的参数，默认不设置。</p>
<ul class="simple">
<li><p><strong>job_type</strong> (str): 设置调优类型，有算子调优和子图调优。默认为算子调优。</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;1&quot;</span></code>: 设置为子图调优。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;2&quot;</span></code>: 设置为算子调优。</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>check_bprop</strong> (bool) - 表示是否检查反向传播节点，以确保反向传播节点输出的shape和数据类型与输入参数相同。默认值： <code class="docutils literal notranslate"><span class="pre">False</span></code> 。</p></li>
<li><p><strong>max_call_depth</strong> (int) - 指定函数调用的最大深度。其值必须为正整数。默认值： <code class="docutils literal notranslate"><span class="pre">1000</span></code> 。当嵌套Cell太深或子图数量太多时，需要设置 <cite>max_call_depth</cite> 参数。系统最大堆栈深度应随着 <cite>max_call_depth</cite> 的调整而设置为更大的值，否则可能会因为系统堆栈溢出而引发 “core dumped” 异常。</p></li>
<li><p><strong>grad_for_scalar</strong> (bool) - 表示是否获取标量梯度。默认值： <code class="docutils literal notranslate"><span class="pre">False</span></code> 。当 <cite>grad_for_scalar</cite> 设置为True时，则可以导出函数的标量输入。由于后端目前不支持伸缩操作，所以该接口只支持在前端可推演的简单操作。</p></li>
<li><p><strong>enable_compile_cache</strong> (bool) - 表示是否加载或者保存前端编译的图。当 <cite>enable_compile_cache</cite> 被设置为True时，在第一次执行的过程中，一个硬件无关的编译缓存会被生成并且导出为一个MINDIR文件。当该网络被再次执行时，如果 <cite>enable_compile_cache</cite> 仍然为True并且网络脚本没有被更改，那么这个编译缓存会被加载。注意目前只支持有限的Python脚本更改的自动检测，这意味着可能有正确性风险。默认值： <code class="docutils literal notranslate"><span class="pre">False</span></code> 。这是一个实验特性，可能会被更改或者删除。</p></li>
<li><p><strong>compile_cache_path</strong> (str) - 保存编译缓存的路径。默认值：”.”。如果目录不存在，系统会自动创建这个目录。缓存会被保存到如下目录： <cite>compile_cache_path/rank_${rank_id}/</cite> 。 <cite>rank_id</cite> 是集群上当前设备的ID。</p></li>
<li><p><strong>inter_op_parallel_num</strong> (int) - 算子间并行数控制。 默认值为 <code class="docutils literal notranslate"><span class="pre">0</span></code> ，表示由框架默认指定。</p></li>
<li><p><strong>runtime_num_threads</strong> (int) - 运行时actor和CPU算子核使用的线程池线程数，必须大于等于 <code class="docutils literal notranslate"><span class="pre">0</span></code> 。默认值为 <code class="docutils literal notranslate"><span class="pre">30</span></code> ，如果同时运行多个进程，应将该值设置得小一些，以避免线程争用。</p></li>
<li><p><strong>disable_format_transform</strong> (bool) - 表示是否取消NCHW到NHWC的自动格式转换功能。当fp16的网络性能不如fp32的时，可以设置 <cite>disable_format_transform</cite> 为 <code class="docutils literal notranslate"><span class="pre">True</span></code> ，以尝试提高训练性能。默认值： <code class="docutils literal notranslate"><span class="pre">False</span></code> 。</p></li>
<li><p><strong>support_binary</strong> (bool) - 是否支持在图形模式下运行.pyc或.so。如果要支持在图形模式下运行.so或.pyc，可将 <cite>support_binary</cite> 置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> ，并运行一次.py文件，从而将接口源码保存到接口定义.py文件中，因此要保证该文件可写。然后将.py文件编译成.pyc或.so文件，即可在图模式下运行。</p></li>
<li><p><strong>memory_optimize_level</strong> (str) - 内存优化级别，默认值：O0。其值必须在 [‘O0’, ‘O1’] 范围中。</p>
<ul class="simple">
<li><p>O0: 执行性能优先，关闭 SOMAS (Safe Optimized Memory Allocation Solver)。</p></li>
<li><p>O1: 内存性能优先，使能 SOMAS。</p></li>
</ul>
</li>
<li><p><strong>memory_offload</strong> (str) - 是否开启Offload功能，在内存不足场景下将空闲数据临时拷贝至Host侧内存。其值必须在[‘ON’, ‘OFF’]范围中，默认值为 <code class="docutils literal notranslate"><span class="pre">'OFF'</span></code> 。</p>
<ul class="simple">
<li><p>ON：开启memory offload功能。在Ascend硬件平台，未设置环境变量“GRAPH_OP_RUN=1”时本参数不生效；设置memory_optimize_level=’O1’时本参数不生效。</p></li>
<li><p>OFF：关闭memory offload功能。</p></li>
</ul>
</li>
<li><p><strong>ascend_config</strong> (dict) - 设置Ascend硬件平台专用的参数，默认不设置。
precision_mode、jit_compile和atomic_clean_policy参数的默认值属于实验性质参数，将来可能会发生变化。</p>
<ul class="simple">
<li><p><strong>precision_mode</strong> (str): 混合精度模式设置。推理网络默认值： <code class="docutils literal notranslate"><span class="pre">force_fp16</span></code> 。其值范围如下：</p>
<ul>
<li><p>force_fp16: 当算子既支持float16，又支持float32时，直接选择float16。</p></li>
<li><p>allow_fp32_to_fp16: 当算子不支持float32数据类型时，直接降低精度float16。</p></li>
<li><p>allow_mix_precision: 自动混合精度，针对全网算子，按照内置的优化策略，自动将部分算子的精度降低到float16或bfloat16。</p></li>
<li><p>must_keep_origin_dtype: 保持原图精度。</p></li>
<li><p>force_fp32: 当矩阵计算的算子输入为float16，输出既支持float16又支持float32时，强制转换成float32输出。</p></li>
<li><p>allow_fp32_to_bf16: 当算子不支持float32数据类型时，直接降低精度到bfloat16。</p></li>
<li><p>allow_mix_precision_fp16: 自动混合精度，针对全网算子，按照内置的优化策略，自动将部分算子的精度降低到float16。</p></li>
<li><p>allow_mix_precision_bf16: 自动混合精度，针对全网算子，按照内置的优化策略，自动将部分算子的精度降低到bfloat16。</p></li>
</ul>
</li>
<li><p><strong>jit_compile</strong> (bool): 表示是否选择在线编译。默认值：以CANN设置的默认值为准。当设置为 <code class="docutils literal notranslate"><span class="pre">False</span></code> 时，优先选择系统中已经编译好的算子二进制文件，提升编译性能。</p></li>
<li><p><strong>atomic_clean_policy</strong> (int): 表示清理网络中atomic算子占用的内存的策略。默认值： <code class="docutils literal notranslate"><span class="pre">1</span></code> 。</p>
<ul>
<li><p>0：集中清理网络中所有atomic算子占用的内存。</p></li>
<li><p>1：不集中清理内存，对网络中每一个atomic算子进行单独清零。当网络中内存超限时，可以尝试此种清理方式，但可能会导致一定的性能损耗。</p></li>
</ul>
</li>
<li><p><strong>matmul_allow_hf32</strong> (bool): 是否为Matmul类算子使能FP32转换为HF32。默认值： <code class="docutils literal notranslate"><span class="pre">False</span></code>。这是一个实验特性，可能会被更改或者删除。如果您想了解更多详细信息，
请查询 <a class="reference external" href="https://www.hiascend.com/">昇腾社区</a> 了解。</p></li>
<li><p><strong>conv_allow_hf32</strong> (bool): 是否为Conv类算子使能FP32转换为HF32。默认值： <code class="docutils literal notranslate"><span class="pre">True</span></code>。这是一个实验特性，可能会被更改或者删除。如果您想了解更多详细信息，
请查询 <a class="reference external" href="https://www.hiascend.com/">昇腾社区</a> 了解。</p></li>
<li><p><strong>op_precision_mode</strong> (str): 算子精度模式配置文件的所在路径。如果您想了解更多详细信息, 请查询 <a class="reference external" href="https://www.hiascend.com/">昇腾社区</a> 了解。</p></li>
<li><p><strong>ge_options</strong> (dict): 设置CANN的options配置项，配置项分为 <code class="docutils literal notranslate"><span class="pre">global</span></code> 和 <code class="docutils literal notranslate"><span class="pre">session</span></code> 二类 。这是一个实验特性，可能会被更改或者删除。
详细的配置请查询 <a class="reference external" href="https://www.hiascend.com/document/detail/zh/canncommercial/70RC1/inferapplicationdev/graphdevg/atlasgeapi_07_0119.html">options配置说明</a> 。</p>
<ul>
<li><p>global (dict): 设置global类的选项。</p></li>
<li><p>session (dict): 设置session类的选项。</p></li>
</ul>
</li>
<li><p><strong>parallel_speed_up_json_path</strong> (Union[str, None]): 并行加速配置文件，配置项可以参考 <a class="reference external" href="https://gitee.com/mindspore/mindspore/blob/r2.3/config/parallel_speed_up.json">parallel_speed_up.json</a> 。
当设置为None时，表示不启用。</p>
<ul>
<li><p><strong>recompute_comm_overlap</strong> (bool): 为True时表示开启反向重计算和通信掩盖。默认值：False。</p></li>
<li><p><strong>matmul_grad_comm_overlap</strong> (bool): 为True时表示开启反向Matmul和通信掩盖。默认值：False。</p></li>
<li><p><strong>enable_task_opt</strong> (bool): 为True时表示开启通信算子task数量优化。默认值：False。</p></li>
<li><p><strong>interleaved_matmul_comm</strong> (bool): 为True时表示开启Matmul-Comm的细粒度双副本优化。默认值：False。</p></li>
<li><p><strong>interleaved_layernorm_comm</strong> (bool): 为True时表示开启LayerNorm-Comm细粒度双副本优化。默认值：False。</p></li>
</ul>
</li>
<li><p><strong>host_scheduling_max_threshold</strong> (int): 控制静态小图（根图）执行时是否使用动态shape调度的最大阈值，默认阈值为0。如果静态根图节点个数小于最大阈值，则使用动态shape调度。大模型场景，该方式可以节约stream资源。如果静态根图节点个数大于最大阈值，则保持原有流程不变。</p></li>
</ul>
</li>
<li><p><strong>jit_syntax_level</strong> (int) - 当通过GRAPH_MODE或者&#64;jit装饰器触发图编译时，此选项用于设置JIT语法支持级别。
其值必须为 <code class="docutils literal notranslate"><span class="pre">STRICT</span></code> 或 <code class="docutils literal notranslate"><span class="pre">LAX</span></code> ，默认值为 <code class="docutils literal notranslate"><span class="pre">LAX</span></code> 。全部级别都支持所有后端。</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">STRICT</span></code> : 仅支持基础语法，且执行性能最佳。可用于MindIR导入导出。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LAX</span></code> : 最大程度地兼容Python所有语法。执行性能可能会受影响，不是最佳。由于存在可能无法导出的语法，不能用于MindIR导入导出。</p></li>
</ul>
</li>
<li><p><strong>gpu_config</strong> (dict) - 设置GPU硬件平台专用的参数，默认不设置。
目前只支持GPU硬件平台上设置conv_fprop_algo、conv_dgrad_algo、conv_wgrad_algo、conv_allow_tf32和matmul_allow_tf32参数。</p>
<ul class="simple">
<li><p><strong>conv_fprop_algo</strong> (str): 指定Cudnn的卷积前向算法。默认值： <code class="docutils literal notranslate"><span class="pre">normal</span></code> 。其值范围如下：</p>
<ul>
<li><p>normal:使用Cudnn自带的启发式搜索算法，会根据卷积形状和类型快速选择合适的卷积算法。该参数不保证性能最优。</p></li>
<li><p>performance: 使用Cudnn自带的试运行搜索算法，会根据卷积形状和类型试运行所有卷积算法，然后选择最优算法。该参数保证性能最优。</p></li>
<li><p>implicit_gemm: 该算法将卷积隐式转换成矩阵乘法，完成计算。不需要显式将输入张量数据转换成矩阵形式保存。</p></li>
<li><p>implicit_precomp_gemm: 该算法将卷积隐式转换成矩阵乘法，完成计算。但是需要一些额外的内存空间去保存预计算得到的索引值，以便隐式地将输入张量数据转换成矩阵形式。</p></li>
<li><p>gemm: 该算法将卷积显式转换成矩阵乘法，完成计算。在显式完成矩阵乘法过程中，需要额外申请内存空间，将输入转换成矩阵形式。</p></li>
<li><p>direct: 该算法直接完成卷积计算，不会隐式或显式的将卷积转换成矩阵乘法。</p></li>
<li><p>fft: 该算法利用快速傅里叶变换完成卷积计算。需要额外申请内存空间，保存中间结果。</p></li>
<li><p>fft_tiling: 该算法利用快速傅里叶变换完成卷积计算，但是需要对输入进行分块。同样需要额外申请内存空间，保存中间结果，但是对大尺寸的输入，所需内存空间小于 <code class="docutils literal notranslate"><span class="pre">fft</span></code> 算法。</p></li>
<li><p>winograd: 该算法利用Winograd变换完成卷积计算。需要额外申请内存空间，保存中间结果。</p></li>
<li><p>winograd_nonfused: 该算法利用Winograd变形算法完成卷积计算。需要额外申请内存空间，保存中间结果。</p></li>
</ul>
</li>
<li><p><strong>conv_dgrad_algo</strong> (str): 指定Cudnn的卷积输入数据的反向算法。默认值： <code class="docutils literal notranslate"><span class="pre">normal</span></code> 。其值范围如下：</p>
<ul>
<li><p>normal:使用Cudnn自带的启发式搜索算法，会根据卷积形状和类型快速选择合适的卷积算法。该参数不保证性能最优。</p></li>
<li><p>performance: 使用Cudnn自带的试运行搜索算法，会根据卷积形状和类型试运行所有卷积算法，然后选择最优算法。该参数保证性能最优。</p></li>
<li><p>algo_0: 该算法将卷积表示为矩阵乘积的和，而没有实际显式地形成保存输入张量数据的矩阵。求和使用原子加法操作完成，因此结果是不确定的。</p></li>
<li><p>algo_1: 该算法将卷积表示为矩阵乘积，而没有实际显式地形成保存输入张量数据的矩阵。结果是确定的。</p></li>
<li><p>fft: 该算法利用快速傅里叶变换完成卷积计算。需要额外申请内存空间，保存中间结果。结果是确定的。</p></li>
<li><p>fft_tiling: 该算法利用快速傅里叶变换完成卷积计算，但是需要对输入进行分块。同样需要额外申请内存空间，保存中间结果，但是对大尺寸的输入，所需内存空间小于 <code class="docutils literal notranslate"><span class="pre">fft</span></code> 算法。结果是确定的。</p></li>
<li><p>winograd: 该算法利用Winograd变换完成卷积计算。需要额外申请内存空间，保存中间结果。结果是确定的。</p></li>
<li><p>winograd_nonfused: 该算法利用Winograd变形算法完成卷积计算。需要额外申请内存空间，保存中间结果。结果是确定的。</p></li>
</ul>
</li>
<li><p><strong>conv_wgrad_algo</strong> (str): 指定Cudnn的卷积输入卷积核的反向算法。默认值： <code class="docutils literal notranslate"><span class="pre">normal</span></code> 。其值范围如下：</p>
<ul>
<li><p>normal:使用Cudnn自带的启发式搜索算法，会根据卷积形状和类型快速选择合适的卷积算法。该参数不保证性能最优。</p></li>
<li><p>performance: 使用Cudnn自带的试运行搜索算法，会根据卷积形状和类型试运行所有卷积算法，然后选择最优算法。该参数保证性能最优。</p></li>
<li><p>algo_0: 该算法将卷积表示为矩阵乘积的和，而没有实际显式地形成保存输入张量数据的矩阵。求和使用原子加法操作完成，因此结果是不确定的。</p></li>
<li><p>algo_1: 该算法将卷积表示为矩阵乘积，而没有实际显式地形成保存输入张量数据的矩阵。结果是确定的。</p></li>
<li><p>algo_3: 该算法类似于 <code class="docutils literal notranslate"><span class="pre">algo_0</span></code> ，但使用一些小的工作空间来预计算一些索引。结果也是不确定的。</p></li>
<li><p>fft: 该算法利用快速傅里叶变换完成卷积计算。需要额外申请内存空间，保存中间结果。结果是确定的。</p></li>
<li><p>fft_tiling: 该算法利用快速傅里叶变换完成卷积计算，但是需要对输入进行分块。同样需要额外申请内存空间，保存中间结果，但是对大尺寸的输入，所需内存空间小于 <code class="docutils literal notranslate"><span class="pre">fft</span></code> 算法。结果是确定的。</p></li>
<li><p>winograd_nonfused: 该算法利用Winograd变形算法完成卷积计算。需要额外申请内存空间，保存中间结果。结果是确定的。</p></li>
</ul>
</li>
<li><p><strong>conv_allow_tf32</strong> (bool): 该标志表示是否开启卷积在CUDNN下的TF32张量核计算。默认值： <code class="docutils literal notranslate"><span class="pre">True</span></code> 。</p></li>
<li><p><strong>matmul_allow_tf32</strong> (bool): 该标志表示是否开启矩阵乘在CUBLAS下的TF32张量核计算。默认值： <code class="docutils literal notranslate"><span class="pre">False</span></code> 。</p></li>
</ul>
</li>
</ul>
</dd>
<dt>异常：</dt><dd><ul class="simple">
<li><p><strong>ValueError</strong> - 输入key不是上下文中的属性。</p></li>
</ul>
</dd>
</dl>
<p><strong>样例：</strong></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">precompile_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;Ascend&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_id</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">save_graphs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_graphs_path</span><span class="o">=</span><span class="s2">&quot;./model.ms&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">enable_reduce_precision</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">enable_graph_kernel</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">graph_kernel_flags</span><span class="o">=</span><span class="s2">&quot;--opt_level=2 --dump_as_text&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">reserve_class_name_in_scope</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">variable_memory_max_size</span><span class="o">=</span><span class="s2">&quot;6GB&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">aoe_tune_mode</span><span class="o">=</span><span class="s2">&quot;online&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">aoe_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;job_type&quot;</span><span class="p">:</span> <span class="s2">&quot;2&quot;</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">check_bprop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">max_device_memory</span><span class="o">=</span><span class="s2">&quot;3.5GB&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mempool_block_size</span><span class="o">=</span><span class="s2">&quot;1GB&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">print_file_path</span><span class="o">=</span><span class="s2">&quot;print.pb&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">max_call_depth</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">env_config_path</span><span class="o">=</span><span class="s2">&quot;./env_config.json&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">grad_for_scalar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">enable_compile_cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">compile_cache_path</span><span class="o">=</span><span class="s2">&quot;./cache.ms&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">pynative_synchronize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">runtime_num_threads</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">inter_op_parallel_num</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">disable_format_transform</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">memory_optimize_level</span><span class="o">=</span><span class="s1">&#39;O0&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">memory_offload</span><span class="o">=</span><span class="s1">&#39;ON&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">deterministic</span><span class="o">=</span><span class="s1">&#39;ON&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">ascend_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;precision_mode&quot;</span><span class="p">:</span> <span class="s2">&quot;force_fp16&quot;</span><span class="p">,</span> <span class="s2">&quot;jit_compile&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
<span class="gp">... </span>               <span class="s2">&quot;atomic_clean_policy&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;op_precision_mode&quot;</span><span class="p">:</span> <span class="s2">&quot;./op_precision_config_file&quot;</span><span class="p">,</span>
<span class="gp">... </span>               <span class="s2">&quot;ge_options&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;global&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;ge.opSelectImplmode&quot;</span><span class="p">:</span> <span class="s2">&quot;high_precision&quot;</span><span class="p">},</span>
<span class="gp">... </span>                              <span class="s2">&quot;session&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;ge.exec.atomicCleanPolicy&quot;</span><span class="p">:</span> <span class="s2">&quot;0&quot;</span><span class="p">}}})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">jit_syntax_level</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">STRICT</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">gpu_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;conv_fprop_algo&quot;</span><span class="p">:</span> <span class="s2">&quot;performance&quot;</span><span class="p">,</span> <span class="s2">&quot;conv_allow_tf32&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
<span class="gp">... </span>               <span class="s2">&quot;matmul_allow_tf32&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
</pre></div>
</div>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mindspore.QuantDtype.html" class="btn btn-neutral float-left" title="mindspore.QuantDtype" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="mindspore.get_context.html" class="btn btn-neutral float-right" title="mindspore.get_context" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 MindSpore.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>