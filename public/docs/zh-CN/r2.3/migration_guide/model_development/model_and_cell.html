<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>网络搭建 &mdash; MindSpore master 文档</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script><script src="../../_static/jquery.js"></script>
        <script src="../../_static/js/theme.js"></script><script src="../../_static/underscore.js"></script><script src="../../_static/doctools.js"></script><script src="../../_static/js/mermaid-9.3.0.js"></script><script src="../../_static/translations.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script><script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script><script async="async" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/mathjax/MathJax-3.2.2/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="损失函数" href="loss_function.html" />
    <link rel="prev" title="数据处理" href="dataset.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">设计</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../design/overview.html">MindSpore设计概览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/tensor_view.html">张量视图</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/programming_paradigm.html">函数式和对象式融合编程范式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/dynamic_graph_and_static_graph.html">动静态图结合</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/distributed_training_design.html">分布式并行原生</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/data_engine.html">高性能数据处理引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/all_scenarios.html">全场景统一架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/graph_fusion_engine.html">图算融合加速引擎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/pluggable_device.html">三方硬件对接</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../design/glossary.html">术语</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">模型库</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/official_models.html">官方模型库</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.html">mindspore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.nn.html">mindspore.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.ops.html">mindspore.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.ops.extend.html">mindspore.ops.extend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.ops.primitive.html">mindspore.ops.primitive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.amp.html">mindspore.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.train.html">mindspore.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.communication.html">mindspore.communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.common.initializer.html">mindspore.common.initializer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.hal.html">mindspore.hal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.dataset.html">mindspore.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.dataset.transforms.html">mindspore.dataset.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.mindrecord.html">mindspore.mindrecord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.nn.probability.html">mindspore.nn.probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.rewrite.html">mindspore.rewrite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.multiprocessing.html">mindspore.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.boost.html">mindspore.boost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.numpy.html">mindspore.numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.scipy.html">mindspore.scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_python/mindspore.experimental.html">mindspore.experimental</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API映射</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/api_mapping/pytorch_api_mapping.html">PyTorch与MindSpore API映射表</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">迁移指南</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../overview.html">迁移指南概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../enveriment_preparation.html">环境准备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../analysis_and_preparation.html">模型分析与准备</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="model_development.html">网络搭建对比</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="dataset.html">数据处理</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">网络搭建</a></li>
<li class="toctree-l2"><a class="reference internal" href="loss_function.html">损失函数</a></li>
<li class="toctree-l2"><a class="reference internal" href="learning_rate_and_optimizer.html">学习率与优化器</a></li>
<li class="toctree-l2"><a class="reference internal" href="gradient.html">梯度求导</a></li>
<li class="toctree-l2"><a class="reference internal" href="training_and_evaluation.html">训练及推理流程</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../debug_and_tune.html">调试调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sample_code.html">网络迁移调试实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">常见问题</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">语法支持</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax_support.html">静态图语法支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax/operators.html">静态图语法-运算符</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax/statements.html">静态图语法-Python语句</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/static_graph_syntax/python_builtin_functions.html">静态图语法-Python内置函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../note/index_support.html">Tensor索引支持</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">环境变量</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../note/env_var_list.html">环境变量</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq/installation.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/data_processing.html">数据处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/implement_problem.html">执行问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/network_compilation.html">网络编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/operators_compile.html">算子编译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/performance_tuning.html">性能调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/precision_tuning.html">精度调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/distributed_parallel.html">分布式并行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/inference.html">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/feature_advice.html">特性咨询</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="model_development.html">网络搭建对比</a> &raquo;</li>
      <li>网络搭建</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/migration_guide/model_development/model_and_cell.md.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section class="tex2jax_ignore mathjax_ignore" id="网络搭建">
<h1>网络搭建<a class="headerlink" href="#网络搭建" title="永久链接至标题"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r2.3/docs/mindspore/source_zh_cn/migration_guide/model_development/model_and_cell.md"><img alt="查看源文件" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3/resource/_static/logo_source.png" /></a></p>
<section id="基础逻辑">
<h2>基础逻辑<a class="headerlink" href="#基础逻辑" title="永久链接至标题"></a></h2>
<p>PyTorch和MindSpore的基础逻辑如下图所示：</p>
<p><img alt="flowchart" src="../../_images/pytorch_mindspore_comparison.png" /></p>
<p>可以看到，PyTorch和MindSpore在实现流程中一般都需要网络定义、正向计算、反向计算、梯度更新等步骤。</p>
<ul class="simple">
<li><p>网络定义：在网络定义中，一般会定义出需要的前向网络，损失函数和优化器。在Net()中定义前向网络，PyTorch的网络继承nn.Module；类似地，MindSpore的网络继承nn.Cell。在MindSpore中，除了使用MindSpore中提供的损失函数和优化器外，用户还可以使用自定义的优化器。可参考<a class="reference external" href="https://mindspore.cn/tutorials/zh-CN/r2.3/advanced/modules.html">模型模块自定义</a>。可以使用functional/nn等接口拼接需要的前向网络、损失函数和优化器。</p></li>
<li><p>正向计算：运行实例化后的网络，可以得到logit，将logit和target作为输入计算loss。需要注意的是，如果正向计算的函数有多个输出，在反向计算时需要注意多个输出对于计算结果的影响。</p></li>
<li><p>反向计算：得到loss后，我们可以进行反向计算。在PyTorch中可使用loss.backward()计算梯度，在MindSpore中，先用mindspore.grad()定义出反向传播方程net_backward，再将输入传入net_backward中，即可计算梯度。如果正向计算的函数有多个输出，在反向计算时，可将has_aux设置为True，即可保证只有第一个输出参与求导，其它输出值将直接返回。对于反向计算中接口用法区别详见<a class="reference internal" href="gradient.html"><span class="doc std std-doc">自动微分对比</span></a>。</p></li>
<li><p>梯度更新：将计算后的梯度更新到网络的Parameters中。在PyTorch中使用optim.step()；在MindSpore中，将Parameter的梯度传入定义好的optim中，即可完成梯度更新。</p></li>
</ul>
</section>
<section id="网络基本构成单元-cell">
<h2>网络基本构成单元 Cell<a class="headerlink" href="#网络基本构成单元-cell" title="永久链接至标题"></a></h2>
<p>MindSpore的网络搭建主要使用<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r2.3/api_python/nn/mindspore.nn.Cell.html#mindspore.nn.Cell">Cell</a>进行图的构造，用户需要定义一个类继承 <code class="docutils literal notranslate"><span class="pre">Cell</span></code> 这个基类，在 <code class="docutils literal notranslate"><span class="pre">init</span></code> 里声明需要使用的API及子模块，在 <code class="docutils literal notranslate"><span class="pre">construct</span></code> 里进行计算， <code class="docutils literal notranslate"><span class="pre">Cell</span></code> 在 <code class="docutils literal notranslate"><span class="pre">GRAPH_MODE</span></code> (静态图模式)下将编译为一张计算图，在 <code class="docutils literal notranslate"><span class="pre">PYNATIVE_MODE</span></code> (动态图模式)下作为神经网络的基础模块。</p>
<p>PyTorch 和 MindSpore 基本的 <code class="docutils literal notranslate"><span class="pre">Cell</span></code> 搭建过程如下所示：</p>
<table class="colwidths-auto docutils align-default">
<tr>
<td style="text-align:center"> PyTorch </td> <td style="text-align:center"> MindSpore </td>
</tr>
<tr>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">torch_nn</span>

<span class="k">class</span> <span class="nc">MyCell_pt</span><span class="p">(</span><span class="n">torch_nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">forward_net</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyCell_pt</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">forward_net</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">torch_nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="n">inner_net_pt</span> <span class="o">=</span> <span class="n">torch_nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">pt_net</span> <span class="o">=</span> <span class="n">MyCell_pt</span><span class="p">(</span><span class="n">inner_net_pt</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pt_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>    torch.Size([240, 120, 4, 4])
</pre></div>
</div>
</pre>
</td>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="k">class</span> <span class="nc">MyCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">forward_net</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">auto_prefix</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">forward_net</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="n">inner_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">my_net</span> <span class="o">=</span> <span class="n">MyCell</span><span class="p">(</span><span class="n">inner_net</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">my_net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
</pre></div>
</div>
<p>运行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[Parameter (name=net.weight, shape=(240, 120, 4, 4), dtype=Float32, requires_grad=True)]
</pre></div>
</div>
</pre>
</td>
</tr>
</table>
<p>MindSpore中，参数的名字一般是根据<code class="docutils literal notranslate"><span class="pre">__init__</span></code>定义的对象名字和参数定义时用的名字组成的，比如上面的例子中，卷积的参数名为<code class="docutils literal notranslate"><span class="pre">net.weight</span></code>，其中 <code class="docutils literal notranslate"><span class="pre">net</span></code> 是<code class="docutils literal notranslate"><span class="pre">self.net</span> <span class="pre">=</span> <span class="pre">forward_net</span></code>中的对象名，<code class="docutils literal notranslate"><span class="pre">weight</span></code>是Conv2d中定义卷积的参数时的<code class="docutils literal notranslate"><span class="pre">name</span></code>：<code class="docutils literal notranslate"><span class="pre">self.weight</span> <span class="pre">=</span> <span class="pre">Parameter(initializer(self.weight_init,</span> <span class="pre">shape),</span> <span class="pre">name='weight')</span></code>。</p>
<p>MindSpore的Cell提供了<code class="docutils literal notranslate"><span class="pre">auto_prefix</span></code>接口用来判断Cell中的参数名是否加对象名这层信息，默认是<code class="docutils literal notranslate"><span class="pre">True</span></code>，也就是加对象名。如果<code class="docutils literal notranslate"><span class="pre">auto_prefix</span></code>设置为<code class="docutils literal notranslate"><span class="pre">False</span></code>，则上面这个例子中打印的<code class="docutils literal notranslate"><span class="pre">Parameter</span></code>的<code class="docutils literal notranslate"><span class="pre">name</span></code>是<code class="docutils literal notranslate"><span class="pre">weight</span></code>。通常骨干网络<code class="docutils literal notranslate"><span class="pre">auto_prefix</span></code>应设置为True。用于训练的优化器如 :class:<code class="docutils literal notranslate"><span class="pre">mindspore.nn.TrainOneStepCell</span></code> ，应设置为False，以避免骨干网络的权重参数名被误改。</p>
</section>
<section id="单元测试">
<h2>单元测试<a class="headerlink" href="#单元测试" title="永久链接至标题"></a></h2>
<p>有了构建<code class="docutils literal notranslate"><span class="pre">Cell</span></code>的脚本，需要使用相同的输入数据和参数，对输出做比较：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">pt_net</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch_nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="n">torch_nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">cell</span> <span class="ow">in</span> <span class="n">my_net</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

<span class="n">y_ms</span> <span class="o">=</span> <span class="n">my_net</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">y_pt</span> <span class="o">=</span> <span class="n">pt_net</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_ms</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span> <span class="o">-</span> <span class="n">y_pt</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span>

<span class="c1"># ValueError: operands could not be broadcast together with shapes (2,240,12,12) (2,240,9,9)</span>
</pre></div>
</div>
<p>可以发现MindSpore和PyTorch的输出不一样，什么原因呢？</p>
<p>查询<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r2.3/note/api_mapping/pytorch_diff/Conv2d.html">API差异文档</a>发现，<code class="docutils literal notranslate"><span class="pre">Conv2d</span></code>的默认参数在MindSpore和PyTorch上有区别，
MindSpore默认使用<code class="docutils literal notranslate"><span class="pre">same</span></code>模式，PyTorch默认使用<code class="docutils literal notranslate"><span class="pre">pad</span></code>模式，迁移时需要改一下MindSpore <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code>的<code class="docutils literal notranslate"><span class="pre">pad_mode</span></code>：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">inner_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;pad&quot;</span><span class="p">)</span>
<span class="n">my_net</span> <span class="o">=</span> <span class="n">MyCell</span><span class="p">(</span><span class="n">inner_net</span><span class="p">)</span>

<span class="c1"># 构造随机输入</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">pt_net</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch_nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="c1"># 固定PyTorch初始化参数</span>
        <span class="n">torch_nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">cell</span> <span class="ow">in</span> <span class="n">my_net</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="c1"># 固定MindSpore初始化参数</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

<span class="n">y_ms</span> <span class="o">=</span> <span class="n">my_net</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">y_pt</span> <span class="o">=</span> <span class="n">pt_net</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_ms</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span> <span class="o">-</span> <span class="n">y_pt</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>2.9355288e-06
</pre></div>
</div>
<p>整体误差在万分之一左右，基本符合预期。<strong>在迁移Cell的过程中最好对每个Cell都做一次单元测试，保证迁移的一致性。</strong></p>
</section>
<section id="cell常用的方法介绍">
<h2>Cell常用的方法介绍<a class="headerlink" href="#cell常用的方法介绍" title="永久链接至标题"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">Cell</span></code>是MindSpore中神经网络的基本构成单元，提供了很多好用的方法，下面来介绍一些常用的方法。</p>
<section id="手动混合精度">
<h3>手动混合精度<a class="headerlink" href="#手动混合精度" title="永久链接至标题"></a></h3>
<p>MindSpore提供了一种自动混合精度的方法，详见<a class="reference external" href="https://www.mindspore.cn/docs/en/r2.3/api_python/train/mindspore.train.Model.html#mindspore.train.Model">Model</a>的amp_level属性。</p>
<p>但是有的时候开发网络时希望混合精度策略更加的灵活，MindSpore也提供了<a class="reference external" href="https://mindspore.cn/docs/zh-CN/r2.3/api_python/nn/mindspore.nn.Cell.html#mindspore.nn.Cell.to_float">to_float</a>的方法手动地添加混合精度。</p>
<p><code class="docutils literal notranslate"><span class="pre">to_float(dst_type)</span></code>: 在<code class="docutils literal notranslate"><span class="pre">Cell</span></code>和所有子<code class="docutils literal notranslate"><span class="pre">Cell</span></code>的输入上添加类型转换，以使用特定的浮点类型运行。</p>
<p>如果 <code class="docutils literal notranslate"><span class="pre">dst_type</span></code> 是 <code class="docutils literal notranslate"><span class="pre">ms.float16</span></code> ，<code class="docutils literal notranslate"><span class="pre">Cell</span></code>的所有输入(包括作为常量的input， <code class="docutils literal notranslate"><span class="pre">Parameter</span></code>， <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>)都会被转换为<code class="docutils literal notranslate"><span class="pre">float16</span></code>。</p>
<p>自定义的<code class="docutils literal notranslate"><span class="pre">to_float</span></code>和Model里的<code class="docutils literal notranslate"><span class="pre">amp_level</span></code>冲突，使用自定义的混合精度就不要设置Model里的<code class="docutils literal notranslate"><span class="pre">amp_level</span></code>。</p>
<p><code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> 的 <code class="docutils literal notranslate"><span class="pre">to</span></code> 接口可以实现类似功能。</p>
<p>PyTorch和MindSpore中，将一个网络里所有的BN和loss改成<code class="docutils literal notranslate"><span class="pre">float32</span></code>类型，其余操作是<code class="docutils literal notranslate"><span class="pre">float16</span></code>类型，可以这么做：</p>
<table class="colwidths-auto docutils align-default">
<tr>
<td style="text-align:center"> PyTorch 设置模型数据类型 </td> <td style="text-align:center"> MindSpore 设置模型数据类型 </td>
</tr>
<tr>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">12</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveMaxPool2d</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">)):</span>
        <span class="n">module</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</pre>
</td>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="c1"># 定义模型</span>
<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;pad&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">12</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;pad&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveMaxPool2d</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>
<span class="n">net</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>  <span class="c1"># 将net里所有的操作加float16的标志，框架会在编译时在输入加cast方法</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">cell</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">)):</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">WithLossCell</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</pre>
</td>
</tr>
</table>
</section>
<section id="parameter管理">
<h3>Parameter管理<a class="headerlink" href="#parameter管理" title="永久链接至标题"></a></h3>
<p>在 PyTorch 中，可以存储数据的对象总共有四种，分别时<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>、<code class="docutils literal notranslate"><span class="pre">Variable</span></code>、<code class="docutils literal notranslate"><span class="pre">Parameter</span></code>、<code class="docutils literal notranslate"><span class="pre">Buffer</span></code>。这四种对象的默认行为均不相同，当用户不需要求梯度时，通常使用 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>和 <code class="docutils literal notranslate"><span class="pre">Buffer</span></code>两类数据对象，当用户需要求梯度时，通常使用 <code class="docutils literal notranslate"><span class="pre">Variable</span></code> 和 <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> 两类对象。PyTorch 在设计这四种数据对象时，功能上存在冗余（<code class="docutils literal notranslate"><span class="pre">Variable</span></code> 后续会被废弃也说明了这一点）。</p>
<p>MindSpore 优化了数据对象的设计逻辑，仅保留了两种数据对象：<code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 和 <code class="docutils literal notranslate"><span class="pre">Parameter</span></code>，其中 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> 对象仅参与运算，并不需要对其进行梯度求导和Parameter更新，而 <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> 数据对象和 PyTorch 的 <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> 意义相同，会根据其属性<code class="docutils literal notranslate"><span class="pre">requires_grad</span></code> 来决定是否对其进行梯度求导和Parameter更新。在网络迁移时，只要是在PyTorch中未进行Parameter更新的数据对象，均可在MindSpore中声明为 <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>。</p>
<section id="parameter获取">
<h4>Parameter获取<a class="headerlink" href="#parameter获取" title="永久链接至标题"></a></h4>
<p><code class="docutils literal notranslate"><span class="pre">mindspore.nn.Cell</span></code> 使用 <code class="docutils literal notranslate"><span class="pre">parameters_dict</span></code> 、<code class="docutils literal notranslate"><span class="pre">get_parameters</span></code> 和 <code class="docutils literal notranslate"><span class="pre">trainable_params</span></code> 接口获取 <code class="docutils literal notranslate"><span class="pre">Cell</span></code> 中的 <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> 。</p>
<ul class="simple">
<li><p>parameters_dict：获取网络结构中所有Parameter，返回一个以key为Parameter名，value为Parameter值的<code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code>。</p></li>
<li><p>get_parameters：获取网络结构中的所有Parameter，返回<code class="docutils literal notranslate"><span class="pre">Cell</span></code>中<code class="docutils literal notranslate"><span class="pre">Parameter</span></code>的迭代器。</p></li>
<li><p>trainable_params：获取<code class="docutils literal notranslate"><span class="pre">Parameter</span></code>中<code class="docutils literal notranslate"><span class="pre">requires_grad</span></code>为<code class="docutils literal notranslate"><span class="pre">True</span></code>的属性，返回可训Parameter的列表。</p></li>
</ul>
<p>在定义优化器时，使用<code class="docutils literal notranslate"><span class="pre">net.trainable_params()</span></code>获取需要进行Parameter更新的Parameter列表。</p>
<p><code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> 使用 <code class="docutils literal notranslate"><span class="pre">get_parameter</span></code> 、 <code class="docutils literal notranslate"><span class="pre">named_parameters</span></code> 、 <code class="docutils literal notranslate"><span class="pre">parameters</span></code> 等接口获取 <code class="docutils literal notranslate"><span class="pre">Module</span></code> 中的 <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> 。</p>
<table class="colwidths-auto docutils align-default">
<tr>
<td style="text-align:center"> PyTorch </td> <td style="text-align:center"> MindSpore </td>
</tr>
<tr>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Parameter Name:&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="k">if</span> <span class="s2">&quot;bias&quot;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Parameter Name:&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Parameter Name: weight
Parameter Name: bias
Parameter Name: weight
</pre></div>
</div>
</pre>
</td>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>

<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">():</span>
    <span class="n">param_name</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span>
    <span class="k">if</span> <span class="s2">&quot;bias&quot;</span> <span class="ow">in</span> <span class="n">param_name</span><span class="p">:</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">())</span>
</pre></div>
</div>
<p>运行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[Parameter (name=weight, shape=(1, 2), dtype=Float32, requires_grad=True), Parameter (name=bias, shape=(1,), dtype=Float32, requires_grad=True)]
[Parameter (name=weight, shape=(1, 2), dtype=Float32, requires_grad=True)]
</pre></div>
</div>
</pre>
</td>
</tr>
</table>
</section>
<section id="梯度冻结">
<h4>梯度冻结<a class="headerlink" href="#梯度冻结" title="永久链接至标题"></a></h4>
<p>除了使用给Parameter设置<code class="docutils literal notranslate"><span class="pre">requires_grad=False</span></code>来不更新Parameter外，还可以使用<code class="docutils literal notranslate"><span class="pre">stop_gradient</span></code>来阻断梯度计算以达到冻结Parameter的作用。那什么时候使用<code class="docutils literal notranslate"><span class="pre">requires_grad=False</span></code>，什么时候使用<code class="docutils literal notranslate"><span class="pre">stop_gradient</span></code>呢？</p>
<p><img alt="parameter-freeze" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3/docs/mindspore/source_zh_cn/migration_guide/model_development/images/parameter_freeze.png" /></p>
<p>如上图所示，<code class="docutils literal notranslate"><span class="pre">requires_grad=False</span></code>不更新部分Parameter，但是反向的梯度计算还是正常执行的；
<code class="docutils literal notranslate"><span class="pre">stop_gradient</span></code>会直接截断反向梯度，当冻结的Parameter之前没有需要训练的Parameter时，两者在功能上是等价的。
但是<code class="docutils literal notranslate"><span class="pre">stop_gradient</span></code>会更快（少执行了一部分反向梯度计算）。
当冻结的Parameter之前有需要训练的Parameter时，只能使用<code class="docutils literal notranslate"><span class="pre">requires_grad=False</span></code>。
另外，<code class="docutils literal notranslate"><span class="pre">stop_gradient</span></code>需要加在网络的计算链路里，作用的对象是Tensor：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">A</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">B</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="parameter保存和加载">
<h4>Parameter保存和加载<a class="headerlink" href="#parameter保存和加载" title="永久链接至标题"></a></h4>
<p>MindSpore提供了<code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code>和<code class="docutils literal notranslate"><span class="pre">save_checkpoint</span></code>方法用来Parameter的保存和加载，需要注意的是Parameter保存时，保存的是Parameter列表，Parameter加载时对象必须是Cell。
在Parameter加载时，可能Parameter名对不上需要做一些修改，可以直接构造一个新的Parameter列表给到<code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code>加载到Cell。</p>
<p><code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> 提供 <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> 、 <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> 等接口保存加载模型的Parameter。</p>
<table class="colwidths-auto docutils align-default">
<tr>
<td style="text-align:center"> PyTorch </td> <td style="text-align:center"> MindSpore </td>
</tr>
<tr>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="n">linear_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">linear_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">linear_layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original linear layer parameters:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;linear_layer_params.pth&#39;</span><span class="p">)</span>

<span class="n">new_linear_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">new_linear_layer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;linear_layer_params.pth&#39;</span><span class="p">))</span>

<span class="c1"># 打印加载后的Parameter，应该和原始Parameter一样</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loaded linear layer parameters:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">new_linear_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">new_linear_layer</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Original linear layer parameters:
Parameter containing:
tensor([[1., 1.]], requires_grad=True)
Parameter containing:
tensor([0.], requires_grad=True)
Loaded linear layer parameters:
Parameter containing:
tensor([[1., 1.]], requires_grad=True)
Parameter containing:
tensor([0.], requires_grad=True)
</pre></div>
</div>
</pre>
</td>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">has_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>

<span class="n">ms</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="s2">&quot;dense.ckpt&quot;</span><span class="p">)</span>
<span class="n">dense_params</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="s2">&quot;dense.ckpt&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dense_params</span><span class="p">)</span>
<span class="n">new_params</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="n">dense_params</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param_name</span><span class="p">,</span> <span class="n">dense_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
    <span class="n">new_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">dense_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">param_name</span><span class="p">)</span>

<span class="n">ms</span><span class="o">.</span><span class="n">load_param_into_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">new_params</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">())</span>
</pre></div>
</div>
<p>运行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>weight [[-0.0042482  -0.00427286]]
bias [0.]
{&#39;weight&#39;: Parameter (name=weight, shape=(1, 2), dtype=Float32, requires_grad=True), &#39;bias&#39;: Parameter (name=bias, shape=(1,), dtype=Float32, requires_grad=True)}
weight [[-0.0042482  -0.00427286]]
bias [0.]
weight [[1. 1.]]
bias [1.]
</pre></div>
</div>
</pre>
</td>
</tr>
</table>
</section>
<section id="parameter初始化">
<h4>Parameter初始化<a class="headerlink" href="#parameter初始化" title="永久链接至标题"></a></h4>
<section id="默认权重初始化不同">
<h5>默认权重初始化不同<a class="headerlink" href="#默认权重初始化不同" title="永久链接至标题"></a></h5>
<p>我们知道权重初始化对网络的训练十分重要。每个nn接口一般会有一个隐式的声明权重，在不同的框架中，隐式的声明权重可能不同。即使功能一致，隐式声明的权重初始化方式分布如果不同，也会对训练过程产生影响，甚至无法收敛。</p>
<p>常见隐式声明权重的nn接口：Conv、Dense(Linear)、Embedding、LSTM 等，其中区别较大的是 Conv 类和 Dense 两种接口。MindSpore和PyTorch的 Conv 类和 Dense 隐式声明的权重和偏差初始化方式分布相同。</p>
<ul>
<li><p>Conv2d</p>
<ul class="simple">
<li><p>mindspore.nn.Conv2d的weight为：<span class="math notranslate nohighlight">\(\mathcal{U} (-\sqrt{k},\sqrt{k} )\)</span>，bias为：<span class="math notranslate nohighlight">\(\mathcal{U} (-\sqrt{k},\sqrt{k} )\)</span>。</p></li>
<li><p>torch.nn.Conv2d的weight为：<span class="math notranslate nohighlight">\(\mathcal{U} (-\sqrt{k},\sqrt{k} )\)</span>，bias为：<span class="math notranslate nohighlight">\(\mathcal{U} (-\sqrt{k},\sqrt{k} )\)</span>。</p></li>
<li><p>tf.keras.Layers.Conv2D的weight为：glorot_uniform，bias为：zeros。</p></li>
</ul>
<p>其中，<span class="math notranslate nohighlight">\(k=\frac{groups}{c_{in}*\prod_{i}^{}{kernel\_size[i]}}\)</span></p>
</li>
<li><p>Dense(Linear)</p>
<ul class="simple">
<li><p>mindspore.nn.Dense的weight为：<span class="math notranslate nohighlight">\(\mathcal{U}(-\sqrt{k},\sqrt{k})\)</span>，bias为：<span class="math notranslate nohighlight">\(\mathcal{U}(-\sqrt{k},\sqrt{k} )\)</span>。</p></li>
<li><p>torch.nn.Linear的weight为：<span class="math notranslate nohighlight">\(\mathcal{U}(-\sqrt{k},\sqrt{k})\)</span>，bias为：<span class="math notranslate nohighlight">\(\mathcal{U}(-\sqrt{k},\sqrt{k} )\)</span>。</p></li>
<li><p>tf.keras.Layers.Dense的weight为：glorot_uniform，bias为：zeros。</p></li>
</ul>
</li>
</ul>
<p>其中，<span class="math notranslate nohighlight">\(k=\frac{groups}{in\_features}\)</span> 。</p>
<p>对于没有正则化的网络，如没有 BatchNorm 算子的 GAN 网络，梯度很容易爆炸或者消失，权重初始化就显得十分重要，各位开发者应注意权重初始化带来的影响。</p>
</section>
<section id="parameter初始化api对比">
<h5>Parameter初始化API对比<a class="headerlink" href="#parameter初始化api对比" title="永久链接至标题"></a></h5>
<p>每个 <code class="docutils literal notranslate"><span class="pre">torch.nn.init</span></code> 的API都可以和MindSpore一一对应，除了 <code class="docutils literal notranslate"><span class="pre">torch.nn.init.calculate_gain()</span></code> 之外。更多信息，请查看<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r2.3/note/api_mapping/pytorch_api_mapping.html">PyTorch与MindSpore API映射表</a>。</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">gain</span></code> 用来衡量非线性关系对于数据标准差的影响。由于非线性会影响数据的标准差，可能会导致梯度爆炸或消失。</p>
</div></blockquote>
<table class="colwidths-auto docutils align-default">
<tr>
<td style="text-align:center"> torch.nn.init </td> <td style="text-align:center"> mindspore.common.initializer </td>
</tr>
<tr>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</pre>
</td>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindspore.common.initializer</span> <span class="kn">import</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">Uniform</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">initializer</span><span class="p">(</span><span class="n">Uniform</span><span class="p">(),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</pre>
</td>
</tr>
</table>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mindspore.common.initializer</span></code> 用于在并行模式中延迟Tensor的数据的初始化。只有在调用了 <code class="docutils literal notranslate"><span class="pre">init_data()</span></code> 之后，才会使用指定的 <code class="docutils literal notranslate"><span class="pre">init</span></code> 来初始化Tensor的数据。每个Tensor只能使用一次 <code class="docutils literal notranslate"><span class="pre">init_data()</span></code> 。在运行以上代码之后，<code class="docutils literal notranslate"><span class="pre">x</span></code> 其实尚未完成初始化。如果此时 <code class="docutils literal notranslate"><span class="pre">x</span></code> 被用来计算，将会作为0来处理。然而，在打印时，会自动调用 <code class="docutils literal notranslate"><span class="pre">init_data()</span></code> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.nn.init</span></code> 需要一个Tensor作为输入，将输入的Tensor原地修改为目标结果，运行上述代码之后，x将不再是非初始化状态，其元素将服从均匀分布。</p></li>
</ul>
</section>
<section id="自定义初始化parameter">
<h5>自定义初始化Parameter<a class="headerlink" href="#自定义初始化parameter" title="永久链接至标题"></a></h5>
<p>MindSpore封装的高阶API里一般会给Parameter一个默认的初始化，当这个初始化分布与需要使用的初始化、PyTorch的初始化不一致时，此时需要进行自定义初始化。<a class="reference external" href="https://mindspore.cn/tutorials/zh-CN/r2.3/advanced/modules/initializer.html#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96">网络参数初始化</a>介绍了一种在使用API属性时进行初始化的方法，这里介绍一种利用Cell进行Parameter初始化的方法。</p>
<p>Parameter的相关介绍请参考<a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/r2.3/advanced/modules/initializer.html">网络参数</a>，本节主要以<code class="docutils literal notranslate"><span class="pre">Cell</span></code>为切入口，举例获取<code class="docutils literal notranslate"><span class="pre">Cell</span></code>中的所有参数，并举例说明如何给<code class="docutils literal notranslate"><span class="pre">Cell</span></code>里的Parameter进行初始化。</p>
<blockquote>
<div><p>注意本节的方法不能在<code class="docutils literal notranslate"><span class="pre">construct</span></code>里执行，在网络中修改Parameter的值请使用<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r2.3/api_python/ops/mindspore.ops.assign.html">assign</a>。</p>
</div></blockquote>
<p>MindSpore支持的Parameter初始化方法参考<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r2.3/api_python/mindspore.common.initializer.html">mindspore.common.initializer</a>，当然也可以直接传入一个定义好的<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r2.3/api_python/mindspore/mindspore.Parameter.html#mindspore.Parameter">Parameter</a>对象。</p>
<p>已经创建的Parameter，可以使用<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r2.3/api_python/mindspore/mindspore.Parameter.html?highlight=set_data#mindspore.Parameter.set_data">set_data(data, slice_shape=False)</a>设置Parameter数据。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="c1"># 定义模型</span>
<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;pad&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">12</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;pad&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveMaxPool2d</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">cell</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span>
            <span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">HeNormal</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fan_out&#39;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
            <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">)):</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;ones&quot;</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;zeros&quot;</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">)):</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span>
            <span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">HeUniform</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)),</span>
            <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="n">cell</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">initializer</span><span class="p">(</span><span class="s2">&quot;zeros&quot;</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="子模块管理">
<h3>子模块管理<a class="headerlink" href="#子模块管理" title="永久链接至标题"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">mindspore.nn.Cell</span></code> 中可定义其他Cell实例作为子模块。这些子模块是网络中的组成部分，自身也可能包含可学习的Parameter（如卷积层的权重和偏置）和其他子模块。这种层次化的模块结构允许用户构建复杂且可重用的神经网络架构。</p>
<p><code class="docutils literal notranslate"><span class="pre">mindspore.nn.Cell</span></code> 提供 <code class="docutils literal notranslate"><span class="pre">cells_and_names</span></code> 、 <code class="docutils literal notranslate"><span class="pre">insert_child_to_cell</span></code> 等接口实现子模块管理功能。</p>
<p><code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> 提供 <code class="docutils literal notranslate"><span class="pre">named_modules</span></code> 、 <code class="docutils literal notranslate"><span class="pre">add_module</span></code> 等接口实现子模块管理功能。</p>
<table class="colwidths-auto docutils align-default">
<tr>
<td style="text-align:center"> PyTorch </td> <td style="text-align:center"> MindSpore </td>
</tr>
<tr>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># 使用add_module添加子模块</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s1">&#39;conv3&#39;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sequential_block</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequential_block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">module</span> <span class="o">=</span> <span class="n">MyModule</span><span class="p">()</span>

<span class="c1"># 使用named_modules遍历所有子模块（包括直接和间接子模块）</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module_instance</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Module name: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">, type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">module_instance</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Module name: , type: &lt;class &#39;__main__.MyModule&#39;&gt;
Module name: conv1, type: &lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt;
Module name: conv2, type: &lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt;
Module name: conv3, type: &lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt;
Module name: sequential_block, type: &lt;class &#39;torch.nn.modules.container.Sequential&#39;&gt;
Module name: sequential_block.0, type: &lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt;
Module name: sequential_block.1, type: &lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt;
Module name: sequential_block.2, type: &lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt;
</pre></div>
</div>
</pre>
</td>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">MyCell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># 使用insert_child_to_cell添加子模块</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">insert_child_to_cell</span><span class="p">(</span><span class="s1">&#39;conv3&#39;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sequential_block</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SequentialCell</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequential_block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">module</span> <span class="o">=</span> <span class="n">MyCell</span><span class="p">()</span>

<span class="c1"># 使用cells_and_names遍历所有子模块（包括直接和间接子模块）</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">cell_instance</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">cells_and_names</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cell name: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">, type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">cell_instance</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Cell name: , type: &lt;class &#39;__main__.MyCell&#39;&gt;
Cell name: conv1, type: &lt;class &#39;mindspore.nn.layer.conv.Conv2d&#39;&gt;
Cell name: conv2, type: &lt;class &#39;mindspore.nn.layer.conv.Conv2d&#39;&gt;
Cell name: conv3, type: &lt;class &#39;mindspore.nn.layer.conv.Conv2d&#39;&gt;
Cell name: sequential_block, type: &lt;class &#39;mindspore.nn.layer.container.SequentialCell&#39;&gt;
Cell name: sequential_block.0, type: &lt;class &#39;mindspore.nn.layer.activation.ReLU&#39;&gt;
Cell name: sequential_block.1, type: &lt;class &#39;mindspore.nn.layer.conv.Conv2d&#39;&gt;
Cell name: sequential_block.2, type: &lt;class &#39;mindspore.nn.layer.activation.ReLU&#39;&gt;
</pre></div>
</div>
</pre>
</td>
</tr>
</table>
</section>
<section id="训练评估模式切换">
<h3>训练评估模式切换<a class="headerlink" href="#训练评估模式切换" title="永久链接至标题"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> 提供 <code class="docutils literal notranslate"><span class="pre">train(mode=True)</span></code> 接口设置模型处于训练模式和 <code class="docutils literal notranslate"><span class="pre">eval</span></code> 接口设置模型处于评估模式。这两种模式的区别主要体现在Dropout和BN等层的行为以及权重更新上。</p>
<ul>
<li><p>Dropout和BN层的行为：</p>
<p>训练模式下，Dropout层会按照设定的参数 <code class="docutils literal notranslate"><span class="pre">p</span></code> 来随机关闭一部分神经元，这意味着在前向传播过程中，这部分神经元不会有任何贡献。BN层会继续计算均值和方差，并对数据进行相应的归一化。</p>
<p>评估模式下，Dropout层不会关闭任何神经元，即所有的神经元都会被用于前向传播。BN层会使用训练阶段计算得到的运行均值和运行方差。</p>
</li>
<li><p>权重更新：</p>
<p>在训练模式下，模型的权重会根据反向传播的结果进行更新。这意味着在每次前向传播和反向传播之后，模型的权重都可能会发生变化。</p>
<p>在评估模式下，模型的权重不会被更新。即使进行了前向传播并计算了损失，也不会进行反向传播来更新权重。这是因为评估模式主要用于测试模型的性能，而不是训练模型。</p>
</li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">mindspore.nn.Cell</span></code> 提供 <code class="docutils literal notranslate"><span class="pre">set_train(mode=True)</span></code> 接口实现模式的切换。<code class="docutils literal notranslate"><span class="pre">mode</span></code> 设置成 <code class="docutils literal notranslate"><span class="pre">True</span></code> 时，模型处于训练模式；<code class="docutils literal notranslate"><span class="pre">mode</span></code> 设置成 <code class="docutils literal notranslate"><span class="pre">False</span></code> 时，模型处于评估模式。</p>
</section>
<section id="设备相关">
<h3>设备相关<a class="headerlink" href="#设备相关" title="永久链接至标题"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> 提供 <code class="docutils literal notranslate"><span class="pre">CPU</span></code> 、 <code class="docutils literal notranslate"><span class="pre">cuda</span></code> 、 <code class="docutils literal notranslate"><span class="pre">ipu</span></code> 等接口将模型移动到指定设备上。</p>
<p><code class="docutils literal notranslate"><span class="pre">mindspore.set_context()</span></code> 的 <code class="docutils literal notranslate"><span class="pre">device_target</span></code> 参数实现类似功能， <code class="docutils literal notranslate"><span class="pre">device_target</span></code> 可以指定 <code class="docutils literal notranslate"><span class="pre">CPU</span></code> 、 <code class="docutils literal notranslate"><span class="pre">GPU</span></code> 和 <code class="docutils literal notranslate"><span class="pre">Ascend</span></code> 设备。与PyTorch不同的是，一旦设备设置成功，输入数据和模型会默认拷贝到指定的设备中执行，不需要也无法再改变数据和模型所运行的设备类型。</p>
<table class="colwidths-auto docutils align-default">
<tr>
<td style="text-align:center"> PyTorch </td> <td style="text-align:center"> MindSpore </td>
</tr>
<tr>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">torch_net</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">torch_net</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</pre></div>
</div>
</pre>
</td>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="n">mindspore</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">device_target</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>
<span class="n">ms_net</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</pre>
</td>
</tr>
</table>
</section>
</section>
<section id="动态图与静态图">
<h2>动态图与静态图<a class="headerlink" href="#动态图与静态图" title="永久链接至标题"></a></h2>
<p>对于<code class="docutils literal notranslate"><span class="pre">Cell</span></code>，MindSpore提供<code class="docutils literal notranslate"><span class="pre">GRAPH_MODE</span></code>（静态图）和<code class="docutils literal notranslate"><span class="pre">PYNATIVE_MODE</span></code>（动态图）两种模式，详情请参考<a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/r2.3/beginner/accelerate_with_static_graph.html">动态图和静态图</a>。</p>
<p><code class="docutils literal notranslate"><span class="pre">PyNative</span></code>模式下模型进行<strong>推理</strong>的行为与一般Python代码无异。但是在训练过程中，注意<strong>一旦将Tensor转换成numpy做其他的运算后将会截断网络的梯度，相当于PyTorch的detach</strong>。</p>
<p>而在使用<code class="docutils literal notranslate"><span class="pre">GRAPH_MODE</span></code>时，通常会出现语法限制。在这种情况下，需要对Python代码进行图编译操作，而这一步操作中MindSpore目前还未能支持完整的Python语法全集，所以<code class="docutils literal notranslate"><span class="pre">construct</span></code>函数的编写会存在部分限制。具体限制内容可以参考<a class="reference external" href="https://www.mindspore.cn/docs/zh-CN/r2.3/note/static_graph_syntax_support.html">MindSpore静态图语法</a>。</p>
<p>相较于详细的语法说明，常见的限制可以归结为以下几点：</p>
<ul>
<li><p>场景1</p>
<p>限制：构图时（<code class="docutils literal notranslate"><span class="pre">construct</span></code>函数部分或者用<code class="docutils literal notranslate"><span class="pre">&#64;jit</span></code>修饰的函数），不要调用其他Python库，例如numpy、scipy，相关的处理应该前移到<code class="docutils literal notranslate"><span class="pre">__init__</span></code>阶段。
措施：使用MindSpore内部提供的API替换其他Python库的功能。常量的处理可以前移到<code class="docutils literal notranslate"><span class="pre">__init__</span></code>阶段。</p>
</li>
<li><p>场景2</p>
<p>限制：构图时不要使用自定义类型，而应该使用MindSpore提供的数据类型和Python基础类型，可以使用基于这些类型的tuple/list组合。
措施：使用基础类型进行组合，可以考虑增加函数参数量。函数入参数没有限制，并且可以使用不定长输入。</p>
</li>
<li><p>场景3</p>
<p>限制：构图时不要对数据进行多线程或多进程处理。
措施：避免网络中出现多线程处理。</p>
</li>
</ul>
</section>
<section id="自定义反向">
<h2>自定义反向<a class="headerlink" href="#自定义反向" title="永久链接至标题"></a></h2>
<p>有时MindSpore不支持某些处理，需要使用一些第三方库的方法，但是我们又不想截断网络的梯度，这时该怎么办呢？这里介绍一种在<code class="docutils literal notranslate"><span class="pre">PYNATIVE_MODE</span></code>模式下，通过自定义反向规避此问题的方法：</p>
<p>如下面此场景，需要随机有放回的选取大于0.5的值，且每个batch的shape固定是<code class="docutils literal notranslate"><span class="pre">max_num</span></code>。但是这个随机有放回的操作目前没有MindSpore的API支持，这时我们在<code class="docutils literal notranslate"><span class="pre">PYNATIVE_MODE</span></code>下使用numpy的方法来计算，然后自己构造一个梯度传播的过程。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">MySampler</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="c1"># 自定义取样器，在每个batch选取max_num个大于0.5的值</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_num</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MySampler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_num</span> <span class="o">=</span> <span class="n">max_num</span>

    <span class="k">def</span> <span class="nf">random_positive</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># 三方库numpy的方法，选取大于0.5的位置</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">pos_indice</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_num</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pos_indice</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># 正向网络构造</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">pos_value</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">pos_indice</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
            <span class="n">pos_ind</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_positive</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
            <span class="n">pos_value</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">pos_ind</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            <span class="n">pos_indice</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">pos_ind</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
        <span class="n">pos_values</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">pos_value</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">pos_indices</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">pos_indice</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pos_values forword&quot;</span><span class="p">,</span> <span class="n">pos_values</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pos_indices forword&quot;</span><span class="p">,</span> <span class="n">pos_indices</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pos_values</span><span class="p">,</span> <span class="n">pos_indices</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">MySampler</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">pos_values</span><span class="p">,</span> <span class="n">pos_indices</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">grad</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">sampler</span><span class="p">,</span> <span class="n">grad_position</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dx&quot;</span><span class="p">,</span> <span class="n">grad</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>x [[1.2510660e+00 2.1609735e+00 3.4312444e-04 9.0699774e-01 4.4026768e-01]
 [2.7701578e-01 5.5878061e-01 1.0366821e+00 1.1903024e+00 1.6164502e+00]]
pos_values forword [[0.90699774 2.1609735  0.90699774]
 [0.5587806  1.6164502  0.5587806 ]]
pos_indices forword [[3 1 3]
 [1 4 1]]
pos_values forword [[0.90699774 1.251066   2.1609735 ]
 [1.1903024  1.1903024  0.5587806 ]]
pos_indices forword [[3 0 1]
 [3 3 1]]
dx (Tensor(shape=[2, 5], dtype=Float32, value=
[[0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
 [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]),)
</pre></div>
</div>
<p>当我们不构造这个反向过程时，由于使用的是numpy的方法计算的<code class="docutils literal notranslate"><span class="pre">pos_value</span></code>，梯度将会截断。
如上面注释所示，<code class="docutils literal notranslate"><span class="pre">dx</span></code>的值全是0。另外细心的同学会发现这个过程打印了两次<code class="docutils literal notranslate"><span class="pre">pos_values</span> <span class="pre">forword</span></code>和<code class="docutils literal notranslate"><span class="pre">pos_indices</span> <span class="pre">forword</span></code>，这是因为在<code class="docutils literal notranslate"><span class="pre">PYNATIVE_MODE</span></code>下在构造反向图时会再次构造一次正向图，这使得上面的这种写法实际上跑了两次正向和一次反向，这不但浪费了训练资源，在某些情况还会造成精度问题，如有BatchNorm的情况，在运行正向时就会更新<code class="docutils literal notranslate"><span class="pre">moving_mean</span></code>和<code class="docutils literal notranslate"><span class="pre">moving_var</span></code>导致一次训练更新了两次<code class="docutils literal notranslate"><span class="pre">moving_mean</span></code>和<code class="docutils literal notranslate"><span class="pre">moving_var</span></code>。
为了避免这种场景，MindSpore针对<code class="docutils literal notranslate"><span class="pre">Cell</span></code>有一个方法<code class="docutils literal notranslate"><span class="pre">set_grad()</span></code>，在<code class="docutils literal notranslate"><span class="pre">PYNATIVE_MODE</span></code>模式下框架会在构造正向时同步构造反向，这样在执行反向时就不会再运行正向的流程了。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">MySampler</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">set_grad</span><span class="p">()</span>
<span class="n">pos_values</span><span class="p">,</span> <span class="n">pos_indices</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">grad</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">sampler</span><span class="p">,</span> <span class="n">grad_position</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dx&quot;</span><span class="p">,</span> <span class="n">grad</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>x [[1.2519144  1.6760695  0.42116082 0.59430444 2.4022336 ]
 [2.9047847  0.9402725  2.076968   2.6291676  2.68382   ]]
pos_values forword [[1.2519144 1.2519144 1.6760695]
 [2.6291676 2.076968  0.9402725]]
pos_indices forword [[0 0 1]
 [3 2 1]]
dx (Tensor(shape=[2, 5], dtype=Float32, value=
[[0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
 [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]),)
</pre></div>
</div>
<p>下面，我们来演示下如何<a class="reference external" href="https://mindspore.cn/tutorials/zh-CN/r2.3/advanced/modules/layer.html#%E8%87%AA%E5%AE%9A%E4%B9%89cell%E5%8F%8D%E5%90%91">自定义反向</a>：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">mindspore.ops</span> <span class="k">as</span> <span class="nn">ops</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">MySampler</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="c1"># 自定义取样器，在每个batch选取max_num个大于0.5的值</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_num</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MySampler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_num</span> <span class="o">=</span> <span class="n">max_num</span>

    <span class="k">def</span> <span class="nf">random_positive</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># 三方库numpy的方法，选取大于0.5的位置</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">pos_indice</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_num</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pos_indice</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># 正向网络构造</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">pos_value</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">pos_indice</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
            <span class="n">pos_ind</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_positive</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
            <span class="n">pos_value</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">pos_ind</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            <span class="n">pos_indice</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">pos_ind</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
        <span class="n">pos_values</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">pos_value</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">pos_indices</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">pos_indice</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pos_values forword&quot;</span><span class="p">,</span> <span class="n">pos_values</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pos_indices forword&quot;</span><span class="p">,</span> <span class="n">pos_indices</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pos_values</span><span class="p">,</span> <span class="n">pos_indices</span>

    <span class="k">def</span> <span class="nf">bprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">dout</span><span class="p">):</span>
        <span class="c1"># 反向网络构造</span>
        <span class="n">pos_indices</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pos_indices backward&quot;</span><span class="p">,</span> <span class="n">pos_indices</span><span class="p">)</span>
        <span class="n">grad_x</span> <span class="o">=</span> <span class="n">dout</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;grad_x backward&quot;</span><span class="p">,</span> <span class="n">grad_x</span><span class="p">)</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">dx</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
            <span class="n">dx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">UnsortedSegmentSum</span><span class="p">()(</span><span class="n">grad_x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">pos_indices</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">MySampler</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">set_grad</span><span class="p">()</span>
<span class="n">pos_values</span><span class="p">,</span> <span class="n">pos_indices</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">grad</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">sampler</span><span class="p">,</span> <span class="n">grad_position</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dx&quot;</span><span class="p">,</span> <span class="n">grad</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>x [[1.2510660e+00 2.1609735e+00 3.4312444e-04 9.0699774e-01 4.4026768e-01]
 [2.7701578e-01 5.5878061e-01 1.0366821e+00 1.1903024e+00 1.6164502e+00]]
pos_values forword [[0.90699774 2.1609735  0.90699774]
 [0.5587806  1.6164502  0.5587806 ]]
pos_indices forword [[3 1 3]
 [1 4 1]]
pos_indices backward [[3 1 3]
 [1 4 1]]
grad_x backward [[1. 1. 1.]
 [1. 1. 1.]]
dx (Tensor(shape=[2, 5], dtype=Float32, value=
[[0.00000000e+000, 1.00000000e+000, 0.00000000e+000, 2.00000000e+000, 0.00000000e+000],
 [0.00000000e+000, 2.00000000e+000, 0.00000000e+000, 0.00000000e+000, 1.00000000e+000]]),)
</pre></div>
</div>
<p>我们在<code class="docutils literal notranslate"><span class="pre">MySampler</span></code>类里加入了<code class="docutils literal notranslate"><span class="pre">bprop</span></code>方法，这个方法的输入是正向的输入（展开写），正向的输出（一个tuple），输出的梯度（一个tuple）。在这个方法里构造梯度到输入的梯度反传流程。
可以看到在第0个batch，我们随机选取第3、1、3位置的值，输出的梯度都是1，最后反传出去的梯度为<code class="docutils literal notranslate"><span class="pre">[0.00000000e+000,</span> <span class="pre">1.00000000e+000,</span> <span class="pre">0.00000000e+000,</span> <span class="pre">2.00000000e+000,</span> <span class="pre">0.00000000e+000]</span></code>，符合预期。</p>
</section>
<section id="动态shape规避策略">
<h2>动态shape规避策略<a class="headerlink" href="#动态shape规避策略" title="永久链接至标题"></a></h2>
<p>一般动态shape引入的原因有：</p>
<ul class="simple">
<li><p>输入shape不固定；</p></li>
<li><p>网络执行过程中有引发shape变化的算子；</p></li>
<li><p>控制流不同分支引入shape上的变化。</p></li>
</ul>
<p>下面，我们针对这几种场景介绍一些规避策略。</p>
<section id="输入shape不固定的场景">
<h3>输入shape不固定的场景<a class="headerlink" href="#输入shape不固定的场景" title="永久链接至标题"></a></h3>
<ol class="arabic simple">
<li><p>可以在输入数据上加pad，pad到固定的shape。如deep_speechv2的<a class="reference external" href="https://gitee.com/mindspore/models/blob/master/official/audio/DeepSpeech2/src/dataset.py#L153">数据处理</a> 规定<code class="docutils literal notranslate"><span class="pre">input_length</span></code>的最大长度，短的补0，长的随机截断，但是注意这种方法可能会影响训练的精度，需要平衡训练精度和训练性能。</p></li>
<li><p>可以设置一组固定的输入shape，将输入分别处理成几个固定的shape。如YOLOv3_darknet53的<a class="reference external" href="https://gitee.com/mindspore/models/blob/master/official/cv/YOLOv3/src/yolo_dataset.py#L177">数据处理</a>，在batch方法加处理函数<code class="docutils literal notranslate"><span class="pre">multi_scale_trans</span></code> ，在<a class="reference external" href="https://gitee.com/mindspore/models/blob/master/official/cv/YOLOv3/src/transforms.py#L456">MultiScaleTrans</a>中随机选取一个shape进行处理。</p></li>
</ol>
<p>目前对输入shape完全随机的情况支持有限，需要等待新版本支持。</p>
</section>
<section id="网络执行过程中有引发shape变化的操作">
<h3>网络执行过程中有引发shape变化的操作<a class="headerlink" href="#网络执行过程中有引发shape变化的操作" title="永久链接至标题"></a></h3>
<p>对于网络运行过程中生成不固定shape的Tensor的场景，最常用的方式是构造mask来过滤掉无效的位置的值。一个简单的例子，在检测场景下需要根据预测框和真实框的iou结果选取一些框。
PyTorch 和 MindSpore（MindSpore1.8之后全场景支持了<code class="docutils literal notranslate"><span class="pre">masked_select</span></code>） 的实现方式如下：</p>
<table class="colwidths-auto docutils align-default">
<tr>
<td style="text-align:center"> PyTorch </td> <td style="text-align:center"> MindSpore </td>
</tr>
<tr>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">box_select_torch</span><span class="p">(</span><span class="n">box</span><span class="p">,</span> <span class="n">iou_score</span><span class="p">):</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">iou_score</span> <span class="o">&gt;</span> <span class="mf">0.3</span>
    <span class="k">return</span> <span class="n">box</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
</pre></div>
</div>
</pre>
</td>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">box_select_ms</span><span class="p">(</span><span class="n">box</span><span class="p">,</span> <span class="n">iou_score</span><span class="p">):</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">iou_score</span> <span class="o">&gt;</span> <span class="mf">0.3</span><span class="p">)</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">box</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
</pre></div>
</div>
</pre>
</td>
</tr>
</table>
<p>看一下结果对比：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">box</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">iou_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;box_select_ms&quot;</span><span class="p">,</span> <span class="n">box_select_ms</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">box</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">iou_score</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;box_select_torch&quot;</span><span class="p">,</span> <span class="n">box_select_torch</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">box</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">iou_score</span><span class="p">)))</span>
</pre></div>
</div>
<p>运行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>box_select_ms [0.14675589 0.09233859 0.18626021 0.34556073]
box_select_torch tensor([[0.1468, 0.0923, 0.1863, 0.3456]])
</pre></div>
</div>
<p>但是这样操作后会产生动态shape，在后续的网络计算中可能会有问题，在现阶段，推荐先使用mask规避一下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">box_select_ms2</span><span class="p">(</span><span class="n">box</span><span class="p">,</span> <span class="n">iou_score</span><span class="p">):</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">iou_score</span> <span class="o">&gt;</span> <span class="mf">0.3</span><span class="p">)</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">box</span> <span class="o">*</span> <span class="n">mask</span><span class="p">,</span> <span class="n">mask</span>
</pre></div>
</div>
<p>在后续计算中，如果涉及box的一些操作，需要注意是否需要乘mask用来过滤非有效结果。</p>
<p>对于求loss时对feature做选取，导致获取到不固定shape的Tensor的场景，处理方式基本和网络运行过程中不固定shape的处理方式相同，只是loss部分后续可能没有其他的操作，不需要返回mask。</p>
<p>举个例子，我们想选取前70%的正样本的值求loss。实现如下：</p>
<table class="colwidths-auto docutils align-default">
<tr>
<td style="text-align:center"> PyTorch </td> <td style="text-align:center"> MindSpore </td>
</tr>
<tr>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">torch_nn</span>

<span class="k">class</span> <span class="nc">ClassLoss_pt</span><span class="p">(</span><span class="n">torch_nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ClassLoss_pt</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">con_loss</span> <span class="o">=</span> <span class="n">torch_nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>

    <span class="c1"># 使用 torch.topk 来获取前70%的正样本数据</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">label</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="n">vaild_label</span> <span class="o">=</span> <span class="n">label</span> <span class="o">*</span> <span class="n">mask</span>
        <span class="n">pos_num</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">int</span><span class="p">()</span>
        <span class="n">con</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">con_loss</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">vaild_label</span><span class="o">.</span><span class="n">long</span><span class="p">())</span> <span class="o">*</span> <span class="n">mask</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">unused_value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">con</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">pos_num</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</pre>
</td>
<td style="vertical-align:top"><pre>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">nn</span> <span class="k">as</span> <span class="n">ms_nn</span>
<span class="k">class</span> <span class="nc">ClassLoss_ms</span><span class="p">(</span><span class="n">ms_nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ClassLoss_ms</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">con_loss</span> <span class="o">=</span> <span class="n">ms_nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sort_descending</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sort</span><span class="p">(</span><span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># MindSpore目前不支持TopK的K是变量，转换思路，获取到第K大的值，然后通过该值获取到topk的mask</span>
    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">label</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="n">vaild_label</span> <span class="o">=</span> <span class="n">label</span> <span class="o">*</span> <span class="n">mask</span>
        <span class="n">pos_num</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="n">con</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">con_loss</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">vaild_label</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span> <span class="o">*</span> <span class="n">mask</span>
        <span class="n">con_sort</span><span class="p">,</span> <span class="n">unused_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sort_descending</span><span class="p">(</span><span class="n">con</span><span class="p">)</span>
        <span class="n">con_k</span> <span class="o">=</span> <span class="n">con_sort</span><span class="p">[</span><span class="n">pos_num</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">con_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">con</span> <span class="o">&gt;=</span> <span class="n">con_k</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">con</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">con</span> <span class="o">*</span> <span class="n">con_mask</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">con_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</pre>
</td>
</tr>
</table>
<p>我们来看一下实验结果：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="n">ms</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pred&quot;</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
<span class="n">t_loss</span> <span class="o">=</span> <span class="n">ClassLoss_pt</span><span class="p">()</span>
<span class="n">cls_loss_pt</span> <span class="o">=</span> <span class="n">t_loss</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">pred</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">label</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cls_loss_pt&quot;</span><span class="p">,</span> <span class="n">cls_loss_pt</span><span class="p">)</span>
<span class="n">m_loss</span> <span class="o">=</span> <span class="n">ClassLoss_ms</span><span class="p">()</span>
<span class="n">cls_loss_ms</span> <span class="o">=</span> <span class="n">m_loss</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">pred</span><span class="p">),</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">label</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cls_loss_ms&quot;</span><span class="p">,</span> <span class="n">cls_loss_ms</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>pred [[4.17021990e-01 7.20324516e-01]
 [1.14374816e-04 3.02332580e-01]
 [1.46755889e-01 9.23385918e-02]
 [1.86260208e-01 3.45560730e-01]
 [3.96767467e-01 5.38816750e-01]]
label [-1  0  1  1  0]
cls_loss_pt tensor(0.7207)
cls_loss_ms 0.7207259
</pre></div>
</div>
</section>
<section id="控制流不同分支引入shape上的变化">
<h3>控制流不同分支引入shape上的变化<a class="headerlink" href="#控制流不同分支引入shape上的变化" title="永久链接至标题"></a></h3>
<p>分析下在模型分析与准备章节的例子：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">cond</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>

<span class="k">if</span> <span class="n">cond</span><span class="p">:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cond</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[4.17021990e-01 7.20324516e-01 1.14374816e-04 3.02332580e-01
 1.46755889e-01 9.23385918e-02 1.86260208e-01 3.45560730e-01
 3.96767467e-01 5.38816750e-01]
True
[0.7203245  0.53881675]
</pre></div>
</div>
<p>在<code class="docutils literal notranslate"><span class="pre">cond=True</span></code>时，最大的shape和x一样大，根据上面的加mask方法，可以写成：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">cond</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>

<span class="k">if</span> <span class="n">cond</span><span class="p">:</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">mask</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cond</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>运行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[4.17021990e-01 7.20324516e-01 1.14374816e-04 3.02332580e-01
 1.46755889e-01 9.23385918e-02 1.86260208e-01 3.45560730e-01
 3.96767467e-01 5.38816750e-01]
True
[0.         0.7203245  0.         0.         0.         0.
 0.         0.         0.         0.53881675]
</pre></div>
</div>
<p>需要注意的是如果y在后续有参与其他的计算，需要一起传入mask对有效位置做过滤。</p>
</section>
</section>
<section id="随机数策略对比">
<h2>随机数策略对比<a class="headerlink" href="#随机数策略对比" title="永久链接至标题"></a></h2>
<section id="随机数api对比">
<h3>随机数API对比<a class="headerlink" href="#随机数api对比" title="永久链接至标题"></a></h3>
<p>PyTorch与MindSpore在接口名称上无差异，MindSpore由于不支持原地修改，所以缺少<code class="docutils literal notranslate"><span class="pre">Tensor.random_</span></code>接口。其余接口均可和PyTorch一一对应。</p>
</section>
<section id="随机种子和生成器">
<h3>随机种子和生成器<a class="headerlink" href="#随机种子和生成器" title="永久链接至标题"></a></h3>
<p>MindSpore使用<code class="docutils literal notranslate"><span class="pre">seed</span></code>控制随机数的生成，而PyTorch使用<code class="docutils literal notranslate"><span class="pre">torch.Generator</span></code>进行随机数的控制。</p>
<ol class="arabic">
<li><p>MindSpore的seed分为两个等级，graph-level和op-level。graph-level下seed作为全局变量，绝大多数情况下无需用户设置，用户只需调整op-level seed。（API中涉及的<code class="docutils literal notranslate"><span class="pre">seed</span></code>参数，均为op-level）如果一段程序中两次使用了同一个随机数算法，那么两次的结果是不同的（尽管设置了相同的随机种子）；如果重新运行脚本，那么第二次运行的结果应该与第一次保持一致。示例如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># If a random op is called twice within one program, the two results will be different:</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">ops</span>

<span class="n">minval</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">maxval</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># generates &#39;A1&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># generates &#39;A2&#39;</span>
<span class="c1"># If the same program runs again, it repeat the results:</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># generates &#39;A1&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">minval</span><span class="p">,</span> <span class="n">maxval</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># generates &#39;A2&#39;</span>
</pre></div>
</div>
<p>不同后端产生随机数不同，以下是 <code class="docutils literal notranslate"><span class="pre">CPU</span></code> 后端运行结果：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[[1.4519546 1.242295  1.9052019 1.7309945]]
[[1.269552  1.6567562 1.9240322 1.7505953]]
[[1.8540323 1.3442079 1.074909  1.0930715]]
[[1.9383929 1.8798318 1.178043  1.8124416]]
</pre></div>
</div>
</li>
<li><p>torch.Generator常在函数中作为关键字参数传入。在未指定/实例化Generator时，会使用默认Generator (torch.default_generator)。可以使用以下代码设置指定的torch.Generator的seed：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">G</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
<span class="n">G</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>此时和使用default_generator并将seed设置为1的结果相同。例如torch.manual_seed(1)。</p>
<p>PyTorch的Generator中的state表示的是此Generator的状态，长度为5056，dtype为uint8的Tensor。在同一个脚本中，多次使用同一个Generator，Generator的state会发生改变。在有两个/多个Generator的情况下，如g1，g2，可以设置 g2.set_state(g1.get_state()) 使得g2达到和g1相同的状态。即使用g2相当于使用当时状态的g1。如果g1和g2具有相同的seed和state，则二者生成的随机数相同。</p>
</li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="dataset.html" class="btn btn-neutral float-left" title="数据处理" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="loss_function.html" class="btn btn-neutral float-right" title="损失函数" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 MindSpore.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>