<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Horizontal FL-Local Differential Privacy Perturbation Training &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script><script async="async" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/mathjax/MathJax-3.2.2/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Horizontal FL-Local Differential Privacy SignDS training" href="local_differential_privacy_training_signds.html" />
    <link rel="prev" title="Vertical Federated Learning Model Training - Pangu Alpha Large Model Cross-Domain Training" href="split_pangu_alpha_application.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="federated_install.html">Obtaining MindSpore Federated</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_federated_server.html">Horizontal Federated Cloud-based Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_federated_client.html">Horizontal Federated Device-side Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_vfl.html">Vertical Federated Deployment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Horizontal Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="image_classfication_dataset_process.html">Federated Learning Image Classification Dataset Process</a></li>
<li class="toctree-l1"><a class="reference internal" href="image_classification_application.html">Implementing an Image Classification Application of Cross-device Federated Learning (x86)</a></li>
<li class="toctree-l1"><a class="reference internal" href="sentiment_classification_application.html">Implementing a Sentiment Classification Application (Android)</a></li>
<li class="toctree-l1"><a class="reference internal" href="image_classification_application_in_cross_silo.html">Implementing a Cloud-Slio Federated Image Classification Application (x86)</a></li>
<li class="toctree-l1"><a class="reference internal" href="object_detection_application_in_cross_silo.html">Implementing a Cross-Silo Federated Target Detection Application (x86)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Vertical Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="data_join.html">Vertical Federated Learning Data Access</a></li>
<li class="toctree-l1"><a class="reference internal" href="split_wnd_application.html">Vertical Federated Learning Model Training - Wide&amp;Deep Recommendation Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="split_pangu_alpha_application.html">Vertical Federated Learning Model Training - Pangu Alpha Large Model Cross-Domain Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Security and Privacy</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Horizontal FL-Local Differential Privacy Perturbation Training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#principles">Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="#usage">Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="local_differential_privacy_training_signds.html">Horizontal FL-Local Differential Privacy SignDS training</a></li>
<li class="toctree-l1"><a class="reference internal" href="local_differential_privacy_eval_laplace.html">Horizontal Federated-Local Differential Privacy Inference Result Protection</a></li>
<li class="toctree-l1"><a class="reference internal" href="pairwise_encryption_training.html">Horizontal FL-Pairwise encryption training</a></li>
<li class="toctree-l1"><a class="reference internal" href="private_set_intersection.html">Vertical Federated-Privacy Set Intersection</a></li>
<li class="toctree-l1"><a class="reference internal" href="secure_vertical_federated_learning_with_EmbeddingDP.html">Vertical Federated-Feature Protection Based on Information Obfuscation</a></li>
<li class="toctree-l1"><a class="reference internal" href="secure_vertical_federated_learning_with_TEE.html">Vertical Federated - Feature Protection Based on Trusted Execution Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="secure_vertical_federated_learning_with_DP.html">Vertical Federated - Label Protection Based on Differential Privacy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Communication Compression</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="communication_compression.html">Device-Cloud Federated Learning Communication Compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="vfl_communication_compress.html">Vertical Federated Learning Communication Compression</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Horizontal Federated API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="horizontal_server.html">Federated Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="cross_device.html">Device-side Client</a></li>
<li class="toctree-l1"><a class="reference internal" href="horizontal/cross_silo.html">Cross-Silo</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Vertical Federated API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Data_Join.html">Data Join</a></li>
<li class="toctree-l1"><a class="reference internal" href="vertical/vertical_communicator.html">Vertical Federated Learning Communicator</a></li>
<li class="toctree-l1"><a class="reference internal" href="vertical_federated_trainer.html">Vertical Federated Trainer</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Horizontal FL-Local Differential Privacy Perturbation Training</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/local_differential_privacy_training_noise.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="horizontal-fl-local-differential-privacy-perturbation-training">
<h1>Horizontal FL-Local Differential Privacy Perturbation Training<a class="headerlink" href="#horizontal-fl-local-differential-privacy-perturbation-training" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/federated/docs/source_en/local_differential_privacy_training_noise.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.svg" /></a></p>
<p>During federated learning, user data is used only for local device training and does not need to be uploaded to the central server. This prevents personal data leakage.
However, in the conventional federated learning framework, models are migrated to the cloud in plaintext. There is still a risk of indirect disclosure of user privacy.
After obtaining the plaintext model uploaded by a user, the attacker can restore the user’s personal training data through attacks such as reconstruction and model inversion. As a result, user privacy is disclosed.</p>
<p>As a federated learning framework, MindSpore Federated provides secure aggregation algorithms based on local differential privacy (LDP). Noise addition is performed on local models before they are migrated to the cloud. On the premise of ensuring the model availability, the problem of privacy leakage in horizontal federated learning is solved.</p>
<section id="principles">
<h2>Principles<a class="headerlink" href="#principles" title="Permalink to this headline"></a></h2>
<p>Differential privacy is a mechanism for protecting user data privacy. Differential privacy is defined as follows:</p>
<div class="math notranslate nohighlight">
\[
Pr[\mathcal{K}(D)\in S] \le e^{\epsilon} Pr[\mathcal{K}(D') \in S]+\delta​
\]</div>
<p>For datasets <span class="math notranslate nohighlight">\(D and D'\)</span> that have only one record difference, the random algorithm <span class="math notranslate nohighlight">\(\mathcal{K}\)</span> is used to compute the probability of the <span class="math notranslate nohighlight">\(S\)</span> subset, which meets the preceding formula. <span class="math notranslate nohighlight">\(\epsilon\)</span> is the differential privacy budget, and <span class="math notranslate nohighlight">\(\delta\)</span> is the perturbation. The smaller the values of <span class="math notranslate nohighlight">\(\epsilon\)</span> and <span class="math notranslate nohighlight">\(\delta\)</span>, the closer the data distribution of <span class="math notranslate nohighlight">\(\mathcal{K}\)</span> on <span class="math notranslate nohighlight">\(D\)</span> and <span class="math notranslate nohighlight">\(D'\)</span>.</p>
<p>In horizontal federated learning, if the model weight matrix after local training on the client is <span class="math notranslate nohighlight">\(W\)</span>, the attacker can use <span class="math notranslate nohighlight">\(W\)</span> to restore the training dataset[1] of the user because the model “remembers” the features of the training set during the training process.</p>
<p>MindSpore Federated provides a LDP-based secure aggregation algorithm to prevent privacy data leakage when local models are migrated to the cloud.</p>
<p>The MindSpore Federated client generates a differential noise matrix <span class="math notranslate nohighlight">\(G\)</span> that has the same dimension as the local model <span class="math notranslate nohighlight">\(W\)</span>, and then adds the two to obtain a weight <span class="math notranslate nohighlight">\(W_p\)</span> that meets the differential privacy definition:</p>
<div class="math notranslate nohighlight">
\[
W_p=W+G
\]</div>
<p>The MindSpore Federated client uploads the noise-added model <span class="math notranslate nohighlight">\(W_p\)</span> to the cloud server for federated aggregation. The noise matrix <span class="math notranslate nohighlight">\(G\)</span> is equivalent to adding a layer of mask to the original model, which reduces the risk of sensitive data leakage from models and affects the convergence of model training. How to achieve a better balance between model privacy and usability is still a question worth studying. Experiments show that when the number of participants <span class="math notranslate nohighlight">\(n\)</span> is large enough (generally more than 1000), most of the noises can cancel each other, and the LDP mechanism has no obvious impact on the accuracy and convergence of the aggregation model.</p>
</section>
<section id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this headline"></a></h2>
<p>Local differential privacy training currently only supports cross device scenarios. Enabling differential privacy training is simple. You only need to set the <code class="docutils literal notranslate"><span class="pre">encrypt_train_type</span></code> field to <code class="docutils literal notranslate"><span class="pre">DP_ENCRYPT</span></code> via <a class="reference external" href="https://www.mindspore.cn/federated/docs/en/master/horizontal/federated_server_yaml.html#">yaml</a> when starting the cloud-side service.</p>
<p>In addition, to control the effect of privacy protection, three parameters are provided: <code class="docutils literal notranslate"><span class="pre">dp_eps</span></code>, <code class="docutils literal notranslate"><span class="pre">dp_delta</span></code>, and <code class="docutils literal notranslate"><span class="pre">dp_norm_clip</span></code>. They are also set through the yaml file.</p>
<p>The valid value range of <code class="docutils literal notranslate"><span class="pre">dp_eps</span></code> and <code class="docutils literal notranslate"><span class="pre">dp_norm_clip</span></code> is greater than 0. The legal range of <code class="docutils literal notranslate"><span class="pre">dp_delta</span></code> is 0&lt;<code class="docutils literal notranslate"><span class="pre">dp_delta</span></code>&lt;1. In general, the smaller <code class="docutils literal notranslate"><span class="pre">dp_eps</span></code> and <code class="docutils literal notranslate"><span class="pre">dp_delta</span></code> are, the better the privacy protection will be, but the greater the impact on the convergence of the model. It is recommended that <code class="docutils literal notranslate"><span class="pre">dp_delta</span></code> be taken as the inverse of the number of clients and <code class="docutils literal notranslate"><span class="pre">dp_eps</span></code> be greater than 50.</p>
<p><code class="docutils literal notranslate"><span class="pre">dp_norm_clip</span></code> is the adjustment coefficient of the model weight before noise is added to the model weight by the LDP mechanism. It affects the convergence of the model. The recommended value ranges from 0.5 to 2.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline"></a></h2>
<p>[1] Ligeng Zhu, Zhijian Liu, and Song Han. <a class="reference external" href="http://arxiv.org/pdf/1906.08935.pdf">Deep Leakage from Gradients</a>. NeurIPS, 2019.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="split_pangu_alpha_application.html" class="btn btn-neutral float-left" title="Vertical Federated Learning Model Training - Pangu Alpha Large Model Cross-Domain Training" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="local_differential_privacy_training_signds.html" class="btn btn-neutral float-right" title="Horizontal FL-Local Differential Privacy SignDS training" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>