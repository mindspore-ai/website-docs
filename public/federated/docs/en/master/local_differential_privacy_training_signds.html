<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Horizontal FL-Local Differential Privacy SignDS training &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script><script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script><script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Horizontal Federated-Local Differential Privacy Inference Result Protection" href="local_differential_privacy_eval_laplace.html" />
    <link rel="prev" title="Horizontal FL-Local Differential Privacy Perturbation Training" href="local_differential_privacy_training_noise.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="federated_install.html">Obtaining MindSpore Federated</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_federated_server.html">Horizontal Federated Cloud-based Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_federated_client.html">Horizontal Federated Device-side Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_vfl.html">Vertical Federated Deployment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Horizontal Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="image_classfication_dataset_process.html">Federated Learning Image Classification Dataset Process</a></li>
<li class="toctree-l1"><a class="reference internal" href="image_classification_application.html">Implementing an Image Classification Application of Cross-device Federated Learning (x86)</a></li>
<li class="toctree-l1"><a class="reference internal" href="sentiment_classification_application.html">Implementing a Sentiment Classification Application (Android)</a></li>
<li class="toctree-l1"><a class="reference internal" href="image_classification_application_in_cross_silo.html">Implementing a Cloud-Slio Federated Image Classification Application (x86)</a></li>
<li class="toctree-l1"><a class="reference internal" href="object_detection_application_in_cross_silo.html">Implementing a Cross-Silo Federated Target Detection Application (x86)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Vertical Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="data_join.html">Vertical Federated Learning Data Access</a></li>
<li class="toctree-l1"><a class="reference internal" href="split_wnd_application.html">Vertical Federated Learning Model Training - Wide&amp;Deep Recommendation Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="split_pangu_alpha_application.html">Vertical Federated Learning Model Training - Pangu Alpha Large Model Cross-Domain Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Security and Privacy</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="local_differential_privacy_training_noise.html">Horizontal FL-Local Differential Privacy Perturbation Training</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Horizontal FL-Local Differential Privacy SignDS training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#privacy-protection-background">Privacy Protection Background</a></li>
<li class="toctree-l2"><a class="reference internal" href="#algorithm-flow-introduction">Algorithm Flow Introduction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#signds">SignDS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#magrr">MagRR</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#privacy-protection-certificate">Privacy Protection Certificate</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#dimensional-selection-mechanism-based-on-index-mechanism">Dimensional Selection Mechanism Based on Index Mechanism</a></li>
<li class="toctree-l3"><a class="reference internal" href="#local-differential-privacy-random-response-mechanism">Local Differential Privacy-Random Response Mechanism</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#frequency-statistics-based-on-random-response-mechanism">Frequency Statistics Based on Random Response Mechanism</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#preparation">Preparation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#algorithm-opening-script">Algorithm Opening Script</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lenet-experiment-results">LeNet Experiment results</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="local_differential_privacy_eval_laplace.html">Horizontal Federated-Local Differential Privacy Inference Result Protection</a></li>
<li class="toctree-l1"><a class="reference internal" href="pairwise_encryption_training.html">Horizontal FL-Pairwise encryption training</a></li>
<li class="toctree-l1"><a class="reference internal" href="private_set_intersection.html">Vertical Federated-Privacy Set Intersection</a></li>
<li class="toctree-l1"><a class="reference internal" href="secure_vertical_federated_learning_with_EmbeddingDP.html">Vertical Federated-Feature Protection Based on Information Obfuscation</a></li>
<li class="toctree-l1"><a class="reference internal" href="secure_vertical_federated_learning_with_TEE.html">Vertical Federated - Feature Protection Based on Trusted Execution Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="secure_vertical_federated_learning_with_DP.html">Vertical Federated - Label Protection Based on Differential Privacy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Communication Compression</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="communication_compression.html">Device-Cloud Federated Learning Communication Compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="vfl_communication_compress.html">Vertical Federated Learning Communication Compression</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Horizontal Federated API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="horizontal_server.html">Federated Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="cross_device.html">Device-side Client</a></li>
<li class="toctree-l1"><a class="reference internal" href="horizontal/cross_silo.html">Cross-Silo</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Vertical Federated API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Data_Join.html">Data Join</a></li>
<li class="toctree-l1"><a class="reference internal" href="vertical/vertical_communicator.html">Vertical Federated Learning Communicator</a></li>
<li class="toctree-l1"><a class="reference internal" href="vertical_federated_trainer.html">Vertical Federated Trainer</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Horizontal FL-Local Differential Privacy SignDS training</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/local_differential_privacy_training_signds.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="horizontal-fl-local-differential-privacy-signds-training">
<h1>Horizontal FL-Local Differential Privacy SignDS training<a class="headerlink" href="#horizontal-fl-local-differential-privacy-signds-training" title="Permalink to this headline">ÔÉÅ</a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/master/docs/federated/docs/source_en/local_differential_privacy_training_signds.md"><img alt="View Source On Gitee" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.svg" /></a></p>
<section id="privacy-protection-background">
<h2>Privacy Protection Background<a class="headerlink" href="#privacy-protection-background" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>Federated learning enables the client user to participate in global model training without uploading the original dataset by allowing the participant to upload only the new model after local training or update the update information of the model, breaking through the data silos. This common scenario of federated learning corresponds to the default scheme in the MindSpore federated learning framework, where the <code class="docutils literal notranslate"><span class="pre">encrypt_train_type</span></code> switch defaults to <code class="docutils literal notranslate"><span class="pre">not_encrypt</span></code> when starting the <code class="docutils literal notranslate"><span class="pre">server</span></code>. The <code class="docutils literal notranslate"><span class="pre">installation</span> <span class="pre">and</span> <span class="pre">deployment</span></code> and <code class="docutils literal notranslate"><span class="pre">application</span> <span class="pre">practices</span></code> in the federated learning tutorial both use this approach by default, which is a common federated seeking averaging scheme without any privacy-protecting treatment such as cryptographic perturbation. For the convenience of description, `not_encrypt‚Äô is used below to refer specifically to this default scheme.</p>
<p>This federated learning scheme is not free from privacy leakage, using the above <code class="docutils literal notranslate"><span class="pre">not_encrypt</span></code> scheme for training. The Server receives the local training model uploaded by the Client, which can still reconstruct the user training data through some attack methods [1], thus leaking user privacy, so the <code class="docutils literal notranslate"><span class="pre">not_encrypt</span></code> scheme needs to further increase the user privacy protection mechanism.</p>
<p>The global model <code class="docutils literal notranslate"><span class="pre">oldModel</span></code> received by the Client in each round of federated learning is issued by the Server, which does not involve user privacy issues. However, the local model <code class="docutils literal notranslate"><span class="pre">newModel</span></code> obtained by each Client after several epochs of local training fits its local privacy data, so the privacy protection focuses on the weight difference between the two <code class="docutils literal notranslate"><span class="pre">newModel</span></code>-<code class="docutils literal notranslate"><span class="pre">oldModel</span></code>=<code class="docutils literal notranslate"><span class="pre">update</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">DP_ENCRYPT</span></code> differential noise scheme already implemented in the MindSpore Federated framework achieves privacy preservation by iteratively perturbing Gaussian random noise to <code class="docutils literal notranslate"><span class="pre">update</span></code>. However, as the dimensionality of the model increases, the increase in the <code class="docutils literal notranslate"><span class="pre">update</span></code> paradigm will increase the noise, thus requiring more Clients to participate in the same round of aggregation to neutralize the noise impact, otherwise the convergence and accuracy of the model will be reduced. If the noise is set too small, although the convergence and accuracy are close to the performance of the <code class="docutils literal notranslate"><span class="pre">not_encrypt</span></code> scheme, the privacy protection is not strong enough. Also each Client needs to send the perturbed model, and as the model increases, the communication overhead increases. We expect the Client represented by the cell phone to achieve convergence of the global model with as little communication overhead as possible.</p>
</section>
<section id="algorithm-flow-introduction">
<h2>Algorithm Flow Introduction<a class="headerlink" href="#algorithm-flow-introduction" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>SignDS [2] is the abbreviation of Sign Dimension Select, and the processing object is the <code class="docutils literal notranslate"><span class="pre">update</span></code> of Client. Preparation: each layer of Tensor of <code class="docutils literal notranslate"><span class="pre">update</span></code> is flattened and expanded into a one-dimensional vector, connected together, and the number of splicing vector dimensions is noted as <span class="math notranslate nohighlight">\(d\)</span>.</p>
<p>One sentence summarizes the algorithm: Each participant only uploads information about the important dimensions, including their gradient directions and privacy-preserving steps, which corresponds to the SignDS and MagRR (Magnitude Random Response) modules in the figure below, respectively.</p>
<p><img alt="img" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/federated/docs/source_zh_cn/images/signds_framework.png" /></p>
<p>Here is an example: there are 3 clients Client1, 2, 3, whose <code class="docutils literal notranslate"><span class="pre">update</span></code> is a <span class="math notranslate nohighlight">\(d=8\)</span>-dimensional vector after flattening and expanding, and the Server calculates the <code class="docutils literal notranslate"><span class="pre">avg</span></code> of these 3 clients Client and updates the global model with the value, that is, completes a round of federated learning.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-center head"><p>Client</p></th>
<th class="text-center head"><p>d_1</p></th>
<th class="text-center head"><p>d_2</p></th>
<th class="text-center head"><p>d_3</p></th>
<th class="text-center head"><p>d_4</p></th>
<th class="text-center head"><p>d_5</p></th>
<th class="text-center head"><p>d_6</p></th>
<th class="text-center head"><p>d_7</p></th>
<th class="text-center head"><p>d_8</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>1</p></td>
<td class="text-center"><p>0.4</p></td>
<td class="text-center"><p>0.1</p></td>
<td class="text-center"><p>-0.2</p></td>
<td class="text-center"><p>0.3</p></td>
<td class="text-center"><p>0.5</p></td>
<td class="text-center"><p>0.1</p></td>
<td class="text-center"><p>-0.2</p></td>
<td class="text-center"><p>-0.3</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>2</p></td>
<td class="text-center"><p>0.5</p></td>
<td class="text-center"><p>0.2</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0.1</p></td>
<td class="text-center"><p>0.3</p></td>
<td class="text-center"><p>0.2</p></td>
<td class="text-center"><p>-0.1</p></td>
<td class="text-center"><p>-0.2</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>3</p></td>
<td class="text-center"><p>0.3</p></td>
<td class="text-center"><p>0.1</p></td>
<td class="text-center"><p>-0.1</p></td>
<td class="text-center"><p>0.5</p></td>
<td class="text-center"><p>0.2</p></td>
<td class="text-center"><p>0.3</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0.1</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>avg</p></td>
<td class="text-center"><p>0.4</p></td>
<td class="text-center"><p>0.13</p></td>
<td class="text-center"><p>-0.1</p></td>
<td class="text-center"><p>0.3</p></td>
<td class="text-center"><p>0.33</p></td>
<td class="text-center"><p>0.2</p></td>
<td class="text-center"><p>-0.1</p></td>
<td class="text-center"><p>-0.13</p></td>
</tr>
</tbody>
</table>
<section id="signds">
<h3>SignDS<a class="headerlink" href="#signds" title="Permalink to this headline">ÔÉÅ</a></h3>
<p>The dimension with higher importance should be selected, and the importance measure is the size of the <strong>fetching value</strong>, and the update needs to be sorted. update takes positive and negative values to represent different update directions, so in each round of federated learning, the sign values of Client each have <strong>0.5 probability</strong> of taking <code class="docutils literal notranslate"><span class="pre">1</span></code> or <code class="docutils literal notranslate"><span class="pre">-1</span></code>. If sign=1, the largest <span class="math notranslate nohighlight">\(k\)</span> number of <code class="docutils literal notranslate"><span class="pre">update</span></code> dimensions are noted as the <code class="docutils literal notranslate"><span class="pre">topk</span></code> set and the remaining ones are noted as the <code class="docutils literal notranslate"><span class="pre">non-topk</span></code> set. If sign=-1, the smallest <span class="math notranslate nohighlight">\(k\)</span> number of ones are noted as the <code class="docutils literal notranslate"><span class="pre">topk</span></code> set.</p>
<p>If the Server specifies <code class="docutils literal notranslate"><span class="pre">h</span></code>, the total number of selected dimensions, the Client will directly use this value, otherwise each Client will locally calculate the optimal output dimension <code class="docutils literal notranslate"><span class="pre">h</span></code>.</p>
<p>The SignDS algorithm outputs the number of dimensions (denoted as <span class="math notranslate nohighlight">\(v\)</span>) that should be selected from the <code class="docutils literal notranslate"><span class="pre">topk</span></code> set and the <code class="docutils literal notranslate"><span class="pre">non-topk</span></code> set, as in the example in the table below, where the two sets pick a total of dimensions h=3.</p>
<p>Client selects dimensions uniformly and randomly according to the number of dimensions output by the SignDS algorithm, sends the dimension number and sign value to the Server. If the dimension number is output in the order of picking from <code class="docutils literal notranslate"><span class="pre">topk</span></code> first and then from <code class="docutils literal notranslate"><span class="pre">non-topk</span></code>, the dimension number list <code class="docutils literal notranslate"><span class="pre">index</span></code> needs to be shuffled and disordered. The following table shows the part of information finally transferred from each Client of this algorithm to the Server.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-center head"><p>Client</p></th>
<th class="text-center head"><p>index</p></th>
<th class="text-center head"><p>sign</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>1</p></td>
<td class="text-center"><p>1,5,8</p></td>
<td class="text-center"><p>1</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>2</p></td>
<td class="text-center"><p>2,3,4</p></td>
<td class="text-center"><p>-1</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>3</p></td>
<td class="text-center"><p>3,6,7</p></td>
<td class="text-center"><p>1</p></td>
</tr>
</tbody>
</table>
</section>
<section id="magrr">
<h3>MagRR<a class="headerlink" href="#magrr" title="Permalink to this headline">ÔÉÅ</a></h3>
<p>The Server receives the dimension direction from the client, but it is not clear what the step size to update in that direction is. Generally speaking, the step length tends to be large at the beginning of training, and shrinks as the training gradually converges. The general trend of step length change is shown in the following figure:</p>
<p><img alt="img" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/federated/docs/source_zh_cn/images/signds_step_length.png" /></p>
<p>The Server wants to estimate a dynamic range <span class="math notranslate nohighlight">\([0,2‚àór_{est}]\)</span> for the actual step <span class="math notranslate nohighlight">\(r\)</span>, and thus compute the global learning rate <span class="math notranslate nohighlight">\(lr_{global}=2‚àór_{est}*num_{clients}\)</span>.</p>
<p>The <span class="math notranslate nohighlight">\(r\)</span> adjustment uses a similar dichotomous idea. The specific process is as follows:</p>
<ol class="arabic simple">
<li><p>The server initializes a smaller <span class="math notranslate nohighlight">\(r_{est}\)</span> before the start of training (which does not affect the direction of model convergence too much);</p></li>
<li><p>After each round of local training, the participant calculates the true magnitude <span class="math notranslate nohighlight">\(r\)</span> (mean of topk dimensions) and converts <span class="math notranslate nohighlight">\(r\)</span> to <span class="math notranslate nohighlight">\(b\)</span> with certain rules based on the current <span class="math notranslate nohighlight">\(r_{est}\)</span> issued from the cloud side;</p></li>
<li><p>The participant performs local differential Binary Randomized Response (BRR) perturbation on <span class="math notranslate nohighlight">\(b\)</span> and upload the results.</p></li>
</ol>
<p>The whole training process is divided into two phases, namely the <strong>fast growth</strong> phase and the <strong>contraction</strong> phase. The rules for <span class="math notranslate nohighlight">\(r \rightarrow b\)</span> conversions and server-side updates of <span class="math notranslate nohighlight">\(r_{est}\)</span> are slightly different for the participant in the two phases:</p>
<ul>
<li><p>In the fast growth phase, a smaller <span class="math notranslate nohighlight">\(r_{est}\)</span> is chosen, such as <span class="math notranslate nohighlight">\(e^{-5}\)</span>. At this point, <span class="math notranslate nohighlight">\(r_{est}\)</span> is expanded by a certain multiple.
Therefore, we can define:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  b = \begin{cases}
    0 &amp; r \in [2*r_{est}, \infty] \\
    1 &amp; r \in [0,2*r_{est})]
    \end{cases}
  \end{split}\]</div>
<p>The server aggregates all device-side random response results for frequency statistics and calculates the plurality <span class="math notranslate nohighlight">\(B\)</span>.
If <span class="math notranslate nohighlight">\(B=0\)</span>, it is considered that <span class="math notranslate nohighlight">\(r_{est}\)</span> has not reached the range of ùëü at present and needs to continue increasing <span class="math notranslate nohighlight">\(r_{est}\)</span>;
If <span class="math notranslate nohighlight">\(B=1\)</span>, <span class="math notranslate nohighlight">\(r_{est}\)</span> is considered to have reached the range of ùëü, and keep <span class="math notranslate nohighlight">\(r_{est}\)</span> unchanged.</p>
</li>
<li><p>In the contraction phase, it is necessary to fine-tune <span class="math notranslate nohighlight">\(r_{est}\)</span> according to the changes in <span class="math notranslate nohighlight">\(r\)</span>. Therefore we can define:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  b = \begin{cases}
    0 &amp; r \in [r_{est}, \infty] \\
    1 &amp; r \in [0,r_{est})]
    \end{cases}
  \end{split}\]</div>
<p>Calculate <span class="math notranslate nohighlight">\(B\)</span>, and if <span class="math notranslate nohighlight">\(B=0\)</span> , consider that <span class="math notranslate nohighlight">\(r_{est}\)</span> and <span class="math notranslate nohighlight">\(r\)</span> are currently closer and keep <span class="math notranslate nohighlight">\(r_{est}\)</span> unchanged;
If <span class="math notranslate nohighlight">\(B=1\)</span>, <span class="math notranslate nohighlight">\(r\)</span> is considered to be generally smaller than <span class="math notranslate nohighlight">\(r_{est}\)</span>, and <span class="math notranslate nohighlight">\(r_{est}\)</span> is halved.</p>
</li>
</ul>
<p>The Server constructs <code class="docutils literal notranslate"><span class="pre">update</span></code> with privacy protection based on the dimension serial number, sign value and <span class="math notranslate nohighlight">\(r_{est}\)</span> uploaded by each Client, and aggregates and averages all <code class="docutils literal notranslate"><span class="pre">update</span></code> and updates the current <code class="docutils literal notranslate"><span class="pre">oldModel</span></code> to complete one round of federated learning. The following table shows the aggregation when <span class="math notranslate nohighlight">\(2‚àór_{est}*num_{clients}=1\)</span>.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-center head"><p>Client</p></th>
<th class="text-center head"><p>d_1</p></th>
<th class="text-center head"><p>d_2</p></th>
<th class="text-center head"><p>d_3</p></th>
<th class="text-center head"><p>d_4</p></th>
<th class="text-center head"><p>d_5</p></th>
<th class="text-center head"><p>d_6</p></th>
<th class="text-center head"><p>d_7</p></th>
<th class="text-center head"><p>d_8</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>1</p></td>
<td class="text-center"><p><strong>1</strong></p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p><strong>1</strong></p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p><strong>1</strong></p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>2</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p><strong>-1</strong></p></td>
<td class="text-center"><p><strong>-1</strong></p></td>
<td class="text-center"><p><strong>-1</strong></p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>3</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p><strong>1</strong></p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p><strong>1</strong></p></td>
<td class="text-center"><p><strong>1</strong></p></td>
<td class="text-center"><p>0</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>avg</p></td>
<td class="text-center"><p>1/3</p></td>
<td class="text-center"><p>-1/3</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>-1/3</p></td>
<td class="text-center"><p>1/3</p></td>
<td class="text-center"><p>1/3</p></td>
<td class="text-center"><p>1/3</p></td>
<td class="text-center"><p>1/3</p></td>
</tr>
</tbody>
</table>
<p>The SignDS scheme enables the device-side client to upload only a list of dimensional ordinal numbers of type int output by the algorithm, a random Sign value of type boolean and feedback results on the estimated value to the cloud side, which significantly reduces the communication overhead compared to uploading tens of thousands of float-level complete model weights or gradients in a common scenario. From the perspective of the actual reconstruction attack, the cloud side only obtains the dimension serial number, a Sign value representing the direction of gradient update and the step estimation feedback value for privacy protection, and the attack is more difficult to achieve. The data flow fields of the overall scheme are shown in the following figure:</p>
<p><img alt="img" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/docs/federated/docs/source_zh_cn/images/signds_flow.png" /></p>
</section>
</section>
<section id="privacy-protection-certificate">
<h2>Privacy Protection Certificate<a class="headerlink" href="#privacy-protection-certificate" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>The differential privacy noise scheme achieves privacy protection by adding noise so that the attacker cannot determine the original information, while the differential privacy SignDS scheme activates partial dimensions and replaces the original value with the sign value, which largely protects user privacy. Further, using the differential privacy index mechanism makes it impossible for an attacker to confirm whether the activated dimensions are significant (from the <code class="docutils literal notranslate"><span class="pre">topk</span></code> set) and whether the number of dimensions from <code class="docutils literal notranslate"><span class="pre">topk</span></code> in the output dimensions exceeds a given threshold.</p>
<section id="dimensional-selection-mechanism-based-on-index-mechanism">
<h3>Dimensional Selection Mechanism Based on Index Mechanism<a class="headerlink" href="#dimensional-selection-mechanism-based-on-index-mechanism" title="Permalink to this headline">ÔÉÅ</a></h3>
<p>For any two updates <span class="math notranslate nohighlight">\(\Delta\)</span> and <span class="math notranslate nohighlight">\(\Delta'\)</span> of each Client, the set of <code class="docutils literal notranslate"><span class="pre">topk</span></code> dimensions is <span class="math notranslate nohighlight">\(S_{topk}\)</span> , <span class="math notranslate nohighlight">\({S'}_{topk}\)</span> , respectively. The set of any possible output dimensions of the algorithm is <span class="math notranslate nohighlight">\({J}\in {\mathcal{J}}\)</span> . Note that <span class="math notranslate nohighlight">\(\nu=|{S}_ {topk}\cap {J}|\)</span> , <span class="math notranslate nohighlight">\(\nu'=|{S'}_{topk}\cap {J}|\)</span> is the number of intersections of <span class="math notranslate nohighlight">\({J}\)</span> and <code class="docutils literal notranslate"><span class="pre">topk</span></code> sets, and the algorithm such that the following inequality holds:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\frac{{Pr}[{J}|\Delta]}{{Pr}[{J}|\Delta']}=\frac{{Pr}[{J}|{S}_{topk}]}{{Pr}[{J}|{S'}_{topk}]}=\frac{\frac{{exp}(\frac{\epsilon}{\phi_u}\cdot u({S}_{topk},{J}))}{\sum_{{J'}\in {\mathcal{J}}}{exp}(\frac{\epsilon}{\phi_u}\cdot u({S}_{topk}, {J'}))}}{\frac{{exp}(\frac{\epsilon}{\phi_u}\cdot u({S'}_{topk}, {J}))}{\sum_{ {J'}\in {\mathcal{J}}}{exp}(\frac{\epsilon}{\phi_u}\cdot u( {S'}_{topk},{J'}))}}=\frac{\frac{{exp}(\epsilon\cdot \unicode{x1D7D9}(\nu \geq \nu_{th}))}{\sum_{\tau=0}^{\tau=\nu_{th}-1}\omega_{\tau} + \sum_{\tau=\nu_{th}}^{\tau=h}\omega_{\tau}\cdot {exp}(\epsilon)}}{\frac{ {exp}(\epsilon\cdot \unicode{x1D7D9}(\nu' \geq\nu_{th}))}{\sum_{\tau=0}^{\tau=\nu_{th}-1}\omega_{\tau}+\sum_{\tau=\nu_{th}}^{\tau=h}\omega_{\tau}\cdot {exp}(\epsilon)}}\\= \frac{{exp}(\epsilon\cdot \unicode{x1D7D9} (\nu \geq \nu_{th}))}{ {exp}(\epsilon\cdot \unicode{x1D7D9} (\nu' \geq \nu_{th}))} \leq \frac{{exp}(\epsilon\cdot 1)}{{exp}(\epsilon\cdot 0)} = {exp}(\epsilon),
\end{split}\]</div>
<p>It is proved that the algorithm satisfies local differential privacy.</p>
</section>
<section id="local-differential-privacy-random-response-mechanism">
<h3>Local Differential Privacy-Random Response Mechanism<a class="headerlink" href="#local-differential-privacy-random-response-mechanism" title="Permalink to this headline">ÔÉÅ</a></h3>
<p>The participant receives the estimate sent from the server, and after the local training is completed, the topk dimensional weight mean of the real update is calculated, and 0 or 1 is output according to the magRR strategy. We consider that 0 or 1 still carries the weight mean range information, and it needs further protection.</p>
<p>The input of the random response mechanism is the data to be protected (<span class="math notranslate nohighlight">\(\b\in \{0,1\}\)</span>) and the privacy parameter <span class="math notranslate nohighlight">\(\epsilon\)</span>, which flips the data according to a certain probability and outputs <span class="math notranslate nohighlight">\(\hat{b} \in \{0,1\}\)</span> with the following rules:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\hat{b} = \begin{cases}
b &amp; with \quad probability \quad P \\
1-b &amp; with \quad probability \quad 1-P
\end{cases}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(P=\frac{e^\epsilon}{1+e^\epsilon}\)</span>.</p>
<section id="frequency-statistics-based-on-random-response-mechanism">
<h4>Frequency Statistics Based on Random Response Mechanism<a class="headerlink" href="#frequency-statistics-based-on-random-response-mechanism" title="Permalink to this headline">ÔÉÅ</a></h4>
<p>It is difficult for adversaries to distinguish real data from scrambled data by random responses, but it also affects the availability of cloud-side statistical tasks. The server side can approximate the true statistical frequency values by noise reduction, but it is difficult to infer the true input of the user in reverse. Let <span class="math notranslate nohighlight">\(N\)</span> be the total number of participants in a round, <span class="math notranslate nohighlight">\(N^T\)</span> be the total number of 1 originally, and <span class="math notranslate nohighlight">\(N^C\)</span> be the total number of 1 collected by the server, then we have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
N^T*P+(N-N^T)*(1-P)=N^C \\
N^T=\frac{N^C-N+NP}{2P-1}
\end{split}\]</div>
</section>
</section>
</section>
<section id="preparation">
<h2>Preparation<a class="headerlink" href="#preparation" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>To use the algorithm, one first needs to successfully complete the training aggregation process for either cross-device federated scenario. <a class="reference external" href="https://www.mindspore.cn/federated/docs/en/master/image_classification_application.html">Implementing an Image Classification Application of Cross-device Federated Learning (x86)</a> describes the preparation work such as datasets, network models, and simulations to initiate the process of multi-client participation in federated learning in detail.</p>
</section>
<section id="algorithm-opening-script">
<h2>Algorithm Opening Script<a class="headerlink" href="#algorithm-opening-script" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>Local differential privacy SignDS training currently only supports cross-device federated learning scenarios. The opening method needs to change the following parameter configuration in the yaml file when opening the cloud-side service. The complete cloud-side opening script can be referred to the cloud-side deployment, and the relevant parameter configuration for opening this algorithm is given here. Taking LeNet task as an example, the yaml related configuration is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">encrypt</span><span class="p">:</span>
  <span class="n">encrypt_train_type</span><span class="p">:</span> <span class="n">SIGNDS</span>
  <span class="o">...</span>
  <span class="n">signds</span><span class="p">:</span>
    <span class="n">sign_k</span><span class="p">:</span> <span class="mf">0.2</span>
    <span class="n">sign_eps</span><span class="p">:</span> <span class="mi">100</span>
    <span class="n">sign_thr_ratio</span><span class="p">:</span> <span class="mf">0.6</span>
    <span class="n">sign_global_lr</span><span class="p">:</span> <span class="mf">0.1</span>
    <span class="n">sign_dim_out</span><span class="p">:</span> <span class="mi">0</span>
</pre></div>
</div>
<p>For the detailed example, refer to <a class="reference external" href="https://www.mindspore.cn/federated/docs/en/master/image_classification_application.html">Implementing an Image Classification Application of Cross-device Federated Learning (x86)</a>. The cloud-side code implementation gives the definition domain of each parameter. If it is not in the definition domain, Server will report an error prompting the definition domain. The following parameter changes are subject to keeping the remaining 4 parameters unchanged.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sign_k</span></code>: (0,0.25], k*inputDim&gt;50. default=0.01. <code class="docutils literal notranslate"><span class="pre">inputDim</span></code> is the pulling length of the model or update. If not satisfied, there is a device-side warning. Sort update, and the <code class="docutils literal notranslate"><span class="pre">topk</span></code> set is composed of the first k (%) of it. Decreasing k means to pick from more important dimensions with greater probability. The output will have fewer dimensions, but the dimensions are more important and the change in convergence cannot be determined. The user needs to observe the sparsity of model update to determine the value. When it is quite sparse (update has many zeros), it should be taken smaller.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sign_eps</span></code>: (0,100], default=100. Privacy-preserving budget. The number sequence symbol is <span class="math notranslate nohighlight">\(\epsilon\)</span>, abbreviated as eps. When eps decreases, the probability of picking unimportant dimensions increases. When privacy protection is enhanced, output dimensions decrease, the percentage remains the same, and precision decreases.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sign_thr_ratio</span></code>: [0.5,1], default=0.6. The dimension from <code class="docutils literal notranslate"><span class="pre">topk</span></code> in the activation dimension is occupied threshold lower bound. Increasing will reduce the output dimension, but the proportion of output dimensions from <code class="docutils literal notranslate"><span class="pre">topk</span></code> will increase. When the value is increased excessively, more from <code class="docutils literal notranslate"><span class="pre">topk</span></code> is required in the output, and the total output dimension can only be reduced to meet the requirement, and the accuracy decreases when the number of clients is not large enough.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sign_global_lr</span></code>: (0,), default=1. This value is multiplied by sign instead of update, which directly affects the convergence speed and accuracy. Moderately increasing this value will improve the convergence speed, but it may make the model oscillate and the gradient explode. If more epochs are run locally per client and the learning rate used for local training is increased, the value needs to be increased accordingly. If the number of clients involved in the aggregation increases, the value also needs to be increased, because the value needs to be aggregated and then divided by the number of users when reconstruction. The result will remain the same only if the value is increased. If the percentage of participants in the new version (r0.2) involved in aggregation is less than 5%, the <span class="math notranslate nohighlight">\(lr_{global}\)</span> of the MagRR algorithm is directly adjusted to this parameter.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sign_dim_out</span></code>: [0,50], default=0. If a non-zero value is given, the client side uses the value directly, increasing the value to output more dimensions, but the proportion of dimensions from <code class="docutils literal notranslate"><span class="pre">topk</span></code> will decrease. If it is 0, the client user has to calculate the optimal output parameters. If eps is not large enough, and the value is increased, many <code class="docutils literal notranslate"><span class="pre">non-topk</span></code> insignificant dimensions will be output leading to affect the mode convergence and accuracy decrease. When eps is large enough, increasing the value will allow important dimension information of more users to leave the local area and improve the accuracy.</p></li>
</ul>
</section>
<section id="lenet-experiment-results">
<h2>LeNet Experiment results<a class="headerlink" href="#lenet-experiment-results" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>Use 100 client datasets of <code class="docutils literal notranslate"><span class="pre">3500_clients_bin</span></code>, 600 iterations of federated aggregation. 20 epochs run locally per client, and using learning rate of device-side local training is 0.01. The related parameter of SignDS is <code class="docutils literal notranslate"><span class="pre">k=0.2,</span> <span class="pre">eps=100,</span> <span class="pre">ratio=0.6,</span> <span class="pre">lr=4,</span> <span class="pre">out=0</span></code>, and the variation curves of Loss and Auc are shown in the following figure. In the unencrypted scenario, the length of the data uploaded to the cloud side at the end of training on the device side is 266,084, but the length of the data uploaded by SignDS is only 656.</p>
<p><img alt="loss" src="_images/lenet_signds_loss_auc.png" /></p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">ÔÉÅ</a></h2>
<p>[1] Ligeng Zhu, Zhijian Liu, and Song Han. <a class="reference external" href="http://arxiv.org/pdf/1906.08935.pdf">Deep Leakage from Gradients</a>. NeurIPS, 2019.</p>
<p>[2] Xue Jiang, Xuebing Zhou, and Jens Grossklags. ‚ÄúSignDS-FL: Local Differentially-Private Federated Learning with Sign-based Dimension Selection.‚Äù ACM Transactions on Intelligent Systems and Technology, 2022.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="local_differential_privacy_training_noise.html" class="btn btn-neutral float-left" title="Horizontal FL-Local Differential Privacy Perturbation Training" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="local_differential_privacy_eval_laplace.html" class="btn btn-neutral float-right" title="Horizontal Federated-Local Differential Privacy Inference Result Protection" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>