<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Horizontal FL-Local Differential Privacy SignDS training &mdash; MindSpore master documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Horizontal FL-Pairwise encryption training" href="pairwise_encryption_training.html" />
    <link rel="prev" title="Horizontal FL-Local Differential Privacy Perturbation Training" href="local_differential_privacy_training_noise.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="federated_install.html">Obtaining MindSpore Federated</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_federated_server.html">Horizontal Federated Cloud-based Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_federated_client.html">Horizontal Federated Device-side Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_vfl.html">Vertical Federated Deployment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Horizontal Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="image_classfication_dataset_process.html">Federated Learning Image Classification Dataset Process</a></li>
<li class="toctree-l1"><a class="reference internal" href="image_classification_application.html">Implementing an Image Classification Application of Cross-device Federated Learning (x86)</a></li>
<li class="toctree-l1"><a class="reference internal" href="sentiment_classification_application.html">Implementing a Sentiment Classification Application (Android)</a></li>
<li class="toctree-l1"><a class="reference internal" href="image_classification_application_in_cross_silo.html">Implementing a Cloud-Slio Federated Image Classification Application (x86)</a></li>
<li class="toctree-l1"><a class="reference internal" href="object_detection_application_in_cross_silo.html">Implementing a Cross-Silo Federated Target Detection Application (x86)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Vertical Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="data_join.html">Vertical Federated Learning Data Access</a></li>
<li class="toctree-l1"><a class="reference internal" href="split_wnd_application.html">Vertical Federated Learning Model Training - Wide&amp;Deep Recommendation Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="split_pangu_alpha_application.html">Vertical Federated Learning Model Training - Pangu Alpha Large Model Cross-Domain Training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Security and Privacy</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="local_differential_privacy_training_noise.html">Horizontal FL-Local Differential Privacy Perturbation Training</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Horizontal FL-Local Differential Privacy SignDS training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#privacy-protection-background">Privacy Protection Background</a></li>
<li class="toctree-l2"><a class="reference internal" href="#algorithm-flow-introduction">Algorithm Flow Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#privacy-protection-certificate">Privacy Protection Certificate</a></li>
<li class="toctree-l2"><a class="reference internal" href="#preparation">Preparation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#algorithm-opening-script">Algorithm Opening Script</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lenet-experiment-results">LeNet Experiment results</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pairwise_encryption_training.html">Horizontal FL-Pairwise encryption training</a></li>
<li class="toctree-l1"><a class="reference internal" href="private_set_intersection.html">Vertical Federated-Privacy Set Intersection</a></li>
<li class="toctree-l1"><a class="reference internal" href="secure_vertical_federated_learning_with_EmbeddingDP.html">Vertical Federated-Feature Protection Based on Information Obfuscation</a></li>
<li class="toctree-l1"><a class="reference internal" href="secure_vertical_federated_learning_with_TEE.html">Vertical Federated - Feature Protection Based on Trusted Execution Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="secure_vertical_federated_learning_with_DP.html">Vertical Federated - Label Protection Based on Differential Privacy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Communication Compression</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="communication_compression.html">Device-Cloud Federated Learning Communication Compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="vfl_communication_compress.html">Vertical Federated Learning Communication Compression</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Horizontal Federated API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="horizontal_server.html">Federated Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="cross_device.html">Device-side Client</a></li>
<li class="toctree-l1"><a class="reference internal" href="horizontal/cross_silo.html">Cross-Silo</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Vertical Federated API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Data_Join.html">Data Join</a></li>
<li class="toctree-l1"><a class="reference internal" href="vertical/vertical_communicator.html">Vertical Federated Learning Communicator</a></li>
<li class="toctree-l1"><a class="reference internal" href="vertical_federated_trainer.html">Vertical Federated Trainer</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RELEASE NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="RELEASE.html">Release Notes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Horizontal FL-Local Differential Privacy SignDS training</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/local_differential_privacy_training_signds.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="horizontal-fl-local-differential-privacy-signds-training">
<h1>Horizontal FL-Local Differential Privacy SignDS training<a class="headerlink" href="#horizontal-fl-local-differential-privacy-signds-training" title="Permalink to this headline"></a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/r2.0/docs/federated/docs/source_en/local_differential_privacy_training_signds.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.0/resource/_static/logo_source_en.png"></a></p>
<section id="privacy-protection-background">
<h2>Privacy Protection Background<a class="headerlink" href="#privacy-protection-background" title="Permalink to this headline"></a></h2>
<p>Federated learning enables the client user to participate in global model training without uploading the original dataset by allowing the participant to upload only the new model after local training or update the update information of the model, breaking through the data silos. This common scenario of federated learning corresponds to the default scheme in the MindSpore federated learning framework, where the <code class="docutils literal notranslate"><span class="pre">encrypt_type</span></code> switch defaults to <code class="docutils literal notranslate"><span class="pre">not_encrypt</span></code> when starting the <code class="docutils literal notranslate"><span class="pre">server</span></code>. The <code class="docutils literal notranslate"><span class="pre">installation</span> <span class="pre">and</span> <span class="pre">deployment</span></code> and <code class="docutils literal notranslate"><span class="pre">application</span> <span class="pre">practices</span></code> in the federated learning tutorial both use this approach by default, which is a common federated seeking averaging scheme without any privacy-protecting treatment such as cryptographic perturbation. For the convenience of description, `not_encrypt’ is used below to refer specifically to this default scheme.</p>
<p>This federated learning scheme is not free from privacy leakage, using the above <code class="docutils literal notranslate"><span class="pre">not_encrypt</span></code> scheme for training. The Server receives the local training model uploaded by the Client, which can still reconstruct the user training data through some attack methods [1], thus leaking user privacy, so the <code class="docutils literal notranslate"><span class="pre">not_encrypt</span></code> scheme needs to further increase the user privacy protection mechanism.</p>
<p>The global model <code class="docutils literal notranslate"><span class="pre">oldModel</span></code> received by the Client in each round of federated learning is issued by the Server, which does not involve user privacy issues. However, the local model <code class="docutils literal notranslate"><span class="pre">newModel</span></code> obtained by each Client after several epochs of local training fits its local privacy data, so the privacy protection focuses on the weight difference between the two <code class="docutils literal notranslate"><span class="pre">newModel</span></code>-<code class="docutils literal notranslate"><span class="pre">oldModel</span></code>=<code class="docutils literal notranslate"><span class="pre">update</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">DP_ENCRYPT</span></code> differential noise scheme already implemented in the MindSpore Federated framework achieves privacy preservation by iteratively perturbing Gaussian random noise to <code class="docutils literal notranslate"><span class="pre">update</span></code>. However, as the dimensionality of the model increases, the increase in the <code class="docutils literal notranslate"><span class="pre">update</span></code> paradigm will increase the noise, thus requiring more Clients to participate in the same round of aggregation to neutralize the noise impact, otherwise the convergence and accuracy of the model will be reduced. If the noise is set too small, although the convergence and accuracy are close to the performance of the <code class="docutils literal notranslate"><span class="pre">not_encrypt</span></code> scheme, the privacy protection is not strong enough. Also each Client needs to send the perturbed model, and as the model increases, the communication overhead increases. We expect the Client represented by the cell phone to achieve convergence of the global model with as little communication overhead as possible.</p>
</section>
<section id="algorithm-flow-introduction">
<h2>Algorithm Flow Introduction<a class="headerlink" href="#algorithm-flow-introduction" title="Permalink to this headline"></a></h2>
<p>SignDS [2] is the abbreviation of Sign Dimension Select, and the processing object is the <code class="docutils literal notranslate"><span class="pre">update</span></code> of Client. Preparation: each layer of Tensor of <code class="docutils literal notranslate"><span class="pre">update</span></code> is flattened and expanded into a one-dimensional vector, connected together, and the number of splicing vector dimensions is noted as <span class="math notranslate nohighlight">\(d\)</span>.</p>
<p>One sentence summarizes the algorithm: <strong>Select <span class="math notranslate nohighlight">\(h(h&lt;d)\)</span> dimensions of <code class="docutils literal notranslate"><span class="pre">update</span></code>, replace the original update value of the selected dimension with the sign value (sign value: plus or minus 1), and replace the unselected ones with 0.</strong></p>
<p>Here is an example: there are 3 clients Client1, 2, 3, whose <code class="docutils literal notranslate"><span class="pre">update</span></code> is a <span class="math notranslate nohighlight">\(d=8\)</span>-dimensional vector after flattening and expanding, and the Server calculates the <code class="docutils literal notranslate"><span class="pre">avg</span></code> of these 3 clients Client and updates the global model with the value, that is, completes a round of federated learning.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-center head"><p>Client</p></th>
<th class="text-center head"><p>d_1</p></th>
<th class="text-center head"><p>d_2</p></th>
<th class="text-center head"><p>d_3</p></th>
<th class="text-center head"><p>d_4</p></th>
<th class="text-center head"><p>d_5</p></th>
<th class="text-center head"><p>d_6</p></th>
<th class="text-center head"><p>d_7</p></th>
<th class="text-center head"><p>d_8</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>1</p></td>
<td class="text-center"><p>0.4</p></td>
<td class="text-center"><p>0.1</p></td>
<td class="text-center"><p>-0.2</p></td>
<td class="text-center"><p>0.3</p></td>
<td class="text-center"><p>0.5</p></td>
<td class="text-center"><p>0.1</p></td>
<td class="text-center"><p>-0.2</p></td>
<td class="text-center"><p>-0.3</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>2</p></td>
<td class="text-center"><p>0.5</p></td>
<td class="text-center"><p>0.2</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0.1</p></td>
<td class="text-center"><p>0.3</p></td>
<td class="text-center"><p>0.2</p></td>
<td class="text-center"><p>-0.1</p></td>
<td class="text-center"><p>-0.2</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>3</p></td>
<td class="text-center"><p>0.3</p></td>
<td class="text-center"><p>0.1</p></td>
<td class="text-center"><p>-0.1</p></td>
<td class="text-center"><p>0.5</p></td>
<td class="text-center"><p>0.2</p></td>
<td class="text-center"><p>0.3</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0.1</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>avg</p></td>
<td class="text-center"><p>0.4</p></td>
<td class="text-center"><p>0.13</p></td>
<td class="text-center"><p>-0.1</p></td>
<td class="text-center"><p>0.3</p></td>
<td class="text-center"><p>0.33</p></td>
<td class="text-center"><p>0.2</p></td>
<td class="text-center"><p>-0.1</p></td>
<td class="text-center"><p>-0.13</p></td>
</tr>
</tbody>
</table>
<p>The dimension with higher importance should be selected, and the importance measure is the size of the <strong>fetching value</strong>, and the update needs to be sorted. update takes positive and negative values to represent different update directions, so in each round of federated learning, the sign values of Client each have <strong>0.5 probability</strong> of taking <code class="docutils literal notranslate"><span class="pre">1</span></code> or <code class="docutils literal notranslate"><span class="pre">-1</span></code>. If sign=1, the largest <span class="math notranslate nohighlight">\(k\)</span> number of <code class="docutils literal notranslate"><span class="pre">update</span></code> dimensions are noted as the <code class="docutils literal notranslate"><span class="pre">topk</span></code> set and the remaining ones are noted as the <code class="docutils literal notranslate"><span class="pre">non-topk</span></code> set. If sign=-1, the smallest <span class="math notranslate nohighlight">\(k\)</span> number of ones are noted as the <code class="docutils literal notranslate"><span class="pre">topk</span></code> set.</p>
<p>If the Server specifies <code class="docutils literal notranslate"><span class="pre">h</span></code>, the total number of selected dimensions, the Client will directly use this value, otherwise each Client will locally calculate the optimal output dimension <code class="docutils literal notranslate"><span class="pre">h</span></code>.</p>
<p>The SignDS algorithm outputs the number of dimensions (denoted as <span class="math notranslate nohighlight">\(v\)</span>) that should be selected from the <code class="docutils literal notranslate"><span class="pre">topk</span></code> set and the <code class="docutils literal notranslate"><span class="pre">non-topk</span></code> set, as in the example in the table below, where the two sets pick a total of dimensions h=3.</p>
<p>Client selects dimensions uniformly and randomly according to the number of dimensions output by the SignDS algorithm, sends the dimension number and sign value to the Server. If the dimension number is output in the order of picking from <code class="docutils literal notranslate"><span class="pre">topk</span></code> first and then from <code class="docutils literal notranslate"><span class="pre">non-topk</span></code>, the dimension number list <code class="docutils literal notranslate"><span class="pre">index</span></code> needs to be shuffled and disordered. The following table shows the information finally transferred from each Client of this algorithm to the Server.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-center head"><p>Client</p></th>
<th class="text-center head"><p>index</p></th>
<th class="text-center head"><p>sign</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>1</p></td>
<td class="text-center"><p>1,5,8</p></td>
<td class="text-center"><p>1</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>2</p></td>
<td class="text-center"><p>2,3,4</p></td>
<td class="text-center"><p>-1</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>3</p></td>
<td class="text-center"><p>3,6,7</p></td>
<td class="text-center"><p>1</p></td>
</tr>
</tbody>
</table>
<p>Server constructs <code class="docutils literal notranslate"><span class="pre">update</span></code> with privacy protection based on the dimension serial number and sign value uploaded by each client Client, aggregates and averages all <code class="docutils literal notranslate"><span class="pre">updates</span></code> and updates the current <code class="docutils literal notranslate"><span class="pre">oldModel</span></code> to complete a round of federated learning.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-center head"><p>Client</p></th>
<th class="text-center head"><p>d_1</p></th>
<th class="text-center head"><p>d_2</p></th>
<th class="text-center head"><p>d_3</p></th>
<th class="text-center head"><p>d_4</p></th>
<th class="text-center head"><p>d_5</p></th>
<th class="text-center head"><p>d_6</p></th>
<th class="text-center head"><p>d_7</p></th>
<th class="text-center head"><p>d_8</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>1</p></td>
<td class="text-center"><p><strong>1</strong></p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p><strong>1</strong></p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p><strong>1</strong></p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>2</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p><strong>-1</strong></p></td>
<td class="text-center"><p><strong>-1</strong></p></td>
<td class="text-center"><p><strong>-1</strong></p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>3</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p><strong>1</strong></p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p><strong>1</strong></p></td>
<td class="text-center"><p><strong>1</strong></p></td>
<td class="text-center"><p>0</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>avg</p></td>
<td class="text-center"><p>1/3</p></td>
<td class="text-center"><p>-1/3</p></td>
<td class="text-center"><p>0</p></td>
<td class="text-center"><p>-1/3</p></td>
<td class="text-center"><p>1/3</p></td>
<td class="text-center"><p>1/3</p></td>
<td class="text-center"><p>1/3</p></td>
<td class="text-center"><p>1/3</p></td>
</tr>
</tbody>
</table>
<p>The optimized SignDS scheme has realized that the device-side client only uploads a list of dimension numbers of int type and a random Sign value of boolean type outputted by the algorithm to the cloud side, which significantly reduces the communication overhead compared to the common scenario of uploading thousands of float-level complete model weights or gradients. From the perspective of the actual reconstruction attack, the cloud side only gets the dimension serial number and a Sign value representing the direction of gradient update, and the attack is more difficult to achieve. The cloud side receives the dimension serial number and Sign value from the device side, and has to simulate the reconstruction of the original user weight, i.e., using <code class="docutils literal notranslate"><span class="pre">sign_global_lr</span></code> and Sign value, the latter representing the updated direction and the former representing the step size, which is where the accuracy of the scheme is lost. The cloud side can only be reconstructed to simulate each client <strong>partial</strong> gradient update. The number is equal to the number of serial numbers. Because the dimension selection is all random, the more the number of client users involved in aggregation, and the more model weights will be activated. If the reconstructed <code class="docutils literal notranslate"><span class="pre">update</span></code> is mostly focused on a certain position, it means that the real weight of that position is more updated, and vice versa, it means that the original update of that position is less updated. By reconstructing <code class="docutils literal notranslate"><span class="pre">update</span></code> and adding the initial model weights in this round, the cloud side can aggregate and update the final model in this round.</p>
</section>
<section id="privacy-protection-certificate">
<h2>Privacy Protection Certificate<a class="headerlink" href="#privacy-protection-certificate" title="Permalink to this headline"></a></h2>
<p>The differential privacy noise scheme achieves privacy protection by adding noise so that the attacker cannot determine the original information, while the differential privacy SignDS scheme activates partial dimensions and replaces the original value with the sign value, which largely protects user privacy. Further, using the differential privacy index mechanism makes it impossible for an attacker to confirm whether the activated dimensions are significant (from the <code class="docutils literal notranslate"><span class="pre">topk</span></code> set) and whether the number of dimensions from <code class="docutils literal notranslate"><span class="pre">topk</span></code> in the output dimensions exceeds a given threshold.</p>
<p>For any two updates <span class="math notranslate nohighlight">\(\Delta\)</span> and <span class="math notranslate nohighlight">\(\Delta'\)</span> of each Client, the set of <code class="docutils literal notranslate"><span class="pre">topk</span></code> dimensions is <span class="math notranslate nohighlight">\(S_{topk}\)</span> , <span class="math notranslate nohighlight">\({S'}_{topk}\)</span> , respectively. The set of any possible output dimensions of the algorithm is <span class="math notranslate nohighlight">\({J}\in {\mathcal{J}}\)</span> . Note that <span class="math notranslate nohighlight">\(\nu=|{S}_ {topk}\cap {J}|\)</span> , <span class="math notranslate nohighlight">\(\nu'=|{S'}_{topk}\cap {J}|\)</span> is the number of intersections of <span class="math notranslate nohighlight">\({J}\)</span> and <code class="docutils literal notranslate"><span class="pre">topk</span></code> sets, and the algorithm such that the following inequality holds:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\frac{{Pr}[{J}|\Delta]}{{Pr}[{J}|\Delta']}=\frac{{Pr}[{J}|{S}_{topk}]}{{Pr}[{J}|{S'}_{topk}]}=\frac{\frac{{exp}(\frac{\epsilon}{\phi_u}\cdot u({S}_{topk},{J}))}{\sum_{{J'}\in {\mathcal{J}}}{exp}(\frac{\epsilon}{\phi_u}\cdot u({S}_{topk}, {J'}))}}{\frac{{exp}(\frac{\epsilon}{\phi_u}\cdot u({S'}_{topk}, {J}))}{\sum_{ {J'}\in {\mathcal{J}}}{exp}(\frac{\epsilon}{\phi_u}\cdot u( {S'}_{topk},{J'}))}}=\frac{\frac{{exp}(\epsilon\cdot \unicode{x1D7D9}(\nu \geq \nu_{th}))}{\sum_{\tau=0}^{\tau=\nu_{th}-1}\omega_{\tau} + \sum_{\tau=\nu_{th}}^{\tau=h}\omega_{\tau}\cdot {exp}(\epsilon)}}{\frac{ {exp}(\epsilon\cdot \unicode{x1D7D9}(\nu' \geq\nu_{th}))}{\sum_{\tau=0}^{\tau=\nu_{th}-1}\omega_{\tau}+\sum_{\tau=\nu_{th}}^{\tau=h}\omega_{\tau}\cdot {exp}(\epsilon)}}\\= \frac{{exp}(\epsilon\cdot \unicode{x1D7D9} (\nu \geq \nu_{th}))}{ {exp}(\epsilon\cdot \unicode{x1D7D9} (\nu' \geq \nu_{th}))} \leq \frac{{exp}(\epsilon\cdot 1)}{{exp}(\epsilon\cdot 0)} = {exp}(\epsilon),
\end{split}\]</div>
<p>It is proved that the algorithm satisfies local differential privacy.</p>
</section>
<section id="preparation">
<h2>Preparation<a class="headerlink" href="#preparation" title="Permalink to this headline"></a></h2>
<p>To use the algorithm, one first needs to successfully complete the training aggregation process for either cross-device federated scenario. <a class="reference external" href="https://www.mindspore.cn/federated/docs/en/r0.1/image_classification_application.html">Implementing an Image Classification Application of Cross-device Federated Learning (x86)</a> describes the preparation work such as datasets, network models, and simulations to initiate the process of multi-client participation in federated learning in detail.</p>
</section>
<section id="algorithm-opening-script">
<h2>Algorithm Opening Script<a class="headerlink" href="#algorithm-opening-script" title="Permalink to this headline"></a></h2>
<p>Local differential privacy SignDS training currently only supports cross-device federated learning scenarios. The opening method needs to change the following parameter configuration in the yaml file when opening the cloud-side service. The complete cloud-side opening script can be referred to the cloud-side deployment, and the relevant parameter configuration for opening this algorithm is given here. Taking LeNet task as an example, the yaml related configuration is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">encrypt</span><span class="p">:</span>
  <span class="n">encrypt_type</span><span class="p">:</span> <span class="n">SIGNDS</span>
  <span class="o">...</span>
  <span class="n">signds</span><span class="p">:</span>
    <span class="n">sign_k</span><span class="p">:</span> <span class="mf">0.01</span>
    <span class="n">sign_eps</span><span class="p">:</span> <span class="mi">100</span>
    <span class="n">sign_thr_ratio</span><span class="p">:</span> <span class="mf">0.6</span>
    <span class="n">sign_global_lr</span><span class="p">:</span> <span class="mf">0.1</span>
    <span class="n">sign_dim_out</span><span class="p">:</span> <span class="mi">0</span>
</pre></div>
</div>
<p>For the detailed example, refer to <a class="reference external" href="https://www.mindspore.cn/federated/docs/en/r0.1/image_classification_application.html">Implementing an Image Classification Application of Cross-device Federated Learning (x86)</a>. The cloud-side code implementation gives the definition domain of each parameter. If it is not in the definition domain, Server will report an error prompting the definition domain. The following parameter changes are subject to keeping the remaining 4 parameters unchanged.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sign_k</span></code>: (0,0.25], k*inputDim&gt;50. default=0.01. <code class="docutils literal notranslate"><span class="pre">inputDim</span></code> is the pulling length of the model or update. If not satisfied, there is a device-side warning. Sort update, and the <code class="docutils literal notranslate"><span class="pre">topk</span></code> set is composed of the first k (%) of it. Decreasing k means to pick from more important dimensions with greater probability. The output will have fewer dimensions, but the dimensions are more important and the change in convergence cannot be determined. The user needs to observe the sparsity of model update to determine the value. When it is quite sparse (update has many zeros), it should be taken smaller.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sign_eps</span></code>: (0,100], default=100. Privacy-preserving budget. The number sequence symbol is <span class="math notranslate nohighlight">\(\epsilon\)</span>, abbreviated as eps. When eps decreases, the probability of picking unimportant dimensions increases. When privacy protection is enhanced, output dimensions decrease, the percentage remains the same, and precision decreases.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sign_thr_ratio</span></code>: [0.5,1], default=0.6. The dimension from <code class="docutils literal notranslate"><span class="pre">topk</span></code> in the activation dimension is occupied threshold lower bound. Increasing will reduce the output dimension, but the proportion of output dimensions from <code class="docutils literal notranslate"><span class="pre">topk</span></code> will increase. When the value is increased excessively, more from <code class="docutils literal notranslate"><span class="pre">topk</span></code> is required in the output, and the total output dimension can only be reduced to meet the requirement, and the accuracy decreases when the number of clients is not large enough.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sign_global_lr</span></code>: (0,), default=1. This value is multiplied by sign instead of update, which directly affects the convergence speed and accuracy. Moderately increasing this value will improve the convergence speed, but it may make the model oscillate and the gradient explode. If more epochs are run locally per client and the learning rate used for local training is increased, the value needs to be increased accordingly. If the number of clients involved in the aggregation increases, the value also needs to be increased, because the value needs to be aggregated and then divided by the number of users when reconstruction. The result will remain the same only if the value is increased.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sign_dim_out</span></code>: [0,50], default=0. If a non-zero value is given, the client side uses the value directly, increasing the value to output more dimensions, but the proportion of dimensions from <code class="docutils literal notranslate"><span class="pre">topk</span></code> will decrease. If it is 0, the client user has to calculate the optimal output parameters. If eps is not large enough, and the value is increased, many <code class="docutils literal notranslate"><span class="pre">non-topk</span></code> insignificant dimensions will be output leading to affect the mode convergence and accuracy decrease. When eps is large enough, increasing the value will allow important dimension information of more users to leave the local area and improve the accuracy.</p></li>
</ul>
</section>
<section id="lenet-experiment-results">
<h2>LeNet Experiment results<a class="headerlink" href="#lenet-experiment-results" title="Permalink to this headline"></a></h2>
<p>Use 100 client datasets of <code class="docutils literal notranslate"><span class="pre">3500_clients_bin</span></code>, 200 iterations of federated aggregation. 20 epochs run locally per client, and using learning rate of device-side local training is 0.01. The related parameter of SignDS is <code class="docutils literal notranslate"><span class="pre">k=0.01,</span> <span class="pre">eps=100,</span> <span class="pre">ratio=0.6,</span> <span class="pre">lr=4,</span> <span class="pre">out=0</span></code>, and the final accuracy is 66.5% for all users and 69% for the common federated scenario without encryption. In the unencrypted scenario, the length of the data uploaded to the cloud side at the end of training on the device side is 266,084, but the length of the data uploaded by SignDS is only 656.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline"></a></h2>
<p>[1] Ligeng Zhu, Zhijian Liu, and Song Han. <a class="reference external" href="http://arxiv.org/pdf/1906.08935.pdf">Deep Leakage from Gradients</a>. NeurIPS, 2019.</p>
<p>[2] Xue Jiang, Xuebing Zhou, and Jens Grossklags. “SignDS-FL: Local Differentially-Private Federated Learning with Sign-based Dimension Selection.” ACM Transactions on Intelligent Systems and Technology, 2022.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="local_differential_privacy_training_noise.html" class="btn btn-neutral float-left" title="Horizontal FL-Local Differential Privacy Perturbation Training" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="pairwise_encryption_training.html" class="btn btn-neutral float-right" title="Horizontal FL-Pairwise encryption training" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
        <script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>