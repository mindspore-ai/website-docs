<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Model Security and Privacy &mdash; MindSpore master documentation</title><script>;(()=>{const e=localStorage.getItem("ms-theme"),t=window.matchMedia("(prefers-color-scheme: dark)").matches;(e?"dark"===e:t)&&document.documentElement.setAttribute("data-o-theme","dark")})();</script><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script><script src="_static/jquery.js"></script>
        <script src="_static/js/theme.js"></script><script src="_static/underscore.js"></script><script src="_static/doctools.js"></script><script crossorigin="anonymous" integrity="sha256-1fEPhSsRKlFKGfK3eO710tEweHh1fwokU5wFGDHO+vg=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script><script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script><script async="async" src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/mathjax/MathJax-3.2.2/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Implementing a Sentiment Classification Application (Android)" href="sentiment_classification_application.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> MindSpore
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="federated_install.html">Obtaining MindSpore Federated</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_federated_server.html">Cloud-based Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_federated_client.html">On-Device Deployment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="image_classification_application.html">Implementing an Image Classification Application (x86)</a></li>
<li class="toctree-l1"><a class="reference internal" href="sentiment_classification_application.html">Implementing a Sentiment Classification Application (Android)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Security and Privacy</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Model Security and Privacy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#ldp-based-secure-aggregation">LDP-based Secure Aggregation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#principles">Principles</a></li>
<li class="toctree-l3"><a class="reference internal" href="#usage">Usage</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#mpc-based-secure-aggregation">MPC-based Secure Aggregation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Principles</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">Usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Model Security and Privacy</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/security_and_privacy_protection.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="model-security-and-privacy">
<h1>Model Security and Privacy<a class="headerlink" href="#model-security-and-privacy" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://gitee.com/mindspore/docs/blob/r1.3/docs/federated/docs/source_en/security_and_privacy_protection.md"><img alt="View Source On Gitee" src="https://gitee.com/mindspore/docs/raw/r1.3/resource/_static/logo_source.png" /></a></p>
<p>During federated learning, user data is used only for local device training and does not need to be uploaded to the central server. This prevents personal data leakage.
However, in the conventional federated learning framework, models are migrated to the cloud in plaintext. There is still a risk of indirect disclosure of user privacy.
After obtaining the plaintext model uploaded by a user, the attacker can restore the user’s personal training data through attacks such as reconstruction and model inversion. As a result, user privacy is disclosed.
As a federated learning framework, MindSpore Federated provides secure aggregation algorithms based on local differential privacy (LDP) and secure multi-party computation (MPC).
Noise addition or scrambling is performed on local models before they are migrated to the cloud. On the premise of ensuring the model availability, the problem of privacy leakage in horizontal federated learning is solved.</p>
<section id="ldp-based-secure-aggregation">
<h2>LDP-based Secure Aggregation<a class="headerlink" href="#ldp-based-secure-aggregation" title="Permalink to this headline"></a></h2>
<section id="principles">
<h3>Principles<a class="headerlink" href="#principles" title="Permalink to this headline"></a></h3>
<p>Differential privacy is a mechanism for protecting user data privacy. <strong>Differential privacy</strong> is defined as follows:</p>
<div class="math notranslate nohighlight">
\[
Pr[\mathcal{K}(D)\in S] \le e^{\epsilon} Pr[\mathcal{K}(D') \in S]+\delta​
\]</div>
<p>For datasets <span class="math notranslate nohighlight">\(D and D'\)</span> that have only one record difference, the random algorithm <span class="math notranslate nohighlight">\(\mathcal{K}\)</span> is used to compute the probability of the <span class="math notranslate nohighlight">\(S\)</span> subset, which meets the preceding formula. <span class="math notranslate nohighlight">\(\epsilon\)</span> is the differential privacy budget, and <span class="math notranslate nohighlight">\(\delta\)</span> is the perturbation. The smaller the values of <span class="math notranslate nohighlight">\(\epsilon\)</span> and <span class="math notranslate nohighlight">\(\delta\)</span>, the closer the data distribution of <span class="math notranslate nohighlight">\(\mathcal{K}\)</span> on <span class="math notranslate nohighlight">\(D\)</span> and <span class="math notranslate nohighlight">\(D'\)</span>.</p>
<p>In horizontal federated learning, if the model weight matrix after local training on the client is <span class="math notranslate nohighlight">\(W\)</span>, the adversary can use <span class="math notranslate nohighlight">\(W\)</span> to restore the training dataset[1] of the user because the model “remembers” the features of the training set during the training process. MindSpore Federated provides a LDP-based secure aggregation algorithm to prevent privacy data leakage when local models are migrated to the cloud. The MindSpore Federated client generates a differential noise matrix <span class="math notranslate nohighlight">\(G\)</span> that has the same dimension as the local model <span class="math notranslate nohighlight">\(W\)</span>, and then adds the two to obtain a weight <span class="math notranslate nohighlight">\(W_p\)</span> that meets the differential privacy definition:</p>
<div class="math notranslate nohighlight">
\[
W_p=W+G
\]</div>
<p>The MindSpore Federated client uploads the noise-added model <span class="math notranslate nohighlight">\(W_p\)</span> to the cloud server for federated aggregation. The noise matrix <span class="math notranslate nohighlight">\(G\)</span> is equivalent to adding a layer of mask to the original model, which reduces the risk of sensitive data leakage from models and affects the convergence of model training. How to achieve a better balance between model privacy and usability is still a question worth studying. Experiments show that when the number of participants <span class="math notranslate nohighlight">\(n\)</span> is large enough (generally more than 1000), most of the noises can cancel each other, and the LDP mechanism has no obvious impact on the accuracy and convergence of the aggregation model.</p>
</section>
<section id="usage">
<h3>Usage<a class="headerlink" href="#usage" title="Permalink to this headline"></a></h3>
<p>Enabling differential privacy training is simple. You only need to perform the following operation during the cloud service startup.
Use <code class="docutils literal notranslate"><span class="pre">context.set_fl_context()</span></code> to set <code class="docutils literal notranslate"><span class="pre">encrypt_type='DP_ENCRYPT'</span></code>.
In addition, to control the effect of privacy protection, three parameters are provided: <code class="docutils literal notranslate"><span class="pre">dp_eps</span></code>, <code class="docutils literal notranslate"><span class="pre">dp_delta</span></code>, and <code class="docutils literal notranslate"><span class="pre">dp_norm_clip</span></code>.
They are also set through <code class="docutils literal notranslate"><span class="pre">context.set_fl_context()</span></code>. The valid value range of <code class="docutils literal notranslate"><span class="pre">dp_eps</span></code> and <code class="docutils literal notranslate"><span class="pre">dp_norm_clip</span></code> is greater than 0.
The value of <code class="docutils literal notranslate"><span class="pre">dp_delta</span></code> ranges between 0 and 1. Generally, the smaller the values of <code class="docutils literal notranslate"><span class="pre">dp_eps</span></code> and <code class="docutils literal notranslate"><span class="pre">dp_delta</span></code>, the better the privacy protection effect.
However, the impact on model convergence is greater. It is recommended that <code class="docutils literal notranslate"><span class="pre">dp_delta</span></code> be set to the reciprocal of the number of clients and the value of <code class="docutils literal notranslate"><span class="pre">dp_eps</span></code> be greater than 50.
<code class="docutils literal notranslate"><span class="pre">dp_norm_clip</span></code> is the adjustment coefficient of the model weight before noise is added to the model weight by the LDP mechanism. It affects the convergence of the model. The recommended value ranges from 0.5 to 2.</p>
</section>
</section>
<section id="mpc-based-secure-aggregation">
<h2>MPC-based Secure Aggregation<a class="headerlink" href="#mpc-based-secure-aggregation" title="Permalink to this headline"></a></h2>
<section id="id1">
<h3>Principles<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<p>Although the LDP technology can properly protect user data privacy, when there are a relatively small quantity of participating clients or a Gaussian noise amplitude is relatively large, the model accuracy is greatly affected.
To meet both model protection and model convergence requirements, we provide the MPC-based secure aggregation solution.
In this training mode, assuming that the participating client set is <span class="math notranslate nohighlight">\(U\)</span>, for any Federated-Client <span class="math notranslate nohighlight">\(u\)</span> and <span class="math notranslate nohighlight">\(v\)</span>, they negotiate a pair of random perturbations <span class="math notranslate nohighlight">\(p_{uv}\)</span> and <span class="math notranslate nohighlight">\(p_{vu}\)</span>, which meet the following condition:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
p_{uv}=\begin{cases} -p_{vu}, &amp;u{\neq}v\\\\ 0, &amp;u=v \end{cases}
\end{split}\]</div>
<p>Therefore, each Federated-Client <span class="math notranslate nohighlight">\(u\)</span> adds the perturbation negotiated with other users to the original model weight <span class="math notranslate nohighlight">\(x_u\)</span> before uploading the model to the server:</p>
<div class="math notranslate nohighlight">
\[
x_{encrypt}=x_u+\sum\limits_{v{\in}U}p_{uv}
\]</div>
<p>Therefore, the Federated-Server aggregation result <span class="math notranslate nohighlight">\(\overline{x}\)</span> is as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\overline{x}&amp;=\sum\limits_{u{\in}U}(x_{u}+\sum\limits_{v{\in}U}p_{uv})\\\\
&amp;=\sum\limits_{u{\in}U}x_{u}+\sum\limits_{u{\in}U}\sum\limits_{v{\in}U}p_{uv}\\\\
&amp;=\sum\limits_{u{\in}U}x_{u}
\end{align}
\end{split}\]</div>
<p>The preceding process describes only the main idea of the aggregation algorithm. The MPC-based aggregation solution is accuracy-lossless but increases the number of communication rounds.
If you are interested in the specific steps of the algorithm, refer to the paper[2].</p>
</section>
<section id="id2">
<h3>Usage<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<p>Similar to enabling differential privacy training, you only need to set <code class="docutils literal notranslate"><span class="pre">encrypt_type='PW_ENCRYPT'</span></code> in <code class="docutils literal notranslate"><span class="pre">context.set_fl_context()</span></code>.
In addition, the cloud environment parameters related to secure aggregation training include <code class="docutils literal notranslate"><span class="pre">share_secrets_ratio</span></code>, <code class="docutils literal notranslate"><span class="pre">reconstruct_secrets_threshold</span></code>, and <code class="docutils literal notranslate"><span class="pre">cipher_time_window</span></code>.
<code class="docutils literal notranslate"><span class="pre">share_client_ratio</span></code> indicates the ratio of the number of clients participating in key fragment sharing to the number of clients participating in federated learning. The value must be less than or equal to 1.
<code class="docutils literal notranslate"><span class="pre">reconstruct_secrets_threshold</span></code> indicates the number of clients that participate in key fragment reconstruction. The value must be less than the number of clients that participate in key fragment sharing.
To ensure system security, the <code class="docutils literal notranslate"><span class="pre">reconstruct_secrets_threshold</span></code> must be greater than half of the number of federated learning clients when the server and client are not colluded.
When the server and client are colluded, the value of <code class="docutils literal notranslate"><span class="pre">reconstruct_secrets_threshold</span></code> must be greater than two thirds of the number of federated learning clients.
<code class="docutils literal notranslate"><span class="pre">cipher_time_window</span></code> indicates the duration limit of each communication round for secure aggregation. It is used to ensure that the server can start a new round of iteration when some clients are offline.
It should be noted that only <code class="docutils literal notranslate"><span class="pre">server_num=1</span></code> is supported for current PW_ENCRYPT mode.</p>
</section>
<section id="references">
<h3>References<a class="headerlink" href="#references" title="Permalink to this headline"></a></h3>
<p>[1] Ligeng Zhu, Zhijian Liu, and Song Han. <a class="reference external" href="http://arxiv.org/pdf/1906.08935.pdf">Deep Leakage from Gradients</a>. NeurIPS, 2019.</p>
<p>[2] Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, et al. <a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/3133956.3133982">Practical Secure Aggregationfor Privacy-Preserving Machine Learning</a>. NeurIPS, 2016.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="sentiment_classification_application.html" class="btn btn-neutral float-left" title="Implementing a Sentiment Classification Application (Android)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright MindSpore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
</body>
</html>