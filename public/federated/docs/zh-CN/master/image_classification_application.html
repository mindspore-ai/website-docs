

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>实现一个端云联邦的图像分类应用(x86) &mdash; MindSpore master 文档</title>
  

  
   
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  
  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script src="_static/translations.js"></script>
        
        
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" />
    <link rel="next" title="实现一个端云情感分类应用(Android)" href="sentiment_classification_application.html" />
    <link rel="prev" title="联邦学习图像分类数据集处理" href="image_classfication_dataset_process.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MindSpore
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">安装部署</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="federated_install.html">获取MindSpore Federated</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_federated_server.html">横向联邦云侧部署</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_federated_client.html">横向联邦端侧部署</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_vfl.html">纵向联邦部署</a></li>
</ul>
<p class="caption"><span class="caption-text">横向应用实践</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="image_classfication_dataset_process.html">联邦学习图像分类数据集处理</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">实现一个端云联邦的图像分类应用(x86)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#准备工作">准备工作</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#生成端侧模型文件">生成端侧模型文件</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#模拟启动多客户端参与联邦学习">模拟启动多客户端参与联邦学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#为客户端准备好模型文件">为客户端准备好模型文件。</a></li>
<li class="toctree-l3"><a class="reference internal" href="#启动云侧服务">启动云侧服务</a></li>
<li class="toctree-l3"><a class="reference internal" href="#启动客户端">启动客户端</a></li>
<li class="toctree-l3"><a class="reference internal" href="#关闭客户端进程">关闭客户端进程</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="sentiment_classification_application.html">实现一个端云情感分类应用(Android)</a></li>
<li class="toctree-l1"><a class="reference internal" href="image_classification_application_in_cross_silo.html">实现一个云云联邦的图像分类应用(x86)</a></li>
<li class="toctree-l1"><a class="reference internal" href="object_detection_application_in_cross_silo.html">实现一个云云联邦的目标检测应用(x86)</a></li>
</ul>
<p class="caption"><span class="caption-text">纵向应用实践</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="data_join.html">纵向联邦学习数据接入</a></li>
<li class="toctree-l1"><a class="reference internal" href="split_wnd_application.html">纵向联邦学习模型训练 - Wide&amp;Deep推荐应用</a></li>
<li class="toctree-l1"><a class="reference internal" href="split_pangu_alpha_application.html">纵向联邦学习模型训练 - 盘古α大模型跨域训练</a></li>
</ul>
<p class="caption"><span class="caption-text">安全和隐私</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="local_differential_privacy_training_noise.html">横向联邦-局部差分隐私加噪训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="local_differential_privacy_training_signds.html">横向联邦-局部差分隐私SignDS训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="local_differential_privacy_eval_laplace.html">横向联邦-局部差分隐私推理结果保护</a></li>
<li class="toctree-l1"><a class="reference internal" href="pairwise_encryption_training.html">横向联邦-安全聚合训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="private_set_intersection.html">纵向联邦-隐私集合求交</a></li>
<li class="toctree-l1"><a class="reference internal" href="secure_vertical_federated_learning_with_EmbeddingDP.html">纵向联邦-基于信息混淆的特征保护</a></li>
<li class="toctree-l1"><a class="reference internal" href="secure_vertical_federated_learning_with_TEE.html">纵向联邦-基于可信执行环境的特征保护</a></li>
<li class="toctree-l1"><a class="reference internal" href="secure_vertical_federated_learning_with_DP.html">纵向联邦-基于差分隐私的标签保护</a></li>
</ul>
<p class="caption"><span class="caption-text">通信压缩</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="communication_compression.html">端云联邦学习通信压缩</a></li>
<li class="toctree-l1"><a class="reference internal" href="vfl_communication_compress.html">纵向联邦学习通信压缩</a></li>
</ul>
<p class="caption"><span class="caption-text">横向联邦API参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="horizontal_server.html">联邦服务器</a></li>
<li class="toctree-l1"><a class="reference internal" href="cross_device.html">端侧客户端</a></li>
<li class="toctree-l1"><a class="reference internal" href="horizontal/cross_silo.html">云侧客户端</a></li>
</ul>
<p class="caption"><span class="caption-text">纵向联邦API参考</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Data_Join.html">数据求交</a></li>
<li class="toctree-l1"><a class="reference internal" href="vertical/vertical_communicator.html">纵向联邦学习通信器</a></li>
<li class="toctree-l1"><a class="reference internal" href="vertical_federated_trainer.html">纵向联邦训练器</a></li>
</ul>
<p class="caption"><span class="caption-text">参考文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MindSpore</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>实现一个端云联邦的图像分类应用(x86)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/image_classification_application.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="实现一个端云联邦的图像分类应用x86">
<h1>实现一个端云联邦的图像分类应用(x86)<a class="headerlink" href="#实现一个端云联邦的图像分类应用x86" title="永久链接至标题">¶</a></h1>
<p><a href="https://gitee.com/mindspore/docs/blob/master/docs/federated/docs/source_zh_cn/image_classification_application.md" target="_blank"><img src="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source.png"></a></p>
<p>根据参与客户端的类型，联邦学习可分为云云联邦学习（cross-silo）和端云联邦学习（cross-device）。在云云联邦学习场景中，参与联邦学习的客户端是不同的组织（例如，医疗或金融）或地理分布的数据中心，即在多个数据孤岛上训练模型。在端云联邦学习场景中，参与的客户端为大量的移动或物联网设备。本框架将介绍如何在MindSpore端云联邦框架上使用网络LeNet实现一个图片分类应用，并提供在x86环境中模拟启动多客户端参与联邦学习的相关教程。</p>
<p>在动手进行实践之前，确保你已经正确安装了MindSpore。如果没有，可以参考<a class="reference external" href="https://www.mindspore.cn/install">MindSpore安装页面</a>完成安装。</p>
<div class="section" id="准备工作">
<h2>准备工作<a class="headerlink" href="#准备工作" title="永久链接至标题">¶</a></h2>
<p>我们提供了可供用户直接使用的<a class="reference external" href="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/federated/3500_clients_bin.zip">联邦学习图像分类数据集FEMNIST</a>，以及<code class="docutils literal notranslate"><span class="pre">.ms</span></code>格式的<a class="reference external" href="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/models/lenet_train.ms">端侧模型文件</a>。用户也可以根据实际需求，参考以下教程自行生成数据集和模型。</p>
<div class="section" id="生成端侧模型文件">
<h3>生成端侧模型文件<a class="headerlink" href="#生成端侧模型文件" title="永久链接至标题">¶</a></h3>
<ol>
<li><p>定义网络和训练过程。</p>
<p>具体网络和训练过程的定义可参考<a class="reference external" href="https://www.mindspore.cn/tutorials/zh-CN/master/beginner/quick_start.html#%E7%BD%91%E7%BB%9C%E6%9E%84%E5%BB%BA">快速入门</a>。</p>
</li>
<li><p>将模型导出为MindIR格式文件。</p>
<p>代码片段如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;weight initial for conv layer&quot;&quot;&quot;</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
        <span class="n">in_channels</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
        <span class="n">weight_init</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
        <span class="n">has_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span>
    <span class="p">)</span>

<span class="k">def</span> <span class="nf">fc_with_initialize</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;weight initial for fc layer&quot;&quot;&quot;</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">weight_variable</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;weight initial&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">ms</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">TruncatedNormal</span><span class="p">(</span><span class="mf">0.02</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">LeNet5</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_class</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeNet5</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_class</span> <span class="o">=</span> <span class="n">num_class</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">fc_with_initialize</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_class</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;export mindir for lenet&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--device_target&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--mindir_path&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                    <span class="n">default</span><span class="o">=</span><span class="s2">&quot;lenet_train.mindir&quot;</span><span class="p">)</span>  <span class="c1"># the mindir file path of the model to be export</span>

<span class="n">args</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">()</span>
<span class="n">device_target</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">device_target</span>
<span class="n">mindir_path</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">mindir_path</span>

<span class="n">ms</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">GRAPH_MODE</span><span class="p">,</span> <span class="n">device_target</span><span class="o">=</span><span class="n">device_target</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">LeNet5</span><span class="p">(</span><span class="mi">62</span><span class="p">)</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyWithLogits</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
    <span class="n">net_opt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">trainable_params</span><span class="p">(),</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
    <span class="n">net_with_criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">WithLossCell</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
    <span class="n">train_network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TrainOneStepCell</span><span class="p">(</span><span class="n">net_with_criterion</span><span class="p">,</span> <span class="n">net_opt</span><span class="p">)</span>
    <span class="n">train_network</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>

    <span class="n">data</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">62</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">ms</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">train_network</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="n">mindir_path</span><span class="p">,</span>
              <span class="n">file_format</span><span class="o">=</span><span class="s1">&#39;MINDIR&#39;</span><span class="p">)</span>  <span class="c1"># Add the export statement to obtain the model file in MindIR format.</span>
</pre></div>
</div>
<p>参数<code class="docutils literal notranslate"><span class="pre">--mindir_path</span></code>用于设置生成的MindIR格式文件路径。</p>
</li>
<li><p>将MindIR文件转化为联邦学习端侧框架可用的ms文件。</p>
<p>模型转换可参考<a class="reference external" href="https://www.mindspore.cn/lite/docs/zh-CN/master/use/converter_tool.html">训练模型转换教程</a>。</p>
<p>模型转换示例如下：</p>
<p>假设待转换的模型文件为<code class="docutils literal notranslate"><span class="pre">lenet_train.mindir</span></code>，执行如下转换命令：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>./converter_lite<span class="w"> </span>--fmk<span class="o">=</span>MINDIR<span class="w"> </span>--trainModel<span class="o">=</span><span class="nb">true</span><span class="w"> </span>--modelFile<span class="o">=</span>lenet_train.mindir<span class="w"> </span>--outputFile<span class="o">=</span>lenet_train
</pre></div>
</div>
<p>转换成功输出如下：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>CONVERTER<span class="w"> </span>RESULT<span class="w"> </span>SUCCESS:0
</pre></div>
</div>
<p>这表明MindSpore模型成功转换为MindSpore端侧模型，并生成了新文件<code class="docutils literal notranslate"><span class="pre">lenet_train.ms</span></code>。如果转换失败输出如下：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>CONVERT<span class="w"> </span>RESULT<span class="w"> </span>FAILED:
</pre></div>
</div>
<p>生成的<code class="docutils literal notranslate"><span class="pre">.ms</span></code>格式的模型文件为后续客户端所需的模型文件。</p>
</li>
</ol>
</div>
</div>
<div class="section" id="模拟启动多客户端参与联邦学习">
<h2>模拟启动多客户端参与联邦学习<a class="headerlink" href="#模拟启动多客户端参与联邦学习" title="永久链接至标题">¶</a></h2>
<div class="section" id="为客户端准备好模型文件">
<h3>为客户端准备好模型文件。<a class="headerlink" href="#为客户端准备好模型文件" title="永久链接至标题">¶</a></h3>
<p>本例在端侧使用lenet模拟实际用的网络，其中lenet的<code class="docutils literal notranslate"><span class="pre">.ms</span></code>格式的<a class="reference external" href="https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/models/lenet_train.ms">端侧模型文件</a>，由于真实场景一个客户端只包含一个.ms格式的模型文件，在模拟场景中，需要拷贝多份.ms文件，并按照<code class="docutils literal notranslate"><span class="pre">lenet_train{i}.ms</span></code>格式进行命名。其中i代表客户端编号，由于<code class="docutils literal notranslate"><span class="pre">run_client_x86.py</span></code>中，已自动为每个客户端拷贝.ms文件。
具体见<a class="reference external" href="https://gitee.com/mindspore/federated/blob/master/example/cross_device_lenet_femnist/simulate_x86/run_client_x86.py">启动脚本</a>中的copy_ms函数。</p>
</div>
<div class="section" id="启动云侧服务">
<h3>启动云侧服务<a class="headerlink" href="#启动云侧服务" title="永久链接至标题">¶</a></h3>
<p>用户可先参考<a class="reference external" href="https://www.mindspore.cn/federated/docs/zh-CN/master/deploy_federated_server.html">横向云侧部署教程</a>部署云侧环境，并启动云侧服务。</p>
</div>
<div class="section" id="启动客户端">
<h3>启动客户端<a class="headerlink" href="#启动客户端" title="永久链接至标题">¶</a></h3>
<p>启动客户端之前请先参照<a class="reference external" href="https://www.mindspore.cn/federated/docs/zh-CN/master/deploy_federated_client.html">横向端侧部署教程</a>进行端侧环境部署。</p>
<p>使用提供的<a class="reference external" href="https://gitee.com/mindspore/federated/blob/master/example/cross_device_lenet_femnist/simulate_x86/run_client_x86.py">run_client_x86.py</a>脚本进行端侧联邦学习的启动，通过相关参数的设置，来启动不同的联邦学习接口。
待云侧服务启动成功之后，使用提供run_client_x86.py的脚本，调用联邦学习框架jar包<code class="docutils literal notranslate"><span class="pre">mindspore-lite-java-flclient.jar</span></code> 和模型脚本对应的jar包<code class="docutils literal notranslate"><span class="pre">quick_start_flclient.jar</span></code>（可参考<a class="reference external" href="https://www.mindspore.cn/federated/docs/zh-CN/master/deploy_federated_client.html">横向端侧部署中编译出包流程</a>获取）来模拟启动多客户端参与联邦学习任务。</p>
<p>以LeNet网络为例，<code class="docutils literal notranslate"><span class="pre">run_client_x86.py</span></code>脚本中部分入参含义如下，用户可根据实际情况进行设置：</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">--fl_jar_path</span></code></p>
<p>设置联邦学习jar包路径，x86环境联邦学习jar包获取可参考<a class="reference external" href="https://www.mindspore.cn/federated/docs/zh-CN/master/deploy_federated_client.html">横向端侧部署中编译出包流程</a>。</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">--case_jar_path</span></code></p>
<p>设置模型脚本所生成的jar包<code class="docutils literal notranslate"><span class="pre">quick_start_flclient.jar</span></code>的路径，x86环境联邦学习jar包获取可参考<a class="reference external" href="https://www.mindspore.cn/federated/docs/zh-CN/master/deploy_federated_client.html">横向联邦端侧部署中编译出包流程</a>。</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">--lite_jar_path</span></code></p>
<p>设置mindspore lite的端侧jar包<code class="docutils literal notranslate"><span class="pre">mindspore-lite-java.jar</span></code>的路径，位于端侧包mindspore-lite-{version}-linux-x64.tar.gz中，x86环境联邦学习jar包获取可参考<a class="reference external" href="https://www.mindspore.cn/federated/docs/zh-CN/master/deploy_federated_client.html">横向端侧部署中构建环境依赖</a>。</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">--train_data_dir</span></code></p>
<p>训练数据集root路径，LeNet图片分类任务在该root路径中存放的是每个客户端的训练data.bin文件与label.bin文件，例如<code class="docutils literal notranslate"><span class="pre">data/femnist/3500_clients_bin/</span></code>。</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">--fl_name</span></code></p>
<p>联邦学习使用的模型脚本包路径。我们提供了两个类型的模型脚本供大家参考（<a class="reference external" href="https://gitee.com/mindspore/federated/tree/master/example/quick_start_flclient/src/main/java/com/mindspore/flclient/demo/albert">有监督情感分类任务</a>、<a class="reference external" href="https://gitee.com/mindspore/federated/tree/master/example/quick_start_flclient/src/main/java/com/mindspore/flclient/demo/lenet">LeNet图片分类任务</a>），对于有监督情感分类任务，该参数可设置为所提供的脚本文件<a class="reference external" href="https://gitee.com/mindspore/federated/blob/master/example/quick_start_flclient/src/main/java/com/mindspore/flclient/demo/albert/AlbertClient.java">AlBertClient.java</a> 的包路径<code class="docutils literal notranslate"><span class="pre">com.mindspore.flclient.demo.albert.AlbertClient</span></code>；对于LeNet图片分类任务，该参数可设置为所提供的脚本文件<a class="reference external" href="https://gitee.com/mindspore/federated/blob/master/example/quick_start_flclient/src/main/java/com/mindspore/flclient/demo/lenet/LenetClient.java">LenetClient.java</a> 的包路径<code class="docutils literal notranslate"><span class="pre">com.mindspore.flclient.demo.lenet.LenetClient</span></code>。同时，用户可参考这两个类型的模型脚本，自定义模型脚本，然后将该参数设置为自定义的模型文件ModelClient.java（需继承于类<a class="reference external" href="https://gitee.com/mindspore/federated/blob/master/mindspore_federated/device_client/src/main/java/com/mindspore/flclient/model/Client.java">Client.java</a>）的包路径即可。</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">--train_model_dir</span></code></p>
<p>设置联邦学习使用的训练模型路径，为上面教程中拷贝的多份.ms文件所存放的目录，比如<code class="docutils literal notranslate"><span class="pre">ms/lenet</span></code>，必须为绝对路径。</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">--domain_name</span></code></p>
<p>用于设置端云通信url，目前，可支持https和http通信，对应格式分别为：https://……、http://……，当<code class="docutils literal notranslate"><span class="pre">if_use_elb</span></code>设置为true时，格式必须为：https://127.0.0.1:6666 或者http://127.0.0.1:6666 ，其中<code class="docutils literal notranslate"><span class="pre">127.0.0.1</span></code>对应提供云侧服务的机器ip（即云侧参数<code class="docutils literal notranslate"><span class="pre">--scheduler_ip</span></code>），<code class="docutils literal notranslate"><span class="pre">6666</span></code>对应云侧参数<code class="docutils literal notranslate"><span class="pre">--fl_server_port</span></code>。</p>
<p>注意1，当该参数设置为<code class="docutils literal notranslate"><span class="pre">http://......</span></code>时代表使用HTTP通信，可能会存在通信安全风险，请知悉。</p>
<p>注意2，当该参数设置为<code class="docutils literal notranslate"><span class="pre">https://......</span></code>代表使用HTTPS通信。此时必须进行SSL证书认证，需要通过参数<code class="docutils literal notranslate"><span class="pre">--cert_path</span></code>设置证书路径。</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">--task</span></code></p>
<p>用于设置本此启动的任务类型，为<code class="docutils literal notranslate"><span class="pre">train</span></code>代表启动训练任务，为<code class="docutils literal notranslate"><span class="pre">inference</span></code>代表启动多条数据推理任务，为<code class="docutils literal notranslate"><span class="pre">getModel</span></code>代表启动获取云侧模型的任务，设置其他字符串代表启动单条数据推理任务。默认为<code class="docutils literal notranslate"><span class="pre">train</span></code>。由于初始的模型文件(.ms文件)是未训练过的，建议先启动训练任务，待训练完成之后，再启动推理任务（注意两次启动的<code class="docutils literal notranslate"><span class="pre">client_num</span></code>保持一致，以保证<code class="docutils literal notranslate"><span class="pre">inference</span></code>使用的模型文件与<code class="docutils literal notranslate"><span class="pre">train</span></code>保持一致）。</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">--batch_size</span></code></p>
<p>设置联邦学习训练和推理时使用的单步训练样本数，即batch size。需与模型的输入数据的batch size保持一致。</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">--client_num</span></code></p>
<p>设置client数量，与启动server端时的<code class="docutils literal notranslate"><span class="pre">start_fl_job_cnt</span></code>保持一致，真实场景不需要此参数。</p>
</li>
</ul>
<p>若想进一步了解<code class="docutils literal notranslate"><span class="pre">run_client_x86.py</span></code>脚本中其他参数含义，可参考脚本中注释部分。</p>
<p>联邦学习接口基本启动指令示例如下：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="w"> </span>rm<span class="w"> </span>-rf<span class="w"> </span>client_*<span class="se">\</span>
<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>rm<span class="w"> </span>-rf<span class="w"> </span>ms/*<span class="w"> </span><span class="se">\</span>
<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>python3<span class="w"> </span>run_client_x86.py<span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--fl_jar_path<span class="o">=</span><span class="s2">&quot;federated/mindspore_federated/device_client/build/libs/jarX86/mindspore-lite-java-flclient.jar&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--case_jar_path<span class="o">=</span><span class="s2">&quot;federated/example/quick_start_flclient/target/case_jar/quick_start_flclient.jar&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--lite_jar_path<span class="o">=</span><span class="s2">&quot;federated/mindspore_federated/device_client/third/mindspore-lite-2.0.0-linux-x64/runtime/lib/mindspore-lite-java.jar&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--train_data_dir<span class="o">=</span><span class="s2">&quot;federated/tests/st/simulate_x86/data/3500_clients_bin/&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--eval_data_dir<span class="o">=</span><span class="s2">&quot;null&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--infer_data_dir<span class="o">=</span><span class="s2">&quot;null&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--vocab_path<span class="o">=</span><span class="s2">&quot;null&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--ids_path<span class="o">=</span><span class="s2">&quot;null&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--path_regex<span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--fl_name<span class="o">=</span><span class="s2">&quot;com.mindspore.flclient.demo.lenet.LenetClient&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--origin_train_model_path<span class="o">=</span><span class="s2">&quot;federated/tests/st/simulate_x86/ms_files/lenet/lenet_train.ms&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--origin_infer_model_path<span class="o">=</span><span class="s2">&quot;null&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--train_model_dir<span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--infer_model_dir<span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--ssl_protocol<span class="o">=</span><span class="s2">&quot;TLSv1.2&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--deploy_env<span class="o">=</span><span class="s2">&quot;x86&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--domain_name<span class="o">=</span><span class="s2">&quot;http://10.113.216.40:8010&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--cert_path<span class="o">=</span><span class="s2">&quot;CARoot.pem&quot;</span><span class="w"> </span>--use_elb<span class="o">=</span><span class="s2">&quot;false&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--server_num<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--task<span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--thread_num<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--cpu_bind_mode<span class="o">=</span><span class="s2">&quot;NOT_BINDING_CORE&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--train_weight_name<span class="o">=</span><span class="s2">&quot;null&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--infer_weight_name<span class="o">=</span><span class="s2">&quot;null&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--name_regex<span class="o">=</span><span class="s2">&quot;::&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--server_mode<span class="o">=</span><span class="s2">&quot;FEDERATED_LEARNING&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--batch_size<span class="o">=</span><span class="m">32</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--input_shape<span class="o">=</span><span class="s2">&quot;null&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--client_num<span class="o">=</span><span class="m">8</span>
</pre></div>
</div>
<p>注意，启动指令中涉及路径的必须给出绝对路径。</p>
<p>以上指令代表启动8个客户端参与联邦学习训练任务，若启动成功，会在当前文件夹生成8个客户端对应的日志文件，查看日志文件内容可了解每个客户端的运行情况：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>     ./
     ├── client_0
     │   └── client.log  # 客户端0的日志文件
     │           ......
     └── client_7
         └── client.log  # 客户端4的日志文件
</pre></div>
</div>
<p>针对不同的接口和场景，只需根据参数含义，修改特定参数值即可，比如：</p>
<ul>
<li><p>启动联邦学习训练任务SyncFLJob.flJobRun()</p>
<p>当<code class="docutils literal notranslate"><span class="pre">基本启动指令</span></code>中 <code class="docutils literal notranslate"><span class="pre">--task</span></code>设置为<code class="docutils literal notranslate"><span class="pre">train</span></code>时代表启动该任务。</p>
<p>可通过指令<code class="docutils literal notranslate"><span class="pre">grep</span> <span class="pre">-r</span> <span class="pre">&quot;average</span> <span class="pre">loss:&quot;</span> <span class="pre">client_0/client.log</span></code>查看<code class="docutils literal notranslate"><span class="pre">client_0</span></code>在训练过程中每个epoch的平均loss，会有类似如下打印：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>INFO:<span class="w"> </span>&lt;FLClient&gt;<span class="w"> </span>----------epoch:0,average<span class="w"> </span>loss:4.1258564<span class="w"> </span>----------
......
</pre></div>
</div>
<p>也可通过指令<code class="docutils literal notranslate"><span class="pre">grep</span> <span class="pre">-r</span> <span class="pre">&quot;evaluate</span> <span class="pre">acc:&quot;</span> <span class="pre">client_0/client.log</span></code>查看<code class="docutils literal notranslate"><span class="pre">client_0</span></code>在每个联邦学习迭代中聚合后模型的验证精度，会有类似如下打印：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>INFO:<span class="w"> </span>&lt;FLClient&gt;<span class="w"> </span><span class="o">[</span>evaluate<span class="o">]</span><span class="w"> </span>evaluate<span class="w"> </span>acc:<span class="w"> </span><span class="m">0</span>.125
......
</pre></div>
</div>
<p>在云侧，可以通过设置yaml配置文件的<code class="docutils literal notranslate"><span class="pre">cluster_client_num</span></code>参数与<code class="docutils literal notranslate"><span class="pre">eval_type</span></code>参数来指定进行无监督聚类指标统计的客户端group id数量与算法类型，在云侧生成的<code class="docutils literal notranslate"><span class="pre">metrics.json</span></code>统计文件可以查询到无监督指标信息：</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&quot;unsupervisedEval&quot;:0.640
&quot;unsupervisedEval&quot;:0.675
&quot;unsupervisedEval&quot;:0.677
&quot;unsupervisedEval&quot;:0.706
......
</pre></div>
</div>
</li>
<li><p>启动推理任务SyncFLJob.modelInference()</p>
<p>当<code class="docutils literal notranslate"><span class="pre">基本启动指令</span></code>中 <code class="docutils literal notranslate"><span class="pre">--task</span></code>设置为<code class="docutils literal notranslate"><span class="pre">inference</span></code>时代表启动该任务。</p>
<p>可通过指令<code class="docutils literal notranslate"><span class="pre">grep</span> <span class="pre">-r</span> <span class="pre">&quot;the</span> <span class="pre">predicted</span> <span class="pre">labels:&quot;</span> <span class="pre">client_0/client.log</span></code>查看<code class="docutils literal notranslate"><span class="pre">client_0</span></code>的推理结果：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>INFO:<span class="w"> </span>&lt;FLClient&gt;<span class="w"> </span><span class="o">[</span>model<span class="w"> </span>inference<span class="o">]</span><span class="w"> </span>the<span class="w"> </span>predicted<span class="w"> </span>labels:<span class="w"> </span><span class="o">[</span><span class="m">0</span>,<span class="w"> </span><span class="m">0</span>,<span class="w"> </span><span class="m">0</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span>,<span class="w"> </span><span class="m">2</span><span class="o">]</span>
......
</pre></div>
</div>
</li>
<li><p>启动获取云侧最新模型任务SyncFLJob.getModel()</p>
<p>当<code class="docutils literal notranslate"><span class="pre">基本启动指令</span></code>中 <code class="docutils literal notranslate"><span class="pre">--task</span></code>设置为<code class="docutils literal notranslate"><span class="pre">getModel</span></code>时代表启动该任务。</p>
<p>在日志文件中若有如下内容代表获取云侧最新模型成功：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>INFO:<span class="w"> </span>&lt;FLClient&gt;<span class="w"> </span><span class="o">[</span>getModel<span class="o">]</span><span class="w"> </span>get<span class="w"> </span>response<span class="w"> </span>from<span class="w"> </span>server<span class="w"> </span>ok!
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="关闭客户端进程">
<h3>关闭客户端进程<a class="headerlink" href="#关闭客户端进程" title="永久链接至标题">¶</a></h3>
<p>可参考<a class="reference external" href="https://gitee.com/mindspore/federated/blob/master/example/cross_device_lenet_femnist/simulate_x86/finish.py">finish.py</a>脚本，具体如下：</p>
<p>关闭客户端指令如下：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>finish.py<span class="w"> </span>--kill_tag<span class="o">=</span>mindspore-lite-java-flclient
</pre></div>
</div>
<p>其中参数<code class="docutils literal notranslate"><span class="pre">--kill_tag</span></code>用于搜索该关键字对客户端进程进行kill，只需要设置<code class="docutils literal notranslate"><span class="pre">--jarPath</span></code>中的特殊关键字即可。默认为<code class="docutils literal notranslate"><span class="pre">mindspore-lite-java-flclient</span></code>，即联邦学习jar包名。
用户可通过指令<code class="docutils literal notranslate"><span class="pre">ps</span> <span class="pre">-ef</span> <span class="pre">|grep</span> <span class="pre">&quot;mindspore-lite-java-flclient&quot;</span></code>查看进程是否还存在。</p>
<p>50个客户端参与联邦学习训练任务实验结果。</p>
<p>目前<code class="docutils literal notranslate"><span class="pre">3500_clients_bin</span></code>文件夹中包含3500个客户端的数据，本脚本最多可模拟3500个客户端参与联邦学习。</p>
<p>下图给出了50个客户端(设置<code class="docutils literal notranslate"><span class="pre">server_num</span></code>为16)进行联邦学习的测试集精度：</p>
<p><img alt="lenet_50_clients_acc" src="_images/lenet_50_clients_acc.png" /></p>
<p>其中联邦学习总迭代数为100，客户端本地训练epoch数为20，batchSize设置为32。</p>
<p>图中测试精度指对于每个联邦学习迭代，各客户端测试集在云侧聚合后的模型上的精度。</p>
<p>AVG：对于每个联邦学习迭代，50个客户端测试集精度的平均值。</p>
<p>TOP5：对于每个联邦学习迭代，测试集精度最高的5个客户端的精度平均值。</p>
<p>LOW5：对于每个联邦学习迭代，测试集精度最低的5个客户端的精度平均值。</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="sentiment_classification_application.html" class="btn btn-neutral float-right" title="实现一个端云情感分类应用(Android)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="image_classfication_dataset_process.html" class="btn btn-neutral float-left" title="联邦学习图像分类数据集处理" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; 版权所有 2022, MindSpore.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   
	<script async="async" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>